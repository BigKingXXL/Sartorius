{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectron2\n",
    "First we need to install required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wxMyYEPBniL9",
    "outputId": "01ce06c0-7b95-498a-bde6-5149f2b9c30b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
      "gcc is already the newest version (4:7.4.0-1ubuntu2.3).\n",
      "git is already the newest version (1:2.17.1-1ubuntu0.9).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
      "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
      "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-id0edx1s\n",
      "  Running command git clone --filter=blob:none -q https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-id0edx1s\n",
      "  Resolved https://github.com/facebookresearch/detectron2.git to commit e3053c14cfcce515de03d3093c0a7b4e734fa41f\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.6) (8.4.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from detectron2==0.6) (3.5.1)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.6) (2.0.3)\n",
      "Requirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.6) (1.1.0)\n",
      "Requirement already satisfied: yacs>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.6) (0.1.8)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.7/site-packages (from detectron2==0.6) (0.8.9)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from detectron2==0.6) (2.0.0)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.6) (4.61.2)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (from detectron2==0.6) (2.7.0)\n",
      "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.6) (0.1.5.post20211023)\n",
      "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.6) (0.1.9)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from detectron2==0.6) (0.18.2)\n",
      "Requirement already satisfied: pydot in /opt/conda/lib/python3.7/site-packages (from detectron2==0.6) (1.4.2)\n",
      "Requirement already satisfied: omegaconf>=2.1 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.6) (2.1.1)\n",
      "Requirement already satisfied: hydra-core>=1.1 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.6) (1.1.1)\n",
      "Requirement already satisfied: black==21.4b2 in /opt/conda/lib/python3.7/site-packages (from detectron2==0.6) (21.4b2)\n",
      "Requirement already satisfied: click>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from black==21.4b2->detectron2==0.6) (8.0.3)\n",
      "Requirement already satisfied: toml>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from black==21.4b2->detectron2==0.6) (0.10.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.7/site-packages (from black==21.4b2->detectron2==0.6) (0.4.3)\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.7/site-packages (from black==21.4b2->detectron2==0.6) (1.4.4)\n",
      "Requirement already satisfied: typed-ast>=1.4.2 in /opt/conda/lib/python3.7/site-packages (from black==21.4b2->detectron2==0.6) (1.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from black==21.4b2->detectron2==0.6) (3.10.0.2)\n",
      "Requirement already satisfied: pathspec<1,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from black==21.4b2->detectron2==0.6) (0.9.0)\n",
      "Requirement already satisfied: regex>=2020.1.8 in /opt/conda/lib/python3.7/site-packages (from black==21.4b2->detectron2==0.6) (2021.11.10)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.21.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (5.4.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.8 in /opt/conda/lib/python3.7/site-packages (from hydra-core>=1.1->detectron2==0.6) (4.8)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.7/site-packages (from hydra-core>=1.1->detectron2==0.6) (5.4.0)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.3.2)\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools>=2.0.2->detectron2==0.6) (58.0.4)\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from pycocotools>=2.0.2->detectron2==0.6) (0.29.26)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2==0.6) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2==0.6) (4.28.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2==0.6) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2==0.6) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->detectron2==0.6) (21.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.6) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.6) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.6) (2.0.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.6) (0.36.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.6) (0.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.6) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.6) (2.3.3)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.6) (1.43.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.6) (1.8.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.6) (3.19.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard->detectron2==0.6) (2.25.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py>=0.4->tensorboard->detectron2==0.6) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click>=7.1.2->black==21.4b2->detectron2==0.6) (4.10.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (1.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from importlib-resources->hydra-core>=1.1->detectron2==0.6) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (3.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!apt install git gcc g++ -y\n",
    "!pip install \"git+https://github.com/facebookresearch/detectron2.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libsm6 is already the newest version (2:1.2.2-1).\n",
      "libxext6 is already the newest version (2:1.3.3-1).\n",
      "unzip is already the newest version (6.0-21ubuntu1.1).\n",
      "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (4.5.5.62)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (1.7.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (1.0.2)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (0.19.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (1.21.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (3.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (2.13.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (8.4.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (2.6.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (1.2.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image) (2021.11.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->scikit-image) (3.0.6)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!apt-get install ffmpeg libsm6 libxext6 unzip  -y\n",
    "!pip install opencv-python scipy scikit-learn scikit-image pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XeZJTCYvroGM",
    "outputId": "083142f6-eaf6-4ebb-dfb9-e880e9aeccfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (21.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Found existing installation: kaggle 1.5.12\n",
      "Uninstalling kaggle-1.5.12:\n",
      "  Successfully uninstalled kaggle-1.5.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting kaggle\n",
      "  Using cached kaggle-1.5.12-py3-none-any.whl\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from kaggle) (1.26.6)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kaggle) (2021.10.8)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.7/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from kaggle) (4.61.2)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.7/site-packages (from kaggle) (5.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from kaggle) (2.25.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.7/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->kaggle) (2.10)\n",
      "Installing collected packages: kaggle\n",
      "Successfully installed kaggle-1.5.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade pip\n",
    "!pip uninstall --yes kaggle\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle\n",
    "\n",
    "We need to set the kaggle API key in order to download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "id": "VhgUGj4UrtkL",
    "outputId": "d6827368-182a-435f-a3fd-758c5311d08b"
   },
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /root/.kaggle/kaggle.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile ~/.kaggle/kaggle.json\n",
    "{\"username\":\"maximilianschulze\",\"key\":\"secretkey\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6shzeU1er3W_",
    "outputId": "ec5f7c5d-81c1-4ad4-96ad-fb02c44d13aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "Downloading sartorius-cell-instance-segmentation.zip to /workspace\n",
      "100%|█████████████████████████████████████▉| 2.31G/2.31G [01:35<00:00, 25.0MB/s]\n",
      "100%|██████████████████████████████████████| 2.31G/2.31G [01:35<00:00, 26.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c sartorius-cell-instance-segmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tuydqb1PZRkk",
    "outputId": "aa82add0-30da-418b-d783-2f2c957485d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
      "Downloading livecell-dataset.zip to livecell\n",
      "100%|█████████████████████████████████████▉| 4.51G/4.51G [03:02<00:00, 28.0MB/s]\n",
      "100%|██████████████████████████████████████| 4.51G/4.51G [03:02<00:00, 26.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d markunys/livecell-dataset -p livecell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "AdAetcC3tdoH"
   },
   "outputs": [],
   "source": [
    "!unzip sartorius-cell-instance-segmentation.zip > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0gov4PliZj1A",
    "outputId": "ce7d0ad0-73aa-4f0f-c113-12d0c7f24802"
   },
   "outputs": [],
   "source": [
    "%cd livecell\n",
    "!unzip livecell-dataset.zip\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train detectron\n",
    "\n",
    "Now that we installed all dependencies and unpacked all the required data we can start to train detectron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gyIPPP40nkyo",
    "outputId": "1df51d9a-afd5-4d69-e922-93c0f9ad5617"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import detectron2\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import random, cv2, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pycocotools.mask as mask_util\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.evaluation.evaluator import DatasetEvaluator\n",
    "import copy\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4yxavnJt4Aa",
    "outputId": "e013a7d2-d2be-41e8-fa54-0088a8a35248"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycocotools in /opt/conda/lib/python3.7/site-packages (2.0.3)\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (0.29.26)\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (58.0.4)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (3.5.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (3.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (4.28.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pycocotools\n",
    "from pycocotools.coco import COCO\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import pycocotools\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "# From https://www.kaggle.com/stainsby/fast-tested-rle\n",
    "def rle_decode(mask_rle, shape):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape)  # Needed to align to RLE direction\n",
    "\n",
    "# From https://newbedev.com/encode-numpy-array-using-uncompressed-rle-for-coco-dataset\n",
    "def binary_mask_to_rle(binary_mask):\n",
    "    rle = {'counts': [], 'size': list(binary_mask.shape)}\n",
    "    counts = rle.get('counts')\n",
    "    for i, (value, elements) in enumerate(itertools.groupby(binary_mask.ravel(order='F'))):\n",
    "        if i == 0 and value == 1:\n",
    "            counts.append(0)\n",
    "        counts.append(len(list(elements)))\n",
    "    return rle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load annotations and convert them to COCO format\n",
    "\n",
    "First we load all the masks and convert them to the coco format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists(\"out.pickle\")):\n",
    "  with open(\"out.pickle\", \"rb\") as handle:\n",
    "    out = pickle.load(handle)\n",
    "else:\n",
    "  train_df = pd.read_csv('./train.csv')\n",
    "  out = []\n",
    "  # Create unique IDs from the masks\n",
    "  cat_ids = {name:id+1 for id, name in enumerate(train_df.cell_type.unique())} \n",
    "  # For each image which is identifiable by the id create a dict with information about\n",
    "  # the image and about the segmentation masks\n",
    "  for index, group in tqdm(train_df.groupby(\"id\")):\n",
    "      image = {}\n",
    "      image[\"file_name\"] = f\"{index}.png\"\n",
    "      image[\"height\"] = 520\n",
    "      image[\"width\"] = 704\n",
    "      image[\"image_id\"] = index\n",
    "      image[\"annotations\"] = []\n",
    "      # For each instance we create a mask annotation\n",
    "      for _, row in group.iterrows():\n",
    "          annotation = {}\n",
    "          mk = rle_decode(row[\"annotation\"], (row[\"height\"], row[\"width\"]))\n",
    "          # Get the x and y coordinates where the mask is present\n",
    "          ys, xs = np.where(mk)\n",
    "          # Get the x position of the upper left corner\n",
    "          x1 = min(xs)\n",
    "          # Get the x position of the lower right corner\n",
    "          x2 = max(xs)\n",
    "          # Get the y position of the upper left corner\n",
    "          y1 = min(ys)\n",
    "          # Get the y position of the lower right corner\n",
    "          y2 = max(ys)\n",
    "          # Use the coordinates to get the bounding box\n",
    "          annotation[\"bbox\"] = [int(x1), int(y1), int(x2), int(y2)]\n",
    "\n",
    "          annotation[\"bbox_mode\"] = 0\n",
    "          annotation[\"image_id\"] = index\n",
    "          # Set the category\n",
    "          annotation[\"category_id\"] = cat_ids[row.cell_type]\n",
    "          # Encode the segmentation mask using pycocotools\n",
    "          annotation[\"segmentation\"] = pycocotools.mask.encode(np.asarray(mk, order=\"F\"))\n",
    "          # annotation[\"segmentation\"][\"counts\"] = annotation[\"segmentation\"][\"counts\"].decode(\"utf8\")\n",
    "          # Append the annotation to the segmentation masks\n",
    "          image[\"annotations\"].append(annotation)\n",
    "      out.append(image)\n",
    "  # save the result in a pickle file so that we don't have to precompute every time\n",
    "  with open(\"out.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(out, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "v_0sFBaQuPP3"
   },
   "outputs": [],
   "source": [
    "# Filters the annotations so that we get a dataset with only\n",
    "# one celltype\n",
    "def getClassOut(classNum: int):\n",
    "  outClone = [copy.deepcopy(img) for img in out]\n",
    "  for img in outClone:\n",
    "    # Set the file_name to the correct path\n",
    "    img[\"file_name\"] = 'train/' + img[\"file_name\"]\n",
    "    newAnnotations = []\n",
    "    for seg in img[\"annotations\"]:\n",
    "      # Keep only cells with the type we want to filter\n",
    "      if seg[\"category_id\"] == classNum + 1:\n",
    "        seg[\"category_id\"] = 1\n",
    "        newAnnotations.append(seg)\n",
    "    img[\"annotations\"] = newAnnotations\n",
    "  return outClone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NNv6jMAzA54D"
   },
   "outputs": [],
   "source": [
    "# Sets the filename of the dataset correctly\n",
    "def getAllOut():\n",
    "  outClone = [copy.deepcopy(img) for img in out]\n",
    "  for img in outClone:\n",
    "    img[\"file_name\"] = 'train/' + img[\"file_name\"]\n",
    "  return outClone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register datasets\n",
    "\n",
    "After computation of the annotations we need to register the annotations. We use *10%* of the data as validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "C1pr2PElnpwT"
   },
   "outputs": [],
   "source": [
    "#dataDir=Path('../input/sartorius-cell-instance-segmentation/')\n",
    "#register_coco_instances('sartorius_train',{}, '../input/sartorius-cell-instance-segmentation-coco/annotations_train.json', dataDir)\n",
    "#register_coco_instances('sartorius_val',{},'../input/sartorius-cell-instance-segmentation-coco/annotations_val.json', dataDir)\n",
    "DatasetCatalog.clear()\n",
    "MetadataCatalog.clear()\n",
    "livecellData = 'livecell/LIVECell_dataset_2021/images'\n",
    "register_coco_instances('livecell_test', {}, 'livecell/livecell_annotations_test.json', livecellData)\n",
    "register_coco_instances('livecell_train', {}, 'livecell/livecell_annotations_train.json', livecellData)\n",
    "register_coco_instances('livecell_val', {}, 'livecell/livecell_annotations_val.json', livecellData)\n",
    "allOut = getAllOut()\n",
    "# We use 10% of the data as validation data\n",
    "DatasetCatalog.register('sartorius_train', lambda: allOut[:int(len(allOut)*0.9)])\n",
    "DatasetCatalog.register('sartorius_val', lambda: allOut[int(len(allOut)*0.9):])\n",
    "classOut = {}\n",
    "for classNum in range(3):\n",
    "  classOut[classNum] = getClassOut(classNum)\n",
    "  DatasetCatalog.register(f'sartorius_train_{classNum}', lambda: classOut[classNum][:int(len(classOut[classNum])*0.9)])\n",
    "  DatasetCatalog.register(f'sartorius_val_{classNum}', lambda: classOut[classNum][int(len(classOut[classNum])*0.9):])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AXGkdUpgTsnP"
   },
   "outputs": [],
   "source": [
    "# Evaluation masks taken and modified from\n",
    "# https://www.kaggle.com/ammarnassanalhajali/sartorius-segmentation-detectron2-training\n",
    "from detectron2.structures import polygons_to_bitmask\n",
    "def polygon_to_rleLiveCell(polygon, shape=(520, 704)):\n",
    "    #print(polygon)\n",
    "    mask = polygons_to_bitmask([np.asarray(polygon) + 0.25], shape[0], shape[1])\n",
    "\n",
    "    rle = mask_util.encode(np.asfortranarray(mask))\n",
    "    return rle\n",
    "\n",
    "# Taken from https://www.kaggle.com/theoviel/competition-metric-map-iou\n",
    "def precision_atLiveCell(threshold, iou):\n",
    "    matches = iou > threshold\n",
    "    true_positives = np.sum(matches, axis=1) == 1  # Correct objects\n",
    "    false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "    false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "\n",
    "def scoreLiveCell(pred, targ):\n",
    "    pred_masks = pred['instances'].pred_masks.cpu().numpy()\n",
    "    enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in pred_masks]\n",
    "    enc_targs = list(map(lambda x:x['segmentation'], targ))\n",
    "    enc_targs = [polygon_to_rleLiveCell(enc_targ[0]) for enc_targ in enc_targs]\n",
    "    ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_atLiveCell(t, ious)\n",
    "        p = tp / (tp + fp + fn)\n",
    "        prec.append(p)\n",
    "    return np.mean(prec)\n",
    "\n",
    "class MAPIOUEvaluatorLiveCELL(DatasetEvaluator):\n",
    "    def __init__(self, dataset_name):\n",
    "        dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "        self.annotations_cache = {item['image_id']:item['annotations'] for item in dataset_dicts}\n",
    "            \n",
    "    def reset(self):\n",
    "        self.scores = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        for inp, out in zip(inputs, outputs):\n",
    "            if len(out['instances']) == 0:\n",
    "                self.scores.append(0)    \n",
    "            else:\n",
    "                targ = self.annotations_cache[inp['image_id']]\n",
    "                self.scores.append(scoreLiveCell(out, targ))\n",
    "\n",
    "    def evaluate(self):\n",
    "        return {\"MaP IoU\": np.mean(self.scores)}\n",
    "\n",
    "class TrainerLiveCell(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return MAPIOUEvaluatorLiveCELL(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "QT-EBYLHnshb"
   },
   "outputs": [],
   "source": [
    "# Evaluation masks taken and modified from\n",
    "# https://www.kaggle.com/ammarnassanalhajali/sartorius-segmentation-detectron2-training\n",
    "# Taken from https://www.kaggle.com/theoviel/competition-metric-map-iou\n",
    "def precision_at(threshold, iou):\n",
    "    matches = iou > threshold\n",
    "    if len(matches) == 0:\n",
    "      return 0, 0, 0\n",
    "    true_positives = np.sum(matches, axis=1) == 1  # Correct objects\n",
    "    false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "    false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "    return np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "\n",
    "def score(pred, targ):\n",
    "    pred_masks = pred['instances'].pred_masks.cpu().numpy()\n",
    "    enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in pred_masks]\n",
    "    enc_targs = list(map(lambda x:x['segmentation'], targ))\n",
    "    ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, ious)\n",
    "        p = tp / (tp + fp + fn) if (tp + fp + fn) != 0 else 0\n",
    "        prec.append(p)\n",
    "    return np.mean(prec)\n",
    "\n",
    "class MAPIOUEvaluator(DatasetEvaluator):\n",
    "    def __init__(self, dataset_name):\n",
    "        dataset_dicts = DatasetCatalog.get(dataset_name)\n",
    "        self.annotations_cache = {item['image_id']:item['annotations'] for item in dataset_dicts}\n",
    "            \n",
    "    def reset(self):\n",
    "        self.scores = []\n",
    "\n",
    "    def process(self, inputs, outputs):\n",
    "        for inp, out in zip(inputs, outputs):\n",
    "          if len(out['instances']) == 0 and len(self.annotations_cache[inp['image_id']]) != 0:\n",
    "            self.scores.append(0)\n",
    "          elif len(out['instances']) == 0 and len(self.annotations_cache[inp['image_id']]) == 0:\n",
    "            self.scores.append(1)\n",
    "          else:\n",
    "            targ = self.annotations_cache[inp['image_id']]\n",
    "            self.scores.append(score(out, targ))\n",
    "\n",
    "    def evaluate(self):\n",
    "        return {\"MaP IoU\": np.mean(self.scores)}\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return MAPIOUEvaluator(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Train Detectron2 with LiveCell Data\n",
    "\n",
    "First we pretrain the Detectron2 model with the LiveCell data. We tried two different configurations, one with a ResNet101 backbone and one with a ResNet 50 backbone. The ResNet50 backbone seems to archieve much better performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CDl5__bWIquK"
   },
   "outputs": [],
   "source": [
    "def trainModelLiveCell():\n",
    "  epochLength = (len(DatasetCatalog.get('livecell_train')) + len(DatasetCatalog.get('livecell_test'))) // 2\n",
    "  cfg = get_cfg()\n",
    "  cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "  cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "  \n",
    "  cfg.DATASETS.TRAIN = (\"livecell_train\", \"livecell_test\")\n",
    "  cfg.DATASETS.TEST = (\"livecell_val\",)\n",
    "  cfg.TEST.EVAL_PERIOD = epochLength\n",
    "  cfg.SOLVER.CHECKPOINT_PERIOD = epochLength\n",
    "  cfg.DATALOADER.NUM_WORKERS = 2\n",
    "  # Use the official pretrained weights\n",
    "  cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")\n",
    "  cfg.SOLVER.BASE_LR = 0.005\n",
    "  cfg.SOLVER.MAX_ITER = epochLength * 20\n",
    "  cfg.SOLVER.STEPS = []\n",
    "  cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "  # Set the number of classes to eight as LiveCell includes eight different cell tpes\n",
    "  cfg.MODEL.ROI_HEADS.NUM_CLASSES = 8\n",
    "  cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "  cfg.OUTPUT_DIR = os.path.join(cfg.OUTPUT_DIR, f'/livecell')\n",
    "  print(cfg.OUTPUT_DIR)\n",
    "  os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "  trainer = TrainerLiveCell(cfg) \n",
    "  trainer.resume_or_load(resume=False)\n",
    "  trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GlGx0qHOEdM7"
   },
   "outputs": [],
   "source": [
    "def trainModelLiveCell50():\n",
    "  epochLength = (len(DatasetCatalog.get('livecell_train')) + len(DatasetCatalog.get('livecell_test')))\n",
    "  cfg = get_cfg()\n",
    "  cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "  cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "  \n",
    "  cfg.DATASETS.TRAIN = (\"livecell_train\", \"livecell_test\")\n",
    "  cfg.DATASETS.TEST = (\"livecell_val\",)\n",
    "  cfg.TEST.EVAL_PERIOD = epochLength\n",
    "  cfg.SOLVER.CHECKPOINT_PERIOD = epochLength // 2\n",
    "  cfg.DATALOADER.NUM_WORKERS = 2\n",
    "  cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "  cfg.SOLVER.BASE_LR = 0.01 * 2 / 16\n",
    "  cfg.SOLVER.MAX_ITER = epochLength * 20\n",
    "  cfg.SOLVER.STEPS = []\n",
    "  cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "  cfg.MODEL.ROI_HEADS.NUM_CLASSES = 8\n",
    "  cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "  cfg.OUTPUT_DIR = os.path.join(cfg.OUTPUT_DIR, f'./livecell50')\n",
    "  print(cfg.OUTPUT_DIR)\n",
    "  os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "  trainer = TrainerLiveCell(cfg) \n",
    "  trainer.resume_or_load(resume=True)\n",
    "  trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "40g9GPuoEmDP",
    "outputId": "91428f2d-218f-4459-d1f2-5be36b8deb81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 21:30:38 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_train.json takes 15.25 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/29 21:30:38 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/29 21:30:38 d2.data.datasets.coco]: \u001b[0mLoaded 3253 images in COCO format from livecell/livecell_annotations_train.json\n",
      "\u001b[32m[12/29 21:30:51 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_test.json takes 7.03 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/29 21:30:51 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/29 21:30:51 d2.data.datasets.coco]: \u001b[0mLoaded 1564 images in COCO format from livecell/livecell_annotations_test.json\n",
      "./output/./livecell50\n",
      "\u001b[32m[12/29 21:30:54 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=9, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=32, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 21:31:09 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_train.json takes 14.55 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/29 21:31:09 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/29 21:31:09 d2.data.datasets.coco]: \u001b[0mLoaded 3253 images in COCO format from livecell/livecell_annotations_train.json\n",
      "\u001b[32m[12/29 21:31:23 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_test.json takes 7.06 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/29 21:31:23 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/29 21:31:23 d2.data.datasets.coco]: \u001b[0mLoaded 1564 images in COCO format from livecell/livecell_annotations_test.json\n",
      "\u001b[32m[12/29 21:31:24 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 4817 images left.\n",
      "\u001b[32m[12/29 21:31:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[12/29 21:31:25 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/29 21:31:25 d2.data.common]: \u001b[0mSerializing 4817 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 21:31:28 d2.data.common]: \u001b[0mSerialized dataset takes 707.55 MiB\n",
      "\u001b[32m[12/29 21:31:31 d2.engine.hooks]: \u001b[0mLoading scheduler from state_dict ...\n",
      "\u001b[32m[12/29 21:31:31 d2.engine.train_loop]: \u001b[0mStarting training from iteration 7224\n",
      "\u001b[32m[12/29 21:31:34 d2.utils.events]: \u001b[0m eta: 5:16:18  iter: 7239  total_loss: 1.298  loss_cls: 0.3588  loss_box_reg: 0.4502  loss_mask: 0.2705  loss_rpn_cls: 0.08398  loss_rpn_loc: 0.1733  time: 0.2165  data_time: 0.0277  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:31:40 d2.utils.events]: \u001b[0m eta: 5:22:46  iter: 7259  total_loss: 1.317  loss_cls: 0.3264  loss_box_reg: 0.414  loss_mask: 0.2869  loss_rpn_cls: 0.09077  loss_rpn_loc: 0.1815  time: 0.2373  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:31:44 d2.utils.events]: \u001b[0m eta: 5:25:00  iter: 7279  total_loss: 1.458  loss_cls: 0.3954  loss_box_reg: 0.4643  loss_mask: 0.2824  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.19  time: 0.2366  data_time: 0.0172  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:31:49 d2.utils.events]: \u001b[0m eta: 5:25:39  iter: 7299  total_loss: 1.283  loss_cls: 0.3196  loss_box_reg: 0.4017  loss_mask: 0.2734  loss_rpn_cls: 0.0834  loss_rpn_loc: 0.1812  time: 0.2350  data_time: 0.0185  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:31:53 d2.utils.events]: \u001b[0m eta: 5:23:18  iter: 7319  total_loss: 1.42  loss_cls: 0.4085  loss_box_reg: 0.4301  loss_mask: 0.2876  loss_rpn_cls: 0.08116  loss_rpn_loc: 0.1698  time: 0.2311  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:31:58 d2.utils.events]: \u001b[0m eta: 5:23:42  iter: 7339  total_loss: 1.302  loss_cls: 0.3436  loss_box_reg: 0.3917  loss_mask: 0.2639  loss_rpn_cls: 0.1077  loss_rpn_loc: 0.1823  time: 0.2314  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:32:02 d2.utils.events]: \u001b[0m eta: 5:25:15  iter: 7359  total_loss: 1.275  loss_cls: 0.345  loss_box_reg: 0.3907  loss_mask: 0.2507  loss_rpn_cls: 0.08507  loss_rpn_loc: 0.1703  time: 0.2313  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:32:07 d2.utils.events]: \u001b[0m eta: 5:25:29  iter: 7379  total_loss: 1.263  loss_cls: 0.3169  loss_box_reg: 0.4003  loss_mask: 0.2731  loss_rpn_cls: 0.08328  loss_rpn_loc: 0.1815  time: 0.2308  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:32:11 d2.utils.events]: \u001b[0m eta: 5:25:06  iter: 7399  total_loss: 1.391  loss_cls: 0.3525  loss_box_reg: 0.4402  loss_mask: 0.264  loss_rpn_cls: 0.0778  loss_rpn_loc: 0.1768  time: 0.2284  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:32:16 d2.utils.events]: \u001b[0m eta: 5:24:23  iter: 7419  total_loss: 1.355  loss_cls: 0.3476  loss_box_reg: 0.4216  loss_mask: 0.2828  loss_rpn_cls: 0.09266  loss_rpn_loc: 0.1779  time: 0.2274  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:32:20 d2.utils.events]: \u001b[0m eta: 5:24:41  iter: 7439  total_loss: 1.266  loss_cls: 0.3293  loss_box_reg: 0.365  loss_mask: 0.2589  loss_rpn_cls: 0.07358  loss_rpn_loc: 0.1829  time: 0.2271  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:32:24 d2.utils.events]: \u001b[0m eta: 5:24:37  iter: 7459  total_loss: 1.393  loss_cls: 0.3572  loss_box_reg: 0.4517  loss_mask: 0.2751  loss_rpn_cls: 0.09891  loss_rpn_loc: 0.1726  time: 0.2262  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:32:29 d2.utils.events]: \u001b[0m eta: 5:24:35  iter: 7479  total_loss: 1.406  loss_cls: 0.39  loss_box_reg: 0.422  loss_mask: 0.2726  loss_rpn_cls: 0.1058  loss_rpn_loc: 0.1838  time: 0.2256  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:32:33 d2.utils.events]: \u001b[0m eta: 5:24:56  iter: 7499  total_loss: 1.361  loss_cls: 0.3678  loss_box_reg: 0.4131  loss_mask: 0.2764  loss_rpn_cls: 0.1108  loss_rpn_loc: 0.1866  time: 0.2259  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:32:38 d2.utils.events]: \u001b[0m eta: 5:24:40  iter: 7519  total_loss: 1.403  loss_cls: 0.3676  loss_box_reg: 0.425  loss_mask: 0.2799  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.1763  time: 0.2257  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:32:42 d2.utils.events]: \u001b[0m eta: 5:24:22  iter: 7539  total_loss: 1.319  loss_cls: 0.3387  loss_box_reg: 0.4299  loss_mask: 0.2639  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.1724  time: 0.2255  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:32:47 d2.utils.events]: \u001b[0m eta: 5:24:49  iter: 7559  total_loss: 1.324  loss_cls: 0.3235  loss_box_reg: 0.3918  loss_mask: 0.2776  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.169  time: 0.2259  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:32:51 d2.utils.events]: \u001b[0m eta: 5:24:27  iter: 7579  total_loss: 1.381  loss_cls: 0.3823  loss_box_reg: 0.411  loss_mask: 0.2803  loss_rpn_cls: 0.103  loss_rpn_loc: 0.1827  time: 0.2256  data_time: 0.0171  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:32:56 d2.utils.events]: \u001b[0m eta: 5:25:22  iter: 7599  total_loss: 1.4  loss_cls: 0.358  loss_box_reg: 0.4154  loss_mask: 0.2917  loss_rpn_cls: 0.1216  loss_rpn_loc: 0.1956  time: 0.2269  data_time: 0.0215  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:33:01 d2.utils.events]: \u001b[0m eta: 5:25:33  iter: 7619  total_loss: 1.344  loss_cls: 0.3476  loss_box_reg: 0.4585  loss_mask: 0.2902  loss_rpn_cls: 0.07558  loss_rpn_loc: 0.1712  time: 0.2268  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:34:53 d2.utils.events]: \u001b[0m eta: 5:22:09  iter: 8119  total_loss: 1.308  loss_cls: 0.3508  loss_box_reg: 0.4248  loss_mask: 0.2697  loss_rpn_cls: 0.111  loss_rpn_loc: 0.18  time: 0.2245  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:34:57 d2.utils.events]: \u001b[0m eta: 5:22:04  iter: 8139  total_loss: 1.369  loss_cls: 0.3433  loss_box_reg: 0.4281  loss_mask: 0.2689  loss_rpn_cls: 0.1067  loss_rpn_loc: 0.1795  time: 0.2244  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:35:01 d2.utils.events]: \u001b[0m eta: 5:21:45  iter: 8159  total_loss: 1.377  loss_cls: 0.3734  loss_box_reg: 0.4341  loss_mask: 0.2773  loss_rpn_cls: 0.092  loss_rpn_loc: 0.192  time: 0.2242  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:35:06 d2.utils.events]: \u001b[0m eta: 5:21:55  iter: 8179  total_loss: 1.299  loss_cls: 0.3337  loss_box_reg: 0.4021  loss_mask: 0.2773  loss_rpn_cls: 0.1029  loss_rpn_loc: 0.1768  time: 0.2242  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:35:10 d2.utils.events]: \u001b[0m eta: 5:21:51  iter: 8199  total_loss: 1.32  loss_cls: 0.3281  loss_box_reg: 0.4288  loss_mask: 0.2754  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.1884  time: 0.2242  data_time: 0.0110  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:35:15 d2.utils.events]: \u001b[0m eta: 5:21:32  iter: 8219  total_loss: 1.257  loss_cls: 0.3429  loss_box_reg: 0.4066  loss_mask: 0.2615  loss_rpn_cls: 0.07698  loss_rpn_loc: 0.1757  time: 0.2243  data_time: 0.0233  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:35:19 d2.utils.events]: \u001b[0m eta: 5:21:27  iter: 8239  total_loss: 1.269  loss_cls: 0.2897  loss_box_reg: 0.4266  loss_mask: 0.2779  loss_rpn_cls: 0.0825  loss_rpn_loc: 0.1806  time: 0.2242  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 21:35:24 d2.utils.events]: \u001b[0m eta: 5:21:07  iter: 8259  total_loss: 1.291  loss_cls: 0.3347  loss_box_reg: 0.4186  loss_mask: 0.2677  loss_rpn_cls: 0.08459  loss_rpn_loc: 0.1839  time: 0.2240  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:35:28 d2.utils.events]: \u001b[0m eta: 5:21:08  iter: 8279  total_loss: 1.192  loss_cls: 0.2704  loss_box_reg: 0.3678  loss_mask: 0.2647  loss_rpn_cls: 0.09439  loss_rpn_loc: 0.1755  time: 0.2242  data_time: 0.0174  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:35:33 d2.utils.events]: \u001b[0m eta: 5:20:29  iter: 8299  total_loss: 1.347  loss_cls: 0.3643  loss_box_reg: 0.431  loss_mask: 0.2874  loss_rpn_cls: 0.09616  loss_rpn_loc: 0.1885  time: 0.2240  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:35:37 d2.utils.events]: \u001b[0m eta: 5:20:52  iter: 8319  total_loss: 1.257  loss_cls: 0.365  loss_box_reg: 0.3873  loss_mask: 0.264  loss_rpn_cls: 0.08971  loss_rpn_loc: 0.1575  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:35:42 d2.utils.events]: \u001b[0m eta: 5:20:55  iter: 8339  total_loss: 1.185  loss_cls: 0.3163  loss_box_reg: 0.3958  loss_mask: 0.2666  loss_rpn_cls: 0.09434  loss_rpn_loc: 0.1696  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:35:46 d2.utils.events]: \u001b[0m eta: 5:19:56  iter: 8359  total_loss: 1.151  loss_cls: 0.2869  loss_box_reg: 0.3703  loss_mask: 0.2638  loss_rpn_cls: 0.09202  loss_rpn_loc: 0.1695  time: 0.2238  data_time: 0.0092  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:35:50 d2.utils.events]: \u001b[0m eta: 5:19:36  iter: 8379  total_loss: 1.336  loss_cls: 0.3552  loss_box_reg: 0.4422  loss_mask: 0.2868  loss_rpn_cls: 0.07443  loss_rpn_loc: 0.1899  time: 0.2235  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:35:54 d2.utils.events]: \u001b[0m eta: 5:19:34  iter: 8399  total_loss: 1.347  loss_cls: 0.356  loss_box_reg: 0.4489  loss_mask: 0.2943  loss_rpn_cls: 0.08898  loss_rpn_loc: 0.178  time: 0.2234  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:35:59 d2.utils.events]: \u001b[0m eta: 5:19:27  iter: 8419  total_loss: 1.351  loss_cls: 0.3597  loss_box_reg: 0.4229  loss_mask: 0.2781  loss_rpn_cls: 0.07211  loss_rpn_loc: 0.1814  time: 0.2233  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:36:03 d2.utils.events]: \u001b[0m eta: 5:19:04  iter: 8439  total_loss: 1.371  loss_cls: 0.3659  loss_box_reg: 0.4531  loss_mask: 0.2779  loss_rpn_cls: 0.0885  loss_rpn_loc: 0.1902  time: 0.2232  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:36:08 d2.utils.events]: \u001b[0m eta: 5:18:57  iter: 8459  total_loss: 1.227  loss_cls: 0.3131  loss_box_reg: 0.394  loss_mask: 0.2715  loss_rpn_cls: 0.0948  loss_rpn_loc: 0.1715  time: 0.2232  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:36:12 d2.utils.events]: \u001b[0m eta: 5:18:52  iter: 8479  total_loss: 1.326  loss_cls: 0.3289  loss_box_reg: 0.3981  loss_mask: 0.2775  loss_rpn_cls: 0.09177  loss_rpn_loc: 0.1819  time: 0.2233  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:36:17 d2.utils.events]: \u001b[0m eta: 5:18:27  iter: 8499  total_loss: 1.284  loss_cls: 0.3267  loss_box_reg: 0.4073  loss_mask: 0.2684  loss_rpn_cls: 0.09319  loss_rpn_loc: 0.1774  time: 0.2232  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:36:21 d2.utils.events]: \u001b[0m eta: 5:18:44  iter: 8519  total_loss: 1.316  loss_cls: 0.3473  loss_box_reg: 0.4346  loss_mask: 0.2734  loss_rpn_cls: 0.07509  loss_rpn_loc: 0.1738  time: 0.2232  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:36:26 d2.utils.events]: \u001b[0m eta: 5:18:53  iter: 8539  total_loss: 1.231  loss_cls: 0.3198  loss_box_reg: 0.3922  loss_mask: 0.2551  loss_rpn_cls: 0.07421  loss_rpn_loc: 0.1697  time: 0.2233  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:36:30 d2.utils.events]: \u001b[0m eta: 5:18:28  iter: 8559  total_loss: 1.232  loss_cls: 0.3027  loss_box_reg: 0.4166  loss_mask: 0.2457  loss_rpn_cls: 0.069  loss_rpn_loc: 0.1666  time: 0.2232  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:36:35 d2.utils.events]: \u001b[0m eta: 5:18:31  iter: 8579  total_loss: 1.271  loss_cls: 0.3206  loss_box_reg: 0.4208  loss_mask: 0.2736  loss_rpn_cls: 0.1133  loss_rpn_loc: 0.1705  time: 0.2233  data_time: 0.0176  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:36:39 d2.utils.events]: \u001b[0m eta: 5:18:06  iter: 8599  total_loss: 1.29  loss_cls: 0.3153  loss_box_reg: 0.4122  loss_mask: 0.2757  loss_rpn_cls: 0.06419  loss_rpn_loc: 0.1736  time: 0.2233  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:36:44 d2.utils.events]: \u001b[0m eta: 5:18:08  iter: 8619  total_loss: 1.275  loss_cls: 0.3535  loss_box_reg: 0.3939  loss_mask: 0.2799  loss_rpn_cls: 0.101  loss_rpn_loc: 0.1792  time: 0.2234  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:36:48 d2.utils.events]: \u001b[0m eta: 5:17:47  iter: 8639  total_loss: 1.255  loss_cls: 0.346  loss_box_reg: 0.3993  loss_mask: 0.2776  loss_rpn_cls: 0.08281  loss_rpn_loc: 0.1822  time: 0.2236  data_time: 0.0165  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:36:53 d2.utils.events]: \u001b[0m eta: 5:18:12  iter: 8659  total_loss: 1.261  loss_cls: 0.3466  loss_box_reg: 0.3827  loss_mask: 0.2853  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.188  time: 0.2236  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:36:57 d2.utils.events]: \u001b[0m eta: 5:17:38  iter: 8679  total_loss: 1.297  loss_cls: 0.3495  loss_box_reg: 0.4009  loss_mask: 0.2642  loss_rpn_cls: 0.09217  loss_rpn_loc: 0.1818  time: 0.2236  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:37:02 d2.utils.events]: \u001b[0m eta: 5:17:22  iter: 8699  total_loss: 1.371  loss_cls: 0.3614  loss_box_reg: 0.4269  loss_mask: 0.2943  loss_rpn_cls: 0.07596  loss_rpn_loc: 0.1763  time: 0.2235  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:37:06 d2.utils.events]: \u001b[0m eta: 5:17:27  iter: 8719  total_loss: 1.284  loss_cls: 0.3276  loss_box_reg: 0.4097  loss_mask: 0.2864  loss_rpn_cls: 0.07947  loss_rpn_loc: 0.1767  time: 0.2235  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:37:11 d2.utils.events]: \u001b[0m eta: 5:17:14  iter: 8739  total_loss: 1.302  loss_cls: 0.3252  loss_box_reg: 0.4233  loss_mask: 0.2576  loss_rpn_cls: 0.07186  loss_rpn_loc: 0.1705  time: 0.2234  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:37:15 d2.utils.events]: \u001b[0m eta: 5:16:37  iter: 8759  total_loss: 1.169  loss_cls: 0.3036  loss_box_reg: 0.3586  loss_mask: 0.2639  loss_rpn_cls: 0.08403  loss_rpn_loc: 0.1852  time: 0.2234  data_time: 0.0133  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:37:20 d2.utils.events]: \u001b[0m eta: 5:16:51  iter: 8779  total_loss: 1.222  loss_cls: 0.3087  loss_box_reg: 0.4098  loss_mask: 0.2663  loss_rpn_cls: 0.07179  loss_rpn_loc: 0.1698  time: 0.2236  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:37:24 d2.utils.events]: \u001b[0m eta: 5:16:52  iter: 8799  total_loss: 1.22  loss_cls: 0.2909  loss_box_reg: 0.3992  loss_mask: 0.259  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.1783  time: 0.2235  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:37:29 d2.utils.events]: \u001b[0m eta: 5:16:47  iter: 8819  total_loss: 1.316  loss_cls: 0.3458  loss_box_reg: 0.3812  loss_mask: 0.2694  loss_rpn_cls: 0.07245  loss_rpn_loc: 0.1765  time: 0.2235  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:37:33 d2.utils.events]: \u001b[0m eta: 5:17:11  iter: 8839  total_loss: 1.402  loss_cls: 0.3452  loss_box_reg: 0.4297  loss_mask: 0.2987  loss_rpn_cls: 0.08796  loss_rpn_loc: 0.1813  time: 0.2237  data_time: 0.0159  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:37:38 d2.utils.events]: \u001b[0m eta: 5:17:14  iter: 8859  total_loss: 1.266  loss_cls: 0.3486  loss_box_reg: 0.405  loss_mask: 0.2674  loss_rpn_cls: 0.09164  loss_rpn_loc: 0.1779  time: 0.2236  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:37:42 d2.utils.events]: \u001b[0m eta: 5:17:05  iter: 8879  total_loss: 1.262  loss_cls: 0.3147  loss_box_reg: 0.4119  loss_mask: 0.2555  loss_rpn_cls: 0.08106  loss_rpn_loc: 0.168  time: 0.2236  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:37:47 d2.utils.events]: \u001b[0m eta: 5:17:18  iter: 8899  total_loss: 1.253  loss_cls: 0.3222  loss_box_reg: 0.402  loss_mask: 0.2598  loss_rpn_cls: 0.08127  loss_rpn_loc: 0.1713  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 21:37:51 d2.utils.events]: \u001b[0m eta: 5:17:33  iter: 8919  total_loss: 1.228  loss_cls: 0.3056  loss_box_reg: 0.3836  loss_mask: 0.2737  loss_rpn_cls: 0.0683  loss_rpn_loc: 0.1834  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:37:56 d2.utils.events]: \u001b[0m eta: 5:17:29  iter: 8939  total_loss: 1.298  loss_cls: 0.3203  loss_box_reg: 0.4279  loss_mask: 0.2665  loss_rpn_cls: 0.09791  loss_rpn_loc: 0.1814  time: 0.2239  data_time: 0.0216  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:38:01 d2.utils.events]: \u001b[0m eta: 5:17:25  iter: 8959  total_loss: 1.301  loss_cls: 0.3244  loss_box_reg: 0.4138  loss_mask: 0.2855  loss_rpn_cls: 0.083  loss_rpn_loc: 0.1697  time: 0.2240  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:38:05 d2.utils.events]: \u001b[0m eta: 5:17:33  iter: 8979  total_loss: 1.4  loss_cls: 0.3698  loss_box_reg: 0.4666  loss_mask: 0.3043  loss_rpn_cls: 0.06318  loss_rpn_loc: 0.1851  time: 0.2239  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:38:10 d2.utils.events]: \u001b[0m eta: 5:17:34  iter: 8999  total_loss: 1.366  loss_cls: 0.3597  loss_box_reg: 0.4471  loss_mask: 0.2803  loss_rpn_cls: 0.07802  loss_rpn_loc: 0.1727  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:38:14 d2.utils.events]: \u001b[0m eta: 5:17:24  iter: 9019  total_loss: 1.355  loss_cls: 0.3683  loss_box_reg: 0.4508  loss_mask: 0.2786  loss_rpn_cls: 0.07458  loss_rpn_loc: 0.1822  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:38:18 d2.utils.events]: \u001b[0m eta: 5:17:07  iter: 9039  total_loss: 1.263  loss_cls: 0.352  loss_box_reg: 0.4216  loss_mask: 0.2574  loss_rpn_cls: 0.1071  loss_rpn_loc: 0.198  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:38:23 d2.utils.events]: \u001b[0m eta: 5:17:24  iter: 9059  total_loss: 1.25  loss_cls: 0.3058  loss_box_reg: 0.3846  loss_mask: 0.2751  loss_rpn_cls: 0.09875  loss_rpn_loc: 0.1604  time: 0.2239  data_time: 0.0110  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:38:28 d2.utils.events]: \u001b[0m eta: 5:17:20  iter: 9079  total_loss: 1.143  loss_cls: 0.267  loss_box_reg: 0.3543  loss_mask: 0.2583  loss_rpn_cls: 0.07118  loss_rpn_loc: 0.1609  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:38:32 d2.utils.events]: \u001b[0m eta: 5:17:22  iter: 9099  total_loss: 1.346  loss_cls: 0.3194  loss_box_reg: 0.4343  loss_mask: 0.2854  loss_rpn_cls: 0.1037  loss_rpn_loc: 0.2027  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:38:37 d2.utils.events]: \u001b[0m eta: 5:17:12  iter: 9119  total_loss: 1.394  loss_cls: 0.3612  loss_box_reg: 0.4536  loss_mask: 0.2906  loss_rpn_cls: 0.1273  loss_rpn_loc: 0.1769  time: 0.2240  data_time: 0.0121  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:38:41 d2.utils.events]: \u001b[0m eta: 5:17:07  iter: 9139  total_loss: 1.242  loss_cls: 0.3347  loss_box_reg: 0.3624  loss_mask: 0.2574  loss_rpn_cls: 0.08523  loss_rpn_loc: 0.1663  time: 0.2240  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:38:46 d2.utils.events]: \u001b[0m eta: 5:16:59  iter: 9159  total_loss: 1.377  loss_cls: 0.3448  loss_box_reg: 0.4265  loss_mask: 0.275  loss_rpn_cls: 0.08688  loss_rpn_loc: 0.1889  time: 0.2240  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:38:50 d2.utils.events]: \u001b[0m eta: 5:16:59  iter: 9179  total_loss: 1.246  loss_cls: 0.3198  loss_box_reg: 0.4151  loss_mask: 0.2565  loss_rpn_cls: 0.0945  loss_rpn_loc: 0.1836  time: 0.2240  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:38:55 d2.utils.events]: \u001b[0m eta: 5:16:32  iter: 9199  total_loss: 1.342  loss_cls: 0.3337  loss_box_reg: 0.4489  loss_mask: 0.2715  loss_rpn_cls: 0.07321  loss_rpn_loc: 0.1952  time: 0.2240  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:38:59 d2.utils.events]: \u001b[0m eta: 5:16:28  iter: 9219  total_loss: 1.128  loss_cls: 0.2937  loss_box_reg: 0.3408  loss_mask: 0.2334  loss_rpn_cls: 0.07613  loss_rpn_loc: 0.1775  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:39:03 d2.utils.events]: \u001b[0m eta: 5:16:19  iter: 9239  total_loss: 1.333  loss_cls: 0.3473  loss_box_reg: 0.4485  loss_mask: 0.2825  loss_rpn_cls: 0.08171  loss_rpn_loc: 0.1736  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:39:08 d2.utils.events]: \u001b[0m eta: 5:16:35  iter: 9259  total_loss: 1.159  loss_cls: 0.2613  loss_box_reg: 0.3439  loss_mask: 0.2595  loss_rpn_cls: 0.07946  loss_rpn_loc: 0.1916  time: 0.2239  data_time: 0.0159  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:39:13 d2.utils.events]: \u001b[0m eta: 5:15:59  iter: 9279  total_loss: 1.371  loss_cls: 0.347  loss_box_reg: 0.4063  loss_mask: 0.2759  loss_rpn_cls: 0.09134  loss_rpn_loc: 0.201  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:39:17 d2.utils.events]: \u001b[0m eta: 5:16:26  iter: 9299  total_loss: 1.265  loss_cls: 0.3323  loss_box_reg: 0.3561  loss_mask: 0.2382  loss_rpn_cls: 0.07906  loss_rpn_loc: 0.1809  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:39:22 d2.utils.events]: \u001b[0m eta: 5:16:34  iter: 9319  total_loss: 1.248  loss_cls: 0.2968  loss_box_reg: 0.3861  loss_mask: 0.2742  loss_rpn_cls: 0.1079  loss_rpn_loc: 0.1763  time: 0.2240  data_time: 0.0098  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:39:26 d2.utils.events]: \u001b[0m eta: 5:16:18  iter: 9339  total_loss: 1.399  loss_cls: 0.3727  loss_box_reg: 0.4135  loss_mask: 0.2608  loss_rpn_cls: 0.08489  loss_rpn_loc: 0.1768  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:39:31 d2.utils.events]: \u001b[0m eta: 5:16:26  iter: 9359  total_loss: 1.255  loss_cls: 0.2957  loss_box_reg: 0.3769  loss_mask: 0.279  loss_rpn_cls: 0.09868  loss_rpn_loc: 0.1772  time: 0.2239  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:39:35 d2.utils.events]: \u001b[0m eta: 5:16:32  iter: 9379  total_loss: 1.249  loss_cls: 0.3221  loss_box_reg: 0.3996  loss_mask: 0.2758  loss_rpn_cls: 0.07929  loss_rpn_loc: 0.1956  time: 0.2239  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:39:40 d2.utils.events]: \u001b[0m eta: 5:16:36  iter: 9399  total_loss: 1.345  loss_cls: 0.3708  loss_box_reg: 0.4446  loss_mask: 0.2979  loss_rpn_cls: 0.08679  loss_rpn_loc: 0.1826  time: 0.2239  data_time: 0.0150  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:39:44 d2.utils.events]: \u001b[0m eta: 5:17:03  iter: 9419  total_loss: 1.251  loss_cls: 0.3169  loss_box_reg: 0.3579  loss_mask: 0.256  loss_rpn_cls: 0.09559  loss_rpn_loc: 0.2014  time: 0.2239  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:39:49 d2.utils.events]: \u001b[0m eta: 5:16:47  iter: 9439  total_loss: 1.36  loss_cls: 0.3478  loss_box_reg: 0.3888  loss_mask: 0.2823  loss_rpn_cls: 0.07725  loss_rpn_loc: 0.1935  time: 0.2239  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:39:53 d2.utils.events]: \u001b[0m eta: 5:16:43  iter: 9459  total_loss: 1.169  loss_cls: 0.2794  loss_box_reg: 0.3933  loss_mask: 0.2737  loss_rpn_cls: 0.06569  loss_rpn_loc: 0.1659  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:39:57 d2.utils.events]: \u001b[0m eta: 5:16:26  iter: 9479  total_loss: 1.267  loss_cls: 0.3265  loss_box_reg: 0.3968  loss_mask: 0.2836  loss_rpn_cls: 0.09721  loss_rpn_loc: 0.1863  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:40:01 d2.utils.events]: \u001b[0m eta: 5:16:17  iter: 9499  total_loss: 1.199  loss_cls: 0.3194  loss_box_reg: 0.3979  loss_mask: 0.2479  loss_rpn_cls: 0.07113  loss_rpn_loc: 0.1549  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:40:06 d2.utils.events]: \u001b[0m eta: 5:15:44  iter: 9519  total_loss: 1.304  loss_cls: 0.3557  loss_box_reg: 0.402  loss_mask: 0.2634  loss_rpn_cls: 0.07513  loss_rpn_loc: 0.1727  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:40:11 d2.utils.events]: \u001b[0m eta: 5:15:41  iter: 9539  total_loss: 1.297  loss_cls: 0.3243  loss_box_reg: 0.3854  loss_mask: 0.2627  loss_rpn_cls: 0.08019  loss_rpn_loc: 0.1893  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:40:15 d2.utils.events]: \u001b[0m eta: 5:16:00  iter: 9559  total_loss: 1.374  loss_cls: 0.3552  loss_box_reg: 0.4067  loss_mask: 0.2837  loss_rpn_cls: 0.1181  loss_rpn_loc: 0.1869  time: 0.2238  data_time: 0.0150  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 21:40:20 d2.utils.events]: \u001b[0m eta: 5:15:56  iter: 9579  total_loss: 1.252  loss_cls: 0.3449  loss_box_reg: 0.4114  loss_mask: 0.2566  loss_rpn_cls: 0.08127  loss_rpn_loc: 0.1787  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:40:25 d2.utils.events]: \u001b[0m eta: 5:15:55  iter: 9599  total_loss: 1.35  loss_cls: 0.3434  loss_box_reg: 0.4135  loss_mask: 0.274  loss_rpn_cls: 0.1069  loss_rpn_loc: 0.2055  time: 0.2239  data_time: 0.0134  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:40:29 d2.utils.events]: \u001b[0m eta: 5:15:32  iter: 9619  total_loss: 1.269  loss_cls: 0.3184  loss_box_reg: 0.4246  loss_mask: 0.2695  loss_rpn_cls: 0.06672  loss_rpn_loc: 0.1747  time: 0.2239  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:40:35 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.52 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/29 21:40:35 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/29 21:40:35 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/29 21:40:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/29 21:40:36 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 21:40:36 d2.data.common]: \u001b[0mSerialized dataset takes 84.20 MiB\n",
      "\u001b[32m[12/29 21:40:39 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.41 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/29 21:40:39 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/29 21:40:39 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/29 21:40:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/29 21:40:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0007 s/iter. Inference: 0.0601 s/iter. Eval: 0.1584 s/iter. Total: 0.2193 s/iter. ETA=0:02:02\n",
      "\u001b[32m[12/29 21:40:48 d2.evaluation.evaluator]: \u001b[0mInference done 39/570. Dataloading: 0.0009 s/iter. Inference: 0.0578 s/iter. Eval: 0.1313 s/iter. Total: 0.1901 s/iter. ETA=0:01:40\n",
      "\u001b[32m[12/29 21:40:53 d2.evaluation.evaluator]: \u001b[0mInference done 66/570. Dataloading: 0.0009 s/iter. Inference: 0.0578 s/iter. Eval: 0.1298 s/iter. Total: 0.1886 s/iter. ETA=0:01:35\n",
      "\u001b[32m[12/29 21:40:58 d2.evaluation.evaluator]: \u001b[0mInference done 92/570. Dataloading: 0.0009 s/iter. Inference: 0.0575 s/iter. Eval: 0.1315 s/iter. Total: 0.1900 s/iter. ETA=0:01:30\n",
      "\u001b[32m[12/29 21:41:03 d2.evaluation.evaluator]: \u001b[0mInference done 119/570. Dataloading: 0.0009 s/iter. Inference: 0.0565 s/iter. Eval: 0.1322 s/iter. Total: 0.1897 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/29 21:41:08 d2.evaluation.evaluator]: \u001b[0mInference done 146/570. Dataloading: 0.0009 s/iter. Inference: 0.0554 s/iter. Eval: 0.1341 s/iter. Total: 0.1905 s/iter. ETA=0:01:20\n",
      "\u001b[32m[12/29 21:41:14 d2.evaluation.evaluator]: \u001b[0mInference done 164/570. Dataloading: 0.0009 s/iter. Inference: 0.0554 s/iter. Eval: 0.1456 s/iter. Total: 0.2020 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/29 21:41:19 d2.evaluation.evaluator]: \u001b[0mInference done 177/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1618 s/iter. Total: 0.2184 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/29 21:41:24 d2.evaluation.evaluator]: \u001b[0mInference done 197/570. Dataloading: 0.0009 s/iter. Inference: 0.0563 s/iter. Eval: 0.1657 s/iter. Total: 0.2230 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/29 21:41:30 d2.evaluation.evaluator]: \u001b[0mInference done 211/570. Dataloading: 0.0009 s/iter. Inference: 0.0567 s/iter. Eval: 0.1756 s/iter. Total: 0.2333 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/29 21:41:35 d2.evaluation.evaluator]: \u001b[0mInference done 227/570. Dataloading: 0.0009 s/iter. Inference: 0.0569 s/iter. Eval: 0.1838 s/iter. Total: 0.2417 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/29 21:41:41 d2.evaluation.evaluator]: \u001b[0mInference done 239/570. Dataloading: 0.0009 s/iter. Inference: 0.0570 s/iter. Eval: 0.1950 s/iter. Total: 0.2529 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/29 21:41:46 d2.evaluation.evaluator]: \u001b[0mInference done 252/570. Dataloading: 0.0009 s/iter. Inference: 0.0571 s/iter. Eval: 0.2039 s/iter. Total: 0.2619 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/29 21:41:51 d2.evaluation.evaluator]: \u001b[0mInference done 268/570. Dataloading: 0.0009 s/iter. Inference: 0.0570 s/iter. Eval: 0.2077 s/iter. Total: 0.2657 s/iter. ETA=0:01:20\n",
      "\u001b[32m[12/29 21:41:57 d2.evaluation.evaluator]: \u001b[0mInference done 288/570. Dataloading: 0.0009 s/iter. Inference: 0.0573 s/iter. Eval: 0.2081 s/iter. Total: 0.2663 s/iter. ETA=0:01:15\n",
      "\u001b[32m[12/29 21:42:02 d2.evaluation.evaluator]: \u001b[0mInference done 308/570. Dataloading: 0.0009 s/iter. Inference: 0.0573 s/iter. Eval: 0.2071 s/iter. Total: 0.2654 s/iter. ETA=0:01:09\n",
      "\u001b[32m[12/29 21:42:07 d2.evaluation.evaluator]: \u001b[0mInference done 361/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1835 s/iter. Total: 0.2402 s/iter. ETA=0:00:50\n",
      "\u001b[32m[12/29 21:42:12 d2.evaluation.evaluator]: \u001b[0mInference done 381/570. Dataloading: 0.0009 s/iter. Inference: 0.0558 s/iter. Eval: 0.1842 s/iter. Total: 0.2410 s/iter. ETA=0:00:45\n",
      "\u001b[32m[12/29 21:42:17 d2.evaluation.evaluator]: \u001b[0mInference done 403/570. Dataloading: 0.0009 s/iter. Inference: 0.0558 s/iter. Eval: 0.1836 s/iter. Total: 0.2404 s/iter. ETA=0:00:40\n",
      "\u001b[32m[12/29 21:42:22 d2.evaluation.evaluator]: \u001b[0mInference done 421/570. Dataloading: 0.0009 s/iter. Inference: 0.0561 s/iter. Eval: 0.1856 s/iter. Total: 0.2426 s/iter. ETA=0:00:36\n",
      "\u001b[32m[12/29 21:42:27 d2.evaluation.evaluator]: \u001b[0mInference done 441/570. Dataloading: 0.0009 s/iter. Inference: 0.0564 s/iter. Eval: 0.1859 s/iter. Total: 0.2432 s/iter. ETA=0:00:31\n",
      "\u001b[32m[12/29 21:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 475/570. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.1794 s/iter. Total: 0.2363 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/29 21:42:38 d2.evaluation.evaluator]: \u001b[0mInference done 500/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1779 s/iter. Total: 0.2345 s/iter. ETA=0:00:16\n",
      "\u001b[32m[12/29 21:42:43 d2.evaluation.evaluator]: \u001b[0mInference done 522/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1779 s/iter. Total: 0.2345 s/iter. ETA=0:00:11\n",
      "\u001b[32m[12/29 21:42:48 d2.evaluation.evaluator]: \u001b[0mInference done 545/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1777 s/iter. Total: 0.2343 s/iter. ETA=0:00:05\n",
      "\u001b[32m[12/29 21:42:53 d2.evaluation.evaluator]: \u001b[0mInference done 563/570. Dataloading: 0.0009 s/iter. Inference: 0.0558 s/iter. Eval: 0.1789 s/iter. Total: 0.2357 s/iter. ETA=0:00:01\n",
      "\u001b[32m[12/29 21:42:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:13.370178 (0.236053 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 21:42:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.055840 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 21:42:55 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/29 21:42:55 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2692781166570116\n",
      "\u001b[32m[12/29 21:42:56 d2.utils.events]: \u001b[0m eta: 5:15:46  iter: 9639  total_loss: 1.309  loss_cls: 0.3742  loss_box_reg: 0.4382  loss_mask: 0.266  loss_rpn_cls: 0.1053  loss_rpn_loc: 0.1772  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:43:01 d2.utils.events]: \u001b[0m eta: 5:15:04  iter: 9659  total_loss: 1.15  loss_cls: 0.3212  loss_box_reg: 0.3742  loss_mask: 0.2574  loss_rpn_cls: 0.07768  loss_rpn_loc: 0.1706  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:43:05 d2.utils.events]: \u001b[0m eta: 5:15:29  iter: 9679  total_loss: 1.202  loss_cls: 0.3064  loss_box_reg: 0.3866  loss_mask: 0.2776  loss_rpn_cls: 0.08756  loss_rpn_loc: 0.1984  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:43:10 d2.utils.events]: \u001b[0m eta: 5:15:33  iter: 9699  total_loss: 1.399  loss_cls: 0.3714  loss_box_reg: 0.467  loss_mask: 0.2793  loss_rpn_cls: 0.09554  loss_rpn_loc: 0.1828  time: 0.2239  data_time: 0.0162  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 21:43:15 d2.utils.events]: \u001b[0m eta: 5:15:26  iter: 9719  total_loss: 1.238  loss_cls: 0.3366  loss_box_reg: 0.3845  loss_mask: 0.2542  loss_rpn_cls: 0.092  loss_rpn_loc: 0.1705  time: 0.2239  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:43:19 d2.utils.events]: \u001b[0m eta: 5:15:27  iter: 9739  total_loss: 1.302  loss_cls: 0.334  loss_box_reg: 0.4049  loss_mask: 0.2597  loss_rpn_cls: 0.08748  loss_rpn_loc: 0.1895  time: 0.2239  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:43:23 d2.utils.events]: \u001b[0m eta: 5:15:31  iter: 9759  total_loss: 1.234  loss_cls: 0.3496  loss_box_reg: 0.4142  loss_mask: 0.271  loss_rpn_cls: 0.06322  loss_rpn_loc: 0.1605  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:43:28 d2.utils.events]: \u001b[0m eta: 5:15:32  iter: 9779  total_loss: 1.36  loss_cls: 0.3369  loss_box_reg: 0.424  loss_mask: 0.276  loss_rpn_cls: 0.09872  loss_rpn_loc: 0.1906  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:43:32 d2.utils.events]: \u001b[0m eta: 5:15:16  iter: 9799  total_loss: 1.32  loss_cls: 0.3297  loss_box_reg: 0.4343  loss_mask: 0.2765  loss_rpn_cls: 0.09138  loss_rpn_loc: 0.1961  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:43:36 d2.utils.events]: \u001b[0m eta: 5:15:21  iter: 9819  total_loss: 1.299  loss_cls: 0.3309  loss_box_reg: 0.4157  loss_mask: 0.2484  loss_rpn_cls: 0.06443  loss_rpn_loc: 0.1626  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:43:41 d2.utils.events]: \u001b[0m eta: 5:15:05  iter: 9839  total_loss: 1.29  loss_cls: 0.3063  loss_box_reg: 0.3709  loss_mask: 0.271  loss_rpn_cls: 0.08605  loss_rpn_loc: 0.1813  time: 0.2237  data_time: 0.0142  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:43:45 d2.utils.events]: \u001b[0m eta: 5:15:10  iter: 9859  total_loss: 1.338  loss_cls: 0.3562  loss_box_reg: 0.4396  loss_mask: 0.2858  loss_rpn_cls: 0.09831  loss_rpn_loc: 0.1646  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:43:50 d2.utils.events]: \u001b[0m eta: 5:15:11  iter: 9879  total_loss: 1.267  loss_cls: 0.3699  loss_box_reg: 0.4221  loss_mask: 0.2648  loss_rpn_cls: 0.07546  loss_rpn_loc: 0.1859  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:43:55 d2.utils.events]: \u001b[0m eta: 5:15:01  iter: 9899  total_loss: 1.199  loss_cls: 0.2886  loss_box_reg: 0.3648  loss_mask: 0.272  loss_rpn_cls: 0.05914  loss_rpn_loc: 0.1563  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:43:59 d2.utils.events]: \u001b[0m eta: 5:14:51  iter: 9919  total_loss: 1.143  loss_cls: 0.2687  loss_box_reg: 0.3817  loss_mask: 0.2646  loss_rpn_cls: 0.06491  loss_rpn_loc: 0.1745  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:44:04 d2.utils.events]: \u001b[0m eta: 5:14:33  iter: 9939  total_loss: 1.314  loss_cls: 0.3247  loss_box_reg: 0.4339  loss_mask: 0.2834  loss_rpn_cls: 0.05489  loss_rpn_loc: 0.1678  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:44:08 d2.utils.events]: \u001b[0m eta: 5:13:21  iter: 9959  total_loss: 1.313  loss_cls: 0.3289  loss_box_reg: 0.3965  loss_mask: 0.2772  loss_rpn_cls: 0.08168  loss_rpn_loc: 0.1783  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:44:12 d2.utils.events]: \u001b[0m eta: 5:13:36  iter: 9979  total_loss: 1.284  loss_cls: 0.2987  loss_box_reg: 0.4357  loss_mask: 0.276  loss_rpn_cls: 0.07129  loss_rpn_loc: 0.1607  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:44:17 d2.utils.events]: \u001b[0m eta: 5:14:20  iter: 9999  total_loss: 1.243  loss_cls: 0.3372  loss_box_reg: 0.4096  loss_mask: 0.2625  loss_rpn_cls: 0.08624  loss_rpn_loc: 0.1783  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:44:21 d2.utils.events]: \u001b[0m eta: 5:14:07  iter: 10019  total_loss: 1.268  loss_cls: 0.3267  loss_box_reg: 0.43  loss_mask: 0.2759  loss_rpn_cls: 0.09189  loss_rpn_loc: 0.1857  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:44:26 d2.utils.events]: \u001b[0m eta: 5:14:05  iter: 10039  total_loss: 1.253  loss_cls: 0.3327  loss_box_reg: 0.4174  loss_mask: 0.2774  loss_rpn_cls: 0.08845  loss_rpn_loc: 0.1627  time: 0.2239  data_time: 0.0116  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:44:31 d2.utils.events]: \u001b[0m eta: 5:13:37  iter: 10059  total_loss: 1.313  loss_cls: 0.3634  loss_box_reg: 0.425  loss_mask: 0.2761  loss_rpn_cls: 0.06293  loss_rpn_loc: 0.1529  time: 0.2239  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:44:35 d2.utils.events]: \u001b[0m eta: 5:13:33  iter: 10079  total_loss: 1.312  loss_cls: 0.34  loss_box_reg: 0.4266  loss_mask: 0.2828  loss_rpn_cls: 0.09491  loss_rpn_loc: 0.1734  time: 0.2239  data_time: 0.0194  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:44:40 d2.utils.events]: \u001b[0m eta: 5:12:35  iter: 10099  total_loss: 1.27  loss_cls: 0.3097  loss_box_reg: 0.422  loss_mask: 0.2697  loss_rpn_cls: 0.08181  loss_rpn_loc: 0.1753  time: 0.2239  data_time: 0.0181  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:44:44 d2.utils.events]: \u001b[0m eta: 5:12:30  iter: 10119  total_loss: 1.22  loss_cls: 0.3202  loss_box_reg: 0.3693  loss_mask: 0.272  loss_rpn_cls: 0.08537  loss_rpn_loc: 0.1707  time: 0.2239  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:44:49 d2.utils.events]: \u001b[0m eta: 5:12:26  iter: 10139  total_loss: 1.355  loss_cls: 0.3681  loss_box_reg: 0.3904  loss_mask: 0.2681  loss_rpn_cls: 0.09318  loss_rpn_loc: 0.1792  time: 0.2239  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:44:53 d2.utils.events]: \u001b[0m eta: 5:12:25  iter: 10159  total_loss: 1.432  loss_cls: 0.3896  loss_box_reg: 0.4345  loss_mask: 0.2947  loss_rpn_cls: 0.09087  loss_rpn_loc: 0.1748  time: 0.2239  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:44:58 d2.utils.events]: \u001b[0m eta: 5:12:09  iter: 10179  total_loss: 1.254  loss_cls: 0.3136  loss_box_reg: 0.3844  loss_mask: 0.2704  loss_rpn_cls: 0.08613  loss_rpn_loc: 0.1861  time: 0.2240  data_time: 0.0102  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:45:02 d2.utils.events]: \u001b[0m eta: 5:12:11  iter: 10199  total_loss: 1.311  loss_cls: 0.3409  loss_box_reg: 0.3823  loss_mask: 0.2858  loss_rpn_cls: 0.08261  loss_rpn_loc: 0.1784  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:45:07 d2.utils.events]: \u001b[0m eta: 5:12:24  iter: 10219  total_loss: 1.289  loss_cls: 0.3431  loss_box_reg: 0.4141  loss_mask: 0.2859  loss_rpn_cls: 0.1007  loss_rpn_loc: 0.1961  time: 0.2240  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:45:11 d2.utils.events]: \u001b[0m eta: 5:13:21  iter: 10239  total_loss: 1.23  loss_cls: 0.311  loss_box_reg: 0.4025  loss_mask: 0.2755  loss_rpn_cls: 0.07044  loss_rpn_loc: 0.1851  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:45:16 d2.utils.events]: \u001b[0m eta: 5:13:23  iter: 10259  total_loss: 1.259  loss_cls: 0.2655  loss_box_reg: 0.402  loss_mask: 0.2616  loss_rpn_cls: 0.06999  loss_rpn_loc: 0.166  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:45:20 d2.utils.events]: \u001b[0m eta: 5:13:21  iter: 10279  total_loss: 1.374  loss_cls: 0.3757  loss_box_reg: 0.4229  loss_mask: 0.277  loss_rpn_cls: 0.06788  loss_rpn_loc: 0.1842  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:45:25 d2.utils.events]: \u001b[0m eta: 5:13:17  iter: 10299  total_loss: 1.303  loss_cls: 0.339  loss_box_reg: 0.3903  loss_mask: 0.2752  loss_rpn_cls: 0.08937  loss_rpn_loc: 0.1761  time: 0.2240  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:45:29 d2.utils.events]: \u001b[0m eta: 5:13:09  iter: 10319  total_loss: 1.356  loss_cls: 0.3558  loss_box_reg: 0.4268  loss_mask: 0.2866  loss_rpn_cls: 0.1071  loss_rpn_loc: 0.1863  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:45:34 d2.utils.events]: \u001b[0m eta: 5:13:08  iter: 10339  total_loss: 1.234  loss_cls: 0.3112  loss_box_reg: 0.3634  loss_mask: 0.2778  loss_rpn_cls: 0.08423  loss_rpn_loc: 0.1861  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:45:38 d2.utils.events]: \u001b[0m eta: 5:13:04  iter: 10359  total_loss: 1.193  loss_cls: 0.285  loss_box_reg: 0.3968  loss_mask: 0.2569  loss_rpn_cls: 0.08007  loss_rpn_loc: 0.1685  time: 0.2240  data_time: 0.0138  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 21:45:43 d2.utils.events]: \u001b[0m eta: 5:12:56  iter: 10379  total_loss: 1.084  loss_cls: 0.2735  loss_box_reg: 0.3639  loss_mask: 0.2453  loss_rpn_cls: 0.06244  loss_rpn_loc: 0.1545  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:45:47 d2.utils.events]: \u001b[0m eta: 5:12:38  iter: 10399  total_loss: 1.299  loss_cls: 0.3497  loss_box_reg: 0.4123  loss_mask: 0.2623  loss_rpn_cls: 0.08401  loss_rpn_loc: 0.1681  time: 0.2239  data_time: 0.0165  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:45:52 d2.utils.events]: \u001b[0m eta: 5:12:36  iter: 10419  total_loss: 1.362  loss_cls: 0.3667  loss_box_reg: 0.405  loss_mask: 0.2782  loss_rpn_cls: 0.1202  loss_rpn_loc: 0.1743  time: 0.2240  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:45:56 d2.utils.events]: \u001b[0m eta: 5:12:32  iter: 10439  total_loss: 1.422  loss_cls: 0.3913  loss_box_reg: 0.454  loss_mask: 0.2782  loss_rpn_cls: 0.0794  loss_rpn_loc: 0.1771  time: 0.2240  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:46:01 d2.utils.events]: \u001b[0m eta: 5:12:28  iter: 10459  total_loss: 1.405  loss_cls: 0.3564  loss_box_reg: 0.4342  loss_mask: 0.303  loss_rpn_cls: 0.106  loss_rpn_loc: 0.1878  time: 0.2239  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:46:05 d2.utils.events]: \u001b[0m eta: 5:12:36  iter: 10479  total_loss: 1.414  loss_cls: 0.3464  loss_box_reg: 0.4386  loss_mask: 0.2758  loss_rpn_cls: 0.111  loss_rpn_loc: 0.185  time: 0.2240  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:46:10 d2.utils.events]: \u001b[0m eta: 5:12:37  iter: 10499  total_loss: 1.233  loss_cls: 0.3246  loss_box_reg: 0.3827  loss_mask: 0.2645  loss_rpn_cls: 0.08982  loss_rpn_loc: 0.175  time: 0.2240  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:46:14 d2.utils.events]: \u001b[0m eta: 5:12:36  iter: 10519  total_loss: 1.185  loss_cls: 0.2853  loss_box_reg: 0.4029  loss_mask: 0.2701  loss_rpn_cls: 0.1067  loss_rpn_loc: 0.1674  time: 0.2239  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:46:18 d2.utils.events]: \u001b[0m eta: 5:12:15  iter: 10539  total_loss: 1.369  loss_cls: 0.3423  loss_box_reg: 0.4371  loss_mask: 0.2741  loss_rpn_cls: 0.09962  loss_rpn_loc: 0.1728  time: 0.2239  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:46:23 d2.utils.events]: \u001b[0m eta: 5:11:22  iter: 10559  total_loss: 1.265  loss_cls: 0.2911  loss_box_reg: 0.4396  loss_mask: 0.2737  loss_rpn_cls: 0.07616  loss_rpn_loc: 0.1752  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:46:27 d2.utils.events]: \u001b[0m eta: 5:11:46  iter: 10579  total_loss: 1.243  loss_cls: 0.3216  loss_box_reg: 0.3994  loss_mask: 0.2665  loss_rpn_cls: 0.08472  loss_rpn_loc: 0.1783  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:46:32 d2.utils.events]: \u001b[0m eta: 5:11:42  iter: 10599  total_loss: 1.371  loss_cls: 0.3418  loss_box_reg: 0.4506  loss_mask: 0.2739  loss_rpn_cls: 0.1062  loss_rpn_loc: 0.1899  time: 0.2239  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:46:36 d2.utils.events]: \u001b[0m eta: 5:11:57  iter: 10619  total_loss: 1.343  loss_cls: 0.3253  loss_box_reg: 0.425  loss_mask: 0.2898  loss_rpn_cls: 0.07393  loss_rpn_loc: 0.1625  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:46:41 d2.utils.events]: \u001b[0m eta: 5:11:33  iter: 10639  total_loss: 1.362  loss_cls: 0.3555  loss_box_reg: 0.4133  loss_mask: 0.272  loss_rpn_cls: 0.1109  loss_rpn_loc: 0.1839  time: 0.2239  data_time: 0.0174  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:46:45 d2.utils.events]: \u001b[0m eta: 5:11:14  iter: 10659  total_loss: 1.217  loss_cls: 0.2857  loss_box_reg: 0.3951  loss_mask: 0.2498  loss_rpn_cls: 0.08923  loss_rpn_loc: 0.1642  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:46:49 d2.utils.events]: \u001b[0m eta: 5:10:08  iter: 10679  total_loss: 1.331  loss_cls: 0.3525  loss_box_reg: 0.4485  loss_mask: 0.2779  loss_rpn_cls: 0.07343  loss_rpn_loc: 0.1681  time: 0.2238  data_time: 0.0058  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:46:54 d2.utils.events]: \u001b[0m eta: 5:10:03  iter: 10699  total_loss: 1.294  loss_cls: 0.3241  loss_box_reg: 0.389  loss_mask: 0.2817  loss_rpn_cls: 0.09826  loss_rpn_loc: 0.1902  time: 0.2239  data_time: 0.0237  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:46:59 d2.utils.events]: \u001b[0m eta: 5:09:49  iter: 10719  total_loss: 1.251  loss_cls: 0.3246  loss_box_reg: 0.3895  loss_mask: 0.2586  loss_rpn_cls: 0.05616  loss_rpn_loc: 0.163  time: 0.2239  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:47:03 d2.utils.events]: \u001b[0m eta: 5:09:47  iter: 10739  total_loss: 1.224  loss_cls: 0.3321  loss_box_reg: 0.361  loss_mask: 0.2634  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.1844  time: 0.2239  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:47:08 d2.utils.events]: \u001b[0m eta: 5:09:38  iter: 10759  total_loss: 1.21  loss_cls: 0.3338  loss_box_reg: 0.3957  loss_mask: 0.256  loss_rpn_cls: 0.09686  loss_rpn_loc: 0.1616  time: 0.2239  data_time: 0.0058  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:47:12 d2.utils.events]: \u001b[0m eta: 5:09:08  iter: 10779  total_loss: 1.279  loss_cls: 0.3392  loss_box_reg: 0.3707  loss_mask: 0.2746  loss_rpn_cls: 0.08045  loss_rpn_loc: 0.1748  time: 0.2239  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:47:17 d2.utils.events]: \u001b[0m eta: 5:09:04  iter: 10799  total_loss: 1.253  loss_cls: 0.3085  loss_box_reg: 0.3912  loss_mask: 0.2724  loss_rpn_cls: 0.07838  loss_rpn_loc: 0.1987  time: 0.2238  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:47:21 d2.utils.events]: \u001b[0m eta: 5:08:58  iter: 10819  total_loss: 1.256  loss_cls: 0.3292  loss_box_reg: 0.3999  loss_mask: 0.273  loss_rpn_cls: 0.07404  loss_rpn_loc: 0.1895  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:47:26 d2.utils.events]: \u001b[0m eta: 5:09:22  iter: 10839  total_loss: 1.367  loss_cls: 0.3577  loss_box_reg: 0.4372  loss_mask: 0.2793  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.1944  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:47:30 d2.utils.events]: \u001b[0m eta: 5:09:01  iter: 10859  total_loss: 1.25  loss_cls: 0.3094  loss_box_reg: 0.4035  loss_mask: 0.2696  loss_rpn_cls: 0.06131  loss_rpn_loc: 0.1755  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:47:35 d2.utils.events]: \u001b[0m eta: 5:08:56  iter: 10879  total_loss: 1.265  loss_cls: 0.3113  loss_box_reg: 0.3887  loss_mask: 0.2661  loss_rpn_cls: 0.08566  loss_rpn_loc: 0.172  time: 0.2238  data_time: 0.0089  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:47:39 d2.utils.events]: \u001b[0m eta: 5:09:01  iter: 10899  total_loss: 1.102  loss_cls: 0.2731  loss_box_reg: 0.3733  loss_mask: 0.2611  loss_rpn_cls: 0.07166  loss_rpn_loc: 0.1679  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:47:44 d2.utils.events]: \u001b[0m eta: 5:09:03  iter: 10919  total_loss: 1.24  loss_cls: 0.3242  loss_box_reg: 0.4047  loss_mask: 0.2739  loss_rpn_cls: 0.07228  loss_rpn_loc: 0.1724  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:47:48 d2.utils.events]: \u001b[0m eta: 5:09:01  iter: 10939  total_loss: 1.29  loss_cls: 0.3473  loss_box_reg: 0.4235  loss_mask: 0.2703  loss_rpn_cls: 0.07419  loss_rpn_loc: 0.1582  time: 0.2238  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:47:53 d2.utils.events]: \u001b[0m eta: 5:08:58  iter: 10959  total_loss: 1.147  loss_cls: 0.294  loss_box_reg: 0.3696  loss_mask: 0.2627  loss_rpn_cls: 0.06602  loss_rpn_loc: 0.1598  time: 0.2239  data_time: 0.0276  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:47:57 d2.utils.events]: \u001b[0m eta: 5:08:59  iter: 10979  total_loss: 1.197  loss_cls: 0.3222  loss_box_reg: 0.4124  loss_mask: 0.2696  loss_rpn_cls: 0.08592  loss_rpn_loc: 0.1691  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:48:02 d2.utils.events]: \u001b[0m eta: 5:08:49  iter: 10999  total_loss: 1.306  loss_cls: 0.3359  loss_box_reg: 0.4412  loss_mask: 0.2753  loss_rpn_cls: 0.08564  loss_rpn_loc: 0.1778  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:48:06 d2.utils.events]: \u001b[0m eta: 5:08:47  iter: 11019  total_loss: 1.214  loss_cls: 0.2834  loss_box_reg: 0.3725  loss_mask: 0.257  loss_rpn_cls: 0.08462  loss_rpn_loc: 0.1733  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 21:48:10 d2.utils.events]: \u001b[0m eta: 5:08:46  iter: 11039  total_loss: 1.364  loss_cls: 0.3404  loss_box_reg: 0.406  loss_mask: 0.2871  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.1748  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:48:15 d2.utils.events]: \u001b[0m eta: 5:08:51  iter: 11059  total_loss: 1.266  loss_cls: 0.3157  loss_box_reg: 0.4194  loss_mask: 0.266  loss_rpn_cls: 0.07965  loss_rpn_loc: 0.1763  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:48:20 d2.utils.events]: \u001b[0m eta: 5:09:10  iter: 11079  total_loss: 1.239  loss_cls: 0.2825  loss_box_reg: 0.4218  loss_mask: 0.2756  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.1877  time: 0.2240  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:48:25 d2.utils.events]: \u001b[0m eta: 5:09:38  iter: 11099  total_loss: 1.263  loss_cls: 0.3117  loss_box_reg: 0.3907  loss_mask: 0.2856  loss_rpn_cls: 0.0898  loss_rpn_loc: 0.195  time: 0.2240  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:48:29 d2.utils.events]: \u001b[0m eta: 5:09:23  iter: 11119  total_loss: 1.359  loss_cls: 0.3618  loss_box_reg: 0.4701  loss_mask: 0.2903  loss_rpn_cls: 0.08508  loss_rpn_loc: 0.1782  time: 0.2240  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:48:33 d2.utils.events]: \u001b[0m eta: 5:09:29  iter: 11139  total_loss: 1.341  loss_cls: 0.39  loss_box_reg: 0.4265  loss_mask: 0.2699  loss_rpn_cls: 0.09678  loss_rpn_loc: 0.1984  time: 0.2240  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:48:38 d2.utils.events]: \u001b[0m eta: 5:09:35  iter: 11159  total_loss: 1.21  loss_cls: 0.3298  loss_box_reg: 0.3835  loss_mask: 0.2522  loss_rpn_cls: 0.08872  loss_rpn_loc: 0.1682  time: 0.2240  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:48:43 d2.utils.events]: \u001b[0m eta: 5:09:42  iter: 11179  total_loss: 1.263  loss_cls: 0.345  loss_box_reg: 0.4208  loss_mask: 0.2733  loss_rpn_cls: 0.08088  loss_rpn_loc: 0.1728  time: 0.2240  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:48:47 d2.utils.events]: \u001b[0m eta: 5:09:42  iter: 11199  total_loss: 1.327  loss_cls: 0.3433  loss_box_reg: 0.4106  loss_mask: 0.2787  loss_rpn_cls: 0.07392  loss_rpn_loc: 0.1761  time: 0.2240  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:48:51 d2.utils.events]: \u001b[0m eta: 5:09:18  iter: 11219  total_loss: 1.301  loss_cls: 0.3598  loss_box_reg: 0.4465  loss_mask: 0.2671  loss_rpn_cls: 0.08421  loss_rpn_loc: 0.1684  time: 0.2240  data_time: 0.0159  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:48:56 d2.utils.events]: \u001b[0m eta: 5:09:29  iter: 11239  total_loss: 1.236  loss_cls: 0.3095  loss_box_reg: 0.378  loss_mask: 0.2658  loss_rpn_cls: 0.1215  loss_rpn_loc: 0.1901  time: 0.2241  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:49:01 d2.utils.events]: \u001b[0m eta: 5:08:56  iter: 11259  total_loss: 1.156  loss_cls: 0.2764  loss_box_reg: 0.3878  loss_mask: 0.2364  loss_rpn_cls: 0.07174  loss_rpn_loc: 0.1626  time: 0.2240  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:49:05 d2.utils.events]: \u001b[0m eta: 5:08:47  iter: 11279  total_loss: 1.242  loss_cls: 0.3337  loss_box_reg: 0.4019  loss_mask: 0.2639  loss_rpn_cls: 0.06627  loss_rpn_loc: 0.1811  time: 0.2240  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:49:09 d2.utils.events]: \u001b[0m eta: 5:08:07  iter: 11299  total_loss: 1.278  loss_cls: 0.3079  loss_box_reg: 0.4313  loss_mask: 0.2752  loss_rpn_cls: 0.1071  loss_rpn_loc: 0.1896  time: 0.2240  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:49:14 d2.utils.events]: \u001b[0m eta: 5:08:02  iter: 11319  total_loss: 1.189  loss_cls: 0.3066  loss_box_reg: 0.3957  loss_mask: 0.2767  loss_rpn_cls: 0.08319  loss_rpn_loc: 0.1738  time: 0.2241  data_time: 0.0176  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:49:19 d2.utils.events]: \u001b[0m eta: 5:07:58  iter: 11339  total_loss: 1.297  loss_cls: 0.3183  loss_box_reg: 0.4298  loss_mask: 0.2677  loss_rpn_cls: 0.08534  loss_rpn_loc: 0.1667  time: 0.2240  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:49:23 d2.utils.events]: \u001b[0m eta: 5:07:52  iter: 11359  total_loss: 1.16  loss_cls: 0.2607  loss_box_reg: 0.3935  loss_mask: 0.2662  loss_rpn_cls: 0.08278  loss_rpn_loc: 0.1746  time: 0.2241  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:49:28 d2.utils.events]: \u001b[0m eta: 5:08:26  iter: 11379  total_loss: 1.325  loss_cls: 0.3314  loss_box_reg: 0.4267  loss_mask: 0.278  loss_rpn_cls: 0.08218  loss_rpn_loc: 0.1765  time: 0.2241  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:49:32 d2.utils.events]: \u001b[0m eta: 5:08:21  iter: 11399  total_loss: 1.234  loss_cls: 0.2932  loss_box_reg: 0.3955  loss_mask: 0.2885  loss_rpn_cls: 0.105  loss_rpn_loc: 0.1698  time: 0.2240  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:49:36 d2.utils.events]: \u001b[0m eta: 5:08:03  iter: 11419  total_loss: 1.3  loss_cls: 0.3014  loss_box_reg: 0.4116  loss_mask: 0.2663  loss_rpn_cls: 0.07549  loss_rpn_loc: 0.1724  time: 0.2240  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:49:41 d2.utils.events]: \u001b[0m eta: 5:08:13  iter: 11439  total_loss: 1.261  loss_cls: 0.3531  loss_box_reg: 0.3849  loss_mask: 0.2827  loss_rpn_cls: 0.0876  loss_rpn_loc: 0.1754  time: 0.2240  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:49:45 d2.utils.events]: \u001b[0m eta: 5:08:41  iter: 11459  total_loss: 1.3  loss_cls: 0.3031  loss_box_reg: 0.4237  loss_mask: 0.2898  loss_rpn_cls: 0.07596  loss_rpn_loc: 0.1838  time: 0.2240  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:49:50 d2.utils.events]: \u001b[0m eta: 5:08:32  iter: 11479  total_loss: 1.343  loss_cls: 0.3535  loss_box_reg: 0.4207  loss_mask: 0.2819  loss_rpn_cls: 0.09271  loss_rpn_loc: 0.1842  time: 0.2240  data_time: 0.0156  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:49:54 d2.utils.events]: \u001b[0m eta: 5:08:32  iter: 11499  total_loss: 1.283  loss_cls: 0.3375  loss_box_reg: 0.4158  loss_mask: 0.2941  loss_rpn_cls: 0.09502  loss_rpn_loc: 0.1795  time: 0.2240  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:49:59 d2.utils.events]: \u001b[0m eta: 5:08:49  iter: 11519  total_loss: 1.385  loss_cls: 0.3614  loss_box_reg: 0.41  loss_mask: 0.271  loss_rpn_cls: 0.09583  loss_rpn_loc: 0.1843  time: 0.2241  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:50:03 d2.utils.events]: \u001b[0m eta: 5:08:40  iter: 11539  total_loss: 1.298  loss_cls: 0.3288  loss_box_reg: 0.4437  loss_mask: 0.2664  loss_rpn_cls: 0.07415  loss_rpn_loc: 0.1736  time: 0.2240  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:50:08 d2.utils.events]: \u001b[0m eta: 5:09:05  iter: 11559  total_loss: 1.321  loss_cls: 0.3621  loss_box_reg: 0.4302  loss_mask: 0.2801  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.1925  time: 0.2240  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:50:12 d2.utils.events]: \u001b[0m eta: 5:08:43  iter: 11579  total_loss: 1.239  loss_cls: 0.3285  loss_box_reg: 0.3616  loss_mask: 0.2561  loss_rpn_cls: 0.08196  loss_rpn_loc: 0.183  time: 0.2240  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:50:17 d2.utils.events]: \u001b[0m eta: 5:08:31  iter: 11599  total_loss: 1.341  loss_cls: 0.3434  loss_box_reg: 0.3966  loss_mask: 0.2846  loss_rpn_cls: 0.09876  loss_rpn_loc: 0.1687  time: 0.2240  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:50:21 d2.utils.events]: \u001b[0m eta: 5:08:25  iter: 11619  total_loss: 1.173  loss_cls: 0.2684  loss_box_reg: 0.3945  loss_mask: 0.2423  loss_rpn_cls: 0.07396  loss_rpn_loc: 0.1743  time: 0.2240  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:50:26 d2.utils.events]: \u001b[0m eta: 5:08:55  iter: 11639  total_loss: 1.319  loss_cls: 0.3361  loss_box_reg: 0.3857  loss_mask: 0.2784  loss_rpn_cls: 0.09  loss_rpn_loc: 0.1992  time: 0.2241  data_time: 0.0199  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:50:30 d2.utils.events]: \u001b[0m eta: 5:08:51  iter: 11659  total_loss: 1.306  loss_cls: 0.3576  loss_box_reg: 0.4169  loss_mask: 0.2708  loss_rpn_cls: 0.08638  loss_rpn_loc: 0.181  time: 0.2241  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:50:35 d2.utils.events]: \u001b[0m eta: 5:09:29  iter: 11679  total_loss: 1.266  loss_cls: 0.3636  loss_box_reg: 0.3831  loss_mask: 0.2781  loss_rpn_cls: 0.0881  loss_rpn_loc: 0.1748  time: 0.2241  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 21:50:39 d2.utils.events]: \u001b[0m eta: 5:08:45  iter: 11699  total_loss: 1.303  loss_cls: 0.3624  loss_box_reg: 0.4055  loss_mask: 0.2468  loss_rpn_cls: 0.07188  loss_rpn_loc: 0.1608  time: 0.2240  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:50:43 d2.utils.events]: \u001b[0m eta: 5:08:41  iter: 11719  total_loss: 1.362  loss_cls: 0.3581  loss_box_reg: 0.4228  loss_mask: 0.2905  loss_rpn_cls: 0.07057  loss_rpn_loc: 0.1818  time: 0.2239  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:50:48 d2.utils.events]: \u001b[0m eta: 5:08:25  iter: 11739  total_loss: 1.199  loss_cls: 0.3307  loss_box_reg: 0.3813  loss_mask: 0.2565  loss_rpn_cls: 0.06575  loss_rpn_loc: 0.1639  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:50:52 d2.utils.events]: \u001b[0m eta: 5:08:46  iter: 11759  total_loss: 1.257  loss_cls: 0.2782  loss_box_reg: 0.4069  loss_mask: 0.264  loss_rpn_cls: 0.08261  loss_rpn_loc: 0.1718  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:50:57 d2.utils.events]: \u001b[0m eta: 5:08:48  iter: 11779  total_loss: 1.222  loss_cls: 0.3263  loss_box_reg: 0.3922  loss_mask: 0.2585  loss_rpn_cls: 0.09559  loss_rpn_loc: 0.1698  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:51:01 d2.utils.events]: \u001b[0m eta: 5:08:43  iter: 11799  total_loss: 1.257  loss_cls: 0.327  loss_box_reg: 0.4183  loss_mask: 0.2815  loss_rpn_cls: 0.06828  loss_rpn_loc: 0.161  time: 0.2239  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:51:06 d2.utils.events]: \u001b[0m eta: 5:09:01  iter: 11819  total_loss: 1.262  loss_cls: 0.3283  loss_box_reg: 0.4021  loss_mask: 0.2816  loss_rpn_cls: 0.1103  loss_rpn_loc: 0.1842  time: 0.2239  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:51:10 d2.utils.events]: \u001b[0m eta: 5:08:35  iter: 11839  total_loss: 1.304  loss_cls: 0.3487  loss_box_reg: 0.3787  loss_mask: 0.2642  loss_rpn_cls: 0.09757  loss_rpn_loc: 0.1801  time: 0.2239  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:51:15 d2.utils.events]: \u001b[0m eta: 5:08:39  iter: 11859  total_loss: 1.298  loss_cls: 0.273  loss_box_reg: 0.393  loss_mask: 0.2687  loss_rpn_cls: 0.104  loss_rpn_loc: 0.1895  time: 0.2240  data_time: 0.0261  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:51:20 d2.utils.events]: \u001b[0m eta: 5:08:35  iter: 11879  total_loss: 1.386  loss_cls: 0.3317  loss_box_reg: 0.4355  loss_mask: 0.2992  loss_rpn_cls: 0.107  loss_rpn_loc: 0.1911  time: 0.2241  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:51:24 d2.utils.events]: \u001b[0m eta: 5:08:01  iter: 11899  total_loss: 1.332  loss_cls: 0.3365  loss_box_reg: 0.4688  loss_mask: 0.2727  loss_rpn_cls: 0.06933  loss_rpn_loc: 0.1859  time: 0.2240  data_time: 0.0057  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:51:29 d2.utils.events]: \u001b[0m eta: 5:07:46  iter: 11919  total_loss: 1.401  loss_cls: 0.4041  loss_box_reg: 0.4457  loss_mask: 0.2989  loss_rpn_cls: 0.08973  loss_rpn_loc: 0.1757  time: 0.2240  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:51:33 d2.utils.events]: \u001b[0m eta: 5:07:46  iter: 11939  total_loss: 1.198  loss_cls: 0.3109  loss_box_reg: 0.4153  loss_mask: 0.2532  loss_rpn_cls: 0.06685  loss_rpn_loc: 0.17  time: 0.2241  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:51:38 d2.utils.events]: \u001b[0m eta: 5:08:13  iter: 11959  total_loss: 1.087  loss_cls: 0.2219  loss_box_reg: 0.3538  loss_mask: 0.2505  loss_rpn_cls: 0.07701  loss_rpn_loc: 0.1556  time: 0.2241  data_time: 0.0100  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:51:42 d2.utils.events]: \u001b[0m eta: 5:08:03  iter: 11979  total_loss: 1.319  loss_cls: 0.3505  loss_box_reg: 0.434  loss_mask: 0.2649  loss_rpn_cls: 0.0816  loss_rpn_loc: 0.1713  time: 0.2241  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:51:47 d2.utils.events]: \u001b[0m eta: 5:08:17  iter: 11999  total_loss: 1.175  loss_cls: 0.2916  loss_box_reg: 0.3644  loss_mask: 0.255  loss_rpn_cls: 0.07254  loss_rpn_loc: 0.1704  time: 0.2241  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:51:52 d2.utils.events]: \u001b[0m eta: 5:08:23  iter: 12019  total_loss: 1.336  loss_cls: 0.3444  loss_box_reg: 0.4165  loss_mask: 0.285  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.1849  time: 0.2242  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:51:57 d2.utils.events]: \u001b[0m eta: 5:08:44  iter: 12039  total_loss: 1.266  loss_cls: 0.3432  loss_box_reg: 0.38  loss_mask: 0.2679  loss_rpn_cls: 0.06796  loss_rpn_loc: 0.1971  time: 0.2242  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:52:01 d2.utils.events]: \u001b[0m eta: 5:08:40  iter: 12059  total_loss: 1.316  loss_cls: 0.3137  loss_box_reg: 0.4032  loss_mask: 0.2753  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.1914  time: 0.2242  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:52:06 d2.utils.events]: \u001b[0m eta: 5:08:20  iter: 12079  total_loss: 1.312  loss_cls: 0.3282  loss_box_reg: 0.415  loss_mask: 0.2717  loss_rpn_cls: 0.09104  loss_rpn_loc: 0.1798  time: 0.2242  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:52:10 d2.utils.events]: \u001b[0m eta: 5:07:55  iter: 12099  total_loss: 1.24  loss_cls: 0.3226  loss_box_reg: 0.4085  loss_mask: 0.273  loss_rpn_cls: 0.0737  loss_rpn_loc: 0.1673  time: 0.2242  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:52:15 d2.utils.events]: \u001b[0m eta: 5:08:00  iter: 12119  total_loss: 1.296  loss_cls: 0.3307  loss_box_reg: 0.4152  loss_mask: 0.2809  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.1678  time: 0.2242  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:52:19 d2.utils.events]: \u001b[0m eta: 5:07:29  iter: 12139  total_loss: 1.325  loss_cls: 0.3267  loss_box_reg: 0.4079  loss_mask: 0.2722  loss_rpn_cls: 0.09682  loss_rpn_loc: 0.1874  time: 0.2242  data_time: 0.0157  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:52:24 d2.utils.events]: \u001b[0m eta: 5:07:25  iter: 12159  total_loss: 1.207  loss_cls: 0.2838  loss_box_reg: 0.3704  loss_mask: 0.2837  loss_rpn_cls: 0.09153  loss_rpn_loc: 0.2015  time: 0.2242  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:52:28 d2.utils.events]: \u001b[0m eta: 5:07:05  iter: 12179  total_loss: 1.388  loss_cls: 0.3339  loss_box_reg: 0.4132  loss_mask: 0.2784  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.1874  time: 0.2242  data_time: 0.0106  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:52:33 d2.utils.events]: \u001b[0m eta: 5:07:01  iter: 12199  total_loss: 1.432  loss_cls: 0.3765  loss_box_reg: 0.4393  loss_mask: 0.2897  loss_rpn_cls: 0.1144  loss_rpn_loc: 0.1948  time: 0.2242  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:52:37 d2.utils.events]: \u001b[0m eta: 5:06:59  iter: 12219  total_loss: 1.391  loss_cls: 0.3494  loss_box_reg: 0.423  loss_mask: 0.2904  loss_rpn_cls: 0.09025  loss_rpn_loc: 0.1884  time: 0.2242  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:52:42 d2.utils.events]: \u001b[0m eta: 5:06:36  iter: 12239  total_loss: 1.287  loss_cls: 0.3338  loss_box_reg: 0.4383  loss_mask: 0.2642  loss_rpn_cls: 0.0869  loss_rpn_loc: 0.165  time: 0.2243  data_time: 0.0152  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:52:47 d2.utils.events]: \u001b[0m eta: 5:07:03  iter: 12259  total_loss: 1.154  loss_cls: 0.3044  loss_box_reg: 0.3639  loss_mask: 0.2552  loss_rpn_cls: 0.0963  loss_rpn_loc: 0.1857  time: 0.2243  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:52:51 d2.utils.events]: \u001b[0m eta: 5:07:25  iter: 12279  total_loss: 1.242  loss_cls: 0.3449  loss_box_reg: 0.407  loss_mask: 0.248  loss_rpn_cls: 0.07254  loss_rpn_loc: 0.1744  time: 0.2243  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:52:56 d2.utils.events]: \u001b[0m eta: 5:07:27  iter: 12299  total_loss: 1.192  loss_cls: 0.2952  loss_box_reg: 0.3648  loss_mask: 0.2497  loss_rpn_cls: 0.07566  loss_rpn_loc: 0.1694  time: 0.2243  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:53:00 d2.utils.events]: \u001b[0m eta: 5:07:17  iter: 12319  total_loss: 1.189  loss_cls: 0.2788  loss_box_reg: 0.3986  loss_mask: 0.2507  loss_rpn_cls: 0.07189  loss_rpn_loc: 0.1639  time: 0.2243  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:53:05 d2.utils.events]: \u001b[0m eta: 5:07:14  iter: 12339  total_loss: 1.344  loss_cls: 0.3435  loss_box_reg: 0.4421  loss_mask: 0.2752  loss_rpn_cls: 0.09099  loss_rpn_loc: 0.182  time: 0.2243  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 21:53:09 d2.utils.events]: \u001b[0m eta: 5:06:45  iter: 12359  total_loss: 1.044  loss_cls: 0.2542  loss_box_reg: 0.3807  loss_mask: 0.2292  loss_rpn_cls: 0.04811  loss_rpn_loc: 0.1549  time: 0.2243  data_time: 0.0164  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:53:14 d2.utils.events]: \u001b[0m eta: 5:06:36  iter: 12379  total_loss: 1.395  loss_cls: 0.3689  loss_box_reg: 0.4701  loss_mask: 0.2848  loss_rpn_cls: 0.09903  loss_rpn_loc: 0.1907  time: 0.2243  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:53:18 d2.utils.events]: \u001b[0m eta: 5:06:31  iter: 12399  total_loss: 1.24  loss_cls: 0.3301  loss_box_reg: 0.3776  loss_mask: 0.2603  loss_rpn_cls: 0.07847  loss_rpn_loc: 0.1751  time: 0.2243  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:53:23 d2.utils.events]: \u001b[0m eta: 5:06:15  iter: 12419  total_loss: 1.193  loss_cls: 0.3123  loss_box_reg: 0.4124  loss_mask: 0.2483  loss_rpn_cls: 0.06974  loss_rpn_loc: 0.1632  time: 0.2243  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:53:27 d2.utils.events]: \u001b[0m eta: 5:06:23  iter: 12439  total_loss: 1.335  loss_cls: 0.3456  loss_box_reg: 0.4267  loss_mask: 0.2644  loss_rpn_cls: 0.05919  loss_rpn_loc: 0.1663  time: 0.2242  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:53:32 d2.utils.events]: \u001b[0m eta: 5:06:13  iter: 12459  total_loss: 1.273  loss_cls: 0.3058  loss_box_reg: 0.4  loss_mask: 0.2766  loss_rpn_cls: 0.08773  loss_rpn_loc: 0.1843  time: 0.2242  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:53:36 d2.utils.events]: \u001b[0m eta: 5:05:55  iter: 12479  total_loss: 1.294  loss_cls: 0.3396  loss_box_reg: 0.4219  loss_mask: 0.2734  loss_rpn_cls: 0.06593  loss_rpn_loc: 0.1807  time: 0.2242  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:53:40 d2.utils.events]: \u001b[0m eta: 5:05:57  iter: 12499  total_loss: 1.254  loss_cls: 0.3244  loss_box_reg: 0.413  loss_mask: 0.2578  loss_rpn_cls: 0.06653  loss_rpn_loc: 0.1624  time: 0.2242  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:53:45 d2.utils.events]: \u001b[0m eta: 5:05:47  iter: 12519  total_loss: 1.238  loss_cls: 0.3071  loss_box_reg: 0.389  loss_mask: 0.2729  loss_rpn_cls: 0.08056  loss_rpn_loc: 0.1464  time: 0.2242  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:53:49 d2.utils.events]: \u001b[0m eta: 5:06:24  iter: 12539  total_loss: 1.328  loss_cls: 0.3247  loss_box_reg: 0.4568  loss_mask: 0.2957  loss_rpn_cls: 0.09852  loss_rpn_loc: 0.1876  time: 0.2242  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:53:54 d2.utils.events]: \u001b[0m eta: 5:06:11  iter: 12559  total_loss: 1.17  loss_cls: 0.2924  loss_box_reg: 0.3771  loss_mask: 0.2644  loss_rpn_cls: 0.09171  loss_rpn_loc: 0.1726  time: 0.2242  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:53:58 d2.utils.events]: \u001b[0m eta: 5:05:40  iter: 12579  total_loss: 1.224  loss_cls: 0.2871  loss_box_reg: 0.3805  loss_mask: 0.2706  loss_rpn_cls: 0.07643  loss_rpn_loc: 0.1713  time: 0.2242  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:54:03 d2.utils.events]: \u001b[0m eta: 5:05:33  iter: 12599  total_loss: 1.193  loss_cls: 0.2969  loss_box_reg: 0.3686  loss_mask: 0.2584  loss_rpn_cls: 0.08793  loss_rpn_loc: 0.1642  time: 0.2242  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:54:07 d2.utils.events]: \u001b[0m eta: 5:05:23  iter: 12619  total_loss: 1.278  loss_cls: 0.3114  loss_box_reg: 0.3996  loss_mask: 0.28  loss_rpn_cls: 0.09663  loss_rpn_loc: 0.1976  time: 0.2242  data_time: 0.0118  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:54:12 d2.utils.events]: \u001b[0m eta: 5:04:53  iter: 12639  total_loss: 1.226  loss_cls: 0.3248  loss_box_reg: 0.4012  loss_mask: 0.2661  loss_rpn_cls: 0.08444  loss_rpn_loc: 0.1602  time: 0.2242  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:54:16 d2.utils.events]: \u001b[0m eta: 5:05:09  iter: 12659  total_loss: 1.352  loss_cls: 0.3409  loss_box_reg: 0.3978  loss_mask: 0.2632  loss_rpn_cls: 0.07497  loss_rpn_loc: 0.1839  time: 0.2242  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:54:21 d2.utils.events]: \u001b[0m eta: 5:05:15  iter: 12679  total_loss: 1.175  loss_cls: 0.2895  loss_box_reg: 0.3894  loss_mask: 0.2619  loss_rpn_cls: 0.08403  loss_rpn_loc: 0.1707  time: 0.2242  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:54:25 d2.utils.events]: \u001b[0m eta: 5:05:19  iter: 12699  total_loss: 1.172  loss_cls: 0.2911  loss_box_reg: 0.4042  loss_mask: 0.2554  loss_rpn_cls: 0.04856  loss_rpn_loc: 0.1502  time: 0.2242  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:54:30 d2.utils.events]: \u001b[0m eta: 5:05:48  iter: 12719  total_loss: 1.191  loss_cls: 0.3057  loss_box_reg: 0.4217  loss_mask: 0.2818  loss_rpn_cls: 0.07564  loss_rpn_loc: 0.1713  time: 0.2242  data_time: 0.0160  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:54:34 d2.utils.events]: \u001b[0m eta: 5:05:49  iter: 12739  total_loss: 1.328  loss_cls: 0.3427  loss_box_reg: 0.3807  loss_mask: 0.2843  loss_rpn_cls: 0.09325  loss_rpn_loc: 0.1709  time: 0.2242  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:54:39 d2.utils.events]: \u001b[0m eta: 5:05:36  iter: 12759  total_loss: 1.252  loss_cls: 0.3016  loss_box_reg: 0.3533  loss_mask: 0.2566  loss_rpn_cls: 0.08974  loss_rpn_loc: 0.1815  time: 0.2242  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:54:43 d2.utils.events]: \u001b[0m eta: 5:05:13  iter: 12779  total_loss: 1.287  loss_cls: 0.3668  loss_box_reg: 0.3996  loss_mask: 0.2744  loss_rpn_cls: 0.06527  loss_rpn_loc: 0.1572  time: 0.2242  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:54:48 d2.utils.events]: \u001b[0m eta: 5:05:19  iter: 12799  total_loss: 1.335  loss_cls: 0.3562  loss_box_reg: 0.4221  loss_mask: 0.2729  loss_rpn_cls: 0.1026  loss_rpn_loc: 0.1744  time: 0.2242  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:54:52 d2.utils.events]: \u001b[0m eta: 5:04:48  iter: 12819  total_loss: 1.321  loss_cls: 0.3269  loss_box_reg: 0.4199  loss_mask: 0.2828  loss_rpn_cls: 0.1006  loss_rpn_loc: 0.1738  time: 0.2242  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:54:56 d2.utils.events]: \u001b[0m eta: 5:04:14  iter: 12839  total_loss: 1.311  loss_cls: 0.3454  loss_box_reg: 0.4097  loss_mask: 0.2694  loss_rpn_cls: 0.09222  loss_rpn_loc: 0.172  time: 0.2241  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:55:01 d2.utils.events]: \u001b[0m eta: 5:04:03  iter: 12859  total_loss: 1.363  loss_cls: 0.3696  loss_box_reg: 0.438  loss_mask: 0.2783  loss_rpn_cls: 0.08165  loss_rpn_loc: 0.1835  time: 0.2241  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:55:06 d2.utils.events]: \u001b[0m eta: 5:03:49  iter: 12879  total_loss: 1.374  loss_cls: 0.3518  loss_box_reg: 0.4186  loss_mask: 0.2701  loss_rpn_cls: 0.1181  loss_rpn_loc: 0.2227  time: 0.2242  data_time: 0.0115  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:55:10 d2.utils.events]: \u001b[0m eta: 5:04:03  iter: 12899  total_loss: 1.391  loss_cls: 0.3417  loss_box_reg: 0.4379  loss_mask: 0.2843  loss_rpn_cls: 0.09764  loss_rpn_loc: 0.2127  time: 0.2242  data_time: 0.0162  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:55:15 d2.utils.events]: \u001b[0m eta: 5:04:22  iter: 12919  total_loss: 1.301  loss_cls: 0.3417  loss_box_reg: 0.4221  loss_mask: 0.2774  loss_rpn_cls: 0.09654  loss_rpn_loc: 0.1678  time: 0.2243  data_time: 0.0089  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:55:20 d2.utils.events]: \u001b[0m eta: 5:04:32  iter: 12939  total_loss: 1.196  loss_cls: 0.3002  loss_box_reg: 0.3805  loss_mask: 0.2673  loss_rpn_cls: 0.08641  loss_rpn_loc: 0.157  time: 0.2243  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:55:24 d2.utils.events]: \u001b[0m eta: 5:04:14  iter: 12959  total_loss: 1.206  loss_cls: 0.3337  loss_box_reg: 0.3818  loss_mask: 0.2536  loss_rpn_cls: 0.07029  loss_rpn_loc: 0.1692  time: 0.2243  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:55:29 d2.utils.events]: \u001b[0m eta: 5:04:29  iter: 12979  total_loss: 1.21  loss_cls: 0.2976  loss_box_reg: 0.3863  loss_mask: 0.2746  loss_rpn_cls: 0.08027  loss_rpn_loc: 0.1715  time: 0.2243  data_time: 0.0214  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:55:34 d2.utils.events]: \u001b[0m eta: 5:04:15  iter: 12999  total_loss: 1.126  loss_cls: 0.2555  loss_box_reg: 0.386  loss_mask: 0.2706  loss_rpn_cls: 0.0905  loss_rpn_loc: 0.1635  time: 0.2244  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 21:55:38 d2.utils.events]: \u001b[0m eta: 5:04:07  iter: 13019  total_loss: 1.244  loss_cls: 0.3102  loss_box_reg: 0.3956  loss_mask: 0.2797  loss_rpn_cls: 0.07003  loss_rpn_loc: 0.1724  time: 0.2243  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:55:43 d2.utils.events]: \u001b[0m eta: 5:03:54  iter: 13039  total_loss: 1.11  loss_cls: 0.2632  loss_box_reg: 0.3563  loss_mask: 0.263  loss_rpn_cls: 0.0653  loss_rpn_loc: 0.1631  time: 0.2244  data_time: 0.0132  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:55:47 d2.utils.events]: \u001b[0m eta: 5:03:21  iter: 13059  total_loss: 1.27  loss_cls: 0.3347  loss_box_reg: 0.4389  loss_mask: 0.2599  loss_rpn_cls: 0.07268  loss_rpn_loc: 0.168  time: 0.2243  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:55:51 d2.utils.events]: \u001b[0m eta: 5:02:49  iter: 13079  total_loss: 1.25  loss_cls: 0.3232  loss_box_reg: 0.4276  loss_mask: 0.2786  loss_rpn_cls: 0.08101  loss_rpn_loc: 0.1695  time: 0.2243  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:55:56 d2.utils.events]: \u001b[0m eta: 5:03:09  iter: 13099  total_loss: 1.098  loss_cls: 0.2519  loss_box_reg: 0.3201  loss_mask: 0.2649  loss_rpn_cls: 0.06693  loss_rpn_loc: 0.1714  time: 0.2243  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:56:00 d2.utils.events]: \u001b[0m eta: 5:02:56  iter: 13119  total_loss: 1.318  loss_cls: 0.3729  loss_box_reg: 0.3927  loss_mask: 0.2665  loss_rpn_cls: 0.07385  loss_rpn_loc: 0.1649  time: 0.2243  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:56:05 d2.utils.events]: \u001b[0m eta: 5:03:00  iter: 13139  total_loss: 1.265  loss_cls: 0.337  loss_box_reg: 0.3842  loss_mask: 0.2682  loss_rpn_cls: 0.07301  loss_rpn_loc: 0.1725  time: 0.2243  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:56:09 d2.utils.events]: \u001b[0m eta: 5:02:47  iter: 13159  total_loss: 1.323  loss_cls: 0.3433  loss_box_reg: 0.3889  loss_mask: 0.2658  loss_rpn_cls: 0.07586  loss_rpn_loc: 0.178  time: 0.2243  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:56:13 d2.utils.events]: \u001b[0m eta: 5:02:33  iter: 13179  total_loss: 1.272  loss_cls: 0.3565  loss_box_reg: 0.4468  loss_mask: 0.2704  loss_rpn_cls: 0.0706  loss_rpn_loc: 0.1673  time: 0.2242  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:56:18 d2.utils.events]: \u001b[0m eta: 5:02:30  iter: 13199  total_loss: 1.306  loss_cls: 0.3583  loss_box_reg: 0.4459  loss_mask: 0.2647  loss_rpn_cls: 0.09646  loss_rpn_loc: 0.1802  time: 0.2242  data_time: 0.0165  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:56:23 d2.utils.events]: \u001b[0m eta: 5:02:46  iter: 13219  total_loss: 1.211  loss_cls: 0.3447  loss_box_reg: 0.3623  loss_mask: 0.2657  loss_rpn_cls: 0.1136  loss_rpn_loc: 0.181  time: 0.2243  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:56:27 d2.utils.events]: \u001b[0m eta: 5:02:46  iter: 13239  total_loss: 1.239  loss_cls: 0.3437  loss_box_reg: 0.3893  loss_mask: 0.254  loss_rpn_cls: 0.06979  loss_rpn_loc: 0.1757  time: 0.2243  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:56:32 d2.utils.events]: \u001b[0m eta: 5:02:37  iter: 13259  total_loss: 1.352  loss_cls: 0.3471  loss_box_reg: 0.4142  loss_mask: 0.2781  loss_rpn_cls: 0.09234  loss_rpn_loc: 0.21  time: 0.2243  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:56:36 d2.utils.events]: \u001b[0m eta: 5:02:40  iter: 13279  total_loss: 1.286  loss_cls: 0.3469  loss_box_reg: 0.4058  loss_mask: 0.2597  loss_rpn_cls: 0.07349  loss_rpn_loc: 0.176  time: 0.2243  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:56:41 d2.utils.events]: \u001b[0m eta: 5:02:49  iter: 13299  total_loss: 1.375  loss_cls: 0.3551  loss_box_reg: 0.4138  loss_mask: 0.2921  loss_rpn_cls: 0.09889  loss_rpn_loc: 0.1939  time: 0.2243  data_time: 0.0159  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:56:45 d2.utils.events]: \u001b[0m eta: 5:02:55  iter: 13319  total_loss: 1.315  loss_cls: 0.3318  loss_box_reg: 0.3808  loss_mask: 0.2785  loss_rpn_cls: 0.09655  loss_rpn_loc: 0.1711  time: 0.2243  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:56:50 d2.utils.events]: \u001b[0m eta: 5:02:55  iter: 13339  total_loss: 1.204  loss_cls: 0.2732  loss_box_reg: 0.3774  loss_mask: 0.2697  loss_rpn_cls: 0.0814  loss_rpn_loc: 0.1833  time: 0.2243  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:56:54 d2.utils.events]: \u001b[0m eta: 5:03:03  iter: 13359  total_loss: 1.372  loss_cls: 0.3024  loss_box_reg: 0.3862  loss_mask: 0.2765  loss_rpn_cls: 0.08893  loss_rpn_loc: 0.1614  time: 0.2243  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:56:59 d2.utils.events]: \u001b[0m eta: 5:02:59  iter: 13379  total_loss: 1.369  loss_cls: 0.3277  loss_box_reg: 0.4314  loss_mask: 0.2799  loss_rpn_cls: 0.07558  loss_rpn_loc: 0.1744  time: 0.2243  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:57:03 d2.utils.events]: \u001b[0m eta: 5:03:03  iter: 13399  total_loss: 1.242  loss_cls: 0.3154  loss_box_reg: 0.3987  loss_mask: 0.2675  loss_rpn_cls: 0.08686  loss_rpn_loc: 0.1819  time: 0.2243  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:57:08 d2.utils.events]: \u001b[0m eta: 5:03:08  iter: 13419  total_loss: 1.201  loss_cls: 0.2879  loss_box_reg: 0.3853  loss_mask: 0.2564  loss_rpn_cls: 0.08722  loss_rpn_loc: 0.173  time: 0.2243  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:57:12 d2.utils.events]: \u001b[0m eta: 5:03:11  iter: 13439  total_loss: 1.38  loss_cls: 0.362  loss_box_reg: 0.4046  loss_mask: 0.291  loss_rpn_cls: 0.08829  loss_rpn_loc: 0.18  time: 0.2243  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:57:17 d2.utils.events]: \u001b[0m eta: 5:02:44  iter: 13459  total_loss: 1.39  loss_cls: 0.3564  loss_box_reg: 0.472  loss_mask: 0.2816  loss_rpn_cls: 0.08227  loss_rpn_loc: 0.1747  time: 0.2243  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:57:21 d2.utils.events]: \u001b[0m eta: 5:02:40  iter: 13479  total_loss: 1.236  loss_cls: 0.3125  loss_box_reg: 0.399  loss_mask: 0.28  loss_rpn_cls: 0.08422  loss_rpn_loc: 0.1665  time: 0.2243  data_time: 0.0151  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:57:26 d2.utils.events]: \u001b[0m eta: 5:02:58  iter: 13499  total_loss: 1.243  loss_cls: 0.3357  loss_box_reg: 0.3781  loss_mask: 0.2739  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.1795  time: 0.2243  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:57:30 d2.utils.events]: \u001b[0m eta: 5:02:34  iter: 13519  total_loss: 1.389  loss_cls: 0.3806  loss_box_reg: 0.455  loss_mask: 0.2793  loss_rpn_cls: 0.07562  loss_rpn_loc: 0.1751  time: 0.2243  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:57:34 d2.utils.events]: \u001b[0m eta: 5:02:22  iter: 13539  total_loss: 1.371  loss_cls: 0.359  loss_box_reg: 0.4114  loss_mask: 0.2852  loss_rpn_cls: 0.08288  loss_rpn_loc: 0.1768  time: 0.2243  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:57:39 d2.utils.events]: \u001b[0m eta: 5:02:22  iter: 13559  total_loss: 1.222  loss_cls: 0.3002  loss_box_reg: 0.3891  loss_mask: 0.2655  loss_rpn_cls: 0.06945  loss_rpn_loc: 0.1618  time: 0.2243  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:57:43 d2.utils.events]: \u001b[0m eta: 5:02:24  iter: 13579  total_loss: 1.233  loss_cls: 0.3455  loss_box_reg: 0.3983  loss_mask: 0.2554  loss_rpn_cls: 0.0699  loss_rpn_loc: 0.1764  time: 0.2242  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:57:48 d2.utils.events]: \u001b[0m eta: 5:02:40  iter: 13599  total_loss: 1.219  loss_cls: 0.3117  loss_box_reg: 0.4075  loss_mask: 0.2616  loss_rpn_cls: 0.09781  loss_rpn_loc: 0.1737  time: 0.2243  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:57:52 d2.utils.events]: \u001b[0m eta: 5:02:24  iter: 13619  total_loss: 1.347  loss_cls: 0.3429  loss_box_reg: 0.4752  loss_mask: 0.2906  loss_rpn_cls: 0.08969  loss_rpn_loc: 0.1819  time: 0.2242  data_time: 0.0143  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:57:57 d2.utils.events]: \u001b[0m eta: 5:02:07  iter: 13639  total_loss: 1.226  loss_cls: 0.3226  loss_box_reg: 0.399  loss_mask: 0.2559  loss_rpn_cls: 0.07884  loss_rpn_loc: 0.1675  time: 0.2242  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:58:01 d2.utils.events]: \u001b[0m eta: 5:02:03  iter: 13659  total_loss: 1.192  loss_cls: 0.3034  loss_box_reg: 0.3964  loss_mask: 0.2613  loss_rpn_cls: 0.07931  loss_rpn_loc: 0.1822  time: 0.2242  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 21:58:05 d2.utils.events]: \u001b[0m eta: 5:01:51  iter: 13679  total_loss: 1.354  loss_cls: 0.3458  loss_box_reg: 0.4046  loss_mask: 0.2722  loss_rpn_cls: 0.1231  loss_rpn_loc: 0.2005  time: 0.2242  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:58:10 d2.utils.events]: \u001b[0m eta: 5:01:49  iter: 13699  total_loss: 1.348  loss_cls: 0.3706  loss_box_reg: 0.44  loss_mask: 0.2657  loss_rpn_cls: 0.09685  loss_rpn_loc: 0.1777  time: 0.2242  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:58:14 d2.utils.events]: \u001b[0m eta: 5:01:41  iter: 13719  total_loss: 1.413  loss_cls: 0.3652  loss_box_reg: 0.4146  loss_mask: 0.2736  loss_rpn_cls: 0.1049  loss_rpn_loc: 0.1941  time: 0.2242  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:58:19 d2.utils.events]: \u001b[0m eta: 5:01:25  iter: 13739  total_loss: 1.239  loss_cls: 0.3226  loss_box_reg: 0.3984  loss_mask: 0.2547  loss_rpn_cls: 0.06241  loss_rpn_loc: 0.1733  time: 0.2241  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:58:23 d2.utils.events]: \u001b[0m eta: 5:01:08  iter: 13759  total_loss: 1.175  loss_cls: 0.2982  loss_box_reg: 0.3746  loss_mask: 0.2585  loss_rpn_cls: 0.07673  loss_rpn_loc: 0.1734  time: 0.2241  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:58:27 d2.utils.events]: \u001b[0m eta: 5:01:13  iter: 13779  total_loss: 1.304  loss_cls: 0.3361  loss_box_reg: 0.412  loss_mask: 0.2677  loss_rpn_cls: 0.1171  loss_rpn_loc: 0.1785  time: 0.2241  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:58:32 d2.utils.events]: \u001b[0m eta: 5:01:04  iter: 13799  total_loss: 1.285  loss_cls: 0.3463  loss_box_reg: 0.4138  loss_mask: 0.2551  loss_rpn_cls: 0.08182  loss_rpn_loc: 0.1589  time: 0.2241  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:58:36 d2.utils.events]: \u001b[0m eta: 5:01:06  iter: 13819  total_loss: 1.33  loss_cls: 0.3529  loss_box_reg: 0.4334  loss_mask: 0.2671  loss_rpn_cls: 0.06803  loss_rpn_loc: 0.1773  time: 0.2240  data_time: 0.0118  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:58:41 d2.utils.events]: \u001b[0m eta: 5:01:14  iter: 13839  total_loss: 1.268  loss_cls: 0.3062  loss_box_reg: 0.3842  loss_mask: 0.2717  loss_rpn_cls: 0.09326  loss_rpn_loc: 0.1938  time: 0.2241  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:58:45 d2.utils.events]: \u001b[0m eta: 5:01:13  iter: 13859  total_loss: 1.277  loss_cls: 0.3669  loss_box_reg: 0.4175  loss_mask: 0.2817  loss_rpn_cls: 0.1119  loss_rpn_loc: 0.1802  time: 0.2241  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:58:50 d2.utils.events]: \u001b[0m eta: 5:01:15  iter: 13879  total_loss: 1.239  loss_cls: 0.3154  loss_box_reg: 0.3967  loss_mask: 0.2627  loss_rpn_cls: 0.1009  loss_rpn_loc: 0.1641  time: 0.2241  data_time: 0.0210  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:58:55 d2.utils.events]: \u001b[0m eta: 5:01:25  iter: 13899  total_loss: 1.198  loss_cls: 0.3113  loss_box_reg: 0.3846  loss_mask: 0.2711  loss_rpn_cls: 0.09569  loss_rpn_loc: 0.1544  time: 0.2241  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:58:59 d2.utils.events]: \u001b[0m eta: 5:01:09  iter: 13919  total_loss: 1.137  loss_cls: 0.2785  loss_box_reg: 0.3748  loss_mask: 0.2652  loss_rpn_cls: 0.05746  loss_rpn_loc: 0.1567  time: 0.2241  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:59:03 d2.utils.events]: \u001b[0m eta: 5:00:53  iter: 13939  total_loss: 1.334  loss_cls: 0.3362  loss_box_reg: 0.4381  loss_mask: 0.2772  loss_rpn_cls: 0.07215  loss_rpn_loc: 0.1735  time: 0.2241  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:59:08 d2.utils.events]: \u001b[0m eta: 5:00:41  iter: 13959  total_loss: 1.196  loss_cls: 0.3037  loss_box_reg: 0.4016  loss_mask: 0.2633  loss_rpn_cls: 0.06255  loss_rpn_loc: 0.1644  time: 0.2241  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:59:12 d2.utils.events]: \u001b[0m eta: 5:00:27  iter: 13979  total_loss: 1.316  loss_cls: 0.3285  loss_box_reg: 0.445  loss_mask: 0.2714  loss_rpn_cls: 0.07265  loss_rpn_loc: 0.1569  time: 0.2241  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:59:17 d2.utils.events]: \u001b[0m eta: 5:00:30  iter: 13999  total_loss: 1.222  loss_cls: 0.3084  loss_box_reg: 0.3928  loss_mask: 0.269  loss_rpn_cls: 0.09095  loss_rpn_loc: 0.1638  time: 0.2241  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:59:21 d2.utils.events]: \u001b[0m eta: 5:00:23  iter: 14019  total_loss: 1.315  loss_cls: 0.3531  loss_box_reg: 0.4274  loss_mask: 0.2682  loss_rpn_cls: 0.08084  loss_rpn_loc: 0.161  time: 0.2240  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:59:25 d2.utils.events]: \u001b[0m eta: 5:00:19  iter: 14039  total_loss: 1.305  loss_cls: 0.3218  loss_box_reg: 0.4049  loss_mask: 0.2833  loss_rpn_cls: 0.09564  loss_rpn_loc: 0.1835  time: 0.2240  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:59:30 d2.utils.events]: \u001b[0m eta: 5:00:16  iter: 14059  total_loss: 1.251  loss_cls: 0.3138  loss_box_reg: 0.4062  loss_mask: 0.2691  loss_rpn_cls: 0.07097  loss_rpn_loc: 0.1594  time: 0.2240  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:59:34 d2.utils.events]: \u001b[0m eta: 5:00:18  iter: 14079  total_loss: 1.298  loss_cls: 0.3555  loss_box_reg: 0.4075  loss_mask: 0.2506  loss_rpn_cls: 0.06688  loss_rpn_loc: 0.1835  time: 0.2240  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:59:38 d2.utils.events]: \u001b[0m eta: 5:00:07  iter: 14099  total_loss: 1.239  loss_cls: 0.3345  loss_box_reg: 0.3798  loss_mask: 0.2566  loss_rpn_cls: 0.05351  loss_rpn_loc: 0.1651  time: 0.2240  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:59:43 d2.utils.events]: \u001b[0m eta: 5:00:15  iter: 14119  total_loss: 1.151  loss_cls: 0.2641  loss_box_reg: 0.3813  loss_mask: 0.2732  loss_rpn_cls: 0.09106  loss_rpn_loc: 0.1788  time: 0.2240  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:59:48 d2.utils.events]: \u001b[0m eta: 5:00:05  iter: 14139  total_loss: 1.199  loss_cls: 0.3137  loss_box_reg: 0.3939  loss_mask: 0.2761  loss_rpn_cls: 0.07002  loss_rpn_loc: 0.1701  time: 0.2240  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:59:52 d2.utils.events]: \u001b[0m eta: 4:59:57  iter: 14159  total_loss: 1.401  loss_cls: 0.3655  loss_box_reg: 0.4187  loss_mask: 0.2707  loss_rpn_cls: 0.1075  loss_rpn_loc: 0.1746  time: 0.2240  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 21:59:57 d2.utils.events]: \u001b[0m eta: 5:00:00  iter: 14179  total_loss: 1.242  loss_cls: 0.3173  loss_box_reg: 0.3892  loss_mask: 0.2577  loss_rpn_cls: 0.07007  loss_rpn_loc: 0.1566  time: 0.2240  data_time: 0.0175  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:00:01 d2.utils.events]: \u001b[0m eta: 4:59:57  iter: 14199  total_loss: 1.36  loss_cls: 0.3652  loss_box_reg: 0.4072  loss_mask: 0.2927  loss_rpn_cls: 0.1078  loss_rpn_loc: 0.1873  time: 0.2240  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:00:06 d2.utils.events]: \u001b[0m eta: 4:59:44  iter: 14219  total_loss: 1.224  loss_cls: 0.3168  loss_box_reg: 0.3823  loss_mask: 0.2589  loss_rpn_cls: 0.06475  loss_rpn_loc: 0.1558  time: 0.2241  data_time: 0.0249  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:00:11 d2.utils.events]: \u001b[0m eta: 4:59:43  iter: 14239  total_loss: 1.289  loss_cls: 0.3334  loss_box_reg: 0.4219  loss_mask: 0.2849  loss_rpn_cls: 0.102  loss_rpn_loc: 0.1904  time: 0.2241  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:00:15 d2.utils.events]: \u001b[0m eta: 4:59:31  iter: 14259  total_loss: 1.317  loss_cls: 0.3463  loss_box_reg: 0.4236  loss_mask: 0.2692  loss_rpn_cls: 0.06418  loss_rpn_loc: 0.159  time: 0.2241  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:00:20 d2.utils.events]: \u001b[0m eta: 4:59:31  iter: 14279  total_loss: 1.251  loss_cls: 0.3271  loss_box_reg: 0.4118  loss_mask: 0.2744  loss_rpn_cls: 0.08873  loss_rpn_loc: 0.1763  time: 0.2241  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:00:24 d2.utils.events]: \u001b[0m eta: 4:59:07  iter: 14299  total_loss: 1.335  loss_cls: 0.3471  loss_box_reg: 0.4059  loss_mask: 0.2904  loss_rpn_cls: 0.07349  loss_rpn_loc: 0.1799  time: 0.2241  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:00:29 d2.utils.events]: \u001b[0m eta: 4:59:20  iter: 14319  total_loss: 1.279  loss_cls: 0.3062  loss_box_reg: 0.3943  loss_mask: 0.2777  loss_rpn_cls: 0.08565  loss_rpn_loc: 0.172  time: 0.2241  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:00:33 d2.utils.events]: \u001b[0m eta: 4:59:18  iter: 14339  total_loss: 1.295  loss_cls: 0.3213  loss_box_reg: 0.413  loss_mask: 0.2686  loss_rpn_cls: 0.113  loss_rpn_loc: 0.1867  time: 0.2241  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:00:38 d2.utils.events]: \u001b[0m eta: 4:59:12  iter: 14359  total_loss: 1.363  loss_cls: 0.3499  loss_box_reg: 0.4438  loss_mask: 0.2771  loss_rpn_cls: 0.09263  loss_rpn_loc: 0.1955  time: 0.2241  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:00:42 d2.utils.events]: \u001b[0m eta: 4:59:04  iter: 14379  total_loss: 1.229  loss_cls: 0.3027  loss_box_reg: 0.359  loss_mask: 0.2744  loss_rpn_cls: 0.1111  loss_rpn_loc: 0.2002  time: 0.2241  data_time: 0.0089  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:00:47 d2.utils.events]: \u001b[0m eta: 4:59:09  iter: 14399  total_loss: 1.224  loss_cls: 0.2928  loss_box_reg: 0.377  loss_mask: 0.2568  loss_rpn_cls: 0.1121  loss_rpn_loc: 0.1808  time: 0.2241  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:00:51 d2.utils.events]: \u001b[0m eta: 4:59:05  iter: 14419  total_loss: 1.284  loss_cls: 0.3573  loss_box_reg: 0.4269  loss_mask: 0.2746  loss_rpn_cls: 0.09879  loss_rpn_loc: 0.1651  time: 0.2241  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:00:56 d2.utils.events]: \u001b[0m eta: 4:58:56  iter: 14439  total_loss: 1.401  loss_cls: 0.3586  loss_box_reg: 0.4062  loss_mask: 0.2733  loss_rpn_cls: 0.09958  loss_rpn_loc: 0.1902  time: 0.2241  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:01:01 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.50 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/29 22:01:01 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/29 22:01:01 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/29 22:01:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/29 22:01:03 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 22:01:03 d2.data.common]: \u001b[0mSerialized dataset takes 84.20 MiB\n",
      "\u001b[32m[12/29 22:01:05 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.02 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/29 22:01:05 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/29 22:01:05 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/29 22:01:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/29 22:01:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0008 s/iter. Inference: 0.0624 s/iter. Eval: 0.1424 s/iter. Total: 0.2056 s/iter. ETA=0:01:54\n",
      "\u001b[32m[12/29 22:01:14 d2.evaluation.evaluator]: \u001b[0mInference done 39/570. Dataloading: 0.0009 s/iter. Inference: 0.0581 s/iter. Eval: 0.1258 s/iter. Total: 0.1848 s/iter. ETA=0:01:38\n",
      "\u001b[32m[12/29 22:01:19 d2.evaluation.evaluator]: \u001b[0mInference done 66/570. Dataloading: 0.0009 s/iter. Inference: 0.0578 s/iter. Eval: 0.1273 s/iter. Total: 0.1860 s/iter. ETA=0:01:33\n",
      "\u001b[32m[12/29 22:01:24 d2.evaluation.evaluator]: \u001b[0mInference done 91/570. Dataloading: 0.0009 s/iter. Inference: 0.0586 s/iter. Eval: 0.1320 s/iter. Total: 0.1915 s/iter. ETA=0:01:31\n",
      "\u001b[32m[12/29 22:01:29 d2.evaluation.evaluator]: \u001b[0mInference done 117/570. Dataloading: 0.0009 s/iter. Inference: 0.0578 s/iter. Eval: 0.1331 s/iter. Total: 0.1919 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/29 22:01:34 d2.evaluation.evaluator]: \u001b[0mInference done 142/570. Dataloading: 0.0009 s/iter. Inference: 0.0572 s/iter. Eval: 0.1359 s/iter. Total: 0.1940 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/29 22:01:39 d2.evaluation.evaluator]: \u001b[0mInference done 162/570. Dataloading: 0.0009 s/iter. Inference: 0.0569 s/iter. Eval: 0.1451 s/iter. Total: 0.2030 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/29 22:01:45 d2.evaluation.evaluator]: \u001b[0mInference done 175/570. Dataloading: 0.0009 s/iter. Inference: 0.0573 s/iter. Eval: 0.1603 s/iter. Total: 0.2185 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/29 22:01:50 d2.evaluation.evaluator]: \u001b[0mInference done 192/570. Dataloading: 0.0009 s/iter. Inference: 0.0578 s/iter. Eval: 0.1669 s/iter. Total: 0.2257 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/29 22:01:55 d2.evaluation.evaluator]: \u001b[0mInference done 208/570. Dataloading: 0.0009 s/iter. Inference: 0.0581 s/iter. Eval: 0.1744 s/iter. Total: 0.2334 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/29 22:02:00 d2.evaluation.evaluator]: \u001b[0mInference done 225/570. Dataloading: 0.0009 s/iter. Inference: 0.0583 s/iter. Eval: 0.1795 s/iter. Total: 0.2387 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/29 22:02:05 d2.evaluation.evaluator]: \u001b[0mInference done 236/570. Dataloading: 0.0009 s/iter. Inference: 0.0583 s/iter. Eval: 0.1912 s/iter. Total: 0.2505 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/29 22:02:11 d2.evaluation.evaluator]: \u001b[0mInference done 249/570. Dataloading: 0.0009 s/iter. Inference: 0.0583 s/iter. Eval: 0.2007 s/iter. Total: 0.2599 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/29 22:02:16 d2.evaluation.evaluator]: \u001b[0mInference done 265/570. Dataloading: 0.0009 s/iter. Inference: 0.0584 s/iter. Eval: 0.2049 s/iter. Total: 0.2642 s/iter. ETA=0:01:20\n",
      "\u001b[32m[12/29 22:02:21 d2.evaluation.evaluator]: \u001b[0mInference done 283/570. Dataloading: 0.0009 s/iter. Inference: 0.0584 s/iter. Eval: 0.2064 s/iter. Total: 0.2657 s/iter. ETA=0:01:16\n",
      "\u001b[32m[12/29 22:02:27 d2.evaluation.evaluator]: \u001b[0mInference done 298/570. Dataloading: 0.0009 s/iter. Inference: 0.0582 s/iter. Eval: 0.2117 s/iter. Total: 0.2708 s/iter. ETA=0:01:13\n",
      "\u001b[32m[12/29 22:02:32 d2.evaluation.evaluator]: \u001b[0mInference done 346/570. Dataloading: 0.0009 s/iter. Inference: 0.0567 s/iter. Eval: 0.1897 s/iter. Total: 0.2473 s/iter. ETA=0:00:55\n",
      "\u001b[32m[12/29 22:02:37 d2.evaluation.evaluator]: \u001b[0mInference done 376/570. Dataloading: 0.0009 s/iter. Inference: 0.0563 s/iter. Eval: 0.1842 s/iter. Total: 0.2415 s/iter. ETA=0:00:46\n",
      "\u001b[32m[12/29 22:02:42 d2.evaluation.evaluator]: \u001b[0mInference done 398/570. Dataloading: 0.0009 s/iter. Inference: 0.0566 s/iter. Eval: 0.1835 s/iter. Total: 0.2410 s/iter. ETA=0:00:41\n",
      "\u001b[32m[12/29 22:02:47 d2.evaluation.evaluator]: \u001b[0mInference done 416/570. Dataloading: 0.0009 s/iter. Inference: 0.0567 s/iter. Eval: 0.1854 s/iter. Total: 0.2430 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 22:02:53 d2.evaluation.evaluator]: \u001b[0mInference done 435/570. Dataloading: 0.0009 s/iter. Inference: 0.0569 s/iter. Eval: 0.1862 s/iter. Total: 0.2440 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/29 22:02:58 d2.evaluation.evaluator]: \u001b[0mInference done 465/570. Dataloading: 0.0009 s/iter. Inference: 0.0565 s/iter. Eval: 0.1816 s/iter. Total: 0.2391 s/iter. ETA=0:00:25\n",
      "\u001b[32m[12/29 22:03:03 d2.evaluation.evaluator]: \u001b[0mInference done 496/570. Dataloading: 0.0009 s/iter. Inference: 0.0560 s/iter. Eval: 0.1779 s/iter. Total: 0.2348 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 22:03:08 d2.evaluation.evaluator]: \u001b[0mInference done 518/570. Dataloading: 0.0009 s/iter. Inference: 0.0560 s/iter. Eval: 0.1777 s/iter. Total: 0.2346 s/iter. ETA=0:00:12\n",
      "\u001b[32m[12/29 22:03:13 d2.evaluation.evaluator]: \u001b[0mInference done 541/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1773 s/iter. Total: 0.2340 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/29 22:03:18 d2.evaluation.evaluator]: \u001b[0mInference done 560/570. Dataloading: 0.0009 s/iter. Inference: 0.0558 s/iter. Eval: 0.1786 s/iter. Total: 0.2353 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/29 22:03:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:12.933244 (0.235280 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 22:03:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.055805 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 22:03:21 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/29 22:03:21 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.27663997509539534\n",
      "\u001b[32m[12/29 22:03:23 d2.utils.events]: \u001b[0m eta: 4:58:56  iter: 14459  total_loss: 1.214  loss_cls: 0.2954  loss_box_reg: 0.3878  loss_mask: 0.2573  loss_rpn_cls: 0.08349  loss_rpn_loc: 0.168  time: 0.2241  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:03:27 d2.utils.events]: \u001b[0m eta: 4:58:56  iter: 14479  total_loss: 1.211  loss_cls: 0.3228  loss_box_reg: 0.401  loss_mask: 0.2699  loss_rpn_cls: 0.06591  loss_rpn_loc: 0.1601  time: 0.2242  data_time: 0.0195  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:03:32 d2.utils.events]: \u001b[0m eta: 4:58:39  iter: 14499  total_loss: 1.218  loss_cls: 0.2906  loss_box_reg: 0.4185  loss_mask: 0.2619  loss_rpn_cls: 0.06156  loss_rpn_loc: 0.1573  time: 0.2241  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:03:36 d2.utils.events]: \u001b[0m eta: 4:58:23  iter: 14519  total_loss: 1.234  loss_cls: 0.3213  loss_box_reg: 0.3979  loss_mask: 0.2537  loss_rpn_cls: 0.08808  loss_rpn_loc: 0.1636  time: 0.2241  data_time: 0.0134  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:03:41 d2.utils.events]: \u001b[0m eta: 4:58:32  iter: 14539  total_loss: 1.251  loss_cls: 0.2911  loss_box_reg: 0.4318  loss_mask: 0.2793  loss_rpn_cls: 0.08864  loss_rpn_loc: 0.1814  time: 0.2241  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:03:45 d2.utils.events]: \u001b[0m eta: 4:58:20  iter: 14559  total_loss: 1.181  loss_cls: 0.3057  loss_box_reg: 0.358  loss_mask: 0.2696  loss_rpn_cls: 0.1079  loss_rpn_loc: 0.1922  time: 0.2241  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:03:50 d2.utils.events]: \u001b[0m eta: 4:58:25  iter: 14579  total_loss: 1.186  loss_cls: 0.2932  loss_box_reg: 0.3571  loss_mask: 0.2572  loss_rpn_cls: 0.07841  loss_rpn_loc: 0.1787  time: 0.2241  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:03:54 d2.utils.events]: \u001b[0m eta: 4:58:11  iter: 14599  total_loss: 1.271  loss_cls: 0.3203  loss_box_reg: 0.4174  loss_mask: 0.2568  loss_rpn_cls: 0.09066  loss_rpn_loc: 0.1665  time: 0.2241  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:03:59 d2.utils.events]: \u001b[0m eta: 4:58:14  iter: 14619  total_loss: 1.332  loss_cls: 0.3469  loss_box_reg: 0.404  loss_mask: 0.2817  loss_rpn_cls: 0.07986  loss_rpn_loc: 0.1813  time: 0.2241  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:04:03 d2.utils.events]: \u001b[0m eta: 4:58:14  iter: 14639  total_loss: 1.273  loss_cls: 0.3114  loss_box_reg: 0.3892  loss_mask: 0.2628  loss_rpn_cls: 0.0968  loss_rpn_loc: 0.175  time: 0.2241  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:04:07 d2.utils.events]: \u001b[0m eta: 4:57:58  iter: 14659  total_loss: 1.409  loss_cls: 0.3635  loss_box_reg: 0.4349  loss_mask: 0.2924  loss_rpn_cls: 0.08586  loss_rpn_loc: 0.2012  time: 0.2241  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:04:12 d2.utils.events]: \u001b[0m eta: 4:57:59  iter: 14679  total_loss: 1.191  loss_cls: 0.3156  loss_box_reg: 0.3881  loss_mask: 0.2407  loss_rpn_cls: 0.07498  loss_rpn_loc: 0.1586  time: 0.2241  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:04:16 d2.utils.events]: \u001b[0m eta: 4:57:55  iter: 14699  total_loss: 1.324  loss_cls: 0.3594  loss_box_reg: 0.4268  loss_mask: 0.2898  loss_rpn_cls: 0.09758  loss_rpn_loc: 0.1817  time: 0.2241  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:04:21 d2.utils.events]: \u001b[0m eta: 4:57:37  iter: 14719  total_loss: 1.138  loss_cls: 0.2699  loss_box_reg: 0.3907  loss_mask: 0.259  loss_rpn_cls: 0.07424  loss_rpn_loc: 0.1599  time: 0.2241  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:04:25 d2.utils.events]: \u001b[0m eta: 4:57:48  iter: 14739  total_loss: 1.234  loss_cls: 0.307  loss_box_reg: 0.3682  loss_mask: 0.2757  loss_rpn_cls: 0.1098  loss_rpn_loc: 0.1854  time: 0.2241  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:04:30 d2.utils.events]: \u001b[0m eta: 4:57:46  iter: 14759  total_loss: 1.239  loss_cls: 0.3021  loss_box_reg: 0.4049  loss_mask: 0.2608  loss_rpn_cls: 0.06943  loss_rpn_loc: 0.1666  time: 0.2241  data_time: 0.0109  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:04:34 d2.utils.events]: \u001b[0m eta: 4:57:39  iter: 14779  total_loss: 1.315  loss_cls: 0.3127  loss_box_reg: 0.4361  loss_mask: 0.2762  loss_rpn_cls: 0.08685  loss_rpn_loc: 0.1774  time: 0.2240  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:04:38 d2.utils.events]: \u001b[0m eta: 4:57:35  iter: 14799  total_loss: 1.297  loss_cls: 0.3645  loss_box_reg: 0.4314  loss_mask: 0.2719  loss_rpn_cls: 0.07006  loss_rpn_loc: 0.1702  time: 0.2240  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:04:43 d2.utils.events]: \u001b[0m eta: 4:57:30  iter: 14819  total_loss: 1.286  loss_cls: 0.3234  loss_box_reg: 0.3836  loss_mask: 0.2763  loss_rpn_cls: 0.09165  loss_rpn_loc: 0.1926  time: 0.2240  data_time: 0.0168  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:04:47 d2.utils.events]: \u001b[0m eta: 4:57:24  iter: 14839  total_loss: 1.269  loss_cls: 0.2849  loss_box_reg: 0.4006  loss_mask: 0.295  loss_rpn_cls: 0.09336  loss_rpn_loc: 0.179  time: 0.2240  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:04:52 d2.utils.events]: \u001b[0m eta: 4:57:13  iter: 14859  total_loss: 1.325  loss_cls: 0.3201  loss_box_reg: 0.4465  loss_mask: 0.2641  loss_rpn_cls: 0.09956  loss_rpn_loc: 0.1856  time: 0.2241  data_time: 0.0199  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:04:57 d2.utils.events]: \u001b[0m eta: 4:57:15  iter: 14879  total_loss: 1.341  loss_cls: 0.3521  loss_box_reg: 0.4177  loss_mask: 0.2851  loss_rpn_cls: 0.1129  loss_rpn_loc: 0.1886  time: 0.2241  data_time: 0.0094  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:05:01 d2.utils.events]: \u001b[0m eta: 4:56:47  iter: 14899  total_loss: 1.217  loss_cls: 0.325  loss_box_reg: 0.4055  loss_mask: 0.252  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.1618  time: 0.2241  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:05:06 d2.utils.events]: \u001b[0m eta: 4:56:49  iter: 14919  total_loss: 1.118  loss_cls: 0.292  loss_box_reg: 0.3859  loss_mask: 0.2326  loss_rpn_cls: 0.06735  loss_rpn_loc: 0.1603  time: 0.2241  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:05:10 d2.utils.events]: \u001b[0m eta: 4:56:45  iter: 14939  total_loss: 1.255  loss_cls: 0.3102  loss_box_reg: 0.4142  loss_mask: 0.2679  loss_rpn_cls: 0.08147  loss_rpn_loc: 0.1738  time: 0.2241  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:05:15 d2.utils.events]: \u001b[0m eta: 4:57:00  iter: 14959  total_loss: 1.178  loss_cls: 0.2964  loss_box_reg: 0.3756  loss_mask: 0.2742  loss_rpn_cls: 0.08999  loss_rpn_loc: 0.1818  time: 0.2241  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:05:19 d2.utils.events]: \u001b[0m eta: 4:56:59  iter: 14979  total_loss: 1.255  loss_cls: 0.2884  loss_box_reg: 0.3998  loss_mask: 0.2727  loss_rpn_cls: 0.08167  loss_rpn_loc: 0.1774  time: 0.2241  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:05:24 d2.utils.events]: \u001b[0m eta: 4:56:50  iter: 14999  total_loss: 1.083  loss_cls: 0.26  loss_box_reg: 0.36  loss_mask: 0.2564  loss_rpn_cls: 0.0859  loss_rpn_loc: 0.1608  time: 0.2241  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:05:28 d2.utils.events]: \u001b[0m eta: 4:56:48  iter: 15019  total_loss: 1.225  loss_cls: 0.3207  loss_box_reg: 0.3756  loss_mask: 0.2773  loss_rpn_cls: 0.09083  loss_rpn_loc: 0.1762  time: 0.2241  data_time: 0.0090  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:05:33 d2.utils.events]: \u001b[0m eta: 4:56:44  iter: 15039  total_loss: 1.165  loss_cls: 0.3038  loss_box_reg: 0.3887  loss_mask: 0.2562  loss_rpn_cls: 0.07617  loss_rpn_loc: 0.1569  time: 0.2241  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:05:37 d2.utils.events]: \u001b[0m eta: 4:56:46  iter: 15059  total_loss: 1.178  loss_cls: 0.2777  loss_box_reg: 0.391  loss_mask: 0.2756  loss_rpn_cls: 0.07651  loss_rpn_loc: 0.1728  time: 0.2241  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:05:42 d2.utils.events]: \u001b[0m eta: 4:56:44  iter: 15079  total_loss: 1.192  loss_cls: 0.2873  loss_box_reg: 0.3904  loss_mask: 0.2633  loss_rpn_cls: 0.07766  loss_rpn_loc: 0.1821  time: 0.2241  data_time: 0.0149  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:05:46 d2.utils.events]: \u001b[0m eta: 4:56:37  iter: 15099  total_loss: 1.358  loss_cls: 0.3452  loss_box_reg: 0.423  loss_mask: 0.2721  loss_rpn_cls: 0.09236  loss_rpn_loc: 0.2007  time: 0.2241  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:05:51 d2.utils.events]: \u001b[0m eta: 4:56:33  iter: 15119  total_loss: 1.317  loss_cls: 0.3381  loss_box_reg: 0.3993  loss_mask: 0.2739  loss_rpn_cls: 0.07884  loss_rpn_loc: 0.1758  time: 0.2242  data_time: 0.0158  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:05:56 d2.utils.events]: \u001b[0m eta: 4:56:24  iter: 15139  total_loss: 1.208  loss_cls: 0.3029  loss_box_reg: 0.3778  loss_mask: 0.2519  loss_rpn_cls: 0.07028  loss_rpn_loc: 0.1565  time: 0.2241  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:06:00 d2.utils.events]: \u001b[0m eta: 4:56:24  iter: 15159  total_loss: 1.215  loss_cls: 0.3038  loss_box_reg: 0.3915  loss_mask: 0.2691  loss_rpn_cls: 0.08609  loss_rpn_loc: 0.1916  time: 0.2241  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:06:05 d2.utils.events]: \u001b[0m eta: 4:56:24  iter: 15179  total_loss: 1.189  loss_cls: 0.3021  loss_box_reg: 0.367  loss_mask: 0.2697  loss_rpn_cls: 0.08546  loss_rpn_loc: 0.1784  time: 0.2242  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:06:09 d2.utils.events]: \u001b[0m eta: 4:56:09  iter: 15199  total_loss: 1.228  loss_cls: 0.2945  loss_box_reg: 0.4109  loss_mask: 0.2373  loss_rpn_cls: 0.07184  loss_rpn_loc: 0.1667  time: 0.2242  data_time: 0.0119  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:06:14 d2.utils.events]: \u001b[0m eta: 4:56:03  iter: 15219  total_loss: 1.183  loss_cls: 0.293  loss_box_reg: 0.4103  loss_mask: 0.2593  loss_rpn_cls: 0.07613  loss_rpn_loc: 0.1585  time: 0.2242  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:06:18 d2.utils.events]: \u001b[0m eta: 4:55:57  iter: 15239  total_loss: 1.233  loss_cls: 0.3085  loss_box_reg: 0.3969  loss_mask: 0.266  loss_rpn_cls: 0.08113  loss_rpn_loc: 0.1593  time: 0.2241  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:06:22 d2.utils.events]: \u001b[0m eta: 4:56:02  iter: 15259  total_loss: 1.193  loss_cls: 0.3073  loss_box_reg: 0.4055  loss_mask: 0.2656  loss_rpn_cls: 0.07893  loss_rpn_loc: 0.1691  time: 0.2241  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:06:27 d2.utils.events]: \u001b[0m eta: 4:55:51  iter: 15279  total_loss: 1.329  loss_cls: 0.3481  loss_box_reg: 0.429  loss_mask: 0.2791  loss_rpn_cls: 0.07563  loss_rpn_loc: 0.1964  time: 0.2241  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:06:32 d2.utils.events]: \u001b[0m eta: 4:55:56  iter: 15299  total_loss: 1.299  loss_cls: 0.3228  loss_box_reg: 0.4288  loss_mask: 0.2513  loss_rpn_cls: 0.098  loss_rpn_loc: 0.1992  time: 0.2242  data_time: 0.0090  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:06:36 d2.utils.events]: \u001b[0m eta: 4:55:39  iter: 15319  total_loss: 1.259  loss_cls: 0.3118  loss_box_reg: 0.4183  loss_mask: 0.2696  loss_rpn_cls: 0.0757  loss_rpn_loc: 0.1641  time: 0.2241  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:06:40 d2.utils.events]: \u001b[0m eta: 4:55:07  iter: 15339  total_loss: 1.318  loss_cls: 0.3379  loss_box_reg: 0.4269  loss_mask: 0.281  loss_rpn_cls: 0.08032  loss_rpn_loc: 0.1769  time: 0.2241  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:06:45 d2.utils.events]: \u001b[0m eta: 4:55:02  iter: 15359  total_loss: 1.411  loss_cls: 0.3719  loss_box_reg: 0.4405  loss_mask: 0.2894  loss_rpn_cls: 0.09968  loss_rpn_loc: 0.1734  time: 0.2241  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:06:49 d2.utils.events]: \u001b[0m eta: 4:54:58  iter: 15379  total_loss: 1.274  loss_cls: 0.3748  loss_box_reg: 0.4308  loss_mask: 0.2651  loss_rpn_cls: 0.07891  loss_rpn_loc: 0.1666  time: 0.2241  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:06:54 d2.utils.events]: \u001b[0m eta: 4:54:15  iter: 15399  total_loss: 1.302  loss_cls: 0.3509  loss_box_reg: 0.4045  loss_mask: 0.2782  loss_rpn_cls: 0.09624  loss_rpn_loc: 0.1703  time: 0.2242  data_time: 0.0344  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:06:59 d2.utils.events]: \u001b[0m eta: 4:53:51  iter: 15419  total_loss: 1.274  loss_cls: 0.3571  loss_box_reg: 0.419  loss_mask: 0.2659  loss_rpn_cls: 0.09571  loss_rpn_loc: 0.1761  time: 0.2242  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:07:03 d2.utils.events]: \u001b[0m eta: 4:54:06  iter: 15439  total_loss: 1.342  loss_cls: 0.3775  loss_box_reg: 0.4104  loss_mask: 0.2779  loss_rpn_cls: 0.102  loss_rpn_loc: 0.1723  time: 0.2242  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:07:08 d2.utils.events]: \u001b[0m eta: 4:54:29  iter: 15459  total_loss: 1.221  loss_cls: 0.3039  loss_box_reg: 0.3733  loss_mask: 0.2681  loss_rpn_cls: 0.06662  loss_rpn_loc: 0.1649  time: 0.2242  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:07:12 d2.utils.events]: \u001b[0m eta: 4:54:33  iter: 15479  total_loss: 1.331  loss_cls: 0.3707  loss_box_reg: 0.4514  loss_mask: 0.2868  loss_rpn_cls: 0.08321  loss_rpn_loc: 0.1712  time: 0.2242  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:07:17 d2.utils.events]: \u001b[0m eta: 4:54:32  iter: 15499  total_loss: 1.154  loss_cls: 0.2775  loss_box_reg: 0.3558  loss_mask: 0.2667  loss_rpn_cls: 0.05785  loss_rpn_loc: 0.1661  time: 0.2242  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:07:21 d2.utils.events]: \u001b[0m eta: 4:54:43  iter: 15519  total_loss: 1.291  loss_cls: 0.3653  loss_box_reg: 0.4088  loss_mask: 0.2661  loss_rpn_cls: 0.07461  loss_rpn_loc: 0.1669  time: 0.2242  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:07:26 d2.utils.events]: \u001b[0m eta: 4:54:23  iter: 15539  total_loss: 1.35  loss_cls: 0.3571  loss_box_reg: 0.4502  loss_mask: 0.2788  loss_rpn_cls: 0.0815  loss_rpn_loc: 0.1722  time: 0.2242  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:07:30 d2.utils.events]: \u001b[0m eta: 4:54:07  iter: 15559  total_loss: 1.134  loss_cls: 0.2622  loss_box_reg: 0.3689  loss_mask: 0.2475  loss_rpn_cls: 0.07154  loss_rpn_loc: 0.1596  time: 0.2241  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:07:34 d2.utils.events]: \u001b[0m eta: 4:53:36  iter: 15579  total_loss: 1.17  loss_cls: 0.303  loss_box_reg: 0.3886  loss_mask: 0.2674  loss_rpn_cls: 0.07498  loss_rpn_loc: 0.1675  time: 0.2241  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:07:39 d2.utils.events]: \u001b[0m eta: 4:53:42  iter: 15599  total_loss: 1.287  loss_cls: 0.314  loss_box_reg: 0.3978  loss_mask: 0.2643  loss_rpn_cls: 0.08022  loss_rpn_loc: 0.1798  time: 0.2241  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:07:43 d2.utils.events]: \u001b[0m eta: 4:53:24  iter: 15619  total_loss: 1.341  loss_cls: 0.365  loss_box_reg: 0.4157  loss_mask: 0.265  loss_rpn_cls: 0.08545  loss_rpn_loc: 0.1713  time: 0.2241  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:07:48 d2.utils.events]: \u001b[0m eta: 4:53:08  iter: 15639  total_loss: 1.016  loss_cls: 0.2346  loss_box_reg: 0.3287  loss_mask: 0.2219  loss_rpn_cls: 0.04956  loss_rpn_loc: 0.1509  time: 0.2242  data_time: 0.0299  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:07:53 d2.utils.events]: \u001b[0m eta: 4:53:50  iter: 15659  total_loss: 1.213  loss_cls: 0.2765  loss_box_reg: 0.3324  loss_mask: 0.2694  loss_rpn_cls: 0.09975  loss_rpn_loc: 0.173  time: 0.2242  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:07:57 d2.utils.events]: \u001b[0m eta: 4:53:52  iter: 15679  total_loss: 1.204  loss_cls: 0.3156  loss_box_reg: 0.4099  loss_mask: 0.2707  loss_rpn_cls: 0.06563  loss_rpn_loc: 0.1482  time: 0.2242  data_time: 0.0120  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:08:02 d2.utils.events]: \u001b[0m eta: 4:53:45  iter: 15699  total_loss: 1.24  loss_cls: 0.3054  loss_box_reg: 0.4519  loss_mask: 0.2602  loss_rpn_cls: 0.08266  loss_rpn_loc: 0.1652  time: 0.2242  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:08:06 d2.utils.events]: \u001b[0m eta: 4:53:54  iter: 15719  total_loss: 1.181  loss_cls: 0.306  loss_box_reg: 0.373  loss_mask: 0.2647  loss_rpn_cls: 0.09086  loss_rpn_loc: 0.1867  time: 0.2242  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:08:11 d2.utils.events]: \u001b[0m eta: 4:53:43  iter: 15739  total_loss: 1.349  loss_cls: 0.3605  loss_box_reg: 0.396  loss_mask: 0.2628  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.1705  time: 0.2242  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:08:15 d2.utils.events]: \u001b[0m eta: 4:54:02  iter: 15759  total_loss: 1.229  loss_cls: 0.3056  loss_box_reg: 0.4186  loss_mask: 0.248  loss_rpn_cls: 0.07417  loss_rpn_loc: 0.1741  time: 0.2242  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:08:20 d2.utils.events]: \u001b[0m eta: 4:53:47  iter: 15779  total_loss: 1.277  loss_cls: 0.2897  loss_box_reg: 0.4052  loss_mask: 0.2789  loss_rpn_cls: 0.07594  loss_rpn_loc: 0.1797  time: 0.2242  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:08:24 d2.utils.events]: \u001b[0m eta: 4:53:48  iter: 15799  total_loss: 1.321  loss_cls: 0.3155  loss_box_reg: 0.4326  loss_mask: 0.2761  loss_rpn_cls: 0.09879  loss_rpn_loc: 0.1743  time: 0.2242  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:08:29 d2.utils.events]: \u001b[0m eta: 4:54:28  iter: 15819  total_loss: 1.188  loss_cls: 0.2883  loss_box_reg: 0.3384  loss_mask: 0.2582  loss_rpn_cls: 0.09473  loss_rpn_loc: 0.1769  time: 0.2242  data_time: 0.0095  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:08:33 d2.utils.events]: \u001b[0m eta: 4:54:15  iter: 15839  total_loss: 1.257  loss_cls: 0.3204  loss_box_reg: 0.4104  loss_mask: 0.2489  loss_rpn_cls: 0.06604  loss_rpn_loc: 0.156  time: 0.2242  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:08:38 d2.utils.events]: \u001b[0m eta: 4:54:19  iter: 15859  total_loss: 1.266  loss_cls: 0.3221  loss_box_reg: 0.444  loss_mask: 0.278  loss_rpn_cls: 0.08338  loss_rpn_loc: 0.1681  time: 0.2242  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:08:42 d2.utils.events]: \u001b[0m eta: 4:53:54  iter: 15879  total_loss: 1.399  loss_cls: 0.358  loss_box_reg: 0.4009  loss_mask: 0.3023  loss_rpn_cls: 0.08646  loss_rpn_loc: 0.1966  time: 0.2241  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:08:46 d2.utils.events]: \u001b[0m eta: 4:53:55  iter: 15899  total_loss: 1.236  loss_cls: 0.3013  loss_box_reg: 0.405  loss_mask: 0.2676  loss_rpn_cls: 0.08184  loss_rpn_loc: 0.1864  time: 0.2242  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:08:51 d2.utils.events]: \u001b[0m eta: 4:54:06  iter: 15919  total_loss: 1.271  loss_cls: 0.3372  loss_box_reg: 0.3884  loss_mask: 0.2729  loss_rpn_cls: 0.07791  loss_rpn_loc: 0.1685  time: 0.2242  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:08:56 d2.utils.events]: \u001b[0m eta: 4:54:09  iter: 15939  total_loss: 1.293  loss_cls: 0.3238  loss_box_reg: 0.3757  loss_mask: 0.2748  loss_rpn_cls: 0.1215  loss_rpn_loc: 0.201  time: 0.2242  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:09:00 d2.utils.events]: \u001b[0m eta: 4:53:57  iter: 15959  total_loss: 1.27  loss_cls: 0.3175  loss_box_reg: 0.4145  loss_mask: 0.2773  loss_rpn_cls: 0.08478  loss_rpn_loc: 0.1769  time: 0.2242  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:09:04 d2.utils.events]: \u001b[0m eta: 4:53:32  iter: 15979  total_loss: 1.237  loss_cls: 0.3156  loss_box_reg: 0.4141  loss_mask: 0.2574  loss_rpn_cls: 0.06115  loss_rpn_loc: 0.161  time: 0.2242  data_time: 0.0154  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:09:09 d2.utils.events]: \u001b[0m eta: 4:52:56  iter: 15999  total_loss: 1.329  loss_cls: 0.3349  loss_box_reg: 0.4775  loss_mask: 0.2574  loss_rpn_cls: 0.07483  loss_rpn_loc: 0.1846  time: 0.2241  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:09:13 d2.utils.events]: \u001b[0m eta: 4:52:47  iter: 16019  total_loss: 1.212  loss_cls: 0.317  loss_box_reg: 0.3942  loss_mask: 0.269  loss_rpn_cls: 0.09664  loss_rpn_loc: 0.1816  time: 0.2241  data_time: 0.0203  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:09:17 d2.utils.events]: \u001b[0m eta: 4:52:28  iter: 16039  total_loss: 1.214  loss_cls: 0.3025  loss_box_reg: 0.4148  loss_mask: 0.2679  loss_rpn_cls: 0.06758  loss_rpn_loc: 0.1739  time: 0.2241  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:09:22 d2.utils.events]: \u001b[0m eta: 4:52:11  iter: 16059  total_loss: 1.375  loss_cls: 0.3451  loss_box_reg: 0.4325  loss_mask: 0.2807  loss_rpn_cls: 0.09612  loss_rpn_loc: 0.1736  time: 0.2241  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:09:26 d2.utils.events]: \u001b[0m eta: 4:52:04  iter: 16079  total_loss: 1.366  loss_cls: 0.3724  loss_box_reg: 0.4035  loss_mask: 0.2839  loss_rpn_cls: 0.08496  loss_rpn_loc: 0.1745  time: 0.2241  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:09:31 d2.utils.events]: \u001b[0m eta: 4:51:53  iter: 16099  total_loss: 1.303  loss_cls: 0.3543  loss_box_reg: 0.4121  loss_mask: 0.267  loss_rpn_cls: 0.08059  loss_rpn_loc: 0.1778  time: 0.2241  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:09:35 d2.utils.events]: \u001b[0m eta: 4:51:40  iter: 16119  total_loss: 1.272  loss_cls: 0.3688  loss_box_reg: 0.405  loss_mask: 0.2549  loss_rpn_cls: 0.08175  loss_rpn_loc: 0.1636  time: 0.2240  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:09:39 d2.utils.events]: \u001b[0m eta: 4:51:49  iter: 16139  total_loss: 1.332  loss_cls: 0.3665  loss_box_reg: 0.4233  loss_mask: 0.2858  loss_rpn_cls: 0.1108  loss_rpn_loc: 0.1878  time: 0.2240  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:09:44 d2.utils.events]: \u001b[0m eta: 4:51:47  iter: 16159  total_loss: 1.196  loss_cls: 0.2699  loss_box_reg: 0.3617  loss_mask: 0.2641  loss_rpn_cls: 0.08854  loss_rpn_loc: 0.1806  time: 0.2240  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:09:48 d2.utils.events]: \u001b[0m eta: 4:51:50  iter: 16179  total_loss: 1.304  loss_cls: 0.3196  loss_box_reg: 0.4148  loss_mask: 0.2672  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.184  time: 0.2240  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:09:53 d2.utils.events]: \u001b[0m eta: 4:51:52  iter: 16199  total_loss: 1.379  loss_cls: 0.3832  loss_box_reg: 0.4343  loss_mask: 0.2758  loss_rpn_cls: 0.09534  loss_rpn_loc: 0.1705  time: 0.2240  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:09:57 d2.utils.events]: \u001b[0m eta: 4:51:32  iter: 16219  total_loss: 1.297  loss_cls: 0.3004  loss_box_reg: 0.4076  loss_mask: 0.2564  loss_rpn_cls: 0.08059  loss_rpn_loc: 0.183  time: 0.2240  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:10:02 d2.utils.events]: \u001b[0m eta: 4:51:43  iter: 16239  total_loss: 1.22  loss_cls: 0.3112  loss_box_reg: 0.3762  loss_mask: 0.2798  loss_rpn_cls: 0.0965  loss_rpn_loc: 0.1716  time: 0.2240  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:10:06 d2.utils.events]: \u001b[0m eta: 4:51:38  iter: 16259  total_loss: 1.328  loss_cls: 0.3324  loss_box_reg: 0.4056  loss_mask: 0.3011  loss_rpn_cls: 0.09401  loss_rpn_loc: 0.1878  time: 0.2240  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:10:11 d2.utils.events]: \u001b[0m eta: 4:51:33  iter: 16279  total_loss: 1.259  loss_cls: 0.3062  loss_box_reg: 0.3893  loss_mask: 0.2661  loss_rpn_cls: 0.06317  loss_rpn_loc: 0.1581  time: 0.2240  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:10:15 d2.utils.events]: \u001b[0m eta: 4:51:09  iter: 16299  total_loss: 1.302  loss_cls: 0.3402  loss_box_reg: 0.4229  loss_mask: 0.2759  loss_rpn_cls: 0.07995  loss_rpn_loc: 0.1733  time: 0.2240  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:10:19 d2.utils.events]: \u001b[0m eta: 4:50:55  iter: 16319  total_loss: 1.321  loss_cls: 0.3315  loss_box_reg: 0.4291  loss_mask: 0.2743  loss_rpn_cls: 0.08151  loss_rpn_loc: 0.1792  time: 0.2240  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:10:24 d2.utils.events]: \u001b[0m eta: 4:50:55  iter: 16339  total_loss: 1.247  loss_cls: 0.3025  loss_box_reg: 0.383  loss_mask: 0.2642  loss_rpn_cls: 0.0958  loss_rpn_loc: 0.1832  time: 0.2240  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:10:28 d2.utils.events]: \u001b[0m eta: 4:51:10  iter: 16359  total_loss: 1.291  loss_cls: 0.3155  loss_box_reg: 0.3822  loss_mask: 0.2764  loss_rpn_cls: 0.08797  loss_rpn_loc: 0.1975  time: 0.2240  data_time: 0.0160  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:10:33 d2.utils.events]: \u001b[0m eta: 4:51:00  iter: 16379  total_loss: 1.335  loss_cls: 0.3346  loss_box_reg: 0.4029  loss_mask: 0.2754  loss_rpn_cls: 0.08513  loss_rpn_loc: 0.2019  time: 0.2240  data_time: 0.0128  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:10:37 d2.utils.events]: \u001b[0m eta: 4:50:56  iter: 16399  total_loss: 1.308  loss_cls: 0.3448  loss_box_reg: 0.4338  loss_mask: 0.2652  loss_rpn_cls: 0.07597  loss_rpn_loc: 0.1814  time: 0.2240  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:10:42 d2.utils.events]: \u001b[0m eta: 4:51:02  iter: 16419  total_loss: 1.222  loss_cls: 0.3131  loss_box_reg: 0.3526  loss_mask: 0.2591  loss_rpn_cls: 0.09858  loss_rpn_loc: 0.1972  time: 0.2240  data_time: 0.0099  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:10:47 d2.utils.events]: \u001b[0m eta: 4:50:42  iter: 16439  total_loss: 1.336  loss_cls: 0.3305  loss_box_reg: 0.4051  loss_mask: 0.2859  loss_rpn_cls: 0.09752  loss_rpn_loc: 0.1838  time: 0.2240  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:10:51 d2.utils.events]: \u001b[0m eta: 4:50:25  iter: 16459  total_loss: 1.397  loss_cls: 0.3382  loss_box_reg: 0.4427  loss_mask: 0.2862  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.1867  time: 0.2240  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:10:55 d2.utils.events]: \u001b[0m eta: 4:50:11  iter: 16479  total_loss: 1.15  loss_cls: 0.2607  loss_box_reg: 0.3957  loss_mask: 0.2615  loss_rpn_cls: 0.07033  loss_rpn_loc: 0.1616  time: 0.2240  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:11:00 d2.utils.events]: \u001b[0m eta: 4:50:15  iter: 16499  total_loss: 1.286  loss_cls: 0.3027  loss_box_reg: 0.3513  loss_mask: 0.2746  loss_rpn_cls: 0.08986  loss_rpn_loc: 0.1717  time: 0.2240  data_time: 0.0089  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:11:05 d2.utils.events]: \u001b[0m eta: 4:50:08  iter: 16519  total_loss: 1.212  loss_cls: 0.2744  loss_box_reg: 0.3805  loss_mask: 0.2749  loss_rpn_cls: 0.08898  loss_rpn_loc: 0.1771  time: 0.2240  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:11:09 d2.utils.events]: \u001b[0m eta: 4:50:09  iter: 16539  total_loss: 1.261  loss_cls: 0.2786  loss_box_reg: 0.3816  loss_mask: 0.2737  loss_rpn_cls: 0.09102  loss_rpn_loc: 0.1783  time: 0.2241  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:11:14 d2.utils.events]: \u001b[0m eta: 4:50:16  iter: 16559  total_loss: 1.231  loss_cls: 0.289  loss_box_reg: 0.3855  loss_mask: 0.2809  loss_rpn_cls: 0.07937  loss_rpn_loc: 0.1997  time: 0.2241  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:11:18 d2.utils.events]: \u001b[0m eta: 4:50:00  iter: 16579  total_loss: 1.338  loss_cls: 0.3532  loss_box_reg: 0.4545  loss_mask: 0.2688  loss_rpn_cls: 0.07289  loss_rpn_loc: 0.1841  time: 0.2240  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:11:23 d2.utils.events]: \u001b[0m eta: 4:50:09  iter: 16599  total_loss: 1.262  loss_cls: 0.338  loss_box_reg: 0.4032  loss_mask: 0.2895  loss_rpn_cls: 0.07713  loss_rpn_loc: 0.1783  time: 0.2240  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:11:27 d2.utils.events]: \u001b[0m eta: 4:50:06  iter: 16619  total_loss: 1.082  loss_cls: 0.2958  loss_box_reg: 0.3484  loss_mask: 0.239  loss_rpn_cls: 0.0589  loss_rpn_loc: 0.1543  time: 0.2240  data_time: 0.0139  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:11:32 d2.utils.events]: \u001b[0m eta: 4:49:54  iter: 16639  total_loss: 1.124  loss_cls: 0.2813  loss_box_reg: 0.3929  loss_mask: 0.2475  loss_rpn_cls: 0.06155  loss_rpn_loc: 0.1511  time: 0.2240  data_time: 0.0090  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:11:36 d2.utils.events]: \u001b[0m eta: 4:49:37  iter: 16659  total_loss: 1.202  loss_cls: 0.2908  loss_box_reg: 0.3736  loss_mask: 0.2585  loss_rpn_cls: 0.08401  loss_rpn_loc: 0.1623  time: 0.2241  data_time: 0.0155  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:11:41 d2.utils.events]: \u001b[0m eta: 4:49:28  iter: 16679  total_loss: 1.327  loss_cls: 0.3467  loss_box_reg: 0.4147  loss_mask: 0.2775  loss_rpn_cls: 0.09337  loss_rpn_loc: 0.1724  time: 0.2241  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:11:45 d2.utils.events]: \u001b[0m eta: 4:49:28  iter: 16699  total_loss: 1.146  loss_cls: 0.246  loss_box_reg: 0.3695  loss_mask: 0.2618  loss_rpn_cls: 0.07881  loss_rpn_loc: 0.1764  time: 0.2241  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:11:50 d2.utils.events]: \u001b[0m eta: 4:49:24  iter: 16719  total_loss: 1.218  loss_cls: 0.2905  loss_box_reg: 0.3962  loss_mask: 0.2551  loss_rpn_cls: 0.08132  loss_rpn_loc: 0.1662  time: 0.2240  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:11:54 d2.utils.events]: \u001b[0m eta: 4:48:53  iter: 16739  total_loss: 1.236  loss_cls: 0.334  loss_box_reg: 0.3829  loss_mask: 0.257  loss_rpn_cls: 0.08704  loss_rpn_loc: 0.1698  time: 0.2240  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:11:59 d2.utils.events]: \u001b[0m eta: 4:48:59  iter: 16759  total_loss: 1.276  loss_cls: 0.3233  loss_box_reg: 0.3854  loss_mask: 0.2689  loss_rpn_cls: 0.1093  loss_rpn_loc: 0.1876  time: 0.2240  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:12:03 d2.utils.events]: \u001b[0m eta: 4:48:59  iter: 16779  total_loss: 1.138  loss_cls: 0.2803  loss_box_reg: 0.3547  loss_mask: 0.2635  loss_rpn_cls: 0.06795  loss_rpn_loc: 0.1671  time: 0.2240  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:12:08 d2.utils.events]: \u001b[0m eta: 4:49:02  iter: 16799  total_loss: 1.208  loss_cls: 0.3392  loss_box_reg: 0.3827  loss_mask: 0.276  loss_rpn_cls: 0.07503  loss_rpn_loc: 0.1796  time: 0.2240  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:12:12 d2.utils.events]: \u001b[0m eta: 4:48:31  iter: 16819  total_loss: 1.286  loss_cls: 0.342  loss_box_reg: 0.3878  loss_mask: 0.2625  loss_rpn_cls: 0.1059  loss_rpn_loc: 0.195  time: 0.2240  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:12:16 d2.utils.events]: \u001b[0m eta: 4:48:24  iter: 16839  total_loss: 1.205  loss_cls: 0.2978  loss_box_reg: 0.4044  loss_mask: 0.2625  loss_rpn_cls: 0.05856  loss_rpn_loc: 0.166  time: 0.2240  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:12:21 d2.utils.events]: \u001b[0m eta: 4:48:01  iter: 16859  total_loss: 1.39  loss_cls: 0.4064  loss_box_reg: 0.4545  loss_mask: 0.2708  loss_rpn_cls: 0.09551  loss_rpn_loc: 0.1751  time: 0.2240  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:12:25 d2.utils.events]: \u001b[0m eta: 4:47:50  iter: 16879  total_loss: 1.291  loss_cls: 0.3339  loss_box_reg: 0.4111  loss_mask: 0.2836  loss_rpn_cls: 0.08775  loss_rpn_loc: 0.1856  time: 0.2240  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:12:30 d2.utils.events]: \u001b[0m eta: 4:47:46  iter: 16899  total_loss: 1.39  loss_cls: 0.3386  loss_box_reg: 0.4481  loss_mask: 0.2859  loss_rpn_cls: 0.08459  loss_rpn_loc: 0.195  time: 0.2240  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:12:34 d2.utils.events]: \u001b[0m eta: 4:47:28  iter: 16919  total_loss: 1.31  loss_cls: 0.3527  loss_box_reg: 0.4476  loss_mask: 0.2862  loss_rpn_cls: 0.08503  loss_rpn_loc: 0.2006  time: 0.2240  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:12:39 d2.utils.events]: \u001b[0m eta: 4:47:14  iter: 16939  total_loss: 1.231  loss_cls: 0.3149  loss_box_reg: 0.4037  loss_mask: 0.2888  loss_rpn_cls: 0.06256  loss_rpn_loc: 0.1689  time: 0.2240  data_time: 0.0221  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:12:44 d2.utils.events]: \u001b[0m eta: 4:47:16  iter: 16959  total_loss: 1.379  loss_cls: 0.3498  loss_box_reg: 0.432  loss_mask: 0.2742  loss_rpn_cls: 0.09638  loss_rpn_loc: 0.1804  time: 0.2240  data_time: 0.0211  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:12:48 d2.utils.events]: \u001b[0m eta: 4:47:21  iter: 16979  total_loss: 1.317  loss_cls: 0.3651  loss_box_reg: 0.4105  loss_mask: 0.2694  loss_rpn_cls: 0.08039  loss_rpn_loc: 0.1754  time: 0.2240  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:12:52 d2.utils.events]: \u001b[0m eta: 4:47:10  iter: 16999  total_loss: 1.254  loss_cls: 0.346  loss_box_reg: 0.4462  loss_mask: 0.2698  loss_rpn_cls: 0.07173  loss_rpn_loc: 0.1654  time: 0.2240  data_time: 0.0058  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:12:57 d2.utils.events]: \u001b[0m eta: 4:47:03  iter: 17019  total_loss: 1.184  loss_cls: 0.3015  loss_box_reg: 0.3776  loss_mask: 0.2587  loss_rpn_cls: 0.07578  loss_rpn_loc: 0.1709  time: 0.2240  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:13:01 d2.utils.events]: \u001b[0m eta: 4:47:13  iter: 17039  total_loss: 1.309  loss_cls: 0.3383  loss_box_reg: 0.4406  loss_mask: 0.2804  loss_rpn_cls: 0.06978  loss_rpn_loc: 0.1694  time: 0.2240  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:13:06 d2.utils.events]: \u001b[0m eta: 4:47:13  iter: 17059  total_loss: 1.404  loss_cls: 0.3601  loss_box_reg: 0.4086  loss_mask: 0.2818  loss_rpn_cls: 0.1101  loss_rpn_loc: 0.2001  time: 0.2240  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:13:10 d2.utils.events]: \u001b[0m eta: 4:47:13  iter: 17079  total_loss: 1.341  loss_cls: 0.3428  loss_box_reg: 0.4104  loss_mask: 0.2644  loss_rpn_cls: 0.08746  loss_rpn_loc: 0.1781  time: 0.2240  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:13:15 d2.utils.events]: \u001b[0m eta: 4:47:27  iter: 17099  total_loss: 1.218  loss_cls: 0.325  loss_box_reg: 0.4266  loss_mask: 0.2696  loss_rpn_cls: 0.07728  loss_rpn_loc: 0.1581  time: 0.2240  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:13:19 d2.utils.events]: \u001b[0m eta: 4:47:09  iter: 17119  total_loss: 1.282  loss_cls: 0.3557  loss_box_reg: 0.4094  loss_mask: 0.2506  loss_rpn_cls: 0.07237  loss_rpn_loc: 0.1625  time: 0.2239  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:13:23 d2.utils.events]: \u001b[0m eta: 4:47:04  iter: 17139  total_loss: 1.179  loss_cls: 0.3168  loss_box_reg: 0.3786  loss_mask: 0.2701  loss_rpn_cls: 0.07178  loss_rpn_loc: 0.1633  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:13:28 d2.utils.events]: \u001b[0m eta: 4:46:56  iter: 17159  total_loss: 1.39  loss_cls: 0.3565  loss_box_reg: 0.4188  loss_mask: 0.2734  loss_rpn_cls: 0.1079  loss_rpn_loc: 0.1875  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:13:32 d2.utils.events]: \u001b[0m eta: 4:46:45  iter: 17179  total_loss: 1.233  loss_cls: 0.3052  loss_box_reg: 0.3911  loss_mask: 0.2758  loss_rpn_cls: 0.08099  loss_rpn_loc: 0.1862  time: 0.2240  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:13:37 d2.utils.events]: \u001b[0m eta: 4:46:44  iter: 17199  total_loss: 1.245  loss_cls: 0.2957  loss_box_reg: 0.3724  loss_mask: 0.2666  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.1735  time: 0.2240  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:13:42 d2.utils.events]: \u001b[0m eta: 4:47:08  iter: 17219  total_loss: 1.234  loss_cls: 0.2895  loss_box_reg: 0.3954  loss_mask: 0.2636  loss_rpn_cls: 0.1055  loss_rpn_loc: 0.1824  time: 0.2240  data_time: 0.0180  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:13:46 d2.utils.events]: \u001b[0m eta: 4:46:59  iter: 17239  total_loss: 1.215  loss_cls: 0.3246  loss_box_reg: 0.3865  loss_mask: 0.2806  loss_rpn_cls: 0.07801  loss_rpn_loc: 0.1665  time: 0.2240  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:13:51 d2.utils.events]: \u001b[0m eta: 4:46:55  iter: 17259  total_loss: 1.293  loss_cls: 0.3225  loss_box_reg: 0.4032  loss_mask: 0.2813  loss_rpn_cls: 0.08723  loss_rpn_loc: 0.1664  time: 0.2240  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:13:55 d2.utils.events]: \u001b[0m eta: 4:46:50  iter: 17279  total_loss: 1.269  loss_cls: 0.3062  loss_box_reg: 0.4083  loss_mask: 0.2727  loss_rpn_cls: 0.1122  loss_rpn_loc: 0.1771  time: 0.2240  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:14:00 d2.utils.events]: \u001b[0m eta: 4:47:10  iter: 17299  total_loss: 1.244  loss_cls: 0.343  loss_box_reg: 0.3954  loss_mask: 0.2678  loss_rpn_cls: 0.09832  loss_rpn_loc: 0.1917  time: 0.2240  data_time: 0.0173  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:14:04 d2.utils.events]: \u001b[0m eta: 4:47:07  iter: 17319  total_loss: 1.096  loss_cls: 0.2803  loss_box_reg: 0.3582  loss_mask: 0.2449  loss_rpn_cls: 0.07333  loss_rpn_loc: 0.1609  time: 0.2240  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:14:09 d2.utils.events]: \u001b[0m eta: 4:47:06  iter: 17339  total_loss: 1.199  loss_cls: 0.293  loss_box_reg: 0.3816  loss_mask: 0.2735  loss_rpn_cls: 0.08972  loss_rpn_loc: 0.1739  time: 0.2240  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:14:13 d2.utils.events]: \u001b[0m eta: 4:46:54  iter: 17359  total_loss: 1.311  loss_cls: 0.3153  loss_box_reg: 0.4287  loss_mask: 0.2854  loss_rpn_cls: 0.09937  loss_rpn_loc: 0.1782  time: 0.2240  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:14:18 d2.utils.events]: \u001b[0m eta: 4:46:30  iter: 17379  total_loss: 1.269  loss_cls: 0.3146  loss_box_reg: 0.4432  loss_mask: 0.264  loss_rpn_cls: 0.07906  loss_rpn_loc: 0.1644  time: 0.2240  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:14:22 d2.utils.events]: \u001b[0m eta: 4:46:10  iter: 17399  total_loss: 1.219  loss_cls: 0.283  loss_box_reg: 0.4117  loss_mask: 0.2498  loss_rpn_cls: 0.07606  loss_rpn_loc: 0.1613  time: 0.2240  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:14:26 d2.utils.events]: \u001b[0m eta: 4:46:04  iter: 17419  total_loss: 1.09  loss_cls: 0.2599  loss_box_reg: 0.3899  loss_mask: 0.2564  loss_rpn_cls: 0.06847  loss_rpn_loc: 0.1604  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:14:31 d2.utils.events]: \u001b[0m eta: 4:46:20  iter: 17439  total_loss: 1.231  loss_cls: 0.3165  loss_box_reg: 0.3765  loss_mask: 0.2751  loss_rpn_cls: 0.1082  loss_rpn_loc: 0.1885  time: 0.2240  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:14:35 d2.utils.events]: \u001b[0m eta: 4:46:13  iter: 17459  total_loss: 1.295  loss_cls: 0.3329  loss_box_reg: 0.4337  loss_mask: 0.2764  loss_rpn_cls: 0.07511  loss_rpn_loc: 0.1758  time: 0.2240  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:14:40 d2.utils.events]: \u001b[0m eta: 4:46:31  iter: 17479  total_loss: 1.282  loss_cls: 0.311  loss_box_reg: 0.3589  loss_mask: 0.2622  loss_rpn_cls: 0.1239  loss_rpn_loc: 0.1941  time: 0.2240  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:14:45 d2.utils.events]: \u001b[0m eta: 4:46:07  iter: 17499  total_loss: 1.208  loss_cls: 0.2864  loss_box_reg: 0.3472  loss_mask: 0.2711  loss_rpn_cls: 0.07009  loss_rpn_loc: 0.1807  time: 0.2240  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:14:49 d2.utils.events]: \u001b[0m eta: 4:46:19  iter: 17519  total_loss: 1.181  loss_cls: 0.2542  loss_box_reg: 0.3693  loss_mask: 0.2602  loss_rpn_cls: 0.06567  loss_rpn_loc: 0.1724  time: 0.2240  data_time: 0.0173  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:14:54 d2.utils.events]: \u001b[0m eta: 4:46:15  iter: 17539  total_loss: 1.109  loss_cls: 0.2441  loss_box_reg: 0.3707  loss_mask: 0.2582  loss_rpn_cls: 0.05488  loss_rpn_loc: 0.1689  time: 0.2240  data_time: 0.0157  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:14:59 d2.utils.events]: \u001b[0m eta: 4:46:15  iter: 17559  total_loss: 1.194  loss_cls: 0.2952  loss_box_reg: 0.3806  loss_mask: 0.2735  loss_rpn_cls: 0.08719  loss_rpn_loc: 0.1534  time: 0.2240  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:15:03 d2.utils.events]: \u001b[0m eta: 4:46:09  iter: 17579  total_loss: 1.322  loss_cls: 0.3187  loss_box_reg: 0.405  loss_mask: 0.2709  loss_rpn_cls: 0.07315  loss_rpn_loc: 0.2009  time: 0.2240  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:15:08 d2.utils.events]: \u001b[0m eta: 4:46:04  iter: 17599  total_loss: 1.256  loss_cls: 0.2996  loss_box_reg: 0.3949  loss_mask: 0.2754  loss_rpn_cls: 0.07883  loss_rpn_loc: 0.176  time: 0.2240  data_time: 0.0128  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:15:13 d2.utils.events]: \u001b[0m eta: 4:46:01  iter: 17619  total_loss: 1.153  loss_cls: 0.2896  loss_box_reg: 0.3535  loss_mask: 0.2578  loss_rpn_cls: 0.08913  loss_rpn_loc: 0.1637  time: 0.2241  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:15:17 d2.utils.events]: \u001b[0m eta: 4:46:01  iter: 17639  total_loss: 1.195  loss_cls: 0.2997  loss_box_reg: 0.4  loss_mask: 0.2639  loss_rpn_cls: 0.06796  loss_rpn_loc: 0.1641  time: 0.2241  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:15:21 d2.utils.events]: \u001b[0m eta: 4:46:00  iter: 17659  total_loss: 1.188  loss_cls: 0.296  loss_box_reg: 0.4105  loss_mask: 0.2765  loss_rpn_cls: 0.06934  loss_rpn_loc: 0.1669  time: 0.2241  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:15:26 d2.utils.events]: \u001b[0m eta: 4:46:22  iter: 17679  total_loss: 1.256  loss_cls: 0.336  loss_box_reg: 0.3852  loss_mask: 0.2495  loss_rpn_cls: 0.09651  loss_rpn_loc: 0.167  time: 0.2241  data_time: 0.0255  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:15:31 d2.utils.events]: \u001b[0m eta: 4:46:19  iter: 17699  total_loss: 1.155  loss_cls: 0.2565  loss_box_reg: 0.4064  loss_mask: 0.2628  loss_rpn_cls: 0.0805  loss_rpn_loc: 0.1614  time: 0.2241  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:15:36 d2.utils.events]: \u001b[0m eta: 4:46:22  iter: 17719  total_loss: 1.334  loss_cls: 0.3519  loss_box_reg: 0.4122  loss_mask: 0.2739  loss_rpn_cls: 0.07207  loss_rpn_loc: 0.1735  time: 0.2241  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:15:40 d2.utils.events]: \u001b[0m eta: 4:47:06  iter: 17739  total_loss: 1.145  loss_cls: 0.2686  loss_box_reg: 0.34  loss_mask: 0.2753  loss_rpn_cls: 0.08717  loss_rpn_loc: 0.1708  time: 0.2241  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:15:45 d2.utils.events]: \u001b[0m eta: 4:46:45  iter: 17759  total_loss: 1.331  loss_cls: 0.341  loss_box_reg: 0.411  loss_mask: 0.2732  loss_rpn_cls: 0.09528  loss_rpn_loc: 0.1652  time: 0.2241  data_time: 0.0146  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:15:49 d2.utils.events]: \u001b[0m eta: 4:46:30  iter: 17779  total_loss: 1.26  loss_cls: 0.3299  loss_box_reg: 0.4079  loss_mask: 0.2716  loss_rpn_cls: 0.06146  loss_rpn_loc: 0.1631  time: 0.2241  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:15:54 d2.utils.events]: \u001b[0m eta: 4:46:12  iter: 17799  total_loss: 1.196  loss_cls: 0.311  loss_box_reg: 0.3866  loss_mask: 0.2519  loss_rpn_cls: 0.07977  loss_rpn_loc: 0.1642  time: 0.2242  data_time: 0.0223  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:15:59 d2.utils.events]: \u001b[0m eta: 4:46:57  iter: 17819  total_loss: 1.268  loss_cls: 0.2995  loss_box_reg: 0.3914  loss_mask: 0.2709  loss_rpn_cls: 0.113  loss_rpn_loc: 0.1736  time: 0.2242  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:16:03 d2.utils.events]: \u001b[0m eta: 4:47:16  iter: 17839  total_loss: 1.249  loss_cls: 0.3295  loss_box_reg: 0.4156  loss_mask: 0.2565  loss_rpn_cls: 0.07056  loss_rpn_loc: 0.1565  time: 0.2242  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:16:08 d2.utils.events]: \u001b[0m eta: 4:47:17  iter: 17859  total_loss: 1.302  loss_cls: 0.3081  loss_box_reg: 0.3711  loss_mask: 0.2673  loss_rpn_cls: 0.1087  loss_rpn_loc: 0.1776  time: 0.2242  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:16:12 d2.utils.events]: \u001b[0m eta: 4:47:23  iter: 17879  total_loss: 1.329  loss_cls: 0.3815  loss_box_reg: 0.4301  loss_mask: 0.2766  loss_rpn_cls: 0.08596  loss_rpn_loc: 0.1863  time: 0.2242  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:16:17 d2.utils.events]: \u001b[0m eta: 4:47:08  iter: 17899  total_loss: 1.299  loss_cls: 0.3253  loss_box_reg: 0.4123  loss_mask: 0.2818  loss_rpn_cls: 0.09866  loss_rpn_loc: 0.1692  time: 0.2242  data_time: 0.0143  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:16:21 d2.utils.events]: \u001b[0m eta: 4:46:38  iter: 17919  total_loss: 1.285  loss_cls: 0.3371  loss_box_reg: 0.3434  loss_mask: 0.268  loss_rpn_cls: 0.09629  loss_rpn_loc: 0.1671  time: 0.2242  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:16:26 d2.utils.events]: \u001b[0m eta: 4:46:26  iter: 17939  total_loss: 1.084  loss_cls: 0.2712  loss_box_reg: 0.3676  loss_mask: 0.2484  loss_rpn_cls: 0.06074  loss_rpn_loc: 0.1629  time: 0.2242  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:16:30 d2.utils.events]: \u001b[0m eta: 4:46:38  iter: 17959  total_loss: 1.175  loss_cls: 0.325  loss_box_reg: 0.358  loss_mask: 0.2572  loss_rpn_cls: 0.06703  loss_rpn_loc: 0.1552  time: 0.2242  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:16:35 d2.utils.events]: \u001b[0m eta: 4:47:05  iter: 17979  total_loss: 1.262  loss_cls: 0.3312  loss_box_reg: 0.4118  loss_mask: 0.2692  loss_rpn_cls: 0.0802  loss_rpn_loc: 0.171  time: 0.2242  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:16:39 d2.utils.events]: \u001b[0m eta: 4:47:49  iter: 17999  total_loss: 1.234  loss_cls: 0.3198  loss_box_reg: 0.3971  loss_mask: 0.2851  loss_rpn_cls: 0.06934  loss_rpn_loc: 0.1794  time: 0.2242  data_time: 0.0161  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:16:44 d2.utils.events]: \u001b[0m eta: 4:48:03  iter: 18019  total_loss: 1.322  loss_cls: 0.3596  loss_box_reg: 0.3641  loss_mask: 0.3035  loss_rpn_cls: 0.07642  loss_rpn_loc: 0.1895  time: 0.2242  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:16:49 d2.utils.events]: \u001b[0m eta: 4:47:40  iter: 18039  total_loss: 1.204  loss_cls: 0.3042  loss_box_reg: 0.3733  loss_mask: 0.2692  loss_rpn_cls: 0.07164  loss_rpn_loc: 0.1748  time: 0.2242  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:16:53 d2.utils.events]: \u001b[0m eta: 4:47:27  iter: 18059  total_loss: 1.217  loss_cls: 0.2751  loss_box_reg: 0.4039  loss_mask: 0.2682  loss_rpn_cls: 0.06958  loss_rpn_loc: 0.168  time: 0.2243  data_time: 0.0170  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:16:58 d2.utils.events]: \u001b[0m eta: 4:47:50  iter: 18079  total_loss: 1.263  loss_cls: 0.3141  loss_box_reg: 0.4178  loss_mask: 0.2631  loss_rpn_cls: 0.06677  loss_rpn_loc: 0.1674  time: 0.2242  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:17:02 d2.utils.events]: \u001b[0m eta: 4:47:27  iter: 18099  total_loss: 1.292  loss_cls: 0.3163  loss_box_reg: 0.3936  loss_mask: 0.26  loss_rpn_cls: 0.06623  loss_rpn_loc: 0.1728  time: 0.2242  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:17:07 d2.utils.events]: \u001b[0m eta: 4:47:41  iter: 18119  total_loss: 1.33  loss_cls: 0.2925  loss_box_reg: 0.4021  loss_mask: 0.2979  loss_rpn_cls: 0.09397  loss_rpn_loc: 0.171  time: 0.2242  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:17:11 d2.utils.events]: \u001b[0m eta: 4:47:36  iter: 18139  total_loss: 1.232  loss_cls: 0.3179  loss_box_reg: 0.3924  loss_mask: 0.2736  loss_rpn_cls: 0.08006  loss_rpn_loc: 0.1649  time: 0.2242  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:17:15 d2.utils.events]: \u001b[0m eta: 4:47:24  iter: 18159  total_loss: 1.243  loss_cls: 0.3112  loss_box_reg: 0.3711  loss_mask: 0.2547  loss_rpn_cls: 0.07416  loss_rpn_loc: 0.167  time: 0.2242  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:17:20 d2.utils.events]: \u001b[0m eta: 4:47:09  iter: 18179  total_loss: 1.328  loss_cls: 0.3594  loss_box_reg: 0.4638  loss_mask: 0.2854  loss_rpn_cls: 0.08973  loss_rpn_loc: 0.2055  time: 0.2242  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:17:24 d2.utils.events]: \u001b[0m eta: 4:46:57  iter: 18199  total_loss: 1.278  loss_cls: 0.3183  loss_box_reg: 0.3739  loss_mask: 0.2611  loss_rpn_cls: 0.08055  loss_rpn_loc: 0.1689  time: 0.2242  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:17:29 d2.utils.events]: \u001b[0m eta: 4:46:38  iter: 18219  total_loss: 1.297  loss_cls: 0.3281  loss_box_reg: 0.432  loss_mask: 0.2949  loss_rpn_cls: 0.09223  loss_rpn_loc: 0.1704  time: 0.2242  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:17:33 d2.utils.events]: \u001b[0m eta: 4:46:33  iter: 18239  total_loss: 1.205  loss_cls: 0.2863  loss_box_reg: 0.3948  loss_mask: 0.265  loss_rpn_cls: 0.07643  loss_rpn_loc: 0.1711  time: 0.2242  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:17:38 d2.utils.events]: \u001b[0m eta: 4:45:58  iter: 18259  total_loss: 1.313  loss_cls: 0.3316  loss_box_reg: 0.4137  loss_mask: 0.2701  loss_rpn_cls: 0.08177  loss_rpn_loc: 0.1681  time: 0.2242  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:17:42 d2.utils.events]: \u001b[0m eta: 4:45:36  iter: 18279  total_loss: 1.232  loss_cls: 0.2885  loss_box_reg: 0.4008  loss_mask: 0.2551  loss_rpn_cls: 0.07916  loss_rpn_loc: 0.1796  time: 0.2242  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:17:47 d2.utils.events]: \u001b[0m eta: 4:45:17  iter: 18299  total_loss: 1.237  loss_cls: 0.3071  loss_box_reg: 0.3872  loss_mask: 0.289  loss_rpn_cls: 0.07853  loss_rpn_loc: 0.1905  time: 0.2242  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:17:51 d2.utils.events]: \u001b[0m eta: 4:45:18  iter: 18319  total_loss: 1.139  loss_cls: 0.266  loss_box_reg: 0.3946  loss_mask: 0.2509  loss_rpn_cls: 0.06675  loss_rpn_loc: 0.1662  time: 0.2242  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:17:56 d2.utils.events]: \u001b[0m eta: 4:45:14  iter: 18339  total_loss: 1.139  loss_cls: 0.2917  loss_box_reg: 0.3891  loss_mask: 0.2425  loss_rpn_cls: 0.05842  loss_rpn_loc: 0.1592  time: 0.2242  data_time: 0.0203  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:18:00 d2.utils.events]: \u001b[0m eta: 4:45:10  iter: 18359  total_loss: 1.252  loss_cls: 0.3096  loss_box_reg: 0.4236  loss_mask: 0.2556  loss_rpn_cls: 0.07018  loss_rpn_loc: 0.1651  time: 0.2242  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:18:05 d2.utils.events]: \u001b[0m eta: 4:45:20  iter: 18379  total_loss: 1.283  loss_cls: 0.3497  loss_box_reg: 0.4002  loss_mask: 0.2687  loss_rpn_cls: 0.06649  loss_rpn_loc: 0.1744  time: 0.2242  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:18:09 d2.utils.events]: \u001b[0m eta: 4:45:58  iter: 18399  total_loss: 1.307  loss_cls: 0.3394  loss_box_reg: 0.407  loss_mask: 0.2781  loss_rpn_cls: 0.0836  loss_rpn_loc: 0.1738  time: 0.2242  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:18:14 d2.utils.events]: \u001b[0m eta: 4:45:02  iter: 18419  total_loss: 1.262  loss_cls: 0.3288  loss_box_reg: 0.4138  loss_mask: 0.2772  loss_rpn_cls: 0.08871  loss_rpn_loc: 0.1641  time: 0.2242  data_time: 0.0221  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:18:18 d2.utils.events]: \u001b[0m eta: 4:44:32  iter: 18439  total_loss: 1.226  loss_cls: 0.3232  loss_box_reg: 0.4195  loss_mask: 0.2737  loss_rpn_cls: 0.052  loss_rpn_loc: 0.1699  time: 0.2242  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:18:23 d2.utils.events]: \u001b[0m eta: 4:44:48  iter: 18459  total_loss: 1.151  loss_cls: 0.2884  loss_box_reg: 0.3801  loss_mask: 0.2509  loss_rpn_cls: 0.07681  loss_rpn_loc: 0.1799  time: 0.2242  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:18:27 d2.utils.events]: \u001b[0m eta: 4:44:34  iter: 18479  total_loss: 1.158  loss_cls: 0.2781  loss_box_reg: 0.3794  loss_mask: 0.2504  loss_rpn_cls: 0.08707  loss_rpn_loc: 0.1587  time: 0.2242  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:18:31 d2.utils.events]: \u001b[0m eta: 4:44:29  iter: 18499  total_loss: 1.266  loss_cls: 0.3171  loss_box_reg: 0.4071  loss_mask: 0.272  loss_rpn_cls: 0.09168  loss_rpn_loc: 0.167  time: 0.2242  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:18:36 d2.utils.events]: \u001b[0m eta: 4:44:15  iter: 18519  total_loss: 1.283  loss_cls: 0.3364  loss_box_reg: 0.4279  loss_mask: 0.274  loss_rpn_cls: 0.09793  loss_rpn_loc: 0.1642  time: 0.2242  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:18:40 d2.utils.events]: \u001b[0m eta: 4:44:02  iter: 18539  total_loss: 1.193  loss_cls: 0.2889  loss_box_reg: 0.4059  loss_mask: 0.2596  loss_rpn_cls: 0.07131  loss_rpn_loc: 0.178  time: 0.2242  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:18:44 d2.utils.events]: \u001b[0m eta: 4:43:35  iter: 18559  total_loss: 1.338  loss_cls: 0.3472  loss_box_reg: 0.4103  loss_mask: 0.277  loss_rpn_cls: 0.07439  loss_rpn_loc: 0.1625  time: 0.2241  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:18:49 d2.utils.events]: \u001b[0m eta: 4:43:35  iter: 18579  total_loss: 1.284  loss_cls: 0.3163  loss_box_reg: 0.4428  loss_mask: 0.2678  loss_rpn_cls: 0.0866  loss_rpn_loc: 0.1795  time: 0.2241  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:18:53 d2.utils.events]: \u001b[0m eta: 4:43:31  iter: 18599  total_loss: 1.169  loss_cls: 0.2856  loss_box_reg: 0.3797  loss_mask: 0.2582  loss_rpn_cls: 0.08  loss_rpn_loc: 0.1807  time: 0.2241  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:18:57 d2.utils.events]: \u001b[0m eta: 4:43:04  iter: 18619  total_loss: 1.301  loss_cls: 0.3388  loss_box_reg: 0.4288  loss_mask: 0.272  loss_rpn_cls: 0.08308  loss_rpn_loc: 0.1732  time: 0.2241  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:19:02 d2.utils.events]: \u001b[0m eta: 4:43:03  iter: 18639  total_loss: 1.221  loss_cls: 0.2783  loss_box_reg: 0.4233  loss_mask: 0.2831  loss_rpn_cls: 0.07595  loss_rpn_loc: 0.1665  time: 0.2241  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:19:06 d2.utils.events]: \u001b[0m eta: 4:42:51  iter: 18659  total_loss: 1.183  loss_cls: 0.296  loss_box_reg: 0.3834  loss_mask: 0.2445  loss_rpn_cls: 0.05671  loss_rpn_loc: 0.153  time: 0.2241  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:19:11 d2.utils.events]: \u001b[0m eta: 4:42:25  iter: 18679  total_loss: 1.33  loss_cls: 0.3529  loss_box_reg: 0.3984  loss_mask: 0.2828  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.2043  time: 0.2241  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:19:15 d2.utils.events]: \u001b[0m eta: 4:42:16  iter: 18699  total_loss: 1.308  loss_cls: 0.328  loss_box_reg: 0.3983  loss_mask: 0.2871  loss_rpn_cls: 0.09053  loss_rpn_loc: 0.187  time: 0.2241  data_time: 0.0167  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:19:20 d2.utils.events]: \u001b[0m eta: 4:42:08  iter: 18719  total_loss: 1.134  loss_cls: 0.2987  loss_box_reg: 0.3617  loss_mask: 0.2523  loss_rpn_cls: 0.06921  loss_rpn_loc: 0.1632  time: 0.2241  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:19:24 d2.utils.events]: \u001b[0m eta: 4:42:07  iter: 18739  total_loss: 1.305  loss_cls: 0.3318  loss_box_reg: 0.394  loss_mask: 0.2924  loss_rpn_cls: 0.08981  loss_rpn_loc: 0.1859  time: 0.2241  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:19:29 d2.utils.events]: \u001b[0m eta: 4:42:03  iter: 18759  total_loss: 1.271  loss_cls: 0.308  loss_box_reg: 0.406  loss_mask: 0.284  loss_rpn_cls: 0.08475  loss_rpn_loc: 0.1699  time: 0.2241  data_time: 0.0156  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:19:33 d2.utils.events]: \u001b[0m eta: 4:41:50  iter: 18779  total_loss: 1.22  loss_cls: 0.3265  loss_box_reg: 0.4029  loss_mask: 0.2609  loss_rpn_cls: 0.07665  loss_rpn_loc: 0.1734  time: 0.2241  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:19:37 d2.utils.events]: \u001b[0m eta: 4:41:46  iter: 18799  total_loss: 1.174  loss_cls: 0.2891  loss_box_reg: 0.3717  loss_mask: 0.2638  loss_rpn_cls: 0.0801  loss_rpn_loc: 0.1782  time: 0.2241  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:19:42 d2.utils.events]: \u001b[0m eta: 4:41:37  iter: 18819  total_loss: 1.253  loss_cls: 0.3254  loss_box_reg: 0.3839  loss_mask: 0.2734  loss_rpn_cls: 0.08114  loss_rpn_loc: 0.1753  time: 0.2241  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:19:47 d2.utils.events]: \u001b[0m eta: 4:41:17  iter: 18839  total_loss: 1.225  loss_cls: 0.3097  loss_box_reg: 0.3713  loss_mask: 0.2603  loss_rpn_cls: 0.08829  loss_rpn_loc: 0.1697  time: 0.2241  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:19:51 d2.utils.events]: \u001b[0m eta: 4:41:23  iter: 18859  total_loss: 1.258  loss_cls: 0.279  loss_box_reg: 0.344  loss_mask: 0.2693  loss_rpn_cls: 0.09469  loss_rpn_loc: 0.1779  time: 0.2241  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:19:56 d2.utils.events]: \u001b[0m eta: 4:41:33  iter: 18879  total_loss: 1.125  loss_cls: 0.2743  loss_box_reg: 0.3728  loss_mask: 0.2508  loss_rpn_cls: 0.06452  loss_rpn_loc: 0.1558  time: 0.2241  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:20:00 d2.utils.events]: \u001b[0m eta: 4:41:38  iter: 18899  total_loss: 1.241  loss_cls: 0.3095  loss_box_reg: 0.4138  loss_mask: 0.2726  loss_rpn_cls: 0.08461  loss_rpn_loc: 0.198  time: 0.2241  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:20:05 d2.utils.events]: \u001b[0m eta: 4:41:24  iter: 18919  total_loss: 1.394  loss_cls: 0.3621  loss_box_reg: 0.4611  loss_mask: 0.2997  loss_rpn_cls: 0.07019  loss_rpn_loc: 0.1765  time: 0.2241  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:20:09 d2.utils.events]: \u001b[0m eta: 4:41:28  iter: 18939  total_loss: 1.268  loss_cls: 0.3307  loss_box_reg: 0.3957  loss_mask: 0.2652  loss_rpn_cls: 0.07998  loss_rpn_loc: 0.178  time: 0.2241  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:20:14 d2.utils.events]: \u001b[0m eta: 4:41:21  iter: 18959  total_loss: 1.318  loss_cls: 0.336  loss_box_reg: 0.4464  loss_mask: 0.2811  loss_rpn_cls: 0.09641  loss_rpn_loc: 0.1984  time: 0.2241  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:20:18 d2.utils.events]: \u001b[0m eta: 4:40:57  iter: 18979  total_loss: 1.099  loss_cls: 0.282  loss_box_reg: 0.4149  loss_mask: 0.261  loss_rpn_cls: 0.08278  loss_rpn_loc: 0.1531  time: 0.2241  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:20:23 d2.utils.events]: \u001b[0m eta: 4:40:42  iter: 18999  total_loss: 1.27  loss_cls: 0.2897  loss_box_reg: 0.4247  loss_mask: 0.2698  loss_rpn_cls: 0.07345  loss_rpn_loc: 0.1592  time: 0.2241  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:20:27 d2.utils.events]: \u001b[0m eta: 4:40:33  iter: 19019  total_loss: 1.276  loss_cls: 0.3084  loss_box_reg: 0.3463  loss_mask: 0.2819  loss_rpn_cls: 0.07041  loss_rpn_loc: 0.1814  time: 0.2241  data_time: 0.0248  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:20:32 d2.utils.events]: \u001b[0m eta: 4:40:28  iter: 19039  total_loss: 1.226  loss_cls: 0.3152  loss_box_reg: 0.389  loss_mask: 0.2603  loss_rpn_cls: 0.06461  loss_rpn_loc: 0.1642  time: 0.2241  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:20:36 d2.utils.events]: \u001b[0m eta: 4:40:18  iter: 19059  total_loss: 1.256  loss_cls: 0.3408  loss_box_reg: 0.3929  loss_mask: 0.2542  loss_rpn_cls: 0.07767  loss_rpn_loc: 0.1792  time: 0.2241  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:20:41 d2.utils.events]: \u001b[0m eta: 4:40:07  iter: 19079  total_loss: 1.074  loss_cls: 0.2858  loss_box_reg: 0.369  loss_mask: 0.2341  loss_rpn_cls: 0.06139  loss_rpn_loc: 0.1449  time: 0.2241  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:20:45 d2.utils.events]: \u001b[0m eta: 4:40:15  iter: 19099  total_loss: 1.249  loss_cls: 0.3013  loss_box_reg: 0.3921  loss_mask: 0.2761  loss_rpn_cls: 0.1033  loss_rpn_loc: 0.1619  time: 0.2241  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:20:50 d2.utils.events]: \u001b[0m eta: 4:40:26  iter: 19119  total_loss: 1.274  loss_cls: 0.3179  loss_box_reg: 0.4008  loss_mask: 0.2692  loss_rpn_cls: 0.09893  loss_rpn_loc: 0.1832  time: 0.2241  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:20:54 d2.utils.events]: \u001b[0m eta: 4:40:12  iter: 19139  total_loss: 1.134  loss_cls: 0.2862  loss_box_reg: 0.3977  loss_mask: 0.239  loss_rpn_cls: 0.0639  loss_rpn_loc: 0.1442  time: 0.2241  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:20:58 d2.utils.events]: \u001b[0m eta: 4:40:14  iter: 19159  total_loss: 1.142  loss_cls: 0.2581  loss_box_reg: 0.3774  loss_mask: 0.2551  loss_rpn_cls: 0.07539  loss_rpn_loc: 0.1671  time: 0.2241  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:21:03 d2.utils.events]: \u001b[0m eta: 4:40:10  iter: 19179  total_loss: 1.22  loss_cls: 0.331  loss_box_reg: 0.3898  loss_mask: 0.2568  loss_rpn_cls: 0.07439  loss_rpn_loc: 0.1702  time: 0.2241  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:21:07 d2.utils.events]: \u001b[0m eta: 4:40:18  iter: 19199  total_loss: 1.209  loss_cls: 0.2794  loss_box_reg: 0.3762  loss_mask: 0.2512  loss_rpn_cls: 0.07115  loss_rpn_loc: 0.1562  time: 0.2240  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:21:12 d2.utils.events]: \u001b[0m eta: 4:40:22  iter: 19219  total_loss: 1.186  loss_cls: 0.3058  loss_box_reg: 0.3548  loss_mask: 0.2728  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.1822  time: 0.2241  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:21:17 d2.utils.events]: \u001b[0m eta: 4:40:06  iter: 19239  total_loss: 1.186  loss_cls: 0.2907  loss_box_reg: 0.3786  loss_mask: 0.2555  loss_rpn_cls: 0.09697  loss_rpn_loc: 0.1619  time: 0.2241  data_time: 0.0090  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:21:21 d2.utils.events]: \u001b[0m eta: 4:40:01  iter: 19259  total_loss: 1.332  loss_cls: 0.3224  loss_box_reg: 0.445  loss_mask: 0.2746  loss_rpn_cls: 0.07569  loss_rpn_loc: 0.1925  time: 0.2241  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:21:25 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.42 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/29 22:21:25 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/29 22:21:25 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/29 22:21:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/29 22:21:26 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 22:21:27 d2.data.common]: \u001b[0mSerialized dataset takes 84.20 MiB\n",
      "\u001b[32m[12/29 22:21:29 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.44 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/29 22:21:29 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/29 22:21:29 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/29 22:21:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/29 22:21:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0007 s/iter. Inference: 0.0627 s/iter. Eval: 0.1428 s/iter. Total: 0.2063 s/iter. ETA=0:01:55\n",
      "\u001b[32m[12/29 22:21:38 d2.evaluation.evaluator]: \u001b[0mInference done 38/570. Dataloading: 0.0008 s/iter. Inference: 0.0599 s/iter. Eval: 0.1294 s/iter. Total: 0.1902 s/iter. ETA=0:01:41\n",
      "\u001b[32m[12/29 22:21:43 d2.evaluation.evaluator]: \u001b[0mInference done 66/570. Dataloading: 0.0009 s/iter. Inference: 0.0573 s/iter. Eval: 0.1284 s/iter. Total: 0.1866 s/iter. ETA=0:01:34\n",
      "\u001b[32m[12/29 22:21:48 d2.evaluation.evaluator]: \u001b[0mInference done 91/570. Dataloading: 0.0009 s/iter. Inference: 0.0575 s/iter. Eval: 0.1329 s/iter. Total: 0.1914 s/iter. ETA=0:01:31\n",
      "\u001b[32m[12/29 22:21:53 d2.evaluation.evaluator]: \u001b[0mInference done 117/570. Dataloading: 0.0009 s/iter. Inference: 0.0570 s/iter. Eval: 0.1341 s/iter. Total: 0.1921 s/iter. ETA=0:01:27\n",
      "\u001b[32m[12/29 22:21:58 d2.evaluation.evaluator]: \u001b[0mInference done 142/570. Dataloading: 0.0009 s/iter. Inference: 0.0564 s/iter. Eval: 0.1373 s/iter. Total: 0.1946 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/29 22:22:04 d2.evaluation.evaluator]: \u001b[0mInference done 162/570. Dataloading: 0.0009 s/iter. Inference: 0.0556 s/iter. Eval: 0.1469 s/iter. Total: 0.2034 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/29 22:22:09 d2.evaluation.evaluator]: \u001b[0mInference done 175/570. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.1619 s/iter. Total: 0.2187 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/29 22:22:14 d2.evaluation.evaluator]: \u001b[0mInference done 193/570. Dataloading: 0.0009 s/iter. Inference: 0.0563 s/iter. Eval: 0.1678 s/iter. Total: 0.2251 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/29 22:22:19 d2.evaluation.evaluator]: \u001b[0mInference done 208/570. Dataloading: 0.0009 s/iter. Inference: 0.0564 s/iter. Eval: 0.1759 s/iter. Total: 0.2332 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/29 22:22:24 d2.evaluation.evaluator]: \u001b[0mInference done 225/570. Dataloading: 0.0009 s/iter. Inference: 0.0568 s/iter. Eval: 0.1810 s/iter. Total: 0.2388 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/29 22:22:30 d2.evaluation.evaluator]: \u001b[0mInference done 236/570. Dataloading: 0.0009 s/iter. Inference: 0.0570 s/iter. Eval: 0.1925 s/iter. Total: 0.2504 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/29 22:22:35 d2.evaluation.evaluator]: \u001b[0mInference done 249/570. Dataloading: 0.0009 s/iter. Inference: 0.0571 s/iter. Eval: 0.2022 s/iter. Total: 0.2602 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/29 22:22:41 d2.evaluation.evaluator]: \u001b[0mInference done 265/570. Dataloading: 0.0009 s/iter. Inference: 0.0572 s/iter. Eval: 0.2066 s/iter. Total: 0.2648 s/iter. ETA=0:01:20\n",
      "\u001b[32m[12/29 22:22:46 d2.evaluation.evaluator]: \u001b[0mInference done 283/570. Dataloading: 0.0009 s/iter. Inference: 0.0574 s/iter. Eval: 0.2080 s/iter. Total: 0.2664 s/iter. ETA=0:01:16\n",
      "\u001b[32m[12/29 22:22:51 d2.evaluation.evaluator]: \u001b[0mInference done 298/570. Dataloading: 0.0009 s/iter. Inference: 0.0574 s/iter. Eval: 0.2135 s/iter. Total: 0.2718 s/iter. ETA=0:01:13\n",
      "\u001b[32m[12/29 22:22:57 d2.evaluation.evaluator]: \u001b[0mInference done 346/570. Dataloading: 0.0009 s/iter. Inference: 0.0561 s/iter. Eval: 0.1915 s/iter. Total: 0.2485 s/iter. ETA=0:00:55\n",
      "\u001b[32m[12/29 22:23:02 d2.evaluation.evaluator]: \u001b[0mInference done 376/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1858 s/iter. Total: 0.2425 s/iter. ETA=0:00:47\n",
      "\u001b[32m[12/29 22:23:07 d2.evaluation.evaluator]: \u001b[0mInference done 398/570. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.1851 s/iter. Total: 0.2419 s/iter. ETA=0:00:41\n",
      "\u001b[32m[12/29 22:23:12 d2.evaluation.evaluator]: \u001b[0mInference done 416/570. Dataloading: 0.0009 s/iter. Inference: 0.0561 s/iter. Eval: 0.1870 s/iter. Total: 0.2440 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 22:23:17 d2.evaluation.evaluator]: \u001b[0mInference done 435/570. Dataloading: 0.0009 s/iter. Inference: 0.0563 s/iter. Eval: 0.1877 s/iter. Total: 0.2449 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/29 22:23:22 d2.evaluation.evaluator]: \u001b[0mInference done 465/570. Dataloading: 0.0009 s/iter. Inference: 0.0560 s/iter. Eval: 0.1830 s/iter. Total: 0.2399 s/iter. ETA=0:00:25\n",
      "\u001b[32m[12/29 22:23:28 d2.evaluation.evaluator]: \u001b[0mInference done 496/570. Dataloading: 0.0009 s/iter. Inference: 0.0555 s/iter. Eval: 0.1792 s/iter. Total: 0.2357 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 22:23:33 d2.evaluation.evaluator]: \u001b[0mInference done 518/570. Dataloading: 0.0009 s/iter. Inference: 0.0553 s/iter. Eval: 0.1793 s/iter. Total: 0.2355 s/iter. ETA=0:00:12\n",
      "\u001b[32m[12/29 22:23:38 d2.evaluation.evaluator]: \u001b[0mInference done 541/570. Dataloading: 0.0009 s/iter. Inference: 0.0554 s/iter. Eval: 0.1788 s/iter. Total: 0.2351 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/29 22:23:43 d2.evaluation.evaluator]: \u001b[0mInference done 559/570. Dataloading: 0.0009 s/iter. Inference: 0.0556 s/iter. Eval: 0.1803 s/iter. Total: 0.2368 s/iter. ETA=0:00:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:23:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:13.937835 (0.237058 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 22:23:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.055640 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 22:23:46 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/29 22:23:46 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.27843237100642004\n",
      "\u001b[32m[12/29 22:23:49 d2.utils.events]: \u001b[0m eta: 4:39:57  iter: 19279  total_loss: 1.128  loss_cls: 0.3201  loss_box_reg: 0.3789  loss_mask: 0.2629  loss_rpn_cls: 0.07653  loss_rpn_loc: 0.1611  time: 0.2241  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:23:53 d2.utils.events]: \u001b[0m eta: 4:39:37  iter: 19299  total_loss: 1.206  loss_cls: 0.3013  loss_box_reg: 0.3899  loss_mask: 0.255  loss_rpn_cls: 0.08171  loss_rpn_loc: 0.1752  time: 0.2241  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:23:58 d2.utils.events]: \u001b[0m eta: 4:39:24  iter: 19319  total_loss: 1.17  loss_cls: 0.2952  loss_box_reg: 0.3899  loss_mask: 0.2541  loss_rpn_cls: 0.05904  loss_rpn_loc: 0.1683  time: 0.2241  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:24:02 d2.utils.events]: \u001b[0m eta: 4:38:52  iter: 19339  total_loss: 1.182  loss_cls: 0.3151  loss_box_reg: 0.3916  loss_mask: 0.2527  loss_rpn_cls: 0.09256  loss_rpn_loc: 0.1861  time: 0.2240  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:24:07 d2.utils.events]: \u001b[0m eta: 4:38:48  iter: 19359  total_loss: 1.164  loss_cls: 0.2801  loss_box_reg: 0.3931  loss_mask: 0.2501  loss_rpn_cls: 0.06807  loss_rpn_loc: 0.1796  time: 0.2241  data_time: 0.0245  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:24:11 d2.utils.events]: \u001b[0m eta: 4:38:56  iter: 19379  total_loss: 1.331  loss_cls: 0.3589  loss_box_reg: 0.4545  loss_mask: 0.2929  loss_rpn_cls: 0.07877  loss_rpn_loc: 0.1775  time: 0.2241  data_time: 0.0176  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:24:16 d2.utils.events]: \u001b[0m eta: 4:38:52  iter: 19399  total_loss: 1.293  loss_cls: 0.3633  loss_box_reg: 0.3632  loss_mask: 0.2703  loss_rpn_cls: 0.1126  loss_rpn_loc: 0.1776  time: 0.2241  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:24:20 d2.utils.events]: \u001b[0m eta: 4:39:06  iter: 19419  total_loss: 1.328  loss_cls: 0.3216  loss_box_reg: 0.4201  loss_mask: 0.2772  loss_rpn_cls: 0.0868  loss_rpn_loc: 0.164  time: 0.2241  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:24:25 d2.utils.events]: \u001b[0m eta: 4:39:24  iter: 19439  total_loss: 1.276  loss_cls: 0.331  loss_box_reg: 0.4231  loss_mask: 0.2659  loss_rpn_cls: 0.07447  loss_rpn_loc: 0.1786  time: 0.2241  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:24:29 d2.utils.events]: \u001b[0m eta: 4:39:16  iter: 19459  total_loss: 1.193  loss_cls: 0.2728  loss_box_reg: 0.4112  loss_mask: 0.2729  loss_rpn_cls: 0.08597  loss_rpn_loc: 0.1795  time: 0.2241  data_time: 0.0110  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:24:34 d2.utils.events]: \u001b[0m eta: 4:39:11  iter: 19479  total_loss: 1.246  loss_cls: 0.3149  loss_box_reg: 0.4236  loss_mask: 0.2757  loss_rpn_cls: 0.07398  loss_rpn_loc: 0.1846  time: 0.2241  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:24:38 d2.utils.events]: \u001b[0m eta: 4:39:39  iter: 19499  total_loss: 1.373  loss_cls: 0.3581  loss_box_reg: 0.4376  loss_mask: 0.2834  loss_rpn_cls: 0.1027  loss_rpn_loc: 0.1865  time: 0.2241  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:24:43 d2.utils.events]: \u001b[0m eta: 4:39:45  iter: 19519  total_loss: 1.264  loss_cls: 0.3498  loss_box_reg: 0.3965  loss_mask: 0.267  loss_rpn_cls: 0.09163  loss_rpn_loc: 0.1879  time: 0.2241  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:24:47 d2.utils.events]: \u001b[0m eta: 4:39:14  iter: 19539  total_loss: 1.314  loss_cls: 0.3084  loss_box_reg: 0.4218  loss_mask: 0.2726  loss_rpn_cls: 0.07327  loss_rpn_loc: 0.1601  time: 0.2241  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:24:52 d2.utils.events]: \u001b[0m eta: 4:39:37  iter: 19559  total_loss: 1.237  loss_cls: 0.3221  loss_box_reg: 0.3661  loss_mask: 0.2676  loss_rpn_cls: 0.07542  loss_rpn_loc: 0.1706  time: 0.2241  data_time: 0.0146  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:24:56 d2.utils.events]: \u001b[0m eta: 4:40:08  iter: 19579  total_loss: 1.302  loss_cls: 0.304  loss_box_reg: 0.4254  loss_mask: 0.2703  loss_rpn_cls: 0.08631  loss_rpn_loc: 0.1763  time: 0.2241  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:25:01 d2.utils.events]: \u001b[0m eta: 4:40:08  iter: 19599  total_loss: 1.178  loss_cls: 0.2983  loss_box_reg: 0.369  loss_mask: 0.2609  loss_rpn_cls: 0.07713  loss_rpn_loc: 0.1743  time: 0.2241  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:25:05 d2.utils.events]: \u001b[0m eta: 4:40:18  iter: 19619  total_loss: 1.239  loss_cls: 0.3149  loss_box_reg: 0.3837  loss_mask: 0.249  loss_rpn_cls: 0.07576  loss_rpn_loc: 0.175  time: 0.2241  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:25:10 d2.utils.events]: \u001b[0m eta: 4:40:14  iter: 19639  total_loss: 1.211  loss_cls: 0.2895  loss_box_reg: 0.375  loss_mask: 0.2737  loss_rpn_cls: 0.06985  loss_rpn_loc: 0.1783  time: 0.2241  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:25:14 d2.utils.events]: \u001b[0m eta: 4:40:17  iter: 19659  total_loss: 1.315  loss_cls: 0.3506  loss_box_reg: 0.439  loss_mask: 0.2788  loss_rpn_cls: 0.05971  loss_rpn_loc: 0.1688  time: 0.2241  data_time: 0.0144  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:25:19 d2.utils.events]: \u001b[0m eta: 4:40:05  iter: 19679  total_loss: 1.174  loss_cls: 0.2901  loss_box_reg: 0.3754  loss_mask: 0.2581  loss_rpn_cls: 0.05318  loss_rpn_loc: 0.1575  time: 0.2241  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:25:24 d2.utils.events]: \u001b[0m eta: 4:40:09  iter: 19699  total_loss: 1.265  loss_cls: 0.3098  loss_box_reg: 0.3652  loss_mask: 0.2896  loss_rpn_cls: 0.1148  loss_rpn_loc: 0.1893  time: 0.2241  data_time: 0.0095  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:25:28 d2.utils.events]: \u001b[0m eta: 4:39:56  iter: 19719  total_loss: 1.115  loss_cls: 0.2934  loss_box_reg: 0.3795  loss_mask: 0.2586  loss_rpn_cls: 0.08468  loss_rpn_loc: 0.1599  time: 0.2241  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:25:32 d2.utils.events]: \u001b[0m eta: 4:39:45  iter: 19739  total_loss: 1.103  loss_cls: 0.2788  loss_box_reg: 0.3544  loss_mask: 0.2525  loss_rpn_cls: 0.05722  loss_rpn_loc: 0.1471  time: 0.2241  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:25:36 d2.utils.events]: \u001b[0m eta: 4:39:28  iter: 19759  total_loss: 1.184  loss_cls: 0.3074  loss_box_reg: 0.3851  loss_mask: 0.2655  loss_rpn_cls: 0.07617  loss_rpn_loc: 0.1542  time: 0.2241  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:25:41 d2.utils.events]: \u001b[0m eta: 4:39:27  iter: 19779  total_loss: 1.264  loss_cls: 0.3224  loss_box_reg: 0.4096  loss_mask: 0.2605  loss_rpn_cls: 0.09181  loss_rpn_loc: 0.1658  time: 0.2241  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:25:45 d2.utils.events]: \u001b[0m eta: 4:39:19  iter: 19799  total_loss: 1.225  loss_cls: 0.3159  loss_box_reg: 0.3751  loss_mask: 0.256  loss_rpn_cls: 0.07062  loss_rpn_loc: 0.1693  time: 0.2241  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:25:50 d2.utils.events]: \u001b[0m eta: 4:38:52  iter: 19819  total_loss: 1.141  loss_cls: 0.2499  loss_box_reg: 0.397  loss_mask: 0.2538  loss_rpn_cls: 0.07146  loss_rpn_loc: 0.159  time: 0.2240  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:25:54 d2.utils.events]: \u001b[0m eta: 4:38:52  iter: 19839  total_loss: 1.292  loss_cls: 0.3226  loss_box_reg: 0.4059  loss_mask: 0.2738  loss_rpn_cls: 0.117  loss_rpn_loc: 0.1831  time: 0.2240  data_time: 0.0094  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:25:59 d2.utils.events]: \u001b[0m eta: 4:38:37  iter: 19859  total_loss: 1.263  loss_cls: 0.3141  loss_box_reg: 0.4306  loss_mask: 0.2621  loss_rpn_cls: 0.08576  loss_rpn_loc: 0.1757  time: 0.2240  data_time: 0.0168  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:26:03 d2.utils.events]: \u001b[0m eta: 4:38:33  iter: 19879  total_loss: 1.166  loss_cls: 0.2899  loss_box_reg: 0.3358  loss_mask: 0.2787  loss_rpn_cls: 0.07417  loss_rpn_loc: 0.166  time: 0.2241  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:26:08 d2.utils.events]: \u001b[0m eta: 4:38:46  iter: 19899  total_loss: 1.21  loss_cls: 0.2889  loss_box_reg: 0.3438  loss_mask: 0.2716  loss_rpn_cls: 0.08914  loss_rpn_loc: 0.1598  time: 0.2241  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:26:12 d2.utils.events]: \u001b[0m eta: 4:38:53  iter: 19919  total_loss: 1.201  loss_cls: 0.3032  loss_box_reg: 0.4163  loss_mask: 0.2668  loss_rpn_cls: 0.06707  loss_rpn_loc: 0.1501  time: 0.2241  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:26:17 d2.utils.events]: \u001b[0m eta: 4:38:52  iter: 19939  total_loss: 1.187  loss_cls: 0.2948  loss_box_reg: 0.4021  loss_mask: 0.2635  loss_rpn_cls: 0.08353  loss_rpn_loc: 0.1648  time: 0.2241  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:26:22 d2.utils.events]: \u001b[0m eta: 4:38:45  iter: 19959  total_loss: 1.221  loss_cls: 0.2974  loss_box_reg: 0.4285  loss_mask: 0.2685  loss_rpn_cls: 0.06743  loss_rpn_loc: 0.1714  time: 0.2241  data_time: 0.0208  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:26:26 d2.utils.events]: \u001b[0m eta: 4:38:40  iter: 19979  total_loss: 1.219  loss_cls: 0.3094  loss_box_reg: 0.3655  loss_mask: 0.2636  loss_rpn_cls: 0.09097  loss_rpn_loc: 0.1751  time: 0.2241  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:26:31 d2.utils.events]: \u001b[0m eta: 4:38:31  iter: 19999  total_loss: 1.162  loss_cls: 0.2787  loss_box_reg: 0.3961  loss_mask: 0.2571  loss_rpn_cls: 0.08061  loss_rpn_loc: 0.1764  time: 0.2241  data_time: 0.0111  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:26:35 d2.utils.events]: \u001b[0m eta: 4:38:32  iter: 20019  total_loss: 1.319  loss_cls: 0.3141  loss_box_reg: 0.3836  loss_mask: 0.2748  loss_rpn_cls: 0.08388  loss_rpn_loc: 0.17  time: 0.2241  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:26:40 d2.utils.events]: \u001b[0m eta: 4:38:38  iter: 20039  total_loss: 1.256  loss_cls: 0.3196  loss_box_reg: 0.37  loss_mask: 0.2668  loss_rpn_cls: 0.09323  loss_rpn_loc: 0.1785  time: 0.2241  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:26:44 d2.utils.events]: \u001b[0m eta: 4:38:36  iter: 20059  total_loss: 1.306  loss_cls: 0.312  loss_box_reg: 0.3855  loss_mask: 0.2703  loss_rpn_cls: 0.06666  loss_rpn_loc: 0.1718  time: 0.2241  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:26:48 d2.utils.events]: \u001b[0m eta: 4:38:33  iter: 20079  total_loss: 1.188  loss_cls: 0.3021  loss_box_reg: 0.3731  loss_mask: 0.2634  loss_rpn_cls: 0.06587  loss_rpn_loc: 0.1707  time: 0.2241  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:26:53 d2.utils.events]: \u001b[0m eta: 4:38:26  iter: 20099  total_loss: 1.198  loss_cls: 0.3261  loss_box_reg: 0.3892  loss_mask: 0.266  loss_rpn_cls: 0.08119  loss_rpn_loc: 0.1584  time: 0.2241  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:26:58 d2.utils.events]: \u001b[0m eta: 4:38:16  iter: 20119  total_loss: 1.307  loss_cls: 0.3267  loss_box_reg: 0.4335  loss_mask: 0.2609  loss_rpn_cls: 0.08603  loss_rpn_loc: 0.1657  time: 0.2241  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:27:02 d2.utils.events]: \u001b[0m eta: 4:38:20  iter: 20139  total_loss: 1.347  loss_cls: 0.3311  loss_box_reg: 0.4421  loss_mask: 0.2667  loss_rpn_cls: 0.09457  loss_rpn_loc: 0.1888  time: 0.2241  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:27:07 d2.utils.events]: \u001b[0m eta: 4:38:32  iter: 20159  total_loss: 1.313  loss_cls: 0.3385  loss_box_reg: 0.4364  loss_mask: 0.2902  loss_rpn_cls: 0.07517  loss_rpn_loc: 0.182  time: 0.2241  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:27:11 d2.utils.events]: \u001b[0m eta: 4:38:10  iter: 20179  total_loss: 1.218  loss_cls: 0.3228  loss_box_reg: 0.3939  loss_mask: 0.2659  loss_rpn_cls: 0.07096  loss_rpn_loc: 0.1533  time: 0.2241  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:27:16 d2.utils.events]: \u001b[0m eta: 4:38:00  iter: 20199  total_loss: 1.209  loss_cls: 0.2925  loss_box_reg: 0.3631  loss_mask: 0.2674  loss_rpn_cls: 0.07592  loss_rpn_loc: 0.1614  time: 0.2241  data_time: 0.0194  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:27:20 d2.utils.events]: \u001b[0m eta: 4:37:28  iter: 20219  total_loss: 1.351  loss_cls: 0.32  loss_box_reg: 0.434  loss_mask: 0.2699  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.1905  time: 0.2241  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:27:25 d2.utils.events]: \u001b[0m eta: 4:36:36  iter: 20239  total_loss: 1.204  loss_cls: 0.3175  loss_box_reg: 0.3791  loss_mask: 0.2675  loss_rpn_cls: 0.06278  loss_rpn_loc: 0.1632  time: 0.2241  data_time: 0.0184  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:27:29 d2.utils.events]: \u001b[0m eta: 4:37:39  iter: 20259  total_loss: 1.107  loss_cls: 0.2901  loss_box_reg: 0.3868  loss_mask: 0.2602  loss_rpn_cls: 0.07802  loss_rpn_loc: 0.17  time: 0.2241  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:27:34 d2.utils.events]: \u001b[0m eta: 4:38:06  iter: 20279  total_loss: 1.262  loss_cls: 0.329  loss_box_reg: 0.3869  loss_mask: 0.275  loss_rpn_cls: 0.09415  loss_rpn_loc: 0.1911  time: 0.2241  data_time: 0.0095  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:27:38 d2.utils.events]: \u001b[0m eta: 4:37:45  iter: 20299  total_loss: 1.285  loss_cls: 0.3268  loss_box_reg: 0.3973  loss_mask: 0.2714  loss_rpn_cls: 0.07687  loss_rpn_loc: 0.1867  time: 0.2241  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:27:43 d2.utils.events]: \u001b[0m eta: 4:38:20  iter: 20319  total_loss: 1.196  loss_cls: 0.3009  loss_box_reg: 0.388  loss_mask: 0.2648  loss_rpn_cls: 0.1063  loss_rpn_loc: 0.1742  time: 0.2241  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:27:47 d2.utils.events]: \u001b[0m eta: 4:38:31  iter: 20339  total_loss: 1.223  loss_cls: 0.3091  loss_box_reg: 0.3941  loss_mask: 0.2629  loss_rpn_cls: 0.0909  loss_rpn_loc: 0.1762  time: 0.2241  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:27:51 d2.utils.events]: \u001b[0m eta: 4:38:04  iter: 20359  total_loss: 1.215  loss_cls: 0.3157  loss_box_reg: 0.4083  loss_mask: 0.2615  loss_rpn_cls: 0.06487  loss_rpn_loc: 0.1564  time: 0.2241  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:27:56 d2.utils.events]: \u001b[0m eta: 4:37:31  iter: 20379  total_loss: 1.328  loss_cls: 0.3829  loss_box_reg: 0.4081  loss_mask: 0.2685  loss_rpn_cls: 0.0824  loss_rpn_loc: 0.1884  time: 0.2241  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:28:00 d2.utils.events]: \u001b[0m eta: 4:37:11  iter: 20399  total_loss: 1.303  loss_cls: 0.3466  loss_box_reg: 0.4137  loss_mask: 0.2652  loss_rpn_cls: 0.08295  loss_rpn_loc: 0.1675  time: 0.2241  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:28:05 d2.utils.events]: \u001b[0m eta: 4:37:23  iter: 20419  total_loss: 1.305  loss_cls: 0.3746  loss_box_reg: 0.3607  loss_mask: 0.2837  loss_rpn_cls: 0.09915  loss_rpn_loc: 0.1793  time: 0.2241  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:28:09 d2.utils.events]: \u001b[0m eta: 4:37:18  iter: 20439  total_loss: 1.337  loss_cls: 0.3381  loss_box_reg: 0.4202  loss_mask: 0.2719  loss_rpn_cls: 0.06661  loss_rpn_loc: 0.1864  time: 0.2241  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:28:14 d2.utils.events]: \u001b[0m eta: 4:36:45  iter: 20459  total_loss: 1.033  loss_cls: 0.2526  loss_box_reg: 0.3553  loss_mask: 0.241  loss_rpn_cls: 0.04532  loss_rpn_loc: 0.1493  time: 0.2240  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:28:18 d2.utils.events]: \u001b[0m eta: 4:36:41  iter: 20479  total_loss: 1.229  loss_cls: 0.3113  loss_box_reg: 0.3869  loss_mask: 0.2695  loss_rpn_cls: 0.07633  loss_rpn_loc: 0.1897  time: 0.2240  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:28:23 d2.utils.events]: \u001b[0m eta: 4:36:49  iter: 20499  total_loss: 1.212  loss_cls: 0.2858  loss_box_reg: 0.4022  loss_mask: 0.2607  loss_rpn_cls: 0.06529  loss_rpn_loc: 0.1742  time: 0.2241  data_time: 0.0156  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:28:27 d2.utils.events]: \u001b[0m eta: 4:36:17  iter: 20519  total_loss: 1.196  loss_cls: 0.3014  loss_box_reg: 0.3975  loss_mask: 0.2675  loss_rpn_cls: 0.07322  loss_rpn_loc: 0.1759  time: 0.2240  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:28:31 d2.utils.events]: \u001b[0m eta: 4:36:24  iter: 20539  total_loss: 1.198  loss_cls: 0.2751  loss_box_reg: 0.3767  loss_mask: 0.2694  loss_rpn_cls: 0.08264  loss_rpn_loc: 0.1653  time: 0.2240  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:28:36 d2.utils.events]: \u001b[0m eta: 4:36:23  iter: 20559  total_loss: 1.24  loss_cls: 0.2769  loss_box_reg: 0.3934  loss_mask: 0.2706  loss_rpn_cls: 0.0804  loss_rpn_loc: 0.1746  time: 0.2240  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:28:40 d2.utils.events]: \u001b[0m eta: 4:36:19  iter: 20579  total_loss: 1.239  loss_cls: 0.3257  loss_box_reg: 0.4131  loss_mask: 0.2465  loss_rpn_cls: 0.08729  loss_rpn_loc: 0.1595  time: 0.2240  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:28:45 d2.utils.events]: \u001b[0m eta: 4:36:11  iter: 20599  total_loss: 1.125  loss_cls: 0.2764  loss_box_reg: 0.3717  loss_mask: 0.2528  loss_rpn_cls: 0.07026  loss_rpn_loc: 0.1639  time: 0.2240  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:28:49 d2.utils.events]: \u001b[0m eta: 4:35:36  iter: 20619  total_loss: 1.228  loss_cls: 0.3106  loss_box_reg: 0.3946  loss_mask: 0.2523  loss_rpn_cls: 0.07112  loss_rpn_loc: 0.1728  time: 0.2240  data_time: 0.0143  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:28:54 d2.utils.events]: \u001b[0m eta: 4:35:27  iter: 20639  total_loss: 1.294  loss_cls: 0.3625  loss_box_reg: 0.4468  loss_mask: 0.2771  loss_rpn_cls: 0.09616  loss_rpn_loc: 0.1953  time: 0.2240  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:28:58 d2.utils.events]: \u001b[0m eta: 4:35:12  iter: 20659  total_loss: 1.184  loss_cls: 0.2981  loss_box_reg: 0.3809  loss_mask: 0.2627  loss_rpn_cls: 0.06458  loss_rpn_loc: 0.1553  time: 0.2240  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:29:02 d2.utils.events]: \u001b[0m eta: 4:35:08  iter: 20679  total_loss: 1.438  loss_cls: 0.3895  loss_box_reg: 0.4806  loss_mask: 0.2741  loss_rpn_cls: 0.09581  loss_rpn_loc: 0.1652  time: 0.2240  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:29:06 d2.utils.events]: \u001b[0m eta: 4:34:33  iter: 20699  total_loss: 1.268  loss_cls: 0.3287  loss_box_reg: 0.4213  loss_mask: 0.2822  loss_rpn_cls: 0.07038  loss_rpn_loc: 0.1666  time: 0.2240  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:29:11 d2.utils.events]: \u001b[0m eta: 4:34:29  iter: 20719  total_loss: 1.187  loss_cls: 0.2915  loss_box_reg: 0.4117  loss_mask: 0.2625  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.1672  time: 0.2240  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:29:15 d2.utils.events]: \u001b[0m eta: 4:34:29  iter: 20739  total_loss: 1.175  loss_cls: 0.304  loss_box_reg: 0.3869  loss_mask: 0.2767  loss_rpn_cls: 0.08819  loss_rpn_loc: 0.1668  time: 0.2240  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:29:20 d2.utils.events]: \u001b[0m eta: 4:34:45  iter: 20759  total_loss: 1.328  loss_cls: 0.3455  loss_box_reg: 0.3921  loss_mask: 0.275  loss_rpn_cls: 0.1009  loss_rpn_loc: 0.1848  time: 0.2240  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:29:24 d2.utils.events]: \u001b[0m eta: 4:34:49  iter: 20779  total_loss: 1.279  loss_cls: 0.3468  loss_box_reg: 0.4061  loss_mask: 0.2656  loss_rpn_cls: 0.08701  loss_rpn_loc: 0.1899  time: 0.2239  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:29:28 d2.utils.events]: \u001b[0m eta: 4:34:39  iter: 20799  total_loss: 1.244  loss_cls: 0.3166  loss_box_reg: 0.4084  loss_mask: 0.2556  loss_rpn_cls: 0.05156  loss_rpn_loc: 0.1711  time: 0.2239  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:29:33 d2.utils.events]: \u001b[0m eta: 4:34:35  iter: 20819  total_loss: 1.243  loss_cls: 0.3351  loss_box_reg: 0.4037  loss_mask: 0.2621  loss_rpn_cls: 0.08713  loss_rpn_loc: 0.1801  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:29:37 d2.utils.events]: \u001b[0m eta: 4:34:31  iter: 20839  total_loss: 1.205  loss_cls: 0.3099  loss_box_reg: 0.3861  loss_mask: 0.2677  loss_rpn_cls: 0.08152  loss_rpn_loc: 0.1752  time: 0.2239  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:29:42 d2.utils.events]: \u001b[0m eta: 4:34:19  iter: 20859  total_loss: 1.185  loss_cls: 0.2926  loss_box_reg: 0.3904  loss_mask: 0.2667  loss_rpn_cls: 0.06445  loss_rpn_loc: 0.1656  time: 0.2239  data_time: 0.0189  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:29:47 d2.utils.events]: \u001b[0m eta: 4:33:56  iter: 20879  total_loss: 1.197  loss_cls: 0.291  loss_box_reg: 0.3731  loss_mask: 0.2602  loss_rpn_cls: 0.07908  loss_rpn_loc: 0.1669  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:29:51 d2.utils.events]: \u001b[0m eta: 4:33:31  iter: 20899  total_loss: 1.237  loss_cls: 0.2982  loss_box_reg: 0.3937  loss_mask: 0.2498  loss_rpn_cls: 0.06145  loss_rpn_loc: 0.1575  time: 0.2240  data_time: 0.0093  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:29:56 d2.utils.events]: \u001b[0m eta: 4:33:42  iter: 20919  total_loss: 1.235  loss_cls: 0.3337  loss_box_reg: 0.3736  loss_mask: 0.2785  loss_rpn_cls: 0.09395  loss_rpn_loc: 0.1875  time: 0.2240  data_time: 0.0168  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:30:00 d2.utils.events]: \u001b[0m eta: 4:33:30  iter: 20939  total_loss: 1.267  loss_cls: 0.3377  loss_box_reg: 0.4275  loss_mask: 0.2685  loss_rpn_cls: 0.09106  loss_rpn_loc: 0.163  time: 0.2240  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:30:05 d2.utils.events]: \u001b[0m eta: 4:33:32  iter: 20959  total_loss: 1.024  loss_cls: 0.2726  loss_box_reg: 0.3497  loss_mask: 0.2472  loss_rpn_cls: 0.07395  loss_rpn_loc: 0.1553  time: 0.2240  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:30:09 d2.utils.events]: \u001b[0m eta: 4:33:28  iter: 20979  total_loss: 1.208  loss_cls: 0.3131  loss_box_reg: 0.3581  loss_mask: 0.2583  loss_rpn_cls: 0.08748  loss_rpn_loc: 0.1787  time: 0.2240  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:30:14 d2.utils.events]: \u001b[0m eta: 4:33:30  iter: 20999  total_loss: 1.361  loss_cls: 0.3469  loss_box_reg: 0.426  loss_mask: 0.2849  loss_rpn_cls: 0.07588  loss_rpn_loc: 0.1797  time: 0.2240  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:30:18 d2.utils.events]: \u001b[0m eta: 4:33:19  iter: 21019  total_loss: 1.286  loss_cls: 0.3159  loss_box_reg: 0.3915  loss_mask: 0.2721  loss_rpn_cls: 0.08734  loss_rpn_loc: 0.1877  time: 0.2239  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:30:23 d2.utils.events]: \u001b[0m eta: 4:32:57  iter: 21039  total_loss: 1.339  loss_cls: 0.3507  loss_box_reg: 0.4317  loss_mask: 0.2894  loss_rpn_cls: 0.08836  loss_rpn_loc: 0.1696  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:30:27 d2.utils.events]: \u001b[0m eta: 4:32:57  iter: 21059  total_loss: 1.331  loss_cls: 0.3182  loss_box_reg: 0.4198  loss_mask: 0.2996  loss_rpn_cls: 0.09583  loss_rpn_loc: 0.1964  time: 0.2239  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:30:31 d2.utils.events]: \u001b[0m eta: 4:32:52  iter: 21079  total_loss: 1.319  loss_cls: 0.3458  loss_box_reg: 0.3931  loss_mask: 0.282  loss_rpn_cls: 0.119  loss_rpn_loc: 0.1953  time: 0.2239  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:30:36 d2.utils.events]: \u001b[0m eta: 4:32:41  iter: 21099  total_loss: 1.285  loss_cls: 0.3241  loss_box_reg: 0.4272  loss_mask: 0.2643  loss_rpn_cls: 0.085  loss_rpn_loc: 0.2066  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:30:41 d2.utils.events]: \u001b[0m eta: 4:32:37  iter: 21119  total_loss: 1.051  loss_cls: 0.2276  loss_box_reg: 0.3337  loss_mask: 0.2568  loss_rpn_cls: 0.07418  loss_rpn_loc: 0.1521  time: 0.2240  data_time: 0.0170  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:30:45 d2.utils.events]: \u001b[0m eta: 4:32:30  iter: 21139  total_loss: 1.275  loss_cls: 0.3218  loss_box_reg: 0.387  loss_mask: 0.262  loss_rpn_cls: 0.07088  loss_rpn_loc: 0.1733  time: 0.2240  data_time: 0.0102  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:30:50 d2.utils.events]: \u001b[0m eta: 4:32:11  iter: 21159  total_loss: 1.226  loss_cls: 0.3048  loss_box_reg: 0.4303  loss_mask: 0.2666  loss_rpn_cls: 0.07534  loss_rpn_loc: 0.1677  time: 0.2240  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:30:54 d2.utils.events]: \u001b[0m eta: 4:32:06  iter: 21179  total_loss: 1.209  loss_cls: 0.2699  loss_box_reg: 0.3801  loss_mask: 0.2558  loss_rpn_cls: 0.09055  loss_rpn_loc: 0.1838  time: 0.2240  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:30:59 d2.utils.events]: \u001b[0m eta: 4:32:17  iter: 21199  total_loss: 1.248  loss_cls: 0.3148  loss_box_reg: 0.4194  loss_mask: 0.2686  loss_rpn_cls: 0.09935  loss_rpn_loc: 0.1757  time: 0.2240  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:31:03 d2.utils.events]: \u001b[0m eta: 4:32:12  iter: 21219  total_loss: 1.183  loss_cls: 0.2758  loss_box_reg: 0.3433  loss_mask: 0.2417  loss_rpn_cls: 0.06866  loss_rpn_loc: 0.172  time: 0.2240  data_time: 0.0095  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:31:08 d2.utils.events]: \u001b[0m eta: 4:32:25  iter: 21239  total_loss: 1.302  loss_cls: 0.3249  loss_box_reg: 0.4046  loss_mask: 0.2765  loss_rpn_cls: 0.0899  loss_rpn_loc: 0.1808  time: 0.2240  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:31:13 d2.utils.events]: \u001b[0m eta: 4:32:06  iter: 21259  total_loss: 1.282  loss_cls: 0.3231  loss_box_reg: 0.3983  loss_mask: 0.257  loss_rpn_cls: 0.07634  loss_rpn_loc: 0.1776  time: 0.2240  data_time: 0.0220  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:31:17 d2.utils.events]: \u001b[0m eta: 4:31:34  iter: 21279  total_loss: 1.136  loss_cls: 0.3175  loss_box_reg: 0.3806  loss_mask: 0.267  loss_rpn_cls: 0.07845  loss_rpn_loc: 0.1701  time: 0.2240  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:31:22 d2.utils.events]: \u001b[0m eta: 4:31:58  iter: 21299  total_loss: 1.424  loss_cls: 0.3637  loss_box_reg: 0.4063  loss_mask: 0.2783  loss_rpn_cls: 0.09622  loss_rpn_loc: 0.1947  time: 0.2240  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:31:26 d2.utils.events]: \u001b[0m eta: 4:32:00  iter: 21319  total_loss: 1.276  loss_cls: 0.3663  loss_box_reg: 0.3838  loss_mask: 0.2703  loss_rpn_cls: 0.07249  loss_rpn_loc: 0.1775  time: 0.2240  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:31:31 d2.utils.events]: \u001b[0m eta: 4:32:25  iter: 21339  total_loss: 1.162  loss_cls: 0.2836  loss_box_reg: 0.3829  loss_mask: 0.2715  loss_rpn_cls: 0.08261  loss_rpn_loc: 0.1716  time: 0.2240  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:31:35 d2.utils.events]: \u001b[0m eta: 4:32:36  iter: 21359  total_loss: 1.181  loss_cls: 0.3006  loss_box_reg: 0.3929  loss_mask: 0.2628  loss_rpn_cls: 0.07718  loss_rpn_loc: 0.177  time: 0.2240  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:31:40 d2.utils.events]: \u001b[0m eta: 4:32:36  iter: 21379  total_loss: 1.157  loss_cls: 0.2931  loss_box_reg: 0.3855  loss_mask: 0.249  loss_rpn_cls: 0.07418  loss_rpn_loc: 0.1595  time: 0.2240  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:31:44 d2.utils.events]: \u001b[0m eta: 4:32:44  iter: 21399  total_loss: 1.183  loss_cls: 0.3193  loss_box_reg: 0.3702  loss_mask: 0.2632  loss_rpn_cls: 0.07499  loss_rpn_loc: 0.1555  time: 0.2240  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:31:49 d2.utils.events]: \u001b[0m eta: 4:32:40  iter: 21419  total_loss: 1.298  loss_cls: 0.3441  loss_box_reg: 0.4265  loss_mask: 0.2685  loss_rpn_cls: 0.08007  loss_rpn_loc: 0.1625  time: 0.2240  data_time: 0.0220  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:31:53 d2.utils.events]: \u001b[0m eta: 4:32:42  iter: 21439  total_loss: 1.333  loss_cls: 0.3657  loss_box_reg: 0.3956  loss_mask: 0.2579  loss_rpn_cls: 0.1105  loss_rpn_loc: 0.1823  time: 0.2240  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:31:58 d2.utils.events]: \u001b[0m eta: 4:32:50  iter: 21459  total_loss: 1.302  loss_cls: 0.343  loss_box_reg: 0.426  loss_mask: 0.2696  loss_rpn_cls: 0.07569  loss_rpn_loc: 0.1634  time: 0.2240  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:32:02 d2.utils.events]: \u001b[0m eta: 4:33:00  iter: 21479  total_loss: 1.177  loss_cls: 0.2977  loss_box_reg: 0.3554  loss_mask: 0.2478  loss_rpn_cls: 0.05863  loss_rpn_loc: 0.1591  time: 0.2240  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:32:06 d2.utils.events]: \u001b[0m eta: 4:32:29  iter: 21499  total_loss: 1.197  loss_cls: 0.3  loss_box_reg: 0.3826  loss_mask: 0.2788  loss_rpn_cls: 0.05707  loss_rpn_loc: 0.1673  time: 0.2240  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:32:11 d2.utils.events]: \u001b[0m eta: 4:32:37  iter: 21519  total_loss: 1.335  loss_cls: 0.3532  loss_box_reg: 0.4513  loss_mask: 0.286  loss_rpn_cls: 0.08871  loss_rpn_loc: 0.1789  time: 0.2240  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:32:16 d2.utils.events]: \u001b[0m eta: 4:32:44  iter: 21539  total_loss: 1.23  loss_cls: 0.3082  loss_box_reg: 0.3678  loss_mask: 0.2745  loss_rpn_cls: 0.08  loss_rpn_loc: 0.1759  time: 0.2240  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:32:20 d2.utils.events]: \u001b[0m eta: 4:32:46  iter: 21559  total_loss: 1.248  loss_cls: 0.2756  loss_box_reg: 0.3485  loss_mask: 0.2742  loss_rpn_cls: 0.08584  loss_rpn_loc: 0.1776  time: 0.2240  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:32:25 d2.utils.events]: \u001b[0m eta: 4:32:33  iter: 21579  total_loss: 1.266  loss_cls: 0.3211  loss_box_reg: 0.4162  loss_mask: 0.2819  loss_rpn_cls: 0.06758  loss_rpn_loc: 0.1649  time: 0.2240  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:32:29 d2.utils.events]: \u001b[0m eta: 4:32:21  iter: 21599  total_loss: 1.264  loss_cls: 0.3196  loss_box_reg: 0.4062  loss_mask: 0.2822  loss_rpn_cls: 0.08246  loss_rpn_loc: 0.1705  time: 0.2240  data_time: 0.0227  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:32:34 d2.utils.events]: \u001b[0m eta: 4:32:03  iter: 21619  total_loss: 1.229  loss_cls: 0.3089  loss_box_reg: 0.3819  loss_mask: 0.2568  loss_rpn_cls: 0.04869  loss_rpn_loc: 0.1486  time: 0.2240  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:32:38 d2.utils.events]: \u001b[0m eta: 4:31:51  iter: 21639  total_loss: 1.456  loss_cls: 0.363  loss_box_reg: 0.4384  loss_mask: 0.2791  loss_rpn_cls: 0.09468  loss_rpn_loc: 0.1837  time: 0.2240  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:32:43 d2.utils.events]: \u001b[0m eta: 4:31:59  iter: 21659  total_loss: 1.22  loss_cls: 0.2788  loss_box_reg: 0.3798  loss_mask: 0.2586  loss_rpn_cls: 0.0809  loss_rpn_loc: 0.169  time: 0.2240  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:32:48 d2.utils.events]: \u001b[0m eta: 4:32:13  iter: 21679  total_loss: 1.329  loss_cls: 0.313  loss_box_reg: 0.3938  loss_mask: 0.2746  loss_rpn_cls: 0.1117  loss_rpn_loc: 0.1917  time: 0.2240  data_time: 0.0145  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:32:52 d2.utils.events]: \u001b[0m eta: 4:32:27  iter: 21699  total_loss: 1.145  loss_cls: 0.2381  loss_box_reg: 0.3483  loss_mask: 0.2638  loss_rpn_cls: 0.07428  loss_rpn_loc: 0.1627  time: 0.2240  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:32:56 d2.utils.events]: \u001b[0m eta: 4:32:22  iter: 21719  total_loss: 1.299  loss_cls: 0.3062  loss_box_reg: 0.3758  loss_mask: 0.2887  loss_rpn_cls: 0.08258  loss_rpn_loc: 0.17  time: 0.2240  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:33:01 d2.utils.events]: \u001b[0m eta: 4:32:19  iter: 21739  total_loss: 1.201  loss_cls: 0.2673  loss_box_reg: 0.3561  loss_mask: 0.2516  loss_rpn_cls: 0.09243  loss_rpn_loc: 0.1704  time: 0.2240  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:33:05 d2.utils.events]: \u001b[0m eta: 4:32:15  iter: 21759  total_loss: 1.313  loss_cls: 0.3426  loss_box_reg: 0.4748  loss_mask: 0.2735  loss_rpn_cls: 0.08833  loss_rpn_loc: 0.171  time: 0.2240  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:33:10 d2.utils.events]: \u001b[0m eta: 4:32:10  iter: 21779  total_loss: 1.214  loss_cls: 0.3004  loss_box_reg: 0.3911  loss_mask: 0.2554  loss_rpn_cls: 0.09059  loss_rpn_loc: 0.1639  time: 0.2240  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:33:14 d2.utils.events]: \u001b[0m eta: 4:32:17  iter: 21799  total_loss: 1.311  loss_cls: 0.3337  loss_box_reg: 0.4438  loss_mask: 0.3048  loss_rpn_cls: 0.09364  loss_rpn_loc: 0.1887  time: 0.2240  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:33:19 d2.utils.events]: \u001b[0m eta: 4:32:45  iter: 21819  total_loss: 1.25  loss_cls: 0.2932  loss_box_reg: 0.4217  loss_mask: 0.2695  loss_rpn_cls: 0.09136  loss_rpn_loc: 0.1697  time: 0.2240  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:33:23 d2.utils.events]: \u001b[0m eta: 4:32:41  iter: 21839  total_loss: 1.176  loss_cls: 0.2902  loss_box_reg: 0.3998  loss_mask: 0.257  loss_rpn_cls: 0.05812  loss_rpn_loc: 0.1732  time: 0.2240  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:33:28 d2.utils.events]: \u001b[0m eta: 4:32:59  iter: 21859  total_loss: 1.37  loss_cls: 0.3482  loss_box_reg: 0.3834  loss_mask: 0.2975  loss_rpn_cls: 0.1085  loss_rpn_loc: 0.199  time: 0.2240  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:33:33 d2.utils.events]: \u001b[0m eta: 4:32:39  iter: 21879  total_loss: 1.249  loss_cls: 0.3068  loss_box_reg: 0.3782  loss_mask: 0.276  loss_rpn_cls: 0.1042  loss_rpn_loc: 0.183  time: 0.2240  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:33:37 d2.utils.events]: \u001b[0m eta: 4:32:20  iter: 21899  total_loss: 1.218  loss_cls: 0.3104  loss_box_reg: 0.3759  loss_mask: 0.262  loss_rpn_cls: 0.08401  loss_rpn_loc: 0.1668  time: 0.2240  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:33:41 d2.utils.events]: \u001b[0m eta: 4:31:51  iter: 21919  total_loss: 1.245  loss_cls: 0.319  loss_box_reg: 0.4071  loss_mask: 0.26  loss_rpn_cls: 0.06576  loss_rpn_loc: 0.1963  time: 0.2240  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:33:46 d2.utils.events]: \u001b[0m eta: 4:31:46  iter: 21939  total_loss: 1.256  loss_cls: 0.3186  loss_box_reg: 0.4104  loss_mask: 0.2609  loss_rpn_cls: 0.06411  loss_rpn_loc: 0.175  time: 0.2240  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:33:50 d2.utils.events]: \u001b[0m eta: 4:31:40  iter: 21959  total_loss: 1.305  loss_cls: 0.3355  loss_box_reg: 0.4001  loss_mask: 0.2711  loss_rpn_cls: 0.07318  loss_rpn_loc: 0.1893  time: 0.2240  data_time: 0.0152  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:33:55 d2.utils.events]: \u001b[0m eta: 4:31:28  iter: 21979  total_loss: 1.248  loss_cls: 0.3105  loss_box_reg: 0.4175  loss_mask: 0.2601  loss_rpn_cls: 0.0834  loss_rpn_loc: 0.1655  time: 0.2240  data_time: 0.0120  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:33:59 d2.utils.events]: \u001b[0m eta: 4:31:27  iter: 21999  total_loss: 1.232  loss_cls: 0.3019  loss_box_reg: 0.3943  loss_mask: 0.2635  loss_rpn_cls: 0.09966  loss_rpn_loc: 0.1792  time: 0.2240  data_time: 0.0162  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:34:04 d2.utils.events]: \u001b[0m eta: 4:31:17  iter: 22019  total_loss: 1.248  loss_cls: 0.3075  loss_box_reg: 0.4096  loss_mask: 0.2622  loss_rpn_cls: 0.09135  loss_rpn_loc: 0.1711  time: 0.2240  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:34:08 d2.utils.events]: \u001b[0m eta: 4:30:52  iter: 22039  total_loss: 1.316  loss_cls: 0.3476  loss_box_reg: 0.3971  loss_mask: 0.2764  loss_rpn_cls: 0.08704  loss_rpn_loc: 0.1906  time: 0.2240  data_time: 0.0090  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:34:13 d2.utils.events]: \u001b[0m eta: 4:30:48  iter: 22059  total_loss: 1.269  loss_cls: 0.3158  loss_box_reg: 0.4193  loss_mask: 0.2766  loss_rpn_cls: 0.105  loss_rpn_loc: 0.1801  time: 0.2240  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:34:17 d2.utils.events]: \u001b[0m eta: 4:31:05  iter: 22079  total_loss: 1.275  loss_cls: 0.3247  loss_box_reg: 0.3771  loss_mask: 0.2477  loss_rpn_cls: 0.08977  loss_rpn_loc: 0.1693  time: 0.2240  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:34:22 d2.utils.events]: \u001b[0m eta: 4:31:08  iter: 22099  total_loss: 1.303  loss_cls: 0.3322  loss_box_reg: 0.3723  loss_mask: 0.2859  loss_rpn_cls: 0.0995  loss_rpn_loc: 0.1852  time: 0.2240  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:34:26 d2.utils.events]: \u001b[0m eta: 4:31:12  iter: 22119  total_loss: 1.128  loss_cls: 0.2675  loss_box_reg: 0.3709  loss_mask: 0.2524  loss_rpn_cls: 0.06618  loss_rpn_loc: 0.1721  time: 0.2240  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:34:31 d2.utils.events]: \u001b[0m eta: 4:30:59  iter: 22139  total_loss: 1.277  loss_cls: 0.3462  loss_box_reg: 0.4091  loss_mask: 0.2669  loss_rpn_cls: 0.08425  loss_rpn_loc: 0.1664  time: 0.2240  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:34:35 d2.utils.events]: \u001b[0m eta: 4:30:54  iter: 22159  total_loss: 1.208  loss_cls: 0.2986  loss_box_reg: 0.4154  loss_mask: 0.2728  loss_rpn_cls: 0.07016  loss_rpn_loc: 0.1705  time: 0.2240  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:34:39 d2.utils.events]: \u001b[0m eta: 4:30:47  iter: 22179  total_loss: 1.22  loss_cls: 0.3001  loss_box_reg: 0.408  loss_mask: 0.2763  loss_rpn_cls: 0.06464  loss_rpn_loc: 0.1703  time: 0.2240  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:34:44 d2.utils.events]: \u001b[0m eta: 4:30:31  iter: 22199  total_loss: 1.288  loss_cls: 0.3238  loss_box_reg: 0.4278  loss_mask: 0.2728  loss_rpn_cls: 0.09906  loss_rpn_loc: 0.1664  time: 0.2240  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:34:48 d2.utils.events]: \u001b[0m eta: 4:30:26  iter: 22219  total_loss: 1.212  loss_cls: 0.284  loss_box_reg: 0.4072  loss_mask: 0.2783  loss_rpn_cls: 0.09736  loss_rpn_loc: 0.185  time: 0.2240  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:34:53 d2.utils.events]: \u001b[0m eta: 4:30:22  iter: 22239  total_loss: 1.243  loss_cls: 0.3036  loss_box_reg: 0.3648  loss_mask: 0.2583  loss_rpn_cls: 0.06207  loss_rpn_loc: 0.165  time: 0.2240  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:34:57 d2.utils.events]: \u001b[0m eta: 4:30:17  iter: 22259  total_loss: 1.27  loss_cls: 0.3419  loss_box_reg: 0.4175  loss_mask: 0.2776  loss_rpn_cls: 0.08184  loss_rpn_loc: 0.1673  time: 0.2240  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:35:02 d2.utils.events]: \u001b[0m eta: 4:30:27  iter: 22279  total_loss: 1.217  loss_cls: 0.2796  loss_box_reg: 0.3649  loss_mask: 0.2817  loss_rpn_cls: 0.07604  loss_rpn_loc: 0.1825  time: 0.2240  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:35:07 d2.utils.events]: \u001b[0m eta: 4:30:24  iter: 22299  total_loss: 1.295  loss_cls: 0.3282  loss_box_reg: 0.4221  loss_mask: 0.2951  loss_rpn_cls: 0.09381  loss_rpn_loc: 0.1871  time: 0.2240  data_time: 0.0180  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:35:11 d2.utils.events]: \u001b[0m eta: 4:30:12  iter: 22319  total_loss: 1.284  loss_cls: 0.3461  loss_box_reg: 0.398  loss_mask: 0.2692  loss_rpn_cls: 0.1132  loss_rpn_loc: 0.181  time: 0.2240  data_time: 0.0160  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:35:16 d2.utils.events]: \u001b[0m eta: 4:30:04  iter: 22339  total_loss: 1.261  loss_cls: 0.3166  loss_box_reg: 0.4067  loss_mask: 0.2822  loss_rpn_cls: 0.08635  loss_rpn_loc: 0.1884  time: 0.2240  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:35:20 d2.utils.events]: \u001b[0m eta: 4:29:48  iter: 22359  total_loss: 1.308  loss_cls: 0.323  loss_box_reg: 0.4094  loss_mask: 0.2624  loss_rpn_cls: 0.07573  loss_rpn_loc: 0.1748  time: 0.2240  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:35:25 d2.utils.events]: \u001b[0m eta: 4:29:36  iter: 22379  total_loss: 1.153  loss_cls: 0.2994  loss_box_reg: 0.3757  loss_mask: 0.2688  loss_rpn_cls: 0.08523  loss_rpn_loc: 0.1696  time: 0.2240  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:35:29 d2.utils.events]: \u001b[0m eta: 4:28:57  iter: 22399  total_loss: 1.231  loss_cls: 0.3042  loss_box_reg: 0.3886  loss_mask: 0.2466  loss_rpn_cls: 0.07279  loss_rpn_loc: 0.184  time: 0.2240  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:35:33 d2.utils.events]: \u001b[0m eta: 4:28:50  iter: 22419  total_loss: 1.202  loss_cls: 0.2721  loss_box_reg: 0.3685  loss_mask: 0.2625  loss_rpn_cls: 0.07896  loss_rpn_loc: 0.1573  time: 0.2240  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:35:38 d2.utils.events]: \u001b[0m eta: 4:28:45  iter: 22439  total_loss: 1.276  loss_cls: 0.2949  loss_box_reg: 0.3963  loss_mask: 0.278  loss_rpn_cls: 0.08772  loss_rpn_loc: 0.1712  time: 0.2240  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:35:42 d2.utils.events]: \u001b[0m eta: 4:28:38  iter: 22459  total_loss: 1.385  loss_cls: 0.3461  loss_box_reg: 0.4344  loss_mask: 0.2639  loss_rpn_cls: 0.07414  loss_rpn_loc: 0.1765  time: 0.2240  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:35:47 d2.utils.events]: \u001b[0m eta: 4:28:29  iter: 22479  total_loss: 1.26  loss_cls: 0.2923  loss_box_reg: 0.3919  loss_mask: 0.2737  loss_rpn_cls: 0.08888  loss_rpn_loc: 0.1725  time: 0.2240  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:35:51 d2.utils.events]: \u001b[0m eta: 4:28:35  iter: 22499  total_loss: 1.155  loss_cls: 0.2731  loss_box_reg: 0.3559  loss_mask: 0.2625  loss_rpn_cls: 0.08635  loss_rpn_loc: 0.1759  time: 0.2240  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:35:55 d2.utils.events]: \u001b[0m eta: 4:28:30  iter: 22519  total_loss: 1.17  loss_cls: 0.2781  loss_box_reg: 0.3967  loss_mask: 0.2524  loss_rpn_cls: 0.05455  loss_rpn_loc: 0.1515  time: 0.2240  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:36:00 d2.utils.events]: \u001b[0m eta: 4:28:23  iter: 22539  total_loss: 1.223  loss_cls: 0.2924  loss_box_reg: 0.4272  loss_mask: 0.2746  loss_rpn_cls: 0.07672  loss_rpn_loc: 0.1657  time: 0.2240  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:36:04 d2.utils.events]: \u001b[0m eta: 4:28:13  iter: 22559  total_loss: 1.221  loss_cls: 0.2822  loss_box_reg: 0.3825  loss_mask: 0.2686  loss_rpn_cls: 0.07095  loss_rpn_loc: 0.1585  time: 0.2240  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:36:09 d2.utils.events]: \u001b[0m eta: 4:28:26  iter: 22579  total_loss: 1.338  loss_cls: 0.367  loss_box_reg: 0.4181  loss_mask: 0.2879  loss_rpn_cls: 0.1009  loss_rpn_loc: 0.1721  time: 0.2240  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:36:14 d2.utils.events]: \u001b[0m eta: 4:28:26  iter: 22599  total_loss: 1.321  loss_cls: 0.3288  loss_box_reg: 0.4096  loss_mask: 0.2736  loss_rpn_cls: 0.085  loss_rpn_loc: 0.185  time: 0.2240  data_time: 0.0290  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:36:19 d2.utils.events]: \u001b[0m eta: 4:28:51  iter: 22619  total_loss: 1.051  loss_cls: 0.2612  loss_box_reg: 0.3399  loss_mask: 0.2344  loss_rpn_cls: 0.06191  loss_rpn_loc: 0.1606  time: 0.2240  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:36:23 d2.utils.events]: \u001b[0m eta: 4:29:07  iter: 22639  total_loss: 1.2  loss_cls: 0.2729  loss_box_reg: 0.3688  loss_mask: 0.2648  loss_rpn_cls: 0.07755  loss_rpn_loc: 0.1808  time: 0.2240  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:36:28 d2.utils.events]: \u001b[0m eta: 4:29:02  iter: 22659  total_loss: 1.19  loss_cls: 0.2461  loss_box_reg: 0.377  loss_mask: 0.2754  loss_rpn_cls: 0.08054  loss_rpn_loc: 0.1729  time: 0.2240  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:36:32 d2.utils.events]: \u001b[0m eta: 4:28:46  iter: 22679  total_loss: 1.258  loss_cls: 0.3148  loss_box_reg: 0.3878  loss_mask: 0.2719  loss_rpn_cls: 0.08547  loss_rpn_loc: 0.1724  time: 0.2240  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:36:37 d2.utils.events]: \u001b[0m eta: 4:28:19  iter: 22699  total_loss: 1.31  loss_cls: 0.3289  loss_box_reg: 0.4018  loss_mask: 0.2722  loss_rpn_cls: 0.102  loss_rpn_loc: 0.1774  time: 0.2240  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:36:41 d2.utils.events]: \u001b[0m eta: 4:28:01  iter: 22719  total_loss: 1.189  loss_cls: 0.3359  loss_box_reg: 0.3954  loss_mask: 0.2649  loss_rpn_cls: 0.07853  loss_rpn_loc: 0.1623  time: 0.2240  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:36:45 d2.utils.events]: \u001b[0m eta: 4:27:56  iter: 22739  total_loss: 1.185  loss_cls: 0.2957  loss_box_reg: 0.3899  loss_mask: 0.2672  loss_rpn_cls: 0.08057  loss_rpn_loc: 0.1717  time: 0.2240  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:36:50 d2.utils.events]: \u001b[0m eta: 4:27:54  iter: 22759  total_loss: 1.248  loss_cls: 0.296  loss_box_reg: 0.3746  loss_mask: 0.2777  loss_rpn_cls: 0.06709  loss_rpn_loc: 0.1736  time: 0.2240  data_time: 0.0184  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:36:55 d2.utils.events]: \u001b[0m eta: 4:28:11  iter: 22779  total_loss: 1.308  loss_cls: 0.3578  loss_box_reg: 0.4062  loss_mask: 0.2907  loss_rpn_cls: 0.08899  loss_rpn_loc: 0.1703  time: 0.2240  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:37:00 d2.utils.events]: \u001b[0m eta: 4:28:12  iter: 22799  total_loss: 1.19  loss_cls: 0.2815  loss_box_reg: 0.3877  loss_mask: 0.2437  loss_rpn_cls: 0.07918  loss_rpn_loc: 0.1716  time: 0.2240  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:37:04 d2.utils.events]: \u001b[0m eta: 4:27:40  iter: 22819  total_loss: 1.32  loss_cls: 0.3357  loss_box_reg: 0.4285  loss_mask: 0.2705  loss_rpn_cls: 0.07656  loss_rpn_loc: 0.1667  time: 0.2240  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:37:08 d2.utils.events]: \u001b[0m eta: 4:27:36  iter: 22839  total_loss: 1.082  loss_cls: 0.2712  loss_box_reg: 0.4032  loss_mask: 0.243  loss_rpn_cls: 0.05891  loss_rpn_loc: 0.1579  time: 0.2240  data_time: 0.0157  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:37:13 d2.utils.events]: \u001b[0m eta: 4:27:27  iter: 22859  total_loss: 1.208  loss_cls: 0.2882  loss_box_reg: 0.3953  loss_mask: 0.255  loss_rpn_cls: 0.05802  loss_rpn_loc: 0.1774  time: 0.2240  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:37:17 d2.utils.events]: \u001b[0m eta: 4:27:28  iter: 22879  total_loss: 1.216  loss_cls: 0.2889  loss_box_reg: 0.4005  loss_mask: 0.2583  loss_rpn_cls: 0.07512  loss_rpn_loc: 0.1732  time: 0.2240  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:37:22 d2.utils.events]: \u001b[0m eta: 4:27:45  iter: 22899  total_loss: 1.178  loss_cls: 0.3237  loss_box_reg: 0.3924  loss_mask: 0.2567  loss_rpn_cls: 0.06988  loss_rpn_loc: 0.1627  time: 0.2240  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:37:26 d2.utils.events]: \u001b[0m eta: 4:28:04  iter: 22919  total_loss: 1.231  loss_cls: 0.2958  loss_box_reg: 0.3761  loss_mask: 0.268  loss_rpn_cls: 0.06845  loss_rpn_loc: 0.1833  time: 0.2240  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:37:31 d2.utils.events]: \u001b[0m eta: 4:28:07  iter: 22939  total_loss: 1.198  loss_cls: 0.2799  loss_box_reg: 0.3661  loss_mask: 0.2644  loss_rpn_cls: 0.08825  loss_rpn_loc: 0.1672  time: 0.2240  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:37:36 d2.utils.events]: \u001b[0m eta: 4:28:15  iter: 22959  total_loss: 1.108  loss_cls: 0.2389  loss_box_reg: 0.3385  loss_mask: 0.2394  loss_rpn_cls: 0.09331  loss_rpn_loc: 0.1837  time: 0.2241  data_time: 0.0202  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:37:40 d2.utils.events]: \u001b[0m eta: 4:28:10  iter: 22979  total_loss: 1.165  loss_cls: 0.2777  loss_box_reg: 0.3985  loss_mask: 0.2566  loss_rpn_cls: 0.06493  loss_rpn_loc: 0.1721  time: 0.2240  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:37:44 d2.utils.events]: \u001b[0m eta: 4:27:35  iter: 22999  total_loss: 1.174  loss_cls: 0.2826  loss_box_reg: 0.4242  loss_mask: 0.2638  loss_rpn_cls: 0.06354  loss_rpn_loc: 0.16  time: 0.2240  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:37:49 d2.utils.events]: \u001b[0m eta: 4:27:42  iter: 23019  total_loss: 1.185  loss_cls: 0.2802  loss_box_reg: 0.3864  loss_mask: 0.2581  loss_rpn_cls: 0.07162  loss_rpn_loc: 0.1585  time: 0.2240  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:37:53 d2.utils.events]: \u001b[0m eta: 4:27:57  iter: 23039  total_loss: 1.22  loss_cls: 0.3091  loss_box_reg: 0.3806  loss_mask: 0.2809  loss_rpn_cls: 0.05924  loss_rpn_loc: 0.163  time: 0.2240  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:37:58 d2.utils.events]: \u001b[0m eta: 4:27:41  iter: 23059  total_loss: 1.338  loss_cls: 0.3395  loss_box_reg: 0.4145  loss_mask: 0.2824  loss_rpn_cls: 0.1169  loss_rpn_loc: 0.1765  time: 0.2240  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:38:02 d2.utils.events]: \u001b[0m eta: 4:27:01  iter: 23079  total_loss: 1.204  loss_cls: 0.2979  loss_box_reg: 0.3871  loss_mask: 0.2683  loss_rpn_cls: 0.07313  loss_rpn_loc: 0.1718  time: 0.2240  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:38:07 d2.utils.events]: \u001b[0m eta: 4:26:40  iter: 23099  total_loss: 1.057  loss_cls: 0.2771  loss_box_reg: 0.3401  loss_mask: 0.2414  loss_rpn_cls: 0.05643  loss_rpn_loc: 0.1563  time: 0.2240  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:38:11 d2.utils.events]: \u001b[0m eta: 4:26:27  iter: 23119  total_loss: 1.417  loss_cls: 0.3459  loss_box_reg: 0.4666  loss_mask: 0.2893  loss_rpn_cls: 0.1095  loss_rpn_loc: 0.2031  time: 0.2240  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:38:16 d2.utils.events]: \u001b[0m eta: 4:26:26  iter: 23139  total_loss: 1.178  loss_cls: 0.2905  loss_box_reg: 0.3624  loss_mask: 0.2625  loss_rpn_cls: 0.08327  loss_rpn_loc: 0.1869  time: 0.2240  data_time: 0.0149  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:38:20 d2.utils.events]: \u001b[0m eta: 4:26:22  iter: 23159  total_loss: 1.25  loss_cls: 0.3083  loss_box_reg: 0.4131  loss_mask: 0.2687  loss_rpn_cls: 0.05591  loss_rpn_loc: 0.156  time: 0.2240  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:38:25 d2.utils.events]: \u001b[0m eta: 4:26:34  iter: 23179  total_loss: 1.358  loss_cls: 0.3469  loss_box_reg: 0.4015  loss_mask: 0.2717  loss_rpn_cls: 0.08588  loss_rpn_loc: 0.1691  time: 0.2240  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:38:29 d2.utils.events]: \u001b[0m eta: 4:26:38  iter: 23199  total_loss: 1.237  loss_cls: 0.2994  loss_box_reg: 0.3834  loss_mask: 0.2662  loss_rpn_cls: 0.07639  loss_rpn_loc: 0.1644  time: 0.2240  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:38:33 d2.utils.events]: \u001b[0m eta: 4:26:14  iter: 23219  total_loss: 1.262  loss_cls: 0.2993  loss_box_reg: 0.3925  loss_mask: 0.2555  loss_rpn_cls: 0.09054  loss_rpn_loc: 0.1745  time: 0.2240  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:38:38 d2.utils.events]: \u001b[0m eta: 4:26:05  iter: 23239  total_loss: 1.267  loss_cls: 0.3316  loss_box_reg: 0.3985  loss_mask: 0.2759  loss_rpn_cls: 0.06573  loss_rpn_loc: 0.1669  time: 0.2240  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:38:42 d2.utils.events]: \u001b[0m eta: 4:25:53  iter: 23259  total_loss: 1.238  loss_cls: 0.3165  loss_box_reg: 0.4311  loss_mask: 0.2504  loss_rpn_cls: 0.05564  loss_rpn_loc: 0.1611  time: 0.2240  data_time: 0.0179  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:38:47 d2.utils.events]: \u001b[0m eta: 4:25:48  iter: 23279  total_loss: 1.226  loss_cls: 0.3475  loss_box_reg: 0.3445  loss_mask: 0.2486  loss_rpn_cls: 0.07796  loss_rpn_loc: 0.175  time: 0.2240  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:38:51 d2.utils.events]: \u001b[0m eta: 4:25:04  iter: 23299  total_loss: 1.144  loss_cls: 0.2884  loss_box_reg: 0.4198  loss_mask: 0.2459  loss_rpn_cls: 0.07477  loss_rpn_loc: 0.1524  time: 0.2240  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:38:56 d2.utils.events]: \u001b[0m eta: 4:25:02  iter: 23319  total_loss: 1.152  loss_cls: 0.2969  loss_box_reg: 0.3921  loss_mask: 0.2712  loss_rpn_cls: 0.07066  loss_rpn_loc: 0.1645  time: 0.2240  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:39:01 d2.utils.events]: \u001b[0m eta: 4:25:22  iter: 23339  total_loss: 1.236  loss_cls: 0.3141  loss_box_reg: 0.3873  loss_mask: 0.2808  loss_rpn_cls: 0.07573  loss_rpn_loc: 0.1567  time: 0.2240  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:39:05 d2.utils.events]: \u001b[0m eta: 4:25:43  iter: 23359  total_loss: 1.201  loss_cls: 0.2866  loss_box_reg: 0.369  loss_mask: 0.2563  loss_rpn_cls: 0.08644  loss_rpn_loc: 0.1698  time: 0.2240  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:39:10 d2.utils.events]: \u001b[0m eta: 4:25:43  iter: 23379  total_loss: 1.123  loss_cls: 0.2742  loss_box_reg: 0.3539  loss_mask: 0.2765  loss_rpn_cls: 0.06732  loss_rpn_loc: 0.1774  time: 0.2240  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:39:14 d2.utils.events]: \u001b[0m eta: 4:25:34  iter: 23399  total_loss: 1.299  loss_cls: 0.3418  loss_box_reg: 0.418  loss_mask: 0.2691  loss_rpn_cls: 0.06896  loss_rpn_loc: 0.1772  time: 0.2240  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:39:18 d2.utils.events]: \u001b[0m eta: 4:25:43  iter: 23419  total_loss: 1.157  loss_cls: 0.313  loss_box_reg: 0.3744  loss_mask: 0.2667  loss_rpn_cls: 0.07509  loss_rpn_loc: 0.1685  time: 0.2240  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:39:23 d2.utils.events]: \u001b[0m eta: 4:25:26  iter: 23439  total_loss: 1.134  loss_cls: 0.2945  loss_box_reg: 0.3964  loss_mask: 0.2551  loss_rpn_cls: 0.06586  loss_rpn_loc: 0.1655  time: 0.2240  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:39:27 d2.utils.events]: \u001b[0m eta: 4:25:35  iter: 23459  total_loss: 1.287  loss_cls: 0.3351  loss_box_reg: 0.4063  loss_mask: 0.2853  loss_rpn_cls: 0.0877  loss_rpn_loc: 0.1923  time: 0.2240  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:40:39 d2.utils.events]: \u001b[0m eta: 4:24:26  iter: 23779  total_loss: 1.245  loss_cls: 0.2975  loss_box_reg: 0.3744  loss_mask: 0.2843  loss_rpn_cls: 0.09605  loss_rpn_loc: 0.1739  time: 0.2240  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:40:44 d2.utils.events]: \u001b[0m eta: 4:24:29  iter: 23799  total_loss: 1.292  loss_cls: 0.2973  loss_box_reg: 0.3948  loss_mask: 0.2684  loss_rpn_cls: 0.08061  loss_rpn_loc: 0.1819  time: 0.2240  data_time: 0.0241  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:40:48 d2.utils.events]: \u001b[0m eta: 4:24:25  iter: 23819  total_loss: 1.305  loss_cls: 0.3436  loss_box_reg: 0.4171  loss_mask: 0.2684  loss_rpn_cls: 0.07339  loss_rpn_loc: 0.1707  time: 0.2240  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:40:53 d2.utils.events]: \u001b[0m eta: 4:24:21  iter: 23839  total_loss: 1.201  loss_cls: 0.2856  loss_box_reg: 0.3754  loss_mask: 0.2634  loss_rpn_cls: 0.08957  loss_rpn_loc: 0.1735  time: 0.2240  data_time: 0.0105  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:40:57 d2.utils.events]: \u001b[0m eta: 4:24:16  iter: 23859  total_loss: 1.308  loss_cls: 0.3531  loss_box_reg: 0.4455  loss_mask: 0.2797  loss_rpn_cls: 0.07422  loss_rpn_loc: 0.1948  time: 0.2240  data_time: 0.0148  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:41:02 d2.utils.events]: \u001b[0m eta: 4:23:50  iter: 23879  total_loss: 1.176  loss_cls: 0.278  loss_box_reg: 0.3634  loss_mask: 0.2594  loss_rpn_cls: 0.06512  loss_rpn_loc: 0.164  time: 0.2240  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:41:06 d2.utils.events]: \u001b[0m eta: 4:23:39  iter: 23899  total_loss: 1.291  loss_cls: 0.3333  loss_box_reg: 0.4367  loss_mask: 0.2905  loss_rpn_cls: 0.07028  loss_rpn_loc: 0.1621  time: 0.2240  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:41:10 d2.utils.events]: \u001b[0m eta: 4:22:54  iter: 23919  total_loss: 1.359  loss_cls: 0.3579  loss_box_reg: 0.4335  loss_mask: 0.2855  loss_rpn_cls: 0.09925  loss_rpn_loc: 0.1788  time: 0.2240  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:41:15 d2.utils.events]: \u001b[0m eta: 4:22:50  iter: 23939  total_loss: 1.235  loss_cls: 0.2895  loss_box_reg: 0.4024  loss_mask: 0.2658  loss_rpn_cls: 0.08982  loss_rpn_loc: 0.1771  time: 0.2240  data_time: 0.0093  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:41:20 d2.utils.events]: \u001b[0m eta: 4:22:56  iter: 23959  total_loss: 1.05  loss_cls: 0.2315  loss_box_reg: 0.3499  loss_mask: 0.2592  loss_rpn_cls: 0.06583  loss_rpn_loc: 0.1701  time: 0.2240  data_time: 0.0099  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:41:24 d2.utils.events]: \u001b[0m eta: 4:22:52  iter: 23979  total_loss: 1.198  loss_cls: 0.3134  loss_box_reg: 0.3988  loss_mask: 0.276  loss_rpn_cls: 0.07074  loss_rpn_loc: 0.1785  time: 0.2240  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:41:28 d2.utils.events]: \u001b[0m eta: 4:23:22  iter: 23999  total_loss: 1.064  loss_cls: 0.284  loss_box_reg: 0.3602  loss_mask: 0.2377  loss_rpn_cls: 0.07518  loss_rpn_loc: 0.1551  time: 0.2240  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:41:33 d2.utils.events]: \u001b[0m eta: 4:23:18  iter: 24019  total_loss: 1.214  loss_cls: 0.3051  loss_box_reg: 0.43  loss_mask: 0.2621  loss_rpn_cls: 0.09305  loss_rpn_loc: 0.1631  time: 0.2240  data_time: 0.0095  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:41:37 d2.utils.events]: \u001b[0m eta: 4:23:00  iter: 24039  total_loss: 1.115  loss_cls: 0.2748  loss_box_reg: 0.3693  loss_mask: 0.2465  loss_rpn_cls: 0.07589  loss_rpn_loc: 0.1632  time: 0.2240  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:41:42 d2.utils.events]: \u001b[0m eta: 4:23:04  iter: 24059  total_loss: 1.251  loss_cls: 0.3252  loss_box_reg: 0.4079  loss_mask: 0.2807  loss_rpn_cls: 0.07833  loss_rpn_loc: 0.1611  time: 0.2240  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:41:46 d2.utils.events]: \u001b[0m eta: 4:23:26  iter: 24079  total_loss: 1.142  loss_cls: 0.2696  loss_box_reg: 0.3899  loss_mask: 0.2568  loss_rpn_cls: 0.06904  loss_rpn_loc: 0.1627  time: 0.2240  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:41:50 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.43 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/29 22:41:50 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/29 22:41:50 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/29 22:41:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:41:51 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 22:41:51 d2.data.common]: \u001b[0mSerialized dataset takes 84.20 MiB\n",
      "\u001b[32m[12/29 22:41:54 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.51 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/29 22:41:54 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/29 22:41:54 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/29 22:41:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/29 22:41:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0007 s/iter. Inference: 0.0620 s/iter. Eval: 0.1443 s/iter. Total: 0.2070 s/iter. ETA=0:01:55\n",
      "\u001b[32m[12/29 22:42:03 d2.evaluation.evaluator]: \u001b[0mInference done 39/570. Dataloading: 0.0008 s/iter. Inference: 0.0554 s/iter. Eval: 0.1287 s/iter. Total: 0.1849 s/iter. ETA=0:01:38\n",
      "\u001b[32m[12/29 22:42:08 d2.evaluation.evaluator]: \u001b[0mInference done 67/570. Dataloading: 0.0008 s/iter. Inference: 0.0535 s/iter. Eval: 0.1293 s/iter. Total: 0.1838 s/iter. ETA=0:01:32\n",
      "\u001b[32m[12/29 22:42:13 d2.evaluation.evaluator]: \u001b[0mInference done 93/570. Dataloading: 0.0008 s/iter. Inference: 0.0536 s/iter. Eval: 0.1335 s/iter. Total: 0.1879 s/iter. ETA=0:01:29\n",
      "\u001b[32m[12/29 22:42:18 d2.evaluation.evaluator]: \u001b[0mInference done 119/570. Dataloading: 0.0009 s/iter. Inference: 0.0543 s/iter. Eval: 0.1339 s/iter. Total: 0.1891 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/29 22:42:23 d2.evaluation.evaluator]: \u001b[0mInference done 144/570. Dataloading: 0.0009 s/iter. Inference: 0.0544 s/iter. Eval: 0.1361 s/iter. Total: 0.1914 s/iter. ETA=0:01:21\n",
      "\u001b[32m[12/29 22:42:28 d2.evaluation.evaluator]: \u001b[0mInference done 162/570. Dataloading: 0.0009 s/iter. Inference: 0.0547 s/iter. Eval: 0.1461 s/iter. Total: 0.2017 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/29 22:42:33 d2.evaluation.evaluator]: \u001b[0mInference done 175/570. Dataloading: 0.0009 s/iter. Inference: 0.0553 s/iter. Eval: 0.1612 s/iter. Total: 0.2174 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/29 22:42:38 d2.evaluation.evaluator]: \u001b[0mInference done 193/570. Dataloading: 0.0009 s/iter. Inference: 0.0554 s/iter. Eval: 0.1675 s/iter. Total: 0.2238 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/29 22:42:44 d2.evaluation.evaluator]: \u001b[0mInference done 208/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1765 s/iter. Total: 0.2332 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/29 22:42:49 d2.evaluation.evaluator]: \u001b[0mInference done 225/570. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.1816 s/iter. Total: 0.2384 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/29 22:42:54 d2.evaluation.evaluator]: \u001b[0mInference done 236/570. Dataloading: 0.0009 s/iter. Inference: 0.0560 s/iter. Eval: 0.1931 s/iter. Total: 0.2501 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/29 22:43:00 d2.evaluation.evaluator]: \u001b[0mInference done 249/570. Dataloading: 0.0009 s/iter. Inference: 0.0563 s/iter. Eval: 0.2028 s/iter. Total: 0.2601 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/29 22:43:05 d2.evaluation.evaluator]: \u001b[0mInference done 265/570. Dataloading: 0.0009 s/iter. Inference: 0.0565 s/iter. Eval: 0.2066 s/iter. Total: 0.2640 s/iter. ETA=0:01:20\n",
      "\u001b[32m[12/29 22:43:10 d2.evaluation.evaluator]: \u001b[0mInference done 283/570. Dataloading: 0.0009 s/iter. Inference: 0.0563 s/iter. Eval: 0.2081 s/iter. Total: 0.2653 s/iter. ETA=0:01:16\n",
      "\u001b[32m[12/29 22:43:15 d2.evaluation.evaluator]: \u001b[0mInference done 297/570. Dataloading: 0.0009 s/iter. Inference: 0.0564 s/iter. Eval: 0.2125 s/iter. Total: 0.2698 s/iter. ETA=0:01:13\n",
      "\u001b[32m[12/29 22:43:20 d2.evaluation.evaluator]: \u001b[0mInference done 340/570. Dataloading: 0.0009 s/iter. Inference: 0.0554 s/iter. Eval: 0.1939 s/iter. Total: 0.2502 s/iter. ETA=0:00:57\n",
      "\u001b[32m[12/29 22:43:25 d2.evaluation.evaluator]: \u001b[0mInference done 374/570. Dataloading: 0.0009 s/iter. Inference: 0.0549 s/iter. Eval: 0.1854 s/iter. Total: 0.2413 s/iter. ETA=0:00:47\n",
      "\u001b[32m[12/29 22:43:30 d2.evaluation.evaluator]: \u001b[0mInference done 395/570. Dataloading: 0.0009 s/iter. Inference: 0.0552 s/iter. Eval: 0.1851 s/iter. Total: 0.2412 s/iter. ETA=0:00:42\n",
      "\u001b[32m[12/29 22:43:36 d2.evaluation.evaluator]: \u001b[0mInference done 414/570. Dataloading: 0.0009 s/iter. Inference: 0.0554 s/iter. Eval: 0.1865 s/iter. Total: 0.2428 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 22:43:41 d2.evaluation.evaluator]: \u001b[0mInference done 433/570. Dataloading: 0.0009 s/iter. Inference: 0.0556 s/iter. Eval: 0.1873 s/iter. Total: 0.2438 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/29 22:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 458/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1849 s/iter. Total: 0.2415 s/iter. ETA=0:00:27\n",
      "\u001b[32m[12/29 22:43:51 d2.evaluation.evaluator]: \u001b[0mInference done 493/570. Dataloading: 0.0009 s/iter. Inference: 0.0552 s/iter. Eval: 0.1786 s/iter. Total: 0.2348 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/29 22:43:56 d2.evaluation.evaluator]: \u001b[0mInference done 513/570. Dataloading: 0.0009 s/iter. Inference: 0.0551 s/iter. Eval: 0.1796 s/iter. Total: 0.2356 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 22:44:01 d2.evaluation.evaluator]: \u001b[0mInference done 539/570. Dataloading: 0.0009 s/iter. Inference: 0.0549 s/iter. Eval: 0.1781 s/iter. Total: 0.2340 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/29 22:44:06 d2.evaluation.evaluator]: \u001b[0mInference done 558/570. Dataloading: 0.0009 s/iter. Inference: 0.0551 s/iter. Eval: 0.1791 s/iter. Total: 0.2351 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/29 22:44:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:13.144456 (0.235654 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 22:44:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.055146 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 22:44:10 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/29 22:44:10 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2798248519230486\n",
      "\u001b[32m[12/29 22:44:13 d2.utils.events]: \u001b[0m eta: 4:23:27  iter: 24099  total_loss: 1.132  loss_cls: 0.2644  loss_box_reg: 0.3572  loss_mask: 0.2565  loss_rpn_cls: 0.06047  loss_rpn_loc: 0.1657  time: 0.2240  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:44:18 d2.utils.events]: \u001b[0m eta: 4:23:23  iter: 24119  total_loss: 1.307  loss_cls: 0.3389  loss_box_reg: 0.4151  loss_mask: 0.2686  loss_rpn_cls: 0.08727  loss_rpn_loc: 0.166  time: 0.2240  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:44:22 d2.utils.events]: \u001b[0m eta: 4:23:28  iter: 24139  total_loss: 1.281  loss_cls: 0.368  loss_box_reg: 0.3941  loss_mask: 0.2793  loss_rpn_cls: 0.0816  loss_rpn_loc: 0.1786  time: 0.2240  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:44:27 d2.utils.events]: \u001b[0m eta: 4:23:24  iter: 24159  total_loss: 1.158  loss_cls: 0.2858  loss_box_reg: 0.3711  loss_mask: 0.2675  loss_rpn_cls: 0.07634  loss_rpn_loc: 0.1948  time: 0.2240  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:44:31 d2.utils.events]: \u001b[0m eta: 4:23:17  iter: 24179  total_loss: 1.209  loss_cls: 0.3293  loss_box_reg: 0.3796  loss_mask: 0.2577  loss_rpn_cls: 0.06897  loss_rpn_loc: 0.1574  time: 0.2240  data_time: 0.0157  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:44:36 d2.utils.events]: \u001b[0m eta: 4:23:03  iter: 24199  total_loss: 1.183  loss_cls: 0.305  loss_box_reg: 0.3742  loss_mask: 0.246  loss_rpn_cls: 0.06226  loss_rpn_loc: 0.1699  time: 0.2240  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:44:40 d2.utils.events]: \u001b[0m eta: 4:22:58  iter: 24219  total_loss: 1.215  loss_cls: 0.3254  loss_box_reg: 0.3978  loss_mask: 0.2644  loss_rpn_cls: 0.06937  loss_rpn_loc: 0.1697  time: 0.2240  data_time: 0.0137  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:44:44 d2.utils.events]: \u001b[0m eta: 4:22:57  iter: 24239  total_loss: 1.277  loss_cls: 0.3378  loss_box_reg: 0.4076  loss_mask: 0.2532  loss_rpn_cls: 0.09576  loss_rpn_loc: 0.168  time: 0.2240  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:44:49 d2.utils.events]: \u001b[0m eta: 4:22:56  iter: 24259  total_loss: 1.174  loss_cls: 0.2824  loss_box_reg: 0.388  loss_mask: 0.2607  loss_rpn_cls: 0.04848  loss_rpn_loc: 0.171  time: 0.2240  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:44:53 d2.utils.events]: \u001b[0m eta: 4:22:42  iter: 24279  total_loss: 1.382  loss_cls: 0.3451  loss_box_reg: 0.4751  loss_mask: 0.2828  loss_rpn_cls: 0.0875  loss_rpn_loc: 0.2016  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:44:58 d2.utils.events]: \u001b[0m eta: 4:22:44  iter: 24299  total_loss: 1.231  loss_cls: 0.285  loss_box_reg: 0.4157  loss_mask: 0.2818  loss_rpn_cls: 0.09742  loss_rpn_loc: 0.1958  time: 0.2240  data_time: 0.0090  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:45:02 d2.utils.events]: \u001b[0m eta: 4:22:43  iter: 24319  total_loss: 1.105  loss_cls: 0.2746  loss_box_reg: 0.3484  loss_mask: 0.255  loss_rpn_cls: 0.07038  loss_rpn_loc: 0.1654  time: 0.2240  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:45:07 d2.utils.events]: \u001b[0m eta: 4:22:24  iter: 24339  total_loss: 1.253  loss_cls: 0.3342  loss_box_reg: 0.4058  loss_mask: 0.2608  loss_rpn_cls: 0.08681  loss_rpn_loc: 0.1581  time: 0.2240  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:45:11 d2.utils.events]: \u001b[0m eta: 4:22:03  iter: 24359  total_loss: 1.316  loss_cls: 0.3348  loss_box_reg: 0.397  loss_mask: 0.2637  loss_rpn_cls: 0.07742  loss_rpn_loc: 0.1916  time: 0.2239  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:45:15 d2.utils.events]: \u001b[0m eta: 4:21:59  iter: 24379  total_loss: 1.178  loss_cls: 0.3177  loss_box_reg: 0.4143  loss_mask: 0.2654  loss_rpn_cls: 0.08172  loss_rpn_loc: 0.1687  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:45:20 d2.utils.events]: \u001b[0m eta: 4:22:11  iter: 24399  total_loss: 1.257  loss_cls: 0.2833  loss_box_reg: 0.4147  loss_mask: 0.2807  loss_rpn_cls: 0.09524  loss_rpn_loc: 0.1843  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:45:24 d2.utils.events]: \u001b[0m eta: 4:21:50  iter: 24419  total_loss: 1.207  loss_cls: 0.3193  loss_box_reg: 0.3911  loss_mask: 0.2655  loss_rpn_cls: 0.07558  loss_rpn_loc: 0.1671  time: 0.2239  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:45:29 d2.utils.events]: \u001b[0m eta: 4:22:02  iter: 24439  total_loss: 1.28  loss_cls: 0.3182  loss_box_reg: 0.4431  loss_mask: 0.2766  loss_rpn_cls: 0.08894  loss_rpn_loc: 0.176  time: 0.2239  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:45:33 d2.utils.events]: \u001b[0m eta: 4:21:45  iter: 24459  total_loss: 1.265  loss_cls: 0.3133  loss_box_reg: 0.4056  loss_mask: 0.255  loss_rpn_cls: 0.08112  loss_rpn_loc: 0.1641  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:45:38 d2.utils.events]: \u001b[0m eta: 4:21:33  iter: 24479  total_loss: 1.234  loss_cls: 0.327  loss_box_reg: 0.3864  loss_mask: 0.2542  loss_rpn_cls: 0.08513  loss_rpn_loc: 0.171  time: 0.2239  data_time: 0.0108  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:45:42 d2.utils.events]: \u001b[0m eta: 4:21:36  iter: 24499  total_loss: 1.262  loss_cls: 0.3038  loss_box_reg: 0.3732  loss_mask: 0.275  loss_rpn_cls: 0.08586  loss_rpn_loc: 0.1838  time: 0.2239  data_time: 0.0162  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:45:47 d2.utils.events]: \u001b[0m eta: 4:21:28  iter: 24519  total_loss: 1.206  loss_cls: 0.3019  loss_box_reg: 0.3855  loss_mask: 0.2904  loss_rpn_cls: 0.0566  loss_rpn_loc: 0.1603  time: 0.2240  data_time: 0.0176  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:45:51 d2.utils.events]: \u001b[0m eta: 4:21:20  iter: 24539  total_loss: 1.281  loss_cls: 0.3003  loss_box_reg: 0.393  loss_mask: 0.2629  loss_rpn_cls: 0.0887  loss_rpn_loc: 0.1818  time: 0.2240  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:45:56 d2.utils.events]: \u001b[0m eta: 4:20:56  iter: 24559  total_loss: 1.183  loss_cls: 0.287  loss_box_reg: 0.4127  loss_mask: 0.2519  loss_rpn_cls: 0.06849  loss_rpn_loc: 0.1526  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:46:00 d2.utils.events]: \u001b[0m eta: 4:20:31  iter: 24579  total_loss: 1.149  loss_cls: 0.2724  loss_box_reg: 0.3931  loss_mask: 0.2615  loss_rpn_cls: 0.06098  loss_rpn_loc: 0.165  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:46:04 d2.utils.events]: \u001b[0m eta: 4:20:41  iter: 24599  total_loss: 1.238  loss_cls: 0.3335  loss_box_reg: 0.4128  loss_mask: 0.2568  loss_rpn_cls: 0.06927  loss_rpn_loc: 0.1604  time: 0.2239  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:46:09 d2.utils.events]: \u001b[0m eta: 4:20:29  iter: 24619  total_loss: 1.171  loss_cls: 0.2681  loss_box_reg: 0.3888  loss_mask: 0.2644  loss_rpn_cls: 0.06655  loss_rpn_loc: 0.1729  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:46:13 d2.utils.events]: \u001b[0m eta: 4:20:15  iter: 24639  total_loss: 1.168  loss_cls: 0.2848  loss_box_reg: 0.3785  loss_mask: 0.2512  loss_rpn_cls: 0.0606  loss_rpn_loc: 0.1645  time: 0.2239  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:46:17 d2.utils.events]: \u001b[0m eta: 4:20:15  iter: 24659  total_loss: 1.297  loss_cls: 0.3363  loss_box_reg: 0.416  loss_mask: 0.2696  loss_rpn_cls: 0.08474  loss_rpn_loc: 0.1643  time: 0.2239  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:46:22 d2.utils.events]: \u001b[0m eta: 4:20:26  iter: 24679  total_loss: 1.282  loss_cls: 0.3469  loss_box_reg: 0.4168  loss_mask: 0.2768  loss_rpn_cls: 0.08736  loss_rpn_loc: 0.1788  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:46:26 d2.utils.events]: \u001b[0m eta: 4:20:07  iter: 24699  total_loss: 1.195  loss_cls: 0.2863  loss_box_reg: 0.3707  loss_mask: 0.2623  loss_rpn_cls: 0.06832  loss_rpn_loc: 0.1687  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:46:31 d2.utils.events]: \u001b[0m eta: 4:20:12  iter: 24719  total_loss: 1.218  loss_cls: 0.3135  loss_box_reg: 0.3984  loss_mask: 0.281  loss_rpn_cls: 0.07807  loss_rpn_loc: 0.1741  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:46:35 d2.utils.events]: \u001b[0m eta: 4:19:56  iter: 24739  total_loss: 1.201  loss_cls: 0.3139  loss_box_reg: 0.38  loss_mask: 0.2574  loss_rpn_cls: 0.06478  loss_rpn_loc: 0.1637  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:46:40 d2.utils.events]: \u001b[0m eta: 4:19:53  iter: 24759  total_loss: 1.257  loss_cls: 0.3283  loss_box_reg: 0.3721  loss_mask: 0.2793  loss_rpn_cls: 0.09173  loss_rpn_loc: 0.1761  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:46:44 d2.utils.events]: \u001b[0m eta: 4:19:50  iter: 24779  total_loss: 1.328  loss_cls: 0.3174  loss_box_reg: 0.4105  loss_mask: 0.2739  loss_rpn_cls: 0.08142  loss_rpn_loc: 0.198  time: 0.2239  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:46:49 d2.utils.events]: \u001b[0m eta: 4:19:46  iter: 24799  total_loss: 1.226  loss_cls: 0.3078  loss_box_reg: 0.3808  loss_mask: 0.2941  loss_rpn_cls: 0.09426  loss_rpn_loc: 0.182  time: 0.2239  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:46:53 d2.utils.events]: \u001b[0m eta: 4:19:45  iter: 24819  total_loss: 1.183  loss_cls: 0.286  loss_box_reg: 0.3753  loss_mask: 0.2867  loss_rpn_cls: 0.07638  loss_rpn_loc: 0.1544  time: 0.2239  data_time: 0.0148  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:46:58 d2.utils.events]: \u001b[0m eta: 4:19:37  iter: 24839  total_loss: 1.168  loss_cls: 0.2881  loss_box_reg: 0.4063  loss_mask: 0.2419  loss_rpn_cls: 0.06387  loss_rpn_loc: 0.1598  time: 0.2239  data_time: 0.0154  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:47:03 d2.utils.events]: \u001b[0m eta: 4:19:32  iter: 24859  total_loss: 1.206  loss_cls: 0.3017  loss_box_reg: 0.3764  loss_mask: 0.2532  loss_rpn_cls: 0.07956  loss_rpn_loc: 0.1816  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:47:07 d2.utils.events]: \u001b[0m eta: 4:19:42  iter: 24879  total_loss: 1.224  loss_cls: 0.3091  loss_box_reg: 0.3653  loss_mask: 0.2604  loss_rpn_cls: 0.09014  loss_rpn_loc: 0.1652  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:47:12 d2.utils.events]: \u001b[0m eta: 4:19:51  iter: 24899  total_loss: 1.206  loss_cls: 0.3293  loss_box_reg: 0.3881  loss_mask: 0.2651  loss_rpn_cls: 0.05493  loss_rpn_loc: 0.1614  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:47:16 d2.utils.events]: \u001b[0m eta: 4:19:57  iter: 24919  total_loss: 1.326  loss_cls: 0.3574  loss_box_reg: 0.4429  loss_mask: 0.2835  loss_rpn_cls: 0.08322  loss_rpn_loc: 0.1597  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:47:21 d2.utils.events]: \u001b[0m eta: 4:19:33  iter: 24939  total_loss: 1.302  loss_cls: 0.3387  loss_box_reg: 0.4186  loss_mask: 0.2772  loss_rpn_cls: 0.09186  loss_rpn_loc: 0.1856  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:47:25 d2.utils.events]: \u001b[0m eta: 4:19:06  iter: 24959  total_loss: 1.17  loss_cls: 0.2743  loss_box_reg: 0.389  loss_mask: 0.2662  loss_rpn_cls: 0.07892  loss_rpn_loc: 0.1524  time: 0.2239  data_time: 0.0142  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:47:30 d2.utils.events]: \u001b[0m eta: 4:19:16  iter: 24979  total_loss: 1.232  loss_cls: 0.3114  loss_box_reg: 0.4038  loss_mask: 0.2591  loss_rpn_cls: 0.0864  loss_rpn_loc: 0.171  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:47:34 d2.utils.events]: \u001b[0m eta: 4:19:16  iter: 24999  total_loss: 1.143  loss_cls: 0.2873  loss_box_reg: 0.3863  loss_mask: 0.2485  loss_rpn_cls: 0.06893  loss_rpn_loc: 0.1506  time: 0.2239  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:47:38 d2.utils.events]: \u001b[0m eta: 4:18:57  iter: 25019  total_loss: 1.312  loss_cls: 0.3445  loss_box_reg: 0.409  loss_mask: 0.2794  loss_rpn_cls: 0.08528  loss_rpn_loc: 0.1651  time: 0.2239  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:47:43 d2.utils.events]: \u001b[0m eta: 4:19:20  iter: 25039  total_loss: 1.249  loss_cls: 0.3365  loss_box_reg: 0.3851  loss_mask: 0.2611  loss_rpn_cls: 0.08607  loss_rpn_loc: 0.1658  time: 0.2239  data_time: 0.0096  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:47:47 d2.utils.events]: \u001b[0m eta: 4:19:22  iter: 25059  total_loss: 1.222  loss_cls: 0.2969  loss_box_reg: 0.3824  loss_mask: 0.2841  loss_rpn_cls: 0.08042  loss_rpn_loc: 0.1708  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:47:52 d2.utils.events]: \u001b[0m eta: 4:19:17  iter: 25079  total_loss: 1.22  loss_cls: 0.2943  loss_box_reg: 0.4202  loss_mask: 0.2726  loss_rpn_cls: 0.08596  loss_rpn_loc: 0.1854  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:47:56 d2.utils.events]: \u001b[0m eta: 4:19:00  iter: 25099  total_loss: 1.155  loss_cls: 0.3003  loss_box_reg: 0.4062  loss_mask: 0.2832  loss_rpn_cls: 0.07368  loss_rpn_loc: 0.1597  time: 0.2239  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:48:01 d2.utils.events]: \u001b[0m eta: 4:18:54  iter: 25119  total_loss: 1.254  loss_cls: 0.3118  loss_box_reg: 0.4417  loss_mask: 0.2657  loss_rpn_cls: 0.07512  loss_rpn_loc: 0.164  time: 0.2239  data_time: 0.0152  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:48:05 d2.utils.events]: \u001b[0m eta: 4:18:31  iter: 25139  total_loss: 1.293  loss_cls: 0.3254  loss_box_reg: 0.3882  loss_mask: 0.2528  loss_rpn_cls: 0.1078  loss_rpn_loc: 0.1618  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:48:10 d2.utils.events]: \u001b[0m eta: 4:18:26  iter: 25159  total_loss: 1.21  loss_cls: 0.3087  loss_box_reg: 0.427  loss_mask: 0.2755  loss_rpn_cls: 0.07979  loss_rpn_loc: 0.1741  time: 0.2239  data_time: 0.0175  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:48:15 d2.utils.events]: \u001b[0m eta: 4:18:22  iter: 25179  total_loss: 1.096  loss_cls: 0.2582  loss_box_reg: 0.343  loss_mask: 0.2527  loss_rpn_cls: 0.05445  loss_rpn_loc: 0.1577  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:48:19 d2.utils.events]: \u001b[0m eta: 4:18:38  iter: 25199  total_loss: 1.352  loss_cls: 0.341  loss_box_reg: 0.4349  loss_mask: 0.2847  loss_rpn_cls: 0.09645  loss_rpn_loc: 0.1817  time: 0.2239  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:48:23 d2.utils.events]: \u001b[0m eta: 4:18:51  iter: 25219  total_loss: 1.225  loss_cls: 0.3069  loss_box_reg: 0.4143  loss_mask: 0.2669  loss_rpn_cls: 0.08474  loss_rpn_loc: 0.1477  time: 0.2239  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:48:28 d2.utils.events]: \u001b[0m eta: 4:18:30  iter: 25239  total_loss: 1.223  loss_cls: 0.3092  loss_box_reg: 0.4052  loss_mask: 0.2734  loss_rpn_cls: 0.08267  loss_rpn_loc: 0.1714  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:48:32 d2.utils.events]: \u001b[0m eta: 4:18:32  iter: 25259  total_loss: 1.258  loss_cls: 0.3143  loss_box_reg: 0.4009  loss_mask: 0.2662  loss_rpn_cls: 0.09067  loss_rpn_loc: 0.1803  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:48:37 d2.utils.events]: \u001b[0m eta: 4:18:39  iter: 25279  total_loss: 1.09  loss_cls: 0.2688  loss_box_reg: 0.3658  loss_mask: 0.2476  loss_rpn_cls: 0.0747  loss_rpn_loc: 0.1589  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:48:42 d2.utils.events]: \u001b[0m eta: 4:19:01  iter: 25299  total_loss: 1.21  loss_cls: 0.3253  loss_box_reg: 0.3937  loss_mask: 0.2686  loss_rpn_cls: 0.07934  loss_rpn_loc: 0.17  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:48:46 d2.utils.events]: \u001b[0m eta: 4:19:04  iter: 25319  total_loss: 1.102  loss_cls: 0.233  loss_box_reg: 0.369  loss_mask: 0.2695  loss_rpn_cls: 0.07425  loss_rpn_loc: 0.1701  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:48:50 d2.utils.events]: \u001b[0m eta: 4:18:57  iter: 25339  total_loss: 1.238  loss_cls: 0.2937  loss_box_reg: 0.3971  loss_mask: 0.2791  loss_rpn_cls: 0.07838  loss_rpn_loc: 0.1668  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:48:55 d2.utils.events]: \u001b[0m eta: 4:18:41  iter: 25359  total_loss: 1.36  loss_cls: 0.323  loss_box_reg: 0.4661  loss_mask: 0.2854  loss_rpn_cls: 0.08783  loss_rpn_loc: 0.1754  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:48:59 d2.utils.events]: \u001b[0m eta: 4:18:17  iter: 25379  total_loss: 1.194  loss_cls: 0.2805  loss_box_reg: 0.3824  loss_mask: 0.265  loss_rpn_cls: 0.08508  loss_rpn_loc: 0.1779  time: 0.2239  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:49:03 d2.utils.events]: \u001b[0m eta: 4:18:12  iter: 25399  total_loss: 1.294  loss_cls: 0.3244  loss_box_reg: 0.4111  loss_mask: 0.2615  loss_rpn_cls: 0.07427  loss_rpn_loc: 0.1681  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:49:08 d2.utils.events]: \u001b[0m eta: 4:18:28  iter: 25419  total_loss: 1.183  loss_cls: 0.294  loss_box_reg: 0.412  loss_mask: 0.2601  loss_rpn_cls: 0.0648  loss_rpn_loc: 0.1514  time: 0.2239  data_time: 0.0058  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:49:12 d2.utils.events]: \u001b[0m eta: 4:17:47  iter: 25439  total_loss: 1.272  loss_cls: 0.3159  loss_box_reg: 0.4241  loss_mask: 0.2783  loss_rpn_cls: 0.0953  loss_rpn_loc: 0.1738  time: 0.2239  data_time: 0.0189  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:49:17 d2.utils.events]: \u001b[0m eta: 4:18:08  iter: 25459  total_loss: 1.202  loss_cls: 0.3038  loss_box_reg: 0.4112  loss_mask: 0.2557  loss_rpn_cls: 0.07091  loss_rpn_loc: 0.1631  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:49:21 d2.utils.events]: \u001b[0m eta: 4:18:03  iter: 25479  total_loss: 1.178  loss_cls: 0.2827  loss_box_reg: 0.3725  loss_mask: 0.2514  loss_rpn_cls: 0.07163  loss_rpn_loc: 0.1703  time: 0.2239  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:49:26 d2.utils.events]: \u001b[0m eta: 4:17:29  iter: 25499  total_loss: 1.28  loss_cls: 0.3108  loss_box_reg: 0.4176  loss_mask: 0.2901  loss_rpn_cls: 0.08191  loss_rpn_loc: 0.1625  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:49:31 d2.utils.events]: \u001b[0m eta: 4:17:30  iter: 25519  total_loss: 1.033  loss_cls: 0.2693  loss_box_reg: 0.3328  loss_mask: 0.2322  loss_rpn_cls: 0.06448  loss_rpn_loc: 0.16  time: 0.2239  data_time: 0.0205  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:49:35 d2.utils.events]: \u001b[0m eta: 4:18:14  iter: 25539  total_loss: 1.294  loss_cls: 0.3276  loss_box_reg: 0.4128  loss_mask: 0.2778  loss_rpn_cls: 0.09797  loss_rpn_loc: 0.1951  time: 0.2239  data_time: 0.0093  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:49:40 d2.utils.events]: \u001b[0m eta: 4:18:30  iter: 25559  total_loss: 1.287  loss_cls: 0.3184  loss_box_reg: 0.3713  loss_mask: 0.2756  loss_rpn_cls: 0.09209  loss_rpn_loc: 0.1895  time: 0.2239  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:49:44 d2.utils.events]: \u001b[0m eta: 4:18:31  iter: 25579  total_loss: 1.266  loss_cls: 0.2788  loss_box_reg: 0.4145  loss_mask: 0.2721  loss_rpn_cls: 0.07935  loss_rpn_loc: 0.1687  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:49:49 d2.utils.events]: \u001b[0m eta: 4:18:34  iter: 25599  total_loss: 1.195  loss_cls: 0.2727  loss_box_reg: 0.4024  loss_mask: 0.2523  loss_rpn_cls: 0.08127  loss_rpn_loc: 0.177  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:49:53 d2.utils.events]: \u001b[0m eta: 4:18:31  iter: 25619  total_loss: 1.238  loss_cls: 0.3164  loss_box_reg: 0.3811  loss_mask: 0.2795  loss_rpn_cls: 0.07503  loss_rpn_loc: 0.1791  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:49:58 d2.utils.events]: \u001b[0m eta: 4:18:47  iter: 25639  total_loss: 1.182  loss_cls: 0.258  loss_box_reg: 0.3694  loss_mask: 0.2817  loss_rpn_cls: 0.0847  loss_rpn_loc: 0.1769  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:50:02 d2.utils.events]: \u001b[0m eta: 4:18:56  iter: 25659  total_loss: 1.277  loss_cls: 0.3184  loss_box_reg: 0.4251  loss_mask: 0.2894  loss_rpn_cls: 0.08485  loss_rpn_loc: 0.1718  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:50:07 d2.utils.events]: \u001b[0m eta: 4:18:55  iter: 25679  total_loss: 1.176  loss_cls: 0.276  loss_box_reg: 0.3615  loss_mask: 0.2579  loss_rpn_cls: 0.08429  loss_rpn_loc: 0.1806  time: 0.2239  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:50:12 d2.utils.events]: \u001b[0m eta: 4:18:53  iter: 25699  total_loss: 1.159  loss_cls: 0.2684  loss_box_reg: 0.3651  loss_mask: 0.255  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.172  time: 0.2239  data_time: 0.0090  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:50:16 d2.utils.events]: \u001b[0m eta: 4:18:53  iter: 25719  total_loss: 1.206  loss_cls: 0.2826  loss_box_reg: 0.3863  loss_mask: 0.2679  loss_rpn_cls: 0.06449  loss_rpn_loc: 0.1811  time: 0.2239  data_time: 0.0144  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:50:21 d2.utils.events]: \u001b[0m eta: 4:18:51  iter: 25739  total_loss: 1.161  loss_cls: 0.2945  loss_box_reg: 0.3845  loss_mask: 0.2685  loss_rpn_cls: 0.07807  loss_rpn_loc: 0.1693  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:50:25 d2.utils.events]: \u001b[0m eta: 4:18:34  iter: 25759  total_loss: 1.339  loss_cls: 0.3279  loss_box_reg: 0.4188  loss_mask: 0.2865  loss_rpn_cls: 0.0684  loss_rpn_loc: 0.1643  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:50:29 d2.utils.events]: \u001b[0m eta: 4:18:09  iter: 25779  total_loss: 1.243  loss_cls: 0.3259  loss_box_reg: 0.4008  loss_mask: 0.2606  loss_rpn_cls: 0.06741  loss_rpn_loc: 0.1643  time: 0.2239  data_time: 0.0165  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:50:34 d2.utils.events]: \u001b[0m eta: 4:17:52  iter: 25799  total_loss: 1.172  loss_cls: 0.3022  loss_box_reg: 0.3795  loss_mask: 0.2431  loss_rpn_cls: 0.05276  loss_rpn_loc: 0.1531  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:50:38 d2.utils.events]: \u001b[0m eta: 4:17:54  iter: 25819  total_loss: 1.298  loss_cls: 0.3479  loss_box_reg: 0.4389  loss_mask: 0.2644  loss_rpn_cls: 0.08631  loss_rpn_loc: 0.1695  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:50:42 d2.utils.events]: \u001b[0m eta: 4:17:34  iter: 25839  total_loss: 1.172  loss_cls: 0.3134  loss_box_reg: 0.3634  loss_mask: 0.2657  loss_rpn_cls: 0.06752  loss_rpn_loc: 0.1626  time: 0.2239  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:50:47 d2.utils.events]: \u001b[0m eta: 4:17:19  iter: 25859  total_loss: 1.334  loss_cls: 0.3507  loss_box_reg: 0.4427  loss_mask: 0.2877  loss_rpn_cls: 0.08908  loss_rpn_loc: 0.1834  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:50:51 d2.utils.events]: \u001b[0m eta: 4:17:01  iter: 25879  total_loss: 1.184  loss_cls: 0.2906  loss_box_reg: 0.3815  loss_mask: 0.2647  loss_rpn_cls: 0.0789  loss_rpn_loc: 0.1639  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:50:56 d2.utils.events]: \u001b[0m eta: 4:17:03  iter: 25899  total_loss: 1.308  loss_cls: 0.3399  loss_box_reg: 0.387  loss_mask: 0.2646  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.193  time: 0.2239  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:51:00 d2.utils.events]: \u001b[0m eta: 4:17:16  iter: 25919  total_loss: 1.304  loss_cls: 0.3264  loss_box_reg: 0.4283  loss_mask: 0.268  loss_rpn_cls: 0.1118  loss_rpn_loc: 0.1862  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:51:05 d2.utils.events]: \u001b[0m eta: 4:17:21  iter: 25939  total_loss: 1.291  loss_cls: 0.3306  loss_box_reg: 0.4354  loss_mask: 0.2739  loss_rpn_cls: 0.08608  loss_rpn_loc: 0.1574  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:51:09 d2.utils.events]: \u001b[0m eta: 4:17:08  iter: 25959  total_loss: 1.147  loss_cls: 0.2883  loss_box_reg: 0.4115  loss_mask: 0.2518  loss_rpn_cls: 0.05188  loss_rpn_loc: 0.1503  time: 0.2239  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:51:13 d2.utils.events]: \u001b[0m eta: 4:17:06  iter: 25979  total_loss: 1.139  loss_cls: 0.2687  loss_box_reg: 0.3769  loss_mask: 0.2365  loss_rpn_cls: 0.09857  loss_rpn_loc: 0.1779  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:51:18 d2.utils.events]: \u001b[0m eta: 4:16:53  iter: 25999  total_loss: 1.143  loss_cls: 0.2644  loss_box_reg: 0.375  loss_mask: 0.2472  loss_rpn_cls: 0.06807  loss_rpn_loc: 0.1527  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:51:22 d2.utils.events]: \u001b[0m eta: 4:16:55  iter: 26019  total_loss: 1.363  loss_cls: 0.3465  loss_box_reg: 0.4302  loss_mask: 0.269  loss_rpn_cls: 0.09803  loss_rpn_loc: 0.1658  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:51:27 d2.utils.events]: \u001b[0m eta: 4:16:26  iter: 26039  total_loss: 1.09  loss_cls: 0.2071  loss_box_reg: 0.3552  loss_mask: 0.2828  loss_rpn_cls: 0.07595  loss_rpn_loc: 0.1497  time: 0.2239  data_time: 0.0107  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:51:32 d2.utils.events]: \u001b[0m eta: 4:16:40  iter: 26059  total_loss: 1.22  loss_cls: 0.2979  loss_box_reg: 0.3855  loss_mask: 0.2973  loss_rpn_cls: 0.06509  loss_rpn_loc: 0.1577  time: 0.2239  data_time: 0.0151  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:51:36 d2.utils.events]: \u001b[0m eta: 4:16:31  iter: 26079  total_loss: 1.204  loss_cls: 0.3378  loss_box_reg: 0.4049  loss_mask: 0.2627  loss_rpn_cls: 0.08074  loss_rpn_loc: 0.1965  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:51:41 d2.utils.events]: \u001b[0m eta: 4:16:31  iter: 26099  total_loss: 1.091  loss_cls: 0.2234  loss_box_reg: 0.3429  loss_mask: 0.2639  loss_rpn_cls: 0.07151  loss_rpn_loc: 0.1747  time: 0.2239  data_time: 0.0161  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:51:45 d2.utils.events]: \u001b[0m eta: 4:16:27  iter: 26119  total_loss: 1.228  loss_cls: 0.28  loss_box_reg: 0.4181  loss_mask: 0.2734  loss_rpn_cls: 0.09755  loss_rpn_loc: 0.1794  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:51:50 d2.utils.events]: \u001b[0m eta: 4:16:28  iter: 26139  total_loss: 1.185  loss_cls: 0.3166  loss_box_reg: 0.3641  loss_mask: 0.2632  loss_rpn_cls: 0.09345  loss_rpn_loc: 0.1756  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:51:54 d2.utils.events]: \u001b[0m eta: 4:16:58  iter: 26159  total_loss: 1.143  loss_cls: 0.2938  loss_box_reg: 0.3835  loss_mask: 0.2435  loss_rpn_cls: 0.09268  loss_rpn_loc: 0.1758  time: 0.2239  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:51:59 d2.utils.events]: \u001b[0m eta: 4:17:05  iter: 26179  total_loss: 1.157  loss_cls: 0.2859  loss_box_reg: 0.3411  loss_mask: 0.2675  loss_rpn_cls: 0.06723  loss_rpn_loc: 0.162  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:52:03 d2.utils.events]: \u001b[0m eta: 4:16:15  iter: 26199  total_loss: 1.087  loss_cls: 0.2736  loss_box_reg: 0.3544  loss_mask: 0.239  loss_rpn_cls: 0.04981  loss_rpn_loc: 0.1574  time: 0.2239  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:52:08 d2.utils.events]: \u001b[0m eta: 4:16:10  iter: 26219  total_loss: 1.225  loss_cls: 0.3353  loss_box_reg: 0.3724  loss_mask: 0.2655  loss_rpn_cls: 0.08611  loss_rpn_loc: 0.1831  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:52:12 d2.utils.events]: \u001b[0m eta: 4:16:03  iter: 26239  total_loss: 1.208  loss_cls: 0.321  loss_box_reg: 0.4071  loss_mask: 0.2596  loss_rpn_cls: 0.06421  loss_rpn_loc: 0.1613  time: 0.2239  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:52:17 d2.utils.events]: \u001b[0m eta: 4:15:34  iter: 26259  total_loss: 1.23  loss_cls: 0.2897  loss_box_reg: 0.3778  loss_mask: 0.2701  loss_rpn_cls: 0.08384  loss_rpn_loc: 0.1885  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:52:21 d2.utils.events]: \u001b[0m eta: 4:15:18  iter: 26279  total_loss: 1.137  loss_cls: 0.2878  loss_box_reg: 0.3746  loss_mask: 0.268  loss_rpn_cls: 0.08488  loss_rpn_loc: 0.1525  time: 0.2239  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:52:25 d2.utils.events]: \u001b[0m eta: 4:14:51  iter: 26299  total_loss: 1.113  loss_cls: 0.2787  loss_box_reg: 0.3533  loss_mask: 0.239  loss_rpn_cls: 0.06549  loss_rpn_loc: 0.1516  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:52:30 d2.utils.events]: \u001b[0m eta: 4:14:35  iter: 26319  total_loss: 1.317  loss_cls: 0.3268  loss_box_reg: 0.3854  loss_mask: 0.2823  loss_rpn_cls: 0.08454  loss_rpn_loc: 0.181  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:52:35 d2.utils.events]: \u001b[0m eta: 4:14:42  iter: 26339  total_loss: 1.247  loss_cls: 0.3032  loss_box_reg: 0.3844  loss_mask: 0.2834  loss_rpn_cls: 0.07732  loss_rpn_loc: 0.1623  time: 0.2239  data_time: 0.0192  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:52:39 d2.utils.events]: \u001b[0m eta: 4:14:57  iter: 26359  total_loss: 1.215  loss_cls: 0.3049  loss_box_reg: 0.4006  loss_mask: 0.2518  loss_rpn_cls: 0.08715  loss_rpn_loc: 0.181  time: 0.2239  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:52:43 d2.utils.events]: \u001b[0m eta: 4:14:48  iter: 26379  total_loss: 1.152  loss_cls: 0.2971  loss_box_reg: 0.3507  loss_mask: 0.2498  loss_rpn_cls: 0.07091  loss_rpn_loc: 0.1624  time: 0.2239  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:52:48 d2.utils.events]: \u001b[0m eta: 4:14:48  iter: 26399  total_loss: 1.14  loss_cls: 0.2784  loss_box_reg: 0.3903  loss_mask: 0.2655  loss_rpn_cls: 0.08425  loss_rpn_loc: 0.1732  time: 0.2239  data_time: 0.0179  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:52:53 d2.utils.events]: \u001b[0m eta: 4:15:34  iter: 26419  total_loss: 1.127  loss_cls: 0.2718  loss_box_reg: 0.3494  loss_mask: 0.2387  loss_rpn_cls: 0.05859  loss_rpn_loc: 0.1653  time: 0.2239  data_time: 0.0093  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:52:58 d2.utils.events]: \u001b[0m eta: 4:15:44  iter: 26439  total_loss: 1.242  loss_cls: 0.33  loss_box_reg: 0.3999  loss_mask: 0.2735  loss_rpn_cls: 0.05924  loss_rpn_loc: 0.1647  time: 0.2239  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:53:02 d2.utils.events]: \u001b[0m eta: 4:15:34  iter: 26459  total_loss: 1.108  loss_cls: 0.281  loss_box_reg: 0.3514  loss_mask: 0.2562  loss_rpn_cls: 0.05888  loss_rpn_loc: 0.161  time: 0.2239  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:53:07 d2.utils.events]: \u001b[0m eta: 4:15:46  iter: 26479  total_loss: 1.268  loss_cls: 0.3109  loss_box_reg: 0.3997  loss_mask: 0.2824  loss_rpn_cls: 0.08636  loss_rpn_loc: 0.2024  time: 0.2239  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:53:12 d2.utils.events]: \u001b[0m eta: 4:15:03  iter: 26499  total_loss: 1.2  loss_cls: 0.3068  loss_box_reg: 0.3964  loss_mask: 0.2707  loss_rpn_cls: 0.07207  loss_rpn_loc: 0.156  time: 0.2239  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:53:16 d2.utils.events]: \u001b[0m eta: 4:14:45  iter: 26519  total_loss: 1.283  loss_cls: 0.3302  loss_box_reg: 0.4349  loss_mask: 0.2657  loss_rpn_cls: 0.08616  loss_rpn_loc: 0.181  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:53:21 d2.utils.events]: \u001b[0m eta: 4:14:18  iter: 26539  total_loss: 1.237  loss_cls: 0.3195  loss_box_reg: 0.4165  loss_mask: 0.2693  loss_rpn_cls: 0.07279  loss_rpn_loc: 0.1646  time: 0.2239  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:53:25 d2.utils.events]: \u001b[0m eta: 4:14:10  iter: 26559  total_loss: 1.298  loss_cls: 0.3325  loss_box_reg: 0.4344  loss_mask: 0.2716  loss_rpn_cls: 0.07878  loss_rpn_loc: 0.1586  time: 0.2239  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:53:29 d2.utils.events]: \u001b[0m eta: 4:13:58  iter: 26579  total_loss: 1.246  loss_cls: 0.3058  loss_box_reg: 0.3928  loss_mask: 0.2505  loss_rpn_cls: 0.0756  loss_rpn_loc: 0.1603  time: 0.2239  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:53:34 d2.utils.events]: \u001b[0m eta: 4:14:01  iter: 26599  total_loss: 1.24  loss_cls: 0.3026  loss_box_reg: 0.3943  loss_mask: 0.2803  loss_rpn_cls: 0.09643  loss_rpn_loc: 0.1717  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:53:39 d2.utils.events]: \u001b[0m eta: 4:14:00  iter: 26619  total_loss: 1.25  loss_cls: 0.3182  loss_box_reg: 0.4048  loss_mask: 0.2666  loss_rpn_cls: 0.09982  loss_rpn_loc: 0.1878  time: 0.2239  data_time: 0.0187  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:53:43 d2.utils.events]: \u001b[0m eta: 4:13:48  iter: 26639  total_loss: 1.152  loss_cls: 0.2779  loss_box_reg: 0.367  loss_mask: 0.2572  loss_rpn_cls: 0.06279  loss_rpn_loc: 0.1644  time: 0.2239  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:53:48 d2.utils.events]: \u001b[0m eta: 4:13:41  iter: 26659  total_loss: 1.355  loss_cls: 0.3594  loss_box_reg: 0.4363  loss_mask: 0.2808  loss_rpn_cls: 0.08317  loss_rpn_loc: 0.1708  time: 0.2239  data_time: 0.0164  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:53:52 d2.utils.events]: \u001b[0m eta: 4:13:30  iter: 26679  total_loss: 1.277  loss_cls: 0.3018  loss_box_reg: 0.3781  loss_mask: 0.2767  loss_rpn_cls: 0.06496  loss_rpn_loc: 0.1588  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:53:57 d2.utils.events]: \u001b[0m eta: 4:13:28  iter: 26699  total_loss: 1.21  loss_cls: 0.2987  loss_box_reg: 0.3791  loss_mask: 0.2628  loss_rpn_cls: 0.08696  loss_rpn_loc: 0.1751  time: 0.2239  data_time: 0.0090  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:54:01 d2.utils.events]: \u001b[0m eta: 4:13:21  iter: 26719  total_loss: 1.275  loss_cls: 0.3008  loss_box_reg: 0.3668  loss_mask: 0.2711  loss_rpn_cls: 0.1112  loss_rpn_loc: 0.1529  time: 0.2239  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:54:06 d2.utils.events]: \u001b[0m eta: 4:13:19  iter: 26739  total_loss: 1.105  loss_cls: 0.2693  loss_box_reg: 0.3491  loss_mask: 0.2388  loss_rpn_cls: 0.06119  loss_rpn_loc: 0.1675  time: 0.2239  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:54:10 d2.utils.events]: \u001b[0m eta: 4:13:15  iter: 26759  total_loss: 1.125  loss_cls: 0.2893  loss_box_reg: 0.3443  loss_mask: 0.2494  loss_rpn_cls: 0.07522  loss_rpn_loc: 0.164  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:54:14 d2.utils.events]: \u001b[0m eta: 4:13:27  iter: 26779  total_loss: 1.044  loss_cls: 0.2799  loss_box_reg: 0.3644  loss_mask: 0.2402  loss_rpn_cls: 0.05443  loss_rpn_loc: 0.1502  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:54:19 d2.utils.events]: \u001b[0m eta: 4:13:25  iter: 26799  total_loss: 1.197  loss_cls: 0.2884  loss_box_reg: 0.3649  loss_mask: 0.2707  loss_rpn_cls: 0.08684  loss_rpn_loc: 0.1726  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:54:23 d2.utils.events]: \u001b[0m eta: 4:13:17  iter: 26819  total_loss: 1.152  loss_cls: 0.2547  loss_box_reg: 0.3591  loss_mask: 0.2663  loss_rpn_cls: 0.06439  loss_rpn_loc: 0.1675  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:54:28 d2.utils.events]: \u001b[0m eta: 4:13:32  iter: 26839  total_loss: 1.22  loss_cls: 0.3342  loss_box_reg: 0.3853  loss_mask: 0.2401  loss_rpn_cls: 0.08361  loss_rpn_loc: 0.1795  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:54:32 d2.utils.events]: \u001b[0m eta: 4:13:18  iter: 26859  total_loss: 1.21  loss_cls: 0.3031  loss_box_reg: 0.3906  loss_mask: 0.2656  loss_rpn_cls: 0.07155  loss_rpn_loc: 0.1682  time: 0.2239  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:54:36 d2.utils.events]: \u001b[0m eta: 4:13:09  iter: 26879  total_loss: 1.236  loss_cls: 0.3044  loss_box_reg: 0.4016  loss_mask: 0.2664  loss_rpn_cls: 0.0817  loss_rpn_loc: 0.1675  time: 0.2239  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:54:41 d2.utils.events]: \u001b[0m eta: 4:13:05  iter: 26899  total_loss: 1.174  loss_cls: 0.2387  loss_box_reg: 0.3502  loss_mask: 0.2509  loss_rpn_cls: 0.05708  loss_rpn_loc: 0.1704  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:54:45 d2.utils.events]: \u001b[0m eta: 4:12:59  iter: 26919  total_loss: 1.195  loss_cls: 0.289  loss_box_reg: 0.359  loss_mask: 0.2654  loss_rpn_cls: 0.09291  loss_rpn_loc: 0.167  time: 0.2239  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:54:50 d2.utils.events]: \u001b[0m eta: 4:12:56  iter: 26939  total_loss: 1.308  loss_cls: 0.3441  loss_box_reg: 0.4114  loss_mask: 0.2754  loss_rpn_cls: 0.09211  loss_rpn_loc: 0.1817  time: 0.2239  data_time: 0.0164  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:54:55 d2.utils.events]: \u001b[0m eta: 4:13:17  iter: 26959  total_loss: 1.323  loss_cls: 0.3258  loss_box_reg: 0.458  loss_mask: 0.2686  loss_rpn_cls: 0.08401  loss_rpn_loc: 0.1657  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:54:59 d2.utils.events]: \u001b[0m eta: 4:13:01  iter: 26979  total_loss: 1.229  loss_cls: 0.2957  loss_box_reg: 0.4046  loss_mask: 0.2547  loss_rpn_cls: 0.07729  loss_rpn_loc: 0.1789  time: 0.2239  data_time: 0.0190  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:55:04 d2.utils.events]: \u001b[0m eta: 4:13:13  iter: 26999  total_loss: 1.161  loss_cls: 0.2438  loss_box_reg: 0.3443  loss_mask: 0.2729  loss_rpn_cls: 0.06709  loss_rpn_loc: 0.1622  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:55:08 d2.utils.events]: \u001b[0m eta: 4:12:53  iter: 27019  total_loss: 1.224  loss_cls: 0.3161  loss_box_reg: 0.4218  loss_mask: 0.2714  loss_rpn_cls: 0.06427  loss_rpn_loc: 0.159  time: 0.2239  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:55:12 d2.utils.events]: \u001b[0m eta: 4:12:32  iter: 27039  total_loss: 1.242  loss_cls: 0.2972  loss_box_reg: 0.3771  loss_mask: 0.2647  loss_rpn_cls: 0.09767  loss_rpn_loc: 0.1654  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:55:17 d2.utils.events]: \u001b[0m eta: 4:12:11  iter: 27059  total_loss: 1.156  loss_cls: 0.2965  loss_box_reg: 0.3537  loss_mask: 0.2478  loss_rpn_cls: 0.07809  loss_rpn_loc: 0.1651  time: 0.2239  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:55:21 d2.utils.events]: \u001b[0m eta: 4:12:19  iter: 27079  total_loss: 1.317  loss_cls: 0.336  loss_box_reg: 0.3645  loss_mask: 0.2664  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.1785  time: 0.2239  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:55:26 d2.utils.events]: \u001b[0m eta: 4:12:19  iter: 27099  total_loss: 1.354  loss_cls: 0.3432  loss_box_reg: 0.4228  loss_mask: 0.2516  loss_rpn_cls: 0.1115  loss_rpn_loc: 0.1762  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:55:30 d2.utils.events]: \u001b[0m eta: 4:12:31  iter: 27119  total_loss: 1.22  loss_cls: 0.2859  loss_box_reg: 0.4149  loss_mask: 0.2731  loss_rpn_cls: 0.08545  loss_rpn_loc: 0.1791  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:55:35 d2.utils.events]: \u001b[0m eta: 4:12:15  iter: 27139  total_loss: 1.185  loss_cls: 0.2843  loss_box_reg: 0.3523  loss_mask: 0.2576  loss_rpn_cls: 0.08121  loss_rpn_loc: 0.1782  time: 0.2239  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:55:39 d2.utils.events]: \u001b[0m eta: 4:12:22  iter: 27159  total_loss: 1.252  loss_cls: 0.3094  loss_box_reg: 0.393  loss_mask: 0.2728  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.1705  time: 0.2239  data_time: 0.0101  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:55:44 d2.utils.events]: \u001b[0m eta: 4:12:06  iter: 27179  total_loss: 1.14  loss_cls: 0.2606  loss_box_reg: 0.3788  loss_mask: 0.2641  loss_rpn_cls: 0.06838  loss_rpn_loc: 0.166  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:55:48 d2.utils.events]: \u001b[0m eta: 4:12:20  iter: 27199  total_loss: 1.276  loss_cls: 0.3087  loss_box_reg: 0.4507  loss_mask: 0.2711  loss_rpn_cls: 0.0702  loss_rpn_loc: 0.1714  time: 0.2239  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:55:53 d2.utils.events]: \u001b[0m eta: 4:12:58  iter: 27219  total_loss: 1.355  loss_cls: 0.3462  loss_box_reg: 0.4296  loss_mask: 0.2922  loss_rpn_cls: 0.09486  loss_rpn_loc: 0.1907  time: 0.2239  data_time: 0.0183  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:55:58 d2.utils.events]: \u001b[0m eta: 4:13:02  iter: 27239  total_loss: 1.2  loss_cls: 0.3009  loss_box_reg: 0.4172  loss_mask: 0.2584  loss_rpn_cls: 0.09209  loss_rpn_loc: 0.1666  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:56:02 d2.utils.events]: \u001b[0m eta: 4:13:28  iter: 27259  total_loss: 1.277  loss_cls: 0.3223  loss_box_reg: 0.4115  loss_mask: 0.2815  loss_rpn_cls: 0.09598  loss_rpn_loc: 0.1781  time: 0.2239  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:56:07 d2.utils.events]: \u001b[0m eta: 4:13:36  iter: 27279  total_loss: 1.271  loss_cls: 0.3268  loss_box_reg: 0.3799  loss_mask: 0.268  loss_rpn_cls: 0.08663  loss_rpn_loc: 0.1635  time: 0.2239  data_time: 0.0148  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:56:11 d2.utils.events]: \u001b[0m eta: 4:13:32  iter: 27299  total_loss: 1.223  loss_cls: 0.2915  loss_box_reg: 0.3924  loss_mask: 0.2703  loss_rpn_cls: 0.05712  loss_rpn_loc: 0.1622  time: 0.2239  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:56:16 d2.utils.events]: \u001b[0m eta: 4:13:16  iter: 27319  total_loss: 1.125  loss_cls: 0.2874  loss_box_reg: 0.367  loss_mask: 0.2579  loss_rpn_cls: 0.06605  loss_rpn_loc: 0.1601  time: 0.2239  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:56:20 d2.utils.events]: \u001b[0m eta: 4:13:12  iter: 27339  total_loss: 1.296  loss_cls: 0.342  loss_box_reg: 0.4384  loss_mask: 0.2836  loss_rpn_cls: 0.08519  loss_rpn_loc: 0.1695  time: 0.2239  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:56:25 d2.utils.events]: \u001b[0m eta: 4:13:07  iter: 27359  total_loss: 1.299  loss_cls: 0.3161  loss_box_reg: 0.4062  loss_mask: 0.2646  loss_rpn_cls: 0.08161  loss_rpn_loc: 0.1546  time: 0.2239  data_time: 0.0147  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:56:29 d2.utils.events]: \u001b[0m eta: 4:13:09  iter: 27379  total_loss: 1.29  loss_cls: 0.3523  loss_box_reg: 0.4352  loss_mask: 0.2646  loss_rpn_cls: 0.08709  loss_rpn_loc: 0.1729  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:56:33 d2.utils.events]: \u001b[0m eta: 4:12:26  iter: 27399  total_loss: 1.297  loss_cls: 0.3428  loss_box_reg: 0.4318  loss_mask: 0.2798  loss_rpn_cls: 0.07923  loss_rpn_loc: 0.176  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:56:38 d2.utils.events]: \u001b[0m eta: 4:12:04  iter: 27419  total_loss: 1.28  loss_cls: 0.2974  loss_box_reg: 0.4006  loss_mask: 0.2758  loss_rpn_cls: 0.09053  loss_rpn_loc: 0.1675  time: 0.2239  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:56:42 d2.utils.events]: \u001b[0m eta: 4:11:45  iter: 27439  total_loss: 1.123  loss_cls: 0.2766  loss_box_reg: 0.3287  loss_mask: 0.2542  loss_rpn_cls: 0.06756  loss_rpn_loc: 0.1667  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:56:47 d2.utils.events]: \u001b[0m eta: 4:11:23  iter: 27459  total_loss: 1.222  loss_cls: 0.3168  loss_box_reg: 0.4208  loss_mask: 0.2647  loss_rpn_cls: 0.0692  loss_rpn_loc: 0.153  time: 0.2239  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:56:51 d2.utils.events]: \u001b[0m eta: 4:11:12  iter: 27479  total_loss: 1.195  loss_cls: 0.3148  loss_box_reg: 0.4098  loss_mask: 0.2462  loss_rpn_cls: 0.07586  loss_rpn_loc: 0.1574  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:56:55 d2.utils.events]: \u001b[0m eta: 4:11:52  iter: 27499  total_loss: 1.189  loss_cls: 0.295  loss_box_reg: 0.3719  loss_mask: 0.2759  loss_rpn_cls: 0.06991  loss_rpn_loc: 0.1758  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:57:00 d2.utils.events]: \u001b[0m eta: 4:11:48  iter: 27519  total_loss: 1.216  loss_cls: 0.2895  loss_box_reg: 0.4207  loss_mask: 0.273  loss_rpn_cls: 0.07903  loss_rpn_loc: 0.1757  time: 0.2239  data_time: 0.0153  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:57:04 d2.utils.events]: \u001b[0m eta: 4:11:43  iter: 27539  total_loss: 1.266  loss_cls: 0.3247  loss_box_reg: 0.4284  loss_mask: 0.2686  loss_rpn_cls: 0.09285  loss_rpn_loc: 0.1709  time: 0.2239  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:57:09 d2.utils.events]: \u001b[0m eta: 4:11:26  iter: 27559  total_loss: 1.15  loss_cls: 0.2894  loss_box_reg: 0.3852  loss_mask: 0.2548  loss_rpn_cls: 0.07398  loss_rpn_loc: 0.1627  time: 0.2239  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:57:14 d2.utils.events]: \u001b[0m eta: 4:11:45  iter: 27579  total_loss: 1.212  loss_cls: 0.2921  loss_box_reg: 0.3669  loss_mask: 0.276  loss_rpn_cls: 0.09048  loss_rpn_loc: 0.187  time: 0.2239  data_time: 0.0269  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:57:18 d2.utils.events]: \u001b[0m eta: 4:11:35  iter: 27599  total_loss: 1.174  loss_cls: 0.2977  loss_box_reg: 0.3959  loss_mask: 0.2571  loss_rpn_cls: 0.08561  loss_rpn_loc: 0.1688  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:57:23 d2.utils.events]: \u001b[0m eta: 4:11:02  iter: 27619  total_loss: 1.139  loss_cls: 0.2876  loss_box_reg: 0.392  loss_mask: 0.2509  loss_rpn_cls: 0.07268  loss_rpn_loc: 0.1454  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:57:27 d2.utils.events]: \u001b[0m eta: 4:10:21  iter: 27639  total_loss: 1.108  loss_cls: 0.27  loss_box_reg: 0.3406  loss_mask: 0.263  loss_rpn_cls: 0.06613  loss_rpn_loc: 0.1644  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:57:31 d2.utils.events]: \u001b[0m eta: 4:10:21  iter: 27659  total_loss: 1.126  loss_cls: 0.2777  loss_box_reg: 0.3721  loss_mask: 0.2537  loss_rpn_cls: 0.06142  loss_rpn_loc: 0.1569  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:57:36 d2.utils.events]: \u001b[0m eta: 4:10:19  iter: 27679  total_loss: 1.311  loss_cls: 0.3235  loss_box_reg: 0.3863  loss_mask: 0.2868  loss_rpn_cls: 0.09945  loss_rpn_loc: 0.1784  time: 0.2239  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:57:40 d2.utils.events]: \u001b[0m eta: 4:10:05  iter: 27699  total_loss: 1.168  loss_cls: 0.2874  loss_box_reg: 0.39  loss_mask: 0.2569  loss_rpn_cls: 0.06743  loss_rpn_loc: 0.1553  time: 0.2239  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:57:45 d2.utils.events]: \u001b[0m eta: 4:10:00  iter: 27719  total_loss: 1.084  loss_cls: 0.2715  loss_box_reg: 0.3542  loss_mask: 0.2637  loss_rpn_cls: 0.06139  loss_rpn_loc: 0.1646  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:57:49 d2.utils.events]: \u001b[0m eta: 4:09:56  iter: 27739  total_loss: 1.286  loss_cls: 0.314  loss_box_reg: 0.401  loss_mask: 0.278  loss_rpn_cls: 0.09286  loss_rpn_loc: 0.171  time: 0.2239  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:57:53 d2.utils.events]: \u001b[0m eta: 4:09:54  iter: 27759  total_loss: 1.23  loss_cls: 0.2882  loss_box_reg: 0.3745  loss_mask: 0.268  loss_rpn_cls: 0.08575  loss_rpn_loc: 0.156  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:57:58 d2.utils.events]: \u001b[0m eta: 4:09:47  iter: 27779  total_loss: 1.16  loss_cls: 0.2681  loss_box_reg: 0.3684  loss_mask: 0.2528  loss_rpn_cls: 0.09161  loss_rpn_loc: 0.1698  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:58:02 d2.utils.events]: \u001b[0m eta: 4:09:41  iter: 27799  total_loss: 1.281  loss_cls: 0.3386  loss_box_reg: 0.4471  loss_mask: 0.2726  loss_rpn_cls: 0.09399  loss_rpn_loc: 0.1683  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:58:07 d2.utils.events]: \u001b[0m eta: 4:09:34  iter: 27819  total_loss: 1.168  loss_cls: 0.2983  loss_box_reg: 0.3977  loss_mask: 0.2567  loss_rpn_cls: 0.06167  loss_rpn_loc: 0.1653  time: 0.2239  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:58:11 d2.utils.events]: \u001b[0m eta: 4:09:24  iter: 27839  total_loss: 1.271  loss_cls: 0.3098  loss_box_reg: 0.4065  loss_mask: 0.2638  loss_rpn_cls: 0.05988  loss_rpn_loc: 0.1555  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:58:16 d2.utils.events]: \u001b[0m eta: 4:09:25  iter: 27859  total_loss: 1.128  loss_cls: 0.2862  loss_box_reg: 0.3558  loss_mask: 0.2481  loss_rpn_cls: 0.06273  loss_rpn_loc: 0.155  time: 0.2239  data_time: 0.0185  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:58:20 d2.utils.events]: \u001b[0m eta: 4:09:32  iter: 27879  total_loss: 1.207  loss_cls: 0.2687  loss_box_reg: 0.3458  loss_mask: 0.2774  loss_rpn_cls: 0.08366  loss_rpn_loc: 0.1892  time: 0.2239  data_time: 0.0104  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:58:25 d2.utils.events]: \u001b[0m eta: 4:09:25  iter: 27899  total_loss: 1.255  loss_cls: 0.3248  loss_box_reg: 0.3781  loss_mask: 0.2782  loss_rpn_cls: 0.09497  loss_rpn_loc: 0.1953  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:58:29 d2.utils.events]: \u001b[0m eta: 4:09:24  iter: 27919  total_loss: 1.263  loss_cls: 0.3131  loss_box_reg: 0.4048  loss_mask: 0.2819  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.1774  time: 0.2239  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:58:34 d2.utils.events]: \u001b[0m eta: 4:08:55  iter: 27939  total_loss: 1.209  loss_cls: 0.2901  loss_box_reg: 0.3973  loss_mask: 0.2594  loss_rpn_cls: 0.06763  loss_rpn_loc: 0.1662  time: 0.2239  data_time: 0.0163  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:58:38 d2.utils.events]: \u001b[0m eta: 4:09:06  iter: 27959  total_loss: 1.213  loss_cls: 0.2901  loss_box_reg: 0.3847  loss_mask: 0.2488  loss_rpn_cls: 0.0701  loss_rpn_loc: 0.1553  time: 0.2239  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:58:43 d2.utils.events]: \u001b[0m eta: 4:08:58  iter: 27979  total_loss: 1.234  loss_cls: 0.3376  loss_box_reg: 0.3779  loss_mask: 0.2665  loss_rpn_cls: 0.07178  loss_rpn_loc: 0.1529  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:58:47 d2.utils.events]: \u001b[0m eta: 4:08:40  iter: 27999  total_loss: 1.17  loss_cls: 0.306  loss_box_reg: 0.3779  loss_mask: 0.2601  loss_rpn_cls: 0.0628  loss_rpn_loc: 0.155  time: 0.2239  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:58:51 d2.utils.events]: \u001b[0m eta: 4:08:50  iter: 28019  total_loss: 1.184  loss_cls: 0.2945  loss_box_reg: 0.4018  loss_mask: 0.263  loss_rpn_cls: 0.07049  loss_rpn_loc: 0.1583  time: 0.2239  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:58:56 d2.utils.events]: \u001b[0m eta: 4:08:40  iter: 28039  total_loss: 1.235  loss_cls: 0.3168  loss_box_reg: 0.4101  loss_mask: 0.2671  loss_rpn_cls: 0.06945  loss_rpn_loc: 0.1824  time: 0.2238  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:59:00 d2.utils.events]: \u001b[0m eta: 4:08:41  iter: 28059  total_loss: 1.319  loss_cls: 0.3006  loss_box_reg: 0.4131  loss_mask: 0.2701  loss_rpn_cls: 0.07749  loss_rpn_loc: 0.1706  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:59:04 d2.utils.events]: \u001b[0m eta: 4:08:05  iter: 28079  total_loss: 1.178  loss_cls: 0.2923  loss_box_reg: 0.3628  loss_mask: 0.2666  loss_rpn_cls: 0.07069  loss_rpn_loc: 0.1642  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:59:09 d2.utils.events]: \u001b[0m eta: 4:07:58  iter: 28099  total_loss: 1.223  loss_cls: 0.3088  loss_box_reg: 0.381  loss_mask: 0.262  loss_rpn_cls: 0.08141  loss_rpn_loc: 0.1729  time: 0.2238  data_time: 0.0092  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:59:14 d2.utils.events]: \u001b[0m eta: 4:07:26  iter: 28119  total_loss: 1.257  loss_cls: 0.3029  loss_box_reg: 0.3936  loss_mask: 0.269  loss_rpn_cls: 0.0737  loss_rpn_loc: 0.1651  time: 0.2239  data_time: 0.0131  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:59:18 d2.utils.events]: \u001b[0m eta: 4:07:20  iter: 28139  total_loss: 1.096  loss_cls: 0.2578  loss_box_reg: 0.3707  loss_mask: 0.2667  loss_rpn_cls: 0.06378  loss_rpn_loc: 0.1552  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:59:22 d2.utils.events]: \u001b[0m eta: 4:06:56  iter: 28159  total_loss: 1.376  loss_cls: 0.3241  loss_box_reg: 0.4459  loss_mask: 0.2893  loss_rpn_cls: 0.07422  loss_rpn_loc: 0.1835  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:59:26 d2.utils.events]: \u001b[0m eta: 4:06:38  iter: 28179  total_loss: 1.136  loss_cls: 0.2994  loss_box_reg: 0.3991  loss_mask: 0.2622  loss_rpn_cls: 0.06409  loss_rpn_loc: 0.1594  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:59:31 d2.utils.events]: \u001b[0m eta: 4:06:15  iter: 28199  total_loss: 1.14  loss_cls: 0.2958  loss_box_reg: 0.3711  loss_mask: 0.2586  loss_rpn_cls: 0.07671  loss_rpn_loc: 0.1686  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:59:36 d2.utils.events]: \u001b[0m eta: 4:05:52  iter: 28219  total_loss: 1.257  loss_cls: 0.2787  loss_box_reg: 0.3763  loss_mask: 0.2913  loss_rpn_cls: 0.07323  loss_rpn_loc: 0.1689  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 22:59:40 d2.utils.events]: \u001b[0m eta: 4:05:36  iter: 28239  total_loss: 1.208  loss_cls: 0.3007  loss_box_reg: 0.4125  loss_mask: 0.2627  loss_rpn_cls: 0.07782  loss_rpn_loc: 0.162  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:59:44 d2.utils.events]: \u001b[0m eta: 4:05:16  iter: 28259  total_loss: 1.173  loss_cls: 0.3158  loss_box_reg: 0.4009  loss_mask: 0.266  loss_rpn_cls: 0.06662  loss_rpn_loc: 0.1487  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:59:49 d2.utils.events]: \u001b[0m eta: 4:05:01  iter: 28279  total_loss: 1.207  loss_cls: 0.2939  loss_box_reg: 0.3919  loss_mask: 0.2792  loss_rpn_cls: 0.078  loss_rpn_loc: 0.1712  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:59:53 d2.utils.events]: \u001b[0m eta: 4:04:57  iter: 28299  total_loss: 1.232  loss_cls: 0.3196  loss_box_reg: 0.3866  loss_mask: 0.2588  loss_rpn_cls: 0.0737  loss_rpn_loc: 0.1501  time: 0.2238  data_time: 0.0175  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 22:59:58 d2.utils.events]: \u001b[0m eta: 4:05:08  iter: 28319  total_loss: 1.281  loss_cls: 0.3214  loss_box_reg: 0.3829  loss_mask: 0.2748  loss_rpn_cls: 0.1178  loss_rpn_loc: 0.1927  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:00:02 d2.utils.events]: \u001b[0m eta: 4:04:58  iter: 28339  total_loss: 1.276  loss_cls: 0.2694  loss_box_reg: 0.4057  loss_mask: 0.2725  loss_rpn_cls: 0.09248  loss_rpn_loc: 0.1968  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:00:06 d2.utils.events]: \u001b[0m eta: 4:04:44  iter: 28359  total_loss: 1.273  loss_cls: 0.3151  loss_box_reg: 0.4499  loss_mask: 0.2978  loss_rpn_cls: 0.07519  loss_rpn_loc: 0.1638  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:00:11 d2.utils.events]: \u001b[0m eta: 4:04:50  iter: 28379  total_loss: 1.274  loss_cls: 0.3373  loss_box_reg: 0.4299  loss_mask: 0.2782  loss_rpn_cls: 0.09705  loss_rpn_loc: 0.1871  time: 0.2238  data_time: 0.0110  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:00:16 d2.utils.events]: \u001b[0m eta: 4:04:45  iter: 28399  total_loss: 1.159  loss_cls: 0.296  loss_box_reg: 0.3974  loss_mask: 0.2684  loss_rpn_cls: 0.08821  loss_rpn_loc: 0.1819  time: 0.2238  data_time: 0.0094  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:00:20 d2.utils.events]: \u001b[0m eta: 4:04:46  iter: 28419  total_loss: 1.288  loss_cls: 0.3222  loss_box_reg: 0.44  loss_mask: 0.2637  loss_rpn_cls: 0.09041  loss_rpn_loc: 0.1645  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:00:25 d2.utils.events]: \u001b[0m eta: 4:04:31  iter: 28439  total_loss: 1.313  loss_cls: 0.3426  loss_box_reg: 0.3967  loss_mask: 0.2784  loss_rpn_cls: 0.07396  loss_rpn_loc: 0.1778  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:00:29 d2.utils.events]: \u001b[0m eta: 4:04:58  iter: 28459  total_loss: 1.335  loss_cls: 0.3222  loss_box_reg: 0.3971  loss_mask: 0.2846  loss_rpn_cls: 0.08626  loss_rpn_loc: 0.1918  time: 0.2238  data_time: 0.0202  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:00:34 d2.utils.events]: \u001b[0m eta: 4:04:56  iter: 28479  total_loss: 1.291  loss_cls: 0.3231  loss_box_reg: 0.3778  loss_mask: 0.2636  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.1802  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:00:38 d2.utils.events]: \u001b[0m eta: 4:04:47  iter: 28499  total_loss: 1.13  loss_cls: 0.2778  loss_box_reg: 0.3601  loss_mask: 0.2537  loss_rpn_cls: 0.07138  loss_rpn_loc: 0.1706  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:00:43 d2.utils.events]: \u001b[0m eta: 4:04:40  iter: 28519  total_loss: 1.185  loss_cls: 0.2657  loss_box_reg: 0.3859  loss_mask: 0.2679  loss_rpn_cls: 0.04879  loss_rpn_loc: 0.1609  time: 0.2238  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:00:47 d2.utils.events]: \u001b[0m eta: 4:04:41  iter: 28539  total_loss: 1.277  loss_cls: 0.3135  loss_box_reg: 0.3992  loss_mask: 0.2643  loss_rpn_cls: 0.07315  loss_rpn_loc: 0.1818  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:00:52 d2.utils.events]: \u001b[0m eta: 4:04:31  iter: 28559  total_loss: 1.278  loss_cls: 0.363  loss_box_reg: 0.4276  loss_mask: 0.2761  loss_rpn_cls: 0.07794  loss_rpn_loc: 0.1915  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:00:56 d2.utils.events]: \u001b[0m eta: 4:04:04  iter: 28579  total_loss: 1.185  loss_cls: 0.3183  loss_box_reg: 0.3854  loss_mask: 0.2607  loss_rpn_cls: 0.06053  loss_rpn_loc: 0.1527  time: 0.2238  data_time: 0.0123  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:01:01 d2.utils.events]: \u001b[0m eta: 4:03:52  iter: 28599  total_loss: 1.23  loss_cls: 0.3131  loss_box_reg: 0.4001  loss_mask: 0.2669  loss_rpn_cls: 0.08615  loss_rpn_loc: 0.1703  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:01:05 d2.utils.events]: \u001b[0m eta: 4:04:18  iter: 28619  total_loss: 1.2  loss_cls: 0.2985  loss_box_reg: 0.3902  loss_mask: 0.2661  loss_rpn_cls: 0.07778  loss_rpn_loc: 0.1804  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:01:10 d2.utils.events]: \u001b[0m eta: 4:04:38  iter: 28639  total_loss: 1.243  loss_cls: 0.2979  loss_box_reg: 0.3671  loss_mask: 0.2738  loss_rpn_cls: 0.06925  loss_rpn_loc: 0.1814  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:01:14 d2.utils.events]: \u001b[0m eta: 4:04:18  iter: 28659  total_loss: 1.316  loss_cls: 0.3317  loss_box_reg: 0.3904  loss_mask: 0.2653  loss_rpn_cls: 0.06607  loss_rpn_loc: 0.1675  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:01:18 d2.utils.events]: \u001b[0m eta: 4:04:14  iter: 28679  total_loss: 1.232  loss_cls: 0.3025  loss_box_reg: 0.3892  loss_mask: 0.2571  loss_rpn_cls: 0.07978  loss_rpn_loc: 0.1826  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:01:23 d2.utils.events]: \u001b[0m eta: 4:04:43  iter: 28699  total_loss: 1.282  loss_cls: 0.2984  loss_box_reg: 0.408  loss_mask: 0.2771  loss_rpn_cls: 0.06957  loss_rpn_loc: 0.1657  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:01:27 d2.utils.events]: \u001b[0m eta: 4:04:39  iter: 28719  total_loss: 1.168  loss_cls: 0.2707  loss_box_reg: 0.3439  loss_mask: 0.2776  loss_rpn_cls: 0.08968  loss_rpn_loc: 0.1487  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:01:32 d2.utils.events]: \u001b[0m eta: 4:04:35  iter: 28739  total_loss: 1.239  loss_cls: 0.2973  loss_box_reg: 0.366  loss_mask: 0.2608  loss_rpn_cls: 0.08523  loss_rpn_loc: 0.1795  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:01:36 d2.utils.events]: \u001b[0m eta: 4:04:33  iter: 28759  total_loss: 1.336  loss_cls: 0.3432  loss_box_reg: 0.4611  loss_mask: 0.2594  loss_rpn_cls: 0.07815  loss_rpn_loc: 0.1733  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:01:41 d2.utils.events]: \u001b[0m eta: 4:04:34  iter: 28779  total_loss: 1.316  loss_cls: 0.3096  loss_box_reg: 0.3988  loss_mask: 0.2767  loss_rpn_cls: 0.07887  loss_rpn_loc: 0.1972  time: 0.2238  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:01:46 d2.utils.events]: \u001b[0m eta: 4:04:24  iter: 28799  total_loss: 1.124  loss_cls: 0.237  loss_box_reg: 0.3898  loss_mask: 0.2532  loss_rpn_cls: 0.06205  loss_rpn_loc: 0.156  time: 0.2238  data_time: 0.0154  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:01:51 d2.utils.events]: \u001b[0m eta: 4:04:31  iter: 28819  total_loss: 1.25  loss_cls: 0.3034  loss_box_reg: 0.4274  loss_mask: 0.2694  loss_rpn_cls: 0.09061  loss_rpn_loc: 0.1678  time: 0.2238  data_time: 0.0092  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:01:55 d2.utils.events]: \u001b[0m eta: 4:04:37  iter: 28839  total_loss: 1.322  loss_cls: 0.3263  loss_box_reg: 0.3898  loss_mask: 0.2934  loss_rpn_cls: 0.08709  loss_rpn_loc: 0.1806  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:02:00 d2.utils.events]: \u001b[0m eta: 4:04:31  iter: 28859  total_loss: 1.13  loss_cls: 0.2877  loss_box_reg: 0.3647  loss_mask: 0.2545  loss_rpn_cls: 0.05719  loss_rpn_loc: 0.1423  time: 0.2239  data_time: 0.0221  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:02:05 d2.utils.events]: \u001b[0m eta: 4:04:13  iter: 28879  total_loss: 1.231  loss_cls: 0.2975  loss_box_reg: 0.4041  loss_mask: 0.2843  loss_rpn_cls: 0.09171  loss_rpn_loc: 0.1859  time: 0.2239  data_time: 0.0119  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:02:09 d2.utils.events]: \u001b[0m eta: 4:04:09  iter: 28899  total_loss: 1.169  loss_cls: 0.2939  loss_box_reg: 0.3675  loss_mask: 0.2544  loss_rpn_cls: 0.07916  loss_rpn_loc: 0.1731  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:02:12 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.53 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/29 23:02:12 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/29 23:02:12 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/29 23:02:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/29 23:02:13 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 23:02:14 d2.data.common]: \u001b[0mSerialized dataset takes 84.20 MiB\n",
      "\u001b[32m[12/29 23:02:16 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.08 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/29 23:02:16 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/29 23:02:16 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/29 23:02:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/29 23:02:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0007 s/iter. Inference: 0.0596 s/iter. Eval: 0.1410 s/iter. Total: 0.2014 s/iter. ETA=0:01:52\n",
      "\u001b[32m[12/29 23:02:25 d2.evaluation.evaluator]: \u001b[0mInference done 40/570. Dataloading: 0.0009 s/iter. Inference: 0.0542 s/iter. Eval: 0.1226 s/iter. Total: 0.1777 s/iter. ETA=0:01:34\n",
      "\u001b[32m[12/29 23:02:30 d2.evaluation.evaluator]: \u001b[0mInference done 69/570. Dataloading: 0.0009 s/iter. Inference: 0.0523 s/iter. Eval: 0.1241 s/iter. Total: 0.1774 s/iter. ETA=0:01:28\n",
      "\u001b[32m[12/29 23:02:35 d2.evaluation.evaluator]: \u001b[0mInference done 95/570. Dataloading: 0.0009 s/iter. Inference: 0.0530 s/iter. Eval: 0.1292 s/iter. Total: 0.1831 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/29 23:02:40 d2.evaluation.evaluator]: \u001b[0mInference done 123/570. Dataloading: 0.0009 s/iter. Inference: 0.0525 s/iter. Eval: 0.1298 s/iter. Total: 0.1833 s/iter. ETA=0:01:21\n",
      "\u001b[32m[12/29 23:02:45 d2.evaluation.evaluator]: \u001b[0mInference done 148/570. Dataloading: 0.0009 s/iter. Inference: 0.0529 s/iter. Eval: 0.1336 s/iter. Total: 0.1874 s/iter. ETA=0:01:19\n",
      "\u001b[32m[12/29 23:02:51 d2.evaluation.evaluator]: \u001b[0mInference done 165/570. Dataloading: 0.0009 s/iter. Inference: 0.0539 s/iter. Eval: 0.1459 s/iter. Total: 0.2007 s/iter. ETA=0:01:21\n",
      "\u001b[32m[12/29 23:02:56 d2.evaluation.evaluator]: \u001b[0mInference done 177/570. Dataloading: 0.0009 s/iter. Inference: 0.0545 s/iter. Eval: 0.1608 s/iter. Total: 0.2162 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/29 23:03:01 d2.evaluation.evaluator]: \u001b[0mInference done 197/570. Dataloading: 0.0009 s/iter. Inference: 0.0552 s/iter. Eval: 0.1644 s/iter. Total: 0.2206 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/29 23:03:06 d2.evaluation.evaluator]: \u001b[0mInference done 211/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1739 s/iter. Total: 0.2305 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/29 23:03:11 d2.evaluation.evaluator]: \u001b[0mInference done 227/570. Dataloading: 0.0009 s/iter. Inference: 0.0558 s/iter. Eval: 0.1813 s/iter. Total: 0.2380 s/iter. ETA=0:01:21\n",
      "\u001b[32m[12/29 23:03:17 d2.evaluation.evaluator]: \u001b[0mInference done 239/570. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.1928 s/iter. Total: 0.2496 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/29 23:03:23 d2.evaluation.evaluator]: \u001b[0mInference done 252/570. Dataloading: 0.0009 s/iter. Inference: 0.0562 s/iter. Eval: 0.2020 s/iter. Total: 0.2591 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/29 23:03:28 d2.evaluation.evaluator]: \u001b[0mInference done 268/570. Dataloading: 0.0009 s/iter. Inference: 0.0563 s/iter. Eval: 0.2061 s/iter. Total: 0.2633 s/iter. ETA=0:01:19\n",
      "\u001b[32m[12/29 23:03:33 d2.evaluation.evaluator]: \u001b[0mInference done 288/570. Dataloading: 0.0009 s/iter. Inference: 0.0564 s/iter. Eval: 0.2066 s/iter. Total: 0.2639 s/iter. ETA=0:01:14\n",
      "\u001b[32m[12/29 23:03:38 d2.evaluation.evaluator]: \u001b[0mInference done 309/570. Dataloading: 0.0009 s/iter. Inference: 0.0562 s/iter. Eval: 0.2051 s/iter. Total: 0.2623 s/iter. ETA=0:01:08\n",
      "\u001b[32m[12/29 23:03:43 d2.evaluation.evaluator]: \u001b[0mInference done 362/570. Dataloading: 0.0009 s/iter. Inference: 0.0547 s/iter. Eval: 0.1818 s/iter. Total: 0.2374 s/iter. ETA=0:00:49\n",
      "\u001b[32m[12/29 23:03:48 d2.evaluation.evaluator]: \u001b[0mInference done 382/570. Dataloading: 0.0009 s/iter. Inference: 0.0549 s/iter. Eval: 0.1826 s/iter. Total: 0.2384 s/iter. ETA=0:00:44\n",
      "\u001b[32m[12/29 23:03:53 d2.evaluation.evaluator]: \u001b[0mInference done 404/570. Dataloading: 0.0009 s/iter. Inference: 0.0549 s/iter. Eval: 0.1820 s/iter. Total: 0.2378 s/iter. ETA=0:00:39\n",
      "\u001b[32m[12/29 23:03:58 d2.evaluation.evaluator]: \u001b[0mInference done 421/570. Dataloading: 0.0009 s/iter. Inference: 0.0551 s/iter. Eval: 0.1842 s/iter. Total: 0.2402 s/iter. ETA=0:00:35\n",
      "\u001b[32m[12/29 23:04:03 d2.evaluation.evaluator]: \u001b[0mInference done 441/570. Dataloading: 0.0009 s/iter. Inference: 0.0553 s/iter. Eval: 0.1844 s/iter. Total: 0.2407 s/iter. ETA=0:00:31\n",
      "\u001b[32m[12/29 23:04:09 d2.evaluation.evaluator]: \u001b[0mInference done 475/570. Dataloading: 0.0009 s/iter. Inference: 0.0549 s/iter. Eval: 0.1782 s/iter. Total: 0.2341 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/29 23:04:14 d2.evaluation.evaluator]: \u001b[0mInference done 501/570. Dataloading: 0.0009 s/iter. Inference: 0.0546 s/iter. Eval: 0.1766 s/iter. Total: 0.2322 s/iter. ETA=0:00:16\n",
      "\u001b[32m[12/29 23:04:19 d2.evaluation.evaluator]: \u001b[0mInference done 523/570. Dataloading: 0.0009 s/iter. Inference: 0.0546 s/iter. Eval: 0.1766 s/iter. Total: 0.2322 s/iter. ETA=0:00:10\n",
      "\u001b[32m[12/29 23:04:24 d2.evaluation.evaluator]: \u001b[0mInference done 544/570. Dataloading: 0.0009 s/iter. Inference: 0.0546 s/iter. Eval: 0.1769 s/iter. Total: 0.2324 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/29 23:04:29 d2.evaluation.evaluator]: \u001b[0mInference done 562/570. Dataloading: 0.0009 s/iter. Inference: 0.0548 s/iter. Eval: 0.1783 s/iter. Total: 0.2341 s/iter. ETA=0:00:01\n",
      "\u001b[32m[12/29 23:04:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:12.388240 (0.234315 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 23:04:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:30 (0.054852 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 23:04:31 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/29 23:04:31 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.27003224632502754\n",
      "\u001b[32m[12/29 23:04:35 d2.utils.events]: \u001b[0m eta: 4:03:56  iter: 28919  total_loss: 1.276  loss_cls: 0.3495  loss_box_reg: 0.368  loss_mask: 0.2825  loss_rpn_cls: 0.09136  loss_rpn_loc: 0.1743  time: 0.2239  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:04:39 d2.utils.events]: \u001b[0m eta: 4:04:01  iter: 28939  total_loss: 1.22  loss_cls: 0.2761  loss_box_reg: 0.3604  loss_mask: 0.2729  loss_rpn_cls: 0.09765  loss_rpn_loc: 0.1733  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:04:44 d2.utils.events]: \u001b[0m eta: 4:03:56  iter: 28959  total_loss: 1.151  loss_cls: 0.2955  loss_box_reg: 0.3665  loss_mask: 0.2439  loss_rpn_cls: 0.0545  loss_rpn_loc: 0.1632  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:04:48 d2.utils.events]: \u001b[0m eta: 4:03:57  iter: 28979  total_loss: 1.217  loss_cls: 0.2769  loss_box_reg: 0.3774  loss_mask: 0.2753  loss_rpn_cls: 0.09703  loss_rpn_loc: 0.1732  time: 0.2239  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:04:53 d2.utils.events]: \u001b[0m eta: 4:04:03  iter: 28999  total_loss: 1.21  loss_cls: 0.2928  loss_box_reg: 0.3929  loss_mask: 0.2675  loss_rpn_cls: 0.08567  loss_rpn_loc: 0.1651  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:04:57 d2.utils.events]: \u001b[0m eta: 4:04:09  iter: 29019  total_loss: 1.228  loss_cls: 0.3378  loss_box_reg: 0.3848  loss_mask: 0.2721  loss_rpn_cls: 0.09347  loss_rpn_loc: 0.1816  time: 0.2239  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:05:02 d2.utils.events]: \u001b[0m eta: 4:04:09  iter: 29039  total_loss: 1.158  loss_cls: 0.2743  loss_box_reg: 0.348  loss_mask: 0.2573  loss_rpn_cls: 0.07219  loss_rpn_loc: 0.1548  time: 0.2239  data_time: 0.0192  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:05:06 d2.utils.events]: \u001b[0m eta: 4:04:00  iter: 29059  total_loss: 1.16  loss_cls: 0.3176  loss_box_reg: 0.3977  loss_mask: 0.2397  loss_rpn_cls: 0.05486  loss_rpn_loc: 0.1489  time: 0.2239  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:05:11 d2.utils.events]: \u001b[0m eta: 4:03:59  iter: 29079  total_loss: 1.332  loss_cls: 0.346  loss_box_reg: 0.4321  loss_mask: 0.2634  loss_rpn_cls: 0.1009  loss_rpn_loc: 0.1713  time: 0.2239  data_time: 0.0144  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:05:15 d2.utils.events]: \u001b[0m eta: 4:03:45  iter: 29099  total_loss: 1.377  loss_cls: 0.3339  loss_box_reg: 0.4342  loss_mask: 0.2846  loss_rpn_cls: 0.1005  loss_rpn_loc: 0.1631  time: 0.2239  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:05:20 d2.utils.events]: \u001b[0m eta: 4:03:42  iter: 29119  total_loss: 1.177  loss_cls: 0.3215  loss_box_reg: 0.3774  loss_mask: 0.2613  loss_rpn_cls: 0.08292  loss_rpn_loc: 0.1639  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:05:24 d2.utils.events]: \u001b[0m eta: 4:03:43  iter: 29139  total_loss: 1.185  loss_cls: 0.2806  loss_box_reg: 0.3827  loss_mask: 0.2676  loss_rpn_cls: 0.05786  loss_rpn_loc: 0.1786  time: 0.2239  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:05:29 d2.utils.events]: \u001b[0m eta: 4:03:38  iter: 29159  total_loss: 1.104  loss_cls: 0.2675  loss_box_reg: 0.3665  loss_mask: 0.2481  loss_rpn_cls: 0.05912  loss_rpn_loc: 0.1685  time: 0.2239  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:05:34 d2.utils.events]: \u001b[0m eta: 4:03:42  iter: 29179  total_loss: 1.299  loss_cls: 0.3271  loss_box_reg: 0.3944  loss_mask: 0.2769  loss_rpn_cls: 0.09085  loss_rpn_loc: 0.1776  time: 0.2239  data_time: 0.0154  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:05:38 d2.utils.events]: \u001b[0m eta: 4:04:27  iter: 29199  total_loss: 1.28  loss_cls: 0.2966  loss_box_reg: 0.4082  loss_mask: 0.274  loss_rpn_cls: 0.08528  loss_rpn_loc: 0.1719  time: 0.2239  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:05:42 d2.utils.events]: \u001b[0m eta: 4:04:11  iter: 29219  total_loss: 1.156  loss_cls: 0.3001  loss_box_reg: 0.3771  loss_mask: 0.2583  loss_rpn_cls: 0.06146  loss_rpn_loc: 0.1523  time: 0.2239  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:05:47 d2.utils.events]: \u001b[0m eta: 4:04:19  iter: 29239  total_loss: 1.121  loss_cls: 0.2696  loss_box_reg: 0.3905  loss_mask: 0.2461  loss_rpn_cls: 0.06789  loss_rpn_loc: 0.1673  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:05:51 d2.utils.events]: \u001b[0m eta: 4:04:30  iter: 29259  total_loss: 1.196  loss_cls: 0.3165  loss_box_reg: 0.4335  loss_mask: 0.2551  loss_rpn_cls: 0.07423  loss_rpn_loc: 0.1534  time: 0.2239  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:05:56 d2.utils.events]: \u001b[0m eta: 4:04:33  iter: 29279  total_loss: 1.167  loss_cls: 0.2806  loss_box_reg: 0.3747  loss_mask: 0.2557  loss_rpn_cls: 0.04919  loss_rpn_loc: 0.1533  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:06:00 d2.utils.events]: \u001b[0m eta: 4:04:19  iter: 29299  total_loss: 1.146  loss_cls: 0.2599  loss_box_reg: 0.3586  loss_mask: 0.2428  loss_rpn_cls: 0.07351  loss_rpn_loc: 0.1567  time: 0.2239  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:06:05 d2.utils.events]: \u001b[0m eta: 4:04:21  iter: 29319  total_loss: 1.205  loss_cls: 0.2944  loss_box_reg: 0.3638  loss_mask: 0.2587  loss_rpn_cls: 0.07665  loss_rpn_loc: 0.1829  time: 0.2239  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:06:09 d2.utils.events]: \u001b[0m eta: 4:04:22  iter: 29339  total_loss: 1.242  loss_cls: 0.3141  loss_box_reg: 0.3541  loss_mask: 0.2612  loss_rpn_cls: 0.07453  loss_rpn_loc: 0.1836  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:06:14 d2.utils.events]: \u001b[0m eta: 4:04:33  iter: 29359  total_loss: 1.125  loss_cls: 0.2169  loss_box_reg: 0.3189  loss_mask: 0.2667  loss_rpn_cls: 0.08342  loss_rpn_loc: 0.1511  time: 0.2239  data_time: 0.0211  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:06:19 d2.utils.events]: \u001b[0m eta: 4:04:11  iter: 29379  total_loss: 1.168  loss_cls: 0.2466  loss_box_reg: 0.3732  loss_mask: 0.2587  loss_rpn_cls: 0.07935  loss_rpn_loc: 0.1854  time: 0.2239  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:06:23 d2.utils.events]: \u001b[0m eta: 4:03:57  iter: 29399  total_loss: 1.102  loss_cls: 0.244  loss_box_reg: 0.364  loss_mask: 0.2503  loss_rpn_cls: 0.05408  loss_rpn_loc: 0.1553  time: 0.2239  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:06:28 d2.utils.events]: \u001b[0m eta: 4:03:59  iter: 29419  total_loss: 1.176  loss_cls: 0.2842  loss_box_reg: 0.3315  loss_mask: 0.2566  loss_rpn_cls: 0.08679  loss_rpn_loc: 0.1851  time: 0.2239  data_time: 0.0159  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:06:32 d2.utils.events]: \u001b[0m eta: 4:04:04  iter: 29439  total_loss: 1.184  loss_cls: 0.3073  loss_box_reg: 0.3748  loss_mask: 0.2588  loss_rpn_cls: 0.05793  loss_rpn_loc: 0.1721  time: 0.2239  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:06:36 d2.utils.events]: \u001b[0m eta: 4:03:44  iter: 29459  total_loss: 1.184  loss_cls: 0.2837  loss_box_reg: 0.3998  loss_mask: 0.2656  loss_rpn_cls: 0.05856  loss_rpn_loc: 0.1521  time: 0.2239  data_time: 0.0058  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:06:41 d2.utils.events]: \u001b[0m eta: 4:03:53  iter: 29479  total_loss: 1.307  loss_cls: 0.3434  loss_box_reg: 0.4226  loss_mask: 0.2735  loss_rpn_cls: 0.08099  loss_rpn_loc: 0.1614  time: 0.2239  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:06:46 d2.utils.events]: \u001b[0m eta: 4:03:53  iter: 29499  total_loss: 1.352  loss_cls: 0.3583  loss_box_reg: 0.4027  loss_mask: 0.2875  loss_rpn_cls: 0.0876  loss_rpn_loc: 0.1872  time: 0.2239  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:06:50 d2.utils.events]: \u001b[0m eta: 4:04:03  iter: 29519  total_loss: 1.25  loss_cls: 0.3164  loss_box_reg: 0.3971  loss_mask: 0.264  loss_rpn_cls: 0.08474  loss_rpn_loc: 0.1804  time: 0.2239  data_time: 0.0122  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:06:55 d2.utils.events]: \u001b[0m eta: 4:03:53  iter: 29539  total_loss: 1.149  loss_cls: 0.2676  loss_box_reg: 0.365  loss_mask: 0.2658  loss_rpn_cls: 0.08624  loss_rpn_loc: 0.1747  time: 0.2239  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:07:00 d2.utils.events]: \u001b[0m eta: 4:03:54  iter: 29559  total_loss: 1.081  loss_cls: 0.2371  loss_box_reg: 0.3486  loss_mask: 0.2525  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.1608  time: 0.2239  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:07:04 d2.utils.events]: \u001b[0m eta: 4:03:45  iter: 29579  total_loss: 1.167  loss_cls: 0.2864  loss_box_reg: 0.4037  loss_mask: 0.2677  loss_rpn_cls: 0.06233  loss_rpn_loc: 0.1632  time: 0.2239  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:07:09 d2.utils.events]: \u001b[0m eta: 4:04:01  iter: 29599  total_loss: 1.184  loss_cls: 0.2697  loss_box_reg: 0.3925  loss_mask: 0.2629  loss_rpn_cls: 0.07114  loss_rpn_loc: 0.1718  time: 0.2239  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:07:13 d2.utils.events]: \u001b[0m eta: 4:04:03  iter: 29619  total_loss: 1.228  loss_cls: 0.2904  loss_box_reg: 0.3108  loss_mask: 0.2689  loss_rpn_cls: 0.09804  loss_rpn_loc: 0.18  time: 0.2239  data_time: 0.0192  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:07:18 d2.utils.events]: \u001b[0m eta: 4:04:22  iter: 29639  total_loss: 1.178  loss_cls: 0.2817  loss_box_reg: 0.3898  loss_mask: 0.2683  loss_rpn_cls: 0.07445  loss_rpn_loc: 0.1607  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:07:23 d2.utils.events]: \u001b[0m eta: 4:04:39  iter: 29659  total_loss: 1.237  loss_cls: 0.2978  loss_box_reg: 0.4071  loss_mask: 0.28  loss_rpn_cls: 0.08261  loss_rpn_loc: 0.1564  time: 0.2239  data_time: 0.0164  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:07:28 d2.utils.events]: \u001b[0m eta: 4:04:35  iter: 29679  total_loss: 1.311  loss_cls: 0.3332  loss_box_reg: 0.3857  loss_mask: 0.2885  loss_rpn_cls: 0.08561  loss_rpn_loc: 0.1724  time: 0.2240  data_time: 0.0170  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:07:32 d2.utils.events]: \u001b[0m eta: 4:03:39  iter: 29699  total_loss: 1.189  loss_cls: 0.2859  loss_box_reg: 0.3599  loss_mask: 0.2485  loss_rpn_cls: 0.08478  loss_rpn_loc: 0.1666  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:07:36 d2.utils.events]: \u001b[0m eta: 4:03:34  iter: 29719  total_loss: 1.33  loss_cls: 0.3124  loss_box_reg: 0.3871  loss_mask: 0.2829  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.2015  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:07:41 d2.utils.events]: \u001b[0m eta: 4:03:27  iter: 29739  total_loss: 1.238  loss_cls: 0.3283  loss_box_reg: 0.4169  loss_mask: 0.2534  loss_rpn_cls: 0.07225  loss_rpn_loc: 0.1608  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:07:45 d2.utils.events]: \u001b[0m eta: 4:03:25  iter: 29759  total_loss: 1.26  loss_cls: 0.337  loss_box_reg: 0.4166  loss_mask: 0.2535  loss_rpn_cls: 0.08818  loss_rpn_loc: 0.1637  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:07:50 d2.utils.events]: \u001b[0m eta: 4:03:01  iter: 29779  total_loss: 1.16  loss_cls: 0.2949  loss_box_reg: 0.3515  loss_mask: 0.2452  loss_rpn_cls: 0.06535  loss_rpn_loc: 0.1572  time: 0.2240  data_time: 0.0098  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:07:55 d2.utils.events]: \u001b[0m eta: 4:02:57  iter: 29799  total_loss: 1.174  loss_cls: 0.3079  loss_box_reg: 0.3821  loss_mask: 0.2544  loss_rpn_cls: 0.06021  loss_rpn_loc: 0.1736  time: 0.2240  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:07:59 d2.utils.events]: \u001b[0m eta: 4:02:48  iter: 29819  total_loss: 1.263  loss_cls: 0.3028  loss_box_reg: 0.3886  loss_mask: 0.2733  loss_rpn_cls: 0.068  loss_rpn_loc: 0.162  time: 0.2240  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:08:04 d2.utils.events]: \u001b[0m eta: 4:02:43  iter: 29839  total_loss: 1.265  loss_cls: 0.2929  loss_box_reg: 0.3702  loss_mask: 0.2774  loss_rpn_cls: 0.09514  loss_rpn_loc: 0.173  time: 0.2240  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:08:08 d2.utils.events]: \u001b[0m eta: 4:02:39  iter: 29859  total_loss: 1.221  loss_cls: 0.3296  loss_box_reg: 0.4238  loss_mask: 0.2483  loss_rpn_cls: 0.05678  loss_rpn_loc: 0.1447  time: 0.2240  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:08:13 d2.utils.events]: \u001b[0m eta: 4:02:38  iter: 29879  total_loss: 1.122  loss_cls: 0.2813  loss_box_reg: 0.3621  loss_mask: 0.2425  loss_rpn_cls: 0.08472  loss_rpn_loc: 0.1728  time: 0.2240  data_time: 0.0177  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:08:17 d2.utils.events]: \u001b[0m eta: 4:02:28  iter: 29899  total_loss: 1.192  loss_cls: 0.3051  loss_box_reg: 0.4174  loss_mask: 0.2714  loss_rpn_cls: 0.06306  loss_rpn_loc: 0.1656  time: 0.2240  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:08:22 d2.utils.events]: \u001b[0m eta: 4:02:30  iter: 29919  total_loss: 1.173  loss_cls: 0.292  loss_box_reg: 0.3815  loss_mask: 0.2683  loss_rpn_cls: 0.0633  loss_rpn_loc: 0.1564  time: 0.2240  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:08:26 d2.utils.events]: \u001b[0m eta: 4:02:17  iter: 29939  total_loss: 1.167  loss_cls: 0.3006  loss_box_reg: 0.3759  loss_mask: 0.2722  loss_rpn_cls: 0.07166  loss_rpn_loc: 0.1605  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:08:30 d2.utils.events]: \u001b[0m eta: 4:01:58  iter: 29959  total_loss: 1.275  loss_cls: 0.2987  loss_box_reg: 0.3771  loss_mask: 0.2719  loss_rpn_cls: 0.08151  loss_rpn_loc: 0.1709  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:08:35 d2.utils.events]: \u001b[0m eta: 4:01:54  iter: 29979  total_loss: 1.225  loss_cls: 0.2963  loss_box_reg: 0.3766  loss_mask: 0.2688  loss_rpn_cls: 0.06834  loss_rpn_loc: 0.176  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:08:39 d2.utils.events]: \u001b[0m eta: 4:01:28  iter: 29999  total_loss: 1.219  loss_cls: 0.3027  loss_box_reg: 0.3906  loss_mask: 0.2665  loss_rpn_cls: 0.07945  loss_rpn_loc: 0.1666  time: 0.2239  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:08:44 d2.utils.events]: \u001b[0m eta: 4:01:16  iter: 30019  total_loss: 1.301  loss_cls: 0.3409  loss_box_reg: 0.401  loss_mask: 0.2684  loss_rpn_cls: 0.09062  loss_rpn_loc: 0.1783  time: 0.2239  data_time: 0.0149  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:08:48 d2.utils.events]: \u001b[0m eta: 4:01:34  iter: 30039  total_loss: 1.316  loss_cls: 0.3209  loss_box_reg: 0.3967  loss_mask: 0.2815  loss_rpn_cls: 0.07583  loss_rpn_loc: 0.1681  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:08:53 d2.utils.events]: \u001b[0m eta: 4:01:47  iter: 30059  total_loss: 1.161  loss_cls: 0.2853  loss_box_reg: 0.3738  loss_mask: 0.2539  loss_rpn_cls: 0.08139  loss_rpn_loc: 0.1834  time: 0.2239  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:08:57 d2.utils.events]: \u001b[0m eta: 4:01:43  iter: 30079  total_loss: 1.124  loss_cls: 0.2802  loss_box_reg: 0.3839  loss_mask: 0.2554  loss_rpn_cls: 0.07017  loss_rpn_loc: 0.1577  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:09:01 d2.utils.events]: \u001b[0m eta: 4:01:42  iter: 30099  total_loss: 1.258  loss_cls: 0.3101  loss_box_reg: 0.421  loss_mask: 0.2696  loss_rpn_cls: 0.1032  loss_rpn_loc: 0.1735  time: 0.2239  data_time: 0.0100  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:09:06 d2.utils.events]: \u001b[0m eta: 4:01:38  iter: 30119  total_loss: 1.182  loss_cls: 0.2973  loss_box_reg: 0.3872  loss_mask: 0.2489  loss_rpn_cls: 0.07127  loss_rpn_loc: 0.1707  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:09:10 d2.utils.events]: \u001b[0m eta: 4:01:22  iter: 30139  total_loss: 1.017  loss_cls: 0.2409  loss_box_reg: 0.3497  loss_mask: 0.2412  loss_rpn_cls: 0.05588  loss_rpn_loc: 0.1533  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:09:14 d2.utils.events]: \u001b[0m eta: 4:01:16  iter: 30159  total_loss: 1.279  loss_cls: 0.2987  loss_box_reg: 0.4259  loss_mask: 0.2646  loss_rpn_cls: 0.07265  loss_rpn_loc: 0.168  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:09:19 d2.utils.events]: \u001b[0m eta: 4:01:03  iter: 30179  total_loss: 1.237  loss_cls: 0.31  loss_box_reg: 0.3866  loss_mask: 0.2793  loss_rpn_cls: 0.06642  loss_rpn_loc: 0.1605  time: 0.2239  data_time: 0.0149  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:09:23 d2.utils.events]: \u001b[0m eta: 4:00:40  iter: 30199  total_loss: 1.167  loss_cls: 0.3121  loss_box_reg: 0.3974  loss_mask: 0.2606  loss_rpn_cls: 0.08512  loss_rpn_loc: 0.1578  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:09:28 d2.utils.events]: \u001b[0m eta: 4:00:24  iter: 30219  total_loss: 1.25  loss_cls: 0.2813  loss_box_reg: 0.4157  loss_mask: 0.2549  loss_rpn_cls: 0.06675  loss_rpn_loc: 0.174  time: 0.2239  data_time: 0.0058  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:09:32 d2.utils.events]: \u001b[0m eta: 4:00:27  iter: 30239  total_loss: 1.227  loss_cls: 0.3281  loss_box_reg: 0.3736  loss_mask: 0.2858  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.1725  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:09:36 d2.utils.events]: \u001b[0m eta: 4:00:06  iter: 30259  total_loss: 1.195  loss_cls: 0.3119  loss_box_reg: 0.4001  loss_mask: 0.2695  loss_rpn_cls: 0.07088  loss_rpn_loc: 0.1671  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:09:41 d2.utils.events]: \u001b[0m eta: 3:59:53  iter: 30279  total_loss: 1.227  loss_cls: 0.3238  loss_box_reg: 0.3944  loss_mask: 0.2591  loss_rpn_cls: 0.06971  loss_rpn_loc: 0.1526  time: 0.2239  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:09:45 d2.utils.events]: \u001b[0m eta: 4:00:01  iter: 30299  total_loss: 1.169  loss_cls: 0.2855  loss_box_reg: 0.3672  loss_mask: 0.2751  loss_rpn_cls: 0.077  loss_rpn_loc: 0.1852  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:09:50 d2.utils.events]: \u001b[0m eta: 4:00:02  iter: 30319  total_loss: 1.265  loss_cls: 0.328  loss_box_reg: 0.3813  loss_mask: 0.2767  loss_rpn_cls: 0.08948  loss_rpn_loc: 0.169  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:09:55 d2.utils.events]: \u001b[0m eta: 4:00:03  iter: 30339  total_loss: 1.373  loss_cls: 0.3673  loss_box_reg: 0.4144  loss_mask: 0.2517  loss_rpn_cls: 0.0885  loss_rpn_loc: 0.1829  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:09:59 d2.utils.events]: \u001b[0m eta: 3:59:53  iter: 30359  total_loss: 1.208  loss_cls: 0.3065  loss_box_reg: 0.4052  loss_mask: 0.2696  loss_rpn_cls: 0.06475  loss_rpn_loc: 0.1614  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:10:04 d2.utils.events]: \u001b[0m eta: 4:00:00  iter: 30379  total_loss: 1.248  loss_cls: 0.3412  loss_box_reg: 0.3814  loss_mask: 0.262  loss_rpn_cls: 0.0654  loss_rpn_loc: 0.1685  time: 0.2239  data_time: 0.0200  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:10:08 d2.utils.events]: \u001b[0m eta: 4:00:13  iter: 30399  total_loss: 1.164  loss_cls: 0.2779  loss_box_reg: 0.4108  loss_mask: 0.2606  loss_rpn_cls: 0.06953  loss_rpn_loc: 0.1657  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:10:12 d2.utils.events]: \u001b[0m eta: 3:59:54  iter: 30419  total_loss: 1.336  loss_cls: 0.3427  loss_box_reg: 0.4134  loss_mask: 0.2807  loss_rpn_cls: 0.09155  loss_rpn_loc: 0.1607  time: 0.2239  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:10:17 d2.utils.events]: \u001b[0m eta: 3:59:52  iter: 30439  total_loss: 1.194  loss_cls: 0.3009  loss_box_reg: 0.3724  loss_mask: 0.2578  loss_rpn_cls: 0.06595  loss_rpn_loc: 0.1543  time: 0.2239  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:10:22 d2.utils.events]: \u001b[0m eta: 4:00:09  iter: 30459  total_loss: 1.306  loss_cls: 0.3257  loss_box_reg: 0.4269  loss_mask: 0.2665  loss_rpn_cls: 0.1028  loss_rpn_loc: 0.1845  time: 0.2239  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:10:26 d2.utils.events]: \u001b[0m eta: 3:59:39  iter: 30479  total_loss: 1.179  loss_cls: 0.3126  loss_box_reg: 0.3848  loss_mask: 0.2397  loss_rpn_cls: 0.05876  loss_rpn_loc: 0.1471  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:10:30 d2.utils.events]: \u001b[0m eta: 3:59:13  iter: 30499  total_loss: 1.228  loss_cls: 0.2995  loss_box_reg: 0.4173  loss_mask: 0.2641  loss_rpn_cls: 0.07669  loss_rpn_loc: 0.1601  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:10:34 d2.utils.events]: \u001b[0m eta: 3:58:49  iter: 30519  total_loss: 1.275  loss_cls: 0.3172  loss_box_reg: 0.4229  loss_mask: 0.2673  loss_rpn_cls: 0.07465  loss_rpn_loc: 0.1548  time: 0.2239  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:10:39 d2.utils.events]: \u001b[0m eta: 3:58:48  iter: 30539  total_loss: 1.324  loss_cls: 0.3285  loss_box_reg: 0.4421  loss_mask: 0.2875  loss_rpn_cls: 0.08064  loss_rpn_loc: 0.1805  time: 0.2239  data_time: 0.0211  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:10:44 d2.utils.events]: \u001b[0m eta: 3:58:38  iter: 30559  total_loss: 1.216  loss_cls: 0.2751  loss_box_reg: 0.4057  loss_mask: 0.2639  loss_rpn_cls: 0.07159  loss_rpn_loc: 0.167  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:10:48 d2.utils.events]: \u001b[0m eta: 3:58:30  iter: 30579  total_loss: 1.37  loss_cls: 0.3442  loss_box_reg: 0.434  loss_mask: 0.2757  loss_rpn_cls: 0.09578  loss_rpn_loc: 0.1932  time: 0.2239  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:10:52 d2.utils.events]: \u001b[0m eta: 3:57:25  iter: 30599  total_loss: 1.127  loss_cls: 0.31  loss_box_reg: 0.3754  loss_mask: 0.251  loss_rpn_cls: 0.07348  loss_rpn_loc: 0.1607  time: 0.2239  data_time: 0.0058  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:10:57 d2.utils.events]: \u001b[0m eta: 3:57:21  iter: 30619  total_loss: 1.157  loss_cls: 0.2667  loss_box_reg: 0.3582  loss_mask: 0.2503  loss_rpn_cls: 0.07139  loss_rpn_loc: 0.168  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:11:01 d2.utils.events]: \u001b[0m eta: 3:57:31  iter: 30639  total_loss: 1.193  loss_cls: 0.2856  loss_box_reg: 0.3846  loss_mask: 0.2687  loss_rpn_cls: 0.07621  loss_rpn_loc: 0.1692  time: 0.2239  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:11:06 d2.utils.events]: \u001b[0m eta: 3:57:52  iter: 30659  total_loss: 1.236  loss_cls: 0.2986  loss_box_reg: 0.3917  loss_mask: 0.2599  loss_rpn_cls: 0.08005  loss_rpn_loc: 0.1846  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:11:10 d2.utils.events]: \u001b[0m eta: 3:58:02  iter: 30679  total_loss: 1.307  loss_cls: 0.3264  loss_box_reg: 0.4016  loss_mask: 0.2697  loss_rpn_cls: 0.1066  loss_rpn_loc: 0.1798  time: 0.2239  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:11:15 d2.utils.events]: \u001b[0m eta: 3:57:33  iter: 30699  total_loss: 1.161  loss_cls: 0.3052  loss_box_reg: 0.4216  loss_mask: 0.2577  loss_rpn_cls: 0.0826  loss_rpn_loc: 0.1782  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:11:20 d2.utils.events]: \u001b[0m eta: 3:57:39  iter: 30719  total_loss: 1.213  loss_cls: 0.2986  loss_box_reg: 0.4041  loss_mask: 0.263  loss_rpn_cls: 0.1087  loss_rpn_loc: 0.1731  time: 0.2239  data_time: 0.0188  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:11:24 d2.utils.events]: \u001b[0m eta: 3:57:11  iter: 30739  total_loss: 1.139  loss_cls: 0.2792  loss_box_reg: 0.39  loss_mask: 0.26  loss_rpn_cls: 0.0646  loss_rpn_loc: 0.1644  time: 0.2239  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:11:28 d2.utils.events]: \u001b[0m eta: 3:56:58  iter: 30759  total_loss: 1.272  loss_cls: 0.3224  loss_box_reg: 0.4102  loss_mask: 0.2801  loss_rpn_cls: 0.07422  loss_rpn_loc: 0.154  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:11:33 d2.utils.events]: \u001b[0m eta: 3:56:54  iter: 30779  total_loss: 1.102  loss_cls: 0.2772  loss_box_reg: 0.3302  loss_mask: 0.2541  loss_rpn_cls: 0.08736  loss_rpn_loc: 0.1697  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:11:37 d2.utils.events]: \u001b[0m eta: 3:56:43  iter: 30799  total_loss: 1.243  loss_cls: 0.3031  loss_box_reg: 0.3952  loss_mask: 0.2758  loss_rpn_cls: 0.06323  loss_rpn_loc: 0.1598  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:11:42 d2.utils.events]: \u001b[0m eta: 3:56:51  iter: 30819  total_loss: 1.17  loss_cls: 0.2993  loss_box_reg: 0.3799  loss_mask: 0.2555  loss_rpn_cls: 0.07818  loss_rpn_loc: 0.1642  time: 0.2239  data_time: 0.0093  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:11:46 d2.utils.events]: \u001b[0m eta: 3:56:33  iter: 30839  total_loss: 1.171  loss_cls: 0.2771  loss_box_reg: 0.3818  loss_mask: 0.2589  loss_rpn_cls: 0.08076  loss_rpn_loc: 0.1597  time: 0.2239  data_time: 0.0159  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:11:51 d2.utils.events]: \u001b[0m eta: 3:56:45  iter: 30859  total_loss: 1.177  loss_cls: 0.2959  loss_box_reg: 0.3858  loss_mask: 0.2569  loss_rpn_cls: 0.09699  loss_rpn_loc: 0.1801  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:11:55 d2.utils.events]: \u001b[0m eta: 3:56:45  iter: 30879  total_loss: 1.303  loss_cls: 0.3175  loss_box_reg: 0.3869  loss_mask: 0.2618  loss_rpn_cls: 0.09401  loss_rpn_loc: 0.1836  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:12:00 d2.utils.events]: \u001b[0m eta: 3:56:40  iter: 30899  total_loss: 1.178  loss_cls: 0.3004  loss_box_reg: 0.3933  loss_mask: 0.2549  loss_rpn_cls: 0.0767  loss_rpn_loc: 0.1705  time: 0.2239  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:12:04 d2.utils.events]: \u001b[0m eta: 3:56:30  iter: 30919  total_loss: 1.241  loss_cls: 0.3404  loss_box_reg: 0.3955  loss_mask: 0.2691  loss_rpn_cls: 0.07739  loss_rpn_loc: 0.1615  time: 0.2239  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:12:08 d2.utils.events]: \u001b[0m eta: 3:56:28  iter: 30939  total_loss: 1.24  loss_cls: 0.3056  loss_box_reg: 0.4021  loss_mask: 0.2767  loss_rpn_cls: 0.06216  loss_rpn_loc: 0.1705  time: 0.2239  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:12:13 d2.utils.events]: \u001b[0m eta: 3:56:40  iter: 30959  total_loss: 1.228  loss_cls: 0.3018  loss_box_reg: 0.3973  loss_mask: 0.2725  loss_rpn_cls: 0.09666  loss_rpn_loc: 0.1704  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:12:17 d2.utils.events]: \u001b[0m eta: 3:56:30  iter: 30979  total_loss: 1.236  loss_cls: 0.3024  loss_box_reg: 0.3708  loss_mask: 0.2728  loss_rpn_cls: 0.07925  loss_rpn_loc: 0.165  time: 0.2239  data_time: 0.0155  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:12:22 d2.utils.events]: \u001b[0m eta: 3:56:25  iter: 30999  total_loss: 1.264  loss_cls: 0.29  loss_box_reg: 0.4101  loss_mask: 0.2746  loss_rpn_cls: 0.09516  loss_rpn_loc: 0.1707  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:12:26 d2.utils.events]: \u001b[0m eta: 3:56:33  iter: 31019  total_loss: 1.144  loss_cls: 0.2622  loss_box_reg: 0.374  loss_mask: 0.2367  loss_rpn_cls: 0.0775  loss_rpn_loc: 0.1715  time: 0.2239  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:12:31 d2.utils.events]: \u001b[0m eta: 3:56:22  iter: 31039  total_loss: 1.165  loss_cls: 0.2987  loss_box_reg: 0.3738  loss_mask: 0.2811  loss_rpn_cls: 0.07645  loss_rpn_loc: 0.1638  time: 0.2239  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:12:36 d2.utils.events]: \u001b[0m eta: 3:56:48  iter: 31059  total_loss: 1.205  loss_cls: 0.2742  loss_box_reg: 0.381  loss_mask: 0.2755  loss_rpn_cls: 0.07573  loss_rpn_loc: 0.1591  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:12:40 d2.utils.events]: \u001b[0m eta: 3:56:47  iter: 31079  total_loss: 1.188  loss_cls: 0.296  loss_box_reg: 0.3671  loss_mask: 0.2655  loss_rpn_cls: 0.07165  loss_rpn_loc: 0.1703  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:12:45 d2.utils.events]: \u001b[0m eta: 3:56:46  iter: 31099  total_loss: 1.238  loss_cls: 0.3078  loss_box_reg: 0.383  loss_mask: 0.2794  loss_rpn_cls: 0.06678  loss_rpn_loc: 0.1601  time: 0.2239  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:12:49 d2.utils.events]: \u001b[0m eta: 3:56:51  iter: 31119  total_loss: 1.261  loss_cls: 0.308  loss_box_reg: 0.4193  loss_mask: 0.2624  loss_rpn_cls: 0.07835  loss_rpn_loc: 0.1673  time: 0.2239  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:12:53 d2.utils.events]: \u001b[0m eta: 3:56:42  iter: 31139  total_loss: 1.166  loss_cls: 0.2962  loss_box_reg: 0.3849  loss_mask: 0.2806  loss_rpn_cls: 0.06351  loss_rpn_loc: 0.155  time: 0.2239  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:12:58 d2.utils.events]: \u001b[0m eta: 3:56:43  iter: 31159  total_loss: 1.314  loss_cls: 0.3175  loss_box_reg: 0.434  loss_mask: 0.2882  loss_rpn_cls: 0.08738  loss_rpn_loc: 0.1814  time: 0.2239  data_time: 0.0121  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:13:03 d2.utils.events]: \u001b[0m eta: 3:56:47  iter: 31179  total_loss: 1.105  loss_cls: 0.2729  loss_box_reg: 0.3707  loss_mask: 0.2787  loss_rpn_cls: 0.05718  loss_rpn_loc: 0.157  time: 0.2239  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:13:07 d2.utils.events]: \u001b[0m eta: 3:56:53  iter: 31199  total_loss: 1.271  loss_cls: 0.3207  loss_box_reg: 0.4387  loss_mask: 0.2752  loss_rpn_cls: 0.08537  loss_rpn_loc: 0.1769  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:13:11 d2.utils.events]: \u001b[0m eta: 3:56:49  iter: 31219  total_loss: 1.138  loss_cls: 0.2574  loss_box_reg: 0.3643  loss_mask: 0.2536  loss_rpn_cls: 0.05415  loss_rpn_loc: 0.1443  time: 0.2239  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:13:16 d2.utils.events]: \u001b[0m eta: 3:57:07  iter: 31239  total_loss: 1.201  loss_cls: 0.2873  loss_box_reg: 0.3691  loss_mask: 0.271  loss_rpn_cls: 0.08752  loss_rpn_loc: 0.1704  time: 0.2239  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:13:20 d2.utils.events]: \u001b[0m eta: 3:57:13  iter: 31259  total_loss: 1.276  loss_cls: 0.3229  loss_box_reg: 0.3912  loss_mask: 0.2715  loss_rpn_cls: 0.08032  loss_rpn_loc: 0.181  time: 0.2239  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:13:25 d2.utils.events]: \u001b[0m eta: 3:57:29  iter: 31279  total_loss: 1.033  loss_cls: 0.2451  loss_box_reg: 0.3507  loss_mask: 0.2425  loss_rpn_cls: 0.05944  loss_rpn_loc: 0.1586  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:13:29 d2.utils.events]: \u001b[0m eta: 3:57:23  iter: 31299  total_loss: 1.267  loss_cls: 0.3111  loss_box_reg: 0.4274  loss_mask: 0.2659  loss_rpn_cls: 0.06486  loss_rpn_loc: 0.1698  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:13:34 d2.utils.events]: \u001b[0m eta: 3:56:52  iter: 31319  total_loss: 1.227  loss_cls: 0.3082  loss_box_reg: 0.3821  loss_mask: 0.2626  loss_rpn_cls: 0.08008  loss_rpn_loc: 0.1576  time: 0.2239  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:13:38 d2.utils.events]: \u001b[0m eta: 3:56:37  iter: 31339  total_loss: 1.222  loss_cls: 0.2899  loss_box_reg: 0.4211  loss_mask: 0.2737  loss_rpn_cls: 0.07101  loss_rpn_loc: 0.1594  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:13:43 d2.utils.events]: \u001b[0m eta: 3:56:29  iter: 31359  total_loss: 1.312  loss_cls: 0.313  loss_box_reg: 0.4117  loss_mask: 0.279  loss_rpn_cls: 0.09594  loss_rpn_loc: 0.1836  time: 0.2239  data_time: 0.0112  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:13:47 d2.utils.events]: \u001b[0m eta: 3:56:34  iter: 31379  total_loss: 1.292  loss_cls: 0.3425  loss_box_reg: 0.4154  loss_mask: 0.2727  loss_rpn_cls: 0.0969  loss_rpn_loc: 0.1825  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:13:52 d2.utils.events]: \u001b[0m eta: 3:56:12  iter: 31399  total_loss: 1.205  loss_cls: 0.292  loss_box_reg: 0.4009  loss_mask: 0.2592  loss_rpn_cls: 0.08975  loss_rpn_loc: 0.1695  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:13:56 d2.utils.events]: \u001b[0m eta: 3:56:16  iter: 31419  total_loss: 1.16  loss_cls: 0.2962  loss_box_reg: 0.3825  loss_mask: 0.254  loss_rpn_cls: 0.07214  loss_rpn_loc: 0.164  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:14:00 d2.utils.events]: \u001b[0m eta: 3:55:49  iter: 31439  total_loss: 1.341  loss_cls: 0.3388  loss_box_reg: 0.4594  loss_mask: 0.2857  loss_rpn_cls: 0.09114  loss_rpn_loc: 0.1836  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:14:05 d2.utils.events]: \u001b[0m eta: 3:56:03  iter: 31459  total_loss: 1.305  loss_cls: 0.3118  loss_box_reg: 0.4092  loss_mask: 0.2697  loss_rpn_cls: 0.06866  loss_rpn_loc: 0.1654  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:14:09 d2.utils.events]: \u001b[0m eta: 3:55:50  iter: 31479  total_loss: 1.153  loss_cls: 0.3181  loss_box_reg: 0.388  loss_mask: 0.2549  loss_rpn_cls: 0.0534  loss_rpn_loc: 0.1574  time: 0.2238  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:14:14 d2.utils.events]: \u001b[0m eta: 3:55:38  iter: 31499  total_loss: 1.182  loss_cls: 0.3072  loss_box_reg: 0.3668  loss_mask: 0.2529  loss_rpn_cls: 0.07611  loss_rpn_loc: 0.1683  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:14:18 d2.utils.events]: \u001b[0m eta: 3:56:11  iter: 31519  total_loss: 1.264  loss_cls: 0.3131  loss_box_reg: 0.3674  loss_mask: 0.2742  loss_rpn_cls: 0.08142  loss_rpn_loc: 0.1788  time: 0.2238  data_time: 0.0090  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:14:23 d2.utils.events]: \u001b[0m eta: 3:56:07  iter: 31539  total_loss: 1.205  loss_cls: 0.3408  loss_box_reg: 0.3832  loss_mask: 0.269  loss_rpn_cls: 0.09667  loss_rpn_loc: 0.1636  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:14:28 d2.utils.events]: \u001b[0m eta: 3:56:07  iter: 31559  total_loss: 1.252  loss_cls: 0.3126  loss_box_reg: 0.3553  loss_mask: 0.2696  loss_rpn_cls: 0.1066  loss_rpn_loc: 0.1814  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:14:32 d2.utils.events]: \u001b[0m eta: 3:56:03  iter: 31579  total_loss: 1.127  loss_cls: 0.2981  loss_box_reg: 0.341  loss_mask: 0.2538  loss_rpn_cls: 0.05209  loss_rpn_loc: 0.1477  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:14:37 d2.utils.events]: \u001b[0m eta: 3:56:19  iter: 31599  total_loss: 1.232  loss_cls: 0.3289  loss_box_reg: 0.3953  loss_mask: 0.259  loss_rpn_cls: 0.08637  loss_rpn_loc: 0.1692  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:14:41 d2.utils.events]: \u001b[0m eta: 3:55:58  iter: 31619  total_loss: 1.191  loss_cls: 0.287  loss_box_reg: 0.3776  loss_mask: 0.261  loss_rpn_cls: 0.05198  loss_rpn_loc: 0.1566  time: 0.2239  data_time: 0.0144  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:14:46 d2.utils.events]: \u001b[0m eta: 3:55:37  iter: 31639  total_loss: 1.173  loss_cls: 0.2571  loss_box_reg: 0.3777  loss_mask: 0.2563  loss_rpn_cls: 0.07419  loss_rpn_loc: 0.1642  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:14:50 d2.utils.events]: \u001b[0m eta: 3:55:27  iter: 31659  total_loss: 1.185  loss_cls: 0.3133  loss_box_reg: 0.3789  loss_mask: 0.2611  loss_rpn_cls: 0.05952  loss_rpn_loc: 0.1691  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:14:55 d2.utils.events]: \u001b[0m eta: 3:55:25  iter: 31679  total_loss: 1.26  loss_cls: 0.3246  loss_box_reg: 0.3842  loss_mask: 0.2829  loss_rpn_cls: 0.09944  loss_rpn_loc: 0.1848  time: 0.2239  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:15:00 d2.utils.events]: \u001b[0m eta: 3:55:36  iter: 31699  total_loss: 1.132  loss_cls: 0.2546  loss_box_reg: 0.3242  loss_mask: 0.2766  loss_rpn_cls: 0.09636  loss_rpn_loc: 0.1674  time: 0.2239  data_time: 0.0100  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:15:04 d2.utils.events]: \u001b[0m eta: 3:55:14  iter: 31719  total_loss: 1.29  loss_cls: 0.3245  loss_box_reg: 0.4114  loss_mask: 0.2776  loss_rpn_cls: 0.08825  loss_rpn_loc: 0.1737  time: 0.2239  data_time: 0.0185  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:15:09 d2.utils.events]: \u001b[0m eta: 3:55:02  iter: 31739  total_loss: 1.228  loss_cls: 0.2896  loss_box_reg: 0.3904  loss_mask: 0.2698  loss_rpn_cls: 0.07121  loss_rpn_loc: 0.1849  time: 0.2239  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:15:13 d2.utils.events]: \u001b[0m eta: 3:54:58  iter: 31759  total_loss: 1.19  loss_cls: 0.3322  loss_box_reg: 0.3884  loss_mask: 0.2681  loss_rpn_cls: 0.07505  loss_rpn_loc: 0.1678  time: 0.2239  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:15:17 d2.utils.events]: \u001b[0m eta: 3:54:52  iter: 31779  total_loss: 1.231  loss_cls: 0.325  loss_box_reg: 0.3948  loss_mask: 0.2654  loss_rpn_cls: 0.06761  loss_rpn_loc: 0.1705  time: 0.2239  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:15:22 d2.utils.events]: \u001b[0m eta: 3:55:04  iter: 31799  total_loss: 1.121  loss_cls: 0.2691  loss_box_reg: 0.3618  loss_mask: 0.2555  loss_rpn_cls: 0.07073  loss_rpn_loc: 0.1545  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:15:26 d2.utils.events]: \u001b[0m eta: 3:55:00  iter: 31819  total_loss: 1.161  loss_cls: 0.2788  loss_box_reg: 0.3803  loss_mask: 0.2476  loss_rpn_cls: 0.06439  loss_rpn_loc: 0.1508  time: 0.2239  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:15:31 d2.utils.events]: \u001b[0m eta: 3:54:45  iter: 31839  total_loss: 1.115  loss_cls: 0.2636  loss_box_reg: 0.373  loss_mask: 0.2545  loss_rpn_cls: 0.0575  loss_rpn_loc: 0.1497  time: 0.2239  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:15:35 d2.utils.events]: \u001b[0m eta: 3:54:29  iter: 31859  total_loss: 1.132  loss_cls: 0.2619  loss_box_reg: 0.3239  loss_mask: 0.2433  loss_rpn_cls: 0.0652  loss_rpn_loc: 0.1745  time: 0.2239  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:15:40 d2.utils.events]: \u001b[0m eta: 3:54:23  iter: 31879  total_loss: 1.247  loss_cls: 0.3142  loss_box_reg: 0.4148  loss_mask: 0.2592  loss_rpn_cls: 0.06914  loss_rpn_loc: 0.1838  time: 0.2239  data_time: 0.0153  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:15:44 d2.utils.events]: \u001b[0m eta: 3:54:18  iter: 31899  total_loss: 1.127  loss_cls: 0.2456  loss_box_reg: 0.3797  loss_mask: 0.2709  loss_rpn_cls: 0.07942  loss_rpn_loc: 0.1778  time: 0.2239  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:15:49 d2.utils.events]: \u001b[0m eta: 3:54:16  iter: 31919  total_loss: 1.299  loss_cls: 0.339  loss_box_reg: 0.3696  loss_mask: 0.2672  loss_rpn_cls: 0.1099  loss_rpn_loc: 0.1911  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:15:54 d2.utils.events]: \u001b[0m eta: 3:54:23  iter: 31939  total_loss: 1.182  loss_cls: 0.2765  loss_box_reg: 0.3851  loss_mask: 0.2492  loss_rpn_cls: 0.05752  loss_rpn_loc: 0.1633  time: 0.2239  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:15:58 d2.utils.events]: \u001b[0m eta: 3:54:21  iter: 31959  total_loss: 1.287  loss_cls: 0.3383  loss_box_reg: 0.4265  loss_mask: 0.2805  loss_rpn_cls: 0.1006  loss_rpn_loc: 0.181  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:16:03 d2.utils.events]: \u001b[0m eta: 3:54:17  iter: 31979  total_loss: 1.224  loss_cls: 0.3059  loss_box_reg: 0.4051  loss_mask: 0.2691  loss_rpn_cls: 0.07489  loss_rpn_loc: 0.1651  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:16:07 d2.utils.events]: \u001b[0m eta: 3:54:33  iter: 31999  total_loss: 1.243  loss_cls: 0.3016  loss_box_reg: 0.4353  loss_mask: 0.2714  loss_rpn_cls: 0.07415  loss_rpn_loc: 0.1679  time: 0.2239  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:16:12 d2.utils.events]: \u001b[0m eta: 3:54:41  iter: 32019  total_loss: 1.192  loss_cls: 0.2696  loss_box_reg: 0.3852  loss_mask: 0.2776  loss_rpn_cls: 0.08253  loss_rpn_loc: 0.1824  time: 0.2239  data_time: 0.0224  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:16:17 d2.utils.events]: \u001b[0m eta: 3:54:38  iter: 32039  total_loss: 1.241  loss_cls: 0.3183  loss_box_reg: 0.3819  loss_mask: 0.2807  loss_rpn_cls: 0.09842  loss_rpn_loc: 0.1861  time: 0.2239  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:16:21 d2.utils.events]: \u001b[0m eta: 3:54:14  iter: 32059  total_loss: 1.178  loss_cls: 0.2932  loss_box_reg: 0.3953  loss_mask: 0.267  loss_rpn_cls: 0.06749  loss_rpn_loc: 0.1596  time: 0.2239  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:16:25 d2.utils.events]: \u001b[0m eta: 3:53:55  iter: 32079  total_loss: 1.156  loss_cls: 0.2777  loss_box_reg: 0.4254  loss_mask: 0.2622  loss_rpn_cls: 0.05965  loss_rpn_loc: 0.1566  time: 0.2239  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:16:30 d2.utils.events]: \u001b[0m eta: 3:53:48  iter: 32099  total_loss: 1.214  loss_cls: 0.302  loss_box_reg: 0.399  loss_mask: 0.262  loss_rpn_cls: 0.06953  loss_rpn_loc: 0.1641  time: 0.2239  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:16:34 d2.utils.events]: \u001b[0m eta: 3:53:30  iter: 32119  total_loss: 1.168  loss_cls: 0.309  loss_box_reg: 0.3747  loss_mask: 0.2677  loss_rpn_cls: 0.0702  loss_rpn_loc: 0.1582  time: 0.2239  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:16:39 d2.utils.events]: \u001b[0m eta: 3:53:40  iter: 32139  total_loss: 1.225  loss_cls: 0.2921  loss_box_reg: 0.3983  loss_mask: 0.2799  loss_rpn_cls: 0.09908  loss_rpn_loc: 0.1785  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:16:43 d2.utils.events]: \u001b[0m eta: 3:53:43  iter: 32159  total_loss: 1.344  loss_cls: 0.3339  loss_box_reg: 0.4162  loss_mask: 0.2755  loss_rpn_cls: 0.1081  loss_rpn_loc: 0.1747  time: 0.2239  data_time: 0.0097  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:16:48 d2.utils.events]: \u001b[0m eta: 3:53:25  iter: 32179  total_loss: 1.296  loss_cls: 0.2838  loss_box_reg: 0.3862  loss_mask: 0.28  loss_rpn_cls: 0.07701  loss_rpn_loc: 0.1798  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:16:52 d2.utils.events]: \u001b[0m eta: 3:53:26  iter: 32199  total_loss: 1.259  loss_cls: 0.3284  loss_box_reg: 0.4191  loss_mask: 0.2711  loss_rpn_cls: 0.06809  loss_rpn_loc: 0.1729  time: 0.2239  data_time: 0.0231  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:16:57 d2.utils.events]: \u001b[0m eta: 3:53:26  iter: 32219  total_loss: 1.255  loss_cls: 0.3219  loss_box_reg: 0.3851  loss_mask: 0.2747  loss_rpn_cls: 0.09195  loss_rpn_loc: 0.165  time: 0.2239  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:17:01 d2.utils.events]: \u001b[0m eta: 3:53:22  iter: 32239  total_loss: 1.071  loss_cls: 0.2722  loss_box_reg: 0.3206  loss_mask: 0.2421  loss_rpn_cls: 0.08361  loss_rpn_loc: 0.1515  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:17:06 d2.utils.events]: \u001b[0m eta: 3:53:07  iter: 32259  total_loss: 1.174  loss_cls: 0.2675  loss_box_reg: 0.3747  loss_mask: 0.2679  loss_rpn_cls: 0.0778  loss_rpn_loc: 0.1555  time: 0.2239  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:17:10 d2.utils.events]: \u001b[0m eta: 3:52:56  iter: 32279  total_loss: 1.197  loss_cls: 0.2923  loss_box_reg: 0.3777  loss_mask: 0.2633  loss_rpn_cls: 0.07118  loss_rpn_loc: 0.1754  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:17:15 d2.utils.events]: \u001b[0m eta: 3:52:40  iter: 32299  total_loss: 1.257  loss_cls: 0.3221  loss_box_reg: 0.4286  loss_mask: 0.2694  loss_rpn_cls: 0.06556  loss_rpn_loc: 0.1659  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:17:19 d2.utils.events]: \u001b[0m eta: 3:52:42  iter: 32319  total_loss: 1.302  loss_cls: 0.3453  loss_box_reg: 0.4445  loss_mask: 0.2757  loss_rpn_cls: 0.07172  loss_rpn_loc: 0.1761  time: 0.2239  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:17:24 d2.utils.events]: \u001b[0m eta: 3:52:38  iter: 32339  total_loss: 1.193  loss_cls: 0.2972  loss_box_reg: 0.4145  loss_mask: 0.2575  loss_rpn_cls: 0.06627  loss_rpn_loc: 0.1637  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:17:28 d2.utils.events]: \u001b[0m eta: 3:52:40  iter: 32359  total_loss: 1.178  loss_cls: 0.2834  loss_box_reg: 0.3675  loss_mask: 0.2594  loss_rpn_cls: 0.08608  loss_rpn_loc: 0.173  time: 0.2239  data_time: 0.0143  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:17:33 d2.utils.events]: \u001b[0m eta: 3:51:58  iter: 32379  total_loss: 1.202  loss_cls: 0.301  loss_box_reg: 0.411  loss_mask: 0.2512  loss_rpn_cls: 0.07076  loss_rpn_loc: 0.1575  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:17:37 d2.utils.events]: \u001b[0m eta: 3:52:25  iter: 32399  total_loss: 1.237  loss_cls: 0.2956  loss_box_reg: 0.3846  loss_mask: 0.2641  loss_rpn_cls: 0.07593  loss_rpn_loc: 0.1771  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:17:41 d2.utils.events]: \u001b[0m eta: 3:52:12  iter: 32419  total_loss: 1.098  loss_cls: 0.281  loss_box_reg: 0.3436  loss_mask: 0.2461  loss_rpn_cls: 0.06501  loss_rpn_loc: 0.1504  time: 0.2239  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:17:46 d2.utils.events]: \u001b[0m eta: 3:52:26  iter: 32439  total_loss: 1.292  loss_cls: 0.3002  loss_box_reg: 0.4021  loss_mask: 0.2703  loss_rpn_cls: 0.08659  loss_rpn_loc: 0.1677  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:17:51 d2.utils.events]: \u001b[0m eta: 3:51:58  iter: 32459  total_loss: 1.276  loss_cls: 0.3347  loss_box_reg: 0.4071  loss_mask: 0.2824  loss_rpn_cls: 0.08072  loss_rpn_loc: 0.1836  time: 0.2239  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:17:55 d2.utils.events]: \u001b[0m eta: 3:52:17  iter: 32479  total_loss: 1.277  loss_cls: 0.3103  loss_box_reg: 0.3774  loss_mask: 0.2544  loss_rpn_cls: 0.06453  loss_rpn_loc: 0.1623  time: 0.2239  data_time: 0.0127  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:18:00 d2.utils.events]: \u001b[0m eta: 3:52:36  iter: 32499  total_loss: 1.301  loss_cls: 0.3388  loss_box_reg: 0.4175  loss_mask: 0.2682  loss_rpn_cls: 0.09626  loss_rpn_loc: 0.1604  time: 0.2239  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:18:04 d2.utils.events]: \u001b[0m eta: 3:52:26  iter: 32519  total_loss: 1.222  loss_cls: 0.3163  loss_box_reg: 0.3789  loss_mask: 0.2556  loss_rpn_cls: 0.07938  loss_rpn_loc: 0.167  time: 0.2239  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:18:09 d2.utils.events]: \u001b[0m eta: 3:52:09  iter: 32539  total_loss: 1.343  loss_cls: 0.3626  loss_box_reg: 0.4068  loss_mask: 0.276  loss_rpn_cls: 0.07562  loss_rpn_loc: 0.181  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:18:13 d2.utils.events]: \u001b[0m eta: 3:51:51  iter: 32559  total_loss: 1.217  loss_cls: 0.3132  loss_box_reg: 0.3765  loss_mask: 0.267  loss_rpn_cls: 0.06486  loss_rpn_loc: 0.1827  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:18:18 d2.utils.events]: \u001b[0m eta: 3:52:08  iter: 32579  total_loss: 1.165  loss_cls: 0.3034  loss_box_reg: 0.3956  loss_mask: 0.2643  loss_rpn_cls: 0.07165  loss_rpn_loc: 0.1806  time: 0.2239  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:18:22 d2.utils.events]: \u001b[0m eta: 3:52:04  iter: 32599  total_loss: 1.315  loss_cls: 0.3257  loss_box_reg: 0.4415  loss_mask: 0.2772  loss_rpn_cls: 0.0981  loss_rpn_loc: 0.1726  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:18:26 d2.utils.events]: \u001b[0m eta: 3:51:47  iter: 32619  total_loss: 1.196  loss_cls: 0.2999  loss_box_reg: 0.3833  loss_mask: 0.2729  loss_rpn_cls: 0.08208  loss_rpn_loc: 0.1642  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:18:31 d2.utils.events]: \u001b[0m eta: 3:51:55  iter: 32639  total_loss: 1.021  loss_cls: 0.234  loss_box_reg: 0.3133  loss_mask: 0.2461  loss_rpn_cls: 0.0523  loss_rpn_loc: 0.1501  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:18:35 d2.utils.events]: \u001b[0m eta: 3:51:43  iter: 32659  total_loss: 1.228  loss_cls: 0.2994  loss_box_reg: 0.395  loss_mask: 0.2477  loss_rpn_cls: 0.07152  loss_rpn_loc: 0.1649  time: 0.2239  data_time: 0.0127  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:18:40 d2.utils.events]: \u001b[0m eta: 3:51:34  iter: 32679  total_loss: 1.145  loss_cls: 0.2769  loss_box_reg: 0.4021  loss_mask: 0.2537  loss_rpn_cls: 0.05776  loss_rpn_loc: 0.1416  time: 0.2239  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:18:44 d2.utils.events]: \u001b[0m eta: 3:51:06  iter: 32699  total_loss: 1.158  loss_cls: 0.2838  loss_box_reg: 0.3912  loss_mask: 0.2624  loss_rpn_cls: 0.06268  loss_rpn_loc: 0.166  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:18:48 d2.utils.events]: \u001b[0m eta: 3:51:06  iter: 32719  total_loss: 1.124  loss_cls: 0.2745  loss_box_reg: 0.3869  loss_mask: 0.2513  loss_rpn_cls: 0.05174  loss_rpn_loc: 0.1559  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:18:53 d2.utils.events]: \u001b[0m eta: 3:51:33  iter: 32739  total_loss: 1.151  loss_cls: 0.2909  loss_box_reg: 0.3843  loss_mask: 0.2554  loss_rpn_cls: 0.06413  loss_rpn_loc: 0.1676  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:18:58 d2.utils.events]: \u001b[0m eta: 3:51:36  iter: 32759  total_loss: 1.147  loss_cls: 0.2354  loss_box_reg: 0.3635  loss_mask: 0.2547  loss_rpn_cls: 0.06498  loss_rpn_loc: 0.1633  time: 0.2239  data_time: 0.0149  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:19:02 d2.utils.events]: \u001b[0m eta: 3:51:37  iter: 32779  total_loss: 1.249  loss_cls: 0.3027  loss_box_reg: 0.4088  loss_mask: 0.2663  loss_rpn_cls: 0.07238  loss_rpn_loc: 0.1682  time: 0.2239  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:19:06 d2.utils.events]: \u001b[0m eta: 3:51:26  iter: 32799  total_loss: 1.281  loss_cls: 0.3149  loss_box_reg: 0.4631  loss_mask: 0.2548  loss_rpn_cls: 0.06127  loss_rpn_loc: 0.1722  time: 0.2239  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:19:11 d2.utils.events]: \u001b[0m eta: 3:51:23  iter: 32819  total_loss: 1.251  loss_cls: 0.3386  loss_box_reg: 0.4111  loss_mask: 0.2773  loss_rpn_cls: 0.1036  loss_rpn_loc: 0.1971  time: 0.2239  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:19:16 d2.utils.events]: \u001b[0m eta: 3:51:28  iter: 32839  total_loss: 1.205  loss_cls: 0.2954  loss_box_reg: 0.3782  loss_mask: 0.2677  loss_rpn_cls: 0.1024  loss_rpn_loc: 0.1738  time: 0.2239  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:19:20 d2.utils.events]: \u001b[0m eta: 3:51:29  iter: 32859  total_loss: 1.041  loss_cls: 0.2284  loss_box_reg: 0.336  loss_mask: 0.2507  loss_rpn_cls: 0.05495  loss_rpn_loc: 0.1434  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:19:25 d2.utils.events]: \u001b[0m eta: 3:51:17  iter: 32879  total_loss: 1.267  loss_cls: 0.3255  loss_box_reg: 0.4607  loss_mask: 0.2798  loss_rpn_cls: 0.06409  loss_rpn_loc: 0.1575  time: 0.2239  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:19:29 d2.utils.events]: \u001b[0m eta: 3:51:15  iter: 32899  total_loss: 1.245  loss_cls: 0.331  loss_box_reg: 0.4124  loss_mask: 0.2526  loss_rpn_cls: 0.08129  loss_rpn_loc: 0.1898  time: 0.2239  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:19:33 d2.utils.events]: \u001b[0m eta: 3:51:01  iter: 32919  total_loss: 1.214  loss_cls: 0.2944  loss_box_reg: 0.4015  loss_mask: 0.2621  loss_rpn_cls: 0.07666  loss_rpn_loc: 0.1687  time: 0.2239  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:19:38 d2.utils.events]: \u001b[0m eta: 3:50:55  iter: 32939  total_loss: 1.17  loss_cls: 0.2613  loss_box_reg: 0.38  loss_mask: 0.271  loss_rpn_cls: 0.07692  loss_rpn_loc: 0.1671  time: 0.2239  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:19:42 d2.utils.events]: \u001b[0m eta: 3:50:40  iter: 32959  total_loss: 1.084  loss_cls: 0.2437  loss_box_reg: 0.3643  loss_mask: 0.2572  loss_rpn_cls: 0.07592  loss_rpn_loc: 0.1729  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:19:47 d2.utils.events]: \u001b[0m eta: 3:50:33  iter: 32979  total_loss: 1.276  loss_cls: 0.3024  loss_box_reg: 0.4091  loss_mask: 0.262  loss_rpn_cls: 0.07623  loss_rpn_loc: 0.1983  time: 0.2239  data_time: 0.0150  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:19:51 d2.utils.events]: \u001b[0m eta: 3:50:03  iter: 32999  total_loss: 1.304  loss_cls: 0.3261  loss_box_reg: 0.4494  loss_mask: 0.2723  loss_rpn_cls: 0.08779  loss_rpn_loc: 0.1824  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:19:55 d2.utils.events]: \u001b[0m eta: 3:49:36  iter: 33019  total_loss: 1.196  loss_cls: 0.2942  loss_box_reg: 0.3528  loss_mask: 0.2486  loss_rpn_cls: 0.08762  loss_rpn_loc: 0.1741  time: 0.2239  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:20:00 d2.utils.events]: \u001b[0m eta: 3:49:13  iter: 33039  total_loss: 1.171  loss_cls: 0.2766  loss_box_reg: 0.376  loss_mask: 0.2631  loss_rpn_cls: 0.07693  loss_rpn_loc: 0.1637  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:20:04 d2.utils.events]: \u001b[0m eta: 3:49:11  iter: 33059  total_loss: 1.119  loss_cls: 0.2656  loss_box_reg: 0.3844  loss_mask: 0.2607  loss_rpn_cls: 0.0566  loss_rpn_loc: 0.1599  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:20:08 d2.utils.events]: \u001b[0m eta: 3:49:02  iter: 33079  total_loss: 1.163  loss_cls: 0.2846  loss_box_reg: 0.3783  loss_mask: 0.246  loss_rpn_cls: 0.06444  loss_rpn_loc: 0.1832  time: 0.2238  data_time: 0.0092  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:20:13 d2.utils.events]: \u001b[0m eta: 3:49:02  iter: 33099  total_loss: 1.199  loss_cls: 0.323  loss_box_reg: 0.3945  loss_mask: 0.2642  loss_rpn_cls: 0.06687  loss_rpn_loc: 0.1612  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:20:17 d2.utils.events]: \u001b[0m eta: 3:48:58  iter: 33119  total_loss: 1.176  loss_cls: 0.2828  loss_box_reg: 0.3902  loss_mask: 0.258  loss_rpn_cls: 0.04995  loss_rpn_loc: 0.1541  time: 0.2238  data_time: 0.0163  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:20:22 d2.utils.events]: \u001b[0m eta: 3:48:54  iter: 33139  total_loss: 1.143  loss_cls: 0.2672  loss_box_reg: 0.3808  loss_mask: 0.2512  loss_rpn_cls: 0.08672  loss_rpn_loc: 0.1941  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:20:26 d2.utils.events]: \u001b[0m eta: 3:48:46  iter: 33159  total_loss: 1.219  loss_cls: 0.2997  loss_box_reg: 0.3794  loss_mask: 0.2549  loss_rpn_cls: 0.09199  loss_rpn_loc: 0.1708  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:20:30 d2.utils.events]: \u001b[0m eta: 3:48:36  iter: 33179  total_loss: 1.199  loss_cls: 0.2983  loss_box_reg: 0.3746  loss_mask: 0.2574  loss_rpn_cls: 0.08009  loss_rpn_loc: 0.1689  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:20:35 d2.utils.events]: \u001b[0m eta: 3:48:32  iter: 33199  total_loss: 1.254  loss_cls: 0.3036  loss_box_reg: 0.4226  loss_mask: 0.265  loss_rpn_cls: 0.09563  loss_rpn_loc: 0.1693  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:20:39 d2.utils.events]: \u001b[0m eta: 3:48:30  iter: 33219  total_loss: 1.18  loss_cls: 0.2582  loss_box_reg: 0.3838  loss_mask: 0.2565  loss_rpn_cls: 0.05615  loss_rpn_loc: 0.1724  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:20:44 d2.utils.events]: \u001b[0m eta: 3:48:17  iter: 33239  total_loss: 1.31  loss_cls: 0.3567  loss_box_reg: 0.4581  loss_mask: 0.2874  loss_rpn_cls: 0.08002  loss_rpn_loc: 0.1731  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:20:48 d2.utils.events]: \u001b[0m eta: 3:48:11  iter: 33259  total_loss: 1.2  loss_cls: 0.2761  loss_box_reg: 0.3431  loss_mask: 0.2534  loss_rpn_cls: 0.06468  loss_rpn_loc: 0.1511  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:20:53 d2.utils.events]: \u001b[0m eta: 3:48:12  iter: 33279  total_loss: 1.34  loss_cls: 0.3528  loss_box_reg: 0.3886  loss_mask: 0.2708  loss_rpn_cls: 0.07881  loss_rpn_loc: 0.1701  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:20:57 d2.utils.events]: \u001b[0m eta: 3:48:10  iter: 33299  total_loss: 1.078  loss_cls: 0.253  loss_box_reg: 0.3517  loss_mask: 0.2596  loss_rpn_cls: 0.06778  loss_rpn_loc: 0.1595  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:21:02 d2.utils.events]: \u001b[0m eta: 3:48:11  iter: 33319  total_loss: 1.173  loss_cls: 0.2927  loss_box_reg: 0.3804  loss_mask: 0.2671  loss_rpn_cls: 0.08361  loss_rpn_loc: 0.1673  time: 0.2238  data_time: 0.0142  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:21:07 d2.utils.events]: \u001b[0m eta: 3:48:08  iter: 33339  total_loss: 1.141  loss_cls: 0.2688  loss_box_reg: 0.3627  loss_mask: 0.2539  loss_rpn_cls: 0.07913  loss_rpn_loc: 0.1676  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:21:11 d2.utils.events]: \u001b[0m eta: 3:48:02  iter: 33359  total_loss: 1.15  loss_cls: 0.2752  loss_box_reg: 0.386  loss_mask: 0.2706  loss_rpn_cls: 0.08353  loss_rpn_loc: 0.1618  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:21:15 d2.utils.events]: \u001b[0m eta: 3:48:07  iter: 33379  total_loss: 1.174  loss_cls: 0.3062  loss_box_reg: 0.3677  loss_mask: 0.24  loss_rpn_cls: 0.09278  loss_rpn_loc: 0.1766  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:21:20 d2.utils.events]: \u001b[0m eta: 3:48:00  iter: 33399  total_loss: 1.085  loss_cls: 0.2892  loss_box_reg: 0.355  loss_mask: 0.2375  loss_rpn_cls: 0.07136  loss_rpn_loc: 0.1692  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:21:25 d2.utils.events]: \u001b[0m eta: 3:47:56  iter: 33419  total_loss: 1.228  loss_cls: 0.3315  loss_box_reg: 0.4026  loss_mask: 0.254  loss_rpn_cls: 0.04523  loss_rpn_loc: 0.1454  time: 0.2238  data_time: 0.0263  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:21:29 d2.utils.events]: \u001b[0m eta: 3:47:51  iter: 33439  total_loss: 1.341  loss_cls: 0.3597  loss_box_reg: 0.4345  loss_mask: 0.292  loss_rpn_cls: 0.08103  loss_rpn_loc: 0.1642  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:21:34 d2.utils.events]: \u001b[0m eta: 3:47:52  iter: 33459  total_loss: 1.236  loss_cls: 0.3086  loss_box_reg: 0.3521  loss_mask: 0.2713  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.1699  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:21:38 d2.utils.events]: \u001b[0m eta: 3:47:47  iter: 33479  total_loss: 1.341  loss_cls: 0.3553  loss_box_reg: 0.4  loss_mask: 0.2978  loss_rpn_cls: 0.08586  loss_rpn_loc: 0.1683  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:21:43 d2.utils.events]: \u001b[0m eta: 3:47:38  iter: 33499  total_loss: 1.175  loss_cls: 0.2879  loss_box_reg: 0.4359  loss_mask: 0.2824  loss_rpn_cls: 0.05781  loss_rpn_loc: 0.1656  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:21:47 d2.utils.events]: \u001b[0m eta: 3:47:31  iter: 33519  total_loss: 1.332  loss_cls: 0.3241  loss_box_reg: 0.435  loss_mask: 0.2776  loss_rpn_cls: 0.08142  loss_rpn_loc: 0.1867  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:21:52 d2.utils.events]: \u001b[0m eta: 3:47:25  iter: 33539  total_loss: 1.264  loss_cls: 0.3475  loss_box_reg: 0.4067  loss_mask: 0.2784  loss_rpn_cls: 0.0693  loss_rpn_loc: 0.158  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:21:56 d2.utils.events]: \u001b[0m eta: 3:47:25  iter: 33559  total_loss: 1.159  loss_cls: 0.289  loss_box_reg: 0.3585  loss_mask: 0.2642  loss_rpn_cls: 0.0817  loss_rpn_loc: 0.1811  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:22:01 d2.utils.events]: \u001b[0m eta: 3:47:26  iter: 33579  total_loss: 1.226  loss_cls: 0.3034  loss_box_reg: 0.392  loss_mask: 0.2587  loss_rpn_cls: 0.07602  loss_rpn_loc: 0.1755  time: 0.2238  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:22:05 d2.utils.events]: \u001b[0m eta: 3:47:16  iter: 33599  total_loss: 1.299  loss_cls: 0.3292  loss_box_reg: 0.4465  loss_mask: 0.2776  loss_rpn_cls: 0.07893  loss_rpn_loc: 0.1678  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:22:09 d2.utils.events]: \u001b[0m eta: 3:47:26  iter: 33619  total_loss: 1.236  loss_cls: 0.2858  loss_box_reg: 0.3571  loss_mask: 0.2685  loss_rpn_cls: 0.08183  loss_rpn_loc: 0.1685  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:22:14 d2.utils.events]: \u001b[0m eta: 3:47:13  iter: 33639  total_loss: 1.113  loss_cls: 0.2632  loss_box_reg: 0.3777  loss_mask: 0.2676  loss_rpn_cls: 0.08477  loss_rpn_loc: 0.162  time: 0.2238  data_time: 0.0093  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:22:19 d2.utils.events]: \u001b[0m eta: 3:47:34  iter: 33659  total_loss: 1.202  loss_cls: 0.2835  loss_box_reg: 0.3689  loss_mask: 0.2841  loss_rpn_cls: 0.08579  loss_rpn_loc: 0.1668  time: 0.2238  data_time: 0.0158  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:22:23 d2.utils.events]: \u001b[0m eta: 3:47:21  iter: 33679  total_loss: 1.172  loss_cls: 0.279  loss_box_reg: 0.37  loss_mask: 0.2615  loss_rpn_cls: 0.0605  loss_rpn_loc: 0.1518  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:22:28 d2.utils.events]: \u001b[0m eta: 3:47:15  iter: 33699  total_loss: 1.156  loss_cls: 0.2937  loss_box_reg: 0.3878  loss_mask: 0.2561  loss_rpn_cls: 0.07064  loss_rpn_loc: 0.1619  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:22:35 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.44 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/29 23:22:35 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/29 23:22:35 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/29 23:22:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/29 23:22:36 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 23:22:36 d2.data.common]: \u001b[0mSerialized dataset takes 84.20 MiB\n",
      "\u001b[32m[12/29 23:22:39 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.48 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/29 23:22:39 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/29 23:22:39 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/29 23:22:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/29 23:22:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0007 s/iter. Inference: 0.0619 s/iter. Eval: 0.1461 s/iter. Total: 0.2088 s/iter. ETA=0:01:56\n",
      "\u001b[32m[12/29 23:22:48 d2.evaluation.evaluator]: \u001b[0mInference done 39/570. Dataloading: 0.0008 s/iter. Inference: 0.0575 s/iter. Eval: 0.1289 s/iter. Total: 0.1873 s/iter. ETA=0:01:39\n",
      "\u001b[32m[12/29 23:22:53 d2.evaluation.evaluator]: \u001b[0mInference done 66/570. Dataloading: 0.0009 s/iter. Inference: 0.0571 s/iter. Eval: 0.1291 s/iter. Total: 0.1871 s/iter. ETA=0:01:34\n",
      "\u001b[32m[12/29 23:22:58 d2.evaluation.evaluator]: \u001b[0mInference done 91/570. Dataloading: 0.0009 s/iter. Inference: 0.0573 s/iter. Eval: 0.1344 s/iter. Total: 0.1927 s/iter. ETA=0:01:32\n",
      "\u001b[32m[12/29 23:23:03 d2.evaluation.evaluator]: \u001b[0mInference done 118/570. Dataloading: 0.0009 s/iter. Inference: 0.0565 s/iter. Eval: 0.1344 s/iter. Total: 0.1918 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/29 23:23:08 d2.evaluation.evaluator]: \u001b[0mInference done 143/570. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.1373 s/iter. Total: 0.1941 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/29 23:23:13 d2.evaluation.evaluator]: \u001b[0mInference done 162/570. Dataloading: 0.0009 s/iter. Inference: 0.0561 s/iter. Eval: 0.1465 s/iter. Total: 0.2035 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/29 23:23:19 d2.evaluation.evaluator]: \u001b[0mInference done 175/570. Dataloading: 0.0009 s/iter. Inference: 0.0566 s/iter. Eval: 0.1626 s/iter. Total: 0.2201 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/29 23:23:24 d2.evaluation.evaluator]: \u001b[0mInference done 192/570. Dataloading: 0.0009 s/iter. Inference: 0.0571 s/iter. Eval: 0.1706 s/iter. Total: 0.2287 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/29 23:23:29 d2.evaluation.evaluator]: \u001b[0mInference done 208/570. Dataloading: 0.0009 s/iter. Inference: 0.0575 s/iter. Eval: 0.1778 s/iter. Total: 0.2362 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/29 23:23:34 d2.evaluation.evaluator]: \u001b[0mInference done 225/570. Dataloading: 0.0009 s/iter. Inference: 0.0575 s/iter. Eval: 0.1827 s/iter. Total: 0.2411 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/29 23:23:40 d2.evaluation.evaluator]: \u001b[0mInference done 236/570. Dataloading: 0.0009 s/iter. Inference: 0.0576 s/iter. Eval: 0.1941 s/iter. Total: 0.2526 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/29 23:23:45 d2.evaluation.evaluator]: \u001b[0mInference done 249/570. Dataloading: 0.0009 s/iter. Inference: 0.0577 s/iter. Eval: 0.2033 s/iter. Total: 0.2620 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/29 23:23:50 d2.evaluation.evaluator]: \u001b[0mInference done 265/570. Dataloading: 0.0009 s/iter. Inference: 0.0578 s/iter. Eval: 0.2067 s/iter. Total: 0.2654 s/iter. ETA=0:01:20\n",
      "\u001b[32m[12/29 23:23:55 d2.evaluation.evaluator]: \u001b[0mInference done 283/570. Dataloading: 0.0009 s/iter. Inference: 0.0575 s/iter. Eval: 0.2084 s/iter. Total: 0.2669 s/iter. ETA=0:01:16\n",
      "\u001b[32m[12/29 23:24:01 d2.evaluation.evaluator]: \u001b[0mInference done 298/570. Dataloading: 0.0009 s/iter. Inference: 0.0576 s/iter. Eval: 0.2138 s/iter. Total: 0.2723 s/iter. ETA=0:01:14\n",
      "\u001b[32m[12/29 23:24:06 d2.evaluation.evaluator]: \u001b[0mInference done 346/570. Dataloading: 0.0009 s/iter. Inference: 0.0561 s/iter. Eval: 0.1916 s/iter. Total: 0.2487 s/iter. ETA=0:00:55\n",
      "\u001b[32m[12/29 23:24:11 d2.evaluation.evaluator]: \u001b[0mInference done 376/570. Dataloading: 0.0009 s/iter. Inference: 0.0558 s/iter. Eval: 0.1862 s/iter. Total: 0.2429 s/iter. ETA=0:00:47\n",
      "\u001b[32m[12/29 23:24:16 d2.evaluation.evaluator]: \u001b[0mInference done 398/570. Dataloading: 0.0009 s/iter. Inference: 0.0561 s/iter. Eval: 0.1853 s/iter. Total: 0.2423 s/iter. ETA=0:00:41\n",
      "\u001b[32m[12/29 23:24:22 d2.evaluation.evaluator]: \u001b[0mInference done 416/570. Dataloading: 0.0009 s/iter. Inference: 0.0562 s/iter. Eval: 0.1872 s/iter. Total: 0.2443 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 23:24:27 d2.evaluation.evaluator]: \u001b[0mInference done 435/570. Dataloading: 0.0009 s/iter. Inference: 0.0565 s/iter. Eval: 0.1878 s/iter. Total: 0.2452 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/29 23:24:32 d2.evaluation.evaluator]: \u001b[0mInference done 465/570. Dataloading: 0.0009 s/iter. Inference: 0.0562 s/iter. Eval: 0.1831 s/iter. Total: 0.2402 s/iter. ETA=0:00:25\n",
      "\u001b[32m[12/29 23:24:37 d2.evaluation.evaluator]: \u001b[0mInference done 495/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1791 s/iter. Total: 0.2358 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 23:24:42 d2.evaluation.evaluator]: \u001b[0mInference done 515/570. Dataloading: 0.0009 s/iter. Inference: 0.0556 s/iter. Eval: 0.1798 s/iter. Total: 0.2364 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/29 23:24:47 d2.evaluation.evaluator]: \u001b[0mInference done 539/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1791 s/iter. Total: 0.2357 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/29 23:24:52 d2.evaluation.evaluator]: \u001b[0mInference done 556/570. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.1810 s/iter. Total: 0.2379 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/29 23:24:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:14.912403 (0.238783 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 23:24:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.056022 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 23:24:56 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/29 23:24:56 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2845717418229795\n",
      "\u001b[32m[12/29 23:24:56 d2.utils.events]: \u001b[0m eta: 3:47:16  iter: 33719  total_loss: 1.143  loss_cls: 0.2607  loss_box_reg: 0.3809  loss_mask: 0.2647  loss_rpn_cls: 0.07458  loss_rpn_loc: 0.165  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:25:01 d2.utils.events]: \u001b[0m eta: 3:47:08  iter: 33739  total_loss: 1.149  loss_cls: 0.2753  loss_box_reg: 0.3447  loss_mask: 0.262  loss_rpn_cls: 0.06702  loss_rpn_loc: 0.1779  time: 0.2239  data_time: 0.0225  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:25:06 d2.utils.events]: \u001b[0m eta: 3:47:14  iter: 33759  total_loss: 1.243  loss_cls: 0.2831  loss_box_reg: 0.3916  loss_mask: 0.2634  loss_rpn_cls: 0.09555  loss_rpn_loc: 0.1755  time: 0.2239  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:25:10 d2.utils.events]: \u001b[0m eta: 3:46:57  iter: 33779  total_loss: 1.24  loss_cls: 0.2712  loss_box_reg: 0.3735  loss_mask: 0.2534  loss_rpn_cls: 0.07503  loss_rpn_loc: 0.1834  time: 0.2239  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:25:15 d2.utils.events]: \u001b[0m eta: 3:46:53  iter: 33799  total_loss: 1.173  loss_cls: 0.3016  loss_box_reg: 0.3871  loss_mask: 0.2583  loss_rpn_cls: 0.08667  loss_rpn_loc: 0.1614  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:25:19 d2.utils.events]: \u001b[0m eta: 3:46:36  iter: 33819  total_loss: 1.155  loss_cls: 0.2756  loss_box_reg: 0.3488  loss_mask: 0.2597  loss_rpn_cls: 0.07596  loss_rpn_loc: 0.163  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:25:24 d2.utils.events]: \u001b[0m eta: 3:46:16  iter: 33839  total_loss: 1.251  loss_cls: 0.3253  loss_box_reg: 0.4027  loss_mask: 0.2689  loss_rpn_cls: 0.06469  loss_rpn_loc: 0.1656  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:25:28 d2.utils.events]: \u001b[0m eta: 3:46:09  iter: 33859  total_loss: 1.174  loss_cls: 0.3081  loss_box_reg: 0.3625  loss_mask: 0.2536  loss_rpn_cls: 0.08378  loss_rpn_loc: 0.1709  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:25:33 d2.utils.events]: \u001b[0m eta: 3:46:21  iter: 33879  total_loss: 1.46  loss_cls: 0.4133  loss_box_reg: 0.4019  loss_mask: 0.285  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.1857  time: 0.2239  data_time: 0.0109  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:25:37 d2.utils.events]: \u001b[0m eta: 3:46:11  iter: 33899  total_loss: 1.144  loss_cls: 0.2761  loss_box_reg: 0.3887  loss_mask: 0.2576  loss_rpn_cls: 0.07644  loss_rpn_loc: 0.1751  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:25:42 d2.utils.events]: \u001b[0m eta: 3:46:38  iter: 33919  total_loss: 1.207  loss_cls: 0.3017  loss_box_reg: 0.3876  loss_mask: 0.2613  loss_rpn_cls: 0.0821  loss_rpn_loc: 0.1646  time: 0.2239  data_time: 0.0157  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:25:46 d2.utils.events]: \u001b[0m eta: 3:46:37  iter: 33939  total_loss: 1.175  loss_cls: 0.2991  loss_box_reg: 0.3843  loss_mask: 0.2598  loss_rpn_cls: 0.08436  loss_rpn_loc: 0.1583  time: 0.2239  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:25:51 d2.utils.events]: \u001b[0m eta: 3:46:31  iter: 33959  total_loss: 1.194  loss_cls: 0.2976  loss_box_reg: 0.378  loss_mask: 0.2612  loss_rpn_cls: 0.08724  loss_rpn_loc: 0.1609  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:25:55 d2.utils.events]: \u001b[0m eta: 3:46:36  iter: 33979  total_loss: 1.254  loss_cls: 0.2928  loss_box_reg: 0.3912  loss_mask: 0.2593  loss_rpn_cls: 0.08578  loss_rpn_loc: 0.1607  time: 0.2239  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:26:00 d2.utils.events]: \u001b[0m eta: 3:46:24  iter: 33999  total_loss: 1.259  loss_cls: 0.2845  loss_box_reg: 0.3793  loss_mask: 0.2662  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.1764  time: 0.2239  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:26:04 d2.utils.events]: \u001b[0m eta: 3:46:20  iter: 34019  total_loss: 1.199  loss_cls: 0.3044  loss_box_reg: 0.3765  loss_mask: 0.2689  loss_rpn_cls: 0.07533  loss_rpn_loc: 0.1673  time: 0.2239  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:26:09 d2.utils.events]: \u001b[0m eta: 3:46:41  iter: 34039  total_loss: 1.359  loss_cls: 0.3307  loss_box_reg: 0.4292  loss_mask: 0.261  loss_rpn_cls: 0.1019  loss_rpn_loc: 0.1616  time: 0.2239  data_time: 0.0164  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:26:13 d2.utils.events]: \u001b[0m eta: 3:46:30  iter: 34059  total_loss: 1.211  loss_cls: 0.2695  loss_box_reg: 0.3907  loss_mask: 0.2781  loss_rpn_cls: 0.06485  loss_rpn_loc: 0.1808  time: 0.2239  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:26:17 d2.utils.events]: \u001b[0m eta: 3:46:57  iter: 34079  total_loss: 1.157  loss_cls: 0.2785  loss_box_reg: 0.398  loss_mask: 0.2596  loss_rpn_cls: 0.05622  loss_rpn_loc: 0.1542  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:26:22 d2.utils.events]: \u001b[0m eta: 3:46:28  iter: 34099  total_loss: 1.218  loss_cls: 0.2936  loss_box_reg: 0.3924  loss_mask: 0.2682  loss_rpn_cls: 0.09681  loss_rpn_loc: 0.1723  time: 0.2238  data_time: 0.0092  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:26:26 d2.utils.events]: \u001b[0m eta: 3:45:56  iter: 34119  total_loss: 1.102  loss_cls: 0.2703  loss_box_reg: 0.3584  loss_mask: 0.2547  loss_rpn_cls: 0.06664  loss_rpn_loc: 0.1733  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:26:31 d2.utils.events]: \u001b[0m eta: 3:45:54  iter: 34139  total_loss: 1.038  loss_cls: 0.2668  loss_box_reg: 0.3548  loss_mask: 0.2449  loss_rpn_cls: 0.05628  loss_rpn_loc: 0.1518  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:26:35 d2.utils.events]: \u001b[0m eta: 3:45:47  iter: 34159  total_loss: 1.262  loss_cls: 0.3276  loss_box_reg: 0.3982  loss_mask: 0.2755  loss_rpn_cls: 0.06998  loss_rpn_loc: 0.1601  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:26:39 d2.utils.events]: \u001b[0m eta: 3:46:21  iter: 34179  total_loss: 1.133  loss_cls: 0.2672  loss_box_reg: 0.3487  loss_mask: 0.2553  loss_rpn_cls: 0.06345  loss_rpn_loc: 0.1638  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:26:44 d2.utils.events]: \u001b[0m eta: 3:45:52  iter: 34199  total_loss: 1.278  loss_cls: 0.318  loss_box_reg: 0.4325  loss_mask: 0.2762  loss_rpn_cls: 0.0906  loss_rpn_loc: 0.1798  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:26:48 d2.utils.events]: \u001b[0m eta: 3:45:44  iter: 34219  total_loss: 1.306  loss_cls: 0.328  loss_box_reg: 0.3746  loss_mask: 0.2735  loss_rpn_cls: 0.103  loss_rpn_loc: 0.1728  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:26:53 d2.utils.events]: \u001b[0m eta: 3:45:32  iter: 34239  total_loss: 1.133  loss_cls: 0.3087  loss_box_reg: 0.3864  loss_mask: 0.2643  loss_rpn_cls: 0.09128  loss_rpn_loc: 0.1669  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:26:57 d2.utils.events]: \u001b[0m eta: 3:45:26  iter: 34259  total_loss: 1.162  loss_cls: 0.2985  loss_box_reg: 0.3514  loss_mask: 0.2318  loss_rpn_cls: 0.05615  loss_rpn_loc: 0.1481  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:27:01 d2.utils.events]: \u001b[0m eta: 3:45:08  iter: 34279  total_loss: 1.276  loss_cls: 0.3286  loss_box_reg: 0.37  loss_mask: 0.2854  loss_rpn_cls: 0.1072  loss_rpn_loc: 0.1859  time: 0.2238  data_time: 0.0160  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:27:06 d2.utils.events]: \u001b[0m eta: 3:45:04  iter: 34299  total_loss: 1.211  loss_cls: 0.2717  loss_box_reg: 0.3445  loss_mask: 0.2532  loss_rpn_cls: 0.08965  loss_rpn_loc: 0.1704  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:27:11 d2.utils.events]: \u001b[0m eta: 3:44:33  iter: 34319  total_loss: 1.196  loss_cls: 0.2974  loss_box_reg: 0.4046  loss_mask: 0.2641  loss_rpn_cls: 0.06745  loss_rpn_loc: 0.1588  time: 0.2238  data_time: 0.0238  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:27:15 d2.utils.events]: \u001b[0m eta: 3:44:38  iter: 34339  total_loss: 1.323  loss_cls: 0.2952  loss_box_reg: 0.3621  loss_mask: 0.2865  loss_rpn_cls: 0.1043  loss_rpn_loc: 0.1811  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:27:20 d2.utils.events]: \u001b[0m eta: 3:44:27  iter: 34359  total_loss: 1.242  loss_cls: 0.3217  loss_box_reg: 0.3819  loss_mask: 0.2735  loss_rpn_cls: 0.07803  loss_rpn_loc: 0.1741  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:27:24 d2.utils.events]: \u001b[0m eta: 3:44:23  iter: 34379  total_loss: 1.15  loss_cls: 0.2825  loss_box_reg: 0.3638  loss_mask: 0.2617  loss_rpn_cls: 0.08647  loss_rpn_loc: 0.1835  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:27:29 d2.utils.events]: \u001b[0m eta: 3:44:21  iter: 34399  total_loss: 1.1  loss_cls: 0.2825  loss_box_reg: 0.367  loss_mask: 0.2609  loss_rpn_cls: 0.07204  loss_rpn_loc: 0.1619  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:27:34 d2.utils.events]: \u001b[0m eta: 3:44:37  iter: 34419  total_loss: 1.192  loss_cls: 0.3127  loss_box_reg: 0.3625  loss_mask: 0.2591  loss_rpn_cls: 0.08482  loss_rpn_loc: 0.1733  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:27:38 d2.utils.events]: \u001b[0m eta: 3:44:30  iter: 34439  total_loss: 1.251  loss_cls: 0.298  loss_box_reg: 0.3776  loss_mask: 0.2733  loss_rpn_cls: 0.09427  loss_rpn_loc: 0.1768  time: 0.2238  data_time: 0.0091  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:27:43 d2.utils.events]: \u001b[0m eta: 3:44:17  iter: 34459  total_loss: 1.316  loss_cls: 0.3111  loss_box_reg: 0.3956  loss_mask: 0.2774  loss_rpn_cls: 0.08919  loss_rpn_loc: 0.1798  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:27:47 d2.utils.events]: \u001b[0m eta: 3:44:22  iter: 34479  total_loss: 1.232  loss_cls: 0.331  loss_box_reg: 0.3654  loss_mask: 0.2366  loss_rpn_cls: 0.07794  loss_rpn_loc: 0.1891  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:27:52 d2.utils.events]: \u001b[0m eta: 3:44:13  iter: 34499  total_loss: 1.319  loss_cls: 0.3509  loss_box_reg: 0.4096  loss_mask: 0.2755  loss_rpn_cls: 0.09249  loss_rpn_loc: 0.1776  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:27:56 d2.utils.events]: \u001b[0m eta: 3:44:08  iter: 34519  total_loss: 1.21  loss_cls: 0.3276  loss_box_reg: 0.402  loss_mask: 0.2633  loss_rpn_cls: 0.09545  loss_rpn_loc: 0.1628  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:28:00 d2.utils.events]: \u001b[0m eta: 3:43:50  iter: 34539  total_loss: 1.176  loss_cls: 0.2865  loss_box_reg: 0.404  loss_mask: 0.2705  loss_rpn_cls: 0.07115  loss_rpn_loc: 0.1713  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:28:05 d2.utils.events]: \u001b[0m eta: 3:43:39  iter: 34559  total_loss: 1.22  loss_cls: 0.334  loss_box_reg: 0.3941  loss_mask: 0.2504  loss_rpn_cls: 0.07235  loss_rpn_loc: 0.1709  time: 0.2238  data_time: 0.0229  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:28:09 d2.utils.events]: \u001b[0m eta: 3:42:57  iter: 34579  total_loss: 1.362  loss_cls: 0.3499  loss_box_reg: 0.4365  loss_mask: 0.2754  loss_rpn_cls: 0.09097  loss_rpn_loc: 0.1583  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:28:14 d2.utils.events]: \u001b[0m eta: 3:43:02  iter: 34599  total_loss: 1.162  loss_cls: 0.2848  loss_box_reg: 0.3758  loss_mask: 0.2578  loss_rpn_cls: 0.07157  loss_rpn_loc: 0.1748  time: 0.2238  data_time: 0.0091  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:28:18 d2.utils.events]: \u001b[0m eta: 3:43:01  iter: 34619  total_loss: 1.309  loss_cls: 0.3277  loss_box_reg: 0.3891  loss_mask: 0.2881  loss_rpn_cls: 0.09642  loss_rpn_loc: 0.1822  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:28:23 d2.utils.events]: \u001b[0m eta: 3:42:50  iter: 34639  total_loss: 1.221  loss_cls: 0.3164  loss_box_reg: 0.4184  loss_mask: 0.2642  loss_rpn_cls: 0.05523  loss_rpn_loc: 0.1521  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:28:27 d2.utils.events]: \u001b[0m eta: 3:42:28  iter: 34659  total_loss: 1.236  loss_cls: 0.3315  loss_box_reg: 0.3995  loss_mask: 0.2411  loss_rpn_cls: 0.07594  loss_rpn_loc: 0.1784  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:28:31 d2.utils.events]: \u001b[0m eta: 3:42:26  iter: 34679  total_loss: 1.205  loss_cls: 0.2998  loss_box_reg: 0.3906  loss_mask: 0.2676  loss_rpn_cls: 0.07935  loss_rpn_loc: 0.1674  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:28:36 d2.utils.events]: \u001b[0m eta: 3:42:40  iter: 34699  total_loss: 1.191  loss_cls: 0.3285  loss_box_reg: 0.3742  loss_mask: 0.2729  loss_rpn_cls: 0.07255  loss_rpn_loc: 0.1618  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:28:41 d2.utils.events]: \u001b[0m eta: 3:42:50  iter: 34719  total_loss: 1.228  loss_cls: 0.3123  loss_box_reg: 0.3433  loss_mask: 0.2758  loss_rpn_cls: 0.09064  loss_rpn_loc: 0.1812  time: 0.2238  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:28:45 d2.utils.events]: \u001b[0m eta: 3:42:29  iter: 34739  total_loss: 1.178  loss_cls: 0.3052  loss_box_reg: 0.3827  loss_mask: 0.2703  loss_rpn_cls: 0.08526  loss_rpn_loc: 0.1679  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:28:50 d2.utils.events]: \u001b[0m eta: 3:42:06  iter: 34759  total_loss: 1.135  loss_cls: 0.2799  loss_box_reg: 0.3512  loss_mask: 0.2502  loss_rpn_cls: 0.07046  loss_rpn_loc: 0.1552  time: 0.2238  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:28:54 d2.utils.events]: \u001b[0m eta: 3:41:32  iter: 34779  total_loss: 1.192  loss_cls: 0.2967  loss_box_reg: 0.4191  loss_mask: 0.2725  loss_rpn_cls: 0.06442  loss_rpn_loc: 0.1592  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:28:58 d2.utils.events]: \u001b[0m eta: 3:41:28  iter: 34799  total_loss: 1.221  loss_cls: 0.3088  loss_box_reg: 0.4427  loss_mask: 0.2882  loss_rpn_cls: 0.08472  loss_rpn_loc: 0.1627  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:29:03 d2.utils.events]: \u001b[0m eta: 3:41:54  iter: 34819  total_loss: 1.194  loss_cls: 0.3033  loss_box_reg: 0.4046  loss_mask: 0.2774  loss_rpn_cls: 0.08769  loss_rpn_loc: 0.1629  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:29:07 d2.utils.events]: \u001b[0m eta: 3:42:09  iter: 34839  total_loss: 1.334  loss_cls: 0.3209  loss_box_reg: 0.409  loss_mask: 0.294  loss_rpn_cls: 0.08796  loss_rpn_loc: 0.1763  time: 0.2238  data_time: 0.0148  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:29:12 d2.utils.events]: \u001b[0m eta: 3:42:06  iter: 34859  total_loss: 1.175  loss_cls: 0.3013  loss_box_reg: 0.378  loss_mask: 0.2616  loss_rpn_cls: 0.08402  loss_rpn_loc: 0.1649  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:29:17 d2.utils.events]: \u001b[0m eta: 3:41:45  iter: 34879  total_loss: 1.336  loss_cls: 0.3465  loss_box_reg: 0.4662  loss_mask: 0.2765  loss_rpn_cls: 0.09002  loss_rpn_loc: 0.1839  time: 0.2238  data_time: 0.0213  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:29:21 d2.utils.events]: \u001b[0m eta: 3:41:41  iter: 34899  total_loss: 1.245  loss_cls: 0.3025  loss_box_reg: 0.368  loss_mask: 0.2648  loss_rpn_cls: 0.07733  loss_rpn_loc: 0.1557  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:29:25 d2.utils.events]: \u001b[0m eta: 3:40:59  iter: 34919  total_loss: 1.225  loss_cls: 0.317  loss_box_reg: 0.4033  loss_mask: 0.2646  loss_rpn_cls: 0.07462  loss_rpn_loc: 0.162  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:29:30 d2.utils.events]: \u001b[0m eta: 3:40:51  iter: 34939  total_loss: 1.178  loss_cls: 0.2864  loss_box_reg: 0.3792  loss_mask: 0.2856  loss_rpn_cls: 0.07761  loss_rpn_loc: 0.1819  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:29:34 d2.utils.events]: \u001b[0m eta: 3:40:38  iter: 34959  total_loss: 1.241  loss_cls: 0.3307  loss_box_reg: 0.4073  loss_mask: 0.2607  loss_rpn_cls: 0.05824  loss_rpn_loc: 0.1627  time: 0.2238  data_time: 0.0056  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:29:38 d2.utils.events]: \u001b[0m eta: 3:40:35  iter: 34979  total_loss: 1.27  loss_cls: 0.3056  loss_box_reg: 0.3798  loss_mask: 0.2731  loss_rpn_cls: 0.1406  loss_rpn_loc: 0.1865  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:29:43 d2.utils.events]: \u001b[0m eta: 3:40:41  iter: 34999  total_loss: 1.272  loss_cls: 0.3161  loss_box_reg: 0.3792  loss_mask: 0.2665  loss_rpn_cls: 0.09229  loss_rpn_loc: 0.1733  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:29:47 d2.utils.events]: \u001b[0m eta: 3:40:39  iter: 35019  total_loss: 1.136  loss_cls: 0.273  loss_box_reg: 0.3898  loss_mask: 0.2561  loss_rpn_cls: 0.06439  loss_rpn_loc: 0.1633  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:29:52 d2.utils.events]: \u001b[0m eta: 3:40:30  iter: 35039  total_loss: 1.196  loss_cls: 0.3242  loss_box_reg: 0.4127  loss_mask: 0.2715  loss_rpn_cls: 0.07601  loss_rpn_loc: 0.1677  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:29:56 d2.utils.events]: \u001b[0m eta: 3:40:26  iter: 35059  total_loss: 1.098  loss_cls: 0.2511  loss_box_reg: 0.3476  loss_mask: 0.2503  loss_rpn_cls: 0.05362  loss_rpn_loc: 0.1465  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:30:00 d2.utils.events]: \u001b[0m eta: 3:40:24  iter: 35079  total_loss: 1.261  loss_cls: 0.3007  loss_box_reg: 0.4358  loss_mask: 0.2762  loss_rpn_cls: 0.06641  loss_rpn_loc: 0.1653  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:30:05 d2.utils.events]: \u001b[0m eta: 3:40:21  iter: 35099  total_loss: 1.11  loss_cls: 0.2252  loss_box_reg: 0.3299  loss_mask: 0.2622  loss_rpn_cls: 0.0818  loss_rpn_loc: 0.1677  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:30:09 d2.utils.events]: \u001b[0m eta: 3:40:17  iter: 35119  total_loss: 1.086  loss_cls: 0.2705  loss_box_reg: 0.3608  loss_mask: 0.2484  loss_rpn_cls: 0.0665  loss_rpn_loc: 0.1542  time: 0.2238  data_time: 0.0057  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:30:14 d2.utils.events]: \u001b[0m eta: 3:40:06  iter: 35139  total_loss: 1.219  loss_cls: 0.3259  loss_box_reg: 0.3958  loss_mask: 0.2598  loss_rpn_cls: 0.09256  loss_rpn_loc: 0.1789  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:30:18 d2.utils.events]: \u001b[0m eta: 3:40:08  iter: 35159  total_loss: 1.129  loss_cls: 0.261  loss_box_reg: 0.3681  loss_mask: 0.2611  loss_rpn_cls: 0.06135  loss_rpn_loc: 0.1569  time: 0.2238  data_time: 0.0120  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:30:23 d2.utils.events]: \u001b[0m eta: 3:39:54  iter: 35179  total_loss: 1.188  loss_cls: 0.2845  loss_box_reg: 0.4146  loss_mask: 0.2661  loss_rpn_cls: 0.07543  loss_rpn_loc: 0.1564  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:30:27 d2.utils.events]: \u001b[0m eta: 3:39:46  iter: 35199  total_loss: 1.258  loss_cls: 0.3354  loss_box_reg: 0.406  loss_mask: 0.269  loss_rpn_cls: 0.06924  loss_rpn_loc: 0.1686  time: 0.2238  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:30:32 d2.utils.events]: \u001b[0m eta: 3:39:46  iter: 35219  total_loss: 1.217  loss_cls: 0.2739  loss_box_reg: 0.3752  loss_mask: 0.2754  loss_rpn_cls: 0.07056  loss_rpn_loc: 0.1472  time: 0.2238  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:30:36 d2.utils.events]: \u001b[0m eta: 3:39:54  iter: 35239  total_loss: 1.081  loss_cls: 0.2482  loss_box_reg: 0.3744  loss_mask: 0.2568  loss_rpn_cls: 0.06191  loss_rpn_loc: 0.154  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:30:41 d2.utils.events]: \u001b[0m eta: 3:40:02  iter: 35259  total_loss: 1.321  loss_cls: 0.3368  loss_box_reg: 0.4374  loss_mask: 0.2753  loss_rpn_cls: 0.07322  loss_rpn_loc: 0.1698  time: 0.2238  data_time: 0.0176  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:30:45 d2.utils.events]: \u001b[0m eta: 3:40:08  iter: 35279  total_loss: 1.133  loss_cls: 0.2568  loss_box_reg: 0.3689  loss_mask: 0.255  loss_rpn_cls: 0.08418  loss_rpn_loc: 0.1684  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:30:49 d2.utils.events]: \u001b[0m eta: 3:39:46  iter: 35299  total_loss: 1.225  loss_cls: 0.29  loss_box_reg: 0.3927  loss_mask: 0.2582  loss_rpn_cls: 0.06116  loss_rpn_loc: 0.1767  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:30:54 d2.utils.events]: \u001b[0m eta: 3:40:04  iter: 35319  total_loss: 1.322  loss_cls: 0.3189  loss_box_reg: 0.41  loss_mask: 0.2893  loss_rpn_cls: 0.06838  loss_rpn_loc: 0.1742  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:30:58 d2.utils.events]: \u001b[0m eta: 3:39:38  iter: 35339  total_loss: 1.18  loss_cls: 0.3256  loss_box_reg: 0.354  loss_mask: 0.2571  loss_rpn_cls: 0.1035  loss_rpn_loc: 0.1666  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:31:03 d2.utils.events]: \u001b[0m eta: 3:39:57  iter: 35359  total_loss: 1.057  loss_cls: 0.2598  loss_box_reg: 0.3546  loss_mask: 0.2382  loss_rpn_cls: 0.06066  loss_rpn_loc: 0.1434  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:31:08 d2.utils.events]: \u001b[0m eta: 3:40:00  iter: 35379  total_loss: 1.175  loss_cls: 0.324  loss_box_reg: 0.3669  loss_mask: 0.2698  loss_rpn_cls: 0.0621  loss_rpn_loc: 0.1713  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:31:12 d2.utils.events]: \u001b[0m eta: 3:40:02  iter: 35399  total_loss: 1.317  loss_cls: 0.3282  loss_box_reg: 0.3884  loss_mask: 0.2727  loss_rpn_cls: 0.07332  loss_rpn_loc: 0.175  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:31:16 d2.utils.events]: \u001b[0m eta: 3:39:43  iter: 35419  total_loss: 1.212  loss_cls: 0.3286  loss_box_reg: 0.3964  loss_mask: 0.2516  loss_rpn_cls: 0.06879  loss_rpn_loc: 0.1547  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:31:21 d2.utils.events]: \u001b[0m eta: 3:39:40  iter: 35439  total_loss: 1.175  loss_cls: 0.2961  loss_box_reg: 0.3797  loss_mask: 0.2569  loss_rpn_cls: 0.05878  loss_rpn_loc: 0.1436  time: 0.2238  data_time: 0.0132  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:31:26 d2.utils.events]: \u001b[0m eta: 3:39:36  iter: 35459  total_loss: 1.275  loss_cls: 0.2747  loss_box_reg: 0.3758  loss_mask: 0.3003  loss_rpn_cls: 0.09605  loss_rpn_loc: 0.1763  time: 0.2238  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:31:30 d2.utils.events]: \u001b[0m eta: 3:39:34  iter: 35479  total_loss: 1.221  loss_cls: 0.3307  loss_box_reg: 0.397  loss_mask: 0.262  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.1879  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:31:35 d2.utils.events]: \u001b[0m eta: 3:39:21  iter: 35499  total_loss: 1.221  loss_cls: 0.3308  loss_box_reg: 0.4011  loss_mask: 0.2612  loss_rpn_cls: 0.06728  loss_rpn_loc: 0.1677  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:31:39 d2.utils.events]: \u001b[0m eta: 3:39:37  iter: 35519  total_loss: 1.284  loss_cls: 0.2953  loss_box_reg: 0.4015  loss_mask: 0.2932  loss_rpn_cls: 0.1057  loss_rpn_loc: 0.1877  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:31:44 d2.utils.events]: \u001b[0m eta: 3:39:42  iter: 35539  total_loss: 1.321  loss_cls: 0.324  loss_box_reg: 0.4452  loss_mask: 0.2875  loss_rpn_cls: 0.07767  loss_rpn_loc: 0.1818  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:31:48 d2.utils.events]: \u001b[0m eta: 3:39:48  iter: 35559  total_loss: 1.307  loss_cls: 0.3458  loss_box_reg: 0.4126  loss_mask: 0.2759  loss_rpn_cls: 0.07984  loss_rpn_loc: 0.1914  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:31:53 d2.utils.events]: \u001b[0m eta: 3:40:09  iter: 35579  total_loss: 1.063  loss_cls: 0.2691  loss_box_reg: 0.3569  loss_mask: 0.2474  loss_rpn_cls: 0.07131  loss_rpn_loc: 0.1542  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:31:57 d2.utils.events]: \u001b[0m eta: 3:40:01  iter: 35599  total_loss: 1.203  loss_cls: 0.304  loss_box_reg: 0.385  loss_mask: 0.2649  loss_rpn_cls: 0.07293  loss_rpn_loc: 0.1539  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:32:02 d2.utils.events]: \u001b[0m eta: 3:39:50  iter: 35619  total_loss: 1.06  loss_cls: 0.2169  loss_box_reg: 0.3586  loss_mask: 0.2463  loss_rpn_cls: 0.06788  loss_rpn_loc: 0.1538  time: 0.2238  data_time: 0.0173  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:32:07 d2.utils.events]: \u001b[0m eta: 3:39:59  iter: 35639  total_loss: 1.136  loss_cls: 0.2677  loss_box_reg: 0.3443  loss_mask: 0.2608  loss_rpn_cls: 0.08321  loss_rpn_loc: 0.1874  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:32:11 d2.utils.events]: \u001b[0m eta: 3:40:03  iter: 35659  total_loss: 1.228  loss_cls: 0.2863  loss_box_reg: 0.3808  loss_mask: 0.2592  loss_rpn_cls: 0.08257  loss_rpn_loc: 0.1891  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:32:16 d2.utils.events]: \u001b[0m eta: 3:40:07  iter: 35679  total_loss: 1.206  loss_cls: 0.3052  loss_box_reg: 0.3677  loss_mask: 0.2654  loss_rpn_cls: 0.08601  loss_rpn_loc: 0.1791  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:32:20 d2.utils.events]: \u001b[0m eta: 3:40:00  iter: 35699  total_loss: 1.182  loss_cls: 0.3032  loss_box_reg: 0.3732  loss_mask: 0.2537  loss_rpn_cls: 0.06578  loss_rpn_loc: 0.1644  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:32:24 d2.utils.events]: \u001b[0m eta: 3:39:55  iter: 35719  total_loss: 1.132  loss_cls: 0.2469  loss_box_reg: 0.3573  loss_mask: 0.258  loss_rpn_cls: 0.0721  loss_rpn_loc: 0.163  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:32:29 d2.utils.events]: \u001b[0m eta: 3:39:51  iter: 35739  total_loss: 1.215  loss_cls: 0.2762  loss_box_reg: 0.4385  loss_mask: 0.2536  loss_rpn_cls: 0.05821  loss_rpn_loc: 0.1553  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:32:34 d2.utils.events]: \u001b[0m eta: 3:40:01  iter: 35759  total_loss: 1.238  loss_cls: 0.3151  loss_box_reg: 0.3716  loss_mask: 0.2577  loss_rpn_cls: 0.07883  loss_rpn_loc: 0.1695  time: 0.2238  data_time: 0.0166  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:32:38 d2.utils.events]: \u001b[0m eta: 3:40:23  iter: 35779  total_loss: 1.247  loss_cls: 0.3094  loss_box_reg: 0.3833  loss_mask: 0.2634  loss_rpn_cls: 0.08476  loss_rpn_loc: 0.1741  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:32:43 d2.utils.events]: \u001b[0m eta: 3:40:23  iter: 35799  total_loss: 1.144  loss_cls: 0.2819  loss_box_reg: 0.3687  loss_mask: 0.2695  loss_rpn_cls: 0.07412  loss_rpn_loc: 0.1508  time: 0.2238  data_time: 0.0097  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:32:47 d2.utils.events]: \u001b[0m eta: 3:40:21  iter: 35819  total_loss: 1.201  loss_cls: 0.2967  loss_box_reg: 0.388  loss_mask: 0.2804  loss_rpn_cls: 0.06296  loss_rpn_loc: 0.1648  time: 0.2238  data_time: 0.0152  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:32:52 d2.utils.events]: \u001b[0m eta: 3:40:03  iter: 35839  total_loss: 1.092  loss_cls: 0.264  loss_box_reg: 0.3868  loss_mask: 0.2511  loss_rpn_cls: 0.05564  loss_rpn_loc: 0.1417  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:32:56 d2.utils.events]: \u001b[0m eta: 3:39:51  iter: 35859  total_loss: 1.208  loss_cls: 0.2951  loss_box_reg: 0.409  loss_mask: 0.2768  loss_rpn_cls: 0.06657  loss_rpn_loc: 0.1629  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:33:01 d2.utils.events]: \u001b[0m eta: 3:39:47  iter: 35879  total_loss: 1.151  loss_cls: 0.3122  loss_box_reg: 0.3719  loss_mask: 0.258  loss_rpn_cls: 0.07452  loss_rpn_loc: 0.1712  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:33:05 d2.utils.events]: \u001b[0m eta: 3:39:43  iter: 35899  total_loss: 1.227  loss_cls: 0.3032  loss_box_reg: 0.3985  loss_mask: 0.2639  loss_rpn_cls: 0.07097  loss_rpn_loc: 0.166  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:33:10 d2.utils.events]: \u001b[0m eta: 3:40:20  iter: 35919  total_loss: 1.187  loss_cls: 0.2919  loss_box_reg: 0.3715  loss_mask: 0.2689  loss_rpn_cls: 0.113  loss_rpn_loc: 0.1893  time: 0.2238  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:33:15 d2.utils.events]: \u001b[0m eta: 3:40:23  iter: 35939  total_loss: 1.257  loss_cls: 0.299  loss_box_reg: 0.3692  loss_mask: 0.2762  loss_rpn_cls: 0.09856  loss_rpn_loc: 0.1802  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:33:19 d2.utils.events]: \u001b[0m eta: 3:40:26  iter: 35959  total_loss: 1.193  loss_cls: 0.3119  loss_box_reg: 0.3908  loss_mask: 0.2702  loss_rpn_cls: 0.06271  loss_rpn_loc: 0.1572  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:33:23 d2.utils.events]: \u001b[0m eta: 3:40:16  iter: 35979  total_loss: 1.122  loss_cls: 0.2815  loss_box_reg: 0.3656  loss_mask: 0.2588  loss_rpn_cls: 0.06616  loss_rpn_loc: 0.1711  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:33:28 d2.utils.events]: \u001b[0m eta: 3:39:56  iter: 35999  total_loss: 1.321  loss_cls: 0.3406  loss_box_reg: 0.4107  loss_mask: 0.2891  loss_rpn_cls: 0.07413  loss_rpn_loc: 0.1523  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:33:32 d2.utils.events]: \u001b[0m eta: 3:40:02  iter: 36019  total_loss: 1.208  loss_cls: 0.316  loss_box_reg: 0.4211  loss_mask: 0.2693  loss_rpn_cls: 0.08856  loss_rpn_loc: 0.1685  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:33:37 d2.utils.events]: \u001b[0m eta: 3:40:04  iter: 36039  total_loss: 1.133  loss_cls: 0.2604  loss_box_reg: 0.3714  loss_mask: 0.2566  loss_rpn_cls: 0.07676  loss_rpn_loc: 0.1563  time: 0.2238  data_time: 0.0176  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:33:42 d2.utils.events]: \u001b[0m eta: 3:40:09  iter: 36059  total_loss: 1.287  loss_cls: 0.3294  loss_box_reg: 0.4078  loss_mask: 0.2763  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.1881  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:33:46 d2.utils.events]: \u001b[0m eta: 3:40:10  iter: 36079  total_loss: 1.153  loss_cls: 0.2774  loss_box_reg: 0.3578  loss_mask: 0.2476  loss_rpn_cls: 0.06392  loss_rpn_loc: 0.1738  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:33:51 d2.utils.events]: \u001b[0m eta: 3:40:08  iter: 36099  total_loss: 1.226  loss_cls: 0.3041  loss_box_reg: 0.3703  loss_mask: 0.271  loss_rpn_cls: 0.06924  loss_rpn_loc: 0.1501  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:33:55 d2.utils.events]: \u001b[0m eta: 3:40:18  iter: 36119  total_loss: 1.039  loss_cls: 0.2099  loss_box_reg: 0.354  loss_mask: 0.2541  loss_rpn_cls: 0.06958  loss_rpn_loc: 0.1571  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:34:00 d2.utils.events]: \u001b[0m eta: 3:40:31  iter: 36139  total_loss: 1.167  loss_cls: 0.3096  loss_box_reg: 0.3899  loss_mask: 0.262  loss_rpn_cls: 0.09256  loss_rpn_loc: 0.1686  time: 0.2238  data_time: 0.0156  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:34:04 d2.utils.events]: \u001b[0m eta: 3:40:19  iter: 36159  total_loss: 1.199  loss_cls: 0.2896  loss_box_reg: 0.4072  loss_mask: 0.2686  loss_rpn_cls: 0.0701  loss_rpn_loc: 0.1558  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:34:09 d2.utils.events]: \u001b[0m eta: 3:40:22  iter: 36179  total_loss: 1.142  loss_cls: 0.2842  loss_box_reg: 0.3871  loss_mask: 0.2634  loss_rpn_cls: 0.06741  loss_rpn_loc: 0.16  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:34:13 d2.utils.events]: \u001b[0m eta: 3:40:30  iter: 36199  total_loss: 1.133  loss_cls: 0.2601  loss_box_reg: 0.3736  loss_mask: 0.2488  loss_rpn_cls: 0.06289  loss_rpn_loc: 0.1503  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:34:18 d2.utils.events]: \u001b[0m eta: 3:40:17  iter: 36219  total_loss: 1.237  loss_cls: 0.3316  loss_box_reg: 0.3998  loss_mask: 0.2553  loss_rpn_cls: 0.07843  loss_rpn_loc: 0.1797  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:34:22 d2.utils.events]: \u001b[0m eta: 3:40:15  iter: 36239  total_loss: 1.194  loss_cls: 0.3094  loss_box_reg: 0.4005  loss_mask: 0.2554  loss_rpn_cls: 0.07312  loss_rpn_loc: 0.149  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:34:27 d2.utils.events]: \u001b[0m eta: 3:40:08  iter: 36259  total_loss: 1.178  loss_cls: 0.2854  loss_box_reg: 0.3787  loss_mask: 0.254  loss_rpn_cls: 0.067  loss_rpn_loc: 0.1698  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:34:31 d2.utils.events]: \u001b[0m eta: 3:40:09  iter: 36279  total_loss: 1.134  loss_cls: 0.2518  loss_box_reg: 0.3805  loss_mask: 0.2639  loss_rpn_cls: 0.06343  loss_rpn_loc: 0.1625  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:34:36 d2.utils.events]: \u001b[0m eta: 3:40:12  iter: 36299  total_loss: 1.237  loss_cls: 0.3134  loss_box_reg: 0.4076  loss_mask: 0.2647  loss_rpn_cls: 0.07656  loss_rpn_loc: 0.1638  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:34:40 d2.utils.events]: \u001b[0m eta: 3:40:08  iter: 36319  total_loss: 1.176  loss_cls: 0.294  loss_box_reg: 0.3694  loss_mask: 0.2675  loss_rpn_cls: 0.08994  loss_rpn_loc: 0.157  time: 0.2238  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:34:45 d2.utils.events]: \u001b[0m eta: 3:40:05  iter: 36339  total_loss: 1.304  loss_cls: 0.3274  loss_box_reg: 0.3938  loss_mask: 0.2676  loss_rpn_cls: 0.09449  loss_rpn_loc: 0.177  time: 0.2238  data_time: 0.0107  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:34:49 d2.utils.events]: \u001b[0m eta: 3:40:10  iter: 36359  total_loss: 1.279  loss_cls: 0.2979  loss_box_reg: 0.4082  loss_mask: 0.2902  loss_rpn_cls: 0.09541  loss_rpn_loc: 0.1828  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:34:54 d2.utils.events]: \u001b[0m eta: 3:39:55  iter: 36379  total_loss: 1.104  loss_cls: 0.2883  loss_box_reg: 0.3668  loss_mask: 0.2476  loss_rpn_cls: 0.0764  loss_rpn_loc: 0.1635  time: 0.2238  data_time: 0.0136  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:34:58 d2.utils.events]: \u001b[0m eta: 3:39:37  iter: 36399  total_loss: 1.263  loss_cls: 0.3057  loss_box_reg: 0.3971  loss_mask: 0.2609  loss_rpn_cls: 0.06121  loss_rpn_loc: 0.1713  time: 0.2238  data_time: 0.0185  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:35:03 d2.utils.events]: \u001b[0m eta: 3:39:39  iter: 36419  total_loss: 1.178  loss_cls: 0.3071  loss_box_reg: 0.3799  loss_mask: 0.2541  loss_rpn_cls: 0.07348  loss_rpn_loc: 0.1621  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:35:07 d2.utils.events]: \u001b[0m eta: 3:39:37  iter: 36439  total_loss: 1.172  loss_cls: 0.2775  loss_box_reg: 0.3658  loss_mask: 0.2759  loss_rpn_cls: 0.08384  loss_rpn_loc: 0.1655  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:35:12 d2.utils.events]: \u001b[0m eta: 3:39:35  iter: 36459  total_loss: 1.228  loss_cls: 0.2843  loss_box_reg: 0.3748  loss_mask: 0.2662  loss_rpn_cls: 0.09516  loss_rpn_loc: 0.1713  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:35:16 d2.utils.events]: \u001b[0m eta: 3:39:20  iter: 36479  total_loss: 1.408  loss_cls: 0.336  loss_box_reg: 0.4484  loss_mask: 0.2766  loss_rpn_cls: 0.09164  loss_rpn_loc: 0.204  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:35:20 d2.utils.events]: \u001b[0m eta: 3:39:28  iter: 36499  total_loss: 1.282  loss_cls: 0.3679  loss_box_reg: 0.3988  loss_mask: 0.278  loss_rpn_cls: 0.09495  loss_rpn_loc: 0.193  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:35:25 d2.utils.events]: \u001b[0m eta: 3:39:07  iter: 36519  total_loss: 1.213  loss_cls: 0.2991  loss_box_reg: 0.4103  loss_mask: 0.2608  loss_rpn_cls: 0.06915  loss_rpn_loc: 0.1617  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:35:29 d2.utils.events]: \u001b[0m eta: 3:39:02  iter: 36539  total_loss: 1.206  loss_cls: 0.3147  loss_box_reg: 0.4043  loss_mask: 0.2669  loss_rpn_cls: 0.07941  loss_rpn_loc: 0.1699  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:35:33 d2.utils.events]: \u001b[0m eta: 3:38:44  iter: 36559  total_loss: 1.181  loss_cls: 0.2943  loss_box_reg: 0.3833  loss_mask: 0.2648  loss_rpn_cls: 0.06426  loss_rpn_loc: 0.1634  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:35:38 d2.utils.events]: \u001b[0m eta: 3:38:37  iter: 36579  total_loss: 1.12  loss_cls: 0.3093  loss_box_reg: 0.3469  loss_mask: 0.2458  loss_rpn_cls: 0.06199  loss_rpn_loc: 0.1466  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:35:42 d2.utils.events]: \u001b[0m eta: 3:38:28  iter: 36599  total_loss: 1.145  loss_cls: 0.2588  loss_box_reg: 0.3642  loss_mask: 0.2561  loss_rpn_cls: 0.04973  loss_rpn_loc: 0.1313  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:35:47 d2.utils.events]: \u001b[0m eta: 3:38:26  iter: 36619  total_loss: 1.196  loss_cls: 0.2953  loss_box_reg: 0.3925  loss_mask: 0.2793  loss_rpn_cls: 0.0812  loss_rpn_loc: 0.1815  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:35:52 d2.utils.events]: \u001b[0m eta: 3:38:19  iter: 36639  total_loss: 1.25  loss_cls: 0.3229  loss_box_reg: 0.3915  loss_mask: 0.2706  loss_rpn_cls: 0.09661  loss_rpn_loc: 0.1677  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:35:56 d2.utils.events]: \u001b[0m eta: 3:38:11  iter: 36659  total_loss: 1.161  loss_cls: 0.2743  loss_box_reg: 0.3781  loss_mask: 0.2517  loss_rpn_cls: 0.06972  loss_rpn_loc: 0.1547  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:36:00 d2.utils.events]: \u001b[0m eta: 3:37:55  iter: 36679  total_loss: 1.069  loss_cls: 0.2415  loss_box_reg: 0.3765  loss_mask: 0.2516  loss_rpn_cls: 0.06317  loss_rpn_loc: 0.1483  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:36:05 d2.utils.events]: \u001b[0m eta: 3:37:52  iter: 36699  total_loss: 1.246  loss_cls: 0.3253  loss_box_reg: 0.4117  loss_mask: 0.2771  loss_rpn_cls: 0.0688  loss_rpn_loc: 0.1737  time: 0.2238  data_time: 0.0265  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:36:10 d2.utils.events]: \u001b[0m eta: 3:37:39  iter: 36719  total_loss: 1.273  loss_cls: 0.3174  loss_box_reg: 0.4262  loss_mask: 0.2706  loss_rpn_cls: 0.08975  loss_rpn_loc: 0.197  time: 0.2238  data_time: 0.0135  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:36:14 d2.utils.events]: \u001b[0m eta: 3:37:36  iter: 36739  total_loss: 1.225  loss_cls: 0.3137  loss_box_reg: 0.3935  loss_mask: 0.28  loss_rpn_cls: 0.08767  loss_rpn_loc: 0.1747  time: 0.2238  data_time: 0.0162  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:36:19 d2.utils.events]: \u001b[0m eta: 3:37:30  iter: 36759  total_loss: 1.195  loss_cls: 0.303  loss_box_reg: 0.3818  loss_mask: 0.274  loss_rpn_cls: 0.08111  loss_rpn_loc: 0.1723  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:36:23 d2.utils.events]: \u001b[0m eta: 3:37:24  iter: 36779  total_loss: 1.221  loss_cls: 0.3266  loss_box_reg: 0.4188  loss_mask: 0.2766  loss_rpn_cls: 0.08511  loss_rpn_loc: 0.1781  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:36:28 d2.utils.events]: \u001b[0m eta: 3:37:21  iter: 36799  total_loss: 1.231  loss_cls: 0.3062  loss_box_reg: 0.3956  loss_mask: 0.2652  loss_rpn_cls: 0.08486  loss_rpn_loc: 0.1758  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:36:32 d2.utils.events]: \u001b[0m eta: 3:37:15  iter: 36819  total_loss: 1.26  loss_cls: 0.3199  loss_box_reg: 0.4225  loss_mask: 0.2615  loss_rpn_cls: 0.06538  loss_rpn_loc: 0.1646  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:36:37 d2.utils.events]: \u001b[0m eta: 3:37:09  iter: 36839  total_loss: 1.261  loss_cls: 0.2923  loss_box_reg: 0.3991  loss_mask: 0.2604  loss_rpn_cls: 0.05731  loss_rpn_loc: 0.1636  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:36:41 d2.utils.events]: \u001b[0m eta: 3:37:07  iter: 36859  total_loss: 1.155  loss_cls: 0.2773  loss_box_reg: 0.3815  loss_mask: 0.2696  loss_rpn_cls: 0.0753  loss_rpn_loc: 0.1609  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:36:46 d2.utils.events]: \u001b[0m eta: 3:37:00  iter: 36879  total_loss: 1.217  loss_cls: 0.298  loss_box_reg: 0.4017  loss_mask: 0.2673  loss_rpn_cls: 0.06656  loss_rpn_loc: 0.1657  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:36:50 d2.utils.events]: \u001b[0m eta: 3:36:51  iter: 36899  total_loss: 1.07  loss_cls: 0.2654  loss_box_reg: 0.3738  loss_mask: 0.2537  loss_rpn_cls: 0.05625  loss_rpn_loc: 0.1632  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:36:55 d2.utils.events]: \u001b[0m eta: 3:36:28  iter: 36919  total_loss: 1.2  loss_cls: 0.2963  loss_box_reg: 0.407  loss_mask: 0.2626  loss_rpn_cls: 0.07358  loss_rpn_loc: 0.1559  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:36:59 d2.utils.events]: \u001b[0m eta: 3:36:12  iter: 36939  total_loss: 1.155  loss_cls: 0.2923  loss_box_reg: 0.3678  loss_mask: 0.2443  loss_rpn_cls: 0.05633  loss_rpn_loc: 0.1541  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:37:03 d2.utils.events]: \u001b[0m eta: 3:36:07  iter: 36959  total_loss: 1.216  loss_cls: 0.3021  loss_box_reg: 0.3972  loss_mask: 0.2624  loss_rpn_cls: 0.09076  loss_rpn_loc: 0.1812  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:37:08 d2.utils.events]: \u001b[0m eta: 3:36:10  iter: 36979  total_loss: 1.207  loss_cls: 0.2898  loss_box_reg: 0.4147  loss_mask: 0.2723  loss_rpn_cls: 0.0947  loss_rpn_loc: 0.1767  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:37:12 d2.utils.events]: \u001b[0m eta: 3:36:20  iter: 36999  total_loss: 1.24  loss_cls: 0.309  loss_box_reg: 0.3732  loss_mask: 0.2714  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.1729  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:37:17 d2.utils.events]: \u001b[0m eta: 3:36:16  iter: 37019  total_loss: 1.275  loss_cls: 0.3262  loss_box_reg: 0.4002  loss_mask: 0.2758  loss_rpn_cls: 0.07701  loss_rpn_loc: 0.1781  time: 0.2238  data_time: 0.0239  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:37:22 d2.utils.events]: \u001b[0m eta: 3:36:11  iter: 37039  total_loss: 1.149  loss_cls: 0.2647  loss_box_reg: 0.3881  loss_mask: 0.2714  loss_rpn_cls: 0.0751  loss_rpn_loc: 0.1579  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:37:26 d2.utils.events]: \u001b[0m eta: 3:35:58  iter: 37059  total_loss: 1.175  loss_cls: 0.2746  loss_box_reg: 0.3897  loss_mask: 0.2663  loss_rpn_cls: 0.07317  loss_rpn_loc: 0.1591  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:37:31 d2.utils.events]: \u001b[0m eta: 3:35:58  iter: 37079  total_loss: 1.249  loss_cls: 0.2886  loss_box_reg: 0.3978  loss_mask: 0.2725  loss_rpn_cls: 0.07558  loss_rpn_loc: 0.1537  time: 0.2238  data_time: 0.0157  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:37:35 d2.utils.events]: \u001b[0m eta: 3:35:47  iter: 37099  total_loss: 1.105  loss_cls: 0.2695  loss_box_reg: 0.3586  loss_mask: 0.2427  loss_rpn_cls: 0.06732  loss_rpn_loc: 0.1524  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:37:39 d2.utils.events]: \u001b[0m eta: 3:35:37  iter: 37119  total_loss: 1.192  loss_cls: 0.2747  loss_box_reg: 0.3474  loss_mask: 0.253  loss_rpn_cls: 0.06468  loss_rpn_loc: 0.1801  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:37:44 d2.utils.events]: \u001b[0m eta: 3:35:35  iter: 37139  total_loss: 1.232  loss_cls: 0.283  loss_box_reg: 0.3611  loss_mask: 0.2762  loss_rpn_cls: 0.09769  loss_rpn_loc: 0.1981  time: 0.2238  data_time: 0.0096  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:37:49 d2.utils.events]: \u001b[0m eta: 3:35:34  iter: 37159  total_loss: 1.179  loss_cls: 0.2811  loss_box_reg: 0.3858  loss_mask: 0.27  loss_rpn_cls: 0.06978  loss_rpn_loc: 0.1674  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:37:53 d2.utils.events]: \u001b[0m eta: 3:35:36  iter: 37179  total_loss: 1.137  loss_cls: 0.2826  loss_box_reg: 0.3575  loss_mask: 0.2653  loss_rpn_cls: 0.09705  loss_rpn_loc: 0.1823  time: 0.2238  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:37:58 d2.utils.events]: \u001b[0m eta: 3:35:32  iter: 37199  total_loss: 1.167  loss_cls: 0.268  loss_box_reg: 0.3738  loss_mask: 0.2541  loss_rpn_cls: 0.06052  loss_rpn_loc: 0.1648  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:38:02 d2.utils.events]: \u001b[0m eta: 3:35:21  iter: 37219  total_loss: 1.262  loss_cls: 0.3051  loss_box_reg: 0.4353  loss_mask: 0.2829  loss_rpn_cls: 0.06787  loss_rpn_loc: 0.1665  time: 0.2238  data_time: 0.0058  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:38:06 d2.utils.events]: \u001b[0m eta: 3:35:07  iter: 37239  total_loss: 1.214  loss_cls: 0.3032  loss_box_reg: 0.3865  loss_mask: 0.2652  loss_rpn_cls: 0.0902  loss_rpn_loc: 0.1717  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:38:11 d2.utils.events]: \u001b[0m eta: 3:35:05  iter: 37259  total_loss: 1.239  loss_cls: 0.3142  loss_box_reg: 0.3984  loss_mask: 0.2706  loss_rpn_cls: 0.08134  loss_rpn_loc: 0.1556  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:38:15 d2.utils.events]: \u001b[0m eta: 3:34:56  iter: 37279  total_loss: 1.206  loss_cls: 0.2717  loss_box_reg: 0.396  loss_mask: 0.2569  loss_rpn_cls: 0.06383  loss_rpn_loc: 0.1654  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:38:20 d2.utils.events]: \u001b[0m eta: 3:34:58  iter: 37299  total_loss: 1.286  loss_cls: 0.3223  loss_box_reg: 0.3779  loss_mask: 0.2499  loss_rpn_cls: 0.07008  loss_rpn_loc: 0.1558  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:38:24 d2.utils.events]: \u001b[0m eta: 3:34:46  iter: 37319  total_loss: 1.074  loss_cls: 0.2586  loss_box_reg: 0.3536  loss_mask: 0.2402  loss_rpn_cls: 0.04218  loss_rpn_loc: 0.1482  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:38:29 d2.utils.events]: \u001b[0m eta: 3:34:42  iter: 37339  total_loss: 1.295  loss_cls: 0.3336  loss_box_reg: 0.4173  loss_mask: 0.261  loss_rpn_cls: 0.07468  loss_rpn_loc: 0.166  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:38:33 d2.utils.events]: \u001b[0m eta: 3:34:37  iter: 37359  total_loss: 1.273  loss_cls: 0.326  loss_box_reg: 0.4048  loss_mask: 0.2746  loss_rpn_cls: 0.07974  loss_rpn_loc: 0.1666  time: 0.2238  data_time: 0.0138  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:38:38 d2.utils.events]: \u001b[0m eta: 3:34:25  iter: 37379  total_loss: 1.244  loss_cls: 0.3366  loss_box_reg: 0.3972  loss_mask: 0.2604  loss_rpn_cls: 0.07439  loss_rpn_loc: 0.1679  time: 0.2238  data_time: 0.0287  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:38:42 d2.utils.events]: \u001b[0m eta: 3:34:23  iter: 37399  total_loss: 1.211  loss_cls: 0.2866  loss_box_reg: 0.3781  loss_mask: 0.271  loss_rpn_cls: 0.06005  loss_rpn_loc: 0.1718  time: 0.2238  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:38:47 d2.utils.events]: \u001b[0m eta: 3:34:15  iter: 37419  total_loss: 1.178  loss_cls: 0.2989  loss_box_reg: 0.4153  loss_mask: 0.2641  loss_rpn_cls: 0.0812  loss_rpn_loc: 0.1625  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:38:51 d2.utils.events]: \u001b[0m eta: 3:34:09  iter: 37439  total_loss: 1.134  loss_cls: 0.3206  loss_box_reg: 0.3813  loss_mask: 0.2542  loss_rpn_cls: 0.06805  loss_rpn_loc: 0.1541  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:38:55 d2.utils.events]: \u001b[0m eta: 3:34:03  iter: 37459  total_loss: 1.323  loss_cls: 0.3435  loss_box_reg: 0.4068  loss_mask: 0.2797  loss_rpn_cls: 0.06929  loss_rpn_loc: 0.1652  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:39:00 d2.utils.events]: \u001b[0m eta: 3:34:02  iter: 37479  total_loss: 1.186  loss_cls: 0.2791  loss_box_reg: 0.3868  loss_mask: 0.2744  loss_rpn_cls: 0.07023  loss_rpn_loc: 0.168  time: 0.2238  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:39:04 d2.utils.events]: \u001b[0m eta: 3:33:56  iter: 37499  total_loss: 1.217  loss_cls: 0.3168  loss_box_reg: 0.3719  loss_mask: 0.2576  loss_rpn_cls: 0.07911  loss_rpn_loc: 0.1627  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:39:09 d2.utils.events]: \u001b[0m eta: 3:33:53  iter: 37519  total_loss: 1.108  loss_cls: 0.2834  loss_box_reg: 0.3429  loss_mask: 0.2413  loss_rpn_cls: 0.06797  loss_rpn_loc: 0.1592  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:39:13 d2.utils.events]: \u001b[0m eta: 3:33:55  iter: 37539  total_loss: 1.237  loss_cls: 0.2877  loss_box_reg: 0.4018  loss_mask: 0.2676  loss_rpn_cls: 0.08514  loss_rpn_loc: 0.1822  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:39:18 d2.utils.events]: \u001b[0m eta: 3:33:54  iter: 37559  total_loss: 1.277  loss_cls: 0.2829  loss_box_reg: 0.3988  loss_mask: 0.2735  loss_rpn_cls: 0.08819  loss_rpn_loc: 0.1937  time: 0.2238  data_time: 0.0117  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:39:22 d2.utils.events]: \u001b[0m eta: 3:33:47  iter: 37579  total_loss: 1.223  loss_cls: 0.2943  loss_box_reg: 0.3816  loss_mask: 0.2678  loss_rpn_cls: 0.07415  loss_rpn_loc: 0.1613  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:39:27 d2.utils.events]: \u001b[0m eta: 3:33:54  iter: 37599  total_loss: 1.15  loss_cls: 0.2922  loss_box_reg: 0.3553  loss_mask: 0.2594  loss_rpn_cls: 0.107  loss_rpn_loc: 0.174  time: 0.2238  data_time: 0.0104  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:39:32 d2.utils.events]: \u001b[0m eta: 3:33:49  iter: 37619  total_loss: 1.211  loss_cls: 0.3036  loss_box_reg: 0.3713  loss_mask: 0.2599  loss_rpn_cls: 0.06645  loss_rpn_loc: 0.1648  time: 0.2238  data_time: 0.0174  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:39:36 d2.utils.events]: \u001b[0m eta: 3:33:55  iter: 37639  total_loss: 1.299  loss_cls: 0.3284  loss_box_reg: 0.4117  loss_mask: 0.2719  loss_rpn_cls: 0.07569  loss_rpn_loc: 0.1701  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:39:41 d2.utils.events]: \u001b[0m eta: 3:33:59  iter: 37659  total_loss: 1.161  loss_cls: 0.2772  loss_box_reg: 0.3638  loss_mask: 0.2673  loss_rpn_cls: 0.07356  loss_rpn_loc: 0.1583  time: 0.2238  data_time: 0.0187  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:39:46 d2.utils.events]: \u001b[0m eta: 3:34:00  iter: 37679  total_loss: 1.219  loss_cls: 0.3176  loss_box_reg: 0.4196  loss_mask: 0.2615  loss_rpn_cls: 0.07124  loss_rpn_loc: 0.1678  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:39:50 d2.utils.events]: \u001b[0m eta: 3:33:44  iter: 37699  total_loss: 1.062  loss_cls: 0.2935  loss_box_reg: 0.3482  loss_mask: 0.2475  loss_rpn_cls: 0.05829  loss_rpn_loc: 0.1503  time: 0.2238  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:39:54 d2.utils.events]: \u001b[0m eta: 3:33:46  iter: 37719  total_loss: 1.189  loss_cls: 0.2918  loss_box_reg: 0.3611  loss_mask: 0.2615  loss_rpn_cls: 0.07598  loss_rpn_loc: 0.1555  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:39:59 d2.utils.events]: \u001b[0m eta: 3:33:56  iter: 37739  total_loss: 1.153  loss_cls: 0.2633  loss_box_reg: 0.3542  loss_mask: 0.2564  loss_rpn_cls: 0.06104  loss_rpn_loc: 0.1617  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:40:03 d2.utils.events]: \u001b[0m eta: 3:33:33  iter: 37759  total_loss: 1.143  loss_cls: 0.2576  loss_box_reg: 0.3697  loss_mask: 0.2458  loss_rpn_cls: 0.06609  loss_rpn_loc: 0.1485  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:40:07 d2.utils.events]: \u001b[0m eta: 3:33:04  iter: 37779  total_loss: 1.093  loss_cls: 0.3129  loss_box_reg: 0.3796  loss_mask: 0.252  loss_rpn_cls: 0.0488  loss_rpn_loc: 0.1542  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:40:12 d2.utils.events]: \u001b[0m eta: 3:32:54  iter: 37799  total_loss: 1.166  loss_cls: 0.2608  loss_box_reg: 0.368  loss_mask: 0.2635  loss_rpn_cls: 0.06509  loss_rpn_loc: 0.1636  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:40:16 d2.utils.events]: \u001b[0m eta: 3:32:49  iter: 37819  total_loss: 1.255  loss_cls: 0.3226  loss_box_reg: 0.3826  loss_mask: 0.2601  loss_rpn_cls: 0.07579  loss_rpn_loc: 0.168  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:40:21 d2.utils.events]: \u001b[0m eta: 3:33:13  iter: 37839  total_loss: 1.169  loss_cls: 0.2726  loss_box_reg: 0.3655  loss_mask: 0.2546  loss_rpn_cls: 0.07525  loss_rpn_loc: 0.1655  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:40:25 d2.utils.events]: \u001b[0m eta: 3:33:04  iter: 37859  total_loss: 1.054  loss_cls: 0.2338  loss_box_reg: 0.3562  loss_mask: 0.264  loss_rpn_cls: 0.06492  loss_rpn_loc: 0.1519  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:40:30 d2.utils.events]: \u001b[0m eta: 3:33:04  iter: 37879  total_loss: 1.233  loss_cls: 0.3046  loss_box_reg: 0.3756  loss_mask: 0.2764  loss_rpn_cls: 0.09557  loss_rpn_loc: 0.1615  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:40:34 d2.utils.events]: \u001b[0m eta: 3:32:52  iter: 37899  total_loss: 1.312  loss_cls: 0.3287  loss_box_reg: 0.4165  loss_mask: 0.2788  loss_rpn_cls: 0.07026  loss_rpn_loc: 0.1618  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:40:39 d2.utils.events]: \u001b[0m eta: 3:32:48  iter: 37919  total_loss: 1.299  loss_cls: 0.3307  loss_box_reg: 0.372  loss_mask: 0.2641  loss_rpn_cls: 0.06567  loss_rpn_loc: 0.1724  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:40:43 d2.utils.events]: \u001b[0m eta: 3:32:51  iter: 37939  total_loss: 1.25  loss_cls: 0.3101  loss_box_reg: 0.3978  loss_mask: 0.257  loss_rpn_cls: 0.07265  loss_rpn_loc: 0.1697  time: 0.2238  data_time: 0.0178  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:40:48 d2.utils.events]: \u001b[0m eta: 3:32:50  iter: 37959  total_loss: 1.168  loss_cls: 0.3089  loss_box_reg: 0.3586  loss_mask: 0.2805  loss_rpn_cls: 0.06904  loss_rpn_loc: 0.1706  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:40:52 d2.utils.events]: \u001b[0m eta: 3:32:35  iter: 37979  total_loss: 1.023  loss_cls: 0.2686  loss_box_reg: 0.3394  loss_mask: 0.242  loss_rpn_cls: 0.04952  loss_rpn_loc: 0.142  time: 0.2238  data_time: 0.0163  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:40:57 d2.utils.events]: \u001b[0m eta: 3:32:09  iter: 37999  total_loss: 1.174  loss_cls: 0.2675  loss_box_reg: 0.401  loss_mask: 0.2477  loss_rpn_cls: 0.05003  loss_rpn_loc: 0.1801  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:41:01 d2.utils.events]: \u001b[0m eta: 3:31:46  iter: 38019  total_loss: 1.25  loss_cls: 0.3082  loss_box_reg: 0.3996  loss_mask: 0.269  loss_rpn_cls: 0.09323  loss_rpn_loc: 0.1657  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:41:05 d2.utils.events]: \u001b[0m eta: 3:31:44  iter: 38039  total_loss: 1.19  loss_cls: 0.2826  loss_box_reg: 0.3563  loss_mask: 0.2818  loss_rpn_cls: 0.09562  loss_rpn_loc: 0.1766  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:41:10 d2.utils.events]: \u001b[0m eta: 3:31:37  iter: 38059  total_loss: 1.32  loss_cls: 0.3532  loss_box_reg: 0.4227  loss_mask: 0.2729  loss_rpn_cls: 0.09393  loss_rpn_loc: 0.1644  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:41:14 d2.utils.events]: \u001b[0m eta: 3:31:32  iter: 38079  total_loss: 1.166  loss_cls: 0.2918  loss_box_reg: 0.3564  loss_mask: 0.2581  loss_rpn_cls: 0.07088  loss_rpn_loc: 0.1545  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:41:19 d2.utils.events]: \u001b[0m eta: 3:31:42  iter: 38099  total_loss: 1.199  loss_cls: 0.2778  loss_box_reg: 0.3566  loss_mask: 0.2697  loss_rpn_cls: 0.09867  loss_rpn_loc: 0.1692  time: 0.2238  data_time: 0.0100  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:41:23 d2.utils.events]: \u001b[0m eta: 3:31:41  iter: 38119  total_loss: 1.131  loss_cls: 0.2663  loss_box_reg: 0.3262  loss_mask: 0.2617  loss_rpn_cls: 0.07058  loss_rpn_loc: 0.1638  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:41:28 d2.utils.events]: \u001b[0m eta: 3:31:25  iter: 38139  total_loss: 1.246  loss_cls: 0.3109  loss_box_reg: 0.3669  loss_mask: 0.2691  loss_rpn_cls: 0.08088  loss_rpn_loc: 0.1807  time: 0.2238  data_time: 0.0092  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:41:33 d2.utils.events]: \u001b[0m eta: 3:31:18  iter: 38159  total_loss: 1.289  loss_cls: 0.3023  loss_box_reg: 0.3993  loss_mask: 0.2856  loss_rpn_cls: 0.1007  loss_rpn_loc: 0.1992  time: 0.2238  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:41:37 d2.utils.events]: \u001b[0m eta: 3:30:57  iter: 38179  total_loss: 1.169  loss_cls: 0.3007  loss_box_reg: 0.3649  loss_mask: 0.2677  loss_rpn_cls: 0.0948  loss_rpn_loc: 0.1647  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:41:41 d2.utils.events]: \u001b[0m eta: 3:30:46  iter: 38199  total_loss: 1.318  loss_cls: 0.31  loss_box_reg: 0.4423  loss_mask: 0.2883  loss_rpn_cls: 0.07801  loss_rpn_loc: 0.1788  time: 0.2238  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:41:46 d2.utils.events]: \u001b[0m eta: 3:31:02  iter: 38219  total_loss: 1.161  loss_cls: 0.2922  loss_box_reg: 0.3379  loss_mask: 0.2397  loss_rpn_cls: 0.07094  loss_rpn_loc: 0.1681  time: 0.2238  data_time: 0.0135  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:41:50 d2.utils.events]: \u001b[0m eta: 3:31:07  iter: 38239  total_loss: 1.118  loss_cls: 0.2116  loss_box_reg: 0.3499  loss_mask: 0.2513  loss_rpn_cls: 0.06934  loss_rpn_loc: 0.165  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:41:55 d2.utils.events]: \u001b[0m eta: 3:31:03  iter: 38259  total_loss: 1.15  loss_cls: 0.2871  loss_box_reg: 0.3665  loss_mask: 0.2429  loss_rpn_cls: 0.07355  loss_rpn_loc: 0.1681  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:41:59 d2.utils.events]: \u001b[0m eta: 3:30:59  iter: 38279  total_loss: 1.24  loss_cls: 0.2838  loss_box_reg: 0.3787  loss_mask: 0.2624  loss_rpn_cls: 0.09534  loss_rpn_loc: 0.1939  time: 0.2238  data_time: 0.0170  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:42:04 d2.utils.events]: \u001b[0m eta: 3:30:43  iter: 38299  total_loss: 1.244  loss_cls: 0.31  loss_box_reg: 0.4108  loss_mask: 0.2664  loss_rpn_cls: 0.09036  loss_rpn_loc: 0.1798  time: 0.2238  data_time: 0.0091  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:42:08 d2.utils.events]: \u001b[0m eta: 3:30:43  iter: 38319  total_loss: 1.258  loss_cls: 0.3096  loss_box_reg: 0.3697  loss_mask: 0.2587  loss_rpn_cls: 0.09616  loss_rpn_loc: 0.1902  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:42:13 d2.utils.events]: \u001b[0m eta: 3:30:39  iter: 38339  total_loss: 1.172  loss_cls: 0.268  loss_box_reg: 0.3794  loss_mask: 0.2622  loss_rpn_cls: 0.06688  loss_rpn_loc: 0.164  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:42:17 d2.utils.events]: \u001b[0m eta: 3:30:15  iter: 38359  total_loss: 1.324  loss_cls: 0.2959  loss_box_reg: 0.4287  loss_mask: 0.2682  loss_rpn_cls: 0.1053  loss_rpn_loc: 0.1841  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:42:22 d2.utils.events]: \u001b[0m eta: 3:30:13  iter: 38379  total_loss: 1.166  loss_cls: 0.2835  loss_box_reg: 0.3836  loss_mask: 0.2749  loss_rpn_cls: 0.07848  loss_rpn_loc: 0.1484  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:42:26 d2.utils.events]: \u001b[0m eta: 3:30:05  iter: 38399  total_loss: 0.9867  loss_cls: 0.2458  loss_box_reg: 0.3624  loss_mask: 0.2514  loss_rpn_cls: 0.06301  loss_rpn_loc: 0.1462  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:42:31 d2.utils.events]: \u001b[0m eta: 3:30:05  iter: 38419  total_loss: 1.01  loss_cls: 0.2012  loss_box_reg: 0.3143  loss_mask: 0.2523  loss_rpn_cls: 0.0771  loss_rpn_loc: 0.1522  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:42:35 d2.utils.events]: \u001b[0m eta: 3:30:04  iter: 38439  total_loss: 1.183  loss_cls: 0.2856  loss_box_reg: 0.3753  loss_mask: 0.274  loss_rpn_cls: 0.05714  loss_rpn_loc: 0.1633  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:42:40 d2.utils.events]: \u001b[0m eta: 3:29:54  iter: 38459  total_loss: 1.112  loss_cls: 0.2799  loss_box_reg: 0.3524  loss_mask: 0.2406  loss_rpn_cls: 0.06338  loss_rpn_loc: 0.1509  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:42:44 d2.utils.events]: \u001b[0m eta: 3:29:49  iter: 38479  total_loss: 1.162  loss_cls: 0.2562  loss_box_reg: 0.3777  loss_mask: 0.2569  loss_rpn_cls: 0.05966  loss_rpn_loc: 0.1758  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:42:49 d2.utils.events]: \u001b[0m eta: 3:29:47  iter: 38499  total_loss: 1.181  loss_cls: 0.2963  loss_box_reg: 0.3627  loss_mask: 0.2676  loss_rpn_cls: 0.09288  loss_rpn_loc: 0.1724  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:42:53 d2.utils.events]: \u001b[0m eta: 3:29:51  iter: 38519  total_loss: 1.214  loss_cls: 0.297  loss_box_reg: 0.373  loss_mask: 0.2686  loss_rpn_cls: 0.08596  loss_rpn_loc: 0.1683  time: 0.2238  data_time: 0.0207  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:43:00 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.41 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/29 23:43:00 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/29 23:43:00 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/29 23:43:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/29 23:43:01 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/29 23:43:01 d2.data.common]: \u001b[0mSerialized dataset takes 84.20 MiB\n",
      "\u001b[32m[12/29 23:43:04 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.40 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/29 23:43:04 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/29 23:43:04 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/29 23:43:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/29 23:43:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0007 s/iter. Inference: 0.0620 s/iter. Eval: 0.1459 s/iter. Total: 0.2086 s/iter. ETA=0:01:56\n",
      "\u001b[32m[12/29 23:43:13 d2.evaluation.evaluator]: \u001b[0mInference done 39/570. Dataloading: 0.0008 s/iter. Inference: 0.0577 s/iter. Eval: 0.1279 s/iter. Total: 0.1866 s/iter. ETA=0:01:39\n",
      "\u001b[32m[12/29 23:43:18 d2.evaluation.evaluator]: \u001b[0mInference done 66/570. Dataloading: 0.0009 s/iter. Inference: 0.0561 s/iter. Eval: 0.1306 s/iter. Total: 0.1876 s/iter. ETA=0:01:34\n",
      "\u001b[32m[12/29 23:43:23 d2.evaluation.evaluator]: \u001b[0mInference done 91/570. Dataloading: 0.0009 s/iter. Inference: 0.0562 s/iter. Eval: 0.1347 s/iter. Total: 0.1918 s/iter. ETA=0:01:31\n",
      "\u001b[32m[12/29 23:43:28 d2.evaluation.evaluator]: \u001b[0mInference done 118/570. Dataloading: 0.0009 s/iter. Inference: 0.0549 s/iter. Eval: 0.1345 s/iter. Total: 0.1903 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/29 23:43:33 d2.evaluation.evaluator]: \u001b[0mInference done 142/570. Dataloading: 0.0009 s/iter. Inference: 0.0549 s/iter. Eval: 0.1379 s/iter. Total: 0.1937 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/29 23:43:38 d2.evaluation.evaluator]: \u001b[0mInference done 162/570. Dataloading: 0.0009 s/iter. Inference: 0.0549 s/iter. Eval: 0.1466 s/iter. Total: 0.2024 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/29 23:43:43 d2.evaluation.evaluator]: \u001b[0mInference done 175/570. Dataloading: 0.0009 s/iter. Inference: 0.0553 s/iter. Eval: 0.1615 s/iter. Total: 0.2178 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/29 23:43:48 d2.evaluation.evaluator]: \u001b[0mInference done 193/570. Dataloading: 0.0009 s/iter. Inference: 0.0555 s/iter. Eval: 0.1675 s/iter. Total: 0.2239 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/29 23:43:54 d2.evaluation.evaluator]: \u001b[0mInference done 209/570. Dataloading: 0.0009 s/iter. Inference: 0.0558 s/iter. Eval: 0.1746 s/iter. Total: 0.2313 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/29 23:43:59 d2.evaluation.evaluator]: \u001b[0mInference done 226/570. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.1818 s/iter. Total: 0.2387 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/29 23:44:04 d2.evaluation.evaluator]: \u001b[0mInference done 237/570. Dataloading: 0.0009 s/iter. Inference: 0.0561 s/iter. Eval: 0.1926 s/iter. Total: 0.2496 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/29 23:44:09 d2.evaluation.evaluator]: \u001b[0mInference done 249/570. Dataloading: 0.0009 s/iter. Inference: 0.0563 s/iter. Eval: 0.2008 s/iter. Total: 0.2581 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/29 23:44:14 d2.evaluation.evaluator]: \u001b[0mInference done 265/570. Dataloading: 0.0009 s/iter. Inference: 0.0565 s/iter. Eval: 0.2045 s/iter. Total: 0.2619 s/iter. ETA=0:01:19\n",
      "\u001b[32m[12/29 23:44:20 d2.evaluation.evaluator]: \u001b[0mInference done 283/570. Dataloading: 0.0009 s/iter. Inference: 0.0563 s/iter. Eval: 0.2061 s/iter. Total: 0.2633 s/iter. ETA=0:01:15\n",
      "\u001b[32m[12/29 23:44:25 d2.evaluation.evaluator]: \u001b[0mInference done 298/570. Dataloading: 0.0009 s/iter. Inference: 0.0564 s/iter. Eval: 0.2114 s/iter. Total: 0.2688 s/iter. ETA=0:01:13\n",
      "\u001b[32m[12/29 23:44:30 d2.evaluation.evaluator]: \u001b[0mInference done 346/570. Dataloading: 0.0009 s/iter. Inference: 0.0553 s/iter. Eval: 0.1895 s/iter. Total: 0.2457 s/iter. ETA=0:00:55\n",
      "\u001b[32m[12/29 23:44:35 d2.evaluation.evaluator]: \u001b[0mInference done 376/570. Dataloading: 0.0009 s/iter. Inference: 0.0549 s/iter. Eval: 0.1839 s/iter. Total: 0.2398 s/iter. ETA=0:00:46\n",
      "\u001b[32m[12/29 23:44:40 d2.evaluation.evaluator]: \u001b[0mInference done 398/570. Dataloading: 0.0009 s/iter. Inference: 0.0552 s/iter. Eval: 0.1832 s/iter. Total: 0.2394 s/iter. ETA=0:00:41\n",
      "\u001b[32m[12/29 23:44:45 d2.evaluation.evaluator]: \u001b[0mInference done 416/570. Dataloading: 0.0009 s/iter. Inference: 0.0553 s/iter. Eval: 0.1851 s/iter. Total: 0.2413 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/29 23:44:51 d2.evaluation.evaluator]: \u001b[0mInference done 436/570. Dataloading: 0.0009 s/iter. Inference: 0.0554 s/iter. Eval: 0.1857 s/iter. Total: 0.2421 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/29 23:44:56 d2.evaluation.evaluator]: \u001b[0mInference done 466/570. Dataloading: 0.0009 s/iter. Inference: 0.0553 s/iter. Eval: 0.1810 s/iter. Total: 0.2372 s/iter. ETA=0:00:24\n",
      "\u001b[32m[12/29 23:45:01 d2.evaluation.evaluator]: \u001b[0mInference done 496/570. Dataloading: 0.0009 s/iter. Inference: 0.0550 s/iter. Eval: 0.1778 s/iter. Total: 0.2337 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/29 23:45:06 d2.evaluation.evaluator]: \u001b[0mInference done 518/570. Dataloading: 0.0009 s/iter. Inference: 0.0548 s/iter. Eval: 0.1781 s/iter. Total: 0.2338 s/iter. ETA=0:00:12\n",
      "\u001b[32m[12/29 23:45:11 d2.evaluation.evaluator]: \u001b[0mInference done 541/570. Dataloading: 0.0009 s/iter. Inference: 0.0547 s/iter. Eval: 0.1777 s/iter. Total: 0.2334 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/29 23:45:17 d2.evaluation.evaluator]: \u001b[0mInference done 559/570. Dataloading: 0.0009 s/iter. Inference: 0.0549 s/iter. Eval: 0.1795 s/iter. Total: 0.2353 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/29 23:45:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:13.127685 (0.235624 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 23:45:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.054989 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/29 23:45:19 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/29 23:45:19 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2830388484653412\n",
      "\u001b[32m[12/29 23:45:21 d2.utils.events]: \u001b[0m eta: 3:29:49  iter: 38539  total_loss: 1.232  loss_cls: 0.2615  loss_box_reg: 0.3985  loss_mask: 0.2868  loss_rpn_cls: 0.08764  loss_rpn_loc: 0.1788  time: 0.2238  data_time: 0.0164  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:45:25 d2.utils.events]: \u001b[0m eta: 3:29:42  iter: 38559  total_loss: 1.194  loss_cls: 0.3234  loss_box_reg: 0.3818  loss_mask: 0.2642  loss_rpn_cls: 0.07503  loss_rpn_loc: 0.1568  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:45:30 d2.utils.events]: \u001b[0m eta: 3:29:50  iter: 38579  total_loss: 1.161  loss_cls: 0.2742  loss_box_reg: 0.3786  loss_mask: 0.2563  loss_rpn_cls: 0.06926  loss_rpn_loc: 0.1549  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:45:34 d2.utils.events]: \u001b[0m eta: 3:29:29  iter: 38599  total_loss: 1.237  loss_cls: 0.2935  loss_box_reg: 0.4108  loss_mask: 0.2718  loss_rpn_cls: 0.07394  loss_rpn_loc: 0.1621  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:45:38 d2.utils.events]: \u001b[0m eta: 3:29:09  iter: 38619  total_loss: 1.282  loss_cls: 0.3268  loss_box_reg: 0.4233  loss_mask: 0.2588  loss_rpn_cls: 0.07688  loss_rpn_loc: 0.1654  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:45:42 d2.utils.events]: \u001b[0m eta: 3:28:56  iter: 38639  total_loss: 1.172  loss_cls: 0.2974  loss_box_reg: 0.3881  loss_mask: 0.2502  loss_rpn_cls: 0.05908  loss_rpn_loc: 0.1559  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:45:47 d2.utils.events]: \u001b[0m eta: 3:28:31  iter: 38659  total_loss: 1.243  loss_cls: 0.3293  loss_box_reg: 0.34  loss_mask: 0.263  loss_rpn_cls: 0.0919  loss_rpn_loc: 0.1804  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:45:52 d2.utils.events]: \u001b[0m eta: 3:28:37  iter: 38679  total_loss: 1.319  loss_cls: 0.3611  loss_box_reg: 0.3908  loss_mask: 0.2691  loss_rpn_cls: 0.08948  loss_rpn_loc: 0.1799  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:45:56 d2.utils.events]: \u001b[0m eta: 3:28:30  iter: 38699  total_loss: 1.226  loss_cls: 0.3239  loss_box_reg: 0.4011  loss_mask: 0.2523  loss_rpn_cls: 0.05451  loss_rpn_loc: 0.1739  time: 0.2238  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:46:00 d2.utils.events]: \u001b[0m eta: 3:28:24  iter: 38719  total_loss: 1.149  loss_cls: 0.2968  loss_box_reg: 0.3317  loss_mask: 0.2478  loss_rpn_cls: 0.0879  loss_rpn_loc: 0.1749  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:46:05 d2.utils.events]: \u001b[0m eta: 3:28:21  iter: 38739  total_loss: 1.188  loss_cls: 0.2891  loss_box_reg: 0.3593  loss_mask: 0.264  loss_rpn_cls: 0.09027  loss_rpn_loc: 0.1674  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:46:10 d2.utils.events]: \u001b[0m eta: 3:28:45  iter: 38759  total_loss: 1.183  loss_cls: 0.2848  loss_box_reg: 0.3821  loss_mask: 0.253  loss_rpn_cls: 0.05944  loss_rpn_loc: 0.1609  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:46:14 d2.utils.events]: \u001b[0m eta: 3:28:46  iter: 38779  total_loss: 1.294  loss_cls: 0.3485  loss_box_reg: 0.4204  loss_mask: 0.2744  loss_rpn_cls: 0.08889  loss_rpn_loc: 0.162  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:46:19 d2.utils.events]: \u001b[0m eta: 3:28:49  iter: 38799  total_loss: 1.163  loss_cls: 0.3011  loss_box_reg: 0.3876  loss_mask: 0.2671  loss_rpn_cls: 0.06884  loss_rpn_loc: 0.1622  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:46:23 d2.utils.events]: \u001b[0m eta: 3:28:35  iter: 38819  total_loss: 1.146  loss_cls: 0.2831  loss_box_reg: 0.3725  loss_mask: 0.2401  loss_rpn_cls: 0.06597  loss_rpn_loc: 0.1636  time: 0.2238  data_time: 0.0186  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:46:28 d2.utils.events]: \u001b[0m eta: 3:28:25  iter: 38839  total_loss: 1.215  loss_cls: 0.3069  loss_box_reg: 0.3774  loss_mask: 0.2705  loss_rpn_cls: 0.07752  loss_rpn_loc: 0.1594  time: 0.2238  data_time: 0.0152  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:46:32 d2.utils.events]: \u001b[0m eta: 3:28:20  iter: 38859  total_loss: 1.188  loss_cls: 0.2948  loss_box_reg: 0.3796  loss_mask: 0.2585  loss_rpn_cls: 0.04339  loss_rpn_loc: 0.1644  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:46:37 d2.utils.events]: \u001b[0m eta: 3:28:17  iter: 38879  total_loss: 1.259  loss_cls: 0.2968  loss_box_reg: 0.3945  loss_mask: 0.2813  loss_rpn_cls: 0.06692  loss_rpn_loc: 0.165  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:46:42 d2.utils.events]: \u001b[0m eta: 3:28:21  iter: 38899  total_loss: 1.2  loss_cls: 0.315  loss_box_reg: 0.38  loss_mask: 0.2639  loss_rpn_cls: 0.07321  loss_rpn_loc: 0.1668  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:46:46 d2.utils.events]: \u001b[0m eta: 3:28:27  iter: 38919  total_loss: 1.323  loss_cls: 0.3188  loss_box_reg: 0.4296  loss_mask: 0.2816  loss_rpn_cls: 0.08064  loss_rpn_loc: 0.1679  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:46:50 d2.utils.events]: \u001b[0m eta: 3:28:22  iter: 38939  total_loss: 1.198  loss_cls: 0.3004  loss_box_reg: 0.402  loss_mask: 0.2717  loss_rpn_cls: 0.06837  loss_rpn_loc: 0.1635  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:46:55 d2.utils.events]: \u001b[0m eta: 3:28:46  iter: 38959  total_loss: 1.185  loss_cls: 0.2842  loss_box_reg: 0.3511  loss_mask: 0.265  loss_rpn_cls: 0.09316  loss_rpn_loc: 0.1663  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:46:59 d2.utils.events]: \u001b[0m eta: 3:28:50  iter: 38979  total_loss: 1.299  loss_cls: 0.3281  loss_box_reg: 0.4102  loss_mask: 0.2697  loss_rpn_cls: 0.07006  loss_rpn_loc: 0.1819  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:47:04 d2.utils.events]: \u001b[0m eta: 3:29:02  iter: 38999  total_loss: 1.137  loss_cls: 0.2905  loss_box_reg: 0.3594  loss_mask: 0.2567  loss_rpn_cls: 0.05787  loss_rpn_loc: 0.167  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:47:08 d2.utils.events]: \u001b[0m eta: 3:29:04  iter: 39019  total_loss: 1.13  loss_cls: 0.2669  loss_box_reg: 0.3827  loss_mask: 0.2747  loss_rpn_cls: 0.05394  loss_rpn_loc: 0.1761  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:47:13 d2.utils.events]: \u001b[0m eta: 3:29:01  iter: 39039  total_loss: 1.29  loss_cls: 0.316  loss_box_reg: 0.4293  loss_mask: 0.2997  loss_rpn_cls: 0.107  loss_rpn_loc: 0.1723  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:47:17 d2.utils.events]: \u001b[0m eta: 3:28:55  iter: 39059  total_loss: 1.284  loss_cls: 0.3208  loss_box_reg: 0.435  loss_mask: 0.2709  loss_rpn_cls: 0.0556  loss_rpn_loc: 0.1492  time: 0.2238  data_time: 0.0214  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:47:22 d2.utils.events]: \u001b[0m eta: 3:28:34  iter: 39079  total_loss: 1.225  loss_cls: 0.3001  loss_box_reg: 0.4018  loss_mask: 0.2644  loss_rpn_cls: 0.06427  loss_rpn_loc: 0.1601  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:47:26 d2.utils.events]: \u001b[0m eta: 3:28:05  iter: 39099  total_loss: 1.141  loss_cls: 0.2719  loss_box_reg: 0.3468  loss_mask: 0.2702  loss_rpn_cls: 0.0797  loss_rpn_loc: 0.1618  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:47:30 d2.utils.events]: \u001b[0m eta: 3:28:00  iter: 39119  total_loss: 1.13  loss_cls: 0.2986  loss_box_reg: 0.3842  loss_mask: 0.2413  loss_rpn_cls: 0.0562  loss_rpn_loc: 0.1734  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:47:35 d2.utils.events]: \u001b[0m eta: 3:27:39  iter: 39139  total_loss: 1.294  loss_cls: 0.3244  loss_box_reg: 0.4013  loss_mask: 0.2638  loss_rpn_cls: 0.06844  loss_rpn_loc: 0.1794  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:47:39 d2.utils.events]: \u001b[0m eta: 3:27:39  iter: 39159  total_loss: 1.293  loss_cls: 0.3534  loss_box_reg: 0.4013  loss_mask: 0.2591  loss_rpn_cls: 0.09303  loss_rpn_loc: 0.1647  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:47:44 d2.utils.events]: \u001b[0m eta: 3:27:58  iter: 39179  total_loss: 1.205  loss_cls: 0.3288  loss_box_reg: 0.3765  loss_mask: 0.2688  loss_rpn_cls: 0.07396  loss_rpn_loc: 0.1594  time: 0.2238  data_time: 0.0132  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:47:49 d2.utils.events]: \u001b[0m eta: 3:28:03  iter: 39199  total_loss: 1.145  loss_cls: 0.2823  loss_box_reg: 0.3436  loss_mask: 0.2742  loss_rpn_cls: 0.07627  loss_rpn_loc: 0.1693  time: 0.2238  data_time: 0.0089  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:47:53 d2.utils.events]: \u001b[0m eta: 3:27:25  iter: 39219  total_loss: 1.297  loss_cls: 0.3291  loss_box_reg: 0.3837  loss_mask: 0.263  loss_rpn_cls: 0.07495  loss_rpn_loc: 0.1571  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:47:57 d2.utils.events]: \u001b[0m eta: 3:27:23  iter: 39239  total_loss: 1.204  loss_cls: 0.2983  loss_box_reg: 0.3829  loss_mask: 0.263  loss_rpn_cls: 0.05956  loss_rpn_loc: 0.1598  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:48:02 d2.utils.events]: \u001b[0m eta: 3:27:19  iter: 39259  total_loss: 1.156  loss_cls: 0.3195  loss_box_reg: 0.379  loss_mask: 0.2542  loss_rpn_cls: 0.06583  loss_rpn_loc: 0.164  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:48:06 d2.utils.events]: \u001b[0m eta: 3:27:17  iter: 39279  total_loss: 1.172  loss_cls: 0.2955  loss_box_reg: 0.4016  loss_mask: 0.2584  loss_rpn_cls: 0.07589  loss_rpn_loc: 0.158  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:48:11 d2.utils.events]: \u001b[0m eta: 3:27:10  iter: 39299  total_loss: 1.139  loss_cls: 0.2729  loss_box_reg: 0.3799  loss_mask: 0.2508  loss_rpn_cls: 0.06998  loss_rpn_loc: 0.1757  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:48:15 d2.utils.events]: \u001b[0m eta: 3:26:58  iter: 39319  total_loss: 1.175  loss_cls: 0.3128  loss_box_reg: 0.3406  loss_mask: 0.2619  loss_rpn_cls: 0.07777  loss_rpn_loc: 0.172  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:48:20 d2.utils.events]: \u001b[0m eta: 3:26:52  iter: 39339  total_loss: 1.127  loss_cls: 0.2798  loss_box_reg: 0.3855  loss_mask: 0.257  loss_rpn_cls: 0.05981  loss_rpn_loc: 0.1495  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:48:24 d2.utils.events]: \u001b[0m eta: 3:26:50  iter: 39359  total_loss: 1.289  loss_cls: 0.3409  loss_box_reg: 0.427  loss_mask: 0.2715  loss_rpn_cls: 0.09514  loss_rpn_loc: 0.1588  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:48:29 d2.utils.events]: \u001b[0m eta: 3:26:53  iter: 39379  total_loss: 1.243  loss_cls: 0.306  loss_box_reg: 0.3681  loss_mask: 0.2724  loss_rpn_cls: 0.09665  loss_rpn_loc: 0.1792  time: 0.2238  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:48:33 d2.utils.events]: \u001b[0m eta: 3:26:48  iter: 39399  total_loss: 1.222  loss_cls: 0.2841  loss_box_reg: 0.3626  loss_mask: 0.264  loss_rpn_cls: 0.05409  loss_rpn_loc: 0.1755  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:48:37 d2.utils.events]: \u001b[0m eta: 3:26:39  iter: 39419  total_loss: 1.225  loss_cls: 0.3165  loss_box_reg: 0.4198  loss_mask: 0.269  loss_rpn_cls: 0.06935  loss_rpn_loc: 0.1703  time: 0.2238  data_time: 0.0130  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:48:42 d2.utils.events]: \u001b[0m eta: 3:26:36  iter: 39439  total_loss: 1.204  loss_cls: 0.313  loss_box_reg: 0.3607  loss_mask: 0.2749  loss_rpn_cls: 0.07477  loss_rpn_loc: 0.1691  time: 0.2238  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:48:46 d2.utils.events]: \u001b[0m eta: 3:26:32  iter: 39459  total_loss: 1.221  loss_cls: 0.2805  loss_box_reg: 0.3593  loss_mask: 0.2706  loss_rpn_cls: 0.06337  loss_rpn_loc: 0.1775  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:48:51 d2.utils.events]: \u001b[0m eta: 3:26:19  iter: 39479  total_loss: 1.129  loss_cls: 0.2806  loss_box_reg: 0.3923  loss_mask: 0.2456  loss_rpn_cls: 0.06825  loss_rpn_loc: 0.1481  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:48:55 d2.utils.events]: \u001b[0m eta: 3:25:57  iter: 39499  total_loss: 0.9941  loss_cls: 0.2357  loss_box_reg: 0.2999  loss_mask: 0.2269  loss_rpn_cls: 0.05343  loss_rpn_loc: 0.1525  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:49:00 d2.utils.events]: \u001b[0m eta: 3:26:02  iter: 39519  total_loss: 1.341  loss_cls: 0.3395  loss_box_reg: 0.4426  loss_mask: 0.279  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.1797  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:49:04 d2.utils.events]: \u001b[0m eta: 3:25:34  iter: 39539  total_loss: 1.169  loss_cls: 0.2726  loss_box_reg: 0.3494  loss_mask: 0.2502  loss_rpn_cls: 0.07197  loss_rpn_loc: 0.1616  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:49:09 d2.utils.events]: \u001b[0m eta: 3:25:56  iter: 39559  total_loss: 1.206  loss_cls: 0.3054  loss_box_reg: 0.4066  loss_mask: 0.282  loss_rpn_cls: 0.08159  loss_rpn_loc: 0.1556  time: 0.2238  data_time: 0.0162  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:49:13 d2.utils.events]: \u001b[0m eta: 3:25:38  iter: 39579  total_loss: 1.313  loss_cls: 0.3319  loss_box_reg: 0.4014  loss_mask: 0.2765  loss_rpn_cls: 0.09942  loss_rpn_loc: 0.1941  time: 0.2238  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:49:18 d2.utils.events]: \u001b[0m eta: 3:25:54  iter: 39599  total_loss: 1.198  loss_cls: 0.2948  loss_box_reg: 0.3602  loss_mask: 0.2807  loss_rpn_cls: 0.09353  loss_rpn_loc: 0.1609  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:49:22 d2.utils.events]: \u001b[0m eta: 3:26:00  iter: 39619  total_loss: 1.251  loss_cls: 0.3086  loss_box_reg: 0.4499  loss_mask: 0.2714  loss_rpn_cls: 0.07362  loss_rpn_loc: 0.1764  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:49:27 d2.utils.events]: \u001b[0m eta: 3:25:43  iter: 39639  total_loss: 1.175  loss_cls: 0.2961  loss_box_reg: 0.3761  loss_mask: 0.2521  loss_rpn_cls: 0.06277  loss_rpn_loc: 0.1592  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:49:31 d2.utils.events]: \u001b[0m eta: 3:25:52  iter: 39659  total_loss: 1.162  loss_cls: 0.2708  loss_box_reg: 0.355  loss_mask: 0.2486  loss_rpn_cls: 0.07885  loss_rpn_loc: 0.1728  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:49:35 d2.utils.events]: \u001b[0m eta: 3:25:34  iter: 39679  total_loss: 1.191  loss_cls: 0.3136  loss_box_reg: 0.4069  loss_mask: 0.2668  loss_rpn_cls: 0.0602  loss_rpn_loc: 0.1454  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:49:40 d2.utils.events]: \u001b[0m eta: 3:25:44  iter: 39699  total_loss: 1.236  loss_cls: 0.3003  loss_box_reg: 0.4087  loss_mask: 0.26  loss_rpn_cls: 0.09706  loss_rpn_loc: 0.1701  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:49:44 d2.utils.events]: \u001b[0m eta: 3:25:35  iter: 39719  total_loss: 1.242  loss_cls: 0.3111  loss_box_reg: 0.3644  loss_mask: 0.2643  loss_rpn_cls: 0.07958  loss_rpn_loc: 0.1819  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:49:49 d2.utils.events]: \u001b[0m eta: 3:25:52  iter: 39739  total_loss: 1.182  loss_cls: 0.2826  loss_box_reg: 0.3604  loss_mask: 0.2556  loss_rpn_cls: 0.1152  loss_rpn_loc: 0.18  time: 0.2238  data_time: 0.0179  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:49:54 d2.utils.events]: \u001b[0m eta: 3:25:38  iter: 39759  total_loss: 1.221  loss_cls: 0.2924  loss_box_reg: 0.4033  loss_mask: 0.2692  loss_rpn_cls: 0.09612  loss_rpn_loc: 0.1541  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:49:58 d2.utils.events]: \u001b[0m eta: 3:25:46  iter: 39779  total_loss: 1.237  loss_cls: 0.2918  loss_box_reg: 0.3891  loss_mask: 0.2705  loss_rpn_cls: 0.08827  loss_rpn_loc: 0.1815  time: 0.2238  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:50:03 d2.utils.events]: \u001b[0m eta: 3:25:37  iter: 39799  total_loss: 1.175  loss_cls: 0.2794  loss_box_reg: 0.4185  loss_mask: 0.2643  loss_rpn_cls: 0.07652  loss_rpn_loc: 0.1731  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:50:07 d2.utils.events]: \u001b[0m eta: 3:25:33  iter: 39819  total_loss: 1.222  loss_cls: 0.2561  loss_box_reg: 0.4079  loss_mask: 0.2556  loss_rpn_cls: 0.04964  loss_rpn_loc: 0.1539  time: 0.2238  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:50:12 d2.utils.events]: \u001b[0m eta: 3:25:30  iter: 39839  total_loss: 1.191  loss_cls: 0.2861  loss_box_reg: 0.3752  loss_mask: 0.2572  loss_rpn_cls: 0.06553  loss_rpn_loc: 0.1579  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:50:16 d2.utils.events]: \u001b[0m eta: 3:25:09  iter: 39859  total_loss: 1.227  loss_cls: 0.2969  loss_box_reg: 0.4  loss_mask: 0.2478  loss_rpn_cls: 0.08454  loss_rpn_loc: 0.1952  time: 0.2238  data_time: 0.0233  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:50:21 d2.utils.events]: \u001b[0m eta: 3:25:00  iter: 39879  total_loss: 1.095  loss_cls: 0.2843  loss_box_reg: 0.3386  loss_mask: 0.2624  loss_rpn_cls: 0.08189  loss_rpn_loc: 0.1631  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:50:25 d2.utils.events]: \u001b[0m eta: 3:25:08  iter: 39899  total_loss: 1.085  loss_cls: 0.2848  loss_box_reg: 0.329  loss_mask: 0.2401  loss_rpn_cls: 0.08139  loss_rpn_loc: 0.1669  time: 0.2238  data_time: 0.0097  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:50:30 d2.utils.events]: \u001b[0m eta: 3:24:44  iter: 39919  total_loss: 1.329  loss_cls: 0.3684  loss_box_reg: 0.4375  loss_mask: 0.2662  loss_rpn_cls: 0.08798  loss_rpn_loc: 0.1737  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:50:35 d2.utils.events]: \u001b[0m eta: 3:24:43  iter: 39939  total_loss: 1.385  loss_cls: 0.3377  loss_box_reg: 0.398  loss_mask: 0.2687  loss_rpn_cls: 0.08432  loss_rpn_loc: 0.1784  time: 0.2238  data_time: 0.0212  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:50:39 d2.utils.events]: \u001b[0m eta: 3:24:35  iter: 39959  total_loss: 1.151  loss_cls: 0.3008  loss_box_reg: 0.3731  loss_mask: 0.2722  loss_rpn_cls: 0.07581  loss_rpn_loc: 0.1638  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:50:44 d2.utils.events]: \u001b[0m eta: 3:24:09  iter: 39979  total_loss: 1.31  loss_cls: 0.3262  loss_box_reg: 0.4412  loss_mask: 0.2507  loss_rpn_cls: 0.08068  loss_rpn_loc: 0.1576  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:50:48 d2.utils.events]: \u001b[0m eta: 3:23:54  iter: 39999  total_loss: 1.197  loss_cls: 0.3117  loss_box_reg: 0.4314  loss_mask: 0.2735  loss_rpn_cls: 0.06039  loss_rpn_loc: 0.1516  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:50:53 d2.utils.events]: \u001b[0m eta: 3:24:13  iter: 40019  total_loss: 1.123  loss_cls: 0.2725  loss_box_reg: 0.3513  loss_mask: 0.2617  loss_rpn_cls: 0.06423  loss_rpn_loc: 0.1733  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:50:57 d2.utils.events]: \u001b[0m eta: 3:23:56  iter: 40039  total_loss: 1.092  loss_cls: 0.2569  loss_box_reg: 0.3714  loss_mask: 0.2433  loss_rpn_cls: 0.06816  loss_rpn_loc: 0.1544  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:51:02 d2.utils.events]: \u001b[0m eta: 3:24:24  iter: 40059  total_loss: 1.136  loss_cls: 0.2726  loss_box_reg: 0.3768  loss_mask: 0.2599  loss_rpn_cls: 0.09582  loss_rpn_loc: 0.1796  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:51:06 d2.utils.events]: \u001b[0m eta: 3:24:45  iter: 40079  total_loss: 1.073  loss_cls: 0.204  loss_box_reg: 0.3453  loss_mask: 0.2543  loss_rpn_cls: 0.06096  loss_rpn_loc: 0.1645  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:51:11 d2.utils.events]: \u001b[0m eta: 3:24:40  iter: 40099  total_loss: 1.171  loss_cls: 0.2797  loss_box_reg: 0.3933  loss_mask: 0.2768  loss_rpn_cls: 0.06976  loss_rpn_loc: 0.1561  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:51:15 d2.utils.events]: \u001b[0m eta: 3:24:50  iter: 40119  total_loss: 1.171  loss_cls: 0.3137  loss_box_reg: 0.3941  loss_mask: 0.2548  loss_rpn_cls: 0.06809  loss_rpn_loc: 0.1544  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:51:20 d2.utils.events]: \u001b[0m eta: 3:24:55  iter: 40139  total_loss: 1.323  loss_cls: 0.3355  loss_box_reg: 0.4303  loss_mask: 0.2989  loss_rpn_cls: 0.09669  loss_rpn_loc: 0.1809  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:51:24 d2.utils.events]: \u001b[0m eta: 3:24:31  iter: 40159  total_loss: 1.168  loss_cls: 0.2939  loss_box_reg: 0.3654  loss_mask: 0.2503  loss_rpn_cls: 0.08172  loss_rpn_loc: 0.1468  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:51:28 d2.utils.events]: \u001b[0m eta: 3:24:26  iter: 40179  total_loss: 1.171  loss_cls: 0.2889  loss_box_reg: 0.3888  loss_mask: 0.2736  loss_rpn_cls: 0.07219  loss_rpn_loc: 0.1512  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:51:33 d2.utils.events]: \u001b[0m eta: 3:24:14  iter: 40199  total_loss: 1.084  loss_cls: 0.2905  loss_box_reg: 0.3777  loss_mask: 0.2434  loss_rpn_cls: 0.07399  loss_rpn_loc: 0.1467  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:51:37 d2.utils.events]: \u001b[0m eta: 3:24:17  iter: 40219  total_loss: 1.24  loss_cls: 0.3246  loss_box_reg: 0.3997  loss_mask: 0.2601  loss_rpn_cls: 0.07281  loss_rpn_loc: 0.153  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:51:42 d2.utils.events]: \u001b[0m eta: 3:24:13  iter: 40239  total_loss: 1.182  loss_cls: 0.2797  loss_box_reg: 0.3813  loss_mask: 0.2702  loss_rpn_cls: 0.05718  loss_rpn_loc: 0.1575  time: 0.2238  data_time: 0.0166  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:51:46 d2.utils.events]: \u001b[0m eta: 3:24:11  iter: 40259  total_loss: 1.17  loss_cls: 0.2727  loss_box_reg: 0.3497  loss_mask: 0.2688  loss_rpn_cls: 0.06714  loss_rpn_loc: 0.1658  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:51:51 d2.utils.events]: \u001b[0m eta: 3:24:01  iter: 40279  total_loss: 1.215  loss_cls: 0.2967  loss_box_reg: 0.4254  loss_mask: 0.2596  loss_rpn_cls: 0.06166  loss_rpn_loc: 0.159  time: 0.2238  data_time: 0.0232  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:51:55 d2.utils.events]: \u001b[0m eta: 3:23:59  iter: 40299  total_loss: 1.111  loss_cls: 0.2732  loss_box_reg: 0.362  loss_mask: 0.2561  loss_rpn_cls: 0.055  loss_rpn_loc: 0.1573  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:52:00 d2.utils.events]: \u001b[0m eta: 3:23:58  iter: 40319  total_loss: 1.004  loss_cls: 0.2499  loss_box_reg: 0.3142  loss_mask: 0.2326  loss_rpn_cls: 0.06725  loss_rpn_loc: 0.1611  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:52:04 d2.utils.events]: \u001b[0m eta: 3:24:01  iter: 40339  total_loss: 1.206  loss_cls: 0.2806  loss_box_reg: 0.3638  loss_mask: 0.2497  loss_rpn_cls: 0.0829  loss_rpn_loc: 0.169  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:52:09 d2.utils.events]: \u001b[0m eta: 3:24:19  iter: 40359  total_loss: 1.032  loss_cls: 0.2574  loss_box_reg: 0.3437  loss_mask: 0.2548  loss_rpn_cls: 0.08903  loss_rpn_loc: 0.164  time: 0.2238  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:52:13 d2.utils.events]: \u001b[0m eta: 3:24:10  iter: 40379  total_loss: 1.253  loss_cls: 0.3155  loss_box_reg: 0.4127  loss_mask: 0.2708  loss_rpn_cls: 0.0818  loss_rpn_loc: 0.1767  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:52:18 d2.utils.events]: \u001b[0m eta: 3:24:20  iter: 40399  total_loss: 1.215  loss_cls: 0.3115  loss_box_reg: 0.3927  loss_mask: 0.2802  loss_rpn_cls: 0.06892  loss_rpn_loc: 0.176  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:52:22 d2.utils.events]: \u001b[0m eta: 3:24:16  iter: 40419  total_loss: 1.217  loss_cls: 0.2949  loss_box_reg: 0.3769  loss_mask: 0.2708  loss_rpn_cls: 0.08802  loss_rpn_loc: 0.1725  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:52:26 d2.utils.events]: \u001b[0m eta: 3:24:07  iter: 40439  total_loss: 1.28  loss_cls: 0.3102  loss_box_reg: 0.4009  loss_mask: 0.2739  loss_rpn_cls: 0.0881  loss_rpn_loc: 0.1635  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:52:31 d2.utils.events]: \u001b[0m eta: 3:24:12  iter: 40459  total_loss: 1.15  loss_cls: 0.3183  loss_box_reg: 0.3611  loss_mask: 0.2464  loss_rpn_cls: 0.06724  loss_rpn_loc: 0.1592  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:52:35 d2.utils.events]: \u001b[0m eta: 3:24:13  iter: 40479  total_loss: 1.178  loss_cls: 0.2751  loss_box_reg: 0.3659  loss_mask: 0.2499  loss_rpn_cls: 0.06577  loss_rpn_loc: 0.1524  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:52:40 d2.utils.events]: \u001b[0m eta: 3:24:05  iter: 40499  total_loss: 1.203  loss_cls: 0.2977  loss_box_reg: 0.3933  loss_mask: 0.2666  loss_rpn_cls: 0.07447  loss_rpn_loc: 0.1724  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:52:44 d2.utils.events]: \u001b[0m eta: 3:23:59  iter: 40519  total_loss: 1.197  loss_cls: 0.2851  loss_box_reg: 0.4169  loss_mask: 0.2681  loss_rpn_cls: 0.0781  loss_rpn_loc: 0.1716  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:52:48 d2.utils.events]: \u001b[0m eta: 3:23:55  iter: 40539  total_loss: 1.198  loss_cls: 0.3057  loss_box_reg: 0.3978  loss_mask: 0.2581  loss_rpn_cls: 0.0823  loss_rpn_loc: 0.1598  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:52:53 d2.utils.events]: \u001b[0m eta: 3:24:00  iter: 40559  total_loss: 1.132  loss_cls: 0.2823  loss_box_reg: 0.3461  loss_mask: 0.2555  loss_rpn_cls: 0.08703  loss_rpn_loc: 0.1732  time: 0.2238  data_time: 0.0234  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:52:58 d2.utils.events]: \u001b[0m eta: 3:24:10  iter: 40579  total_loss: 1.135  loss_cls: 0.2661  loss_box_reg: 0.357  loss_mask: 0.2452  loss_rpn_cls: 0.08932  loss_rpn_loc: 0.1817  time: 0.2238  data_time: 0.0156  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:53:03 d2.utils.events]: \u001b[0m eta: 3:23:59  iter: 40599  total_loss: 1.238  loss_cls: 0.2964  loss_box_reg: 0.3883  loss_mask: 0.2693  loss_rpn_cls: 0.07829  loss_rpn_loc: 0.191  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:53:07 d2.utils.events]: \u001b[0m eta: 3:24:01  iter: 40619  total_loss: 1.212  loss_cls: 0.2925  loss_box_reg: 0.3943  loss_mask: 0.2666  loss_rpn_cls: 0.07551  loss_rpn_loc: 0.1661  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:53:12 d2.utils.events]: \u001b[0m eta: 3:24:14  iter: 40639  total_loss: 1.036  loss_cls: 0.2136  loss_box_reg: 0.3716  loss_mask: 0.2547  loss_rpn_cls: 0.07453  loss_rpn_loc: 0.1534  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:53:16 d2.utils.events]: \u001b[0m eta: 3:23:47  iter: 40659  total_loss: 1.229  loss_cls: 0.2977  loss_box_reg: 0.4058  loss_mask: 0.2651  loss_rpn_cls: 0.07106  loss_rpn_loc: 0.1661  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:53:20 d2.utils.events]: \u001b[0m eta: 3:23:39  iter: 40679  total_loss: 1.239  loss_cls: 0.2972  loss_box_reg: 0.4394  loss_mask: 0.2665  loss_rpn_cls: 0.06893  loss_rpn_loc: 0.1706  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:53:25 d2.utils.events]: \u001b[0m eta: 3:23:35  iter: 40699  total_loss: 1.158  loss_cls: 0.2756  loss_box_reg: 0.3527  loss_mask: 0.2476  loss_rpn_cls: 0.06076  loss_rpn_loc: 0.1695  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:53:29 d2.utils.events]: \u001b[0m eta: 3:23:31  iter: 40719  total_loss: 1.151  loss_cls: 0.2787  loss_box_reg: 0.379  loss_mask: 0.2466  loss_rpn_cls: 0.08229  loss_rpn_loc: 0.1613  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:53:34 d2.utils.events]: \u001b[0m eta: 3:23:19  iter: 40739  total_loss: 1.182  loss_cls: 0.2991  loss_box_reg: 0.4051  loss_mask: 0.2508  loss_rpn_cls: 0.09619  loss_rpn_loc: 0.1756  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:53:38 d2.utils.events]: \u001b[0m eta: 3:23:11  iter: 40759  total_loss: 1.234  loss_cls: 0.3135  loss_box_reg: 0.4032  loss_mask: 0.2773  loss_rpn_cls: 0.08437  loss_rpn_loc: 0.1555  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:53:42 d2.utils.events]: \u001b[0m eta: 3:23:01  iter: 40779  total_loss: 1.142  loss_cls: 0.2881  loss_box_reg: 0.3962  loss_mask: 0.2623  loss_rpn_cls: 0.06471  loss_rpn_loc: 0.1527  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:53:47 d2.utils.events]: \u001b[0m eta: 3:23:04  iter: 40799  total_loss: 1.226  loss_cls: 0.3217  loss_box_reg: 0.3784  loss_mask: 0.2687  loss_rpn_cls: 0.08495  loss_rpn_loc: 0.1636  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:53:52 d2.utils.events]: \u001b[0m eta: 3:23:09  iter: 40819  total_loss: 1.204  loss_cls: 0.2958  loss_box_reg: 0.3739  loss_mask: 0.2701  loss_rpn_cls: 0.0819  loss_rpn_loc: 0.1803  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:53:57 d2.utils.events]: \u001b[0m eta: 3:23:04  iter: 40839  total_loss: 1.265  loss_cls: 0.3266  loss_box_reg: 0.3673  loss_mask: 0.2771  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.1706  time: 0.2238  data_time: 0.0207  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:54:01 d2.utils.events]: \u001b[0m eta: 3:23:08  iter: 40859  total_loss: 1.157  loss_cls: 0.3342  loss_box_reg: 0.4066  loss_mask: 0.2695  loss_rpn_cls: 0.07072  loss_rpn_loc: 0.1512  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:54:05 d2.utils.events]: \u001b[0m eta: 3:23:04  iter: 40879  total_loss: 1.17  loss_cls: 0.3114  loss_box_reg: 0.3915  loss_mask: 0.2446  loss_rpn_cls: 0.07833  loss_rpn_loc: 0.1688  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:54:10 d2.utils.events]: \u001b[0m eta: 3:22:59  iter: 40899  total_loss: 1.154  loss_cls: 0.2836  loss_box_reg: 0.384  loss_mask: 0.2674  loss_rpn_cls: 0.07341  loss_rpn_loc: 0.172  time: 0.2238  data_time: 0.0090  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:54:15 d2.utils.events]: \u001b[0m eta: 3:22:58  iter: 40919  total_loss: 1.128  loss_cls: 0.2684  loss_box_reg: 0.3567  loss_mask: 0.2495  loss_rpn_cls: 0.06691  loss_rpn_loc: 0.1728  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:54:20 d2.utils.events]: \u001b[0m eta: 3:22:51  iter: 40939  total_loss: 1.26  loss_cls: 0.305  loss_box_reg: 0.4287  loss_mask: 0.2771  loss_rpn_cls: 0.05177  loss_rpn_loc: 0.161  time: 0.2238  data_time: 0.0174  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:54:24 d2.utils.events]: \u001b[0m eta: 3:22:41  iter: 40959  total_loss: 1.303  loss_cls: 0.2941  loss_box_reg: 0.4047  loss_mask: 0.2652  loss_rpn_cls: 0.08614  loss_rpn_loc: 0.1687  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:54:28 d2.utils.events]: \u001b[0m eta: 3:22:42  iter: 40979  total_loss: 1.13  loss_cls: 0.2578  loss_box_reg: 0.359  loss_mask: 0.2504  loss_rpn_cls: 0.06859  loss_rpn_loc: 0.1473  time: 0.2238  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:54:33 d2.utils.events]: \u001b[0m eta: 3:22:35  iter: 40999  total_loss: 1.208  loss_cls: 0.3089  loss_box_reg: 0.4061  loss_mask: 0.2598  loss_rpn_cls: 0.05741  loss_rpn_loc: 0.1632  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:54:37 d2.utils.events]: \u001b[0m eta: 3:22:14  iter: 41019  total_loss: 1.329  loss_cls: 0.3173  loss_box_reg: 0.4352  loss_mask: 0.2897  loss_rpn_cls: 0.06132  loss_rpn_loc: 0.1696  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:54:41 d2.utils.events]: \u001b[0m eta: 3:22:20  iter: 41039  total_loss: 1.06  loss_cls: 0.2665  loss_box_reg: 0.3546  loss_mask: 0.2518  loss_rpn_cls: 0.08063  loss_rpn_loc: 0.1549  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:54:46 d2.utils.events]: \u001b[0m eta: 3:22:02  iter: 41059  total_loss: 1.289  loss_cls: 0.3286  loss_box_reg: 0.377  loss_mask: 0.2668  loss_rpn_cls: 0.07559  loss_rpn_loc: 0.1665  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:54:50 d2.utils.events]: \u001b[0m eta: 3:21:45  iter: 41079  total_loss: 1.191  loss_cls: 0.2998  loss_box_reg: 0.3395  loss_mask: 0.2594  loss_rpn_cls: 0.06897  loss_rpn_loc: 0.1761  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:54:55 d2.utils.events]: \u001b[0m eta: 3:21:59  iter: 41099  total_loss: 1.214  loss_cls: 0.2965  loss_box_reg: 0.3764  loss_mask: 0.2719  loss_rpn_cls: 0.0843  loss_rpn_loc: 0.1893  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:54:59 d2.utils.events]: \u001b[0m eta: 3:21:23  iter: 41119  total_loss: 1.215  loss_cls: 0.2916  loss_box_reg: 0.3866  loss_mask: 0.267  loss_rpn_cls: 0.06603  loss_rpn_loc: 0.1534  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:55:04 d2.utils.events]: \u001b[0m eta: 3:21:44  iter: 41139  total_loss: 1.185  loss_cls: 0.2807  loss_box_reg: 0.3799  loss_mask: 0.2569  loss_rpn_cls: 0.09598  loss_rpn_loc: 0.1619  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:55:08 d2.utils.events]: \u001b[0m eta: 3:21:40  iter: 41159  total_loss: 1.134  loss_cls: 0.2735  loss_box_reg: 0.3784  loss_mask: 0.265  loss_rpn_cls: 0.07645  loss_rpn_loc: 0.1527  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:55:13 d2.utils.events]: \u001b[0m eta: 3:21:10  iter: 41179  total_loss: 1.183  loss_cls: 0.2525  loss_box_reg: 0.3486  loss_mask: 0.2645  loss_rpn_cls: 0.06556  loss_rpn_loc: 0.1665  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:55:17 d2.utils.events]: \u001b[0m eta: 3:21:18  iter: 41199  total_loss: 1.22  loss_cls: 0.2906  loss_box_reg: 0.3794  loss_mask: 0.2664  loss_rpn_cls: 0.08445  loss_rpn_loc: 0.1655  time: 0.2238  data_time: 0.0212  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:55:22 d2.utils.events]: \u001b[0m eta: 3:21:34  iter: 41219  total_loss: 1.092  loss_cls: 0.2901  loss_box_reg: 0.3897  loss_mask: 0.2601  loss_rpn_cls: 0.0707  loss_rpn_loc: 0.1627  time: 0.2238  data_time: 0.0165  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:55:26 d2.utils.events]: \u001b[0m eta: 3:20:57  iter: 41239  total_loss: 1.235  loss_cls: 0.3289  loss_box_reg: 0.4067  loss_mask: 0.2556  loss_rpn_cls: 0.05976  loss_rpn_loc: 0.1479  time: 0.2238  data_time: 0.0056  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:55:31 d2.utils.events]: \u001b[0m eta: 3:21:17  iter: 41259  total_loss: 1.269  loss_cls: 0.3368  loss_box_reg: 0.3842  loss_mask: 0.2594  loss_rpn_cls: 0.07848  loss_rpn_loc: 0.1662  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:55:35 d2.utils.events]: \u001b[0m eta: 3:21:19  iter: 41279  total_loss: 1.217  loss_cls: 0.3218  loss_box_reg: 0.3972  loss_mask: 0.2693  loss_rpn_cls: 0.06746  loss_rpn_loc: 0.1791  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:55:40 d2.utils.events]: \u001b[0m eta: 3:21:15  iter: 41299  total_loss: 1.257  loss_cls: 0.293  loss_box_reg: 0.3957  loss_mask: 0.2668  loss_rpn_cls: 0.0779  loss_rpn_loc: 0.175  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:55:44 d2.utils.events]: \u001b[0m eta: 3:21:09  iter: 41319  total_loss: 1.152  loss_cls: 0.3007  loss_box_reg: 0.3773  loss_mask: 0.2465  loss_rpn_cls: 0.0625  loss_rpn_loc: 0.1756  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:55:49 d2.utils.events]: \u001b[0m eta: 3:21:05  iter: 41339  total_loss: 1.176  loss_cls: 0.2787  loss_box_reg: 0.3839  loss_mask: 0.2569  loss_rpn_cls: 0.08102  loss_rpn_loc: 0.1485  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:55:53 d2.utils.events]: \u001b[0m eta: 3:20:55  iter: 41359  total_loss: 1.172  loss_cls: 0.2726  loss_box_reg: 0.3754  loss_mask: 0.2789  loss_rpn_cls: 0.08571  loss_rpn_loc: 0.1732  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:55:57 d2.utils.events]: \u001b[0m eta: 3:20:26  iter: 41379  total_loss: 1.116  loss_cls: 0.2543  loss_box_reg: 0.3741  loss_mask: 0.2504  loss_rpn_cls: 0.07399  loss_rpn_loc: 0.1573  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:57:54 d2.utils.events]: \u001b[0m eta: 3:17:40  iter: 41899  total_loss: 1.304  loss_cls: 0.3116  loss_box_reg: 0.4077  loss_mask: 0.2793  loss_rpn_cls: 0.08573  loss_rpn_loc: 0.1725  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:57:59 d2.utils.events]: \u001b[0m eta: 3:17:48  iter: 41919  total_loss: 1.278  loss_cls: 0.3121  loss_box_reg: 0.3326  loss_mask: 0.2971  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.1929  time: 0.2238  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:58:04 d2.utils.events]: \u001b[0m eta: 3:17:37  iter: 41939  total_loss: 1.188  loss_cls: 0.2665  loss_box_reg: 0.4153  loss_mask: 0.2723  loss_rpn_cls: 0.06547  loss_rpn_loc: 0.1642  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:58:08 d2.utils.events]: \u001b[0m eta: 3:17:23  iter: 41959  total_loss: 1.214  loss_cls: 0.2931  loss_box_reg: 0.4007  loss_mask: 0.2572  loss_rpn_cls: 0.09027  loss_rpn_loc: 0.1672  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:58:12 d2.utils.events]: \u001b[0m eta: 3:17:34  iter: 41979  total_loss: 1.265  loss_cls: 0.2995  loss_box_reg: 0.4214  loss_mask: 0.2739  loss_rpn_cls: 0.06942  loss_rpn_loc: 0.1652  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:58:17 d2.utils.events]: \u001b[0m eta: 3:17:10  iter: 41999  total_loss: 1.143  loss_cls: 0.2694  loss_box_reg: 0.338  loss_mask: 0.2403  loss_rpn_cls: 0.05913  loss_rpn_loc: 0.1571  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:58:21 d2.utils.events]: \u001b[0m eta: 3:17:41  iter: 42019  total_loss: 1.298  loss_cls: 0.3374  loss_box_reg: 0.4117  loss_mask: 0.2786  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.1771  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:58:26 d2.utils.events]: \u001b[0m eta: 3:17:25  iter: 42039  total_loss: 1.24  loss_cls: 0.3163  loss_box_reg: 0.3925  loss_mask: 0.2777  loss_rpn_cls: 0.08881  loss_rpn_loc: 0.1847  time: 0.2238  data_time: 0.0135  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:58:31 d2.utils.events]: \u001b[0m eta: 3:17:37  iter: 42059  total_loss: 1.307  loss_cls: 0.3262  loss_box_reg: 0.3615  loss_mask: 0.2895  loss_rpn_cls: 0.1178  loss_rpn_loc: 0.1869  time: 0.2238  data_time: 0.0171  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:58:35 d2.utils.events]: \u001b[0m eta: 3:17:36  iter: 42079  total_loss: 1.182  loss_cls: 0.2957  loss_box_reg: 0.3776  loss_mask: 0.2587  loss_rpn_cls: 0.07644  loss_rpn_loc: 0.1569  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:58:40 d2.utils.events]: \u001b[0m eta: 3:17:13  iter: 42099  total_loss: 1.357  loss_cls: 0.3566  loss_box_reg: 0.4235  loss_mask: 0.2836  loss_rpn_cls: 0.08165  loss_rpn_loc: 0.1748  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:58:44 d2.utils.events]: \u001b[0m eta: 3:17:19  iter: 42119  total_loss: 0.9902  loss_cls: 0.2468  loss_box_reg: 0.3327  loss_mask: 0.2247  loss_rpn_cls: 0.05066  loss_rpn_loc: 0.1364  time: 0.2238  data_time: 0.0158  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:58:49 d2.utils.events]: \u001b[0m eta: 3:17:10  iter: 42139  total_loss: 1.114  loss_cls: 0.2736  loss_box_reg: 0.3711  loss_mask: 0.2457  loss_rpn_cls: 0.05552  loss_rpn_loc: 0.1654  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:58:53 d2.utils.events]: \u001b[0m eta: 3:17:24  iter: 42159  total_loss: 1.105  loss_cls: 0.2667  loss_box_reg: 0.351  loss_mask: 0.2499  loss_rpn_cls: 0.07356  loss_rpn_loc: 0.1547  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:58:58 d2.utils.events]: \u001b[0m eta: 3:17:30  iter: 42179  total_loss: 1.267  loss_cls: 0.3144  loss_box_reg: 0.4063  loss_mask: 0.2709  loss_rpn_cls: 0.08404  loss_rpn_loc: 0.1791  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:59:02 d2.utils.events]: \u001b[0m eta: 3:17:25  iter: 42199  total_loss: 1.191  loss_cls: 0.3025  loss_box_reg: 0.3792  loss_mask: 0.2555  loss_rpn_cls: 0.09591  loss_rpn_loc: 0.1681  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:59:06 d2.utils.events]: \u001b[0m eta: 3:16:57  iter: 42219  total_loss: 1.205  loss_cls: 0.3248  loss_box_reg: 0.3925  loss_mask: 0.2788  loss_rpn_cls: 0.07167  loss_rpn_loc: 0.1684  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:59:11 d2.utils.events]: \u001b[0m eta: 3:16:53  iter: 42239  total_loss: 1.199  loss_cls: 0.2886  loss_box_reg: 0.3698  loss_mask: 0.2791  loss_rpn_cls: 0.0739  loss_rpn_loc: 0.1721  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:59:15 d2.utils.events]: \u001b[0m eta: 3:16:38  iter: 42259  total_loss: 1.105  loss_cls: 0.2705  loss_box_reg: 0.3477  loss_mask: 0.243  loss_rpn_cls: 0.05819  loss_rpn_loc: 0.158  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:59:19 d2.utils.events]: \u001b[0m eta: 3:15:57  iter: 42279  total_loss: 1.161  loss_cls: 0.3051  loss_box_reg: 0.3872  loss_mask: 0.2393  loss_rpn_cls: 0.07497  loss_rpn_loc: 0.1589  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:59:24 d2.utils.events]: \u001b[0m eta: 3:15:58  iter: 42299  total_loss: 1.152  loss_cls: 0.2946  loss_box_reg: 0.3934  loss_mask: 0.2684  loss_rpn_cls: 0.06689  loss_rpn_loc: 0.1555  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:59:28 d2.utils.events]: \u001b[0m eta: 3:15:49  iter: 42319  total_loss: 1.263  loss_cls: 0.3254  loss_box_reg: 0.3775  loss_mask: 0.2756  loss_rpn_cls: 0.09035  loss_rpn_loc: 0.1862  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:59:33 d2.utils.events]: \u001b[0m eta: 3:15:44  iter: 42339  total_loss: 1.183  loss_cls: 0.3018  loss_box_reg: 0.4312  loss_mask: 0.2756  loss_rpn_cls: 0.06224  loss_rpn_loc: 0.1621  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/29 23:59:37 d2.utils.events]: \u001b[0m eta: 3:16:22  iter: 42359  total_loss: 1.295  loss_cls: 0.3367  loss_box_reg: 0.4073  loss_mask: 0.284  loss_rpn_cls: 0.09423  loss_rpn_loc: 0.1837  time: 0.2238  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:59:42 d2.utils.events]: \u001b[0m eta: 3:16:23  iter: 42379  total_loss: 1.127  loss_cls: 0.2745  loss_box_reg: 0.3773  loss_mask: 0.272  loss_rpn_cls: 0.08241  loss_rpn_loc: 0.1715  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:59:46 d2.utils.events]: \u001b[0m eta: 3:15:43  iter: 42399  total_loss: 1.078  loss_cls: 0.2395  loss_box_reg: 0.3441  loss_mask: 0.2462  loss_rpn_cls: 0.064  loss_rpn_loc: 0.1545  time: 0.2238  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:59:51 d2.utils.events]: \u001b[0m eta: 3:15:51  iter: 42419  total_loss: 1.116  loss_cls: 0.2618  loss_box_reg: 0.3439  loss_mask: 0.2514  loss_rpn_cls: 0.06086  loss_rpn_loc: 0.1577  time: 0.2238  data_time: 0.0160  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/29 23:59:55 d2.utils.events]: \u001b[0m eta: 3:15:34  iter: 42439  total_loss: 1.118  loss_cls: 0.2886  loss_box_reg: 0.3884  loss_mask: 0.2446  loss_rpn_cls: 0.06541  loss_rpn_loc: 0.1711  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:00:00 d2.utils.events]: \u001b[0m eta: 3:15:18  iter: 42459  total_loss: 1.101  loss_cls: 0.2581  loss_box_reg: 0.3744  loss_mask: 0.2488  loss_rpn_cls: 0.06668  loss_rpn_loc: 0.1631  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:00:04 d2.utils.events]: \u001b[0m eta: 3:15:02  iter: 42479  total_loss: 1.156  loss_cls: 0.2796  loss_box_reg: 0.3745  loss_mask: 0.2446  loss_rpn_cls: 0.07601  loss_rpn_loc: 0.1643  time: 0.2238  data_time: 0.0110  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:00:09 d2.utils.events]: \u001b[0m eta: 3:14:59  iter: 42499  total_loss: 1.067  loss_cls: 0.2308  loss_box_reg: 0.3516  loss_mask: 0.2358  loss_rpn_cls: 0.04681  loss_rpn_loc: 0.1583  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:00:13 d2.utils.events]: \u001b[0m eta: 3:14:50  iter: 42519  total_loss: 1.192  loss_cls: 0.2952  loss_box_reg: 0.3965  loss_mask: 0.2486  loss_rpn_cls: 0.08399  loss_rpn_loc: 0.1733  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:00:18 d2.utils.events]: \u001b[0m eta: 3:15:01  iter: 42539  total_loss: 1.171  loss_cls: 0.2815  loss_box_reg: 0.3561  loss_mask: 0.267  loss_rpn_cls: 0.07985  loss_rpn_loc: 0.1712  time: 0.2238  data_time: 0.0129  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:00:23 d2.utils.events]: \u001b[0m eta: 3:15:08  iter: 42559  total_loss: 1.157  loss_cls: 0.288  loss_box_reg: 0.3617  loss_mask: 0.2563  loss_rpn_cls: 0.083  loss_rpn_loc: 0.186  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:00:27 d2.utils.events]: \u001b[0m eta: 3:15:04  iter: 42579  total_loss: 1.139  loss_cls: 0.2884  loss_box_reg: 0.3611  loss_mask: 0.2767  loss_rpn_cls: 0.06803  loss_rpn_loc: 0.1766  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:00:32 d2.utils.events]: \u001b[0m eta: 3:15:03  iter: 42599  total_loss: 1.159  loss_cls: 0.3112  loss_box_reg: 0.4369  loss_mask: 0.252  loss_rpn_cls: 0.05069  loss_rpn_loc: 0.1456  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:00:36 d2.utils.events]: \u001b[0m eta: 3:14:53  iter: 42619  total_loss: 1.123  loss_cls: 0.2527  loss_box_reg: 0.3571  loss_mask: 0.244  loss_rpn_cls: 0.05966  loss_rpn_loc: 0.1685  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:00:41 d2.utils.events]: \u001b[0m eta: 3:14:27  iter: 42639  total_loss: 1.275  loss_cls: 0.3304  loss_box_reg: 0.4151  loss_mask: 0.2727  loss_rpn_cls: 0.06712  loss_rpn_loc: 0.1666  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:00:45 d2.utils.events]: \u001b[0m eta: 3:14:20  iter: 42659  total_loss: 1.162  loss_cls: 0.2956  loss_box_reg: 0.3819  loss_mask: 0.2476  loss_rpn_cls: 0.09348  loss_rpn_loc: 0.1746  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:00:49 d2.utils.events]: \u001b[0m eta: 3:14:10  iter: 42679  total_loss: 1.131  loss_cls: 0.2611  loss_box_reg: 0.3688  loss_mask: 0.2683  loss_rpn_cls: 0.06702  loss_rpn_loc: 0.17  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:00:54 d2.utils.events]: \u001b[0m eta: 3:14:19  iter: 42699  total_loss: 1.236  loss_cls: 0.2947  loss_box_reg: 0.3876  loss_mask: 0.2591  loss_rpn_cls: 0.07997  loss_rpn_loc: 0.1761  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:00:59 d2.utils.events]: \u001b[0m eta: 3:14:24  iter: 42719  total_loss: 1.087  loss_cls: 0.2735  loss_box_reg: 0.3497  loss_mask: 0.2493  loss_rpn_cls: 0.07392  loss_rpn_loc: 0.1565  time: 0.2238  data_time: 0.0362  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:01:03 d2.utils.events]: \u001b[0m eta: 3:14:30  iter: 42739  total_loss: 1.118  loss_cls: 0.2821  loss_box_reg: 0.3692  loss_mask: 0.2548  loss_rpn_cls: 0.07282  loss_rpn_loc: 0.1675  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:01:07 d2.utils.events]: \u001b[0m eta: 3:14:06  iter: 42759  total_loss: 1.199  loss_cls: 0.2796  loss_box_reg: 0.3681  loss_mask: 0.2641  loss_rpn_cls: 0.08788  loss_rpn_loc: 0.1774  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:01:12 d2.utils.events]: \u001b[0m eta: 3:13:50  iter: 42779  total_loss: 1.158  loss_cls: 0.3126  loss_box_reg: 0.3784  loss_mask: 0.2597  loss_rpn_cls: 0.06223  loss_rpn_loc: 0.1465  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:01:16 d2.utils.events]: \u001b[0m eta: 3:13:45  iter: 42799  total_loss: 1.166  loss_cls: 0.2983  loss_box_reg: 0.3676  loss_mask: 0.2632  loss_rpn_cls: 0.06253  loss_rpn_loc: 0.1581  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:01:21 d2.utils.events]: \u001b[0m eta: 3:13:45  iter: 42819  total_loss: 1.194  loss_cls: 0.294  loss_box_reg: 0.3917  loss_mask: 0.2801  loss_rpn_cls: 0.08182  loss_rpn_loc: 0.1797  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:01:25 d2.utils.events]: \u001b[0m eta: 3:13:50  iter: 42839  total_loss: 1.148  loss_cls: 0.244  loss_box_reg: 0.3385  loss_mask: 0.2594  loss_rpn_cls: 0.0701  loss_rpn_loc: 0.1703  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:01:30 d2.utils.events]: \u001b[0m eta: 3:13:39  iter: 42859  total_loss: 1.122  loss_cls: 0.2661  loss_box_reg: 0.3584  loss_mask: 0.2526  loss_rpn_cls: 0.09336  loss_rpn_loc: 0.1657  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:01:34 d2.utils.events]: \u001b[0m eta: 3:13:35  iter: 42879  total_loss: 1.199  loss_cls: 0.3127  loss_box_reg: 0.3957  loss_mask: 0.2632  loss_rpn_cls: 0.08724  loss_rpn_loc: 0.1594  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:01:39 d2.utils.events]: \u001b[0m eta: 3:13:30  iter: 42899  total_loss: 1.154  loss_cls: 0.3048  loss_box_reg: 0.4093  loss_mask: 0.2447  loss_rpn_cls: 0.07265  loss_rpn_loc: 0.1555  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:01:43 d2.utils.events]: \u001b[0m eta: 3:13:18  iter: 42919  total_loss: 1.27  loss_cls: 0.3112  loss_box_reg: 0.4308  loss_mask: 0.2527  loss_rpn_cls: 0.07247  loss_rpn_loc: 0.1425  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:01:48 d2.utils.events]: \u001b[0m eta: 3:13:19  iter: 42939  total_loss: 1.208  loss_cls: 0.2991  loss_box_reg: 0.3755  loss_mask: 0.2703  loss_rpn_cls: 0.09539  loss_rpn_loc: 0.1799  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:01:52 d2.utils.events]: \u001b[0m eta: 3:13:19  iter: 42959  total_loss: 1.27  loss_cls: 0.325  loss_box_reg: 0.3623  loss_mask: 0.2881  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.1914  time: 0.2238  data_time: 0.0182  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:01:57 d2.utils.events]: \u001b[0m eta: 3:13:38  iter: 42979  total_loss: 1.203  loss_cls: 0.3005  loss_box_reg: 0.3826  loss_mask: 0.2645  loss_rpn_cls: 0.09655  loss_rpn_loc: 0.1737  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:02:01 d2.utils.events]: \u001b[0m eta: 3:13:43  iter: 42999  total_loss: 1.206  loss_cls: 0.307  loss_box_reg: 0.38  loss_mask: 0.2795  loss_rpn_cls: 0.06774  loss_rpn_loc: 0.1749  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:02:06 d2.utils.events]: \u001b[0m eta: 3:13:29  iter: 43019  total_loss: 1.124  loss_cls: 0.272  loss_box_reg: 0.3553  loss_mask: 0.259  loss_rpn_cls: 0.05793  loss_rpn_loc: 0.155  time: 0.2238  data_time: 0.0128  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:02:10 d2.utils.events]: \u001b[0m eta: 3:13:18  iter: 43039  total_loss: 1.294  loss_cls: 0.3242  loss_box_reg: 0.4168  loss_mask: 0.2748  loss_rpn_cls: 0.07785  loss_rpn_loc: 0.1695  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:02:15 d2.utils.events]: \u001b[0m eta: 3:12:53  iter: 43059  total_loss: 1.12  loss_cls: 0.2755  loss_box_reg: 0.3596  loss_mask: 0.2459  loss_rpn_cls: 0.06182  loss_rpn_loc: 0.1561  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:02:19 d2.utils.events]: \u001b[0m eta: 3:12:51  iter: 43079  total_loss: 1.252  loss_cls: 0.3468  loss_box_reg: 0.4251  loss_mask: 0.2807  loss_rpn_cls: 0.06201  loss_rpn_loc: 0.1564  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:02:24 d2.utils.events]: \u001b[0m eta: 3:12:55  iter: 43099  total_loss: 1.227  loss_cls: 0.3186  loss_box_reg: 0.3945  loss_mask: 0.2673  loss_rpn_cls: 0.05944  loss_rpn_loc: 0.1598  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:02:28 d2.utils.events]: \u001b[0m eta: 3:12:43  iter: 43119  total_loss: 1.167  loss_cls: 0.3038  loss_box_reg: 0.3937  loss_mask: 0.2546  loss_rpn_cls: 0.06619  loss_rpn_loc: 0.1545  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:02:32 d2.utils.events]: \u001b[0m eta: 3:12:35  iter: 43139  total_loss: 1.128  loss_cls: 0.3195  loss_box_reg: 0.3605  loss_mask: 0.2413  loss_rpn_cls: 0.07108  loss_rpn_loc: 0.1572  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:02:37 d2.utils.events]: \u001b[0m eta: 3:12:26  iter: 43159  total_loss: 1.293  loss_cls: 0.2991  loss_box_reg: 0.4433  loss_mask: 0.2836  loss_rpn_cls: 0.08777  loss_rpn_loc: 0.1782  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:02:41 d2.utils.events]: \u001b[0m eta: 3:12:24  iter: 43179  total_loss: 1.157  loss_cls: 0.2714  loss_box_reg: 0.3398  loss_mask: 0.2514  loss_rpn_cls: 0.07298  loss_rpn_loc: 0.1538  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:02:46 d2.utils.events]: \u001b[0m eta: 3:12:22  iter: 43199  total_loss: 1.22  loss_cls: 0.3078  loss_box_reg: 0.3721  loss_mask: 0.2733  loss_rpn_cls: 0.08271  loss_rpn_loc: 0.1823  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:02:50 d2.utils.events]: \u001b[0m eta: 3:12:37  iter: 43219  total_loss: 1.183  loss_cls: 0.3335  loss_box_reg: 0.3891  loss_mask: 0.2598  loss_rpn_cls: 0.06771  loss_rpn_loc: 0.1549  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:02:55 d2.utils.events]: \u001b[0m eta: 3:12:41  iter: 43239  total_loss: 1.244  loss_cls: 0.3108  loss_box_reg: 0.3862  loss_mask: 0.2492  loss_rpn_cls: 0.1005  loss_rpn_loc: 0.1937  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:02:59 d2.utils.events]: \u001b[0m eta: 3:12:33  iter: 43259  total_loss: 1.188  loss_cls: 0.2867  loss_box_reg: 0.3609  loss_mask: 0.2571  loss_rpn_cls: 0.07771  loss_rpn_loc: 0.1751  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:03:04 d2.utils.events]: \u001b[0m eta: 3:12:48  iter: 43279  total_loss: 1.22  loss_cls: 0.276  loss_box_reg: 0.3726  loss_mask: 0.2828  loss_rpn_cls: 0.08661  loss_rpn_loc: 0.1619  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:03:08 d2.utils.events]: \u001b[0m eta: 3:12:49  iter: 43299  total_loss: 1.042  loss_cls: 0.2477  loss_box_reg: 0.3275  loss_mask: 0.2634  loss_rpn_cls: 0.0797  loss_rpn_loc: 0.1699  time: 0.2238  data_time: 0.0201  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:03:13 d2.utils.events]: \u001b[0m eta: 3:12:55  iter: 43319  total_loss: 1.225  loss_cls: 0.3044  loss_box_reg: 0.3955  loss_mask: 0.265  loss_rpn_cls: 0.09113  loss_rpn_loc: 0.1742  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:03:18 d2.utils.events]: \u001b[0m eta: 3:12:56  iter: 43339  total_loss: 1.167  loss_cls: 0.2975  loss_box_reg: 0.3739  loss_mask: 0.2568  loss_rpn_cls: 0.07703  loss_rpn_loc: 0.1705  time: 0.2238  data_time: 0.0241  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:03:24 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.91 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 00:03:24 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 00:03:24 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 00:03:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 00:03:24 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 00:03:25 d2.data.common]: \u001b[0mSerialized dataset takes 84.20 MiB\n",
      "\u001b[32m[12/30 00:03:28 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.88 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 00:03:28 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 00:03:28 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 00:03:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/30 00:03:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0007 s/iter. Inference: 0.0611 s/iter. Eval: 0.1432 s/iter. Total: 0.2051 s/iter. ETA=0:01:54\n",
      "\u001b[32m[12/30 00:03:36 d2.evaluation.evaluator]: \u001b[0mInference done 39/570. Dataloading: 0.0009 s/iter. Inference: 0.0569 s/iter. Eval: 0.1266 s/iter. Total: 0.1844 s/iter. ETA=0:01:37\n",
      "\u001b[32m[12/30 00:03:41 d2.evaluation.evaluator]: \u001b[0mInference done 67/570. Dataloading: 0.0009 s/iter. Inference: 0.0544 s/iter. Eval: 0.1268 s/iter. Total: 0.1821 s/iter. ETA=0:01:31\n",
      "\u001b[32m[12/30 00:03:46 d2.evaluation.evaluator]: \u001b[0mInference done 93/570. Dataloading: 0.0009 s/iter. Inference: 0.0539 s/iter. Eval: 0.1310 s/iter. Total: 0.1858 s/iter. ETA=0:01:28\n",
      "\u001b[32m[12/30 00:03:51 d2.evaluation.evaluator]: \u001b[0mInference done 119/570. Dataloading: 0.0042 s/iter. Inference: 0.0536 s/iter. Eval: 0.1313 s/iter. Total: 0.1892 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/30 00:03:56 d2.evaluation.evaluator]: \u001b[0mInference done 141/570. Dataloading: 0.0076 s/iter. Inference: 0.0537 s/iter. Eval: 0.1347 s/iter. Total: 0.1960 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/30 00:04:01 d2.evaluation.evaluator]: \u001b[0mInference done 161/570. Dataloading: 0.0067 s/iter. Inference: 0.0539 s/iter. Eval: 0.1429 s/iter. Total: 0.2037 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 00:04:06 d2.evaluation.evaluator]: \u001b[0mInference done 174/570. Dataloading: 0.0063 s/iter. Inference: 0.0546 s/iter. Eval: 0.1570 s/iter. Total: 0.2179 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/30 00:04:11 d2.evaluation.evaluator]: \u001b[0mInference done 191/570. Dataloading: 0.0058 s/iter. Inference: 0.0548 s/iter. Eval: 0.1654 s/iter. Total: 0.2261 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/30 00:04:16 d2.evaluation.evaluator]: \u001b[0mInference done 207/570. Dataloading: 0.0054 s/iter. Inference: 0.0551 s/iter. Eval: 0.1725 s/iter. Total: 0.2331 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/30 00:04:21 d2.evaluation.evaluator]: \u001b[0mInference done 224/570. Dataloading: 0.0051 s/iter. Inference: 0.0555 s/iter. Eval: 0.1776 s/iter. Total: 0.2382 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 00:04:27 d2.evaluation.evaluator]: \u001b[0mInference done 233/570. Dataloading: 0.0049 s/iter. Inference: 0.0557 s/iter. Eval: 0.1938 s/iter. Total: 0.2545 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/30 00:04:33 d2.evaluation.evaluator]: \u001b[0mInference done 248/570. Dataloading: 0.0047 s/iter. Inference: 0.0557 s/iter. Eval: 0.1996 s/iter. Total: 0.2601 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 00:04:38 d2.evaluation.evaluator]: \u001b[0mInference done 261/570. Dataloading: 0.0045 s/iter. Inference: 0.0558 s/iter. Eval: 0.2062 s/iter. Total: 0.2666 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 00:04:43 d2.evaluation.evaluator]: \u001b[0mInference done 277/570. Dataloading: 0.0043 s/iter. Inference: 0.0561 s/iter. Eval: 0.2093 s/iter. Total: 0.2697 s/iter. ETA=0:01:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:04:48 d2.evaluation.evaluator]: \u001b[0mInference done 294/570. Dataloading: 0.0041 s/iter. Inference: 0.0562 s/iter. Eval: 0.2120 s/iter. Total: 0.2724 s/iter. ETA=0:01:15\n",
      "\u001b[32m[12/30 00:04:53 d2.evaluation.evaluator]: \u001b[0mInference done 332/570. Dataloading: 0.0037 s/iter. Inference: 0.0555 s/iter. Eval: 0.1970 s/iter. Total: 0.2562 s/iter. ETA=0:01:00\n",
      "\u001b[32m[12/30 00:04:58 d2.evaluation.evaluator]: \u001b[0mInference done 370/570. Dataloading: 0.0034 s/iter. Inference: 0.0547 s/iter. Eval: 0.1851 s/iter. Total: 0.2433 s/iter. ETA=0:00:48\n",
      "\u001b[32m[12/30 00:05:03 d2.evaluation.evaluator]: \u001b[0mInference done 391/570. Dataloading: 0.0033 s/iter. Inference: 0.0552 s/iter. Eval: 0.1851 s/iter. Total: 0.2436 s/iter. ETA=0:00:43\n",
      "\u001b[32m[12/30 00:05:09 d2.evaluation.evaluator]: \u001b[0mInference done 411/570. Dataloading: 0.0031 s/iter. Inference: 0.0553 s/iter. Eval: 0.1859 s/iter. Total: 0.2444 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/30 00:05:14 d2.evaluation.evaluator]: \u001b[0mInference done 430/570. Dataloading: 0.0030 s/iter. Inference: 0.0556 s/iter. Eval: 0.1871 s/iter. Total: 0.2458 s/iter. ETA=0:00:34\n",
      "\u001b[32m[12/30 00:05:19 d2.evaluation.evaluator]: \u001b[0mInference done 453/570. Dataloading: 0.0029 s/iter. Inference: 0.0557 s/iter. Eval: 0.1858 s/iter. Total: 0.2445 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/30 00:05:24 d2.evaluation.evaluator]: \u001b[0mInference done 490/570. Dataloading: 0.0028 s/iter. Inference: 0.0552 s/iter. Eval: 0.1782 s/iter. Total: 0.2363 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/30 00:05:29 d2.evaluation.evaluator]: \u001b[0mInference done 511/570. Dataloading: 0.0027 s/iter. Inference: 0.0552 s/iter. Eval: 0.1786 s/iter. Total: 0.2365 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/30 00:05:34 d2.evaluation.evaluator]: \u001b[0mInference done 534/570. Dataloading: 0.0026 s/iter. Inference: 0.0552 s/iter. Eval: 0.1780 s/iter. Total: 0.2358 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/30 00:05:39 d2.evaluation.evaluator]: \u001b[0mInference done 552/570. Dataloading: 0.0026 s/iter. Inference: 0.0554 s/iter. Eval: 0.1795 s/iter. Total: 0.2375 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/30 00:05:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:14.384455 (0.237849 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 00:05:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.055489 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 00:05:44 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/30 00:05:44 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.27978004483314245\n",
      "\u001b[32m[12/30 00:05:45 d2.utils.events]: \u001b[0m eta: 3:12:21  iter: 43359  total_loss: 1.21  loss_cls: 0.279  loss_box_reg: 0.4049  loss_mask: 0.2467  loss_rpn_cls: 0.05354  loss_rpn_loc: 0.1487  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:05:50 d2.utils.events]: \u001b[0m eta: 3:12:17  iter: 43379  total_loss: 1.249  loss_cls: 0.3252  loss_box_reg: 0.3774  loss_mask: 0.2583  loss_rpn_cls: 0.08805  loss_rpn_loc: 0.1598  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:05:54 d2.utils.events]: \u001b[0m eta: 3:12:28  iter: 43399  total_loss: 1.246  loss_cls: 0.3233  loss_box_reg: 0.3901  loss_mask: 0.2797  loss_rpn_cls: 0.08997  loss_rpn_loc: 0.1588  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:05:59 d2.utils.events]: \u001b[0m eta: 3:12:33  iter: 43419  total_loss: 1.149  loss_cls: 0.2575  loss_box_reg: 0.373  loss_mask: 0.2591  loss_rpn_cls: 0.06864  loss_rpn_loc: 0.163  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:06:03 d2.utils.events]: \u001b[0m eta: 3:12:23  iter: 43439  total_loss: 1.336  loss_cls: 0.3158  loss_box_reg: 0.3948  loss_mask: 0.2813  loss_rpn_cls: 0.08064  loss_rpn_loc: 0.1713  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:06:07 d2.utils.events]: \u001b[0m eta: 3:12:22  iter: 43459  total_loss: 1.172  loss_cls: 0.2797  loss_box_reg: 0.3959  loss_mask: 0.2555  loss_rpn_cls: 0.06533  loss_rpn_loc: 0.1445  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:06:12 d2.utils.events]: \u001b[0m eta: 3:12:26  iter: 43479  total_loss: 1.261  loss_cls: 0.327  loss_box_reg: 0.37  loss_mask: 0.2882  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.1783  time: 0.2238  data_time: 0.0107  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:06:16 d2.utils.events]: \u001b[0m eta: 3:12:06  iter: 43499  total_loss: 1.295  loss_cls: 0.3253  loss_box_reg: 0.4023  loss_mask: 0.2736  loss_rpn_cls: 0.06359  loss_rpn_loc: 0.1544  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:06:21 d2.utils.events]: \u001b[0m eta: 3:11:59  iter: 43519  total_loss: 1.204  loss_cls: 0.3009  loss_box_reg: 0.3793  loss_mask: 0.275  loss_rpn_cls: 0.0887  loss_rpn_loc: 0.1762  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:06:25 d2.utils.events]: \u001b[0m eta: 3:11:49  iter: 43539  total_loss: 1.286  loss_cls: 0.331  loss_box_reg: 0.4184  loss_mask: 0.2749  loss_rpn_cls: 0.06477  loss_rpn_loc: 0.1673  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:06:30 d2.utils.events]: \u001b[0m eta: 3:11:38  iter: 43559  total_loss: 1.06  loss_cls: 0.2709  loss_box_reg: 0.3715  loss_mask: 0.2556  loss_rpn_cls: 0.06161  loss_rpn_loc: 0.1538  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:06:34 d2.utils.events]: \u001b[0m eta: 3:11:21  iter: 43579  total_loss: 1.198  loss_cls: 0.3006  loss_box_reg: 0.3662  loss_mask: 0.2645  loss_rpn_cls: 0.05157  loss_rpn_loc: 0.1668  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:06:39 d2.utils.events]: \u001b[0m eta: 3:11:19  iter: 43599  total_loss: 1.334  loss_cls: 0.3228  loss_box_reg: 0.371  loss_mask: 0.2624  loss_rpn_cls: 0.07169  loss_rpn_loc: 0.1863  time: 0.2238  data_time: 0.0196  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:06:44 d2.utils.events]: \u001b[0m eta: 3:11:16  iter: 43619  total_loss: 1.079  loss_cls: 0.2683  loss_box_reg: 0.3153  loss_mask: 0.2471  loss_rpn_cls: 0.0613  loss_rpn_loc: 0.1509  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:06:48 d2.utils.events]: \u001b[0m eta: 3:11:24  iter: 43639  total_loss: 1.261  loss_cls: 0.3279  loss_box_reg: 0.3624  loss_mask: 0.2805  loss_rpn_cls: 0.08776  loss_rpn_loc: 0.1766  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:06:52 d2.utils.events]: \u001b[0m eta: 3:11:06  iter: 43659  total_loss: 1.113  loss_cls: 0.2881  loss_box_reg: 0.3646  loss_mask: 0.2572  loss_rpn_cls: 0.06715  loss_rpn_loc: 0.1609  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:06:57 d2.utils.events]: \u001b[0m eta: 3:11:18  iter: 43679  total_loss: 1.167  loss_cls: 0.3268  loss_box_reg: 0.3944  loss_mask: 0.2605  loss_rpn_cls: 0.05646  loss_rpn_loc: 0.1658  time: 0.2238  data_time: 0.0184  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:07:01 d2.utils.events]: \u001b[0m eta: 3:10:55  iter: 43699  total_loss: 1.128  loss_cls: 0.26  loss_box_reg: 0.3598  loss_mask: 0.2511  loss_rpn_cls: 0.05649  loss_rpn_loc: 0.159  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:07:06 d2.utils.events]: \u001b[0m eta: 3:11:06  iter: 43719  total_loss: 1.246  loss_cls: 0.3075  loss_box_reg: 0.3727  loss_mask: 0.2685  loss_rpn_cls: 0.09613  loss_rpn_loc: 0.1657  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:07:11 d2.utils.events]: \u001b[0m eta: 3:11:17  iter: 43739  total_loss: 1.216  loss_cls: 0.2847  loss_box_reg: 0.3522  loss_mask: 0.2582  loss_rpn_cls: 0.09811  loss_rpn_loc: 0.1692  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:07:15 d2.utils.events]: \u001b[0m eta: 3:11:52  iter: 43759  total_loss: 1.178  loss_cls: 0.276  loss_box_reg: 0.3717  loss_mask: 0.261  loss_rpn_cls: 0.07623  loss_rpn_loc: 0.1605  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:07:20 d2.utils.events]: \u001b[0m eta: 3:11:48  iter: 43779  total_loss: 1.077  loss_cls: 0.2807  loss_box_reg: 0.3365  loss_mask: 0.2459  loss_rpn_cls: 0.0669  loss_rpn_loc: 0.1427  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:07:24 d2.utils.events]: \u001b[0m eta: 3:11:52  iter: 43799  total_loss: 1.218  loss_cls: 0.3206  loss_box_reg: 0.3965  loss_mask: 0.2685  loss_rpn_cls: 0.07406  loss_rpn_loc: 0.1699  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:07:28 d2.utils.events]: \u001b[0m eta: 3:11:36  iter: 43819  total_loss: 1.099  loss_cls: 0.2756  loss_box_reg: 0.3788  loss_mask: 0.2516  loss_rpn_cls: 0.05182  loss_rpn_loc: 0.1515  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:07:33 d2.utils.events]: \u001b[0m eta: 3:11:15  iter: 43839  total_loss: 1.147  loss_cls: 0.2774  loss_box_reg: 0.3868  loss_mask: 0.2479  loss_rpn_cls: 0.06109  loss_rpn_loc: 0.1557  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:07:37 d2.utils.events]: \u001b[0m eta: 3:11:07  iter: 43859  total_loss: 1.243  loss_cls: 0.3136  loss_box_reg: 0.3753  loss_mask: 0.2605  loss_rpn_cls: 0.0644  loss_rpn_loc: 0.163  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:07:41 d2.utils.events]: \u001b[0m eta: 3:11:11  iter: 43879  total_loss: 1.103  loss_cls: 0.273  loss_box_reg: 0.3698  loss_mask: 0.2431  loss_rpn_cls: 0.06766  loss_rpn_loc: 0.1708  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:07:46 d2.utils.events]: \u001b[0m eta: 3:11:30  iter: 43899  total_loss: 1.16  loss_cls: 0.2451  loss_box_reg: 0.3088  loss_mask: 0.2555  loss_rpn_cls: 0.06571  loss_rpn_loc: 0.1581  time: 0.2238  data_time: 0.0244  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:07:51 d2.utils.events]: \u001b[0m eta: 3:11:40  iter: 43919  total_loss: 1.148  loss_cls: 0.2793  loss_box_reg: 0.3865  loss_mask: 0.2732  loss_rpn_cls: 0.07748  loss_rpn_loc: 0.1558  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:07:55 d2.utils.events]: \u001b[0m eta: 3:11:36  iter: 43939  total_loss: 1.223  loss_cls: 0.2844  loss_box_reg: 0.3994  loss_mask: 0.2633  loss_rpn_cls: 0.07437  loss_rpn_loc: 0.1693  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:08:00 d2.utils.events]: \u001b[0m eta: 3:11:31  iter: 43959  total_loss: 1.303  loss_cls: 0.3489  loss_box_reg: 0.4182  loss_mask: 0.2709  loss_rpn_cls: 0.08343  loss_rpn_loc: 0.1587  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:08:04 d2.utils.events]: \u001b[0m eta: 3:11:22  iter: 43979  total_loss: 1.212  loss_cls: 0.3122  loss_box_reg: 0.4031  loss_mask: 0.2538  loss_rpn_cls: 0.08217  loss_rpn_loc: 0.154  time: 0.2238  data_time: 0.0146  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:08:09 d2.utils.events]: \u001b[0m eta: 3:11:13  iter: 43999  total_loss: 1.221  loss_cls: 0.3032  loss_box_reg: 0.4008  loss_mask: 0.2729  loss_rpn_cls: 0.07211  loss_rpn_loc: 0.1767  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:08:13 d2.utils.events]: \u001b[0m eta: 3:10:48  iter: 44019  total_loss: 1.205  loss_cls: 0.2784  loss_box_reg: 0.3769  loss_mask: 0.2662  loss_rpn_cls: 0.1067  loss_rpn_loc: 0.164  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:08:18 d2.utils.events]: \u001b[0m eta: 3:11:04  iter: 44039  total_loss: 1.341  loss_cls: 0.3184  loss_box_reg: 0.418  loss_mask: 0.2871  loss_rpn_cls: 0.09201  loss_rpn_loc: 0.1707  time: 0.2238  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:08:22 d2.utils.events]: \u001b[0m eta: 3:11:14  iter: 44059  total_loss: 1.274  loss_cls: 0.3372  loss_box_reg: 0.421  loss_mask: 0.2733  loss_rpn_cls: 0.09226  loss_rpn_loc: 0.1798  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:08:27 d2.utils.events]: \u001b[0m eta: 3:11:01  iter: 44079  total_loss: 1.218  loss_cls: 0.3001  loss_box_reg: 0.3982  loss_mask: 0.2708  loss_rpn_cls: 0.06398  loss_rpn_loc: 0.1666  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:08:31 d2.utils.events]: \u001b[0m eta: 3:11:01  iter: 44099  total_loss: 1.129  loss_cls: 0.2924  loss_box_reg: 0.3685  loss_mask: 0.2507  loss_rpn_cls: 0.06066  loss_rpn_loc: 0.164  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:08:36 d2.utils.events]: \u001b[0m eta: 3:11:05  iter: 44119  total_loss: 1.14  loss_cls: 0.2961  loss_box_reg: 0.3788  loss_mask: 0.2654  loss_rpn_cls: 0.07686  loss_rpn_loc: 0.1627  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:08:40 d2.utils.events]: \u001b[0m eta: 3:10:47  iter: 44139  total_loss: 1.075  loss_cls: 0.2588  loss_box_reg: 0.3751  loss_mask: 0.2423  loss_rpn_cls: 0.04226  loss_rpn_loc: 0.1439  time: 0.2238  data_time: 0.0057  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:08:44 d2.utils.events]: \u001b[0m eta: 3:10:53  iter: 44159  total_loss: 1.075  loss_cls: 0.2378  loss_box_reg: 0.3298  loss_mask: 0.2531  loss_rpn_cls: 0.06424  loss_rpn_loc: 0.1739  time: 0.2238  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:08:49 d2.utils.events]: \u001b[0m eta: 3:10:49  iter: 44179  total_loss: 1.254  loss_cls: 0.3068  loss_box_reg: 0.3869  loss_mask: 0.2874  loss_rpn_cls: 0.07536  loss_rpn_loc: 0.1903  time: 0.2238  data_time: 0.0099  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:08:53 d2.utils.events]: \u001b[0m eta: 3:10:44  iter: 44199  total_loss: 1.163  loss_cls: 0.2946  loss_box_reg: 0.3903  loss_mask: 0.2579  loss_rpn_cls: 0.05534  loss_rpn_loc: 0.1561  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:08:58 d2.utils.events]: \u001b[0m eta: 3:10:44  iter: 44219  total_loss: 1.163  loss_cls: 0.2822  loss_box_reg: 0.3612  loss_mask: 0.26  loss_rpn_cls: 0.1058  loss_rpn_loc: 0.1814  time: 0.2238  data_time: 0.0153  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:09:03 d2.utils.events]: \u001b[0m eta: 3:10:36  iter: 44239  total_loss: 1.227  loss_cls: 0.2853  loss_box_reg: 0.418  loss_mask: 0.2713  loss_rpn_cls: 0.06263  loss_rpn_loc: 0.1558  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:09:07 d2.utils.events]: \u001b[0m eta: 3:10:31  iter: 44259  total_loss: 1.354  loss_cls: 0.3381  loss_box_reg: 0.4136  loss_mask: 0.28  loss_rpn_cls: 0.1089  loss_rpn_loc: 0.1732  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:09:11 d2.utils.events]: \u001b[0m eta: 3:10:27  iter: 44279  total_loss: 1.192  loss_cls: 0.2849  loss_box_reg: 0.4153  loss_mask: 0.2646  loss_rpn_cls: 0.06571  loss_rpn_loc: 0.1476  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:09:16 d2.utils.events]: \u001b[0m eta: 3:10:12  iter: 44299  total_loss: 1.229  loss_cls: 0.2861  loss_box_reg: 0.4163  loss_mask: 0.2721  loss_rpn_cls: 0.07608  loss_rpn_loc: 0.1965  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:09:21 d2.utils.events]: \u001b[0m eta: 3:10:06  iter: 44319  total_loss: 1.043  loss_cls: 0.2565  loss_box_reg: 0.3583  loss_mask: 0.2656  loss_rpn_cls: 0.04527  loss_rpn_loc: 0.1508  time: 0.2238  data_time: 0.0217  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:09:25 d2.utils.events]: \u001b[0m eta: 3:09:39  iter: 44339  total_loss: 1.291  loss_cls: 0.3375  loss_box_reg: 0.4354  loss_mask: 0.2673  loss_rpn_cls: 0.08206  loss_rpn_loc: 0.1602  time: 0.2238  data_time: 0.0058  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:09:29 d2.utils.events]: \u001b[0m eta: 3:09:56  iter: 44359  total_loss: 1.196  loss_cls: 0.2953  loss_box_reg: 0.3581  loss_mask: 0.2756  loss_rpn_cls: 0.0819  loss_rpn_loc: 0.1744  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:09:34 d2.utils.events]: \u001b[0m eta: 3:10:04  iter: 44379  total_loss: 1.202  loss_cls: 0.2819  loss_box_reg: 0.3516  loss_mask: 0.2664  loss_rpn_cls: 0.09544  loss_rpn_loc: 0.1726  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:09:38 d2.utils.events]: \u001b[0m eta: 3:09:49  iter: 44399  total_loss: 1.225  loss_cls: 0.3077  loss_box_reg: 0.4281  loss_mask: 0.2575  loss_rpn_cls: 0.07567  loss_rpn_loc: 0.1564  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:09:43 d2.utils.events]: \u001b[0m eta: 3:09:17  iter: 44419  total_loss: 1.23  loss_cls: 0.3021  loss_box_reg: 0.4164  loss_mask: 0.2468  loss_rpn_cls: 0.06625  loss_rpn_loc: 0.1636  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:09:47 d2.utils.events]: \u001b[0m eta: 3:09:27  iter: 44439  total_loss: 1.123  loss_cls: 0.2643  loss_box_reg: 0.3376  loss_mask: 0.253  loss_rpn_cls: 0.0874  loss_rpn_loc: 0.1784  time: 0.2238  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:09:52 d2.utils.events]: \u001b[0m eta: 3:09:42  iter: 44459  total_loss: 1.186  loss_cls: 0.2985  loss_box_reg: 0.3869  loss_mask: 0.2578  loss_rpn_cls: 0.09388  loss_rpn_loc: 0.1522  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:09:56 d2.utils.events]: \u001b[0m eta: 3:09:13  iter: 44479  total_loss: 1.215  loss_cls: 0.31  loss_box_reg: 0.4219  loss_mask: 0.2537  loss_rpn_cls: 0.06759  loss_rpn_loc: 0.1647  time: 0.2238  data_time: 0.0057  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:10:00 d2.utils.events]: \u001b[0m eta: 3:09:26  iter: 44499  total_loss: 1.304  loss_cls: 0.3042  loss_box_reg: 0.3933  loss_mask: 0.2808  loss_rpn_cls: 0.07859  loss_rpn_loc: 0.1659  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:10:05 d2.utils.events]: \u001b[0m eta: 3:09:22  iter: 44519  total_loss: 1.18  loss_cls: 0.2895  loss_box_reg: 0.3784  loss_mask: 0.2655  loss_rpn_cls: 0.07081  loss_rpn_loc: 0.1533  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:10:09 d2.utils.events]: \u001b[0m eta: 3:09:04  iter: 44539  total_loss: 1.317  loss_cls: 0.3072  loss_box_reg: 0.404  loss_mask: 0.2684  loss_rpn_cls: 0.0759  loss_rpn_loc: 0.1716  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:10:13 d2.utils.events]: \u001b[0m eta: 3:09:04  iter: 44559  total_loss: 1.086  loss_cls: 0.2554  loss_box_reg: 0.3527  loss_mask: 0.2407  loss_rpn_cls: 0.05771  loss_rpn_loc: 0.1514  time: 0.2238  data_time: 0.0138  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:10:18 d2.utils.events]: \u001b[0m eta: 3:08:56  iter: 44579  total_loss: 1.181  loss_cls: 0.3092  loss_box_reg: 0.3952  loss_mask: 0.2731  loss_rpn_cls: 0.06408  loss_rpn_loc: 0.1728  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:10:22 d2.utils.events]: \u001b[0m eta: 3:08:55  iter: 44599  total_loss: 1.119  loss_cls: 0.2617  loss_box_reg: 0.3366  loss_mask: 0.2429  loss_rpn_cls: 0.07635  loss_rpn_loc: 0.1439  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:10:27 d2.utils.events]: \u001b[0m eta: 3:08:47  iter: 44619  total_loss: 1.193  loss_cls: 0.2753  loss_box_reg: 0.3795  loss_mask: 0.2679  loss_rpn_cls: 0.07899  loss_rpn_loc: 0.1762  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:10:31 d2.utils.events]: \u001b[0m eta: 3:08:42  iter: 44639  total_loss: 1.22  loss_cls: 0.3211  loss_box_reg: 0.3757  loss_mask: 0.2539  loss_rpn_cls: 0.0803  loss_rpn_loc: 0.1626  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:10:36 d2.utils.events]: \u001b[0m eta: 3:08:46  iter: 44659  total_loss: 1.23  loss_cls: 0.3241  loss_box_reg: 0.3757  loss_mask: 0.2483  loss_rpn_cls: 0.07838  loss_rpn_loc: 0.1638  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:10:40 d2.utils.events]: \u001b[0m eta: 3:08:25  iter: 44679  total_loss: 1.176  loss_cls: 0.2741  loss_box_reg: 0.4124  loss_mask: 0.2527  loss_rpn_cls: 0.06326  loss_rpn_loc: 0.1613  time: 0.2238  data_time: 0.0158  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:10:44 d2.utils.events]: \u001b[0m eta: 3:08:19  iter: 44699  total_loss: 1.193  loss_cls: 0.2748  loss_box_reg: 0.3827  loss_mask: 0.2512  loss_rpn_cls: 0.07237  loss_rpn_loc: 0.153  time: 0.2238  data_time: 0.0095  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:10:49 d2.utils.events]: \u001b[0m eta: 3:08:02  iter: 44719  total_loss: 1.201  loss_cls: 0.3001  loss_box_reg: 0.3933  loss_mask: 0.2517  loss_rpn_cls: 0.05634  loss_rpn_loc: 0.1621  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:10:53 d2.utils.events]: \u001b[0m eta: 3:07:41  iter: 44739  total_loss: 1.202  loss_cls: 0.3217  loss_box_reg: 0.3866  loss_mask: 0.272  loss_rpn_cls: 0.09065  loss_rpn_loc: 0.1637  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:10:58 d2.utils.events]: \u001b[0m eta: 3:07:49  iter: 44759  total_loss: 1.107  loss_cls: 0.2778  loss_box_reg: 0.3536  loss_mask: 0.2599  loss_rpn_cls: 0.07696  loss_rpn_loc: 0.161  time: 0.2238  data_time: 0.0094  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:11:03 d2.utils.events]: \u001b[0m eta: 3:07:26  iter: 44779  total_loss: 1.158  loss_cls: 0.2837  loss_box_reg: 0.364  loss_mask: 0.2451  loss_rpn_cls: 0.06075  loss_rpn_loc: 0.1579  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:11:07 d2.utils.events]: \u001b[0m eta: 3:07:16  iter: 44799  total_loss: 1.233  loss_cls: 0.2823  loss_box_reg: 0.383  loss_mask: 0.2725  loss_rpn_cls: 0.09095  loss_rpn_loc: 0.1775  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:11:12 d2.utils.events]: \u001b[0m eta: 3:07:24  iter: 44819  total_loss: 1.133  loss_cls: 0.2651  loss_box_reg: 0.3509  loss_mask: 0.2572  loss_rpn_cls: 0.07306  loss_rpn_loc: 0.1648  time: 0.2238  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:11:16 d2.utils.events]: \u001b[0m eta: 3:07:25  iter: 44839  total_loss: 1.105  loss_cls: 0.2574  loss_box_reg: 0.3819  loss_mask: 0.2591  loss_rpn_cls: 0.05788  loss_rpn_loc: 0.156  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:11:20 d2.utils.events]: \u001b[0m eta: 3:07:18  iter: 44859  total_loss: 1.264  loss_cls: 0.323  loss_box_reg: 0.4247  loss_mask: 0.2865  loss_rpn_cls: 0.07783  loss_rpn_loc: 0.1505  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:11:25 d2.utils.events]: \u001b[0m eta: 3:07:29  iter: 44879  total_loss: 1.068  loss_cls: 0.2518  loss_box_reg: 0.3337  loss_mask: 0.2673  loss_rpn_cls: 0.06573  loss_rpn_loc: 0.1693  time: 0.2238  data_time: 0.0145  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:11:29 d2.utils.events]: \u001b[0m eta: 3:07:12  iter: 44899  total_loss: 1.213  loss_cls: 0.3152  loss_box_reg: 0.3637  loss_mask: 0.2457  loss_rpn_cls: 0.06818  loss_rpn_loc: 0.1689  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:11:34 d2.utils.events]: \u001b[0m eta: 3:07:05  iter: 44919  total_loss: 1.298  loss_cls: 0.3492  loss_box_reg: 0.4089  loss_mask: 0.2637  loss_rpn_cls: 0.09492  loss_rpn_loc: 0.1754  time: 0.2238  data_time: 0.0165  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:11:39 d2.utils.events]: \u001b[0m eta: 3:07:10  iter: 44939  total_loss: 1.113  loss_cls: 0.28  loss_box_reg: 0.3384  loss_mask: 0.2565  loss_rpn_cls: 0.06912  loss_rpn_loc: 0.1673  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:11:43 d2.utils.events]: \u001b[0m eta: 3:07:14  iter: 44959  total_loss: 1.137  loss_cls: 0.2747  loss_box_reg: 0.3813  loss_mask: 0.2634  loss_rpn_cls: 0.07093  loss_rpn_loc: 0.1577  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:11:48 d2.utils.events]: \u001b[0m eta: 3:06:52  iter: 44979  total_loss: 1.166  loss_cls: 0.2766  loss_box_reg: 0.3634  loss_mask: 0.2746  loss_rpn_cls: 0.07425  loss_rpn_loc: 0.1665  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:11:52 d2.utils.events]: \u001b[0m eta: 3:06:57  iter: 44999  total_loss: 1.228  loss_cls: 0.2876  loss_box_reg: 0.3909  loss_mask: 0.2831  loss_rpn_cls: 0.08733  loss_rpn_loc: 0.1677  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:11:56 d2.utils.events]: \u001b[0m eta: 3:07:00  iter: 45019  total_loss: 1.111  loss_cls: 0.2747  loss_box_reg: 0.3512  loss_mask: 0.2607  loss_rpn_cls: 0.08415  loss_rpn_loc: 0.1583  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:12:01 d2.utils.events]: \u001b[0m eta: 3:06:35  iter: 45039  total_loss: 1.134  loss_cls: 0.2691  loss_box_reg: 0.3356  loss_mask: 0.2594  loss_rpn_cls: 0.0814  loss_rpn_loc: 0.1645  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:12:05 d2.utils.events]: \u001b[0m eta: 3:06:17  iter: 45059  total_loss: 1.111  loss_cls: 0.2488  loss_box_reg: 0.3335  loss_mask: 0.2526  loss_rpn_cls: 0.06367  loss_rpn_loc: 0.1511  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:12:09 d2.utils.events]: \u001b[0m eta: 3:06:07  iter: 45079  total_loss: 1.149  loss_cls: 0.2871  loss_box_reg: 0.3828  loss_mask: 0.2418  loss_rpn_cls: 0.06724  loss_rpn_loc: 0.1548  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:12:14 d2.utils.events]: \u001b[0m eta: 3:06:08  iter: 45099  total_loss: 1.08  loss_cls: 0.2654  loss_box_reg: 0.3526  loss_mask: 0.2476  loss_rpn_cls: 0.06137  loss_rpn_loc: 0.1399  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:12:18 d2.utils.events]: \u001b[0m eta: 3:06:07  iter: 45119  total_loss: 1.249  loss_cls: 0.298  loss_box_reg: 0.3816  loss_mask: 0.2549  loss_rpn_cls: 0.08829  loss_rpn_loc: 0.1829  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:12:23 d2.utils.events]: \u001b[0m eta: 3:06:03  iter: 45139  total_loss: 1.102  loss_cls: 0.266  loss_box_reg: 0.403  loss_mask: 0.2347  loss_rpn_cls: 0.06228  loss_rpn_loc: 0.1384  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:12:27 d2.utils.events]: \u001b[0m eta: 3:05:46  iter: 45159  total_loss: 1.163  loss_cls: 0.2816  loss_box_reg: 0.3678  loss_mask: 0.2717  loss_rpn_cls: 0.06106  loss_rpn_loc: 0.1659  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:12:32 d2.utils.events]: \u001b[0m eta: 3:05:40  iter: 45179  total_loss: 1.152  loss_cls: 0.2891  loss_box_reg: 0.3394  loss_mask: 0.2432  loss_rpn_cls: 0.08637  loss_rpn_loc: 0.1674  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:12:36 d2.utils.events]: \u001b[0m eta: 3:05:55  iter: 45199  total_loss: 1.174  loss_cls: 0.2778  loss_box_reg: 0.4124  loss_mask: 0.2508  loss_rpn_cls: 0.08805  loss_rpn_loc: 0.1763  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:12:41 d2.utils.events]: \u001b[0m eta: 3:05:45  iter: 45219  total_loss: 1.213  loss_cls: 0.3005  loss_box_reg: 0.354  loss_mask: 0.2606  loss_rpn_cls: 0.0882  loss_rpn_loc: 0.186  time: 0.2238  data_time: 0.0269  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:12:46 d2.utils.events]: \u001b[0m eta: 3:05:53  iter: 45239  total_loss: 1.313  loss_cls: 0.3251  loss_box_reg: 0.4132  loss_mask: 0.2799  loss_rpn_cls: 0.07537  loss_rpn_loc: 0.1691  time: 0.2238  data_time: 0.0119  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:12:51 d2.utils.events]: \u001b[0m eta: 3:05:50  iter: 45259  total_loss: 1.156  loss_cls: 0.2823  loss_box_reg: 0.3679  loss_mask: 0.266  loss_rpn_cls: 0.07669  loss_rpn_loc: 0.1707  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:12:55 d2.utils.events]: \u001b[0m eta: 3:05:50  iter: 45279  total_loss: 1.222  loss_cls: 0.3067  loss_box_reg: 0.3766  loss_mask: 0.2651  loss_rpn_cls: 0.09652  loss_rpn_loc: 0.1752  time: 0.2238  data_time: 0.0089  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:13:00 d2.utils.events]: \u001b[0m eta: 3:05:53  iter: 45299  total_loss: 1.268  loss_cls: 0.3133  loss_box_reg: 0.3957  loss_mask: 0.2627  loss_rpn_cls: 0.08207  loss_rpn_loc: 0.1644  time: 0.2238  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:13:04 d2.utils.events]: \u001b[0m eta: 3:05:39  iter: 45319  total_loss: 1.175  loss_cls: 0.2953  loss_box_reg: 0.3705  loss_mask: 0.2601  loss_rpn_cls: 0.06901  loss_rpn_loc: 0.1653  time: 0.2238  data_time: 0.0103  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:13:09 d2.utils.events]: \u001b[0m eta: 3:05:47  iter: 45339  total_loss: 1.182  loss_cls: 0.2857  loss_box_reg: 0.3958  loss_mask: 0.2531  loss_rpn_cls: 0.07389  loss_rpn_loc: 0.1571  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:13:13 d2.utils.events]: \u001b[0m eta: 3:05:46  iter: 45359  total_loss: 1.073  loss_cls: 0.2671  loss_box_reg: 0.3458  loss_mask: 0.2336  loss_rpn_cls: 0.05554  loss_rpn_loc: 0.1627  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:13:18 d2.utils.events]: \u001b[0m eta: 3:05:42  iter: 45379  total_loss: 1.193  loss_cls: 0.3095  loss_box_reg: 0.3611  loss_mask: 0.2639  loss_rpn_cls: 0.079  loss_rpn_loc: 0.1849  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:13:23 d2.utils.events]: \u001b[0m eta: 3:05:46  iter: 45399  total_loss: 1.374  loss_cls: 0.3332  loss_box_reg: 0.4239  loss_mask: 0.2955  loss_rpn_cls: 0.08557  loss_rpn_loc: 0.1867  time: 0.2238  data_time: 0.0090  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:13:27 d2.utils.events]: \u001b[0m eta: 3:05:43  iter: 45419  total_loss: 1.313  loss_cls: 0.313  loss_box_reg: 0.4315  loss_mask: 0.2724  loss_rpn_cls: 0.09695  loss_rpn_loc: 0.1813  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:13:32 d2.utils.events]: \u001b[0m eta: 3:05:36  iter: 45439  total_loss: 1.172  loss_cls: 0.3014  loss_box_reg: 0.3493  loss_mask: 0.265  loss_rpn_cls: 0.1037  loss_rpn_loc: 0.1612  time: 0.2238  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:13:36 d2.utils.events]: \u001b[0m eta: 3:05:21  iter: 45459  total_loss: 1.166  loss_cls: 0.3094  loss_box_reg: 0.412  loss_mask: 0.2702  loss_rpn_cls: 0.06671  loss_rpn_loc: 0.1653  time: 0.2238  data_time: 0.0130  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:13:41 d2.utils.events]: \u001b[0m eta: 3:05:27  iter: 45479  total_loss: 1.194  loss_cls: 0.2952  loss_box_reg: 0.3883  loss_mask: 0.2563  loss_rpn_cls: 0.0688  loss_rpn_loc: 0.1552  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:13:45 d2.utils.events]: \u001b[0m eta: 3:05:19  iter: 45499  total_loss: 1.16  loss_cls: 0.2731  loss_box_reg: 0.3621  loss_mask: 0.2716  loss_rpn_cls: 0.09355  loss_rpn_loc: 0.1669  time: 0.2238  data_time: 0.0154  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:13:50 d2.utils.events]: \u001b[0m eta: 3:05:11  iter: 45519  total_loss: 1.168  loss_cls: 0.2899  loss_box_reg: 0.3867  loss_mask: 0.2542  loss_rpn_cls: 0.05206  loss_rpn_loc: 0.1737  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:13:54 d2.utils.events]: \u001b[0m eta: 3:05:16  iter: 45539  total_loss: 1.188  loss_cls: 0.2761  loss_box_reg: 0.3816  loss_mask: 0.2631  loss_rpn_cls: 0.101  loss_rpn_loc: 0.1745  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:13:59 d2.utils.events]: \u001b[0m eta: 3:05:11  iter: 45559  total_loss: 1.12  loss_cls: 0.2729  loss_box_reg: 0.3563  loss_mask: 0.2557  loss_rpn_cls: 0.05802  loss_rpn_loc: 0.1529  time: 0.2238  data_time: 0.0105  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:14:03 d2.utils.events]: \u001b[0m eta: 3:05:08  iter: 45579  total_loss: 1.296  loss_cls: 0.3173  loss_box_reg: 0.4104  loss_mask: 0.2729  loss_rpn_cls: 0.08119  loss_rpn_loc: 0.174  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:14:08 d2.utils.events]: \u001b[0m eta: 3:05:04  iter: 45599  total_loss: 1.148  loss_cls: 0.3119  loss_box_reg: 0.3848  loss_mask: 0.2608  loss_rpn_cls: 0.07557  loss_rpn_loc: 0.1745  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:14:12 d2.utils.events]: \u001b[0m eta: 3:05:08  iter: 45619  total_loss: 1.08  loss_cls: 0.234  loss_box_reg: 0.3516  loss_mask: 0.2569  loss_rpn_cls: 0.07228  loss_rpn_loc: 0.1644  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:14:17 d2.utils.events]: \u001b[0m eta: 3:04:55  iter: 45639  total_loss: 1.162  loss_cls: 0.2924  loss_box_reg: 0.3796  loss_mask: 0.2449  loss_rpn_cls: 0.07834  loss_rpn_loc: 0.1568  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:14:21 d2.utils.events]: \u001b[0m eta: 3:05:00  iter: 45659  total_loss: 1.18  loss_cls: 0.306  loss_box_reg: 0.4002  loss_mask: 0.272  loss_rpn_cls: 0.06485  loss_rpn_loc: 0.1573  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:14:26 d2.utils.events]: \u001b[0m eta: 3:05:06  iter: 45679  total_loss: 1.171  loss_cls: 0.2643  loss_box_reg: 0.3739  loss_mask: 0.2669  loss_rpn_cls: 0.07032  loss_rpn_loc: 0.1647  time: 0.2238  data_time: 0.0163  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:14:30 d2.utils.events]: \u001b[0m eta: 3:05:02  iter: 45699  total_loss: 1.226  loss_cls: 0.3078  loss_box_reg: 0.358  loss_mask: 0.2711  loss_rpn_cls: 0.08231  loss_rpn_loc: 0.1701  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:14:34 d2.utils.events]: \u001b[0m eta: 3:04:46  iter: 45719  total_loss: 1.336  loss_cls: 0.3565  loss_box_reg: 0.4423  loss_mask: 0.2868  loss_rpn_cls: 0.0675  loss_rpn_loc: 0.1644  time: 0.2238  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:14:39 d2.utils.events]: \u001b[0m eta: 3:04:53  iter: 45739  total_loss: 1.265  loss_cls: 0.3243  loss_box_reg: 0.3769  loss_mask: 0.2889  loss_rpn_cls: 0.0741  loss_rpn_loc: 0.1652  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:14:43 d2.utils.events]: \u001b[0m eta: 3:04:14  iter: 45759  total_loss: 1.203  loss_cls: 0.3079  loss_box_reg: 0.4083  loss_mask: 0.2788  loss_rpn_cls: 0.06936  loss_rpn_loc: 0.1472  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:14:48 d2.utils.events]: \u001b[0m eta: 3:04:25  iter: 45779  total_loss: 1.223  loss_cls: 0.3264  loss_box_reg: 0.3883  loss_mask: 0.2584  loss_rpn_cls: 0.08922  loss_rpn_loc: 0.1649  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:14:52 d2.utils.events]: \u001b[0m eta: 3:04:45  iter: 45799  total_loss: 1.033  loss_cls: 0.2559  loss_box_reg: 0.3249  loss_mask: 0.2593  loss_rpn_cls: 0.05574  loss_rpn_loc: 0.1538  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:14:57 d2.utils.events]: \u001b[0m eta: 3:04:24  iter: 45819  total_loss: 1.2  loss_cls: 0.2777  loss_box_reg: 0.3999  loss_mask: 0.2575  loss_rpn_cls: 0.07759  loss_rpn_loc: 0.1886  time: 0.2238  data_time: 0.0145  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:15:02 d2.utils.events]: \u001b[0m eta: 3:04:38  iter: 45839  total_loss: 1.274  loss_cls: 0.3164  loss_box_reg: 0.3733  loss_mask: 0.2772  loss_rpn_cls: 0.07007  loss_rpn_loc: 0.1643  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:15:06 d2.utils.events]: \u001b[0m eta: 3:04:33  iter: 45859  total_loss: 1.169  loss_cls: 0.2888  loss_box_reg: 0.3552  loss_mask: 0.2561  loss_rpn_cls: 0.08233  loss_rpn_loc: 0.1615  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:15:10 d2.utils.events]: \u001b[0m eta: 3:04:02  iter: 45879  total_loss: 1.174  loss_cls: 0.2623  loss_box_reg: 0.3518  loss_mask: 0.2637  loss_rpn_cls: 0.08674  loss_rpn_loc: 0.1779  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:15:15 d2.utils.events]: \u001b[0m eta: 3:04:04  iter: 45899  total_loss: 1.121  loss_cls: 0.2807  loss_box_reg: 0.3636  loss_mask: 0.2501  loss_rpn_cls: 0.05904  loss_rpn_loc: 0.1551  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:15:19 d2.utils.events]: \u001b[0m eta: 3:03:50  iter: 45919  total_loss: 1.202  loss_cls: 0.2707  loss_box_reg: 0.3757  loss_mask: 0.2574  loss_rpn_cls: 0.06748  loss_rpn_loc: 0.1542  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:15:24 d2.utils.events]: \u001b[0m eta: 3:03:49  iter: 45939  total_loss: 1.164  loss_cls: 0.305  loss_box_reg: 0.3735  loss_mask: 0.2557  loss_rpn_cls: 0.08122  loss_rpn_loc: 0.1695  time: 0.2238  data_time: 0.0134  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:15:28 d2.utils.events]: \u001b[0m eta: 3:03:45  iter: 45959  total_loss: 1.105  loss_cls: 0.2309  loss_box_reg: 0.3673  loss_mask: 0.2483  loss_rpn_cls: 0.0644  loss_rpn_loc: 0.175  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:15:33 d2.utils.events]: \u001b[0m eta: 3:03:41  iter: 45979  total_loss: 1.16  loss_cls: 0.3131  loss_box_reg: 0.3842  loss_mask: 0.2586  loss_rpn_cls: 0.06447  loss_rpn_loc: 0.1574  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:15:37 d2.utils.events]: \u001b[0m eta: 3:03:45  iter: 45999  total_loss: 1.202  loss_cls: 0.3085  loss_box_reg: 0.3942  loss_mask: 0.2634  loss_rpn_cls: 0.08649  loss_rpn_loc: 0.1721  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:15:42 d2.utils.events]: \u001b[0m eta: 3:03:41  iter: 46019  total_loss: 1.111  loss_cls: 0.2807  loss_box_reg: 0.378  loss_mask: 0.2535  loss_rpn_cls: 0.05688  loss_rpn_loc: 0.1568  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:15:46 d2.utils.events]: \u001b[0m eta: 3:03:27  iter: 46039  total_loss: 1.278  loss_cls: 0.3611  loss_box_reg: 0.3722  loss_mask: 0.2645  loss_rpn_cls: 0.07824  loss_rpn_loc: 0.1711  time: 0.2238  data_time: 0.0171  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:15:51 d2.utils.events]: \u001b[0m eta: 3:03:39  iter: 46059  total_loss: 1.243  loss_cls: 0.3212  loss_box_reg: 0.3865  loss_mask: 0.2573  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.189  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:15:55 d2.utils.events]: \u001b[0m eta: 3:03:45  iter: 46079  total_loss: 1.135  loss_cls: 0.3108  loss_box_reg: 0.383  loss_mask: 0.277  loss_rpn_cls: 0.08177  loss_rpn_loc: 0.1475  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:16:00 d2.utils.events]: \u001b[0m eta: 3:03:41  iter: 46099  total_loss: 1.239  loss_cls: 0.3131  loss_box_reg: 0.378  loss_mask: 0.2859  loss_rpn_cls: 0.09665  loss_rpn_loc: 0.1637  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:16:05 d2.utils.events]: \u001b[0m eta: 3:03:26  iter: 46119  total_loss: 1.138  loss_cls: 0.2754  loss_box_reg: 0.3527  loss_mask: 0.2471  loss_rpn_cls: 0.06404  loss_rpn_loc: 0.1567  time: 0.2238  data_time: 0.0172  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:16:09 d2.utils.events]: \u001b[0m eta: 3:03:39  iter: 46139  total_loss: 1.099  loss_cls: 0.2849  loss_box_reg: 0.3392  loss_mask: 0.2509  loss_rpn_cls: 0.06205  loss_rpn_loc: 0.1481  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:16:14 d2.utils.events]: \u001b[0m eta: 3:03:36  iter: 46159  total_loss: 1.35  loss_cls: 0.3469  loss_box_reg: 0.4391  loss_mask: 0.2745  loss_rpn_cls: 0.07504  loss_rpn_loc: 0.1736  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:16:18 d2.utils.events]: \u001b[0m eta: 3:03:31  iter: 46179  total_loss: 1.189  loss_cls: 0.2912  loss_box_reg: 0.3722  loss_mask: 0.2584  loss_rpn_cls: 0.0625  loss_rpn_loc: 0.1759  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:16:22 d2.utils.events]: \u001b[0m eta: 3:03:16  iter: 46199  total_loss: 1.211  loss_cls: 0.2996  loss_box_reg: 0.4077  loss_mask: 0.2578  loss_rpn_cls: 0.064  loss_rpn_loc: 0.1589  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:16:27 d2.utils.events]: \u001b[0m eta: 3:02:57  iter: 46219  total_loss: 1.253  loss_cls: 0.3481  loss_box_reg: 0.4094  loss_mask: 0.2696  loss_rpn_cls: 0.06103  loss_rpn_loc: 0.1589  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:16:31 d2.utils.events]: \u001b[0m eta: 3:02:46  iter: 46239  total_loss: 1.212  loss_cls: 0.3069  loss_box_reg: 0.3839  loss_mask: 0.2569  loss_rpn_cls: 0.06342  loss_rpn_loc: 0.1661  time: 0.2238  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:16:35 d2.utils.events]: \u001b[0m eta: 3:02:29  iter: 46259  total_loss: 1.179  loss_cls: 0.3004  loss_box_reg: 0.3761  loss_mask: 0.2384  loss_rpn_cls: 0.08455  loss_rpn_loc: 0.1684  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:16:40 d2.utils.events]: \u001b[0m eta: 3:02:03  iter: 46279  total_loss: 1.207  loss_cls: 0.274  loss_box_reg: 0.3901  loss_mask: 0.2592  loss_rpn_cls: 0.05774  loss_rpn_loc: 0.1622  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:16:44 d2.utils.events]: \u001b[0m eta: 3:01:53  iter: 46299  total_loss: 1.18  loss_cls: 0.2899  loss_box_reg: 0.3731  loss_mask: 0.249  loss_rpn_cls: 0.09035  loss_rpn_loc: 0.1578  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:16:49 d2.utils.events]: \u001b[0m eta: 3:01:52  iter: 46319  total_loss: 1.133  loss_cls: 0.2603  loss_box_reg: 0.3538  loss_mask: 0.2651  loss_rpn_cls: 0.08316  loss_rpn_loc: 0.1677  time: 0.2238  data_time: 0.0125  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:16:53 d2.utils.events]: \u001b[0m eta: 3:01:48  iter: 46339  total_loss: 1.2  loss_cls: 0.2845  loss_box_reg: 0.3936  loss_mask: 0.2551  loss_rpn_cls: 0.06612  loss_rpn_loc: 0.1452  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:16:58 d2.utils.events]: \u001b[0m eta: 3:01:40  iter: 46359  total_loss: 1.215  loss_cls: 0.3136  loss_box_reg: 0.401  loss_mask: 0.2562  loss_rpn_cls: 0.08689  loss_rpn_loc: 0.1642  time: 0.2238  data_time: 0.0230  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:17:03 d2.utils.events]: \u001b[0m eta: 3:01:29  iter: 46379  total_loss: 1.175  loss_cls: 0.2869  loss_box_reg: 0.3855  loss_mask: 0.2623  loss_rpn_cls: 0.07616  loss_rpn_loc: 0.1708  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:17:07 d2.utils.events]: \u001b[0m eta: 3:01:10  iter: 46399  total_loss: 1.147  loss_cls: 0.2937  loss_box_reg: 0.3757  loss_mask: 0.2529  loss_rpn_cls: 0.07252  loss_rpn_loc: 0.1682  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:17:12 d2.utils.events]: \u001b[0m eta: 3:01:04  iter: 46419  total_loss: 1.285  loss_cls: 0.3069  loss_box_reg: 0.427  loss_mask: 0.2664  loss_rpn_cls: 0.07586  loss_rpn_loc: 0.1719  time: 0.2238  data_time: 0.0146  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:17:16 d2.utils.events]: \u001b[0m eta: 3:00:58  iter: 46439  total_loss: 1.222  loss_cls: 0.3181  loss_box_reg: 0.372  loss_mask: 0.2718  loss_rpn_cls: 0.08893  loss_rpn_loc: 0.1634  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:17:21 d2.utils.events]: \u001b[0m eta: 3:00:44  iter: 46459  total_loss: 1.162  loss_cls: 0.2802  loss_box_reg: 0.3589  loss_mask: 0.2564  loss_rpn_cls: 0.0663  loss_rpn_loc: 0.1477  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:17:26 d2.utils.events]: \u001b[0m eta: 3:00:55  iter: 46479  total_loss: 1.219  loss_cls: 0.3003  loss_box_reg: 0.4043  loss_mask: 0.2721  loss_rpn_cls: 0.1033  loss_rpn_loc: 0.18  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:17:30 d2.utils.events]: \u001b[0m eta: 3:00:51  iter: 46499  total_loss: 1.174  loss_cls: 0.2753  loss_box_reg: 0.378  loss_mask: 0.2667  loss_rpn_cls: 0.07547  loss_rpn_loc: 0.1663  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:17:34 d2.utils.events]: \u001b[0m eta: 3:00:42  iter: 46519  total_loss: 1.161  loss_cls: 0.3127  loss_box_reg: 0.3716  loss_mask: 0.2387  loss_rpn_cls: 0.07859  loss_rpn_loc: 0.1559  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:17:39 d2.utils.events]: \u001b[0m eta: 3:00:36  iter: 46539  total_loss: 1.249  loss_cls: 0.3368  loss_box_reg: 0.3855  loss_mask: 0.2701  loss_rpn_cls: 0.07534  loss_rpn_loc: 0.1624  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:17:44 d2.utils.events]: \u001b[0m eta: 3:00:38  iter: 46559  total_loss: 1.294  loss_cls: 0.3291  loss_box_reg: 0.3491  loss_mask: 0.2721  loss_rpn_cls: 0.1068  loss_rpn_loc: 0.1722  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:17:48 d2.utils.events]: \u001b[0m eta: 3:00:34  iter: 46579  total_loss: 1.159  loss_cls: 0.2858  loss_box_reg: 0.3763  loss_mask: 0.257  loss_rpn_cls: 0.09639  loss_rpn_loc: 0.1883  time: 0.2238  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:17:53 d2.utils.events]: \u001b[0m eta: 3:00:25  iter: 46599  total_loss: 1.246  loss_cls: 0.2805  loss_box_reg: 0.4025  loss_mask: 0.2617  loss_rpn_cls: 0.0792  loss_rpn_loc: 0.1554  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:17:57 d2.utils.events]: \u001b[0m eta: 3:00:24  iter: 46619  total_loss: 1.196  loss_cls: 0.2913  loss_box_reg: 0.3651  loss_mask: 0.2792  loss_rpn_cls: 0.09927  loss_rpn_loc: 0.1616  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:18:02 d2.utils.events]: \u001b[0m eta: 3:00:14  iter: 46639  total_loss: 1.157  loss_cls: 0.3053  loss_box_reg: 0.3768  loss_mask: 0.2535  loss_rpn_cls: 0.06845  loss_rpn_loc: 0.1502  time: 0.2238  data_time: 0.0209  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:18:06 d2.utils.events]: \u001b[0m eta: 3:00:10  iter: 46659  total_loss: 1.135  loss_cls: 0.3043  loss_box_reg: 0.3736  loss_mask: 0.2489  loss_rpn_cls: 0.07492  loss_rpn_loc: 0.1905  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:18:11 d2.utils.events]: \u001b[0m eta: 3:00:09  iter: 46679  total_loss: 1.36  loss_cls: 0.335  loss_box_reg: 0.4169  loss_mask: 0.2925  loss_rpn_cls: 0.1041  loss_rpn_loc: 0.183  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:18:16 d2.utils.events]: \u001b[0m eta: 3:00:05  iter: 46699  total_loss: 1.292  loss_cls: 0.2811  loss_box_reg: 0.4309  loss_mask: 0.2785  loss_rpn_cls: 0.08401  loss_rpn_loc: 0.1769  time: 0.2238  data_time: 0.0175  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:18:20 d2.utils.events]: \u001b[0m eta: 3:00:09  iter: 46719  total_loss: 1.231  loss_cls: 0.3066  loss_box_reg: 0.3992  loss_mask: 0.2735  loss_rpn_cls: 0.08135  loss_rpn_loc: 0.1747  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:18:24 d2.utils.events]: \u001b[0m eta: 3:00:15  iter: 46739  total_loss: 1.158  loss_cls: 0.2922  loss_box_reg: 0.3761  loss_mask: 0.2777  loss_rpn_cls: 0.07687  loss_rpn_loc: 0.1794  time: 0.2238  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:18:29 d2.utils.events]: \u001b[0m eta: 3:00:11  iter: 46759  total_loss: 1.158  loss_cls: 0.3017  loss_box_reg: 0.3931  loss_mask: 0.2538  loss_rpn_cls: 0.07819  loss_rpn_loc: 0.1822  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:18:33 d2.utils.events]: \u001b[0m eta: 2:59:50  iter: 46779  total_loss: 1.151  loss_cls: 0.2853  loss_box_reg: 0.3822  loss_mask: 0.2576  loss_rpn_cls: 0.06933  loss_rpn_loc: 0.1788  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:18:38 d2.utils.events]: \u001b[0m eta: 2:59:43  iter: 46799  total_loss: 1.189  loss_cls: 0.286  loss_box_reg: 0.4073  loss_mask: 0.2552  loss_rpn_cls: 0.06624  loss_rpn_loc: 0.1742  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:18:42 d2.utils.events]: \u001b[0m eta: 2:59:47  iter: 46819  total_loss: 1.268  loss_cls: 0.3143  loss_box_reg: 0.3857  loss_mask: 0.2623  loss_rpn_cls: 0.08915  loss_rpn_loc: 0.1835  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:18:46 d2.utils.events]: \u001b[0m eta: 2:59:53  iter: 46839  total_loss: 1.294  loss_cls: 0.3037  loss_box_reg: 0.4182  loss_mask: 0.2693  loss_rpn_cls: 0.07719  loss_rpn_loc: 0.1672  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:18:51 d2.utils.events]: \u001b[0m eta: 2:59:49  iter: 46859  total_loss: 1.171  loss_cls: 0.2502  loss_box_reg: 0.3565  loss_mask: 0.2588  loss_rpn_cls: 0.08865  loss_rpn_loc: 0.1805  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:18:55 d2.utils.events]: \u001b[0m eta: 2:59:49  iter: 46879  total_loss: 1.178  loss_cls: 0.2895  loss_box_reg: 0.3779  loss_mask: 0.2686  loss_rpn_cls: 0.06315  loss_rpn_loc: 0.1625  time: 0.2238  data_time: 0.0156  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:19:00 d2.utils.events]: \u001b[0m eta: 2:59:30  iter: 46899  total_loss: 1.14  loss_cls: 0.25  loss_box_reg: 0.3644  loss_mask: 0.2654  loss_rpn_cls: 0.06102  loss_rpn_loc: 0.1627  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:19:04 d2.utils.events]: \u001b[0m eta: 2:59:36  iter: 46919  total_loss: 1.312  loss_cls: 0.3281  loss_box_reg: 0.3955  loss_mask: 0.2675  loss_rpn_cls: 0.09877  loss_rpn_loc: 0.183  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:19:09 d2.utils.events]: \u001b[0m eta: 2:59:15  iter: 46939  total_loss: 1.148  loss_cls: 0.3161  loss_box_reg: 0.3669  loss_mask: 0.2696  loss_rpn_cls: 0.07389  loss_rpn_loc: 0.1578  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:19:13 d2.utils.events]: \u001b[0m eta: 2:59:12  iter: 46959  total_loss: 1.209  loss_cls: 0.2927  loss_box_reg: 0.4208  loss_mask: 0.2702  loss_rpn_cls: 0.07907  loss_rpn_loc: 0.1552  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:19:18 d2.utils.events]: \u001b[0m eta: 2:59:10  iter: 46979  total_loss: 1.141  loss_cls: 0.272  loss_box_reg: 0.3654  loss_mask: 0.2519  loss_rpn_cls: 0.0629  loss_rpn_loc: 0.1595  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:19:22 d2.utils.events]: \u001b[0m eta: 2:59:03  iter: 46999  total_loss: 1.129  loss_cls: 0.2829  loss_box_reg: 0.3628  loss_mask: 0.2566  loss_rpn_cls: 0.08815  loss_rpn_loc: 0.17  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:19:27 d2.utils.events]: \u001b[0m eta: 2:58:59  iter: 47019  total_loss: 1.096  loss_cls: 0.2394  loss_box_reg: 0.3586  loss_mask: 0.2512  loss_rpn_cls: 0.06725  loss_rpn_loc: 0.156  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:19:31 d2.utils.events]: \u001b[0m eta: 2:58:57  iter: 47039  total_loss: 1.218  loss_cls: 0.2956  loss_box_reg: 0.3885  loss_mask: 0.2714  loss_rpn_cls: 0.0814  loss_rpn_loc: 0.1834  time: 0.2238  data_time: 0.0122  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:19:35 d2.utils.events]: \u001b[0m eta: 2:58:41  iter: 47059  total_loss: 1.322  loss_cls: 0.3348  loss_box_reg: 0.4388  loss_mask: 0.2678  loss_rpn_cls: 0.09133  loss_rpn_loc: 0.1704  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:19:40 d2.utils.events]: \u001b[0m eta: 2:58:39  iter: 47079  total_loss: 1.043  loss_cls: 0.2321  loss_box_reg: 0.3424  loss_mask: 0.2663  loss_rpn_cls: 0.05967  loss_rpn_loc: 0.1681  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:19:44 d2.utils.events]: \u001b[0m eta: 2:58:29  iter: 47099  total_loss: 1.252  loss_cls: 0.3175  loss_box_reg: 0.4133  loss_mask: 0.2468  loss_rpn_cls: 0.06909  loss_rpn_loc: 0.1532  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:19:49 d2.utils.events]: \u001b[0m eta: 2:58:17  iter: 47119  total_loss: 1.129  loss_cls: 0.2536  loss_box_reg: 0.3679  loss_mask: 0.2507  loss_rpn_cls: 0.05118  loss_rpn_loc: 0.1532  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:19:53 d2.utils.events]: \u001b[0m eta: 2:58:12  iter: 47139  total_loss: 1.1  loss_cls: 0.2666  loss_box_reg: 0.3769  loss_mask: 0.2614  loss_rpn_cls: 0.06078  loss_rpn_loc: 0.1645  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:19:58 d2.utils.events]: \u001b[0m eta: 2:58:08  iter: 47159  total_loss: 1.186  loss_cls: 0.2887  loss_box_reg: 0.3452  loss_mask: 0.2586  loss_rpn_cls: 0.0532  loss_rpn_loc: 0.1642  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:20:02 d2.utils.events]: \u001b[0m eta: 2:57:49  iter: 47179  total_loss: 1.191  loss_cls: 0.2766  loss_box_reg: 0.3926  loss_mask: 0.2557  loss_rpn_cls: 0.06667  loss_rpn_loc: 0.1662  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:20:07 d2.utils.events]: \u001b[0m eta: 2:58:07  iter: 47199  total_loss: 1.032  loss_cls: 0.2664  loss_box_reg: 0.3285  loss_mask: 0.2535  loss_rpn_cls: 0.07167  loss_rpn_loc: 0.161  time: 0.2238  data_time: 0.0148  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:20:11 d2.utils.events]: \u001b[0m eta: 2:58:06  iter: 47219  total_loss: 1.271  loss_cls: 0.3308  loss_box_reg: 0.3928  loss_mask: 0.2778  loss_rpn_cls: 0.09075  loss_rpn_loc: 0.1728  time: 0.2238  data_time: 0.0093  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:20:16 d2.utils.events]: \u001b[0m eta: 2:58:06  iter: 47239  total_loss: 1.246  loss_cls: 0.3227  loss_box_reg: 0.3977  loss_mask: 0.2436  loss_rpn_cls: 0.07656  loss_rpn_loc: 0.1686  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:20:20 d2.utils.events]: \u001b[0m eta: 2:58:00  iter: 47259  total_loss: 1.148  loss_cls: 0.2783  loss_box_reg: 0.3804  loss_mask: 0.2641  loss_rpn_cls: 0.06687  loss_rpn_loc: 0.1541  time: 0.2238  data_time: 0.0112  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:20:25 d2.utils.events]: \u001b[0m eta: 2:58:01  iter: 47279  total_loss: 1.012  loss_cls: 0.2313  loss_box_reg: 0.3211  loss_mask: 0.247  loss_rpn_cls: 0.07235  loss_rpn_loc: 0.1823  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:20:29 d2.utils.events]: \u001b[0m eta: 2:58:05  iter: 47299  total_loss: 1.172  loss_cls: 0.287  loss_box_reg: 0.3603  loss_mask: 0.267  loss_rpn_cls: 0.07325  loss_rpn_loc: 0.1801  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:20:34 d2.utils.events]: \u001b[0m eta: 2:57:59  iter: 47319  total_loss: 1.273  loss_cls: 0.3295  loss_box_reg: 0.3789  loss_mask: 0.2555  loss_rpn_cls: 0.08859  loss_rpn_loc: 0.1676  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:20:38 d2.utils.events]: \u001b[0m eta: 2:57:55  iter: 47339  total_loss: 1.352  loss_cls: 0.3518  loss_box_reg: 0.3584  loss_mask: 0.2625  loss_rpn_cls: 0.09931  loss_rpn_loc: 0.1771  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:20:43 d2.utils.events]: \u001b[0m eta: 2:58:05  iter: 47359  total_loss: 1.387  loss_cls: 0.4137  loss_box_reg: 0.3848  loss_mask: 0.2752  loss_rpn_cls: 0.1172  loss_rpn_loc: 0.1945  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:20:48 d2.utils.events]: \u001b[0m eta: 2:57:58  iter: 47379  total_loss: 1.396  loss_cls: 0.3687  loss_box_reg: 0.4126  loss_mask: 0.263  loss_rpn_cls: 0.09186  loss_rpn_loc: 0.1716  time: 0.2238  data_time: 0.0174  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:20:52 d2.utils.events]: \u001b[0m eta: 2:57:56  iter: 47399  total_loss: 1.146  loss_cls: 0.2942  loss_box_reg: 0.3885  loss_mask: 0.2559  loss_rpn_cls: 0.07329  loss_rpn_loc: 0.161  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:20:57 d2.utils.events]: \u001b[0m eta: 2:57:56  iter: 47419  total_loss: 1.104  loss_cls: 0.2552  loss_box_reg: 0.346  loss_mask: 0.2573  loss_rpn_cls: 0.08197  loss_rpn_loc: 0.1718  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:21:01 d2.utils.events]: \u001b[0m eta: 2:57:52  iter: 47439  total_loss: 1.245  loss_cls: 0.2933  loss_box_reg: 0.3979  loss_mask: 0.2722  loss_rpn_cls: 0.06284  loss_rpn_loc: 0.1609  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:21:06 d2.utils.events]: \u001b[0m eta: 2:58:03  iter: 47459  total_loss: 1.15  loss_cls: 0.2433  loss_box_reg: 0.3557  loss_mask: 0.2733  loss_rpn_cls: 0.08351  loss_rpn_loc: 0.1679  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:21:10 d2.utils.events]: \u001b[0m eta: 2:57:39  iter: 47479  total_loss: 1.093  loss_cls: 0.2511  loss_box_reg: 0.3457  loss_mask: 0.2474  loss_rpn_cls: 0.05191  loss_rpn_loc: 0.1569  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:21:15 d2.utils.events]: \u001b[0m eta: 2:57:37  iter: 47499  total_loss: 1.194  loss_cls: 0.3021  loss_box_reg: 0.3368  loss_mask: 0.2475  loss_rpn_cls: 0.09054  loss_rpn_loc: 0.158  time: 0.2238  data_time: 0.0307  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:21:19 d2.utils.events]: \u001b[0m eta: 2:57:30  iter: 47519  total_loss: 1.041  loss_cls: 0.2565  loss_box_reg: 0.3636  loss_mask: 0.2437  loss_rpn_cls: 0.06504  loss_rpn_loc: 0.1389  time: 0.2238  data_time: 0.0057  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:21:24 d2.utils.events]: \u001b[0m eta: 2:57:20  iter: 47539  total_loss: 1.241  loss_cls: 0.3024  loss_box_reg: 0.412  loss_mask: 0.2719  loss_rpn_cls: 0.06039  loss_rpn_loc: 0.161  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:21:28 d2.utils.events]: \u001b[0m eta: 2:57:02  iter: 47559  total_loss: 1.193  loss_cls: 0.2863  loss_box_reg: 0.3714  loss_mask: 0.2679  loss_rpn_cls: 0.0748  loss_rpn_loc: 0.1636  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:21:33 d2.utils.events]: \u001b[0m eta: 2:57:00  iter: 47579  total_loss: 1.209  loss_cls: 0.2858  loss_box_reg: 0.3726  loss_mask: 0.2716  loss_rpn_cls: 0.07057  loss_rpn_loc: 0.1609  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:21:37 d2.utils.events]: \u001b[0m eta: 2:56:58  iter: 47599  total_loss: 1.246  loss_cls: 0.2971  loss_box_reg: 0.3989  loss_mask: 0.2763  loss_rpn_cls: 0.07152  loss_rpn_loc: 0.1696  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:21:42 d2.utils.events]: \u001b[0m eta: 2:56:54  iter: 47619  total_loss: 1.366  loss_cls: 0.3245  loss_box_reg: 0.4408  loss_mask: 0.2694  loss_rpn_cls: 0.07971  loss_rpn_loc: 0.1875  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:21:46 d2.utils.events]: \u001b[0m eta: 2:57:09  iter: 47639  total_loss: 1.132  loss_cls: 0.2601  loss_box_reg: 0.3656  loss_mask: 0.2729  loss_rpn_cls: 0.08945  loss_rpn_loc: 0.1805  time: 0.2238  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:21:51 d2.utils.events]: \u001b[0m eta: 2:57:07  iter: 47659  total_loss: 1.152  loss_cls: 0.3027  loss_box_reg: 0.3696  loss_mask: 0.245  loss_rpn_cls: 0.07228  loss_rpn_loc: 0.1656  time: 0.2238  data_time: 0.0171  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:21:55 d2.utils.events]: \u001b[0m eta: 2:56:58  iter: 47679  total_loss: 1.218  loss_cls: 0.3286  loss_box_reg: 0.4057  loss_mask: 0.2703  loss_rpn_cls: 0.08297  loss_rpn_loc: 0.162  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:22:00 d2.utils.events]: \u001b[0m eta: 2:57:11  iter: 47699  total_loss: 1.161  loss_cls: 0.2725  loss_box_reg: 0.3805  loss_mask: 0.2527  loss_rpn_cls: 0.08601  loss_rpn_loc: 0.1758  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:22:05 d2.utils.events]: \u001b[0m eta: 2:57:21  iter: 47719  total_loss: 1.165  loss_cls: 0.2999  loss_box_reg: 0.3857  loss_mask: 0.2705  loss_rpn_cls: 0.09469  loss_rpn_loc: 0.1742  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:22:09 d2.utils.events]: \u001b[0m eta: 2:56:55  iter: 47739  total_loss: 1.126  loss_cls: 0.2619  loss_box_reg: 0.4018  loss_mask: 0.2468  loss_rpn_cls: 0.04738  loss_rpn_loc: 0.1487  time: 0.2238  data_time: 0.0058  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:22:13 d2.utils.events]: \u001b[0m eta: 2:57:07  iter: 47759  total_loss: 1.179  loss_cls: 0.2714  loss_box_reg: 0.3737  loss_mask: 0.2663  loss_rpn_cls: 0.08313  loss_rpn_loc: 0.1774  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:22:18 d2.utils.events]: \u001b[0m eta: 2:56:59  iter: 47779  total_loss: 1.255  loss_cls: 0.3113  loss_box_reg: 0.3854  loss_mask: 0.2678  loss_rpn_cls: 0.07689  loss_rpn_loc: 0.1793  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:22:22 d2.utils.events]: \u001b[0m eta: 2:57:04  iter: 47799  total_loss: 1.202  loss_cls: 0.302  loss_box_reg: 0.3705  loss_mask: 0.269  loss_rpn_cls: 0.07294  loss_rpn_loc: 0.1656  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:22:27 d2.utils.events]: \u001b[0m eta: 2:56:50  iter: 47819  total_loss: 1.267  loss_cls: 0.2941  loss_box_reg: 0.3997  loss_mask: 0.2692  loss_rpn_cls: 0.07992  loss_rpn_loc: 0.1638  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:22:31 d2.utils.events]: \u001b[0m eta: 2:56:39  iter: 47839  total_loss: 1.161  loss_cls: 0.2901  loss_box_reg: 0.3526  loss_mask: 0.2428  loss_rpn_cls: 0.07333  loss_rpn_loc: 0.1599  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:22:35 d2.utils.events]: \u001b[0m eta: 2:56:25  iter: 47859  total_loss: 1.115  loss_cls: 0.2905  loss_box_reg: 0.4238  loss_mask: 0.2589  loss_rpn_cls: 0.04818  loss_rpn_loc: 0.1456  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:22:40 d2.utils.events]: \u001b[0m eta: 2:56:19  iter: 47879  total_loss: 1.212  loss_cls: 0.2927  loss_box_reg: 0.3768  loss_mask: 0.264  loss_rpn_cls: 0.08154  loss_rpn_loc: 0.149  time: 0.2238  data_time: 0.0176  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:22:44 d2.utils.events]: \u001b[0m eta: 2:56:20  iter: 47899  total_loss: 1.254  loss_cls: 0.3082  loss_box_reg: 0.4021  loss_mask: 0.2639  loss_rpn_cls: 0.0669  loss_rpn_loc: 0.1662  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:22:49 d2.utils.events]: \u001b[0m eta: 2:56:23  iter: 47919  total_loss: 1.293  loss_cls: 0.2934  loss_box_reg: 0.3824  loss_mask: 0.2735  loss_rpn_cls: 0.06878  loss_rpn_loc: 0.182  time: 0.2238  data_time: 0.0152  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:22:54 d2.utils.events]: \u001b[0m eta: 2:56:24  iter: 47939  total_loss: 1.072  loss_cls: 0.2624  loss_box_reg: 0.3676  loss_mask: 0.254  loss_rpn_cls: 0.051  loss_rpn_loc: 0.1584  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:22:58 d2.utils.events]: \u001b[0m eta: 2:56:07  iter: 47959  total_loss: 1.138  loss_cls: 0.2702  loss_box_reg: 0.3772  loss_mask: 0.2604  loss_rpn_cls: 0.0708  loss_rpn_loc: 0.1657  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:23:03 d2.utils.events]: \u001b[0m eta: 2:56:03  iter: 47979  total_loss: 1.296  loss_cls: 0.3459  loss_box_reg: 0.4026  loss_mask: 0.2748  loss_rpn_cls: 0.09015  loss_rpn_loc: 0.1812  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:23:07 d2.utils.events]: \u001b[0m eta: 2:56:04  iter: 47999  total_loss: 1.217  loss_cls: 0.2979  loss_box_reg: 0.4019  loss_mask: 0.2648  loss_rpn_cls: 0.06048  loss_rpn_loc: 0.1636  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:23:12 d2.utils.events]: \u001b[0m eta: 2:55:59  iter: 48019  total_loss: 1.158  loss_cls: 0.25  loss_box_reg: 0.3532  loss_mask: 0.2486  loss_rpn_cls: 0.07458  loss_rpn_loc: 0.1546  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:23:16 d2.utils.events]: \u001b[0m eta: 2:55:50  iter: 48039  total_loss: 1.189  loss_cls: 0.27  loss_box_reg: 0.3581  loss_mask: 0.2452  loss_rpn_cls: 0.06992  loss_rpn_loc: 0.1783  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:23:20 d2.utils.events]: \u001b[0m eta: 2:55:54  iter: 48059  total_loss: 1.205  loss_cls: 0.3308  loss_box_reg: 0.3996  loss_mask: 0.257  loss_rpn_cls: 0.07944  loss_rpn_loc: 0.1564  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:23:25 d2.utils.events]: \u001b[0m eta: 2:55:41  iter: 48079  total_loss: 1.08  loss_cls: 0.2839  loss_box_reg: 0.3658  loss_mask: 0.2433  loss_rpn_cls: 0.07481  loss_rpn_loc: 0.1647  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:23:29 d2.utils.events]: \u001b[0m eta: 2:55:49  iter: 48099  total_loss: 1.163  loss_cls: 0.2726  loss_box_reg: 0.3528  loss_mask: 0.2668  loss_rpn_cls: 0.08089  loss_rpn_loc: 0.1706  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:23:34 d2.utils.events]: \u001b[0m eta: 2:55:50  iter: 48119  total_loss: 1.209  loss_cls: 0.2886  loss_box_reg: 0.4089  loss_mask: 0.2706  loss_rpn_cls: 0.07296  loss_rpn_loc: 0.1734  time: 0.2238  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:23:38 d2.utils.events]: \u001b[0m eta: 2:55:43  iter: 48139  total_loss: 1.123  loss_cls: 0.2818  loss_box_reg: 0.4021  loss_mask: 0.265  loss_rpn_cls: 0.06664  loss_rpn_loc: 0.1499  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:23:43 d2.utils.events]: \u001b[0m eta: 2:55:41  iter: 48159  total_loss: 1.174  loss_cls: 0.2583  loss_box_reg: 0.3766  loss_mask: 0.2779  loss_rpn_cls: 0.07935  loss_rpn_loc: 0.1654  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:23:48 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.51 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 00:23:48 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 00:23:48 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 00:23:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 00:23:49 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 00:23:49 d2.data.common]: \u001b[0mSerialized dataset takes 84.20 MiB\n",
      "\u001b[32m[12/30 00:23:51 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.00 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 00:23:51 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 00:23:51 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 00:23:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/30 00:23:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0007 s/iter. Inference: 0.0619 s/iter. Eval: 0.1479 s/iter. Total: 0.2106 s/iter. ETA=0:01:57\n",
      "\u001b[32m[12/30 00:24:00 d2.evaluation.evaluator]: \u001b[0mInference done 39/570. Dataloading: 0.0008 s/iter. Inference: 0.0570 s/iter. Eval: 0.1264 s/iter. Total: 0.1842 s/iter. ETA=0:01:37\n",
      "\u001b[32m[12/30 00:24:05 d2.evaluation.evaluator]: \u001b[0mInference done 66/570. Dataloading: 0.0008 s/iter. Inference: 0.0580 s/iter. Eval: 0.1270 s/iter. Total: 0.1859 s/iter. ETA=0:01:33\n",
      "\u001b[32m[12/30 00:24:10 d2.evaluation.evaluator]: \u001b[0mInference done 91/570. Dataloading: 0.0008 s/iter. Inference: 0.0573 s/iter. Eval: 0.1319 s/iter. Total: 0.1901 s/iter. ETA=0:01:31\n",
      "\u001b[32m[12/30 00:24:15 d2.evaluation.evaluator]: \u001b[0mInference done 118/570. Dataloading: 0.0008 s/iter. Inference: 0.0560 s/iter. Eval: 0.1324 s/iter. Total: 0.1893 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/30 00:24:20 d2.evaluation.evaluator]: \u001b[0mInference done 143/570. Dataloading: 0.0008 s/iter. Inference: 0.0555 s/iter. Eval: 0.1355 s/iter. Total: 0.1919 s/iter. ETA=0:01:21\n",
      "\u001b[32m[12/30 00:24:25 d2.evaluation.evaluator]: \u001b[0mInference done 162/570. Dataloading: 0.0009 s/iter. Inference: 0.0558 s/iter. Eval: 0.1453 s/iter. Total: 0.2021 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 00:24:31 d2.evaluation.evaluator]: \u001b[0mInference done 175/570. Dataloading: 0.0009 s/iter. Inference: 0.0562 s/iter. Eval: 0.1610 s/iter. Total: 0.2181 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/30 00:24:36 d2.evaluation.evaluator]: \u001b[0mInference done 193/570. Dataloading: 0.0009 s/iter. Inference: 0.0564 s/iter. Eval: 0.1670 s/iter. Total: 0.2243 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/30 00:24:41 d2.evaluation.evaluator]: \u001b[0mInference done 209/570. Dataloading: 0.0009 s/iter. Inference: 0.0566 s/iter. Eval: 0.1742 s/iter. Total: 0.2318 s/iter. ETA=0:01:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:24:46 d2.evaluation.evaluator]: \u001b[0mInference done 225/570. Dataloading: 0.0009 s/iter. Inference: 0.0568 s/iter. Eval: 0.1801 s/iter. Total: 0.2379 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 00:24:51 d2.evaluation.evaluator]: \u001b[0mInference done 236/570. Dataloading: 0.0009 s/iter. Inference: 0.0569 s/iter. Eval: 0.1919 s/iter. Total: 0.2498 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 00:24:57 d2.evaluation.evaluator]: \u001b[0mInference done 249/570. Dataloading: 0.0009 s/iter. Inference: 0.0570 s/iter. Eval: 0.2015 s/iter. Total: 0.2594 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 00:25:03 d2.evaluation.evaluator]: \u001b[0mInference done 265/570. Dataloading: 0.0030 s/iter. Inference: 0.0572 s/iter. Eval: 0.2049 s/iter. Total: 0.2651 s/iter. ETA=0:01:20\n",
      "\u001b[32m[12/30 00:25:08 d2.evaluation.evaluator]: \u001b[0mInference done 283/570. Dataloading: 0.0028 s/iter. Inference: 0.0569 s/iter. Eval: 0.2066 s/iter. Total: 0.2665 s/iter. ETA=0:01:16\n",
      "\u001b[32m[12/30 00:25:13 d2.evaluation.evaluator]: \u001b[0mInference done 298/570. Dataloading: 0.0027 s/iter. Inference: 0.0570 s/iter. Eval: 0.2121 s/iter. Total: 0.2719 s/iter. ETA=0:01:13\n",
      "\u001b[32m[12/30 00:25:18 d2.evaluation.evaluator]: \u001b[0mInference done 346/570. Dataloading: 0.0025 s/iter. Inference: 0.0558 s/iter. Eval: 0.1903 s/iter. Total: 0.2486 s/iter. ETA=0:00:55\n",
      "\u001b[32m[12/30 00:25:24 d2.evaluation.evaluator]: \u001b[0mInference done 376/570. Dataloading: 0.0023 s/iter. Inference: 0.0554 s/iter. Eval: 0.1848 s/iter. Total: 0.2426 s/iter. ETA=0:00:47\n",
      "\u001b[32m[12/30 00:25:29 d2.evaluation.evaluator]: \u001b[0mInference done 398/570. Dataloading: 0.0023 s/iter. Inference: 0.0557 s/iter. Eval: 0.1840 s/iter. Total: 0.2420 s/iter. ETA=0:00:41\n",
      "\u001b[32m[12/30 00:25:34 d2.evaluation.evaluator]: \u001b[0mInference done 416/570. Dataloading: 0.0022 s/iter. Inference: 0.0559 s/iter. Eval: 0.1858 s/iter. Total: 0.2439 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/30 00:25:39 d2.evaluation.evaluator]: \u001b[0mInference done 436/570. Dataloading: 0.0021 s/iter. Inference: 0.0560 s/iter. Eval: 0.1864 s/iter. Total: 0.2446 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/30 00:25:44 d2.evaluation.evaluator]: \u001b[0mInference done 466/570. Dataloading: 0.0020 s/iter. Inference: 0.0558 s/iter. Eval: 0.1816 s/iter. Total: 0.2396 s/iter. ETA=0:00:24\n",
      "\u001b[32m[12/30 00:25:49 d2.evaluation.evaluator]: \u001b[0mInference done 494/570. Dataloading: 0.0029 s/iter. Inference: 0.0555 s/iter. Eval: 0.1778 s/iter. Total: 0.2362 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/30 00:25:54 d2.evaluation.evaluator]: \u001b[0mInference done 514/570. Dataloading: 0.0028 s/iter. Inference: 0.0553 s/iter. Eval: 0.1786 s/iter. Total: 0.2368 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/30 00:25:59 d2.evaluation.evaluator]: \u001b[0mInference done 538/570. Dataloading: 0.0027 s/iter. Inference: 0.0554 s/iter. Eval: 0.1776 s/iter. Total: 0.2359 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/30 00:26:05 d2.evaluation.evaluator]: \u001b[0mInference done 556/570. Dataloading: 0.0026 s/iter. Inference: 0.0556 s/iter. Eval: 0.1794 s/iter. Total: 0.2377 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 00:26:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:14.573927 (0.238184 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 00:26:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.055684 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 00:26:08 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/30 00:26:08 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2862461217327549\n",
      "\u001b[32m[12/30 00:26:11 d2.utils.events]: \u001b[0m eta: 2:55:42  iter: 48179  total_loss: 1.17  loss_cls: 0.3031  loss_box_reg: 0.3865  loss_mask: 0.2621  loss_rpn_cls: 0.06684  loss_rpn_loc: 0.1657  time: 0.2238  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:26:15 d2.utils.events]: \u001b[0m eta: 2:55:28  iter: 48199  total_loss: 1.124  loss_cls: 0.2723  loss_box_reg: 0.3891  loss_mask: 0.2368  loss_rpn_cls: 0.0628  loss_rpn_loc: 0.1522  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:26:20 d2.utils.events]: \u001b[0m eta: 2:55:26  iter: 48219  total_loss: 1.155  loss_cls: 0.2611  loss_box_reg: 0.3539  loss_mask: 0.2565  loss_rpn_cls: 0.09672  loss_rpn_loc: 0.1603  time: 0.2238  data_time: 0.0154  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:26:24 d2.utils.events]: \u001b[0m eta: 2:55:23  iter: 48239  total_loss: 1.161  loss_cls: 0.3012  loss_box_reg: 0.3721  loss_mask: 0.2612  loss_rpn_cls: 0.07619  loss_rpn_loc: 0.1723  time: 0.2238  data_time: 0.0240  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:26:29 d2.utils.events]: \u001b[0m eta: 2:55:23  iter: 48259  total_loss: 1.141  loss_cls: 0.2795  loss_box_reg: 0.3691  loss_mask: 0.2439  loss_rpn_cls: 0.06036  loss_rpn_loc: 0.1595  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:26:33 d2.utils.events]: \u001b[0m eta: 2:55:15  iter: 48279  total_loss: 1.293  loss_cls: 0.3405  loss_box_reg: 0.4584  loss_mask: 0.2698  loss_rpn_cls: 0.08089  loss_rpn_loc: 0.1725  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:26:38 d2.utils.events]: \u001b[0m eta: 2:55:04  iter: 48299  total_loss: 1.298  loss_cls: 0.3197  loss_box_reg: 0.4269  loss_mask: 0.2775  loss_rpn_cls: 0.09394  loss_rpn_loc: 0.1748  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:26:42 d2.utils.events]: \u001b[0m eta: 2:54:52  iter: 48319  total_loss: 1.142  loss_cls: 0.2813  loss_box_reg: 0.3505  loss_mask: 0.2519  loss_rpn_cls: 0.06726  loss_rpn_loc: 0.1629  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:26:47 d2.utils.events]: \u001b[0m eta: 2:54:45  iter: 48339  total_loss: 1.161  loss_cls: 0.272  loss_box_reg: 0.3451  loss_mask: 0.2518  loss_rpn_cls: 0.04938  loss_rpn_loc: 0.1635  time: 0.2238  data_time: 0.0142  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:26:51 d2.utils.events]: \u001b[0m eta: 2:54:32  iter: 48359  total_loss: 1.1  loss_cls: 0.2807  loss_box_reg: 0.3729  loss_mask: 0.2501  loss_rpn_cls: 0.0644  loss_rpn_loc: 0.161  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:26:55 d2.utils.events]: \u001b[0m eta: 2:54:20  iter: 48379  total_loss: 1.208  loss_cls: 0.3076  loss_box_reg: 0.3579  loss_mask: 0.2544  loss_rpn_cls: 0.08314  loss_rpn_loc: 0.177  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:28:25 d2.utils.events]: \u001b[0m eta: 2:52:58  iter: 48779  total_loss: 1.116  loss_cls: 0.2593  loss_box_reg: 0.3331  loss_mask: 0.2689  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.1747  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:28:30 d2.utils.events]: \u001b[0m eta: 2:52:41  iter: 48799  total_loss: 1.228  loss_cls: 0.3096  loss_box_reg: 0.3888  loss_mask: 0.2776  loss_rpn_cls: 0.09779  loss_rpn_loc: 0.17  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:28:35 d2.utils.events]: \u001b[0m eta: 2:52:56  iter: 48819  total_loss: 1.256  loss_cls: 0.322  loss_box_reg: 0.3923  loss_mask: 0.287  loss_rpn_cls: 0.1186  loss_rpn_loc: 0.2023  time: 0.2238  data_time: 0.0120  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:28:39 d2.utils.events]: \u001b[0m eta: 2:52:50  iter: 48839  total_loss: 1.174  loss_cls: 0.3005  loss_box_reg: 0.3893  loss_mask: 0.2568  loss_rpn_cls: 0.06461  loss_rpn_loc: 0.1611  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:28:44 d2.utils.events]: \u001b[0m eta: 2:52:56  iter: 48859  total_loss: 1.21  loss_cls: 0.3011  loss_box_reg: 0.3822  loss_mask: 0.2606  loss_rpn_cls: 0.08928  loss_rpn_loc: 0.1597  time: 0.2238  data_time: 0.0183  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:28:48 d2.utils.events]: \u001b[0m eta: 2:52:49  iter: 48879  total_loss: 1.156  loss_cls: 0.2749  loss_box_reg: 0.358  loss_mask: 0.2546  loss_rpn_cls: 0.05977  loss_rpn_loc: 0.1571  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:28:52 d2.utils.events]: \u001b[0m eta: 2:52:47  iter: 48899  total_loss: 1.263  loss_cls: 0.3236  loss_box_reg: 0.4017  loss_mask: 0.265  loss_rpn_cls: 0.08883  loss_rpn_loc: 0.1742  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:28:57 d2.utils.events]: \u001b[0m eta: 2:52:39  iter: 48919  total_loss: 1.215  loss_cls: 0.3077  loss_box_reg: 0.3932  loss_mask: 0.2743  loss_rpn_cls: 0.08808  loss_rpn_loc: 0.1697  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:29:01 d2.utils.events]: \u001b[0m eta: 2:52:34  iter: 48939  total_loss: 1.18  loss_cls: 0.3189  loss_box_reg: 0.4151  loss_mask: 0.2382  loss_rpn_cls: 0.0623  loss_rpn_loc: 0.15  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:29:06 d2.utils.events]: \u001b[0m eta: 2:52:30  iter: 48959  total_loss: 1.288  loss_cls: 0.3138  loss_box_reg: 0.3537  loss_mask: 0.2664  loss_rpn_cls: 0.08732  loss_rpn_loc: 0.1702  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:29:10 d2.utils.events]: \u001b[0m eta: 2:52:18  iter: 48979  total_loss: 1.134  loss_cls: 0.3073  loss_box_reg: 0.3649  loss_mask: 0.2243  loss_rpn_cls: 0.05641  loss_rpn_loc: 0.159  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:29:15 d2.utils.events]: \u001b[0m eta: 2:52:10  iter: 48999  total_loss: 1.243  loss_cls: 0.3042  loss_box_reg: 0.4136  loss_mask: 0.2553  loss_rpn_cls: 0.07243  loss_rpn_loc: 0.1875  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:29:19 d2.utils.events]: \u001b[0m eta: 2:52:05  iter: 49019  total_loss: 1.353  loss_cls: 0.3322  loss_box_reg: 0.3751  loss_mask: 0.2729  loss_rpn_cls: 0.09594  loss_rpn_loc: 0.1818  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:29:24 d2.utils.events]: \u001b[0m eta: 2:52:12  iter: 49039  total_loss: 1.174  loss_cls: 0.2858  loss_box_reg: 0.3957  loss_mask: 0.2595  loss_rpn_cls: 0.06648  loss_rpn_loc: 0.1714  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:29:28 d2.utils.events]: \u001b[0m eta: 2:52:10  iter: 49059  total_loss: 1.128  loss_cls: 0.2967  loss_box_reg: 0.3682  loss_mask: 0.2455  loss_rpn_cls: 0.06749  loss_rpn_loc: 0.1671  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:29:33 d2.utils.events]: \u001b[0m eta: 2:52:09  iter: 49079  total_loss: 1.057  loss_cls: 0.2439  loss_box_reg: 0.3281  loss_mask: 0.241  loss_rpn_cls: 0.07421  loss_rpn_loc: 0.1601  time: 0.2238  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:29:37 d2.utils.events]: \u001b[0m eta: 2:52:05  iter: 49099  total_loss: 1.137  loss_cls: 0.2652  loss_box_reg: 0.4156  loss_mask: 0.2734  loss_rpn_cls: 0.06985  loss_rpn_loc: 0.1797  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:29:41 d2.utils.events]: \u001b[0m eta: 2:52:00  iter: 49119  total_loss: 1.175  loss_cls: 0.3005  loss_box_reg: 0.4131  loss_mask: 0.2553  loss_rpn_cls: 0.06814  loss_rpn_loc: 0.1548  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:29:46 d2.utils.events]: \u001b[0m eta: 2:51:55  iter: 49139  total_loss: 1.234  loss_cls: 0.3048  loss_box_reg: 0.4202  loss_mask: 0.2596  loss_rpn_cls: 0.06871  loss_rpn_loc: 0.1553  time: 0.2238  data_time: 0.0185  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:29:51 d2.utils.events]: \u001b[0m eta: 2:51:48  iter: 49159  total_loss: 1.149  loss_cls: 0.2885  loss_box_reg: 0.3484  loss_mask: 0.265  loss_rpn_cls: 0.08132  loss_rpn_loc: 0.1626  time: 0.2238  data_time: 0.0152  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:29:55 d2.utils.events]: \u001b[0m eta: 2:51:44  iter: 49179  total_loss: 1.235  loss_cls: 0.316  loss_box_reg: 0.3604  loss_mask: 0.2658  loss_rpn_cls: 0.07992  loss_rpn_loc: 0.1841  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:30:00 d2.utils.events]: \u001b[0m eta: 2:51:56  iter: 49199  total_loss: 1.371  loss_cls: 0.3541  loss_box_reg: 0.3981  loss_mask: 0.2917  loss_rpn_cls: 0.07544  loss_rpn_loc: 0.1619  time: 0.2238  data_time: 0.0089  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:30:04 d2.utils.events]: \u001b[0m eta: 2:51:58  iter: 49219  total_loss: 1.187  loss_cls: 0.3004  loss_box_reg: 0.3552  loss_mask: 0.2562  loss_rpn_cls: 0.08719  loss_rpn_loc: 0.1647  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:30:09 d2.utils.events]: \u001b[0m eta: 2:51:56  iter: 49239  total_loss: 1.123  loss_cls: 0.2805  loss_box_reg: 0.3665  loss_mask: 0.2479  loss_rpn_cls: 0.05269  loss_rpn_loc: 0.1459  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:30:13 d2.utils.events]: \u001b[0m eta: 2:52:01  iter: 49259  total_loss: 1.209  loss_cls: 0.2816  loss_box_reg: 0.3605  loss_mask: 0.2786  loss_rpn_cls: 0.08027  loss_rpn_loc: 0.1746  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:30:18 d2.utils.events]: \u001b[0m eta: 2:52:24  iter: 49279  total_loss: 1.284  loss_cls: 0.3352  loss_box_reg: 0.4109  loss_mask: 0.262  loss_rpn_cls: 0.09094  loss_rpn_loc: 0.1823  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:30:22 d2.utils.events]: \u001b[0m eta: 2:51:57  iter: 49299  total_loss: 1.173  loss_cls: 0.2991  loss_box_reg: 0.3393  loss_mask: 0.2461  loss_rpn_cls: 0.06197  loss_rpn_loc: 0.1563  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:30:27 d2.utils.events]: \u001b[0m eta: 2:51:54  iter: 49319  total_loss: 1.085  loss_cls: 0.2672  loss_box_reg: 0.3674  loss_mask: 0.2504  loss_rpn_cls: 0.06866  loss_rpn_loc: 0.158  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:30:31 d2.utils.events]: \u001b[0m eta: 2:51:49  iter: 49339  total_loss: 1.094  loss_cls: 0.2761  loss_box_reg: 0.3587  loss_mask: 0.244  loss_rpn_cls: 0.05593  loss_rpn_loc: 0.1602  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:30:36 d2.utils.events]: \u001b[0m eta: 2:52:06  iter: 49359  total_loss: 1.227  loss_cls: 0.2954  loss_box_reg: 0.3997  loss_mask: 0.2681  loss_rpn_cls: 0.07794  loss_rpn_loc: 0.1762  time: 0.2238  data_time: 0.0270  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:30:41 d2.utils.events]: \u001b[0m eta: 2:52:02  iter: 49379  total_loss: 1.203  loss_cls: 0.3179  loss_box_reg: 0.4154  loss_mask: 0.2643  loss_rpn_cls: 0.0609  loss_rpn_loc: 0.1548  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:30:45 d2.utils.events]: \u001b[0m eta: 2:52:29  iter: 49399  total_loss: 1.11  loss_cls: 0.2446  loss_box_reg: 0.3605  loss_mask: 0.2487  loss_rpn_cls: 0.0794  loss_rpn_loc: 0.1583  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:30:50 d2.utils.events]: \u001b[0m eta: 2:52:42  iter: 49419  total_loss: 1.167  loss_cls: 0.2586  loss_box_reg: 0.3403  loss_mask: 0.2615  loss_rpn_cls: 0.06892  loss_rpn_loc: 0.1733  time: 0.2238  data_time: 0.0230  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:30:54 d2.utils.events]: \u001b[0m eta: 2:52:37  iter: 49439  total_loss: 1.215  loss_cls: 0.3145  loss_box_reg: 0.4164  loss_mask: 0.2726  loss_rpn_cls: 0.07248  loss_rpn_loc: 0.1524  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:30:59 d2.utils.events]: \u001b[0m eta: 2:52:23  iter: 49459  total_loss: 1.275  loss_cls: 0.3274  loss_box_reg: 0.4209  loss_mask: 0.264  loss_rpn_cls: 0.07147  loss_rpn_loc: 0.1694  time: 0.2238  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:31:04 d2.utils.events]: \u001b[0m eta: 2:52:29  iter: 49479  total_loss: 1.202  loss_cls: 0.2703  loss_box_reg: 0.3882  loss_mask: 0.2722  loss_rpn_cls: 0.0979  loss_rpn_loc: 0.164  time: 0.2238  data_time: 0.0231  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:31:08 d2.utils.events]: \u001b[0m eta: 2:52:07  iter: 49499  total_loss: 1.26  loss_cls: 0.3081  loss_box_reg: 0.4233  loss_mask: 0.2707  loss_rpn_cls: 0.09853  loss_rpn_loc: 0.1676  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:31:12 d2.utils.events]: \u001b[0m eta: 2:52:02  iter: 49519  total_loss: 1.128  loss_cls: 0.282  loss_box_reg: 0.3676  loss_mask: 0.2595  loss_rpn_cls: 0.06987  loss_rpn_loc: 0.1684  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:31:17 d2.utils.events]: \u001b[0m eta: 2:52:05  iter: 49539  total_loss: 1.089  loss_cls: 0.2511  loss_box_reg: 0.3467  loss_mask: 0.2548  loss_rpn_cls: 0.05619  loss_rpn_loc: 0.1651  time: 0.2238  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:31:21 d2.utils.events]: \u001b[0m eta: 2:51:53  iter: 49559  total_loss: 1.099  loss_cls: 0.2653  loss_box_reg: 0.3646  loss_mask: 0.2398  loss_rpn_cls: 0.05479  loss_rpn_loc: 0.165  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:31:26 d2.utils.events]: \u001b[0m eta: 2:51:54  iter: 49579  total_loss: 1.174  loss_cls: 0.2925  loss_box_reg: 0.3913  loss_mask: 0.2707  loss_rpn_cls: 0.08177  loss_rpn_loc: 0.1722  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:31:30 d2.utils.events]: \u001b[0m eta: 2:51:16  iter: 49599  total_loss: 1.325  loss_cls: 0.3445  loss_box_reg: 0.4123  loss_mask: 0.2745  loss_rpn_cls: 0.1026  loss_rpn_loc: 0.1813  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:31:35 d2.utils.events]: \u001b[0m eta: 2:51:09  iter: 49619  total_loss: 1.15  loss_cls: 0.2602  loss_box_reg: 0.3903  loss_mask: 0.2577  loss_rpn_cls: 0.0632  loss_rpn_loc: 0.1628  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:31:39 d2.utils.events]: \u001b[0m eta: 2:51:11  iter: 49639  total_loss: 1.264  loss_cls: 0.2963  loss_box_reg: 0.4249  loss_mask: 0.2591  loss_rpn_cls: 0.05671  loss_rpn_loc: 0.1649  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:31:44 d2.utils.events]: \u001b[0m eta: 2:51:06  iter: 49659  total_loss: 1.216  loss_cls: 0.3099  loss_box_reg: 0.3472  loss_mask: 0.2646  loss_rpn_cls: 0.08966  loss_rpn_loc: 0.171  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:31:48 d2.utils.events]: \u001b[0m eta: 2:51:02  iter: 49679  total_loss: 1.215  loss_cls: 0.2979  loss_box_reg: 0.3689  loss_mask: 0.2712  loss_rpn_cls: 0.08113  loss_rpn_loc: 0.1789  time: 0.2238  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:31:53 d2.utils.events]: \u001b[0m eta: 2:50:31  iter: 49699  total_loss: 1.167  loss_cls: 0.3109  loss_box_reg: 0.3607  loss_mask: 0.2596  loss_rpn_cls: 0.06474  loss_rpn_loc: 0.1529  time: 0.2238  data_time: 0.0167  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:31:57 d2.utils.events]: \u001b[0m eta: 2:50:24  iter: 49719  total_loss: 1.096  loss_cls: 0.2655  loss_box_reg: 0.352  loss_mask: 0.2489  loss_rpn_cls: 0.06231  loss_rpn_loc: 0.1589  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:32:01 d2.utils.events]: \u001b[0m eta: 2:50:07  iter: 49739  total_loss: 1.134  loss_cls: 0.2881  loss_box_reg: 0.3658  loss_mask: 0.2525  loss_rpn_cls: 0.06521  loss_rpn_loc: 0.1581  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:32:06 d2.utils.events]: \u001b[0m eta: 2:50:27  iter: 49759  total_loss: 1.196  loss_cls: 0.2829  loss_box_reg: 0.3526  loss_mask: 0.256  loss_rpn_cls: 0.09172  loss_rpn_loc: 0.1631  time: 0.2238  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:32:10 d2.utils.events]: \u001b[0m eta: 2:50:13  iter: 49779  total_loss: 1.134  loss_cls: 0.287  loss_box_reg: 0.364  loss_mask: 0.249  loss_rpn_cls: 0.06274  loss_rpn_loc: 0.1666  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:32:15 d2.utils.events]: \u001b[0m eta: 2:50:09  iter: 49799  total_loss: 1.215  loss_cls: 0.2985  loss_box_reg: 0.3731  loss_mask: 0.2565  loss_rpn_cls: 0.07387  loss_rpn_loc: 0.1591  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:32:20 d2.utils.events]: \u001b[0m eta: 2:49:50  iter: 49819  total_loss: 1.283  loss_cls: 0.3335  loss_box_reg: 0.3828  loss_mask: 0.2874  loss_rpn_cls: 0.09223  loss_rpn_loc: 0.1785  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:32:24 d2.utils.events]: \u001b[0m eta: 2:50:00  iter: 49839  total_loss: 1.038  loss_cls: 0.2537  loss_box_reg: 0.3497  loss_mask: 0.2518  loss_rpn_cls: 0.0511  loss_rpn_loc: 0.1402  time: 0.2238  data_time: 0.0129  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:32:29 d2.utils.events]: \u001b[0m eta: 2:49:35  iter: 49859  total_loss: 1.23  loss_cls: 0.3232  loss_box_reg: 0.3791  loss_mask: 0.2522  loss_rpn_cls: 0.09323  loss_rpn_loc: 0.1636  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:32:33 d2.utils.events]: \u001b[0m eta: 2:49:54  iter: 49879  total_loss: 1.156  loss_cls: 0.2999  loss_box_reg: 0.356  loss_mask: 0.2755  loss_rpn_cls: 0.08702  loss_rpn_loc: 0.168  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:32:38 d2.utils.events]: \u001b[0m eta: 2:49:40  iter: 49899  total_loss: 1.307  loss_cls: 0.2903  loss_box_reg: 0.418  loss_mask: 0.2739  loss_rpn_cls: 0.07744  loss_rpn_loc: 0.173  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:32:42 d2.utils.events]: \u001b[0m eta: 2:49:42  iter: 49919  total_loss: 1.3  loss_cls: 0.3209  loss_box_reg: 0.4012  loss_mask: 0.2843  loss_rpn_cls: 0.08805  loss_rpn_loc: 0.1697  time: 0.2238  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:32:47 d2.utils.events]: \u001b[0m eta: 2:49:38  iter: 49939  total_loss: 1.206  loss_cls: 0.2929  loss_box_reg: 0.3897  loss_mask: 0.2599  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.1606  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:32:51 d2.utils.events]: \u001b[0m eta: 2:49:31  iter: 49959  total_loss: 1.273  loss_cls: 0.3019  loss_box_reg: 0.4021  loss_mask: 0.2675  loss_rpn_cls: 0.06844  loss_rpn_loc: 0.1716  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:32:56 d2.utils.events]: \u001b[0m eta: 2:49:29  iter: 49979  total_loss: 1.205  loss_cls: 0.276  loss_box_reg: 0.3753  loss_mask: 0.2551  loss_rpn_cls: 0.08459  loss_rpn_loc: 0.173  time: 0.2238  data_time: 0.0194  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:33:00 d2.utils.events]: \u001b[0m eta: 2:49:18  iter: 49999  total_loss: 1.23  loss_cls: 0.3183  loss_box_reg: 0.4193  loss_mask: 0.2528  loss_rpn_cls: 0.0762  loss_rpn_loc: 0.1584  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:33:05 d2.utils.events]: \u001b[0m eta: 2:49:06  iter: 50019  total_loss: 1.167  loss_cls: 0.3218  loss_box_reg: 0.3725  loss_mask: 0.2651  loss_rpn_cls: 0.08205  loss_rpn_loc: 0.1641  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:33:09 d2.utils.events]: \u001b[0m eta: 2:49:02  iter: 50039  total_loss: 1.363  loss_cls: 0.3423  loss_box_reg: 0.4085  loss_mask: 0.2881  loss_rpn_cls: 0.0986  loss_rpn_loc: 0.1794  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:33:14 d2.utils.events]: \u001b[0m eta: 2:48:58  iter: 50059  total_loss: 1.038  loss_cls: 0.235  loss_box_reg: 0.2899  loss_mask: 0.2485  loss_rpn_cls: 0.06212  loss_rpn_loc: 0.1575  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:33:18 d2.utils.events]: \u001b[0m eta: 2:48:44  iter: 50079  total_loss: 1.086  loss_cls: 0.2576  loss_box_reg: 0.3532  loss_mask: 0.2545  loss_rpn_cls: 0.0829  loss_rpn_loc: 0.1487  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:33:23 d2.utils.events]: \u001b[0m eta: 2:48:21  iter: 50099  total_loss: 1.237  loss_cls: 0.306  loss_box_reg: 0.4159  loss_mask: 0.2611  loss_rpn_cls: 0.07441  loss_rpn_loc: 0.155  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:33:27 d2.utils.events]: \u001b[0m eta: 2:48:17  iter: 50119  total_loss: 1.044  loss_cls: 0.2456  loss_box_reg: 0.3417  loss_mask: 0.2405  loss_rpn_cls: 0.05761  loss_rpn_loc: 0.1662  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:33:31 d2.utils.events]: \u001b[0m eta: 2:48:13  iter: 50139  total_loss: 1.193  loss_cls: 0.272  loss_box_reg: 0.4076  loss_mask: 0.2518  loss_rpn_cls: 0.08523  loss_rpn_loc: 0.1667  time: 0.2238  data_time: 0.0152  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:33:36 d2.utils.events]: \u001b[0m eta: 2:48:08  iter: 50159  total_loss: 1.115  loss_cls: 0.2795  loss_box_reg: 0.3706  loss_mask: 0.2446  loss_rpn_cls: 0.04768  loss_rpn_loc: 0.1545  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:33:40 d2.utils.events]: \u001b[0m eta: 2:47:51  iter: 50179  total_loss: 1.187  loss_cls: 0.2891  loss_box_reg: 0.3867  loss_mask: 0.2634  loss_rpn_cls: 0.06981  loss_rpn_loc: 0.1519  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:33:44 d2.utils.events]: \u001b[0m eta: 2:47:32  iter: 50199  total_loss: 1.156  loss_cls: 0.2625  loss_box_reg: 0.4162  loss_mask: 0.2644  loss_rpn_cls: 0.04952  loss_rpn_loc: 0.1449  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:33:49 d2.utils.events]: \u001b[0m eta: 2:47:27  iter: 50219  total_loss: 1.188  loss_cls: 0.2708  loss_box_reg: 0.3459  loss_mask: 0.2692  loss_rpn_cls: 0.09972  loss_rpn_loc: 0.1877  time: 0.2238  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:33:53 d2.utils.events]: \u001b[0m eta: 2:47:21  iter: 50239  total_loss: 1.274  loss_cls: 0.3137  loss_box_reg: 0.4121  loss_mask: 0.2956  loss_rpn_cls: 0.08014  loss_rpn_loc: 0.1647  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:33:58 d2.utils.events]: \u001b[0m eta: 2:47:10  iter: 50259  total_loss: 1.138  loss_cls: 0.2903  loss_box_reg: 0.3755  loss_mask: 0.2293  loss_rpn_cls: 0.09799  loss_rpn_loc: 0.1631  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:34:02 d2.utils.events]: \u001b[0m eta: 2:46:59  iter: 50279  total_loss: 1.185  loss_cls: 0.2761  loss_box_reg: 0.3688  loss_mask: 0.28  loss_rpn_cls: 0.07469  loss_rpn_loc: 0.1692  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:34:07 d2.utils.events]: \u001b[0m eta: 2:47:17  iter: 50299  total_loss: 1.219  loss_cls: 0.2943  loss_box_reg: 0.4302  loss_mask: 0.274  loss_rpn_cls: 0.07804  loss_rpn_loc: 0.1618  time: 0.2238  data_time: 0.0156  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:34:12 d2.utils.events]: \u001b[0m eta: 2:47:06  iter: 50319  total_loss: 1.27  loss_cls: 0.3104  loss_box_reg: 0.4038  loss_mask: 0.2682  loss_rpn_cls: 0.07066  loss_rpn_loc: 0.155  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:34:16 d2.utils.events]: \u001b[0m eta: 2:47:07  iter: 50339  total_loss: 1.25  loss_cls: 0.3315  loss_box_reg: 0.404  loss_mask: 0.2959  loss_rpn_cls: 0.109  loss_rpn_loc: 0.1703  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:34:20 d2.utils.events]: \u001b[0m eta: 2:46:35  iter: 50359  total_loss: 1.171  loss_cls: 0.2929  loss_box_reg: 0.3637  loss_mask: 0.2488  loss_rpn_cls: 0.06828  loss_rpn_loc: 0.1766  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:34:25 d2.utils.events]: \u001b[0m eta: 2:46:36  iter: 50379  total_loss: 1.108  loss_cls: 0.2677  loss_box_reg: 0.3756  loss_mask: 0.2485  loss_rpn_cls: 0.06344  loss_rpn_loc: 0.1542  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:34:29 d2.utils.events]: \u001b[0m eta: 2:46:23  iter: 50399  total_loss: 1.196  loss_cls: 0.278  loss_box_reg: 0.3781  loss_mask: 0.2597  loss_rpn_cls: 0.06996  loss_rpn_loc: 0.1528  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:34:34 d2.utils.events]: \u001b[0m eta: 2:46:07  iter: 50419  total_loss: 1.164  loss_cls: 0.2926  loss_box_reg: 0.4013  loss_mask: 0.2715  loss_rpn_cls: 0.06115  loss_rpn_loc: 0.172  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:34:38 d2.utils.events]: \u001b[0m eta: 2:46:03  iter: 50439  total_loss: 1.094  loss_cls: 0.2356  loss_box_reg: 0.3517  loss_mask: 0.2426  loss_rpn_cls: 0.06987  loss_rpn_loc: 0.1626  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:34:42 d2.utils.events]: \u001b[0m eta: 2:46:13  iter: 50459  total_loss: 1.317  loss_cls: 0.332  loss_box_reg: 0.42  loss_mask: 0.281  loss_rpn_cls: 0.07588  loss_rpn_loc: 0.1763  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:34:47 d2.utils.events]: \u001b[0m eta: 2:46:09  iter: 50479  total_loss: 1.168  loss_cls: 0.2905  loss_box_reg: 0.4234  loss_mask: 0.2642  loss_rpn_cls: 0.06498  loss_rpn_loc: 0.1472  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:34:52 d2.utils.events]: \u001b[0m eta: 2:46:18  iter: 50499  total_loss: 1.11  loss_cls: 0.2481  loss_box_reg: 0.3133  loss_mask: 0.256  loss_rpn_cls: 0.08024  loss_rpn_loc: 0.16  time: 0.2238  data_time: 0.0169  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:34:56 d2.utils.events]: \u001b[0m eta: 2:45:57  iter: 50519  total_loss: 1.23  loss_cls: 0.3107  loss_box_reg: 0.4092  loss_mask: 0.2589  loss_rpn_cls: 0.08831  loss_rpn_loc: 0.1619  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:35:00 d2.utils.events]: \u001b[0m eta: 2:45:46  iter: 50539  total_loss: 1.184  loss_cls: 0.274  loss_box_reg: 0.3785  loss_mask: 0.2665  loss_rpn_cls: 0.09076  loss_rpn_loc: 0.1804  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:35:05 d2.utils.events]: \u001b[0m eta: 2:45:43  iter: 50559  total_loss: 1.224  loss_cls: 0.3106  loss_box_reg: 0.3725  loss_mask: 0.2778  loss_rpn_cls: 0.07612  loss_rpn_loc: 0.1624  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:35:09 d2.utils.events]: \u001b[0m eta: 2:45:39  iter: 50579  total_loss: 1.103  loss_cls: 0.2222  loss_box_reg: 0.3436  loss_mask: 0.2505  loss_rpn_cls: 0.05479  loss_rpn_loc: 0.1399  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:35:14 d2.utils.events]: \u001b[0m eta: 2:45:40  iter: 50599  total_loss: 1.14  loss_cls: 0.2772  loss_box_reg: 0.3579  loss_mask: 0.2568  loss_rpn_cls: 0.08608  loss_rpn_loc: 0.1642  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:35:18 d2.utils.events]: \u001b[0m eta: 2:45:46  iter: 50619  total_loss: 1.203  loss_cls: 0.2909  loss_box_reg: 0.3927  loss_mask: 0.2538  loss_rpn_cls: 0.06498  loss_rpn_loc: 0.1618  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:35:23 d2.utils.events]: \u001b[0m eta: 2:45:40  iter: 50639  total_loss: 1.068  loss_cls: 0.2908  loss_box_reg: 0.3718  loss_mask: 0.2479  loss_rpn_cls: 0.06547  loss_rpn_loc: 0.1626  time: 0.2238  data_time: 0.0136  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:35:27 d2.utils.events]: \u001b[0m eta: 2:45:35  iter: 50659  total_loss: 1.148  loss_cls: 0.2809  loss_box_reg: 0.3638  loss_mask: 0.2684  loss_rpn_cls: 0.06298  loss_rpn_loc: 0.1476  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:35:32 d2.utils.events]: \u001b[0m eta: 2:45:33  iter: 50679  total_loss: 1.252  loss_cls: 0.3183  loss_box_reg: 0.3851  loss_mask: 0.2957  loss_rpn_cls: 0.08537  loss_rpn_loc: 0.1896  time: 0.2238  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:35:36 d2.utils.events]: \u001b[0m eta: 2:45:38  iter: 50699  total_loss: 1.063  loss_cls: 0.2482  loss_box_reg: 0.3586  loss_mask: 0.2616  loss_rpn_cls: 0.05975  loss_rpn_loc: 0.1738  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:35:41 d2.utils.events]: \u001b[0m eta: 2:45:42  iter: 50719  total_loss: 1.033  loss_cls: 0.257  loss_box_reg: 0.349  loss_mask: 0.2296  loss_rpn_cls: 0.07596  loss_rpn_loc: 0.1487  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:35:46 d2.utils.events]: \u001b[0m eta: 2:45:37  iter: 50739  total_loss: 1.128  loss_cls: 0.2815  loss_box_reg: 0.373  loss_mask: 0.2739  loss_rpn_cls: 0.06489  loss_rpn_loc: 0.156  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:35:50 d2.utils.events]: \u001b[0m eta: 2:45:20  iter: 50759  total_loss: 1.155  loss_cls: 0.2715  loss_box_reg: 0.3648  loss_mask: 0.2582  loss_rpn_cls: 0.06401  loss_rpn_loc: 0.1479  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:35:54 d2.utils.events]: \u001b[0m eta: 2:45:21  iter: 50779  total_loss: 1.203  loss_cls: 0.2969  loss_box_reg: 0.3759  loss_mask: 0.2675  loss_rpn_cls: 0.1027  loss_rpn_loc: 0.169  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:35:59 d2.utils.events]: \u001b[0m eta: 2:45:17  iter: 50799  total_loss: 1.151  loss_cls: 0.2915  loss_box_reg: 0.3902  loss_mask: 0.2601  loss_rpn_cls: 0.06641  loss_rpn_loc: 0.1759  time: 0.2238  data_time: 0.0148  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:36:03 d2.utils.events]: \u001b[0m eta: 2:45:11  iter: 50819  total_loss: 1.14  loss_cls: 0.2955  loss_box_reg: 0.3804  loss_mask: 0.2476  loss_rpn_cls: 0.08852  loss_rpn_loc: 0.1815  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:36:08 d2.utils.events]: \u001b[0m eta: 2:44:55  iter: 50839  total_loss: 1.092  loss_cls: 0.2638  loss_box_reg: 0.342  loss_mask: 0.2525  loss_rpn_cls: 0.06879  loss_rpn_loc: 0.1652  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:36:12 d2.utils.events]: \u001b[0m eta: 2:44:56  iter: 50859  total_loss: 1.2  loss_cls: 0.3221  loss_box_reg: 0.408  loss_mask: 0.271  loss_rpn_cls: 0.08111  loss_rpn_loc: 0.1511  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:36:17 d2.utils.events]: \u001b[0m eta: 2:44:49  iter: 50879  total_loss: 1.261  loss_cls: 0.3251  loss_box_reg: 0.394  loss_mask: 0.2863  loss_rpn_cls: 0.08365  loss_rpn_loc: 0.1658  time: 0.2238  data_time: 0.0188  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:36:21 d2.utils.events]: \u001b[0m eta: 2:44:41  iter: 50899  total_loss: 1.124  loss_cls: 0.3035  loss_box_reg: 0.3819  loss_mask: 0.2295  loss_rpn_cls: 0.04954  loss_rpn_loc: 0.15  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:36:26 d2.utils.events]: \u001b[0m eta: 2:44:32  iter: 50919  total_loss: 1.146  loss_cls: 0.3152  loss_box_reg: 0.3778  loss_mask: 0.2479  loss_rpn_cls: 0.05939  loss_rpn_loc: 0.1498  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:36:30 d2.utils.events]: \u001b[0m eta: 2:44:32  iter: 50939  total_loss: 1.237  loss_cls: 0.3029  loss_box_reg: 0.3896  loss_mask: 0.2651  loss_rpn_cls: 0.07609  loss_rpn_loc: 0.17  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:36:35 d2.utils.events]: \u001b[0m eta: 2:44:16  iter: 50959  total_loss: 1.099  loss_cls: 0.2958  loss_box_reg: 0.3999  loss_mask: 0.254  loss_rpn_cls: 0.05372  loss_rpn_loc: 0.1553  time: 0.2238  data_time: 0.0056  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:36:39 d2.utils.events]: \u001b[0m eta: 2:44:15  iter: 50979  total_loss: 1.274  loss_cls: 0.3123  loss_box_reg: 0.3956  loss_mask: 0.2799  loss_rpn_cls: 0.08992  loss_rpn_loc: 0.1774  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:36:43 d2.utils.events]: \u001b[0m eta: 2:44:15  iter: 50999  total_loss: 1.254  loss_cls: 0.3338  loss_box_reg: 0.3572  loss_mask: 0.2642  loss_rpn_cls: 0.08509  loss_rpn_loc: 0.1767  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:36:48 d2.utils.events]: \u001b[0m eta: 2:44:11  iter: 51019  total_loss: 1.142  loss_cls: 0.2854  loss_box_reg: 0.3783  loss_mask: 0.2784  loss_rpn_cls: 0.09332  loss_rpn_loc: 0.1558  time: 0.2238  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:36:53 d2.utils.events]: \u001b[0m eta: 2:44:00  iter: 51039  total_loss: 1.19  loss_cls: 0.2743  loss_box_reg: 0.373  loss_mask: 0.2642  loss_rpn_cls: 0.07132  loss_rpn_loc: 0.1728  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:36:57 d2.utils.events]: \u001b[0m eta: 2:44:06  iter: 51059  total_loss: 1.194  loss_cls: 0.3199  loss_box_reg: 0.3917  loss_mask: 0.2686  loss_rpn_cls: 0.0728  loss_rpn_loc: 0.1503  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:37:02 d2.utils.events]: \u001b[0m eta: 2:44:13  iter: 51079  total_loss: 1.189  loss_cls: 0.2907  loss_box_reg: 0.3918  loss_mask: 0.2468  loss_rpn_cls: 0.08142  loss_rpn_loc: 0.1581  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:37:06 d2.utils.events]: \u001b[0m eta: 2:44:18  iter: 51099  total_loss: 1.141  loss_cls: 0.2813  loss_box_reg: 0.3747  loss_mask: 0.2512  loss_rpn_cls: 0.06452  loss_rpn_loc: 0.1597  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:37:11 d2.utils.events]: \u001b[0m eta: 2:44:14  iter: 51119  total_loss: 1.047  loss_cls: 0.2455  loss_box_reg: 0.3142  loss_mask: 0.2583  loss_rpn_cls: 0.07223  loss_rpn_loc: 0.1567  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:37:15 d2.utils.events]: \u001b[0m eta: 2:44:10  iter: 51139  total_loss: 1.278  loss_cls: 0.3247  loss_box_reg: 0.4136  loss_mask: 0.2731  loss_rpn_cls: 0.08369  loss_rpn_loc: 0.1678  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:37:20 d2.utils.events]: \u001b[0m eta: 2:44:07  iter: 51159  total_loss: 1.154  loss_cls: 0.2772  loss_box_reg: 0.3687  loss_mask: 0.2493  loss_rpn_cls: 0.05894  loss_rpn_loc: 0.1672  time: 0.2238  data_time: 0.0205  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:37:24 d2.utils.events]: \u001b[0m eta: 2:44:10  iter: 51179  total_loss: 1.196  loss_cls: 0.3093  loss_box_reg: 0.3876  loss_mask: 0.2807  loss_rpn_cls: 0.07693  loss_rpn_loc: 0.1806  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:37:29 d2.utils.events]: \u001b[0m eta: 2:44:14  iter: 51199  total_loss: 1.183  loss_cls: 0.2786  loss_box_reg: 0.375  loss_mask: 0.2676  loss_rpn_cls: 0.06998  loss_rpn_loc: 0.1628  time: 0.2238  data_time: 0.0166  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:37:33 d2.utils.events]: \u001b[0m eta: 2:43:55  iter: 51219  total_loss: 1.071  loss_cls: 0.2747  loss_box_reg: 0.3769  loss_mask: 0.2531  loss_rpn_cls: 0.05335  loss_rpn_loc: 0.1486  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:37:38 d2.utils.events]: \u001b[0m eta: 2:44:06  iter: 51239  total_loss: 1.074  loss_cls: 0.274  loss_box_reg: 0.3441  loss_mask: 0.2416  loss_rpn_cls: 0.05159  loss_rpn_loc: 0.1471  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:37:42 d2.utils.events]: \u001b[0m eta: 2:43:46  iter: 51259  total_loss: 1.23  loss_cls: 0.2958  loss_box_reg: 0.3879  loss_mask: 0.2578  loss_rpn_cls: 0.0719  loss_rpn_loc: 0.183  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:37:47 d2.utils.events]: \u001b[0m eta: 2:43:39  iter: 51279  total_loss: 1.148  loss_cls: 0.2788  loss_box_reg: 0.3624  loss_mask: 0.2698  loss_rpn_cls: 0.07114  loss_rpn_loc: 0.1697  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:37:51 d2.utils.events]: \u001b[0m eta: 2:43:35  iter: 51299  total_loss: 1.227  loss_cls: 0.331  loss_box_reg: 0.3777  loss_mask: 0.2631  loss_rpn_cls: 0.08286  loss_rpn_loc: 0.1744  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:37:56 d2.utils.events]: \u001b[0m eta: 2:43:32  iter: 51319  total_loss: 1.17  loss_cls: 0.3043  loss_box_reg: 0.3743  loss_mask: 0.2552  loss_rpn_cls: 0.06994  loss_rpn_loc: 0.1631  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:38:00 d2.utils.events]: \u001b[0m eta: 2:43:27  iter: 51339  total_loss: 1.238  loss_cls: 0.2944  loss_box_reg: 0.3975  loss_mask: 0.2462  loss_rpn_cls: 0.07055  loss_rpn_loc: 0.1828  time: 0.2238  data_time: 0.0089  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:38:04 d2.utils.events]: \u001b[0m eta: 2:43:34  iter: 51359  total_loss: 1.027  loss_cls: 0.2366  loss_box_reg: 0.3531  loss_mask: 0.2467  loss_rpn_cls: 0.06331  loss_rpn_loc: 0.1557  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:38:09 d2.utils.events]: \u001b[0m eta: 2:43:19  iter: 51379  total_loss: 1.166  loss_cls: 0.3044  loss_box_reg: 0.3467  loss_mask: 0.2666  loss_rpn_cls: 0.08187  loss_rpn_loc: 0.1539  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:38:13 d2.utils.events]: \u001b[0m eta: 2:43:14  iter: 51399  total_loss: 1.102  loss_cls: 0.2632  loss_box_reg: 0.388  loss_mask: 0.2583  loss_rpn_cls: 0.08516  loss_rpn_loc: 0.1637  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:38:17 d2.utils.events]: \u001b[0m eta: 2:43:13  iter: 51419  total_loss: 1.175  loss_cls: 0.2703  loss_box_reg: 0.3734  loss_mask: 0.2645  loss_rpn_cls: 0.05717  loss_rpn_loc: 0.165  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:38:22 d2.utils.events]: \u001b[0m eta: 2:43:45  iter: 51439  total_loss: 1.211  loss_cls: 0.2667  loss_box_reg: 0.3592  loss_mask: 0.261  loss_rpn_cls: 0.08096  loss_rpn_loc: 0.1926  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:38:27 d2.utils.events]: \u001b[0m eta: 2:43:45  iter: 51459  total_loss: 1.271  loss_cls: 0.3183  loss_box_reg: 0.3815  loss_mask: 0.2887  loss_rpn_cls: 0.1079  loss_rpn_loc: 0.1886  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:38:31 d2.utils.events]: \u001b[0m eta: 2:43:36  iter: 51479  total_loss: 1.21  loss_cls: 0.3375  loss_box_reg: 0.4315  loss_mask: 0.2538  loss_rpn_cls: 0.06333  loss_rpn_loc: 0.1521  time: 0.2238  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:38:35 d2.utils.events]: \u001b[0m eta: 2:43:18  iter: 51499  total_loss: 1.299  loss_cls: 0.328  loss_box_reg: 0.3919  loss_mask: 0.2786  loss_rpn_cls: 0.08713  loss_rpn_loc: 0.1696  time: 0.2238  data_time: 0.0176  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:38:40 d2.utils.events]: \u001b[0m eta: 2:43:28  iter: 51519  total_loss: 1.161  loss_cls: 0.2969  loss_box_reg: 0.3312  loss_mask: 0.2696  loss_rpn_cls: 0.08185  loss_rpn_loc: 0.1684  time: 0.2238  data_time: 0.0143  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:38:45 d2.utils.events]: \u001b[0m eta: 2:43:36  iter: 51539  total_loss: 1.145  loss_cls: 0.221  loss_box_reg: 0.3377  loss_mask: 0.2532  loss_rpn_cls: 0.0656  loss_rpn_loc: 0.1705  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:38:49 d2.utils.events]: \u001b[0m eta: 2:43:24  iter: 51559  total_loss: 1.079  loss_cls: 0.25  loss_box_reg: 0.3401  loss_mask: 0.2389  loss_rpn_cls: 0.06581  loss_rpn_loc: 0.1624  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:38:53 d2.utils.events]: \u001b[0m eta: 2:43:12  iter: 51579  total_loss: 1.221  loss_cls: 0.3008  loss_box_reg: 0.3789  loss_mask: 0.2724  loss_rpn_cls: 0.06949  loss_rpn_loc: 0.1526  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:38:58 d2.utils.events]: \u001b[0m eta: 2:43:07  iter: 51599  total_loss: 1.166  loss_cls: 0.2865  loss_box_reg: 0.375  loss_mask: 0.2695  loss_rpn_cls: 0.095  loss_rpn_loc: 0.161  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:39:02 d2.utils.events]: \u001b[0m eta: 2:43:10  iter: 51619  total_loss: 1.24  loss_cls: 0.3187  loss_box_reg: 0.3912  loss_mask: 0.2647  loss_rpn_cls: 0.07922  loss_rpn_loc: 0.169  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:39:07 d2.utils.events]: \u001b[0m eta: 2:43:09  iter: 51639  total_loss: 1.243  loss_cls: 0.2952  loss_box_reg: 0.3933  loss_mask: 0.2643  loss_rpn_cls: 0.08527  loss_rpn_loc: 0.1634  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:39:12 d2.utils.events]: \u001b[0m eta: 2:43:12  iter: 51659  total_loss: 1.101  loss_cls: 0.2733  loss_box_reg: 0.3697  loss_mask: 0.2536  loss_rpn_cls: 0.05861  loss_rpn_loc: 0.1692  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:39:16 d2.utils.events]: \u001b[0m eta: 2:43:07  iter: 51679  total_loss: 1.178  loss_cls: 0.2722  loss_box_reg: 0.3831  loss_mask: 0.2562  loss_rpn_cls: 0.07927  loss_rpn_loc: 0.18  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:39:21 d2.utils.events]: \u001b[0m eta: 2:43:04  iter: 51699  total_loss: 1.163  loss_cls: 0.2818  loss_box_reg: 0.3452  loss_mask: 0.2478  loss_rpn_cls: 0.08109  loss_rpn_loc: 0.157  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:39:25 d2.utils.events]: \u001b[0m eta: 2:42:55  iter: 51719  total_loss: 1.107  loss_cls: 0.286  loss_box_reg: 0.3507  loss_mask: 0.2614  loss_rpn_cls: 0.08006  loss_rpn_loc: 0.1612  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:39:29 d2.utils.events]: \u001b[0m eta: 2:42:47  iter: 51739  total_loss: 1.175  loss_cls: 0.2915  loss_box_reg: 0.4104  loss_mask: 0.2645  loss_rpn_cls: 0.07171  loss_rpn_loc: 0.1611  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:39:34 d2.utils.events]: \u001b[0m eta: 2:42:42  iter: 51759  total_loss: 1.076  loss_cls: 0.2378  loss_box_reg: 0.3247  loss_mask: 0.248  loss_rpn_cls: 0.08662  loss_rpn_loc: 0.1637  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:39:38 d2.utils.events]: \u001b[0m eta: 2:42:42  iter: 51779  total_loss: 1.162  loss_cls: 0.313  loss_box_reg: 0.3713  loss_mask: 0.2473  loss_rpn_cls: 0.07456  loss_rpn_loc: 0.1586  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:39:43 d2.utils.events]: \u001b[0m eta: 2:42:34  iter: 51799  total_loss: 1.192  loss_cls: 0.2839  loss_box_reg: 0.4049  loss_mask: 0.2651  loss_rpn_cls: 0.0931  loss_rpn_loc: 0.1744  time: 0.2238  data_time: 0.0223  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:39:48 d2.utils.events]: \u001b[0m eta: 2:42:25  iter: 51819  total_loss: 1.165  loss_cls: 0.2416  loss_box_reg: 0.3899  loss_mask: 0.2608  loss_rpn_cls: 0.04961  loss_rpn_loc: 0.1562  time: 0.2238  data_time: 0.0361  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:39:53 d2.utils.events]: \u001b[0m eta: 2:42:23  iter: 51839  total_loss: 1.183  loss_cls: 0.2845  loss_box_reg: 0.3742  loss_mask: 0.2607  loss_rpn_cls: 0.05968  loss_rpn_loc: 0.1678  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:39:57 d2.utils.events]: \u001b[0m eta: 2:42:18  iter: 51859  total_loss: 1.072  loss_cls: 0.2691  loss_box_reg: 0.348  loss_mask: 0.2449  loss_rpn_cls: 0.07751  loss_rpn_loc: 0.1732  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:40:01 d2.utils.events]: \u001b[0m eta: 2:41:54  iter: 51879  total_loss: 1.172  loss_cls: 0.2567  loss_box_reg: 0.4028  loss_mask: 0.2665  loss_rpn_cls: 0.06771  loss_rpn_loc: 0.1754  time: 0.2238  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:40:06 d2.utils.events]: \u001b[0m eta: 2:42:16  iter: 51899  total_loss: 1.209  loss_cls: 0.2984  loss_box_reg: 0.3971  loss_mask: 0.2559  loss_rpn_cls: 0.06738  loss_rpn_loc: 0.166  time: 0.2238  data_time: 0.0107  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:40:10 d2.utils.events]: \u001b[0m eta: 2:42:05  iter: 51919  total_loss: 1.266  loss_cls: 0.3557  loss_box_reg: 0.4256  loss_mask: 0.2587  loss_rpn_cls: 0.06593  loss_rpn_loc: 0.1646  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:40:15 d2.utils.events]: \u001b[0m eta: 2:41:59  iter: 51939  total_loss: 1.102  loss_cls: 0.2591  loss_box_reg: 0.3677  loss_mask: 0.2684  loss_rpn_cls: 0.05925  loss_rpn_loc: 0.1623  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:40:19 d2.utils.events]: \u001b[0m eta: 2:41:41  iter: 51959  total_loss: 1.222  loss_cls: 0.3224  loss_box_reg: 0.3874  loss_mask: 0.2609  loss_rpn_cls: 0.08694  loss_rpn_loc: 0.1729  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:40:23 d2.utils.events]: \u001b[0m eta: 2:41:20  iter: 51979  total_loss: 1.159  loss_cls: 0.285  loss_box_reg: 0.3742  loss_mask: 0.246  loss_rpn_cls: 0.06629  loss_rpn_loc: 0.1775  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:40:27 d2.utils.events]: \u001b[0m eta: 2:41:03  iter: 51999  total_loss: 1.232  loss_cls: 0.3025  loss_box_reg: 0.4021  loss_mask: 0.2685  loss_rpn_cls: 0.06364  loss_rpn_loc: 0.1803  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:40:32 d2.utils.events]: \u001b[0m eta: 2:41:23  iter: 52019  total_loss: 1.11  loss_cls: 0.2409  loss_box_reg: 0.3557  loss_mask: 0.2674  loss_rpn_cls: 0.06125  loss_rpn_loc: 0.1679  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:40:37 d2.utils.events]: \u001b[0m eta: 2:41:07  iter: 52039  total_loss: 1.075  loss_cls: 0.2452  loss_box_reg: 0.3507  loss_mask: 0.254  loss_rpn_cls: 0.05534  loss_rpn_loc: 0.172  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:40:41 d2.utils.events]: \u001b[0m eta: 2:40:50  iter: 52059  total_loss: 1.109  loss_cls: 0.2865  loss_box_reg: 0.362  loss_mask: 0.2461  loss_rpn_cls: 0.05949  loss_rpn_loc: 0.1667  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:40:45 d2.utils.events]: \u001b[0m eta: 2:40:43  iter: 52079  total_loss: 1.264  loss_cls: 0.3292  loss_box_reg: 0.4045  loss_mask: 0.2581  loss_rpn_cls: 0.06888  loss_rpn_loc: 0.1649  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:40:50 d2.utils.events]: \u001b[0m eta: 2:40:21  iter: 52099  total_loss: 1.219  loss_cls: 0.329  loss_box_reg: 0.3837  loss_mask: 0.2503  loss_rpn_cls: 0.06997  loss_rpn_loc: 0.1722  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:40:54 d2.utils.events]: \u001b[0m eta: 2:40:17  iter: 52119  total_loss: 1.188  loss_cls: 0.2951  loss_box_reg: 0.3837  loss_mask: 0.2623  loss_rpn_cls: 0.08009  loss_rpn_loc: 0.1607  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:40:59 d2.utils.events]: \u001b[0m eta: 2:40:13  iter: 52139  total_loss: 1.216  loss_cls: 0.2808  loss_box_reg: 0.3844  loss_mask: 0.2603  loss_rpn_cls: 0.07886  loss_rpn_loc: 0.1569  time: 0.2238  data_time: 0.0171  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:41:03 d2.utils.events]: \u001b[0m eta: 2:40:07  iter: 52159  total_loss: 1.136  loss_cls: 0.2617  loss_box_reg: 0.3483  loss_mask: 0.2438  loss_rpn_cls: 0.06509  loss_rpn_loc: 0.1627  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:41:08 d2.utils.events]: \u001b[0m eta: 2:40:05  iter: 52179  total_loss: 1.125  loss_cls: 0.2519  loss_box_reg: 0.3379  loss_mask: 0.2604  loss_rpn_cls: 0.09023  loss_rpn_loc: 0.1784  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:41:12 d2.utils.events]: \u001b[0m eta: 2:40:05  iter: 52199  total_loss: 1.176  loss_cls: 0.2873  loss_box_reg: 0.3828  loss_mask: 0.2523  loss_rpn_cls: 0.07116  loss_rpn_loc: 0.1571  time: 0.2238  data_time: 0.0142  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:41:17 d2.utils.events]: \u001b[0m eta: 2:39:59  iter: 52219  total_loss: 1.275  loss_cls: 0.3293  loss_box_reg: 0.4395  loss_mask: 0.2695  loss_rpn_cls: 0.07858  loss_rpn_loc: 0.1587  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:41:21 d2.utils.events]: \u001b[0m eta: 2:40:01  iter: 52239  total_loss: 1.244  loss_cls: 0.2857  loss_box_reg: 0.3725  loss_mask: 0.2791  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.1779  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:41:26 d2.utils.events]: \u001b[0m eta: 2:40:22  iter: 52259  total_loss: 1.08  loss_cls: 0.2338  loss_box_reg: 0.3433  loss_mask: 0.2584  loss_rpn_cls: 0.07988  loss_rpn_loc: 0.1472  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:41:30 d2.utils.events]: \u001b[0m eta: 2:40:32  iter: 52279  total_loss: 1.229  loss_cls: 0.2886  loss_box_reg: 0.3483  loss_mask: 0.2617  loss_rpn_cls: 0.0839  loss_rpn_loc: 0.1621  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:41:35 d2.utils.events]: \u001b[0m eta: 2:40:26  iter: 52299  total_loss: 1.208  loss_cls: 0.2948  loss_box_reg: 0.3877  loss_mask: 0.2646  loss_rpn_cls: 0.0698  loss_rpn_loc: 0.171  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:41:39 d2.utils.events]: \u001b[0m eta: 2:40:23  iter: 52319  total_loss: 1.321  loss_cls: 0.3147  loss_box_reg: 0.4036  loss_mask: 0.2831  loss_rpn_cls: 0.09323  loss_rpn_loc: 0.187  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:41:44 d2.utils.events]: \u001b[0m eta: 2:40:35  iter: 52339  total_loss: 1.271  loss_cls: 0.3161  loss_box_reg: 0.3917  loss_mask: 0.2803  loss_rpn_cls: 0.1176  loss_rpn_loc: 0.1948  time: 0.2238  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:41:49 d2.utils.events]: \u001b[0m eta: 2:40:33  iter: 52359  total_loss: 1.209  loss_cls: 0.2894  loss_box_reg: 0.3871  loss_mask: 0.2668  loss_rpn_cls: 0.07278  loss_rpn_loc: 0.1733  time: 0.2238  data_time: 0.0096  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:41:53 d2.utils.events]: \u001b[0m eta: 2:40:32  iter: 52379  total_loss: 1.21  loss_cls: 0.2954  loss_box_reg: 0.3978  loss_mask: 0.2686  loss_rpn_cls: 0.07986  loss_rpn_loc: 0.17  time: 0.2238  data_time: 0.0160  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:41:58 d2.utils.events]: \u001b[0m eta: 2:40:20  iter: 52399  total_loss: 1.18  loss_cls: 0.3225  loss_box_reg: 0.3551  loss_mask: 0.2336  loss_rpn_cls: 0.06178  loss_rpn_loc: 0.1517  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:42:02 d2.utils.events]: \u001b[0m eta: 2:40:20  iter: 52419  total_loss: 1.186  loss_cls: 0.2969  loss_box_reg: 0.3688  loss_mask: 0.2549  loss_rpn_cls: 0.0909  loss_rpn_loc: 0.1715  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:42:07 d2.utils.events]: \u001b[0m eta: 2:40:04  iter: 52439  total_loss: 1.12  loss_cls: 0.2535  loss_box_reg: 0.3348  loss_mask: 0.2664  loss_rpn_cls: 0.05126  loss_rpn_loc: 0.1617  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:42:11 d2.utils.events]: \u001b[0m eta: 2:40:03  iter: 52459  total_loss: 1.146  loss_cls: 0.2727  loss_box_reg: 0.3366  loss_mask: 0.2502  loss_rpn_cls: 0.05808  loss_rpn_loc: 0.1755  time: 0.2238  data_time: 0.0210  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:42:16 d2.utils.events]: \u001b[0m eta: 2:40:02  iter: 52479  total_loss: 1.147  loss_cls: 0.261  loss_box_reg: 0.3683  loss_mask: 0.2682  loss_rpn_cls: 0.06509  loss_rpn_loc: 0.155  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:42:20 d2.utils.events]: \u001b[0m eta: 2:39:59  iter: 52499  total_loss: 1.228  loss_cls: 0.3081  loss_box_reg: 0.4022  loss_mask: 0.2606  loss_rpn_cls: 0.069  loss_rpn_loc: 0.1712  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:42:24 d2.utils.events]: \u001b[0m eta: 2:39:54  iter: 52519  total_loss: 1.279  loss_cls: 0.3331  loss_box_reg: 0.3754  loss_mask: 0.2766  loss_rpn_cls: 0.09287  loss_rpn_loc: 0.1625  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:42:29 d2.utils.events]: \u001b[0m eta: 2:39:49  iter: 52539  total_loss: 1.148  loss_cls: 0.2799  loss_box_reg: 0.3612  loss_mask: 0.2422  loss_rpn_cls: 0.07989  loss_rpn_loc: 0.1686  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:42:34 d2.utils.events]: \u001b[0m eta: 2:39:54  iter: 52559  total_loss: 1.074  loss_cls: 0.2651  loss_box_reg: 0.3519  loss_mask: 0.2433  loss_rpn_cls: 0.05065  loss_rpn_loc: 0.1566  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:42:38 d2.utils.events]: \u001b[0m eta: 2:39:55  iter: 52579  total_loss: 1.186  loss_cls: 0.2927  loss_box_reg: 0.3614  loss_mask: 0.2657  loss_rpn_cls: 0.06175  loss_rpn_loc: 0.1691  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:42:43 d2.utils.events]: \u001b[0m eta: 2:39:44  iter: 52599  total_loss: 1.195  loss_cls: 0.2582  loss_box_reg: 0.4059  loss_mask: 0.2615  loss_rpn_cls: 0.07907  loss_rpn_loc: 0.1809  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:42:47 d2.utils.events]: \u001b[0m eta: 2:39:42  iter: 52619  total_loss: 1.164  loss_cls: 0.2947  loss_box_reg: 0.3772  loss_mask: 0.2904  loss_rpn_cls: 0.07569  loss_rpn_loc: 0.1588  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:42:52 d2.utils.events]: \u001b[0m eta: 2:39:36  iter: 52639  total_loss: 0.9975  loss_cls: 0.2315  loss_box_reg: 0.3184  loss_mask: 0.2268  loss_rpn_cls: 0.06216  loss_rpn_loc: 0.148  time: 0.2238  data_time: 0.0222  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:42:56 d2.utils.events]: \u001b[0m eta: 2:39:31  iter: 52659  total_loss: 1.18  loss_cls: 0.281  loss_box_reg: 0.3983  loss_mask: 0.2692  loss_rpn_cls: 0.07452  loss_rpn_loc: 0.1614  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:43:01 d2.utils.events]: \u001b[0m eta: 2:39:24  iter: 52679  total_loss: 1.277  loss_cls: 0.3217  loss_box_reg: 0.4013  loss_mask: 0.2836  loss_rpn_cls: 0.07321  loss_rpn_loc: 0.1864  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:43:05 d2.utils.events]: \u001b[0m eta: 2:39:14  iter: 52699  total_loss: 1.243  loss_cls: 0.3494  loss_box_reg: 0.4027  loss_mask: 0.2654  loss_rpn_cls: 0.08018  loss_rpn_loc: 0.1672  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:43:10 d2.utils.events]: \u001b[0m eta: 2:39:07  iter: 52719  total_loss: 1.264  loss_cls: 0.3099  loss_box_reg: 0.3636  loss_mask: 0.2686  loss_rpn_cls: 0.07835  loss_rpn_loc: 0.1808  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:43:14 d2.utils.events]: \u001b[0m eta: 2:39:03  iter: 52739  total_loss: 1.069  loss_cls: 0.2577  loss_box_reg: 0.3618  loss_mask: 0.2492  loss_rpn_cls: 0.05636  loss_rpn_loc: 0.1745  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:43:18 d2.utils.events]: \u001b[0m eta: 2:38:58  iter: 52759  total_loss: 1.125  loss_cls: 0.2612  loss_box_reg: 0.3654  loss_mask: 0.2553  loss_rpn_cls: 0.07326  loss_rpn_loc: 0.1528  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:43:23 d2.utils.events]: \u001b[0m eta: 2:38:50  iter: 52779  total_loss: 1.356  loss_cls: 0.3461  loss_box_reg: 0.4218  loss_mask: 0.2873  loss_rpn_cls: 0.08348  loss_rpn_loc: 0.1804  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:43:27 d2.utils.events]: \u001b[0m eta: 2:38:55  iter: 52799  total_loss: 1.234  loss_cls: 0.3499  loss_box_reg: 0.4126  loss_mask: 0.2667  loss_rpn_cls: 0.07258  loss_rpn_loc: 0.1634  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:43:32 d2.utils.events]: \u001b[0m eta: 2:38:51  iter: 52819  total_loss: 1.133  loss_cls: 0.2804  loss_box_reg: 0.3494  loss_mask: 0.2763  loss_rpn_cls: 0.06955  loss_rpn_loc: 0.165  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:43:36 d2.utils.events]: \u001b[0m eta: 2:38:49  iter: 52839  total_loss: 1.33  loss_cls: 0.3253  loss_box_reg: 0.4068  loss_mask: 0.2849  loss_rpn_cls: 0.08391  loss_rpn_loc: 0.1929  time: 0.2238  data_time: 0.0188  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:43:41 d2.utils.events]: \u001b[0m eta: 2:38:44  iter: 52859  total_loss: 0.9558  loss_cls: 0.2602  loss_box_reg: 0.327  loss_mask: 0.2404  loss_rpn_cls: 0.04885  loss_rpn_loc: 0.1458  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:43:45 d2.utils.events]: \u001b[0m eta: 2:38:54  iter: 52879  total_loss: 1.003  loss_cls: 0.2211  loss_box_reg: 0.3125  loss_mask: 0.2405  loss_rpn_cls: 0.05241  loss_rpn_loc: 0.1559  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:43:50 d2.utils.events]: \u001b[0m eta: 2:39:00  iter: 52899  total_loss: 1.132  loss_cls: 0.2781  loss_box_reg: 0.3565  loss_mask: 0.2588  loss_rpn_cls: 0.07784  loss_rpn_loc: 0.1671  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:43:54 d2.utils.events]: \u001b[0m eta: 2:39:05  iter: 52919  total_loss: 1.22  loss_cls: 0.2858  loss_box_reg: 0.3936  loss_mask: 0.2698  loss_rpn_cls: 0.08496  loss_rpn_loc: 0.1663  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:43:59 d2.utils.events]: \u001b[0m eta: 2:39:12  iter: 52939  total_loss: 1.137  loss_cls: 0.292  loss_box_reg: 0.3763  loss_mask: 0.2599  loss_rpn_cls: 0.06344  loss_rpn_loc: 0.1722  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:44:03 d2.utils.events]: \u001b[0m eta: 2:39:15  iter: 52959  total_loss: 1.316  loss_cls: 0.3365  loss_box_reg: 0.411  loss_mask: 0.2715  loss_rpn_cls: 0.1076  loss_rpn_loc: 0.1862  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:44:08 d2.utils.events]: \u001b[0m eta: 2:39:04  iter: 52979  total_loss: 1.15  loss_cls: 0.2825  loss_box_reg: 0.3727  loss_mask: 0.2541  loss_rpn_cls: 0.06189  loss_rpn_loc: 0.1668  time: 0.2238  data_time: 0.0163  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:44:12 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.48 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 00:44:12 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 00:44:12 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 00:44:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 00:44:14 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 00:44:14 d2.data.common]: \u001b[0mSerialized dataset takes 84.20 MiB\n",
      "\u001b[32m[12/30 00:44:17 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.59 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 00:44:17 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 00:44:17 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 00:44:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/30 00:44:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0007 s/iter. Inference: 0.0617 s/iter. Eval: 0.1425 s/iter. Total: 0.2049 s/iter. ETA=0:01:54\n",
      "\u001b[32m[12/30 00:44:25 d2.evaluation.evaluator]: \u001b[0mInference done 38/570. Dataloading: 0.0008 s/iter. Inference: 0.0608 s/iter. Eval: 0.1273 s/iter. Total: 0.1890 s/iter. ETA=0:01:40\n",
      "\u001b[32m[12/30 00:44:31 d2.evaluation.evaluator]: \u001b[0mInference done 66/570. Dataloading: 0.0009 s/iter. Inference: 0.0593 s/iter. Eval: 0.1269 s/iter. Total: 0.1871 s/iter. ETA=0:01:34\n",
      "\u001b[32m[12/30 00:44:36 d2.evaluation.evaluator]: \u001b[0mInference done 92/570. Dataloading: 0.0009 s/iter. Inference: 0.0573 s/iter. Eval: 0.1307 s/iter. Total: 0.1889 s/iter. ETA=0:01:30\n",
      "\u001b[32m[12/30 00:44:41 d2.evaluation.evaluator]: \u001b[0mInference done 118/570. Dataloading: 0.0009 s/iter. Inference: 0.0572 s/iter. Eval: 0.1316 s/iter. Total: 0.1897 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/30 00:44:46 d2.evaluation.evaluator]: \u001b[0mInference done 143/570. Dataloading: 0.0009 s/iter. Inference: 0.0563 s/iter. Eval: 0.1348 s/iter. Total: 0.1920 s/iter. ETA=0:01:21\n",
      "\u001b[32m[12/30 00:44:51 d2.evaluation.evaluator]: \u001b[0mInference done 162/570. Dataloading: 0.0009 s/iter. Inference: 0.0564 s/iter. Eval: 0.1443 s/iter. Total: 0.2016 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 00:44:56 d2.evaluation.evaluator]: \u001b[0mInference done 175/570. Dataloading: 0.0009 s/iter. Inference: 0.0568 s/iter. Eval: 0.1597 s/iter. Total: 0.2174 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/30 00:45:01 d2.evaluation.evaluator]: \u001b[0mInference done 193/570. Dataloading: 0.0009 s/iter. Inference: 0.0572 s/iter. Eval: 0.1657 s/iter. Total: 0.2239 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/30 00:45:06 d2.evaluation.evaluator]: \u001b[0mInference done 209/570. Dataloading: 0.0009 s/iter. Inference: 0.0574 s/iter. Eval: 0.1732 s/iter. Total: 0.2314 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 00:45:12 d2.evaluation.evaluator]: \u001b[0mInference done 226/570. Dataloading: 0.0009 s/iter. Inference: 0.0577 s/iter. Eval: 0.1804 s/iter. Total: 0.2390 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 00:45:17 d2.evaluation.evaluator]: \u001b[0mInference done 237/570. Dataloading: 0.0009 s/iter. Inference: 0.0577 s/iter. Eval: 0.1912 s/iter. Total: 0.2499 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 00:45:22 d2.evaluation.evaluator]: \u001b[0mInference done 249/570. Dataloading: 0.0009 s/iter. Inference: 0.0578 s/iter. Eval: 0.1996 s/iter. Total: 0.2584 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 00:45:27 d2.evaluation.evaluator]: \u001b[0mInference done 265/570. Dataloading: 0.0009 s/iter. Inference: 0.0578 s/iter. Eval: 0.2033 s/iter. Total: 0.2620 s/iter. ETA=0:01:19\n",
      "\u001b[32m[12/30 00:45:32 d2.evaluation.evaluator]: \u001b[0mInference done 283/570. Dataloading: 0.0009 s/iter. Inference: 0.0577 s/iter. Eval: 0.2051 s/iter. Total: 0.2637 s/iter. ETA=0:01:15\n",
      "\u001b[32m[12/30 00:45:38 d2.evaluation.evaluator]: \u001b[0mInference done 298/570. Dataloading: 0.0009 s/iter. Inference: 0.0577 s/iter. Eval: 0.2105 s/iter. Total: 0.2691 s/iter. ETA=0:01:13\n",
      "\u001b[32m[12/30 00:45:43 d2.evaluation.evaluator]: \u001b[0mInference done 347/570. Dataloading: 0.0009 s/iter. Inference: 0.0563 s/iter. Eval: 0.1882 s/iter. Total: 0.2454 s/iter. ETA=0:00:54\n",
      "\u001b[32m[12/30 00:45:48 d2.evaluation.evaluator]: \u001b[0mInference done 376/570. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.1833 s/iter. Total: 0.2402 s/iter. ETA=0:00:46\n",
      "\u001b[32m[12/30 00:45:53 d2.evaluation.evaluator]: \u001b[0mInference done 398/570. Dataloading: 0.0009 s/iter. Inference: 0.0563 s/iter. Eval: 0.1825 s/iter. Total: 0.2397 s/iter. ETA=0:00:41\n",
      "\u001b[32m[12/30 00:45:58 d2.evaluation.evaluator]: \u001b[0mInference done 416/570. Dataloading: 0.0009 s/iter. Inference: 0.0564 s/iter. Eval: 0.1843 s/iter. Total: 0.2416 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/30 00:46:03 d2.evaluation.evaluator]: \u001b[0mInference done 435/570. Dataloading: 0.0009 s/iter. Inference: 0.0567 s/iter. Eval: 0.1850 s/iter. Total: 0.2426 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/30 00:46:09 d2.evaluation.evaluator]: \u001b[0mInference done 464/570. Dataloading: 0.0009 s/iter. Inference: 0.0565 s/iter. Eval: 0.1809 s/iter. Total: 0.2384 s/iter. ETA=0:00:25\n",
      "\u001b[32m[12/30 00:46:14 d2.evaluation.evaluator]: \u001b[0mInference done 495/570. Dataloading: 0.0009 s/iter. Inference: 0.0560 s/iter. Eval: 0.1767 s/iter. Total: 0.2336 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/30 00:46:19 d2.evaluation.evaluator]: \u001b[0mInference done 516/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1775 s/iter. Total: 0.2342 s/iter. ETA=0:00:12\n",
      "\u001b[32m[12/30 00:46:24 d2.evaluation.evaluator]: \u001b[0mInference done 540/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1769 s/iter. Total: 0.2336 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/30 00:46:30 d2.evaluation.evaluator]: \u001b[0mInference done 559/570. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.1786 s/iter. Total: 0.2355 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/30 00:46:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:13.118776 (0.235608 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 00:46:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.055859 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 00:46:32 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/30 00:46:32 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2870589696674226\n",
      "\u001b[32m[12/30 00:46:35 d2.utils.events]: \u001b[0m eta: 2:39:09  iter: 52999  total_loss: 1.221  loss_cls: 0.2975  loss_box_reg: 0.4144  loss_mask: 0.2671  loss_rpn_cls: 0.07263  loss_rpn_loc: 0.1656  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:46:39 d2.utils.events]: \u001b[0m eta: 2:38:46  iter: 53019  total_loss: 1.164  loss_cls: 0.2849  loss_box_reg: 0.3791  loss_mask: 0.2496  loss_rpn_cls: 0.05935  loss_rpn_loc: 0.1706  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:46:44 d2.utils.events]: \u001b[0m eta: 2:38:36  iter: 53039  total_loss: 1.167  loss_cls: 0.3143  loss_box_reg: 0.3866  loss_mask: 0.2622  loss_rpn_cls: 0.06758  loss_rpn_loc: 0.1567  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:46:48 d2.utils.events]: \u001b[0m eta: 2:38:34  iter: 53059  total_loss: 1.181  loss_cls: 0.3041  loss_box_reg: 0.3989  loss_mask: 0.2687  loss_rpn_cls: 0.0914  loss_rpn_loc: 0.1586  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:46:53 d2.utils.events]: \u001b[0m eta: 2:38:18  iter: 53079  total_loss: 1.328  loss_cls: 0.3581  loss_box_reg: 0.427  loss_mask: 0.2744  loss_rpn_cls: 0.09385  loss_rpn_loc: 0.1823  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:46:57 d2.utils.events]: \u001b[0m eta: 2:38:16  iter: 53099  total_loss: 1.067  loss_cls: 0.2354  loss_box_reg: 0.3561  loss_mask: 0.257  loss_rpn_cls: 0.04859  loss_rpn_loc: 0.1507  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:47:01 d2.utils.events]: \u001b[0m eta: 2:38:12  iter: 53119  total_loss: 1.155  loss_cls: 0.2684  loss_box_reg: 0.3649  loss_mask: 0.2505  loss_rpn_cls: 0.08655  loss_rpn_loc: 0.1658  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:47:06 d2.utils.events]: \u001b[0m eta: 2:38:14  iter: 53139  total_loss: 1.193  loss_cls: 0.2992  loss_box_reg: 0.3607  loss_mask: 0.2781  loss_rpn_cls: 0.07606  loss_rpn_loc: 0.1594  time: 0.2238  data_time: 0.0204  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:47:11 d2.utils.events]: \u001b[0m eta: 2:38:15  iter: 53159  total_loss: 1.214  loss_cls: 0.3024  loss_box_reg: 0.393  loss_mask: 0.2794  loss_rpn_cls: 0.0881  loss_rpn_loc: 0.1694  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:47:15 d2.utils.events]: \u001b[0m eta: 2:38:13  iter: 53179  total_loss: 1.118  loss_cls: 0.279  loss_box_reg: 0.3548  loss_mask: 0.2507  loss_rpn_cls: 0.06225  loss_rpn_loc: 0.1606  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:47:20 d2.utils.events]: \u001b[0m eta: 2:38:03  iter: 53199  total_loss: 1.222  loss_cls: 0.3217  loss_box_reg: 0.3711  loss_mask: 0.2606  loss_rpn_cls: 0.0942  loss_rpn_loc: 0.1671  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:47:24 d2.utils.events]: \u001b[0m eta: 2:37:59  iter: 53219  total_loss: 1.235  loss_cls: 0.2998  loss_box_reg: 0.3806  loss_mask: 0.2677  loss_rpn_cls: 0.07848  loss_rpn_loc: 0.1609  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:47:28 d2.utils.events]: \u001b[0m eta: 2:37:29  iter: 53239  total_loss: 1.226  loss_cls: 0.2926  loss_box_reg: 0.4076  loss_mask: 0.2797  loss_rpn_cls: 0.06466  loss_rpn_loc: 0.1709  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:47:33 d2.utils.events]: \u001b[0m eta: 2:37:24  iter: 53259  total_loss: 1.252  loss_cls: 0.2974  loss_box_reg: 0.421  loss_mask: 0.2804  loss_rpn_cls: 0.07034  loss_rpn_loc: 0.1724  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:47:37 d2.utils.events]: \u001b[0m eta: 2:37:12  iter: 53279  total_loss: 1.136  loss_cls: 0.2967  loss_box_reg: 0.4161  loss_mask: 0.2568  loss_rpn_cls: 0.05201  loss_rpn_loc: 0.159  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:47:41 d2.utils.events]: \u001b[0m eta: 2:37:06  iter: 53299  total_loss: 1.202  loss_cls: 0.2685  loss_box_reg: 0.382  loss_mask: 0.247  loss_rpn_cls: 0.07312  loss_rpn_loc: 0.1526  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:47:46 d2.utils.events]: \u001b[0m eta: 2:37:03  iter: 53319  total_loss: 1.14  loss_cls: 0.2813  loss_box_reg: 0.3386  loss_mask: 0.2512  loss_rpn_cls: 0.08568  loss_rpn_loc: 0.1624  time: 0.2238  data_time: 0.0179  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:47:50 d2.utils.events]: \u001b[0m eta: 2:36:54  iter: 53339  total_loss: 1.243  loss_cls: 0.3336  loss_box_reg: 0.4044  loss_mask: 0.2791  loss_rpn_cls: 0.07988  loss_rpn_loc: 0.16  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:47:54 d2.utils.events]: \u001b[0m eta: 2:36:46  iter: 53359  total_loss: 1.164  loss_cls: 0.2953  loss_box_reg: 0.3972  loss_mask: 0.2619  loss_rpn_cls: 0.06439  loss_rpn_loc: 0.1647  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:47:59 d2.utils.events]: \u001b[0m eta: 2:36:42  iter: 53379  total_loss: 1.159  loss_cls: 0.2725  loss_box_reg: 0.4159  loss_mask: 0.2773  loss_rpn_cls: 0.07457  loss_rpn_loc: 0.1578  time: 0.2238  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:48:03 d2.utils.events]: \u001b[0m eta: 2:36:44  iter: 53399  total_loss: 1.104  loss_cls: 0.2568  loss_box_reg: 0.3215  loss_mask: 0.2591  loss_rpn_cls: 0.05614  loss_rpn_loc: 0.1726  time: 0.2238  data_time: 0.0100  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:48:08 d2.utils.events]: \u001b[0m eta: 2:36:39  iter: 53419  total_loss: 1.2  loss_cls: 0.2951  loss_box_reg: 0.3913  loss_mask: 0.2744  loss_rpn_cls: 0.07631  loss_rpn_loc: 0.1705  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:48:12 d2.utils.events]: \u001b[0m eta: 2:36:35  iter: 53439  total_loss: 1.287  loss_cls: 0.3277  loss_box_reg: 0.4044  loss_mask: 0.276  loss_rpn_cls: 0.1065  loss_rpn_loc: 0.1803  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:48:17 d2.utils.events]: \u001b[0m eta: 2:36:22  iter: 53459  total_loss: 1.074  loss_cls: 0.2679  loss_box_reg: 0.3759  loss_mask: 0.2493  loss_rpn_cls: 0.06225  loss_rpn_loc: 0.1599  time: 0.2238  data_time: 0.0222  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:48:22 d2.utils.events]: \u001b[0m eta: 2:36:25  iter: 53479  total_loss: 1.207  loss_cls: 0.2684  loss_box_reg: 0.3649  loss_mask: 0.263  loss_rpn_cls: 0.08205  loss_rpn_loc: 0.1749  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:48:26 d2.utils.events]: \u001b[0m eta: 2:36:25  iter: 53499  total_loss: 1.181  loss_cls: 0.3011  loss_box_reg: 0.3729  loss_mask: 0.2581  loss_rpn_cls: 0.07067  loss_rpn_loc: 0.1645  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:48:30 d2.utils.events]: \u001b[0m eta: 2:36:14  iter: 53519  total_loss: 1.065  loss_cls: 0.2417  loss_box_reg: 0.3228  loss_mask: 0.2467  loss_rpn_cls: 0.05892  loss_rpn_loc: 0.1658  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:48:35 d2.utils.events]: \u001b[0m eta: 2:36:14  iter: 53539  total_loss: 1.178  loss_cls: 0.3198  loss_box_reg: 0.3793  loss_mask: 0.2691  loss_rpn_cls: 0.08153  loss_rpn_loc: 0.1765  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:48:39 d2.utils.events]: \u001b[0m eta: 2:35:55  iter: 53559  total_loss: 1.213  loss_cls: 0.2982  loss_box_reg: 0.415  loss_mask: 0.2589  loss_rpn_cls: 0.07732  loss_rpn_loc: 0.1726  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:48:44 d2.utils.events]: \u001b[0m eta: 2:35:51  iter: 53579  total_loss: 1.195  loss_cls: 0.2658  loss_box_reg: 0.349  loss_mask: 0.2664  loss_rpn_cls: 0.06504  loss_rpn_loc: 0.1629  time: 0.2238  data_time: 0.0228  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:48:49 d2.utils.events]: \u001b[0m eta: 2:35:48  iter: 53599  total_loss: 1.227  loss_cls: 0.3277  loss_box_reg: 0.3926  loss_mask: 0.2662  loss_rpn_cls: 0.08352  loss_rpn_loc: 0.1596  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:48:53 d2.utils.events]: \u001b[0m eta: 2:35:19  iter: 53619  total_loss: 1.204  loss_cls: 0.2984  loss_box_reg: 0.3935  loss_mask: 0.2589  loss_rpn_cls: 0.05851  loss_rpn_loc: 0.1701  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:48:57 d2.utils.events]: \u001b[0m eta: 2:35:09  iter: 53639  total_loss: 1.187  loss_cls: 0.285  loss_box_reg: 0.4257  loss_mask: 0.248  loss_rpn_cls: 0.07457  loss_rpn_loc: 0.1549  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:49:02 d2.utils.events]: \u001b[0m eta: 2:35:06  iter: 53659  total_loss: 1.102  loss_cls: 0.2597  loss_box_reg: 0.3445  loss_mask: 0.2436  loss_rpn_cls: 0.08396  loss_rpn_loc: 0.1543  time: 0.2238  data_time: 0.0092  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:49:06 d2.utils.events]: \u001b[0m eta: 2:35:02  iter: 53679  total_loss: 1.127  loss_cls: 0.2853  loss_box_reg: 0.3608  loss_mask: 0.256  loss_rpn_cls: 0.05846  loss_rpn_loc: 0.1604  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:49:10 d2.utils.events]: \u001b[0m eta: 2:35:09  iter: 53699  total_loss: 1.228  loss_cls: 0.2964  loss_box_reg: 0.3974  loss_mask: 0.2735  loss_rpn_cls: 0.09784  loss_rpn_loc: 0.1707  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:49:15 d2.utils.events]: \u001b[0m eta: 2:35:01  iter: 53719  total_loss: 1.173  loss_cls: 0.282  loss_box_reg: 0.3748  loss_mask: 0.2684  loss_rpn_cls: 0.08114  loss_rpn_loc: 0.1616  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:49:19 d2.utils.events]: \u001b[0m eta: 2:34:57  iter: 53739  total_loss: 1.162  loss_cls: 0.2865  loss_box_reg: 0.3923  loss_mask: 0.2642  loss_rpn_cls: 0.04677  loss_rpn_loc: 0.1493  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:49:23 d2.utils.events]: \u001b[0m eta: 2:34:49  iter: 53759  total_loss: 1.063  loss_cls: 0.2536  loss_box_reg: 0.3375  loss_mask: 0.2595  loss_rpn_cls: 0.05343  loss_rpn_loc: 0.1354  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:49:28 d2.utils.events]: \u001b[0m eta: 2:34:41  iter: 53779  total_loss: 1.275  loss_cls: 0.3309  loss_box_reg: 0.44  loss_mask: 0.2593  loss_rpn_cls: 0.08202  loss_rpn_loc: 0.1569  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:49:32 d2.utils.events]: \u001b[0m eta: 2:34:38  iter: 53799  total_loss: 1.198  loss_cls: 0.2992  loss_box_reg: 0.3617  loss_mask: 0.2679  loss_rpn_cls: 0.07325  loss_rpn_loc: 0.1774  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:49:37 d2.utils.events]: \u001b[0m eta: 2:34:36  iter: 53819  total_loss: 1.196  loss_cls: 0.3088  loss_box_reg: 0.3743  loss_mask: 0.259  loss_rpn_cls: 0.07982  loss_rpn_loc: 0.1697  time: 0.2238  data_time: 0.0156  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:49:41 d2.utils.events]: \u001b[0m eta: 2:34:32  iter: 53839  total_loss: 1.139  loss_cls: 0.2863  loss_box_reg: 0.3615  loss_mask: 0.2553  loss_rpn_cls: 0.08023  loss_rpn_loc: 0.1582  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:49:46 d2.utils.events]: \u001b[0m eta: 2:34:25  iter: 53859  total_loss: 1.202  loss_cls: 0.2815  loss_box_reg: 0.3836  loss_mask: 0.2616  loss_rpn_cls: 0.0941  loss_rpn_loc: 0.171  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:49:50 d2.utils.events]: \u001b[0m eta: 2:34:15  iter: 53879  total_loss: 1.185  loss_cls: 0.2861  loss_box_reg: 0.3935  loss_mask: 0.2552  loss_rpn_cls: 0.0923  loss_rpn_loc: 0.1627  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:49:55 d2.utils.events]: \u001b[0m eta: 2:33:38  iter: 53899  total_loss: 1.108  loss_cls: 0.2786  loss_box_reg: 0.3807  loss_mask: 0.2714  loss_rpn_cls: 0.06945  loss_rpn_loc: 0.1653  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:49:59 d2.utils.events]: \u001b[0m eta: 2:33:17  iter: 53919  total_loss: 1.106  loss_cls: 0.2812  loss_box_reg: 0.3456  loss_mask: 0.247  loss_rpn_cls: 0.07619  loss_rpn_loc: 0.1589  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:50:03 d2.utils.events]: \u001b[0m eta: 2:33:02  iter: 53939  total_loss: 1.081  loss_cls: 0.2612  loss_box_reg: 0.3536  loss_mask: 0.2428  loss_rpn_cls: 0.04502  loss_rpn_loc: 0.1548  time: 0.2238  data_time: 0.0150  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:50:08 d2.utils.events]: \u001b[0m eta: 2:33:00  iter: 53959  total_loss: 1.31  loss_cls: 0.3315  loss_box_reg: 0.3681  loss_mask: 0.2822  loss_rpn_cls: 0.08142  loss_rpn_loc: 0.173  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:50:12 d2.utils.events]: \u001b[0m eta: 2:33:03  iter: 53979  total_loss: 1.098  loss_cls: 0.2917  loss_box_reg: 0.3822  loss_mask: 0.2433  loss_rpn_cls: 0.05073  loss_rpn_loc: 0.1503  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:50:17 d2.utils.events]: \u001b[0m eta: 2:33:00  iter: 53999  total_loss: 1.069  loss_cls: 0.2546  loss_box_reg: 0.3144  loss_mask: 0.2515  loss_rpn_cls: 0.07874  loss_rpn_loc: 0.1766  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:50:21 d2.utils.events]: \u001b[0m eta: 2:33:23  iter: 54019  total_loss: 1.246  loss_cls: 0.3217  loss_box_reg: 0.3908  loss_mask: 0.2607  loss_rpn_cls: 0.08742  loss_rpn_loc: 0.1658  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:50:26 d2.utils.events]: \u001b[0m eta: 2:33:31  iter: 54039  total_loss: 1.195  loss_cls: 0.2751  loss_box_reg: 0.3704  loss_mask: 0.2672  loss_rpn_cls: 0.07963  loss_rpn_loc: 0.1735  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:50:30 d2.utils.events]: \u001b[0m eta: 2:33:40  iter: 54059  total_loss: 1.092  loss_cls: 0.2661  loss_box_reg: 0.3236  loss_mask: 0.2539  loss_rpn_cls: 0.09115  loss_rpn_loc: 0.1635  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:50:35 d2.utils.events]: \u001b[0m eta: 2:33:47  iter: 54079  total_loss: 1.137  loss_cls: 0.2979  loss_box_reg: 0.3506  loss_mask: 0.2536  loss_rpn_cls: 0.08108  loss_rpn_loc: 0.1608  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:50:39 d2.utils.events]: \u001b[0m eta: 2:33:34  iter: 54099  total_loss: 1.213  loss_cls: 0.3104  loss_box_reg: 0.4172  loss_mask: 0.2426  loss_rpn_cls: 0.0609  loss_rpn_loc: 0.1564  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:50:44 d2.utils.events]: \u001b[0m eta: 2:33:28  iter: 54119  total_loss: 1.138  loss_cls: 0.2825  loss_box_reg: 0.3976  loss_mask: 0.256  loss_rpn_cls: 0.06525  loss_rpn_loc: 0.1472  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:50:48 d2.utils.events]: \u001b[0m eta: 2:33:24  iter: 54139  total_loss: 1.114  loss_cls: 0.2802  loss_box_reg: 0.3672  loss_mask: 0.2673  loss_rpn_cls: 0.08391  loss_rpn_loc: 0.1756  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:50:53 d2.utils.events]: \u001b[0m eta: 2:33:21  iter: 54159  total_loss: 1.034  loss_cls: 0.2187  loss_box_reg: 0.3217  loss_mask: 0.2583  loss_rpn_cls: 0.09302  loss_rpn_loc: 0.1685  time: 0.2238  data_time: 0.0158  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:50:57 d2.utils.events]: \u001b[0m eta: 2:33:15  iter: 54179  total_loss: 1.179  loss_cls: 0.2728  loss_box_reg: 0.3494  loss_mask: 0.2566  loss_rpn_cls: 0.06825  loss_rpn_loc: 0.1655  time: 0.2238  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:51:02 d2.utils.events]: \u001b[0m eta: 2:33:15  iter: 54199  total_loss: 1.157  loss_cls: 0.2676  loss_box_reg: 0.3341  loss_mask: 0.2592  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.1728  time: 0.2238  data_time: 0.0164  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:51:07 d2.utils.events]: \u001b[0m eta: 2:33:11  iter: 54219  total_loss: 1.23  loss_cls: 0.3309  loss_box_reg: 0.3661  loss_mask: 0.2534  loss_rpn_cls: 0.06275  loss_rpn_loc: 0.1563  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:51:11 d2.utils.events]: \u001b[0m eta: 2:33:17  iter: 54239  total_loss: 1.246  loss_cls: 0.3085  loss_box_reg: 0.4125  loss_mask: 0.2476  loss_rpn_cls: 0.06376  loss_rpn_loc: 0.1833  time: 0.2238  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:51:15 d2.utils.events]: \u001b[0m eta: 2:33:02  iter: 54259  total_loss: 1.185  loss_cls: 0.2867  loss_box_reg: 0.4058  loss_mask: 0.261  loss_rpn_cls: 0.06329  loss_rpn_loc: 0.1602  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:51:20 d2.utils.events]: \u001b[0m eta: 2:32:58  iter: 54279  total_loss: 1.308  loss_cls: 0.3103  loss_box_reg: 0.419  loss_mask: 0.2669  loss_rpn_cls: 0.08448  loss_rpn_loc: 0.1606  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:51:24 d2.utils.events]: \u001b[0m eta: 2:32:53  iter: 54299  total_loss: 1.236  loss_cls: 0.2998  loss_box_reg: 0.4059  loss_mask: 0.2683  loss_rpn_cls: 0.08455  loss_rpn_loc: 0.1578  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:51:29 d2.utils.events]: \u001b[0m eta: 2:32:46  iter: 54319  total_loss: 1.233  loss_cls: 0.3171  loss_box_reg: 0.406  loss_mask: 0.2567  loss_rpn_cls: 0.08627  loss_rpn_loc: 0.1658  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:51:33 d2.utils.events]: \u001b[0m eta: 2:32:40  iter: 54339  total_loss: 1.1  loss_cls: 0.2695  loss_box_reg: 0.3674  loss_mask: 0.2625  loss_rpn_cls: 0.06322  loss_rpn_loc: 0.1603  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:51:38 d2.utils.events]: \u001b[0m eta: 2:32:40  iter: 54359  total_loss: 1.227  loss_cls: 0.3058  loss_box_reg: 0.3867  loss_mask: 0.2845  loss_rpn_cls: 0.06717  loss_rpn_loc: 0.1726  time: 0.2237  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:51:42 d2.utils.events]: \u001b[0m eta: 2:32:55  iter: 54379  total_loss: 1.113  loss_cls: 0.2755  loss_box_reg: 0.3169  loss_mask: 0.263  loss_rpn_cls: 0.09776  loss_rpn_loc: 0.1798  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:51:47 d2.utils.events]: \u001b[0m eta: 2:32:32  iter: 54399  total_loss: 1.134  loss_cls: 0.2499  loss_box_reg: 0.3831  loss_mask: 0.272  loss_rpn_cls: 0.0726  loss_rpn_loc: 0.1696  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:51:51 d2.utils.events]: \u001b[0m eta: 2:32:25  iter: 54419  total_loss: 1.207  loss_cls: 0.2821  loss_box_reg: 0.3665  loss_mask: 0.2585  loss_rpn_cls: 0.09199  loss_rpn_loc: 0.1847  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:51:56 d2.utils.events]: \u001b[0m eta: 2:32:42  iter: 54439  total_loss: 1.154  loss_cls: 0.2835  loss_box_reg: 0.3779  loss_mask: 0.2481  loss_rpn_cls: 0.07754  loss_rpn_loc: 0.1692  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:52:01 d2.utils.events]: \u001b[0m eta: 2:32:43  iter: 54459  total_loss: 1.211  loss_cls: 0.2951  loss_box_reg: 0.332  loss_mask: 0.258  loss_rpn_cls: 0.1059  loss_rpn_loc: 0.1778  time: 0.2238  data_time: 0.0312  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:52:05 d2.utils.events]: \u001b[0m eta: 2:32:38  iter: 54479  total_loss: 1.051  loss_cls: 0.2622  loss_box_reg: 0.351  loss_mask: 0.2387  loss_rpn_cls: 0.05744  loss_rpn_loc: 0.1432  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:52:10 d2.utils.events]: \u001b[0m eta: 2:32:34  iter: 54499  total_loss: 1.157  loss_cls: 0.2804  loss_box_reg: 0.3605  loss_mask: 0.2598  loss_rpn_cls: 0.08046  loss_rpn_loc: 0.156  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:52:15 d2.utils.events]: \u001b[0m eta: 2:32:29  iter: 54519  total_loss: 1.128  loss_cls: 0.2967  loss_box_reg: 0.3738  loss_mask: 0.2676  loss_rpn_cls: 0.07265  loss_rpn_loc: 0.1661  time: 0.2238  data_time: 0.0111  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:52:19 d2.utils.events]: \u001b[0m eta: 2:32:01  iter: 54539  total_loss: 1.168  loss_cls: 0.3004  loss_box_reg: 0.3863  loss_mask: 0.2574  loss_rpn_cls: 0.07303  loss_rpn_loc: 0.1953  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:52:24 d2.utils.events]: \u001b[0m eta: 2:31:57  iter: 54559  total_loss: 1.152  loss_cls: 0.2816  loss_box_reg: 0.355  loss_mask: 0.2734  loss_rpn_cls: 0.07659  loss_rpn_loc: 0.178  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:52:28 d2.utils.events]: \u001b[0m eta: 2:31:49  iter: 54579  total_loss: 1.141  loss_cls: 0.2862  loss_box_reg: 0.3567  loss_mask: 0.2623  loss_rpn_cls: 0.05567  loss_rpn_loc: 0.1622  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:52:32 d2.utils.events]: \u001b[0m eta: 2:31:48  iter: 54599  total_loss: 1.247  loss_cls: 0.2766  loss_box_reg: 0.4286  loss_mask: 0.2801  loss_rpn_cls: 0.0785  loss_rpn_loc: 0.1604  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:52:37 d2.utils.events]: \u001b[0m eta: 2:32:10  iter: 54619  total_loss: 1.24  loss_cls: 0.2888  loss_box_reg: 0.3832  loss_mask: 0.2687  loss_rpn_cls: 0.07784  loss_rpn_loc: 0.1708  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:52:41 d2.utils.events]: \u001b[0m eta: 2:32:08  iter: 54639  total_loss: 1.176  loss_cls: 0.3031  loss_box_reg: 0.3921  loss_mask: 0.2556  loss_rpn_cls: 0.06602  loss_rpn_loc: 0.1522  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:52:46 d2.utils.events]: \u001b[0m eta: 2:32:00  iter: 54659  total_loss: 1.231  loss_cls: 0.3186  loss_box_reg: 0.3563  loss_mask: 0.2494  loss_rpn_cls: 0.09547  loss_rpn_loc: 0.1845  time: 0.2238  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:52:50 d2.utils.events]: \u001b[0m eta: 2:32:04  iter: 54679  total_loss: 1.218  loss_cls: 0.2802  loss_box_reg: 0.3665  loss_mask: 0.262  loss_rpn_cls: 0.07361  loss_rpn_loc: 0.1811  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:52:55 d2.utils.events]: \u001b[0m eta: 2:31:52  iter: 54699  total_loss: 1.097  loss_cls: 0.2263  loss_box_reg: 0.3807  loss_mask: 0.2613  loss_rpn_cls: 0.05149  loss_rpn_loc: 0.1457  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:52:59 d2.utils.events]: \u001b[0m eta: 2:31:50  iter: 54719  total_loss: 1.217  loss_cls: 0.3323  loss_box_reg: 0.4206  loss_mask: 0.2525  loss_rpn_cls: 0.08302  loss_rpn_loc: 0.1697  time: 0.2238  data_time: 0.0212  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:53:04 d2.utils.events]: \u001b[0m eta: 2:31:46  iter: 54739  total_loss: 1.149  loss_cls: 0.2881  loss_box_reg: 0.3888  loss_mask: 0.2654  loss_rpn_cls: 0.05527  loss_rpn_loc: 0.1562  time: 0.2238  data_time: 0.0164  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:53:08 d2.utils.events]: \u001b[0m eta: 2:31:39  iter: 54759  total_loss: 1.132  loss_cls: 0.2725  loss_box_reg: 0.3835  loss_mask: 0.2448  loss_rpn_cls: 0.04374  loss_rpn_loc: 0.1446  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:53:13 d2.utils.events]: \u001b[0m eta: 2:31:37  iter: 54779  total_loss: 1.211  loss_cls: 0.2875  loss_box_reg: 0.4158  loss_mask: 0.2579  loss_rpn_cls: 0.06227  loss_rpn_loc: 0.1878  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:53:17 d2.utils.events]: \u001b[0m eta: 2:31:25  iter: 54799  total_loss: 1.163  loss_cls: 0.2876  loss_box_reg: 0.39  loss_mask: 0.2408  loss_rpn_cls: 0.0782  loss_rpn_loc: 0.162  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:53:21 d2.utils.events]: \u001b[0m eta: 2:30:58  iter: 54819  total_loss: 1.23  loss_cls: 0.3141  loss_box_reg: 0.3991  loss_mask: 0.2745  loss_rpn_cls: 0.06245  loss_rpn_loc: 0.1533  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:53:26 d2.utils.events]: \u001b[0m eta: 2:30:57  iter: 54839  total_loss: 1.128  loss_cls: 0.2766  loss_box_reg: 0.3556  loss_mask: 0.2528  loss_rpn_cls: 0.06762  loss_rpn_loc: 0.1686  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:53:31 d2.utils.events]: \u001b[0m eta: 2:31:15  iter: 54859  total_loss: 1.237  loss_cls: 0.2948  loss_box_reg: 0.3903  loss_mask: 0.266  loss_rpn_cls: 0.09653  loss_rpn_loc: 0.1652  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:53:35 d2.utils.events]: \u001b[0m eta: 2:31:11  iter: 54879  total_loss: 1.136  loss_cls: 0.2644  loss_box_reg: 0.3693  loss_mask: 0.2602  loss_rpn_cls: 0.057  loss_rpn_loc: 0.1747  time: 0.2238  data_time: 0.0089  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:53:40 d2.utils.events]: \u001b[0m eta: 2:31:13  iter: 54899  total_loss: 1.164  loss_cls: 0.271  loss_box_reg: 0.3574  loss_mask: 0.2593  loss_rpn_cls: 0.07319  loss_rpn_loc: 0.1487  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:53:44 d2.utils.events]: \u001b[0m eta: 2:31:10  iter: 54919  total_loss: 1.144  loss_cls: 0.2896  loss_box_reg: 0.3942  loss_mask: 0.246  loss_rpn_cls: 0.08271  loss_rpn_loc: 0.1538  time: 0.2238  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:53:48 d2.utils.events]: \u001b[0m eta: 2:31:10  iter: 54939  total_loss: 1.212  loss_cls: 0.2928  loss_box_reg: 0.3669  loss_mask: 0.2557  loss_rpn_cls: 0.1042  loss_rpn_loc: 0.1545  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:53:53 d2.utils.events]: \u001b[0m eta: 2:31:19  iter: 54959  total_loss: 1.233  loss_cls: 0.3051  loss_box_reg: 0.3921  loss_mask: 0.2723  loss_rpn_cls: 0.07274  loss_rpn_loc: 0.1753  time: 0.2238  data_time: 0.0140  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:53:58 d2.utils.events]: \u001b[0m eta: 2:31:06  iter: 54979  total_loss: 1.12  loss_cls: 0.2874  loss_box_reg: 0.37  loss_mask: 0.245  loss_rpn_cls: 0.05072  loss_rpn_loc: 0.1592  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:54:02 d2.utils.events]: \u001b[0m eta: 2:31:02  iter: 54999  total_loss: 1.25  loss_cls: 0.315  loss_box_reg: 0.3968  loss_mask: 0.2768  loss_rpn_cls: 0.1067  loss_rpn_loc: 0.1861  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:54:06 d2.utils.events]: \u001b[0m eta: 2:30:47  iter: 55019  total_loss: 1.225  loss_cls: 0.3109  loss_box_reg: 0.4004  loss_mask: 0.2778  loss_rpn_cls: 0.05432  loss_rpn_loc: 0.1571  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:54:11 d2.utils.events]: \u001b[0m eta: 2:30:34  iter: 55039  total_loss: 1.109  loss_cls: 0.2619  loss_box_reg: 0.3816  loss_mask: 0.2593  loss_rpn_cls: 0.06922  loss_rpn_loc: 0.142  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:54:15 d2.utils.events]: \u001b[0m eta: 2:30:28  iter: 55059  total_loss: 1.181  loss_cls: 0.29  loss_box_reg: 0.3462  loss_mask: 0.2667  loss_rpn_cls: 0.06723  loss_rpn_loc: 0.1534  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:54:20 d2.utils.events]: \u001b[0m eta: 2:30:11  iter: 55079  total_loss: 1.222  loss_cls: 0.2711  loss_box_reg: 0.3695  loss_mask: 0.2588  loss_rpn_cls: 0.08208  loss_rpn_loc: 0.1708  time: 0.2238  data_time: 0.0111  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:54:24 d2.utils.events]: \u001b[0m eta: 2:30:19  iter: 55099  total_loss: 1.244  loss_cls: 0.3055  loss_box_reg: 0.3994  loss_mask: 0.2531  loss_rpn_cls: 0.07946  loss_rpn_loc: 0.1671  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:54:29 d2.utils.events]: \u001b[0m eta: 2:30:19  iter: 55119  total_loss: 1.287  loss_cls: 0.2866  loss_box_reg: 0.4361  loss_mask: 0.2868  loss_rpn_cls: 0.07086  loss_rpn_loc: 0.1696  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:54:33 d2.utils.events]: \u001b[0m eta: 2:30:14  iter: 55139  total_loss: 1.141  loss_cls: 0.2408  loss_box_reg: 0.3385  loss_mask: 0.2779  loss_rpn_cls: 0.06405  loss_rpn_loc: 0.157  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:54:38 d2.utils.events]: \u001b[0m eta: 2:29:54  iter: 55159  total_loss: 1.151  loss_cls: 0.2718  loss_box_reg: 0.3968  loss_mask: 0.2762  loss_rpn_cls: 0.0564  loss_rpn_loc: 0.1698  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:54:42 d2.utils.events]: \u001b[0m eta: 2:29:57  iter: 55179  total_loss: 1.212  loss_cls: 0.3272  loss_box_reg: 0.3815  loss_mask: 0.2656  loss_rpn_cls: 0.06917  loss_rpn_loc: 0.1787  time: 0.2238  data_time: 0.0157  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:54:47 d2.utils.events]: \u001b[0m eta: 2:29:45  iter: 55199  total_loss: 1.138  loss_cls: 0.2602  loss_box_reg: 0.3707  loss_mask: 0.2465  loss_rpn_cls: 0.06249  loss_rpn_loc: 0.1577  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:54:51 d2.utils.events]: \u001b[0m eta: 2:29:29  iter: 55219  total_loss: 1.05  loss_cls: 0.2496  loss_box_reg: 0.3336  loss_mask: 0.2472  loss_rpn_cls: 0.06536  loss_rpn_loc: 0.1439  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:54:56 d2.utils.events]: \u001b[0m eta: 2:29:52  iter: 55239  total_loss: 1.085  loss_cls: 0.2021  loss_box_reg: 0.3695  loss_mask: 0.2635  loss_rpn_cls: 0.06117  loss_rpn_loc: 0.1538  time: 0.2238  data_time: 0.0098  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:55:01 d2.utils.events]: \u001b[0m eta: 2:29:44  iter: 55259  total_loss: 1.147  loss_cls: 0.2813  loss_box_reg: 0.3754  loss_mask: 0.2552  loss_rpn_cls: 0.05249  loss_rpn_loc: 0.1611  time: 0.2238  data_time: 0.0298  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:55:05 d2.utils.events]: \u001b[0m eta: 2:29:49  iter: 55279  total_loss: 1.061  loss_cls: 0.2771  loss_box_reg: 0.349  loss_mask: 0.255  loss_rpn_cls: 0.05414  loss_rpn_loc: 0.1625  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:55:10 d2.utils.events]: \u001b[0m eta: 2:29:49  iter: 55299  total_loss: 1.105  loss_cls: 0.2854  loss_box_reg: 0.3717  loss_mask: 0.2442  loss_rpn_cls: 0.0466  loss_rpn_loc: 0.1541  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:55:14 d2.utils.events]: \u001b[0m eta: 2:29:54  iter: 55319  total_loss: 1.272  loss_cls: 0.3488  loss_box_reg: 0.4134  loss_mask: 0.2749  loss_rpn_cls: 0.09079  loss_rpn_loc: 0.1716  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:55:19 d2.utils.events]: \u001b[0m eta: 2:29:49  iter: 55339  total_loss: 1.215  loss_cls: 0.33  loss_box_reg: 0.4015  loss_mask: 0.2637  loss_rpn_cls: 0.07648  loss_rpn_loc: 0.171  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:55:23 d2.utils.events]: \u001b[0m eta: 2:29:30  iter: 55359  total_loss: 1.2  loss_cls: 0.3221  loss_box_reg: 0.3663  loss_mask: 0.2716  loss_rpn_cls: 0.08321  loss_rpn_loc: 0.1726  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:55:28 d2.utils.events]: \u001b[0m eta: 2:29:25  iter: 55379  total_loss: 1.156  loss_cls: 0.2775  loss_box_reg: 0.3652  loss_mask: 0.2474  loss_rpn_cls: 0.06305  loss_rpn_loc: 0.1629  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:55:33 d2.utils.events]: \u001b[0m eta: 2:29:28  iter: 55399  total_loss: 1.202  loss_cls: 0.3145  loss_box_reg: 0.3753  loss_mask: 0.2666  loss_rpn_cls: 0.08056  loss_rpn_loc: 0.1719  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:55:37 d2.utils.events]: \u001b[0m eta: 2:29:34  iter: 55419  total_loss: 1.285  loss_cls: 0.3165  loss_box_reg: 0.4328  loss_mask: 0.2648  loss_rpn_cls: 0.08122  loss_rpn_loc: 0.1691  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:55:42 d2.utils.events]: \u001b[0m eta: 2:29:15  iter: 55439  total_loss: 1.245  loss_cls: 0.3154  loss_box_reg: 0.4237  loss_mask: 0.2582  loss_rpn_cls: 0.0779  loss_rpn_loc: 0.163  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:55:46 d2.utils.events]: \u001b[0m eta: 2:29:13  iter: 55459  total_loss: 1.262  loss_cls: 0.3045  loss_box_reg: 0.408  loss_mask: 0.2638  loss_rpn_cls: 0.0862  loss_rpn_loc: 0.1646  time: 0.2238  data_time: 0.0175  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:55:51 d2.utils.events]: \u001b[0m eta: 2:29:04  iter: 55479  total_loss: 1.066  loss_cls: 0.2171  loss_box_reg: 0.3698  loss_mask: 0.2467  loss_rpn_cls: 0.06419  loss_rpn_loc: 0.1452  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:55:55 d2.utils.events]: \u001b[0m eta: 2:28:51  iter: 55499  total_loss: 1.177  loss_cls: 0.284  loss_box_reg: 0.4036  loss_mask: 0.2532  loss_rpn_cls: 0.07444  loss_rpn_loc: 0.1807  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:56:00 d2.utils.events]: \u001b[0m eta: 2:28:56  iter: 55519  total_loss: 1.205  loss_cls: 0.3117  loss_box_reg: 0.3382  loss_mask: 0.2692  loss_rpn_cls: 0.0913  loss_rpn_loc: 0.1692  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:56:04 d2.utils.events]: \u001b[0m eta: 2:28:46  iter: 55539  total_loss: 1.057  loss_cls: 0.2732  loss_box_reg: 0.3509  loss_mask: 0.2523  loss_rpn_cls: 0.06089  loss_rpn_loc: 0.1568  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:56:08 d2.utils.events]: \u001b[0m eta: 2:28:38  iter: 55559  total_loss: 1.133  loss_cls: 0.2614  loss_box_reg: 0.3758  loss_mask: 0.2436  loss_rpn_cls: 0.06987  loss_rpn_loc: 0.1465  time: 0.2238  data_time: 0.0156  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:56:13 d2.utils.events]: \u001b[0m eta: 2:28:37  iter: 55579  total_loss: 1.15  loss_cls: 0.2783  loss_box_reg: 0.415  loss_mask: 0.2492  loss_rpn_cls: 0.05594  loss_rpn_loc: 0.147  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:56:17 d2.utils.events]: \u001b[0m eta: 2:28:25  iter: 55599  total_loss: 1.171  loss_cls: 0.2824  loss_box_reg: 0.332  loss_mask: 0.279  loss_rpn_cls: 0.06252  loss_rpn_loc: 0.1696  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:56:22 d2.utils.events]: \u001b[0m eta: 2:28:24  iter: 55619  total_loss: 1.112  loss_cls: 0.2733  loss_box_reg: 0.3575  loss_mask: 0.2359  loss_rpn_cls: 0.06793  loss_rpn_loc: 0.1601  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:56:26 d2.utils.events]: \u001b[0m eta: 2:28:22  iter: 55639  total_loss: 1.187  loss_cls: 0.2614  loss_box_reg: 0.3769  loss_mask: 0.2517  loss_rpn_cls: 0.06525  loss_rpn_loc: 0.1658  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:56:31 d2.utils.events]: \u001b[0m eta: 2:28:16  iter: 55659  total_loss: 1.238  loss_cls: 0.2952  loss_box_reg: 0.3756  loss_mask: 0.2719  loss_rpn_cls: 0.08586  loss_rpn_loc: 0.1708  time: 0.2238  data_time: 0.0101  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:56:36 d2.utils.events]: \u001b[0m eta: 2:28:08  iter: 55679  total_loss: 1.083  loss_cls: 0.2605  loss_box_reg: 0.3482  loss_mask: 0.2467  loss_rpn_cls: 0.07633  loss_rpn_loc: 0.1535  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:56:40 d2.utils.events]: \u001b[0m eta: 2:28:09  iter: 55699  total_loss: 1.188  loss_cls: 0.2697  loss_box_reg: 0.342  loss_mask: 0.2571  loss_rpn_cls: 0.05815  loss_rpn_loc: 0.1607  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:56:45 d2.utils.events]: \u001b[0m eta: 2:28:11  iter: 55719  total_loss: 1.143  loss_cls: 0.2956  loss_box_reg: 0.3599  loss_mask: 0.2653  loss_rpn_cls: 0.098  loss_rpn_loc: 0.1756  time: 0.2238  data_time: 0.0101  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:56:49 d2.utils.events]: \u001b[0m eta: 2:28:09  iter: 55739  total_loss: 1.076  loss_cls: 0.2916  loss_box_reg: 0.3662  loss_mask: 0.2809  loss_rpn_cls: 0.06861  loss_rpn_loc: 0.1468  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:56:53 d2.utils.events]: \u001b[0m eta: 2:28:13  iter: 55759  total_loss: 1.025  loss_cls: 0.2102  loss_box_reg: 0.323  loss_mask: 0.2392  loss_rpn_cls: 0.04241  loss_rpn_loc: 0.1444  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:56:58 d2.utils.events]: \u001b[0m eta: 2:28:15  iter: 55779  total_loss: 1.108  loss_cls: 0.2733  loss_box_reg: 0.3349  loss_mask: 0.2439  loss_rpn_cls: 0.06856  loss_rpn_loc: 0.1558  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:57:03 d2.utils.events]: \u001b[0m eta: 2:28:26  iter: 55799  total_loss: 1.324  loss_cls: 0.3381  loss_box_reg: 0.4156  loss_mask: 0.264  loss_rpn_cls: 0.09676  loss_rpn_loc: 0.1688  time: 0.2238  data_time: 0.0165  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:57:08 d2.utils.events]: \u001b[0m eta: 2:28:27  iter: 55819  total_loss: 1.223  loss_cls: 0.2842  loss_box_reg: 0.3466  loss_mask: 0.2539  loss_rpn_cls: 0.08743  loss_rpn_loc: 0.167  time: 0.2238  data_time: 0.0190  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:57:12 d2.utils.events]: \u001b[0m eta: 2:28:22  iter: 55839  total_loss: 1.188  loss_cls: 0.2981  loss_box_reg: 0.3727  loss_mask: 0.2531  loss_rpn_cls: 0.08433  loss_rpn_loc: 0.1663  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:57:16 d2.utils.events]: \u001b[0m eta: 2:28:02  iter: 55859  total_loss: 1.084  loss_cls: 0.2736  loss_box_reg: 0.3888  loss_mask: 0.247  loss_rpn_cls: 0.06515  loss_rpn_loc: 0.1444  time: 0.2238  data_time: 0.0057  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:57:21 d2.utils.events]: \u001b[0m eta: 2:27:55  iter: 55879  total_loss: 1.252  loss_cls: 0.3451  loss_box_reg: 0.3867  loss_mask: 0.2643  loss_rpn_cls: 0.08703  loss_rpn_loc: 0.1524  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:57:25 d2.utils.events]: \u001b[0m eta: 2:27:49  iter: 55899  total_loss: 0.9983  loss_cls: 0.2621  loss_box_reg: 0.3398  loss_mask: 0.2424  loss_rpn_cls: 0.04648  loss_rpn_loc: 0.1535  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:57:29 d2.utils.events]: \u001b[0m eta: 2:27:32  iter: 55919  total_loss: 1.311  loss_cls: 0.3285  loss_box_reg: 0.4327  loss_mask: 0.2787  loss_rpn_cls: 0.08112  loss_rpn_loc: 0.1545  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:57:34 d2.utils.events]: \u001b[0m eta: 2:27:28  iter: 55939  total_loss: 1.158  loss_cls: 0.2837  loss_box_reg: 0.3892  loss_mask: 0.2717  loss_rpn_cls: 0.09875  loss_rpn_loc: 0.1748  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:57:38 d2.utils.events]: \u001b[0m eta: 2:27:24  iter: 55959  total_loss: 1.249  loss_cls: 0.3312  loss_box_reg: 0.3817  loss_mask: 0.2737  loss_rpn_cls: 0.08262  loss_rpn_loc: 0.1672  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:57:43 d2.utils.events]: \u001b[0m eta: 2:27:33  iter: 55979  total_loss: 1.062  loss_cls: 0.254  loss_box_reg: 0.3346  loss_mask: 0.2368  loss_rpn_cls: 0.08783  loss_rpn_loc: 0.1646  time: 0.2238  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:57:47 d2.utils.events]: \u001b[0m eta: 2:27:28  iter: 55999  total_loss: 1.15  loss_cls: 0.3071  loss_box_reg: 0.3761  loss_mask: 0.2757  loss_rpn_cls: 0.05276  loss_rpn_loc: 0.1516  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:57:52 d2.utils.events]: \u001b[0m eta: 2:27:33  iter: 56019  total_loss: 1.156  loss_cls: 0.2832  loss_box_reg: 0.3677  loss_mask: 0.2621  loss_rpn_cls: 0.06854  loss_rpn_loc: 0.1744  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:57:57 d2.utils.events]: \u001b[0m eta: 2:27:39  iter: 56039  total_loss: 1.109  loss_cls: 0.2772  loss_box_reg: 0.342  loss_mask: 0.2591  loss_rpn_cls: 0.09431  loss_rpn_loc: 0.1639  time: 0.2238  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:58:01 d2.utils.events]: \u001b[0m eta: 2:27:34  iter: 56059  total_loss: 1.127  loss_cls: 0.2955  loss_box_reg: 0.3615  loss_mask: 0.2667  loss_rpn_cls: 0.06159  loss_rpn_loc: 0.1559  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:58:06 d2.utils.events]: \u001b[0m eta: 2:27:27  iter: 56079  total_loss: 1.15  loss_cls: 0.308  loss_box_reg: 0.3907  loss_mask: 0.2686  loss_rpn_cls: 0.05451  loss_rpn_loc: 0.1392  time: 0.2238  data_time: 0.0175  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:58:10 d2.utils.events]: \u001b[0m eta: 2:27:25  iter: 56099  total_loss: 1.166  loss_cls: 0.2769  loss_box_reg: 0.3613  loss_mask: 0.2697  loss_rpn_cls: 0.06277  loss_rpn_loc: 0.1677  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:58:15 d2.utils.events]: \u001b[0m eta: 2:27:20  iter: 56119  total_loss: 1.219  loss_cls: 0.3049  loss_box_reg: 0.3955  loss_mask: 0.2659  loss_rpn_cls: 0.08247  loss_rpn_loc: 0.1691  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:58:19 d2.utils.events]: \u001b[0m eta: 2:27:08  iter: 56139  total_loss: 1.231  loss_cls: 0.3283  loss_box_reg: 0.3586  loss_mask: 0.2767  loss_rpn_cls: 0.09641  loss_rpn_loc: 0.177  time: 0.2238  data_time: 0.0179  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:58:24 d2.utils.events]: \u001b[0m eta: 2:27:12  iter: 56159  total_loss: 1.138  loss_cls: 0.2539  loss_box_reg: 0.3442  loss_mask: 0.2659  loss_rpn_cls: 0.09349  loss_rpn_loc: 0.1585  time: 0.2238  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:58:29 d2.utils.events]: \u001b[0m eta: 2:27:08  iter: 56179  total_loss: 1.13  loss_cls: 0.2579  loss_box_reg: 0.3597  loss_mask: 0.2627  loss_rpn_cls: 0.07737  loss_rpn_loc: 0.1797  time: 0.2238  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:58:33 d2.utils.events]: \u001b[0m eta: 2:27:13  iter: 56199  total_loss: 1.132  loss_cls: 0.2732  loss_box_reg: 0.35  loss_mask: 0.2653  loss_rpn_cls: 0.08112  loss_rpn_loc: 0.1763  time: 0.2238  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:58:38 d2.utils.events]: \u001b[0m eta: 2:27:12  iter: 56219  total_loss: 1.244  loss_cls: 0.3226  loss_box_reg: 0.3822  loss_mask: 0.2738  loss_rpn_cls: 0.07208  loss_rpn_loc: 0.1725  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:58:42 d2.utils.events]: \u001b[0m eta: 2:27:07  iter: 56239  total_loss: 1.186  loss_cls: 0.3158  loss_box_reg: 0.3714  loss_mask: 0.2668  loss_rpn_cls: 0.07409  loss_rpn_loc: 0.1641  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:58:47 d2.utils.events]: \u001b[0m eta: 2:27:04  iter: 56259  total_loss: 1.24  loss_cls: 0.3433  loss_box_reg: 0.4142  loss_mask: 0.2645  loss_rpn_cls: 0.07514  loss_rpn_loc: 0.1628  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:58:52 d2.utils.events]: \u001b[0m eta: 2:26:59  iter: 56279  total_loss: 1.22  loss_cls: 0.2897  loss_box_reg: 0.3762  loss_mask: 0.2782  loss_rpn_cls: 0.07265  loss_rpn_loc: 0.1734  time: 0.2238  data_time: 0.0103  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:58:56 d2.utils.events]: \u001b[0m eta: 2:26:54  iter: 56299  total_loss: 1.259  loss_cls: 0.2921  loss_box_reg: 0.4138  loss_mask: 0.2705  loss_rpn_cls: 0.0583  loss_rpn_loc: 0.1764  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:59:01 d2.utils.events]: \u001b[0m eta: 2:26:46  iter: 56319  total_loss: 1.159  loss_cls: 0.2745  loss_box_reg: 0.3771  loss_mask: 0.2602  loss_rpn_cls: 0.08025  loss_rpn_loc: 0.1852  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 00:59:05 d2.utils.events]: \u001b[0m eta: 2:26:36  iter: 56339  total_loss: 1.181  loss_cls: 0.2707  loss_box_reg: 0.401  loss_mask: 0.2568  loss_rpn_cls: 0.06215  loss_rpn_loc: 0.1535  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:59:09 d2.utils.events]: \u001b[0m eta: 2:26:37  iter: 56359  total_loss: 1.125  loss_cls: 0.3001  loss_box_reg: 0.3626  loss_mask: 0.2425  loss_rpn_cls: 0.05159  loss_rpn_loc: 0.16  time: 0.2238  data_time: 0.0140  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:59:14 d2.utils.events]: \u001b[0m eta: 2:26:30  iter: 56379  total_loss: 1.106  loss_cls: 0.2626  loss_box_reg: 0.3551  loss_mask: 0.2549  loss_rpn_cls: 0.07928  loss_rpn_loc: 0.1656  time: 0.2238  data_time: 0.0173  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:59:18 d2.utils.events]: \u001b[0m eta: 2:26:22  iter: 56399  total_loss: 1.243  loss_cls: 0.3154  loss_box_reg: 0.4219  loss_mask: 0.262  loss_rpn_cls: 0.05537  loss_rpn_loc: 0.1647  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:59:23 d2.utils.events]: \u001b[0m eta: 2:26:16  iter: 56419  total_loss: 1.198  loss_cls: 0.2747  loss_box_reg: 0.406  loss_mask: 0.2656  loss_rpn_cls: 0.06741  loss_rpn_loc: 0.1533  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:59:27 d2.utils.events]: \u001b[0m eta: 2:26:11  iter: 56439  total_loss: 1.267  loss_cls: 0.3191  loss_box_reg: 0.3923  loss_mask: 0.2805  loss_rpn_cls: 0.0674  loss_rpn_loc: 0.1732  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:59:31 d2.utils.events]: \u001b[0m eta: 2:26:06  iter: 56459  total_loss: 1.187  loss_cls: 0.2883  loss_box_reg: 0.3685  loss_mask: 0.2567  loss_rpn_cls: 0.0649  loss_rpn_loc: 0.1732  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:59:36 d2.utils.events]: \u001b[0m eta: 2:26:02  iter: 56479  total_loss: 1.189  loss_cls: 0.299  loss_box_reg: 0.3501  loss_mask: 0.2683  loss_rpn_cls: 0.06461  loss_rpn_loc: 0.1569  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:59:41 d2.utils.events]: \u001b[0m eta: 2:26:00  iter: 56499  total_loss: 1.228  loss_cls: 0.2998  loss_box_reg: 0.4024  loss_mask: 0.2723  loss_rpn_cls: 0.09156  loss_rpn_loc: 0.1716  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:59:45 d2.utils.events]: \u001b[0m eta: 2:25:52  iter: 56519  total_loss: 1.152  loss_cls: 0.2829  loss_box_reg: 0.3763  loss_mask: 0.2508  loss_rpn_cls: 0.06274  loss_rpn_loc: 0.1842  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:59:49 d2.utils.events]: \u001b[0m eta: 2:25:49  iter: 56539  total_loss: 1.119  loss_cls: 0.2675  loss_box_reg: 0.3863  loss_mask: 0.2592  loss_rpn_cls: 0.05542  loss_rpn_loc: 0.1482  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:59:54 d2.utils.events]: \u001b[0m eta: 2:25:46  iter: 56559  total_loss: 1.282  loss_cls: 0.3196  loss_box_reg: 0.4243  loss_mask: 0.2837  loss_rpn_cls: 0.1088  loss_rpn_loc: 0.1703  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 00:59:58 d2.utils.events]: \u001b[0m eta: 2:25:40  iter: 56579  total_loss: 1.174  loss_cls: 0.2709  loss_box_reg: 0.3755  loss_mask: 0.2703  loss_rpn_cls: 0.06129  loss_rpn_loc: 0.1456  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:00:02 d2.utils.events]: \u001b[0m eta: 2:25:37  iter: 56599  total_loss: 1.108  loss_cls: 0.3105  loss_box_reg: 0.3671  loss_mask: 0.2545  loss_rpn_cls: 0.06079  loss_rpn_loc: 0.158  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:00:07 d2.utils.events]: \u001b[0m eta: 2:25:31  iter: 56619  total_loss: 1.2  loss_cls: 0.3128  loss_box_reg: 0.4277  loss_mask: 0.2724  loss_rpn_cls: 0.07901  loss_rpn_loc: 0.1615  time: 0.2238  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:00:11 d2.utils.events]: \u001b[0m eta: 2:25:12  iter: 56639  total_loss: 1.264  loss_cls: 0.3154  loss_box_reg: 0.3976  loss_mask: 0.2741  loss_rpn_cls: 0.08083  loss_rpn_loc: 0.1753  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:00:16 d2.utils.events]: \u001b[0m eta: 2:25:13  iter: 56659  total_loss: 1.157  loss_cls: 0.2823  loss_box_reg: 0.3663  loss_mask: 0.2744  loss_rpn_cls: 0.08454  loss_rpn_loc: 0.1582  time: 0.2238  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:00:20 d2.utils.events]: \u001b[0m eta: 2:25:03  iter: 56679  total_loss: 1.091  loss_cls: 0.2663  loss_box_reg: 0.3619  loss_mask: 0.2473  loss_rpn_cls: 0.05968  loss_rpn_loc: 0.1607  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:00:25 d2.utils.events]: \u001b[0m eta: 2:24:58  iter: 56699  total_loss: 1.201  loss_cls: 0.299  loss_box_reg: 0.3482  loss_mask: 0.2589  loss_rpn_cls: 0.07632  loss_rpn_loc: 0.1502  time: 0.2238  data_time: 0.0178  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:00:29 d2.utils.events]: \u001b[0m eta: 2:24:52  iter: 56719  total_loss: 1.175  loss_cls: 0.2974  loss_box_reg: 0.4124  loss_mask: 0.2552  loss_rpn_cls: 0.08142  loss_rpn_loc: 0.1549  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:00:34 d2.utils.events]: \u001b[0m eta: 2:24:55  iter: 56739  total_loss: 1.147  loss_cls: 0.2867  loss_box_reg: 0.3224  loss_mask: 0.2666  loss_rpn_cls: 0.09927  loss_rpn_loc: 0.1688  time: 0.2238  data_time: 0.0184  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:00:39 d2.utils.events]: \u001b[0m eta: 2:24:57  iter: 56759  total_loss: 1.141  loss_cls: 0.2499  loss_box_reg: 0.3503  loss_mask: 0.2707  loss_rpn_cls: 0.08408  loss_rpn_loc: 0.1599  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:00:43 d2.utils.events]: \u001b[0m eta: 2:24:46  iter: 56779  total_loss: 1.198  loss_cls: 0.2997  loss_box_reg: 0.3942  loss_mask: 0.2536  loss_rpn_cls: 0.07146  loss_rpn_loc: 0.1834  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:00:47 d2.utils.events]: \u001b[0m eta: 2:24:21  iter: 56799  total_loss: 1.132  loss_cls: 0.2748  loss_box_reg: 0.3603  loss_mask: 0.2521  loss_rpn_cls: 0.0589  loss_rpn_loc: 0.1673  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:00:52 d2.utils.events]: \u001b[0m eta: 2:24:08  iter: 56819  total_loss: 1.142  loss_cls: 0.2769  loss_box_reg: 0.3685  loss_mask: 0.2641  loss_rpn_cls: 0.07194  loss_rpn_loc: 0.1598  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:00:56 d2.utils.events]: \u001b[0m eta: 2:23:57  iter: 56839  total_loss: 1.246  loss_cls: 0.3168  loss_box_reg: 0.3953  loss_mask: 0.2627  loss_rpn_cls: 0.1085  loss_rpn_loc: 0.181  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:01:00 d2.utils.events]: \u001b[0m eta: 2:23:57  iter: 56859  total_loss: 1.193  loss_cls: 0.3021  loss_box_reg: 0.4079  loss_mask: 0.2489  loss_rpn_cls: 0.08132  loss_rpn_loc: 0.1651  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:01:05 d2.utils.events]: \u001b[0m eta: 2:23:55  iter: 56879  total_loss: 1.038  loss_cls: 0.2305  loss_box_reg: 0.332  loss_mask: 0.247  loss_rpn_cls: 0.05903  loss_rpn_loc: 0.147  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:01:09 d2.utils.events]: \u001b[0m eta: 2:23:50  iter: 56899  total_loss: 1.24  loss_cls: 0.314  loss_box_reg: 0.412  loss_mask: 0.2528  loss_rpn_cls: 0.06596  loss_rpn_loc: 0.1605  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:01:14 d2.utils.events]: \u001b[0m eta: 2:24:03  iter: 56919  total_loss: 1.15  loss_cls: 0.2946  loss_box_reg: 0.3547  loss_mask: 0.2533  loss_rpn_cls: 0.07489  loss_rpn_loc: 0.165  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:01:18 d2.utils.events]: \u001b[0m eta: 2:24:09  iter: 56939  total_loss: 1.134  loss_cls: 0.2767  loss_box_reg: 0.3592  loss_mask: 0.2413  loss_rpn_cls: 0.06697  loss_rpn_loc: 0.1672  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:01:23 d2.utils.events]: \u001b[0m eta: 2:24:14  iter: 56959  total_loss: 1.083  loss_cls: 0.2493  loss_box_reg: 0.3467  loss_mask: 0.271  loss_rpn_cls: 0.05394  loss_rpn_loc: 0.1475  time: 0.2238  data_time: 0.0173  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:01:27 d2.utils.events]: \u001b[0m eta: 2:23:47  iter: 56979  total_loss: 1.226  loss_cls: 0.325  loss_box_reg: 0.3904  loss_mask: 0.2651  loss_rpn_cls: 0.09642  loss_rpn_loc: 0.1741  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:01:32 d2.utils.events]: \u001b[0m eta: 2:23:33  iter: 56999  total_loss: 1.083  loss_cls: 0.2803  loss_box_reg: 0.3576  loss_mask: 0.2405  loss_rpn_cls: 0.08539  loss_rpn_loc: 0.1655  time: 0.2238  data_time: 0.0105  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:01:37 d2.utils.events]: \u001b[0m eta: 2:23:24  iter: 57019  total_loss: 1.179  loss_cls: 0.2757  loss_box_reg: 0.3887  loss_mask: 0.2617  loss_rpn_cls: 0.07754  loss_rpn_loc: 0.1521  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:01:41 d2.utils.events]: \u001b[0m eta: 2:23:13  iter: 57039  total_loss: 1.139  loss_cls: 0.3005  loss_box_reg: 0.3582  loss_mask: 0.2563  loss_rpn_cls: 0.06679  loss_rpn_loc: 0.1695  time: 0.2238  data_time: 0.0126  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:01:46 d2.utils.events]: \u001b[0m eta: 2:23:13  iter: 57059  total_loss: 1.34  loss_cls: 0.3363  loss_box_reg: 0.3772  loss_mask: 0.2877  loss_rpn_cls: 0.09228  loss_rpn_loc: 0.1921  time: 0.2238  data_time: 0.0179  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:01:50 d2.utils.events]: \u001b[0m eta: 2:23:03  iter: 57079  total_loss: 1.142  loss_cls: 0.2501  loss_box_reg: 0.3787  loss_mask: 0.254  loss_rpn_cls: 0.06683  loss_rpn_loc: 0.1723  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:01:55 d2.utils.events]: \u001b[0m eta: 2:22:52  iter: 57099  total_loss: 1.158  loss_cls: 0.2715  loss_box_reg: 0.3653  loss_mask: 0.2497  loss_rpn_cls: 0.06608  loss_rpn_loc: 0.1565  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:01:59 d2.utils.events]: \u001b[0m eta: 2:22:54  iter: 57119  total_loss: 1.231  loss_cls: 0.309  loss_box_reg: 0.4041  loss_mask: 0.2682  loss_rpn_cls: 0.07863  loss_rpn_loc: 0.1575  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:02:04 d2.utils.events]: \u001b[0m eta: 2:22:58  iter: 57139  total_loss: 1.011  loss_cls: 0.2132  loss_box_reg: 0.3158  loss_mask: 0.2354  loss_rpn_cls: 0.0553  loss_rpn_loc: 0.1536  time: 0.2238  data_time: 0.0112  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:02:08 d2.utils.events]: \u001b[0m eta: 2:22:46  iter: 57159  total_loss: 1.206  loss_cls: 0.2887  loss_box_reg: 0.3839  loss_mask: 0.2589  loss_rpn_cls: 0.09294  loss_rpn_loc: 0.1791  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:02:13 d2.utils.events]: \u001b[0m eta: 2:22:39  iter: 57179  total_loss: 1.182  loss_cls: 0.2569  loss_box_reg: 0.406  loss_mask: 0.2737  loss_rpn_cls: 0.08767  loss_rpn_loc: 0.1706  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:02:17 d2.utils.events]: \u001b[0m eta: 2:22:17  iter: 57199  total_loss: 1.202  loss_cls: 0.3031  loss_box_reg: 0.4124  loss_mask: 0.2847  loss_rpn_cls: 0.07506  loss_rpn_loc: 0.1517  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:02:22 d2.utils.events]: \u001b[0m eta: 2:22:11  iter: 57219  total_loss: 1.118  loss_cls: 0.2753  loss_box_reg: 0.3677  loss_mask: 0.258  loss_rpn_cls: 0.06354  loss_rpn_loc: 0.1462  time: 0.2238  data_time: 0.0250  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:02:26 d2.utils.events]: \u001b[0m eta: 2:22:00  iter: 57239  total_loss: 1.19  loss_cls: 0.3013  loss_box_reg: 0.4054  loss_mask: 0.2528  loss_rpn_cls: 0.07009  loss_rpn_loc: 0.1705  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:02:31 d2.utils.events]: \u001b[0m eta: 2:21:52  iter: 57259  total_loss: 1.146  loss_cls: 0.2576  loss_box_reg: 0.3612  loss_mask: 0.2672  loss_rpn_cls: 0.07864  loss_rpn_loc: 0.1693  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:02:36 d2.utils.events]: \u001b[0m eta: 2:21:52  iter: 57279  total_loss: 1.113  loss_cls: 0.2565  loss_box_reg: 0.3469  loss_mask: 0.2661  loss_rpn_cls: 0.09577  loss_rpn_loc: 0.1857  time: 0.2238  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:02:40 d2.utils.events]: \u001b[0m eta: 2:21:45  iter: 57299  total_loss: 1.194  loss_cls: 0.2943  loss_box_reg: 0.3687  loss_mask: 0.256  loss_rpn_cls: 0.06754  loss_rpn_loc: 0.1648  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:02:44 d2.utils.events]: \u001b[0m eta: 2:21:42  iter: 57319  total_loss: 1.206  loss_cls: 0.2992  loss_box_reg: 0.3793  loss_mask: 0.2636  loss_rpn_cls: 0.07902  loss_rpn_loc: 0.1655  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:02:49 d2.utils.events]: \u001b[0m eta: 2:21:35  iter: 57339  total_loss: 1.163  loss_cls: 0.2899  loss_box_reg: 0.3688  loss_mask: 0.2692  loss_rpn_cls: 0.04781  loss_rpn_loc: 0.1499  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:02:53 d2.utils.events]: \u001b[0m eta: 2:21:31  iter: 57359  total_loss: 1.1  loss_cls: 0.2623  loss_box_reg: 0.3625  loss_mask: 0.2555  loss_rpn_cls: 0.05307  loss_rpn_loc: 0.1402  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:02:58 d2.utils.events]: \u001b[0m eta: 2:21:26  iter: 57379  total_loss: 1.051  loss_cls: 0.2526  loss_box_reg: 0.3249  loss_mask: 0.2496  loss_rpn_cls: 0.06632  loss_rpn_loc: 0.1657  time: 0.2238  data_time: 0.0162  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:03:02 d2.utils.events]: \u001b[0m eta: 2:21:19  iter: 57399  total_loss: 1.127  loss_cls: 0.2733  loss_box_reg: 0.416  loss_mask: 0.2557  loss_rpn_cls: 0.08838  loss_rpn_loc: 0.1861  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:03:06 d2.utils.events]: \u001b[0m eta: 2:21:03  iter: 57419  total_loss: 1.164  loss_cls: 0.2888  loss_box_reg: 0.3882  loss_mask: 0.2502  loss_rpn_cls: 0.06496  loss_rpn_loc: 0.1537  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:03:11 d2.utils.events]: \u001b[0m eta: 2:20:54  iter: 57439  total_loss: 1.226  loss_cls: 0.295  loss_box_reg: 0.4171  loss_mask: 0.266  loss_rpn_cls: 0.07149  loss_rpn_loc: 0.1596  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:03:15 d2.utils.events]: \u001b[0m eta: 2:20:38  iter: 57459  total_loss: 1.154  loss_cls: 0.2864  loss_box_reg: 0.3858  loss_mask: 0.2348  loss_rpn_cls: 0.05898  loss_rpn_loc: 0.1624  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:03:20 d2.utils.events]: \u001b[0m eta: 2:20:29  iter: 57479  total_loss: 1.139  loss_cls: 0.2501  loss_box_reg: 0.3299  loss_mask: 0.2538  loss_rpn_cls: 0.05762  loss_rpn_loc: 0.1588  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:03:24 d2.utils.events]: \u001b[0m eta: 2:20:24  iter: 57499  total_loss: 1.296  loss_cls: 0.3302  loss_box_reg: 0.4457  loss_mask: 0.267  loss_rpn_cls: 0.07587  loss_rpn_loc: 0.1585  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:03:29 d2.utils.events]: \u001b[0m eta: 2:20:29  iter: 57519  total_loss: 1.076  loss_cls: 0.2313  loss_box_reg: 0.3764  loss_mask: 0.2598  loss_rpn_cls: 0.05795  loss_rpn_loc: 0.1504  time: 0.2238  data_time: 0.0232  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:03:33 d2.utils.events]: \u001b[0m eta: 2:20:16  iter: 57539  total_loss: 1.137  loss_cls: 0.2871  loss_box_reg: 0.379  loss_mask: 0.2656  loss_rpn_cls: 0.06337  loss_rpn_loc: 0.1653  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:03:38 d2.utils.events]: \u001b[0m eta: 2:20:11  iter: 57559  total_loss: 1.11  loss_cls: 0.288  loss_box_reg: 0.3511  loss_mask: 0.2378  loss_rpn_cls: 0.07058  loss_rpn_loc: 0.1596  time: 0.2238  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:03:42 d2.utils.events]: \u001b[0m eta: 2:20:09  iter: 57579  total_loss: 1.141  loss_cls: 0.274  loss_box_reg: 0.3501  loss_mask: 0.2442  loss_rpn_cls: 0.05976  loss_rpn_loc: 0.1629  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:03:46 d2.utils.events]: \u001b[0m eta: 2:20:05  iter: 57599  total_loss: 1.213  loss_cls: 0.3207  loss_box_reg: 0.3894  loss_mask: 0.2677  loss_rpn_cls: 0.06239  loss_rpn_loc: 0.165  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:03:51 d2.utils.events]: \u001b[0m eta: 2:19:56  iter: 57619  total_loss: 1.109  loss_cls: 0.254  loss_box_reg: 0.3865  loss_mask: 0.2512  loss_rpn_cls: 0.05748  loss_rpn_loc: 0.1544  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:03:55 d2.utils.events]: \u001b[0m eta: 2:19:49  iter: 57639  total_loss: 1.223  loss_cls: 0.2929  loss_box_reg: 0.4114  loss_mask: 0.2638  loss_rpn_cls: 0.06722  loss_rpn_loc: 0.1527  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:03:59 d2.utils.events]: \u001b[0m eta: 2:19:50  iter: 57659  total_loss: 1.257  loss_cls: 0.3259  loss_box_reg: 0.4102  loss_mask: 0.2787  loss_rpn_cls: 0.08421  loss_rpn_loc: 0.169  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:04:04 d2.utils.events]: \u001b[0m eta: 2:19:58  iter: 57679  total_loss: 1.302  loss_cls: 0.3251  loss_box_reg: 0.4077  loss_mask: 0.2789  loss_rpn_cls: 0.0879  loss_rpn_loc: 0.1809  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:04:09 d2.utils.events]: \u001b[0m eta: 2:19:55  iter: 57699  total_loss: 1.292  loss_cls: 0.3064  loss_box_reg: 0.3739  loss_mask: 0.2638  loss_rpn_cls: 0.08054  loss_rpn_loc: 0.1908  time: 0.2238  data_time: 0.0372  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:04:14 d2.utils.events]: \u001b[0m eta: 2:19:58  iter: 57719  total_loss: 1.187  loss_cls: 0.2797  loss_box_reg: 0.371  loss_mask: 0.2686  loss_rpn_cls: 0.0796  loss_rpn_loc: 0.1648  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:04:18 d2.utils.events]: \u001b[0m eta: 2:19:46  iter: 57739  total_loss: 1.21  loss_cls: 0.2844  loss_box_reg: 0.3983  loss_mask: 0.2825  loss_rpn_cls: 0.07335  loss_rpn_loc: 0.1515  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:04:23 d2.utils.events]: \u001b[0m eta: 2:19:40  iter: 57759  total_loss: 1.124  loss_cls: 0.2606  loss_box_reg: 0.3633  loss_mask: 0.2553  loss_rpn_cls: 0.06749  loss_rpn_loc: 0.1604  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:04:27 d2.utils.events]: \u001b[0m eta: 2:19:26  iter: 57779  total_loss: 1.171  loss_cls: 0.2924  loss_box_reg: 0.4189  loss_mask: 0.2455  loss_rpn_cls: 0.05423  loss_rpn_loc: 0.1508  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:04:31 d2.utils.events]: \u001b[0m eta: 2:19:25  iter: 57799  total_loss: 1.222  loss_cls: 0.3261  loss_box_reg: 0.4046  loss_mask: 0.2675  loss_rpn_cls: 0.06556  loss_rpn_loc: 0.177  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:04:35 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.55 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 01:04:35 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 01:04:35 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 01:04:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 01:04:36 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 01:04:36 d2.data.common]: \u001b[0mSerialized dataset takes 84.20 MiB\n",
      "\u001b[32m[12/30 01:04:39 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.06 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 01:04:39 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 01:04:39 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 01:04:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/30 01:04:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0007 s/iter. Inference: 0.0622 s/iter. Eval: 0.1439 s/iter. Total: 0.2068 s/iter. ETA=0:01:55\n",
      "\u001b[32m[12/30 01:04:47 d2.evaluation.evaluator]: \u001b[0mInference done 39/570. Dataloading: 0.0008 s/iter. Inference: 0.0561 s/iter. Eval: 0.1274 s/iter. Total: 0.1844 s/iter. ETA=0:01:37\n",
      "\u001b[32m[12/30 01:04:52 d2.evaluation.evaluator]: \u001b[0mInference done 66/570. Dataloading: 0.0009 s/iter. Inference: 0.0561 s/iter. Eval: 0.1281 s/iter. Total: 0.1852 s/iter. ETA=0:01:33\n",
      "\u001b[32m[12/30 01:04:57 d2.evaluation.evaluator]: \u001b[0mInference done 91/570. Dataloading: 0.0009 s/iter. Inference: 0.0565 s/iter. Eval: 0.1331 s/iter. Total: 0.1906 s/iter. ETA=0:01:31\n",
      "\u001b[32m[12/30 01:05:02 d2.evaluation.evaluator]: \u001b[0mInference done 118/570. Dataloading: 0.0009 s/iter. Inference: 0.0555 s/iter. Eval: 0.1336 s/iter. Total: 0.1900 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/30 01:05:08 d2.evaluation.evaluator]: \u001b[0mInference done 142/570. Dataloading: 0.0009 s/iter. Inference: 0.0554 s/iter. Eval: 0.1377 s/iter. Total: 0.1940 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 01:05:13 d2.evaluation.evaluator]: \u001b[0mInference done 162/570. Dataloading: 0.0009 s/iter. Inference: 0.0556 s/iter. Eval: 0.1468 s/iter. Total: 0.2034 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 01:05:18 d2.evaluation.evaluator]: \u001b[0mInference done 175/570. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.1616 s/iter. Total: 0.2184 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/30 01:05:23 d2.evaluation.evaluator]: \u001b[0mInference done 193/570. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.1676 s/iter. Total: 0.2245 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/30 01:05:28 d2.evaluation.evaluator]: \u001b[0mInference done 209/570. Dataloading: 0.0009 s/iter. Inference: 0.0562 s/iter. Eval: 0.1749 s/iter. Total: 0.2320 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 01:05:34 d2.evaluation.evaluator]: \u001b[0mInference done 226/570. Dataloading: 0.0009 s/iter. Inference: 0.0566 s/iter. Eval: 0.1823 s/iter. Total: 0.2398 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 01:05:39 d2.evaluation.evaluator]: \u001b[0mInference done 237/570. Dataloading: 0.0009 s/iter. Inference: 0.0567 s/iter. Eval: 0.1928 s/iter. Total: 0.2505 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 01:05:44 d2.evaluation.evaluator]: \u001b[0mInference done 250/570. Dataloading: 0.0009 s/iter. Inference: 0.0568 s/iter. Eval: 0.2013 s/iter. Total: 0.2590 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 01:05:50 d2.evaluation.evaluator]: \u001b[0mInference done 266/570. Dataloading: 0.0009 s/iter. Inference: 0.0569 s/iter. Eval: 0.2057 s/iter. Total: 0.2635 s/iter. ETA=0:01:20\n",
      "\u001b[32m[12/30 01:05:55 d2.evaluation.evaluator]: \u001b[0mInference done 285/570. Dataloading: 0.0009 s/iter. Inference: 0.0570 s/iter. Eval: 0.2061 s/iter. Total: 0.2640 s/iter. ETA=0:01:15\n",
      "\u001b[32m[12/30 01:06:00 d2.evaluation.evaluator]: \u001b[0mInference done 298/570. Dataloading: 0.0009 s/iter. Inference: 0.0571 s/iter. Eval: 0.2115 s/iter. Total: 0.2695 s/iter. ETA=0:01:13\n",
      "\u001b[32m[12/30 01:06:05 d2.evaluation.evaluator]: \u001b[0mInference done 346/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1897 s/iter. Total: 0.2464 s/iter. ETA=0:00:55\n",
      "\u001b[32m[12/30 01:06:10 d2.evaluation.evaluator]: \u001b[0mInference done 376/570. Dataloading: 0.0009 s/iter. Inference: 0.0554 s/iter. Eval: 0.1843 s/iter. Total: 0.2406 s/iter. ETA=0:00:46\n",
      "\u001b[32m[12/30 01:06:15 d2.evaluation.evaluator]: \u001b[0mInference done 398/570. Dataloading: 0.0009 s/iter. Inference: 0.0555 s/iter. Eval: 0.1835 s/iter. Total: 0.2400 s/iter. ETA=0:00:41\n",
      "\u001b[32m[12/30 01:06:21 d2.evaluation.evaluator]: \u001b[0mInference done 416/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1859 s/iter. Total: 0.2425 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/30 01:06:26 d2.evaluation.evaluator]: \u001b[0mInference done 435/570. Dataloading: 0.0009 s/iter. Inference: 0.0560 s/iter. Eval: 0.1869 s/iter. Total: 0.2438 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/30 01:06:31 d2.evaluation.evaluator]: \u001b[0mInference done 464/570. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.1826 s/iter. Total: 0.2395 s/iter. ETA=0:00:25\n",
      "\u001b[32m[12/30 01:06:36 d2.evaluation.evaluator]: \u001b[0mInference done 495/570. Dataloading: 0.0009 s/iter. Inference: 0.0555 s/iter. Eval: 0.1784 s/iter. Total: 0.2348 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/30 01:06:41 d2.evaluation.evaluator]: \u001b[0mInference done 515/570. Dataloading: 0.0009 s/iter. Inference: 0.0553 s/iter. Eval: 0.1793 s/iter. Total: 0.2355 s/iter. ETA=0:00:12\n",
      "\u001b[32m[12/30 01:06:46 d2.evaluation.evaluator]: \u001b[0mInference done 539/570. Dataloading: 0.0009 s/iter. Inference: 0.0553 s/iter. Eval: 0.1786 s/iter. Total: 0.2348 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/30 01:06:51 d2.evaluation.evaluator]: \u001b[0mInference done 556/570. Dataloading: 0.0009 s/iter. Inference: 0.0554 s/iter. Eval: 0.1803 s/iter. Total: 0.2367 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 01:06:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:14.054319 (0.237264 s / iter per device, on 1 devices)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:06:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.055503 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 01:06:55 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/30 01:06:55 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.28688621102518036\n",
      "\u001b[32m[12/30 01:06:59 d2.utils.events]: \u001b[0m eta: 2:19:36  iter: 57819  total_loss: 1.253  loss_cls: 0.3266  loss_box_reg: 0.4197  loss_mask: 0.2535  loss_rpn_cls: 0.09333  loss_rpn_loc: 0.1727  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:07:03 d2.utils.events]: \u001b[0m eta: 2:19:42  iter: 57839  total_loss: 1.176  loss_cls: 0.2907  loss_box_reg: 0.3748  loss_mask: 0.2448  loss_rpn_cls: 0.07303  loss_rpn_loc: 0.1594  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:07:08 d2.utils.events]: \u001b[0m eta: 2:19:42  iter: 57859  total_loss: 1.141  loss_cls: 0.259  loss_box_reg: 0.3169  loss_mask: 0.2415  loss_rpn_cls: 0.08561  loss_rpn_loc: 0.1533  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:07:12 d2.utils.events]: \u001b[0m eta: 2:19:38  iter: 57879  total_loss: 1.206  loss_cls: 0.2914  loss_box_reg: 0.372  loss_mask: 0.2693  loss_rpn_cls: 0.07737  loss_rpn_loc: 0.1702  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:07:17 d2.utils.events]: \u001b[0m eta: 2:19:26  iter: 57899  total_loss: 1.196  loss_cls: 0.2771  loss_box_reg: 0.3874  loss_mask: 0.2536  loss_rpn_cls: 0.07605  loss_rpn_loc: 0.1734  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:07:22 d2.utils.events]: \u001b[0m eta: 2:19:24  iter: 57919  total_loss: 1.289  loss_cls: 0.3165  loss_box_reg: 0.4033  loss_mask: 0.277  loss_rpn_cls: 0.09488  loss_rpn_loc: 0.183  time: 0.2238  data_time: 0.0191  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:07:26 d2.utils.events]: \u001b[0m eta: 2:19:20  iter: 57939  total_loss: 1.209  loss_cls: 0.3033  loss_box_reg: 0.4191  loss_mask: 0.2688  loss_rpn_cls: 0.0682  loss_rpn_loc: 0.1585  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:07:31 d2.utils.events]: \u001b[0m eta: 2:19:07  iter: 57959  total_loss: 1.16  loss_cls: 0.2695  loss_box_reg: 0.3369  loss_mask: 0.2572  loss_rpn_cls: 0.07774  loss_rpn_loc: 0.1682  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:07:35 d2.utils.events]: \u001b[0m eta: 2:19:11  iter: 57979  total_loss: 1.024  loss_cls: 0.2498  loss_box_reg: 0.3113  loss_mask: 0.2309  loss_rpn_cls: 0.07256  loss_rpn_loc: 0.1584  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:07:40 d2.utils.events]: \u001b[0m eta: 2:19:17  iter: 57999  total_loss: 1.173  loss_cls: 0.2976  loss_box_reg: 0.3902  loss_mask: 0.2667  loss_rpn_cls: 0.06946  loss_rpn_loc: 0.163  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:07:45 d2.utils.events]: \u001b[0m eta: 2:19:14  iter: 58019  total_loss: 1.183  loss_cls: 0.283  loss_box_reg: 0.3871  loss_mask: 0.2835  loss_rpn_cls: 0.09064  loss_rpn_loc: 0.1813  time: 0.2238  data_time: 0.0231  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:07:49 d2.utils.events]: \u001b[0m eta: 2:19:09  iter: 58039  total_loss: 1.15  loss_cls: 0.2864  loss_box_reg: 0.378  loss_mask: 0.251  loss_rpn_cls: 0.06531  loss_rpn_loc: 0.1634  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:07:54 d2.utils.events]: \u001b[0m eta: 2:19:12  iter: 58059  total_loss: 1.147  loss_cls: 0.2634  loss_box_reg: 0.3563  loss_mask: 0.2555  loss_rpn_cls: 0.08615  loss_rpn_loc: 0.1574  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:07:58 d2.utils.events]: \u001b[0m eta: 2:19:22  iter: 58079  total_loss: 1.211  loss_cls: 0.3068  loss_box_reg: 0.3874  loss_mask: 0.2672  loss_rpn_cls: 0.08924  loss_rpn_loc: 0.1697  time: 0.2238  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:08:03 d2.utils.events]: \u001b[0m eta: 2:19:03  iter: 58099  total_loss: 1.287  loss_cls: 0.3161  loss_box_reg: 0.4265  loss_mask: 0.2766  loss_rpn_cls: 0.05371  loss_rpn_loc: 0.1668  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:08:07 d2.utils.events]: \u001b[0m eta: 2:19:03  iter: 58119  total_loss: 1.255  loss_cls: 0.3001  loss_box_reg: 0.4194  loss_mask: 0.278  loss_rpn_cls: 0.08441  loss_rpn_loc: 0.1724  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:08:12 d2.utils.events]: \u001b[0m eta: 2:18:49  iter: 58139  total_loss: 1.094  loss_cls: 0.266  loss_box_reg: 0.3556  loss_mask: 0.2529  loss_rpn_cls: 0.08637  loss_rpn_loc: 0.1636  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:08:16 d2.utils.events]: \u001b[0m eta: 2:18:43  iter: 58159  total_loss: 1.189  loss_cls: 0.3048  loss_box_reg: 0.374  loss_mask: 0.2572  loss_rpn_cls: 0.06915  loss_rpn_loc: 0.1695  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:08:20 d2.utils.events]: \u001b[0m eta: 2:18:39  iter: 58179  total_loss: 1.258  loss_cls: 0.3333  loss_box_reg: 0.4342  loss_mask: 0.2596  loss_rpn_cls: 0.05423  loss_rpn_loc: 0.1616  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:08:25 d2.utils.events]: \u001b[0m eta: 2:18:35  iter: 58199  total_loss: 1.167  loss_cls: 0.2686  loss_box_reg: 0.3484  loss_mask: 0.2547  loss_rpn_cls: 0.05957  loss_rpn_loc: 0.161  time: 0.2238  data_time: 0.0210  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:08:29 d2.utils.events]: \u001b[0m eta: 2:18:28  iter: 58219  total_loss: 1.183  loss_cls: 0.2956  loss_box_reg: 0.3588  loss_mask: 0.2667  loss_rpn_cls: 0.06982  loss_rpn_loc: 0.1624  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:08:34 d2.utils.events]: \u001b[0m eta: 2:18:22  iter: 58239  total_loss: 1.185  loss_cls: 0.2982  loss_box_reg: 0.4031  loss_mask: 0.2629  loss_rpn_cls: 0.06626  loss_rpn_loc: 0.1675  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:08:38 d2.utils.events]: \u001b[0m eta: 2:18:07  iter: 58259  total_loss: 1.232  loss_cls: 0.3137  loss_box_reg: 0.4045  loss_mask: 0.2634  loss_rpn_cls: 0.074  loss_rpn_loc: 0.1563  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:08:43 d2.utils.events]: \u001b[0m eta: 2:18:02  iter: 58279  total_loss: 1.033  loss_cls: 0.2606  loss_box_reg: 0.3413  loss_mask: 0.2501  loss_rpn_cls: 0.07165  loss_rpn_loc: 0.1644  time: 0.2238  data_time: 0.0147  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:08:47 d2.utils.events]: \u001b[0m eta: 2:18:00  iter: 58299  total_loss: 1.058  loss_cls: 0.2308  loss_box_reg: 0.356  loss_mask: 0.2466  loss_rpn_cls: 0.05529  loss_rpn_loc: 0.152  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:08:51 d2.utils.events]: \u001b[0m eta: 2:17:50  iter: 58319  total_loss: 1.214  loss_cls: 0.3077  loss_box_reg: 0.415  loss_mask: 0.2678  loss_rpn_cls: 0.06238  loss_rpn_loc: 0.1633  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:08:56 d2.utils.events]: \u001b[0m eta: 2:18:02  iter: 58339  total_loss: 1.14  loss_cls: 0.2842  loss_box_reg: 0.3917  loss_mask: 0.254  loss_rpn_cls: 0.0675  loss_rpn_loc: 0.1736  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:09:00 d2.utils.events]: \u001b[0m eta: 2:17:57  iter: 58359  total_loss: 1.172  loss_cls: 0.2868  loss_box_reg: 0.4145  loss_mask: 0.2557  loss_rpn_cls: 0.05534  loss_rpn_loc: 0.1471  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:09:05 d2.utils.events]: \u001b[0m eta: 2:17:53  iter: 58379  total_loss: 1.086  loss_cls: 0.2714  loss_box_reg: 0.3664  loss_mask: 0.2648  loss_rpn_cls: 0.06176  loss_rpn_loc: 0.1624  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:09:09 d2.utils.events]: \u001b[0m eta: 2:17:48  iter: 58399  total_loss: 1.184  loss_cls: 0.2625  loss_box_reg: 0.3518  loss_mask: 0.2503  loss_rpn_cls: 0.07402  loss_rpn_loc: 0.1854  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:09:14 d2.utils.events]: \u001b[0m eta: 2:17:55  iter: 58419  total_loss: 1.137  loss_cls: 0.2771  loss_box_reg: 0.3863  loss_mask: 0.2612  loss_rpn_cls: 0.07662  loss_rpn_loc: 0.1655  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:09:18 d2.utils.events]: \u001b[0m eta: 2:17:52  iter: 58439  total_loss: 1.128  loss_cls: 0.2866  loss_box_reg: 0.3569  loss_mask: 0.2498  loss_rpn_cls: 0.08055  loss_rpn_loc: 0.1778  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:09:23 d2.utils.events]: \u001b[0m eta: 2:17:49  iter: 58459  total_loss: 0.9817  loss_cls: 0.2291  loss_box_reg: 0.3471  loss_mask: 0.2433  loss_rpn_cls: 0.07694  loss_rpn_loc: 0.1585  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:09:27 d2.utils.events]: \u001b[0m eta: 2:17:46  iter: 58479  total_loss: 1.18  loss_cls: 0.3088  loss_box_reg: 0.3904  loss_mask: 0.2772  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.1577  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:09:31 d2.utils.events]: \u001b[0m eta: 2:17:36  iter: 58499  total_loss: 1.067  loss_cls: 0.2571  loss_box_reg: 0.385  loss_mask: 0.2452  loss_rpn_cls: 0.06544  loss_rpn_loc: 0.1569  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:09:36 d2.utils.events]: \u001b[0m eta: 2:17:38  iter: 58519  total_loss: 1.099  loss_cls: 0.2732  loss_box_reg: 0.3898  loss_mask: 0.2559  loss_rpn_cls: 0.0799  loss_rpn_loc: 0.16  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:09:40 d2.utils.events]: \u001b[0m eta: 2:17:43  iter: 58539  total_loss: 1.078  loss_cls: 0.2479  loss_box_reg: 0.366  loss_mask: 0.2569  loss_rpn_cls: 0.06042  loss_rpn_loc: 0.1694  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:09:45 d2.utils.events]: \u001b[0m eta: 2:17:45  iter: 58559  total_loss: 1.22  loss_cls: 0.2983  loss_box_reg: 0.3653  loss_mask: 0.2542  loss_rpn_cls: 0.09045  loss_rpn_loc: 0.1901  time: 0.2238  data_time: 0.0173  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:09:49 d2.utils.events]: \u001b[0m eta: 2:17:29  iter: 58579  total_loss: 1.096  loss_cls: 0.2368  loss_box_reg: 0.3778  loss_mask: 0.242  loss_rpn_cls: 0.05776  loss_rpn_loc: 0.14  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:09:54 d2.utils.events]: \u001b[0m eta: 2:17:30  iter: 58599  total_loss: 1.166  loss_cls: 0.2933  loss_box_reg: 0.3606  loss_mask: 0.2645  loss_rpn_cls: 0.0878  loss_rpn_loc: 0.1784  time: 0.2238  data_time: 0.0194  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:09:58 d2.utils.events]: \u001b[0m eta: 2:17:45  iter: 58619  total_loss: 1.217  loss_cls: 0.2875  loss_box_reg: 0.3954  loss_mask: 0.2663  loss_rpn_cls: 0.08976  loss_rpn_loc: 0.164  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:10:03 d2.utils.events]: \u001b[0m eta: 2:17:58  iter: 58639  total_loss: 1.157  loss_cls: 0.2922  loss_box_reg: 0.3852  loss_mask: 0.2683  loss_rpn_cls: 0.08742  loss_rpn_loc: 0.1819  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:10:07 d2.utils.events]: \u001b[0m eta: 2:17:49  iter: 58659  total_loss: 1.031  loss_cls: 0.231  loss_box_reg: 0.3267  loss_mask: 0.2495  loss_rpn_cls: 0.05029  loss_rpn_loc: 0.1564  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:10:12 d2.utils.events]: \u001b[0m eta: 2:17:42  iter: 58679  total_loss: 1.315  loss_cls: 0.3038  loss_box_reg: 0.3927  loss_mask: 0.2737  loss_rpn_cls: 0.08982  loss_rpn_loc: 0.1669  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:10:16 d2.utils.events]: \u001b[0m eta: 2:17:39  iter: 58699  total_loss: 1.194  loss_cls: 0.3165  loss_box_reg: 0.3918  loss_mask: 0.2842  loss_rpn_cls: 0.08357  loss_rpn_loc: 0.1798  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:10:20 d2.utils.events]: \u001b[0m eta: 2:17:04  iter: 58719  total_loss: 1.121  loss_cls: 0.2783  loss_box_reg: 0.376  loss_mask: 0.2551  loss_rpn_cls: 0.04772  loss_rpn_loc: 0.1533  time: 0.2238  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:10:25 d2.utils.events]: \u001b[0m eta: 2:17:00  iter: 58739  total_loss: 1.117  loss_cls: 0.2349  loss_box_reg: 0.3467  loss_mask: 0.2623  loss_rpn_cls: 0.07544  loss_rpn_loc: 0.1779  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:10:29 d2.utils.events]: \u001b[0m eta: 2:16:47  iter: 58759  total_loss: 1.179  loss_cls: 0.3045  loss_box_reg: 0.4117  loss_mask: 0.2702  loss_rpn_cls: 0.05594  loss_rpn_loc: 0.151  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:10:33 d2.utils.events]: \u001b[0m eta: 2:16:58  iter: 58779  total_loss: 1.164  loss_cls: 0.2729  loss_box_reg: 0.3568  loss_mask: 0.2567  loss_rpn_cls: 0.06821  loss_rpn_loc: 0.1659  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:10:38 d2.utils.events]: \u001b[0m eta: 2:16:55  iter: 58799  total_loss: 1.116  loss_cls: 0.2801  loss_box_reg: 0.3747  loss_mask: 0.2318  loss_rpn_cls: 0.0808  loss_rpn_loc: 0.1438  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:10:42 d2.utils.events]: \u001b[0m eta: 2:16:48  iter: 58819  total_loss: 1.117  loss_cls: 0.269  loss_box_reg: 0.3841  loss_mask: 0.2667  loss_rpn_cls: 0.09495  loss_rpn_loc: 0.157  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:10:47 d2.utils.events]: \u001b[0m eta: 2:16:32  iter: 58839  total_loss: 1.131  loss_cls: 0.2833  loss_box_reg: 0.3844  loss_mask: 0.2464  loss_rpn_cls: 0.04722  loss_rpn_loc: 0.1473  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:10:51 d2.utils.events]: \u001b[0m eta: 2:16:22  iter: 58859  total_loss: 1.154  loss_cls: 0.3121  loss_box_reg: 0.3725  loss_mask: 0.2528  loss_rpn_cls: 0.07716  loss_rpn_loc: 0.1563  time: 0.2238  data_time: 0.0146  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:10:56 d2.utils.events]: \u001b[0m eta: 2:16:18  iter: 58879  total_loss: 1.219  loss_cls: 0.3093  loss_box_reg: 0.3678  loss_mask: 0.2839  loss_rpn_cls: 0.08556  loss_rpn_loc: 0.1542  time: 0.2238  data_time: 0.0107  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:11:01 d2.utils.events]: \u001b[0m eta: 2:16:16  iter: 58899  total_loss: 1.132  loss_cls: 0.2837  loss_box_reg: 0.3754  loss_mask: 0.247  loss_rpn_cls: 0.05599  loss_rpn_loc: 0.1498  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:11:05 d2.utils.events]: \u001b[0m eta: 2:16:20  iter: 58919  total_loss: 1.147  loss_cls: 0.2717  loss_box_reg: 0.3547  loss_mask: 0.2739  loss_rpn_cls: 0.06855  loss_rpn_loc: 0.1697  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:11:10 d2.utils.events]: \u001b[0m eta: 2:16:06  iter: 58939  total_loss: 1.082  loss_cls: 0.2373  loss_box_reg: 0.362  loss_mask: 0.2646  loss_rpn_cls: 0.06196  loss_rpn_loc: 0.164  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:11:14 d2.utils.events]: \u001b[0m eta: 2:16:00  iter: 58959  total_loss: 1.138  loss_cls: 0.2711  loss_box_reg: 0.3741  loss_mask: 0.2594  loss_rpn_cls: 0.0675  loss_rpn_loc: 0.1601  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:11:19 d2.utils.events]: \u001b[0m eta: 2:15:56  iter: 58979  total_loss: 1.17  loss_cls: 0.2545  loss_box_reg: 0.3827  loss_mask: 0.2597  loss_rpn_cls: 0.08101  loss_rpn_loc: 0.1691  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:11:23 d2.utils.events]: \u001b[0m eta: 2:15:44  iter: 58999  total_loss: 1.244  loss_cls: 0.3218  loss_box_reg: 0.4019  loss_mask: 0.2685  loss_rpn_cls: 0.07286  loss_rpn_loc: 0.1736  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:11:28 d2.utils.events]: \u001b[0m eta: 2:15:42  iter: 59019  total_loss: 1.163  loss_cls: 0.282  loss_box_reg: 0.3423  loss_mask: 0.2649  loss_rpn_cls: 0.1068  loss_rpn_loc: 0.1888  time: 0.2238  data_time: 0.0095  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:11:32 d2.utils.events]: \u001b[0m eta: 2:15:45  iter: 59039  total_loss: 1.244  loss_cls: 0.3292  loss_box_reg: 0.393  loss_mask: 0.2678  loss_rpn_cls: 0.06664  loss_rpn_loc: 0.1604  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:11:37 d2.utils.events]: \u001b[0m eta: 2:15:23  iter: 59059  total_loss: 1.245  loss_cls: 0.3213  loss_box_reg: 0.395  loss_mask: 0.2427  loss_rpn_cls: 0.06242  loss_rpn_loc: 0.1648  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:11:41 d2.utils.events]: \u001b[0m eta: 2:15:10  iter: 59079  total_loss: 1.204  loss_cls: 0.2869  loss_box_reg: 0.3641  loss_mask: 0.2691  loss_rpn_cls: 0.08445  loss_rpn_loc: 0.1799  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:11:46 d2.utils.events]: \u001b[0m eta: 2:15:21  iter: 59099  total_loss: 1.224  loss_cls: 0.2585  loss_box_reg: 0.3919  loss_mask: 0.2508  loss_rpn_cls: 0.09658  loss_rpn_loc: 0.1627  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:11:50 d2.utils.events]: \u001b[0m eta: 2:15:12  iter: 59119  total_loss: 1.219  loss_cls: 0.3144  loss_box_reg: 0.3658  loss_mask: 0.2615  loss_rpn_cls: 0.06264  loss_rpn_loc: 0.1598  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:11:54 d2.utils.events]: \u001b[0m eta: 2:15:02  iter: 59139  total_loss: 1.281  loss_cls: 0.3351  loss_box_reg: 0.4206  loss_mask: 0.2788  loss_rpn_cls: 0.07186  loss_rpn_loc: 0.182  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:11:59 d2.utils.events]: \u001b[0m eta: 2:15:07  iter: 59159  total_loss: 1.017  loss_cls: 0.2523  loss_box_reg: 0.31  loss_mask: 0.2284  loss_rpn_cls: 0.056  loss_rpn_loc: 0.1644  time: 0.2238  data_time: 0.0169  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:12:03 d2.utils.events]: \u001b[0m eta: 2:14:56  iter: 59179  total_loss: 1.002  loss_cls: 0.2069  loss_box_reg: 0.3256  loss_mask: 0.2326  loss_rpn_cls: 0.04952  loss_rpn_loc: 0.1413  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:12:08 d2.utils.events]: \u001b[0m eta: 2:14:55  iter: 59199  total_loss: 1.17  loss_cls: 0.3129  loss_box_reg: 0.3586  loss_mask: 0.2706  loss_rpn_cls: 0.07982  loss_rpn_loc: 0.1601  time: 0.2238  data_time: 0.0144  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:12:12 d2.utils.events]: \u001b[0m eta: 2:14:56  iter: 59219  total_loss: 1.102  loss_cls: 0.259  loss_box_reg: 0.3422  loss_mask: 0.2472  loss_rpn_cls: 0.05302  loss_rpn_loc: 0.1538  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:12:16 d2.utils.events]: \u001b[0m eta: 2:15:01  iter: 59239  total_loss: 1.337  loss_cls: 0.349  loss_box_reg: 0.3921  loss_mask: 0.2781  loss_rpn_cls: 0.1072  loss_rpn_loc: 0.1739  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:12:21 d2.utils.events]: \u001b[0m eta: 2:15:02  iter: 59259  total_loss: 1.198  loss_cls: 0.3076  loss_box_reg: 0.3685  loss_mask: 0.2421  loss_rpn_cls: 0.08305  loss_rpn_loc: 0.1528  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:12:25 d2.utils.events]: \u001b[0m eta: 2:14:47  iter: 59279  total_loss: 1.141  loss_cls: 0.2514  loss_box_reg: 0.3485  loss_mask: 0.2378  loss_rpn_cls: 0.06704  loss_rpn_loc: 0.1626  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:12:30 d2.utils.events]: \u001b[0m eta: 2:15:01  iter: 59299  total_loss: 1.169  loss_cls: 0.3182  loss_box_reg: 0.3685  loss_mask: 0.2524  loss_rpn_cls: 0.07268  loss_rpn_loc: 0.1587  time: 0.2238  data_time: 0.0093  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:12:35 d2.utils.events]: \u001b[0m eta: 2:15:00  iter: 59319  total_loss: 1.174  loss_cls: 0.2712  loss_box_reg: 0.3813  loss_mask: 0.266  loss_rpn_cls: 0.06893  loss_rpn_loc: 0.1682  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:12:39 d2.utils.events]: \u001b[0m eta: 2:14:44  iter: 59339  total_loss: 1.118  loss_cls: 0.2955  loss_box_reg: 0.3721  loss_mask: 0.254  loss_rpn_cls: 0.06031  loss_rpn_loc: 0.1609  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:12:43 d2.utils.events]: \u001b[0m eta: 2:14:35  iter: 59359  total_loss: 1.205  loss_cls: 0.2786  loss_box_reg: 0.3745  loss_mask: 0.2594  loss_rpn_cls: 0.05507  loss_rpn_loc: 0.1713  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:12:48 d2.utils.events]: \u001b[0m eta: 2:14:36  iter: 59379  total_loss: 1.139  loss_cls: 0.274  loss_box_reg: 0.3475  loss_mask: 0.2538  loss_rpn_cls: 0.09043  loss_rpn_loc: 0.1765  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:12:52 d2.utils.events]: \u001b[0m eta: 2:14:34  iter: 59399  total_loss: 1.169  loss_cls: 0.2795  loss_box_reg: 0.3259  loss_mask: 0.2656  loss_rpn_cls: 0.07464  loss_rpn_loc: 0.1546  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:12:57 d2.utils.events]: \u001b[0m eta: 2:14:16  iter: 59419  total_loss: 1.113  loss_cls: 0.2827  loss_box_reg: 0.3827  loss_mask: 0.2412  loss_rpn_cls: 0.07006  loss_rpn_loc: 0.1525  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:13:01 d2.utils.events]: \u001b[0m eta: 2:14:10  iter: 59439  total_loss: 1.161  loss_cls: 0.2753  loss_box_reg: 0.3949  loss_mask: 0.2542  loss_rpn_cls: 0.06406  loss_rpn_loc: 0.1728  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:13:06 d2.utils.events]: \u001b[0m eta: 2:14:04  iter: 59459  total_loss: 1.288  loss_cls: 0.3306  loss_box_reg: 0.4252  loss_mask: 0.2689  loss_rpn_cls: 0.08267  loss_rpn_loc: 0.1582  time: 0.2238  data_time: 0.0248  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:13:10 d2.utils.events]: \u001b[0m eta: 2:13:59  iter: 59479  total_loss: 1.29  loss_cls: 0.311  loss_box_reg: 0.4258  loss_mask: 0.2724  loss_rpn_cls: 0.0694  loss_rpn_loc: 0.18  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:13:15 d2.utils.events]: \u001b[0m eta: 2:14:06  iter: 59499  total_loss: 1.347  loss_cls: 0.3625  loss_box_reg: 0.4107  loss_mask: 0.2724  loss_rpn_cls: 0.07548  loss_rpn_loc: 0.1557  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:13:19 d2.utils.events]: \u001b[0m eta: 2:13:57  iter: 59519  total_loss: 1.133  loss_cls: 0.2633  loss_box_reg: 0.3404  loss_mask: 0.2398  loss_rpn_cls: 0.06771  loss_rpn_loc: 0.1658  time: 0.2238  data_time: 0.0186  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:13:24 d2.utils.events]: \u001b[0m eta: 2:13:52  iter: 59539  total_loss: 1.189  loss_cls: 0.2804  loss_box_reg: 0.3527  loss_mask: 0.2674  loss_rpn_cls: 0.08585  loss_rpn_loc: 0.174  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:13:28 d2.utils.events]: \u001b[0m eta: 2:13:33  iter: 59559  total_loss: 1.136  loss_cls: 0.3125  loss_box_reg: 0.3721  loss_mask: 0.2477  loss_rpn_cls: 0.05177  loss_rpn_loc: 0.1626  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:13:32 d2.utils.events]: \u001b[0m eta: 2:13:35  iter: 59579  total_loss: 1.197  loss_cls: 0.3011  loss_box_reg: 0.3518  loss_mask: 0.2458  loss_rpn_cls: 0.06146  loss_rpn_loc: 0.1599  time: 0.2238  data_time: 0.0097  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:13:37 d2.utils.events]: \u001b[0m eta: 2:13:31  iter: 59599  total_loss: 1.19  loss_cls: 0.2842  loss_box_reg: 0.3817  loss_mask: 0.2669  loss_rpn_cls: 0.07068  loss_rpn_loc: 0.1668  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:13:41 d2.utils.events]: \u001b[0m eta: 2:13:29  iter: 59619  total_loss: 1.186  loss_cls: 0.3209  loss_box_reg: 0.3675  loss_mask: 0.2695  loss_rpn_cls: 0.08059  loss_rpn_loc: 0.1725  time: 0.2238  data_time: 0.0109  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:13:46 d2.utils.events]: \u001b[0m eta: 2:13:22  iter: 59639  total_loss: 1.081  loss_cls: 0.2771  loss_box_reg: 0.3632  loss_mask: 0.2371  loss_rpn_cls: 0.05819  loss_rpn_loc: 0.1454  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:13:51 d2.utils.events]: \u001b[0m eta: 2:13:20  iter: 59659  total_loss: 1.023  loss_cls: 0.2395  loss_box_reg: 0.3364  loss_mask: 0.2414  loss_rpn_cls: 0.05878  loss_rpn_loc: 0.1628  time: 0.2238  data_time: 0.0092  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:13:55 d2.utils.events]: \u001b[0m eta: 2:13:16  iter: 59679  total_loss: 1.008  loss_cls: 0.2591  loss_box_reg: 0.3298  loss_mask: 0.2317  loss_rpn_cls: 0.0814  loss_rpn_loc: 0.1507  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:14:00 d2.utils.events]: \u001b[0m eta: 2:13:03  iter: 59699  total_loss: 1.094  loss_cls: 0.2881  loss_box_reg: 0.3701  loss_mask: 0.2473  loss_rpn_cls: 0.05834  loss_rpn_loc: 0.1523  time: 0.2238  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:14:04 d2.utils.events]: \u001b[0m eta: 2:13:07  iter: 59719  total_loss: 1.236  loss_cls: 0.3414  loss_box_reg: 0.411  loss_mask: 0.2702  loss_rpn_cls: 0.06414  loss_rpn_loc: 0.1773  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:14:09 d2.utils.events]: \u001b[0m eta: 2:13:01  iter: 59739  total_loss: 1.308  loss_cls: 0.3761  loss_box_reg: 0.4405  loss_mask: 0.2759  loss_rpn_cls: 0.07329  loss_rpn_loc: 0.1614  time: 0.2238  data_time: 0.0226  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:14:13 d2.utils.events]: \u001b[0m eta: 2:13:04  iter: 59759  total_loss: 1.014  loss_cls: 0.2392  loss_box_reg: 0.3147  loss_mask: 0.2421  loss_rpn_cls: 0.06701  loss_rpn_loc: 0.1649  time: 0.2238  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:14:18 d2.utils.events]: \u001b[0m eta: 2:13:03  iter: 59779  total_loss: 1.17  loss_cls: 0.2934  loss_box_reg: 0.3807  loss_mask: 0.2661  loss_rpn_cls: 0.06136  loss_rpn_loc: 0.1516  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:14:22 d2.utils.events]: \u001b[0m eta: 2:12:58  iter: 59799  total_loss: 1.19  loss_cls: 0.302  loss_box_reg: 0.4255  loss_mask: 0.2652  loss_rpn_cls: 0.06513  loss_rpn_loc: 0.1478  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:14:27 d2.utils.events]: \u001b[0m eta: 2:12:54  iter: 59819  total_loss: 1.136  loss_cls: 0.2903  loss_box_reg: 0.3596  loss_mask: 0.2618  loss_rpn_cls: 0.06404  loss_rpn_loc: 0.147  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:14:31 d2.utils.events]: \u001b[0m eta: 2:12:51  iter: 59839  total_loss: 1.184  loss_cls: 0.2767  loss_box_reg: 0.3383  loss_mask: 0.2723  loss_rpn_cls: 0.06567  loss_rpn_loc: 0.1464  time: 0.2238  data_time: 0.0183  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:14:36 d2.utils.events]: \u001b[0m eta: 2:12:49  iter: 59859  total_loss: 1.264  loss_cls: 0.3026  loss_box_reg: 0.4277  loss_mask: 0.2713  loss_rpn_cls: 0.07311  loss_rpn_loc: 0.1769  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:14:40 d2.utils.events]: \u001b[0m eta: 2:12:38  iter: 59879  total_loss: 1.26  loss_cls: 0.3278  loss_box_reg: 0.3722  loss_mask: 0.2827  loss_rpn_cls: 0.07829  loss_rpn_loc: 0.1736  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:14:45 d2.utils.events]: \u001b[0m eta: 2:12:25  iter: 59899  total_loss: 1.16  loss_cls: 0.2894  loss_box_reg: 0.3798  loss_mask: 0.241  loss_rpn_cls: 0.07132  loss_rpn_loc: 0.1471  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:14:49 d2.utils.events]: \u001b[0m eta: 2:12:20  iter: 59919  total_loss: 1.175  loss_cls: 0.25  loss_box_reg: 0.3842  loss_mask: 0.266  loss_rpn_cls: 0.07767  loss_rpn_loc: 0.1766  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:14:54 d2.utils.events]: \u001b[0m eta: 2:12:16  iter: 59939  total_loss: 1.194  loss_cls: 0.2776  loss_box_reg: 0.3713  loss_mask: 0.2637  loss_rpn_cls: 0.06815  loss_rpn_loc: 0.1674  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:14:58 d2.utils.events]: \u001b[0m eta: 2:12:12  iter: 59959  total_loss: 1.269  loss_cls: 0.3278  loss_box_reg: 0.4269  loss_mask: 0.2655  loss_rpn_cls: 0.05234  loss_rpn_loc: 0.1873  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:15:03 d2.utils.events]: \u001b[0m eta: 2:12:08  iter: 59979  total_loss: 1.119  loss_cls: 0.2542  loss_box_reg: 0.3546  loss_mask: 0.2567  loss_rpn_cls: 0.07484  loss_rpn_loc: 0.1679  time: 0.2238  data_time: 0.0113  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:15:07 d2.utils.events]: \u001b[0m eta: 2:12:03  iter: 59999  total_loss: 1.282  loss_cls: 0.3373  loss_box_reg: 0.3935  loss_mask: 0.2739  loss_rpn_cls: 0.06441  loss_rpn_loc: 0.1491  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:15:11 d2.utils.events]: \u001b[0m eta: 2:11:49  iter: 60019  total_loss: 1.243  loss_cls: 0.309  loss_box_reg: 0.3485  loss_mask: 0.2584  loss_rpn_cls: 0.08163  loss_rpn_loc: 0.1493  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:15:16 d2.utils.events]: \u001b[0m eta: 2:11:44  iter: 60039  total_loss: 1.071  loss_cls: 0.2611  loss_box_reg: 0.3695  loss_mask: 0.2584  loss_rpn_cls: 0.07515  loss_rpn_loc: 0.166  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:15:21 d2.utils.events]: \u001b[0m eta: 2:11:48  iter: 60059  total_loss: 1.241  loss_cls: 0.3104  loss_box_reg: 0.4098  loss_mask: 0.2701  loss_rpn_cls: 0.09209  loss_rpn_loc: 0.1771  time: 0.2238  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:15:25 d2.utils.events]: \u001b[0m eta: 2:11:39  iter: 60079  total_loss: 1.194  loss_cls: 0.3196  loss_box_reg: 0.404  loss_mask: 0.2779  loss_rpn_cls: 0.07346  loss_rpn_loc: 0.1742  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:15:30 d2.utils.events]: \u001b[0m eta: 2:11:35  iter: 60099  total_loss: 1.131  loss_cls: 0.231  loss_box_reg: 0.3134  loss_mask: 0.2464  loss_rpn_cls: 0.06322  loss_rpn_loc: 0.165  time: 0.2238  data_time: 0.0192  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:15:34 d2.utils.events]: \u001b[0m eta: 2:11:27  iter: 60119  total_loss: 1.2  loss_cls: 0.3029  loss_box_reg: 0.3987  loss_mask: 0.2586  loss_rpn_cls: 0.08886  loss_rpn_loc: 0.1659  time: 0.2238  data_time: 0.0158  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:15:39 d2.utils.events]: \u001b[0m eta: 2:11:26  iter: 60139  total_loss: 1.006  loss_cls: 0.2288  loss_box_reg: 0.3416  loss_mask: 0.2446  loss_rpn_cls: 0.04646  loss_rpn_loc: 0.1315  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:15:43 d2.utils.events]: \u001b[0m eta: 2:11:26  iter: 60159  total_loss: 1.195  loss_cls: 0.2876  loss_box_reg: 0.3716  loss_mask: 0.2545  loss_rpn_cls: 0.09888  loss_rpn_loc: 0.1634  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:15:48 d2.utils.events]: \u001b[0m eta: 2:11:31  iter: 60179  total_loss: 1.199  loss_cls: 0.2788  loss_box_reg: 0.3343  loss_mask: 0.2596  loss_rpn_cls: 0.08912  loss_rpn_loc: 0.1735  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:15:53 d2.utils.events]: \u001b[0m eta: 2:11:22  iter: 60199  total_loss: 1.07  loss_cls: 0.2621  loss_box_reg: 0.3623  loss_mask: 0.2422  loss_rpn_cls: 0.05696  loss_rpn_loc: 0.1585  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:15:57 d2.utils.events]: \u001b[0m eta: 2:11:15  iter: 60219  total_loss: 1.185  loss_cls: 0.2964  loss_box_reg: 0.4056  loss_mask: 0.2498  loss_rpn_cls: 0.05857  loss_rpn_loc: 0.1521  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:16:02 d2.utils.events]: \u001b[0m eta: 2:11:11  iter: 60239  total_loss: 1.153  loss_cls: 0.2669  loss_box_reg: 0.3333  loss_mask: 0.2652  loss_rpn_cls: 0.1239  loss_rpn_loc: 0.1739  time: 0.2238  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:16:06 d2.utils.events]: \u001b[0m eta: 2:11:07  iter: 60259  total_loss: 1.086  loss_cls: 0.2359  loss_box_reg: 0.3432  loss_mask: 0.2611  loss_rpn_cls: 0.06835  loss_rpn_loc: 0.1493  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:16:11 d2.utils.events]: \u001b[0m eta: 2:11:04  iter: 60279  total_loss: 1.219  loss_cls: 0.2994  loss_box_reg: 0.3744  loss_mask: 0.2528  loss_rpn_cls: 0.08894  loss_rpn_loc: 0.1803  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:16:15 d2.utils.events]: \u001b[0m eta: 2:10:51  iter: 60299  total_loss: 1.232  loss_cls: 0.278  loss_box_reg: 0.371  loss_mask: 0.2429  loss_rpn_cls: 0.06311  loss_rpn_loc: 0.1489  time: 0.2238  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:16:20 d2.utils.events]: \u001b[0m eta: 2:10:49  iter: 60319  total_loss: 1.366  loss_cls: 0.3443  loss_box_reg: 0.4364  loss_mask: 0.2775  loss_rpn_cls: 0.1013  loss_rpn_loc: 0.1727  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:16:24 d2.utils.events]: \u001b[0m eta: 2:10:56  iter: 60339  total_loss: 1.293  loss_cls: 0.3119  loss_box_reg: 0.3992  loss_mask: 0.2804  loss_rpn_cls: 0.08832  loss_rpn_loc: 0.1695  time: 0.2238  data_time: 0.0136  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:16:29 d2.utils.events]: \u001b[0m eta: 2:11:02  iter: 60359  total_loss: 1.237  loss_cls: 0.3058  loss_box_reg: 0.3992  loss_mask: 0.2823  loss_rpn_cls: 0.08263  loss_rpn_loc: 0.1865  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:16:33 d2.utils.events]: \u001b[0m eta: 2:10:58  iter: 60379  total_loss: 1.333  loss_cls: 0.3405  loss_box_reg: 0.4081  loss_mask: 0.2868  loss_rpn_cls: 0.09645  loss_rpn_loc: 0.1817  time: 0.2238  data_time: 0.0095  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:16:38 d2.utils.events]: \u001b[0m eta: 2:11:05  iter: 60399  total_loss: 1.292  loss_cls: 0.3411  loss_box_reg: 0.3903  loss_mask: 0.269  loss_rpn_cls: 0.07712  loss_rpn_loc: 0.1687  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:16:43 d2.utils.events]: \u001b[0m eta: 2:11:08  iter: 60419  total_loss: 1.201  loss_cls: 0.311  loss_box_reg: 0.3546  loss_mask: 0.2398  loss_rpn_cls: 0.08215  loss_rpn_loc: 0.1559  time: 0.2238  data_time: 0.0145  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:16:47 d2.utils.events]: \u001b[0m eta: 2:11:05  iter: 60439  total_loss: 1.142  loss_cls: 0.3004  loss_box_reg: 0.384  loss_mask: 0.2529  loss_rpn_cls: 0.08108  loss_rpn_loc: 0.152  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:16:51 d2.utils.events]: \u001b[0m eta: 2:10:57  iter: 60459  total_loss: 1.058  loss_cls: 0.2573  loss_box_reg: 0.3714  loss_mask: 0.2564  loss_rpn_cls: 0.04007  loss_rpn_loc: 0.1493  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:16:56 d2.utils.events]: \u001b[0m eta: 2:10:56  iter: 60479  total_loss: 1.04  loss_cls: 0.2465  loss_box_reg: 0.3068  loss_mask: 0.2473  loss_rpn_cls: 0.08511  loss_rpn_loc: 0.1469  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:17:01 d2.utils.events]: \u001b[0m eta: 2:10:53  iter: 60499  total_loss: 1.143  loss_cls: 0.2773  loss_box_reg: 0.3423  loss_mask: 0.2585  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.1753  time: 0.2238  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:17:05 d2.utils.events]: \u001b[0m eta: 2:10:49  iter: 60519  total_loss: 1.023  loss_cls: 0.2294  loss_box_reg: 0.338  loss_mask: 0.2453  loss_rpn_cls: 0.05399  loss_rpn_loc: 0.1514  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:17:10 d2.utils.events]: \u001b[0m eta: 2:10:44  iter: 60539  total_loss: 1.163  loss_cls: 0.2873  loss_box_reg: 0.3875  loss_mask: 0.2513  loss_rpn_cls: 0.06115  loss_rpn_loc: 0.1718  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:17:14 d2.utils.events]: \u001b[0m eta: 2:10:42  iter: 60559  total_loss: 1.243  loss_cls: 0.334  loss_box_reg: 0.4155  loss_mask: 0.273  loss_rpn_cls: 0.07991  loss_rpn_loc: 0.1736  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:17:19 d2.utils.events]: \u001b[0m eta: 2:10:41  iter: 60579  total_loss: 1.282  loss_cls: 0.3362  loss_box_reg: 0.3845  loss_mask: 0.2762  loss_rpn_cls: 0.08126  loss_rpn_loc: 0.1594  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:17:23 d2.utils.events]: \u001b[0m eta: 2:10:38  iter: 60599  total_loss: 1.122  loss_cls: 0.2774  loss_box_reg: 0.373  loss_mask: 0.2422  loss_rpn_cls: 0.06975  loss_rpn_loc: 0.1639  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:17:28 d2.utils.events]: \u001b[0m eta: 2:10:34  iter: 60619  total_loss: 1.158  loss_cls: 0.3003  loss_box_reg: 0.3779  loss_mask: 0.2678  loss_rpn_cls: 0.07253  loss_rpn_loc: 0.1605  time: 0.2238  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:17:32 d2.utils.events]: \u001b[0m eta: 2:10:29  iter: 60639  total_loss: 1.199  loss_cls: 0.2927  loss_box_reg: 0.3778  loss_mask: 0.2691  loss_rpn_cls: 0.08169  loss_rpn_loc: 0.1558  time: 0.2238  data_time: 0.0171  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:17:37 d2.utils.events]: \u001b[0m eta: 2:10:24  iter: 60659  total_loss: 1.097  loss_cls: 0.2866  loss_box_reg: 0.326  loss_mask: 0.2468  loss_rpn_cls: 0.05466  loss_rpn_loc: 0.1577  time: 0.2238  data_time: 0.0157  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:17:41 d2.utils.events]: \u001b[0m eta: 2:10:18  iter: 60679  total_loss: 1.064  loss_cls: 0.2469  loss_box_reg: 0.3578  loss_mask: 0.2426  loss_rpn_cls: 0.03075  loss_rpn_loc: 0.1338  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:17:46 d2.utils.events]: \u001b[0m eta: 2:10:15  iter: 60699  total_loss: 1.109  loss_cls: 0.2536  loss_box_reg: 0.3324  loss_mask: 0.2528  loss_rpn_cls: 0.05701  loss_rpn_loc: 0.147  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:17:50 d2.utils.events]: \u001b[0m eta: 2:10:11  iter: 60719  total_loss: 1.253  loss_cls: 0.3113  loss_box_reg: 0.401  loss_mask: 0.2784  loss_rpn_cls: 0.07163  loss_rpn_loc: 0.176  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:17:55 d2.utils.events]: \u001b[0m eta: 2:10:08  iter: 60739  total_loss: 1.146  loss_cls: 0.2778  loss_box_reg: 0.3807  loss_mask: 0.2649  loss_rpn_cls: 0.05669  loss_rpn_loc: 0.1782  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:17:59 d2.utils.events]: \u001b[0m eta: 2:10:00  iter: 60759  total_loss: 1.073  loss_cls: 0.2525  loss_box_reg: 0.3596  loss_mask: 0.2449  loss_rpn_cls: 0.05847  loss_rpn_loc: 0.1695  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:18:04 d2.utils.events]: \u001b[0m eta: 2:09:56  iter: 60779  total_loss: 1.23  loss_cls: 0.3152  loss_box_reg: 0.3798  loss_mask: 0.2721  loss_rpn_cls: 0.06445  loss_rpn_loc: 0.163  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:18:08 d2.utils.events]: \u001b[0m eta: 2:09:52  iter: 60799  total_loss: 1.181  loss_cls: 0.2645  loss_box_reg: 0.3838  loss_mask: 0.2542  loss_rpn_cls: 0.09536  loss_rpn_loc: 0.1576  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:18:13 d2.utils.events]: \u001b[0m eta: 2:09:47  iter: 60819  total_loss: 1.163  loss_cls: 0.2767  loss_box_reg: 0.3586  loss_mask: 0.2556  loss_rpn_cls: 0.05834  loss_rpn_loc: 0.162  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:18:17 d2.utils.events]: \u001b[0m eta: 2:09:40  iter: 60839  total_loss: 1.287  loss_cls: 0.3143  loss_box_reg: 0.4271  loss_mask: 0.2665  loss_rpn_cls: 0.08177  loss_rpn_loc: 0.1679  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:18:22 d2.utils.events]: \u001b[0m eta: 2:09:36  iter: 60859  total_loss: 1.231  loss_cls: 0.2984  loss_box_reg: 0.3966  loss_mask: 0.2729  loss_rpn_cls: 0.08123  loss_rpn_loc: 0.1591  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:18:26 d2.utils.events]: \u001b[0m eta: 2:09:29  iter: 60879  total_loss: 1.143  loss_cls: 0.2798  loss_box_reg: 0.3803  loss_mask: 0.2563  loss_rpn_cls: 0.06128  loss_rpn_loc: 0.1564  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:18:31 d2.utils.events]: \u001b[0m eta: 2:09:31  iter: 60899  total_loss: 1.168  loss_cls: 0.2796  loss_box_reg: 0.3941  loss_mask: 0.2612  loss_rpn_cls: 0.07164  loss_rpn_loc: 0.1599  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:18:35 d2.utils.events]: \u001b[0m eta: 2:09:23  iter: 60919  total_loss: 1.263  loss_cls: 0.3039  loss_box_reg: 0.3891  loss_mask: 0.2579  loss_rpn_cls: 0.08658  loss_rpn_loc: 0.1908  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:18:40 d2.utils.events]: \u001b[0m eta: 2:09:19  iter: 60939  total_loss: 1.178  loss_cls: 0.3184  loss_box_reg: 0.3701  loss_mask: 0.2823  loss_rpn_cls: 0.1135  loss_rpn_loc: 0.1646  time: 0.2238  data_time: 0.0146  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:18:44 d2.utils.events]: \u001b[0m eta: 2:09:17  iter: 60959  total_loss: 1.026  loss_cls: 0.2361  loss_box_reg: 0.3075  loss_mask: 0.2298  loss_rpn_cls: 0.05773  loss_rpn_loc: 0.1593  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:18:49 d2.utils.events]: \u001b[0m eta: 2:09:12  iter: 60979  total_loss: 1.119  loss_cls: 0.2633  loss_box_reg: 0.3173  loss_mask: 0.2494  loss_rpn_cls: 0.06449  loss_rpn_loc: 0.1622  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:18:53 d2.utils.events]: \u001b[0m eta: 2:09:16  iter: 60999  total_loss: 1.169  loss_cls: 0.2612  loss_box_reg: 0.3691  loss_mask: 0.2671  loss_rpn_cls: 0.0703  loss_rpn_loc: 0.1603  time: 0.2238  data_time: 0.0145  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:18:58 d2.utils.events]: \u001b[0m eta: 2:09:08  iter: 61019  total_loss: 1.165  loss_cls: 0.2544  loss_box_reg: 0.3602  loss_mask: 0.2485  loss_rpn_cls: 0.0585  loss_rpn_loc: 0.1699  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:19:02 d2.utils.events]: \u001b[0m eta: 2:09:02  iter: 61039  total_loss: 1.014  loss_cls: 0.2246  loss_box_reg: 0.3513  loss_mask: 0.2378  loss_rpn_cls: 0.07152  loss_rpn_loc: 0.1566  time: 0.2238  data_time: 0.0093  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:19:07 d2.utils.events]: \u001b[0m eta: 2:08:56  iter: 61059  total_loss: 1.167  loss_cls: 0.2748  loss_box_reg: 0.3595  loss_mask: 0.279  loss_rpn_cls: 0.07859  loss_rpn_loc: 0.1801  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:19:11 d2.utils.events]: \u001b[0m eta: 2:09:02  iter: 61079  total_loss: 1.072  loss_cls: 0.257  loss_box_reg: 0.3849  loss_mask: 0.2535  loss_rpn_cls: 0.05999  loss_rpn_loc: 0.1664  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:19:16 d2.utils.events]: \u001b[0m eta: 2:08:54  iter: 61099  total_loss: 1.079  loss_cls: 0.2451  loss_box_reg: 0.343  loss_mask: 0.2478  loss_rpn_cls: 0.0725  loss_rpn_loc: 0.175  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:19:20 d2.utils.events]: \u001b[0m eta: 2:09:04  iter: 61119  total_loss: 1.17  loss_cls: 0.2719  loss_box_reg: 0.344  loss_mask: 0.261  loss_rpn_cls: 0.08196  loss_rpn_loc: 0.1721  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:19:25 d2.utils.events]: \u001b[0m eta: 2:08:53  iter: 61139  total_loss: 1.236  loss_cls: 0.2617  loss_box_reg: 0.3567  loss_mask: 0.2719  loss_rpn_cls: 0.06926  loss_rpn_loc: 0.1543  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:19:29 d2.utils.events]: \u001b[0m eta: 2:08:45  iter: 61159  total_loss: 1.183  loss_cls: 0.284  loss_box_reg: 0.3301  loss_mask: 0.2697  loss_rpn_cls: 0.08935  loss_rpn_loc: 0.1677  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:19:34 d2.utils.events]: \u001b[0m eta: 2:08:30  iter: 61179  total_loss: 1.099  loss_cls: 0.2736  loss_box_reg: 0.3477  loss_mask: 0.2583  loss_rpn_cls: 0.07503  loss_rpn_loc: 0.169  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:19:38 d2.utils.events]: \u001b[0m eta: 2:08:38  iter: 61199  total_loss: 1.203  loss_cls: 0.2899  loss_box_reg: 0.3867  loss_mask: 0.2624  loss_rpn_cls: 0.08113  loss_rpn_loc: 0.1614  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:19:43 d2.utils.events]: \u001b[0m eta: 2:08:46  iter: 61219  total_loss: 1.085  loss_cls: 0.2696  loss_box_reg: 0.3613  loss_mask: 0.2434  loss_rpn_cls: 0.06482  loss_rpn_loc: 0.1596  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:19:48 d2.utils.events]: \u001b[0m eta: 2:08:31  iter: 61239  total_loss: 1.183  loss_cls: 0.2767  loss_box_reg: 0.3724  loss_mask: 0.2689  loss_rpn_cls: 0.08152  loss_rpn_loc: 0.1681  time: 0.2238  data_time: 0.0183  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:19:52 d2.utils.events]: \u001b[0m eta: 2:08:29  iter: 61259  total_loss: 1.036  loss_cls: 0.2531  loss_box_reg: 0.3311  loss_mask: 0.2337  loss_rpn_cls: 0.06522  loss_rpn_loc: 0.149  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:19:57 d2.utils.events]: \u001b[0m eta: 2:08:25  iter: 61279  total_loss: 1.098  loss_cls: 0.2441  loss_box_reg: 0.3601  loss_mask: 0.2534  loss_rpn_cls: 0.05132  loss_rpn_loc: 0.1441  time: 0.2238  data_time: 0.0139  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:20:01 d2.utils.events]: \u001b[0m eta: 2:08:31  iter: 61299  total_loss: 1.279  loss_cls: 0.3112  loss_box_reg: 0.4126  loss_mask: 0.2614  loss_rpn_cls: 0.05339  loss_rpn_loc: 0.1666  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:20:05 d2.utils.events]: \u001b[0m eta: 2:08:20  iter: 61319  total_loss: 1.134  loss_cls: 0.3009  loss_box_reg: 0.3406  loss_mask: 0.2614  loss_rpn_cls: 0.06872  loss_rpn_loc: 0.1642  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:20:10 d2.utils.events]: \u001b[0m eta: 2:08:05  iter: 61339  total_loss: 1.071  loss_cls: 0.2756  loss_box_reg: 0.3539  loss_mask: 0.2572  loss_rpn_cls: 0.06171  loss_rpn_loc: 0.1498  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:20:14 d2.utils.events]: \u001b[0m eta: 2:07:58  iter: 61359  total_loss: 1.246  loss_cls: 0.3114  loss_box_reg: 0.3944  loss_mask: 0.2797  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.1803  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:20:19 d2.utils.events]: \u001b[0m eta: 2:07:56  iter: 61379  total_loss: 1.176  loss_cls: 0.3022  loss_box_reg: 0.3769  loss_mask: 0.2621  loss_rpn_cls: 0.07387  loss_rpn_loc: 0.1648  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:20:23 d2.utils.events]: \u001b[0m eta: 2:07:52  iter: 61399  total_loss: 1.06  loss_cls: 0.2444  loss_box_reg: 0.3647  loss_mask: 0.2566  loss_rpn_cls: 0.08012  loss_rpn_loc: 0.1573  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:20:28 d2.utils.events]: \u001b[0m eta: 2:07:45  iter: 61419  total_loss: 1.291  loss_cls: 0.3008  loss_box_reg: 0.4235  loss_mask: 0.2786  loss_rpn_cls: 0.08971  loss_rpn_loc: 0.1691  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:20:32 d2.utils.events]: \u001b[0m eta: 2:07:38  iter: 61439  total_loss: 1.133  loss_cls: 0.2813  loss_box_reg: 0.3802  loss_mask: 0.2473  loss_rpn_cls: 0.05278  loss_rpn_loc: 0.1381  time: 0.2238  data_time: 0.0058  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:20:36 d2.utils.events]: \u001b[0m eta: 2:07:41  iter: 61459  total_loss: 1.17  loss_cls: 0.2702  loss_box_reg: 0.3732  loss_mask: 0.2566  loss_rpn_cls: 0.08087  loss_rpn_loc: 0.1788  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:20:40 d2.utils.events]: \u001b[0m eta: 2:07:21  iter: 61479  total_loss: 1.212  loss_cls: 0.2763  loss_box_reg: 0.4001  loss_mask: 0.2562  loss_rpn_cls: 0.07142  loss_rpn_loc: 0.1687  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:20:45 d2.utils.events]: \u001b[0m eta: 2:07:13  iter: 61499  total_loss: 1.299  loss_cls: 0.3159  loss_box_reg: 0.3811  loss_mask: 0.2799  loss_rpn_cls: 0.09357  loss_rpn_loc: 0.1693  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:20:49 d2.utils.events]: \u001b[0m eta: 2:07:02  iter: 61519  total_loss: 1.128  loss_cls: 0.2756  loss_box_reg: 0.3773  loss_mask: 0.255  loss_rpn_cls: 0.06952  loss_rpn_loc: 0.1907  time: 0.2238  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:20:54 d2.utils.events]: \u001b[0m eta: 2:06:56  iter: 61539  total_loss: 1.198  loss_cls: 0.2919  loss_box_reg: 0.3687  loss_mask: 0.2581  loss_rpn_cls: 0.06207  loss_rpn_loc: 0.1504  time: 0.2238  data_time: 0.0163  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:20:58 d2.utils.events]: \u001b[0m eta: 2:06:52  iter: 61559  total_loss: 1.221  loss_cls: 0.3031  loss_box_reg: 0.3875  loss_mask: 0.2581  loss_rpn_cls: 0.07365  loss_rpn_loc: 0.1542  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:21:03 d2.utils.events]: \u001b[0m eta: 2:06:52  iter: 61579  total_loss: 1.123  loss_cls: 0.2549  loss_box_reg: 0.3525  loss_mask: 0.2483  loss_rpn_cls: 0.06234  loss_rpn_loc: 0.1612  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:21:07 d2.utils.events]: \u001b[0m eta: 2:06:46  iter: 61599  total_loss: 1.209  loss_cls: 0.3316  loss_box_reg: 0.3905  loss_mask: 0.2764  loss_rpn_cls: 0.09465  loss_rpn_loc: 0.1562  time: 0.2238  data_time: 0.0148  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:21:12 d2.utils.events]: \u001b[0m eta: 2:06:36  iter: 61619  total_loss: 1.19  loss_cls: 0.2733  loss_box_reg: 0.3611  loss_mask: 0.2558  loss_rpn_cls: 0.08739  loss_rpn_loc: 0.1737  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:21:16 d2.utils.events]: \u001b[0m eta: 2:06:35  iter: 61639  total_loss: 1.095  loss_cls: 0.2667  loss_box_reg: 0.3549  loss_mask: 0.2476  loss_rpn_cls: 0.06149  loss_rpn_loc: 0.1443  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:21:21 d2.utils.events]: \u001b[0m eta: 2:06:18  iter: 61659  total_loss: 1.093  loss_cls: 0.2521  loss_box_reg: 0.3565  loss_mask: 0.2448  loss_rpn_cls: 0.06401  loss_rpn_loc: 0.1633  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:21:25 d2.utils.events]: \u001b[0m eta: 2:06:26  iter: 61679  total_loss: 1.287  loss_cls: 0.3172  loss_box_reg: 0.3796  loss_mask: 0.2816  loss_rpn_cls: 0.07982  loss_rpn_loc: 0.17  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:21:30 d2.utils.events]: \u001b[0m eta: 2:06:26  iter: 61699  total_loss: 1.104  loss_cls: 0.2857  loss_box_reg: 0.3391  loss_mask: 0.2356  loss_rpn_cls: 0.08283  loss_rpn_loc: 0.1746  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:21:34 d2.utils.events]: \u001b[0m eta: 2:06:24  iter: 61719  total_loss: 1.238  loss_cls: 0.3033  loss_box_reg: 0.3939  loss_mask: 0.2789  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.1808  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:21:39 d2.utils.events]: \u001b[0m eta: 2:06:17  iter: 61739  total_loss: 1.227  loss_cls: 0.3031  loss_box_reg: 0.4034  loss_mask: 0.2771  loss_rpn_cls: 0.06659  loss_rpn_loc: 0.1805  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:21:43 d2.utils.events]: \u001b[0m eta: 2:06:16  iter: 61759  total_loss: 1.231  loss_cls: 0.3038  loss_box_reg: 0.3754  loss_mask: 0.2741  loss_rpn_cls: 0.06957  loss_rpn_loc: 0.1724  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:21:48 d2.utils.events]: \u001b[0m eta: 2:06:11  iter: 61779  total_loss: 1.079  loss_cls: 0.2596  loss_box_reg: 0.3511  loss_mask: 0.2419  loss_rpn_cls: 0.07032  loss_rpn_loc: 0.1601  time: 0.2238  data_time: 0.0297  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:21:53 d2.utils.events]: \u001b[0m eta: 2:06:07  iter: 61799  total_loss: 1.153  loss_cls: 0.2839  loss_box_reg: 0.3548  loss_mask: 0.2692  loss_rpn_cls: 0.07586  loss_rpn_loc: 0.1586  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:21:57 d2.utils.events]: \u001b[0m eta: 2:06:02  iter: 61819  total_loss: 1.227  loss_cls: 0.2925  loss_box_reg: 0.3925  loss_mask: 0.2744  loss_rpn_cls: 0.08039  loss_rpn_loc: 0.1619  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:22:02 d2.utils.events]: \u001b[0m eta: 2:05:59  iter: 61839  total_loss: 1.274  loss_cls: 0.323  loss_box_reg: 0.4027  loss_mask: 0.2791  loss_rpn_cls: 0.08573  loss_rpn_loc: 0.1652  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:22:06 d2.utils.events]: \u001b[0m eta: 2:06:01  iter: 61859  total_loss: 1.206  loss_cls: 0.3011  loss_box_reg: 0.3562  loss_mask: 0.2531  loss_rpn_cls: 0.09026  loss_rpn_loc: 0.1591  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:22:11 d2.utils.events]: \u001b[0m eta: 2:06:01  iter: 61879  total_loss: 1.091  loss_cls: 0.2406  loss_box_reg: 0.3686  loss_mask: 0.2415  loss_rpn_cls: 0.07408  loss_rpn_loc: 0.1535  time: 0.2238  data_time: 0.0237  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:22:15 d2.utils.events]: \u001b[0m eta: 2:05:50  iter: 61899  total_loss: 1.274  loss_cls: 0.3152  loss_box_reg: 0.3944  loss_mask: 0.2919  loss_rpn_cls: 0.0939  loss_rpn_loc: 0.1701  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:22:19 d2.utils.events]: \u001b[0m eta: 2:05:49  iter: 61919  total_loss: 1.158  loss_cls: 0.2914  loss_box_reg: 0.3511  loss_mask: 0.2609  loss_rpn_cls: 0.07237  loss_rpn_loc: 0.1534  time: 0.2238  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:22:24 d2.utils.events]: \u001b[0m eta: 2:05:37  iter: 61939  total_loss: 1.17  loss_cls: 0.2578  loss_box_reg: 0.3731  loss_mask: 0.2544  loss_rpn_cls: 0.07489  loss_rpn_loc: 0.1634  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:22:28 d2.utils.events]: \u001b[0m eta: 2:05:32  iter: 61959  total_loss: 1.271  loss_cls: 0.3116  loss_box_reg: 0.4252  loss_mask: 0.2668  loss_rpn_cls: 0.06979  loss_rpn_loc: 0.1704  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:22:33 d2.utils.events]: \u001b[0m eta: 2:05:25  iter: 61979  total_loss: 1.154  loss_cls: 0.2858  loss_box_reg: 0.3947  loss_mask: 0.2438  loss_rpn_cls: 0.05658  loss_rpn_loc: 0.1505  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:22:37 d2.utils.events]: \u001b[0m eta: 2:05:03  iter: 61999  total_loss: 1.028  loss_cls: 0.2132  loss_box_reg: 0.3323  loss_mask: 0.2461  loss_rpn_cls: 0.04483  loss_rpn_loc: 0.1431  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:22:41 d2.utils.events]: \u001b[0m eta: 2:05:12  iter: 62019  total_loss: 1.17  loss_cls: 0.2607  loss_box_reg: 0.371  loss_mask: 0.2381  loss_rpn_cls: 0.07514  loss_rpn_loc: 0.1798  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:22:45 d2.utils.events]: \u001b[0m eta: 2:05:07  iter: 62039  total_loss: 1.193  loss_cls: 0.2849  loss_box_reg: 0.4181  loss_mask: 0.2634  loss_rpn_cls: 0.06305  loss_rpn_loc: 0.1451  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:22:50 d2.utils.events]: \u001b[0m eta: 2:05:04  iter: 62059  total_loss: 1.194  loss_cls: 0.3038  loss_box_reg: 0.3675  loss_mask: 0.2643  loss_rpn_cls: 0.07405  loss_rpn_loc: 0.1789  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:22:54 d2.utils.events]: \u001b[0m eta: 2:05:06  iter: 62079  total_loss: 1.094  loss_cls: 0.2458  loss_box_reg: 0.3681  loss_mask: 0.2552  loss_rpn_cls: 0.07871  loss_rpn_loc: 0.1723  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:22:59 d2.utils.events]: \u001b[0m eta: 2:05:01  iter: 62099  total_loss: 1.149  loss_cls: 0.2748  loss_box_reg: 0.3801  loss_mask: 0.2687  loss_rpn_cls: 0.09057  loss_rpn_loc: 0.1761  time: 0.2238  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:23:03 d2.utils.events]: \u001b[0m eta: 2:04:47  iter: 62119  total_loss: 1.093  loss_cls: 0.2582  loss_box_reg: 0.3764  loss_mask: 0.2526  loss_rpn_cls: 0.05672  loss_rpn_loc: 0.1516  time: 0.2238  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:23:08 d2.utils.events]: \u001b[0m eta: 2:04:42  iter: 62139  total_loss: 1.196  loss_cls: 0.3073  loss_box_reg: 0.3919  loss_mask: 0.2668  loss_rpn_cls: 0.07028  loss_rpn_loc: 0.1729  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:23:12 d2.utils.events]: \u001b[0m eta: 2:04:42  iter: 62159  total_loss: 1.127  loss_cls: 0.2849  loss_box_reg: 0.3634  loss_mask: 0.2563  loss_rpn_cls: 0.07525  loss_rpn_loc: 0.1491  time: 0.2238  data_time: 0.0177  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:23:17 d2.utils.events]: \u001b[0m eta: 2:04:36  iter: 62179  total_loss: 1.116  loss_cls: 0.2843  loss_box_reg: 0.3633  loss_mask: 0.2482  loss_rpn_cls: 0.04312  loss_rpn_loc: 0.1426  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:23:22 d2.utils.events]: \u001b[0m eta: 2:04:30  iter: 62199  total_loss: 1.205  loss_cls: 0.281  loss_box_reg: 0.3495  loss_mask: 0.2654  loss_rpn_cls: 0.08382  loss_rpn_loc: 0.188  time: 0.2238  data_time: 0.0171  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:23:26 d2.utils.events]: \u001b[0m eta: 2:04:06  iter: 62219  total_loss: 1.349  loss_cls: 0.3724  loss_box_reg: 0.4223  loss_mask: 0.2627  loss_rpn_cls: 0.07487  loss_rpn_loc: 0.1705  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:23:30 d2.utils.events]: \u001b[0m eta: 2:04:00  iter: 62239  total_loss: 1.074  loss_cls: 0.2936  loss_box_reg: 0.3602  loss_mask: 0.2434  loss_rpn_cls: 0.06058  loss_rpn_loc: 0.1516  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:23:35 d2.utils.events]: \u001b[0m eta: 2:03:56  iter: 62259  total_loss: 1.43  loss_cls: 0.4079  loss_box_reg: 0.4074  loss_mask: 0.2933  loss_rpn_cls: 0.1176  loss_rpn_loc: 0.1902  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:23:39 d2.utils.events]: \u001b[0m eta: 2:03:44  iter: 62279  total_loss: 1.246  loss_cls: 0.3191  loss_box_reg: 0.4041  loss_mask: 0.2782  loss_rpn_cls: 0.087  loss_rpn_loc: 0.1582  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:23:44 d2.utils.events]: \u001b[0m eta: 2:03:41  iter: 62299  total_loss: 1.156  loss_cls: 0.3245  loss_box_reg: 0.3805  loss_mask: 0.2597  loss_rpn_cls: 0.08201  loss_rpn_loc: 0.1615  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:23:49 d2.utils.events]: \u001b[0m eta: 2:03:43  iter: 62319  total_loss: 1.174  loss_cls: 0.2547  loss_box_reg: 0.3394  loss_mask: 0.2553  loss_rpn_cls: 0.08343  loss_rpn_loc: 0.1791  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:23:53 d2.utils.events]: \u001b[0m eta: 2:03:33  iter: 62339  total_loss: 1.141  loss_cls: 0.2944  loss_box_reg: 0.3703  loss_mask: 0.2437  loss_rpn_cls: 0.06337  loss_rpn_loc: 0.1489  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:23:57 d2.utils.events]: \u001b[0m eta: 2:03:31  iter: 62359  total_loss: 1.24  loss_cls: 0.3185  loss_box_reg: 0.4062  loss_mask: 0.2742  loss_rpn_cls: 0.085  loss_rpn_loc: 0.1733  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:24:02 d2.utils.events]: \u001b[0m eta: 2:03:22  iter: 62379  total_loss: 1.063  loss_cls: 0.2418  loss_box_reg: 0.3331  loss_mask: 0.2397  loss_rpn_cls: 0.05477  loss_rpn_loc: 0.1497  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:24:06 d2.utils.events]: \u001b[0m eta: 2:03:13  iter: 62399  total_loss: 1.185  loss_cls: 0.2959  loss_box_reg: 0.3809  loss_mask: 0.2563  loss_rpn_cls: 0.07012  loss_rpn_loc: 0.154  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:24:11 d2.utils.events]: \u001b[0m eta: 2:03:12  iter: 62419  total_loss: 1.168  loss_cls: 0.2818  loss_box_reg: 0.3597  loss_mask: 0.2608  loss_rpn_cls: 0.06199  loss_rpn_loc: 0.176  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:24:15 d2.utils.events]: \u001b[0m eta: 2:03:08  iter: 62439  total_loss: 1.162  loss_cls: 0.2875  loss_box_reg: 0.3531  loss_mask: 0.2516  loss_rpn_cls: 0.06201  loss_rpn_loc: 0.164  time: 0.2238  data_time: 0.0156  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:24:20 d2.utils.events]: \u001b[0m eta: 2:03:04  iter: 62459  total_loss: 1.144  loss_cls: 0.2266  loss_box_reg: 0.3974  loss_mask: 0.2688  loss_rpn_cls: 0.05392  loss_rpn_loc: 0.1562  time: 0.2238  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:24:24 d2.utils.events]: \u001b[0m eta: 2:03:08  iter: 62479  total_loss: 1.12  loss_cls: 0.2646  loss_box_reg: 0.3697  loss_mask: 0.2645  loss_rpn_cls: 0.07029  loss_rpn_loc: 0.1448  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:24:28 d2.utils.events]: \u001b[0m eta: 2:02:58  iter: 62499  total_loss: 1.191  loss_cls: 0.2819  loss_box_reg: 0.3521  loss_mask: 0.2558  loss_rpn_cls: 0.06246  loss_rpn_loc: 0.1471  time: 0.2238  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:24:33 d2.utils.events]: \u001b[0m eta: 2:03:00  iter: 62519  total_loss: 1.28  loss_cls: 0.3098  loss_box_reg: 0.3874  loss_mask: 0.2646  loss_rpn_cls: 0.08755  loss_rpn_loc: 0.1814  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:24:37 d2.utils.events]: \u001b[0m eta: 2:03:02  iter: 62539  total_loss: 1.091  loss_cls: 0.2647  loss_box_reg: 0.3423  loss_mask: 0.2392  loss_rpn_cls: 0.05178  loss_rpn_loc: 0.1518  time: 0.2238  data_time: 0.0142  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:24:42 d2.utils.events]: \u001b[0m eta: 2:02:52  iter: 62559  total_loss: 1.147  loss_cls: 0.2927  loss_box_reg: 0.3877  loss_mask: 0.2433  loss_rpn_cls: 0.06677  loss_rpn_loc: 0.1565  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:24:46 d2.utils.events]: \u001b[0m eta: 2:02:48  iter: 62579  total_loss: 1.194  loss_cls: 0.2963  loss_box_reg: 0.383  loss_mask: 0.276  loss_rpn_cls: 0.07296  loss_rpn_loc: 0.1602  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:24:50 d2.utils.events]: \u001b[0m eta: 2:02:37  iter: 62599  total_loss: 1.192  loss_cls: 0.2925  loss_box_reg: 0.411  loss_mask: 0.2595  loss_rpn_cls: 0.08036  loss_rpn_loc: 0.1651  time: 0.2238  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:24:55 d2.utils.events]: \u001b[0m eta: 2:02:35  iter: 62619  total_loss: 1.005  loss_cls: 0.2415  loss_box_reg: 0.3253  loss_mask: 0.2454  loss_rpn_cls: 0.0682  loss_rpn_loc: 0.16  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:24:58 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.46 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 01:24:58 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 01:24:58 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 01:24:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 01:24:59 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 01:24:59 d2.data.common]: \u001b[0mSerialized dataset takes 84.20 MiB\n",
      "\u001b[32m[12/30 01:25:02 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.52 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 01:25:02 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 01:25:02 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 01:25:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/30 01:25:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0007 s/iter. Inference: 0.0622 s/iter. Eval: 0.1413 s/iter. Total: 0.2041 s/iter. ETA=0:01:54\n",
      "\u001b[32m[12/30 01:25:11 d2.evaluation.evaluator]: \u001b[0mInference done 39/570. Dataloading: 0.0008 s/iter. Inference: 0.0587 s/iter. Eval: 0.1244 s/iter. Total: 0.1840 s/iter. ETA=0:01:37\n",
      "\u001b[32m[12/30 01:25:16 d2.evaluation.evaluator]: \u001b[0mInference done 66/570. Dataloading: 0.0008 s/iter. Inference: 0.0580 s/iter. Eval: 0.1257 s/iter. Total: 0.1847 s/iter. ETA=0:01:33\n",
      "\u001b[32m[12/30 01:25:21 d2.evaluation.evaluator]: \u001b[0mInference done 91/570. Dataloading: 0.0008 s/iter. Inference: 0.0583 s/iter. Eval: 0.1307 s/iter. Total: 0.1899 s/iter. ETA=0:01:30\n",
      "\u001b[32m[12/30 01:25:26 d2.evaluation.evaluator]: \u001b[0mInference done 117/570. Dataloading: 0.0008 s/iter. Inference: 0.0578 s/iter. Eval: 0.1320 s/iter. Total: 0.1907 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/30 01:25:31 d2.evaluation.evaluator]: \u001b[0mInference done 142/570. Dataloading: 0.0009 s/iter. Inference: 0.0570 s/iter. Eval: 0.1356 s/iter. Total: 0.1935 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 01:25:36 d2.evaluation.evaluator]: \u001b[0mInference done 162/570. Dataloading: 0.0009 s/iter. Inference: 0.0567 s/iter. Eval: 0.1448 s/iter. Total: 0.2024 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 01:25:41 d2.evaluation.evaluator]: \u001b[0mInference done 175/570. Dataloading: 0.0009 s/iter. Inference: 0.0570 s/iter. Eval: 0.1600 s/iter. Total: 0.2179 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/30 01:25:47 d2.evaluation.evaluator]: \u001b[0mInference done 193/570. Dataloading: 0.0009 s/iter. Inference: 0.0573 s/iter. Eval: 0.1660 s/iter. Total: 0.2242 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/30 01:25:52 d2.evaluation.evaluator]: \u001b[0mInference done 209/570. Dataloading: 0.0009 s/iter. Inference: 0.0571 s/iter. Eval: 0.1734 s/iter. Total: 0.2315 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 01:25:57 d2.evaluation.evaluator]: \u001b[0mInference done 226/570. Dataloading: 0.0009 s/iter. Inference: 0.0575 s/iter. Eval: 0.1805 s/iter. Total: 0.2390 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 01:26:02 d2.evaluation.evaluator]: \u001b[0mInference done 237/570. Dataloading: 0.0009 s/iter. Inference: 0.0576 s/iter. Eval: 0.1915 s/iter. Total: 0.2500 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 01:26:08 d2.evaluation.evaluator]: \u001b[0mInference done 250/570. Dataloading: 0.0009 s/iter. Inference: 0.0575 s/iter. Eval: 0.2001 s/iter. Total: 0.2586 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 01:26:13 d2.evaluation.evaluator]: \u001b[0mInference done 266/570. Dataloading: 0.0009 s/iter. Inference: 0.0576 s/iter. Eval: 0.2047 s/iter. Total: 0.2633 s/iter. ETA=0:01:20\n",
      "\u001b[32m[12/30 01:26:18 d2.evaluation.evaluator]: \u001b[0mInference done 285/570. Dataloading: 0.0009 s/iter. Inference: 0.0578 s/iter. Eval: 0.2050 s/iter. Total: 0.2638 s/iter. ETA=0:01:15\n",
      "\u001b[32m[12/30 01:26:23 d2.evaluation.evaluator]: \u001b[0mInference done 298/570. Dataloading: 0.0009 s/iter. Inference: 0.0579 s/iter. Eval: 0.2105 s/iter. Total: 0.2694 s/iter. ETA=0:01:13\n",
      "\u001b[32m[12/30 01:26:28 d2.evaluation.evaluator]: \u001b[0mInference done 344/570. Dataloading: 0.0009 s/iter. Inference: 0.0566 s/iter. Eval: 0.1902 s/iter. Total: 0.2477 s/iter. ETA=0:00:55\n",
      "\u001b[32m[12/30 01:26:34 d2.evaluation.evaluator]: \u001b[0mInference done 376/570. Dataloading: 0.0009 s/iter. Inference: 0.0560 s/iter. Eval: 0.1837 s/iter. Total: 0.2406 s/iter. ETA=0:00:46\n",
      "\u001b[32m[12/30 01:26:39 d2.evaluation.evaluator]: \u001b[0mInference done 398/570. Dataloading: 0.0009 s/iter. Inference: 0.0563 s/iter. Eval: 0.1831 s/iter. Total: 0.2403 s/iter. ETA=0:00:41\n",
      "\u001b[32m[12/30 01:26:44 d2.evaluation.evaluator]: \u001b[0mInference done 416/570. Dataloading: 0.0009 s/iter. Inference: 0.0564 s/iter. Eval: 0.1849 s/iter. Total: 0.2422 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/30 01:26:49 d2.evaluation.evaluator]: \u001b[0mInference done 436/570. Dataloading: 0.0009 s/iter. Inference: 0.0565 s/iter. Eval: 0.1856 s/iter. Total: 0.2430 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/30 01:26:54 d2.evaluation.evaluator]: \u001b[0mInference done 466/570. Dataloading: 0.0009 s/iter. Inference: 0.0563 s/iter. Eval: 0.1810 s/iter. Total: 0.2382 s/iter. ETA=0:00:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:27:00 d2.evaluation.evaluator]: \u001b[0mInference done 496/570. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.1776 s/iter. Total: 0.2344 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/30 01:27:05 d2.evaluation.evaluator]: \u001b[0mInference done 516/570. Dataloading: 0.0009 s/iter. Inference: 0.0558 s/iter. Eval: 0.1784 s/iter. Total: 0.2351 s/iter. ETA=0:00:12\n",
      "\u001b[32m[12/30 01:27:10 d2.evaluation.evaluator]: \u001b[0mInference done 540/570. Dataloading: 0.0009 s/iter. Inference: 0.0556 s/iter. Eval: 0.1779 s/iter. Total: 0.2345 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/30 01:27:15 d2.evaluation.evaluator]: \u001b[0mInference done 559/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1796 s/iter. Total: 0.2363 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/30 01:27:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:13.859159 (0.236919 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 01:27:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.055779 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 01:27:18 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/30 01:27:18 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.28159033195089866\n",
      "\u001b[32m[12/30 01:27:23 d2.utils.events]: \u001b[0m eta: 2:02:26  iter: 62639  total_loss: 1.122  loss_cls: 0.2622  loss_box_reg: 0.3986  loss_mask: 0.2614  loss_rpn_cls: 0.06143  loss_rpn_loc: 0.1437  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:27:27 d2.utils.events]: \u001b[0m eta: 2:02:28  iter: 62659  total_loss: 1.221  loss_cls: 0.299  loss_box_reg: 0.3886  loss_mask: 0.2737  loss_rpn_cls: 0.06915  loss_rpn_loc: 0.1561  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:27:32 d2.utils.events]: \u001b[0m eta: 2:02:29  iter: 62679  total_loss: 1.251  loss_cls: 0.2851  loss_box_reg: 0.398  loss_mask: 0.2643  loss_rpn_cls: 0.09361  loss_rpn_loc: 0.1878  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:27:36 d2.utils.events]: \u001b[0m eta: 2:02:27  iter: 62699  total_loss: 1.175  loss_cls: 0.291  loss_box_reg: 0.3831  loss_mask: 0.2604  loss_rpn_cls: 0.08656  loss_rpn_loc: 0.1635  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:27:41 d2.utils.events]: \u001b[0m eta: 2:02:13  iter: 62719  total_loss: 1.18  loss_cls: 0.276  loss_box_reg: 0.3553  loss_mask: 0.2632  loss_rpn_cls: 0.07473  loss_rpn_loc: 0.1579  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:27:45 d2.utils.events]: \u001b[0m eta: 2:02:18  iter: 62739  total_loss: 1.248  loss_cls: 0.2891  loss_box_reg: 0.349  loss_mask: 0.2752  loss_rpn_cls: 0.0804  loss_rpn_loc: 0.1712  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:27:50 d2.utils.events]: \u001b[0m eta: 2:02:08  iter: 62759  total_loss: 1.06  loss_cls: 0.2471  loss_box_reg: 0.3342  loss_mask: 0.246  loss_rpn_cls: 0.08633  loss_rpn_loc: 0.1631  time: 0.2238  data_time: 0.0130  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:27:55 d2.utils.events]: \u001b[0m eta: 2:02:10  iter: 62779  total_loss: 1.134  loss_cls: 0.2824  loss_box_reg: 0.3672  loss_mask: 0.2581  loss_rpn_cls: 0.05381  loss_rpn_loc: 0.1568  time: 0.2238  data_time: 0.0091  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:27:59 d2.utils.events]: \u001b[0m eta: 2:02:02  iter: 62799  total_loss: 1.119  loss_cls: 0.2776  loss_box_reg: 0.3625  loss_mask: 0.2586  loss_rpn_cls: 0.06488  loss_rpn_loc: 0.1698  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:28:04 d2.utils.events]: \u001b[0m eta: 2:01:58  iter: 62819  total_loss: 1.213  loss_cls: 0.2992  loss_box_reg: 0.3553  loss_mask: 0.2461  loss_rpn_cls: 0.08737  loss_rpn_loc: 0.1829  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:28:08 d2.utils.events]: \u001b[0m eta: 2:01:49  iter: 62839  total_loss: 1.031  loss_cls: 0.2318  loss_box_reg: 0.3156  loss_mask: 0.2428  loss_rpn_cls: 0.05237  loss_rpn_loc: 0.1472  time: 0.2238  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:28:13 d2.utils.events]: \u001b[0m eta: 2:01:42  iter: 62859  total_loss: 1.221  loss_cls: 0.3106  loss_box_reg: 0.3915  loss_mask: 0.2697  loss_rpn_cls: 0.0738  loss_rpn_loc: 0.177  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:28:17 d2.utils.events]: \u001b[0m eta: 2:01:32  iter: 62879  total_loss: 1.054  loss_cls: 0.2756  loss_box_reg: 0.3576  loss_mask: 0.252  loss_rpn_cls: 0.0482  loss_rpn_loc: 0.1501  time: 0.2238  data_time: 0.0142  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:28:22 d2.utils.events]: \u001b[0m eta: 2:01:32  iter: 62899  total_loss: 1.114  loss_cls: 0.297  loss_box_reg: 0.3527  loss_mask: 0.2533  loss_rpn_cls: 0.08424  loss_rpn_loc: 0.1667  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:28:26 d2.utils.events]: \u001b[0m eta: 2:01:22  iter: 62919  total_loss: 1.19  loss_cls: 0.2812  loss_box_reg: 0.3875  loss_mask: 0.2803  loss_rpn_cls: 0.09454  loss_rpn_loc: 0.169  time: 0.2238  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:28:31 d2.utils.events]: \u001b[0m eta: 2:01:36  iter: 62939  total_loss: 1.066  loss_cls: 0.2245  loss_box_reg: 0.3365  loss_mask: 0.2567  loss_rpn_cls: 0.08368  loss_rpn_loc: 0.178  time: 0.2238  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:28:36 d2.utils.events]: \u001b[0m eta: 2:01:37  iter: 62959  total_loss: 1.163  loss_cls: 0.2968  loss_box_reg: 0.3297  loss_mask: 0.2546  loss_rpn_cls: 0.09076  loss_rpn_loc: 0.1741  time: 0.2238  data_time: 0.0091  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:28:40 d2.utils.events]: \u001b[0m eta: 2:01:42  iter: 62979  total_loss: 1.134  loss_cls: 0.2969  loss_box_reg: 0.3717  loss_mask: 0.2703  loss_rpn_cls: 0.07936  loss_rpn_loc: 0.1648  time: 0.2238  data_time: 0.0161  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:28:45 d2.utils.events]: \u001b[0m eta: 2:01:51  iter: 62999  total_loss: 1.087  loss_cls: 0.2624  loss_box_reg: 0.3142  loss_mask: 0.2644  loss_rpn_cls: 0.06401  loss_rpn_loc: 0.1591  time: 0.2238  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:28:49 d2.utils.events]: \u001b[0m eta: 2:01:46  iter: 63019  total_loss: 1.075  loss_cls: 0.2562  loss_box_reg: 0.3706  loss_mask: 0.2495  loss_rpn_cls: 0.0553  loss_rpn_loc: 0.1545  time: 0.2238  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:28:54 d2.utils.events]: \u001b[0m eta: 2:01:50  iter: 63039  total_loss: 1.183  loss_cls: 0.2912  loss_box_reg: 0.3776  loss_mask: 0.2657  loss_rpn_cls: 0.05683  loss_rpn_loc: 0.1549  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:28:58 d2.utils.events]: \u001b[0m eta: 2:01:45  iter: 63059  total_loss: 1.199  loss_cls: 0.2757  loss_box_reg: 0.4125  loss_mask: 0.2609  loss_rpn_cls: 0.07119  loss_rpn_loc: 0.1896  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:29:03 d2.utils.events]: \u001b[0m eta: 2:01:40  iter: 63079  total_loss: 1.158  loss_cls: 0.2563  loss_box_reg: 0.3847  loss_mask: 0.266  loss_rpn_cls: 0.0768  loss_rpn_loc: 0.1866  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:29:07 d2.utils.events]: \u001b[0m eta: 2:01:35  iter: 63099  total_loss: 1.189  loss_cls: 0.2745  loss_box_reg: 0.367  loss_mask: 0.2527  loss_rpn_cls: 0.07261  loss_rpn_loc: 0.1677  time: 0.2238  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:29:12 d2.utils.events]: \u001b[0m eta: 2:01:50  iter: 63119  total_loss: 1.191  loss_cls: 0.2588  loss_box_reg: 0.3979  loss_mask: 0.2713  loss_rpn_cls: 0.09491  loss_rpn_loc: 0.1794  time: 0.2238  data_time: 0.0227  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:29:17 d2.utils.events]: \u001b[0m eta: 2:01:45  iter: 63139  total_loss: 1.169  loss_cls: 0.26  loss_box_reg: 0.3437  loss_mask: 0.2516  loss_rpn_cls: 0.05936  loss_rpn_loc: 0.1458  time: 0.2238  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:29:21 d2.utils.events]: \u001b[0m eta: 2:01:33  iter: 63159  total_loss: 1.176  loss_cls: 0.2982  loss_box_reg: 0.3916  loss_mask: 0.2701  loss_rpn_cls: 0.06069  loss_rpn_loc: 0.1564  time: 0.2238  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:29:25 d2.utils.events]: \u001b[0m eta: 2:01:33  iter: 63179  total_loss: 1.178  loss_cls: 0.2896  loss_box_reg: 0.36  loss_mask: 0.2678  loss_rpn_cls: 0.08258  loss_rpn_loc: 0.1547  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:29:30 d2.utils.events]: \u001b[0m eta: 2:01:24  iter: 63199  total_loss: 1.187  loss_cls: 0.2958  loss_box_reg: 0.337  loss_mask: 0.2772  loss_rpn_cls: 0.07125  loss_rpn_loc: 0.1763  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:29:34 d2.utils.events]: \u001b[0m eta: 2:01:28  iter: 63219  total_loss: 1.264  loss_cls: 0.3244  loss_box_reg: 0.3826  loss_mask: 0.2648  loss_rpn_cls: 0.08497  loss_rpn_loc: 0.1685  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:29:39 d2.utils.events]: \u001b[0m eta: 2:01:30  iter: 63239  total_loss: 1.203  loss_cls: 0.3067  loss_box_reg: 0.317  loss_mask: 0.2695  loss_rpn_cls: 0.09006  loss_rpn_loc: 0.1806  time: 0.2238  data_time: 0.0179  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:29:44 d2.utils.events]: \u001b[0m eta: 2:01:25  iter: 63259  total_loss: 1.185  loss_cls: 0.3147  loss_box_reg: 0.3872  loss_mask: 0.2671  loss_rpn_cls: 0.06692  loss_rpn_loc: 0.1721  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:29:48 d2.utils.events]: \u001b[0m eta: 2:01:18  iter: 63279  total_loss: 1.3  loss_cls: 0.3466  loss_box_reg: 0.4065  loss_mask: 0.2845  loss_rpn_cls: 0.08766  loss_rpn_loc: 0.1869  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:29:53 d2.utils.events]: \u001b[0m eta: 2:01:07  iter: 63299  total_loss: 1.175  loss_cls: 0.2865  loss_box_reg: 0.3974  loss_mask: 0.2448  loss_rpn_cls: 0.06322  loss_rpn_loc: 0.1585  time: 0.2238  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:29:57 d2.utils.events]: \u001b[0m eta: 2:00:51  iter: 63319  total_loss: 1.125  loss_cls: 0.2999  loss_box_reg: 0.3428  loss_mask: 0.2517  loss_rpn_cls: 0.0801  loss_rpn_loc: 0.151  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:30:01 d2.utils.events]: \u001b[0m eta: 2:00:50  iter: 63339  total_loss: 1.245  loss_cls: 0.3381  loss_box_reg: 0.3925  loss_mask: 0.2726  loss_rpn_cls: 0.06175  loss_rpn_loc: 0.1662  time: 0.2238  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:30:06 d2.utils.events]: \u001b[0m eta: 2:00:48  iter: 63359  total_loss: 1.198  loss_cls: 0.2717  loss_box_reg: 0.4029  loss_mask: 0.2636  loss_rpn_cls: 0.05758  loss_rpn_loc: 0.1715  time: 0.2238  data_time: 0.0135  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:30:10 d2.utils.events]: \u001b[0m eta: 2:00:49  iter: 63379  total_loss: 1.15  loss_cls: 0.2817  loss_box_reg: 0.3689  loss_mask: 0.2626  loss_rpn_cls: 0.07436  loss_rpn_loc: 0.1582  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:30:15 d2.utils.events]: \u001b[0m eta: 2:00:53  iter: 63399  total_loss: 1.213  loss_cls: 0.3077  loss_box_reg: 0.4021  loss_mask: 0.2426  loss_rpn_cls: 0.06428  loss_rpn_loc: 0.1664  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:30:19 d2.utils.events]: \u001b[0m eta: 2:00:37  iter: 63419  total_loss: 1.172  loss_cls: 0.2886  loss_box_reg: 0.356  loss_mask: 0.2627  loss_rpn_cls: 0.079  loss_rpn_loc: 0.1559  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:30:24 d2.utils.events]: \u001b[0m eta: 2:00:30  iter: 63439  total_loss: 1.197  loss_cls: 0.289  loss_box_reg: 0.3992  loss_mask: 0.2682  loss_rpn_cls: 0.08045  loss_rpn_loc: 0.1676  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:30:28 d2.utils.events]: \u001b[0m eta: 2:00:21  iter: 63459  total_loss: 1.105  loss_cls: 0.2759  loss_box_reg: 0.3582  loss_mask: 0.244  loss_rpn_cls: 0.07299  loss_rpn_loc: 0.16  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:30:32 d2.utils.events]: \u001b[0m eta: 2:00:12  iter: 63479  total_loss: 1.133  loss_cls: 0.2689  loss_box_reg: 0.3831  loss_mask: 0.2554  loss_rpn_cls: 0.05521  loss_rpn_loc: 0.1575  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:30:37 d2.utils.events]: \u001b[0m eta: 2:00:09  iter: 63499  total_loss: 1.31  loss_cls: 0.3064  loss_box_reg: 0.3876  loss_mask: 0.2835  loss_rpn_cls: 0.06948  loss_rpn_loc: 0.1754  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:30:41 d2.utils.events]: \u001b[0m eta: 2:00:03  iter: 63519  total_loss: 1.062  loss_cls: 0.232  loss_box_reg: 0.3035  loss_mask: 0.2552  loss_rpn_cls: 0.05906  loss_rpn_loc: 0.1586  time: 0.2238  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:30:45 d2.utils.events]: \u001b[0m eta: 1:59:56  iter: 63539  total_loss: 1.253  loss_cls: 0.2838  loss_box_reg: 0.3913  loss_mask: 0.2699  loss_rpn_cls: 0.06386  loss_rpn_loc: 0.1688  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:30:50 d2.utils.events]: \u001b[0m eta: 1:59:51  iter: 63559  total_loss: 1.159  loss_cls: 0.2991  loss_box_reg: 0.3774  loss_mask: 0.2645  loss_rpn_cls: 0.07483  loss_rpn_loc: 0.1749  time: 0.2238  data_time: 0.0125  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:30:55 d2.utils.events]: \u001b[0m eta: 1:59:43  iter: 63579  total_loss: 1  loss_cls: 0.2581  loss_box_reg: 0.3657  loss_mask: 0.2352  loss_rpn_cls: 0.05246  loss_rpn_loc: 0.145  time: 0.2238  data_time: 0.0146  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:30:59 d2.utils.events]: \u001b[0m eta: 1:59:43  iter: 63599  total_loss: 1.076  loss_cls: 0.2543  loss_box_reg: 0.3648  loss_mask: 0.2443  loss_rpn_cls: 0.05707  loss_rpn_loc: 0.1572  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:31:04 d2.utils.events]: \u001b[0m eta: 1:59:38  iter: 63619  total_loss: 1.213  loss_cls: 0.2978  loss_box_reg: 0.3339  loss_mask: 0.2639  loss_rpn_cls: 0.09984  loss_rpn_loc: 0.1767  time: 0.2238  data_time: 0.0097  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:31:08 d2.utils.events]: \u001b[0m eta: 1:59:36  iter: 63639  total_loss: 1.186  loss_cls: 0.285  loss_box_reg: 0.3925  loss_mask: 0.2497  loss_rpn_cls: 0.0938  loss_rpn_loc: 0.1629  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:31:13 d2.utils.events]: \u001b[0m eta: 1:59:30  iter: 63659  total_loss: 1.177  loss_cls: 0.2557  loss_box_reg: 0.3888  loss_mask: 0.2685  loss_rpn_cls: 0.08193  loss_rpn_loc: 0.1554  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:31:17 d2.utils.events]: \u001b[0m eta: 1:59:12  iter: 63679  total_loss: 1.285  loss_cls: 0.3186  loss_box_reg: 0.3599  loss_mask: 0.2785  loss_rpn_cls: 0.08799  loss_rpn_loc: 0.1838  time: 0.2238  data_time: 0.0159  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:31:22 d2.utils.events]: \u001b[0m eta: 1:59:05  iter: 63699  total_loss: 1.168  loss_cls: 0.2816  loss_box_reg: 0.3589  loss_mask: 0.2607  loss_rpn_cls: 0.07962  loss_rpn_loc: 0.1604  time: 0.2238  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:31:26 d2.utils.events]: \u001b[0m eta: 1:58:55  iter: 63719  total_loss: 1.222  loss_cls: 0.3069  loss_box_reg: 0.3778  loss_mask: 0.2542  loss_rpn_cls: 0.09434  loss_rpn_loc: 0.1663  time: 0.2238  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:31:31 d2.utils.events]: \u001b[0m eta: 1:58:38  iter: 63739  total_loss: 1.224  loss_cls: 0.2888  loss_box_reg: 0.3942  loss_mask: 0.2635  loss_rpn_cls: 0.0799  loss_rpn_loc: 0.162  time: 0.2238  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:31:35 d2.utils.events]: \u001b[0m eta: 1:58:30  iter: 63759  total_loss: 1.111  loss_cls: 0.258  loss_box_reg: 0.3517  loss_mask: 0.2511  loss_rpn_cls: 0.06952  loss_rpn_loc: 0.1689  time: 0.2238  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:31:39 d2.utils.events]: \u001b[0m eta: 1:58:23  iter: 63779  total_loss: 1.187  loss_cls: 0.2656  loss_box_reg: 0.4006  loss_mask: 0.2617  loss_rpn_cls: 0.06187  loss_rpn_loc: 0.1732  time: 0.2238  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:31:44 d2.utils.events]: \u001b[0m eta: 1:58:17  iter: 63799  total_loss: 1.203  loss_cls: 0.2677  loss_box_reg: 0.3718  loss_mask: 0.2752  loss_rpn_cls: 0.06704  loss_rpn_loc: 0.1771  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:31:48 d2.utils.events]: \u001b[0m eta: 1:58:14  iter: 63819  total_loss: 1.172  loss_cls: 0.2738  loss_box_reg: 0.3679  loss_mask: 0.2739  loss_rpn_cls: 0.07359  loss_rpn_loc: 0.1642  time: 0.2238  data_time: 0.0143  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:31:52 d2.utils.events]: \u001b[0m eta: 1:58:08  iter: 63839  total_loss: 1.258  loss_cls: 0.3  loss_box_reg: 0.4125  loss_mask: 0.2629  loss_rpn_cls: 0.0643  loss_rpn_loc: 0.1557  time: 0.2238  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:31:57 d2.utils.events]: \u001b[0m eta: 1:58:00  iter: 63859  total_loss: 1.126  loss_cls: 0.2607  loss_box_reg: 0.3628  loss_mask: 0.2556  loss_rpn_cls: 0.0627  loss_rpn_loc: 0.1595  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:32:01 d2.utils.events]: \u001b[0m eta: 1:57:59  iter: 63879  total_loss: 1.158  loss_cls: 0.2773  loss_box_reg: 0.3674  loss_mask: 0.2562  loss_rpn_cls: 0.0998  loss_rpn_loc: 0.1571  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:32:05 d2.utils.events]: \u001b[0m eta: 1:57:53  iter: 63899  total_loss: 1.053  loss_cls: 0.2361  loss_box_reg: 0.371  loss_mask: 0.2602  loss_rpn_cls: 0.04939  loss_rpn_loc: 0.1529  time: 0.2238  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:32:10 d2.utils.events]: \u001b[0m eta: 1:57:51  iter: 63919  total_loss: 1.128  loss_cls: 0.268  loss_box_reg: 0.372  loss_mask: 0.2667  loss_rpn_cls: 0.05427  loss_rpn_loc: 0.1745  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:32:14 d2.utils.events]: \u001b[0m eta: 1:57:42  iter: 63939  total_loss: 1.227  loss_cls: 0.3064  loss_box_reg: 0.3986  loss_mask: 0.2655  loss_rpn_cls: 0.07008  loss_rpn_loc: 0.1558  time: 0.2238  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:32:19 d2.utils.events]: \u001b[0m eta: 1:57:18  iter: 63959  total_loss: 1.011  loss_cls: 0.2555  loss_box_reg: 0.3399  loss_mask: 0.2378  loss_rpn_cls: 0.05533  loss_rpn_loc: 0.1639  time: 0.2238  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:32:23 d2.utils.events]: \u001b[0m eta: 1:57:16  iter: 63979  total_loss: 1.103  loss_cls: 0.2559  loss_box_reg: 0.3545  loss_mask: 0.2254  loss_rpn_cls: 0.06309  loss_rpn_loc: 0.1527  time: 0.2238  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:32:27 d2.utils.events]: \u001b[0m eta: 1:57:12  iter: 63999  total_loss: 1.104  loss_cls: 0.2565  loss_box_reg: 0.3726  loss_mask: 0.2523  loss_rpn_cls: 0.07374  loss_rpn_loc: 0.1595  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:32:32 d2.utils.events]: \u001b[0m eta: 1:57:21  iter: 64019  total_loss: 0.974  loss_cls: 0.1997  loss_box_reg: 0.3514  loss_mask: 0.2311  loss_rpn_cls: 0.06974  loss_rpn_loc: 0.1463  time: 0.2238  data_time: 0.0095  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:32:37 d2.utils.events]: \u001b[0m eta: 1:57:19  iter: 64039  total_loss: 1.193  loss_cls: 0.2776  loss_box_reg: 0.358  loss_mask: 0.2688  loss_rpn_cls: 0.08332  loss_rpn_loc: 0.1685  time: 0.2238  data_time: 0.0112  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:32:41 d2.utils.events]: \u001b[0m eta: 1:57:04  iter: 64059  total_loss: 1.275  loss_cls: 0.305  loss_box_reg: 0.3957  loss_mask: 0.2781  loss_rpn_cls: 0.09296  loss_rpn_loc: 0.1819  time: 0.2238  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:32:46 d2.utils.events]: \u001b[0m eta: 1:56:52  iter: 64079  total_loss: 1.114  loss_cls: 0.2276  loss_box_reg: 0.3556  loss_mask: 0.2577  loss_rpn_cls: 0.0749  loss_rpn_loc: 0.1659  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:32:50 d2.utils.events]: \u001b[0m eta: 1:56:50  iter: 64099  total_loss: 1.125  loss_cls: 0.2876  loss_box_reg: 0.3745  loss_mask: 0.258  loss_rpn_cls: 0.0789  loss_rpn_loc: 0.1724  time: 0.2238  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:32:54 d2.utils.events]: \u001b[0m eta: 1:56:30  iter: 64119  total_loss: 1.111  loss_cls: 0.2879  loss_box_reg: 0.3779  loss_mask: 0.2444  loss_rpn_cls: 0.06832  loss_rpn_loc: 0.1602  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:32:59 d2.utils.events]: \u001b[0m eta: 1:56:31  iter: 64139  total_loss: 1.125  loss_cls: 0.2558  loss_box_reg: 0.3797  loss_mask: 0.2542  loss_rpn_cls: 0.06732  loss_rpn_loc: 0.1724  time: 0.2238  data_time: 0.0096  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:33:03 d2.utils.events]: \u001b[0m eta: 1:56:13  iter: 64159  total_loss: 1.177  loss_cls: 0.3099  loss_box_reg: 0.3823  loss_mask: 0.2602  loss_rpn_cls: 0.05384  loss_rpn_loc: 0.1647  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:33:07 d2.utils.events]: \u001b[0m eta: 1:56:08  iter: 64179  total_loss: 1.021  loss_cls: 0.2408  loss_box_reg: 0.3433  loss_mask: 0.2403  loss_rpn_cls: 0.05136  loss_rpn_loc: 0.1434  time: 0.2237  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:33:12 d2.utils.events]: \u001b[0m eta: 1:56:01  iter: 64199  total_loss: 1.144  loss_cls: 0.2914  loss_box_reg: 0.3761  loss_mask: 0.2514  loss_rpn_cls: 0.09229  loss_rpn_loc: 0.1719  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:33:16 d2.utils.events]: \u001b[0m eta: 1:56:02  iter: 64219  total_loss: 1.238  loss_cls: 0.3164  loss_box_reg: 0.3836  loss_mask: 0.2724  loss_rpn_cls: 0.07944  loss_rpn_loc: 0.1637  time: 0.2237  data_time: 0.0152  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:33:21 d2.utils.events]: \u001b[0m eta: 1:55:48  iter: 64239  total_loss: 1.184  loss_cls: 0.2773  loss_box_reg: 0.3932  loss_mask: 0.262  loss_rpn_cls: 0.06263  loss_rpn_loc: 0.1506  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:33:25 d2.utils.events]: \u001b[0m eta: 1:55:39  iter: 64259  total_loss: 1.172  loss_cls: 0.281  loss_box_reg: 0.3932  loss_mask: 0.261  loss_rpn_cls: 0.07241  loss_rpn_loc: 0.1723  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:33:30 d2.utils.events]: \u001b[0m eta: 1:55:43  iter: 64279  total_loss: 1.152  loss_cls: 0.3026  loss_box_reg: 0.3806  loss_mask: 0.2475  loss_rpn_cls: 0.06493  loss_rpn_loc: 0.1442  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:33:34 d2.utils.events]: \u001b[0m eta: 1:55:44  iter: 64299  total_loss: 1.221  loss_cls: 0.2903  loss_box_reg: 0.4126  loss_mask: 0.2596  loss_rpn_cls: 0.06979  loss_rpn_loc: 0.1645  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:33:39 d2.utils.events]: \u001b[0m eta: 1:55:36  iter: 64319  total_loss: 1.002  loss_cls: 0.2462  loss_box_reg: 0.3323  loss_mask: 0.2307  loss_rpn_cls: 0.05732  loss_rpn_loc: 0.1381  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:33:43 d2.utils.events]: \u001b[0m eta: 1:55:35  iter: 64339  total_loss: 1.205  loss_cls: 0.2738  loss_box_reg: 0.3767  loss_mask: 0.2615  loss_rpn_cls: 0.07867  loss_rpn_loc: 0.1607  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:33:48 d2.utils.events]: \u001b[0m eta: 1:55:27  iter: 64359  total_loss: 1.118  loss_cls: 0.2865  loss_box_reg: 0.3255  loss_mask: 0.2399  loss_rpn_cls: 0.05263  loss_rpn_loc: 0.1514  time: 0.2237  data_time: 0.0231  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:33:52 d2.utils.events]: \u001b[0m eta: 1:55:23  iter: 64379  total_loss: 1.201  loss_cls: 0.3015  loss_box_reg: 0.3413  loss_mask: 0.2579  loss_rpn_cls: 0.07212  loss_rpn_loc: 0.1579  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:33:56 d2.utils.events]: \u001b[0m eta: 1:55:08  iter: 64399  total_loss: 1.32  loss_cls: 0.3066  loss_box_reg: 0.3749  loss_mask: 0.2804  loss_rpn_cls: 0.0665  loss_rpn_loc: 0.1575  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:34:01 d2.utils.events]: \u001b[0m eta: 1:55:07  iter: 64419  total_loss: 1.161  loss_cls: 0.2974  loss_box_reg: 0.4092  loss_mask: 0.265  loss_rpn_cls: 0.0793  loss_rpn_loc: 0.163  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:34:05 d2.utils.events]: \u001b[0m eta: 1:55:03  iter: 64439  total_loss: 1.253  loss_cls: 0.2921  loss_box_reg: 0.3855  loss_mask: 0.2656  loss_rpn_cls: 0.07902  loss_rpn_loc: 0.1716  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:34:10 d2.utils.events]: \u001b[0m eta: 1:55:03  iter: 64459  total_loss: 1.059  loss_cls: 0.2531  loss_box_reg: 0.378  loss_mask: 0.2525  loss_rpn_cls: 0.06493  loss_rpn_loc: 0.1467  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:34:14 d2.utils.events]: \u001b[0m eta: 1:54:59  iter: 64479  total_loss: 1.174  loss_cls: 0.2995  loss_box_reg: 0.3738  loss_mask: 0.2599  loss_rpn_cls: 0.07096  loss_rpn_loc: 0.1557  time: 0.2237  data_time: 0.0119  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:34:19 d2.utils.events]: \u001b[0m eta: 1:54:55  iter: 64499  total_loss: 1.185  loss_cls: 0.3206  loss_box_reg: 0.3677  loss_mask: 0.2557  loss_rpn_cls: 0.08538  loss_rpn_loc: 0.1546  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:34:23 d2.utils.events]: \u001b[0m eta: 1:54:56  iter: 64519  total_loss: 1.184  loss_cls: 0.3061  loss_box_reg: 0.3878  loss_mask: 0.2593  loss_rpn_cls: 0.06085  loss_rpn_loc: 0.1505  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:34:28 d2.utils.events]: \u001b[0m eta: 1:55:01  iter: 64539  total_loss: 1.218  loss_cls: 0.3024  loss_box_reg: 0.3711  loss_mask: 0.2665  loss_rpn_cls: 0.08047  loss_rpn_loc: 0.1686  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:34:32 d2.utils.events]: \u001b[0m eta: 1:54:46  iter: 64559  total_loss: 1.115  loss_cls: 0.2576  loss_box_reg: 0.3739  loss_mask: 0.2486  loss_rpn_cls: 0.04988  loss_rpn_loc: 0.1661  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:34:36 d2.utils.events]: \u001b[0m eta: 1:54:42  iter: 64579  total_loss: 1.318  loss_cls: 0.3345  loss_box_reg: 0.4051  loss_mask: 0.2661  loss_rpn_cls: 0.08467  loss_rpn_loc: 0.1661  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:34:40 d2.utils.events]: \u001b[0m eta: 1:54:33  iter: 64599  total_loss: 1.26  loss_cls: 0.3212  loss_box_reg: 0.4271  loss_mask: 0.2684  loss_rpn_cls: 0.06848  loss_rpn_loc: 0.1593  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:34:45 d2.utils.events]: \u001b[0m eta: 1:54:29  iter: 64619  total_loss: 1.395  loss_cls: 0.3376  loss_box_reg: 0.4119  loss_mask: 0.2729  loss_rpn_cls: 0.1142  loss_rpn_loc: 0.1923  time: 0.2237  data_time: 0.0152  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:34:49 d2.utils.events]: \u001b[0m eta: 1:53:53  iter: 64639  total_loss: 1.163  loss_cls: 0.3208  loss_box_reg: 0.3857  loss_mask: 0.2588  loss_rpn_cls: 0.06754  loss_rpn_loc: 0.1624  time: 0.2237  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:34:54 d2.utils.events]: \u001b[0m eta: 1:53:49  iter: 64659  total_loss: 1.084  loss_cls: 0.257  loss_box_reg: 0.4102  loss_mask: 0.2718  loss_rpn_cls: 0.0554  loss_rpn_loc: 0.1627  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:34:59 d2.utils.events]: \u001b[0m eta: 1:53:55  iter: 64679  total_loss: 1.162  loss_cls: 0.2758  loss_box_reg: 0.3645  loss_mask: 0.2626  loss_rpn_cls: 0.0838  loss_rpn_loc: 0.1698  time: 0.2237  data_time: 0.0211  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:35:03 d2.utils.events]: \u001b[0m eta: 1:53:44  iter: 64699  total_loss: 1.193  loss_cls: 0.2795  loss_box_reg: 0.3622  loss_mask: 0.2708  loss_rpn_cls: 0.07324  loss_rpn_loc: 0.1699  time: 0.2237  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:35:07 d2.utils.events]: \u001b[0m eta: 1:53:47  iter: 64719  total_loss: 1.123  loss_cls: 0.2585  loss_box_reg: 0.3807  loss_mask: 0.2652  loss_rpn_cls: 0.0724  loss_rpn_loc: 0.1625  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:35:12 d2.utils.events]: \u001b[0m eta: 1:53:55  iter: 64739  total_loss: 1.088  loss_cls: 0.2614  loss_box_reg: 0.3849  loss_mask: 0.2554  loss_rpn_cls: 0.08936  loss_rpn_loc: 0.1591  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:35:16 d2.utils.events]: \u001b[0m eta: 1:53:52  iter: 64759  total_loss: 1.099  loss_cls: 0.2568  loss_box_reg: 0.33  loss_mask: 0.2523  loss_rpn_cls: 0.07584  loss_rpn_loc: 0.1717  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:35:21 d2.utils.events]: \u001b[0m eta: 1:53:46  iter: 64779  total_loss: 1.296  loss_cls: 0.333  loss_box_reg: 0.4203  loss_mask: 0.2738  loss_rpn_cls: 0.08454  loss_rpn_loc: 0.1699  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:35:25 d2.utils.events]: \u001b[0m eta: 1:53:32  iter: 64799  total_loss: 1.19  loss_cls: 0.2872  loss_box_reg: 0.3681  loss_mask: 0.2618  loss_rpn_cls: 0.05753  loss_rpn_loc: 0.1552  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:35:30 d2.utils.events]: \u001b[0m eta: 1:53:21  iter: 64819  total_loss: 1.118  loss_cls: 0.2693  loss_box_reg: 0.3728  loss_mask: 0.2594  loss_rpn_cls: 0.104  loss_rpn_loc: 0.1537  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:35:34 d2.utils.events]: \u001b[0m eta: 1:53:33  iter: 64839  total_loss: 1.167  loss_cls: 0.268  loss_box_reg: 0.392  loss_mask: 0.2581  loss_rpn_cls: 0.05838  loss_rpn_loc: 0.1739  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:35:38 d2.utils.events]: \u001b[0m eta: 1:53:19  iter: 64859  total_loss: 1.293  loss_cls: 0.3141  loss_box_reg: 0.4428  loss_mask: 0.2967  loss_rpn_cls: 0.06804  loss_rpn_loc: 0.1554  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:35:43 d2.utils.events]: \u001b[0m eta: 1:53:24  iter: 64879  total_loss: 1.122  loss_cls: 0.2797  loss_box_reg: 0.3655  loss_mask: 0.2411  loss_rpn_cls: 0.07538  loss_rpn_loc: 0.1791  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:35:47 d2.utils.events]: \u001b[0m eta: 1:53:18  iter: 64899  total_loss: 1.125  loss_cls: 0.2627  loss_box_reg: 0.3713  loss_mask: 0.2496  loss_rpn_cls: 0.04688  loss_rpn_loc: 0.1541  time: 0.2237  data_time: 0.0201  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:35:52 d2.utils.events]: \u001b[0m eta: 1:53:20  iter: 64919  total_loss: 1.207  loss_cls: 0.2633  loss_box_reg: 0.3671  loss_mask: 0.2862  loss_rpn_cls: 0.09771  loss_rpn_loc: 0.1768  time: 0.2237  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:35:56 d2.utils.events]: \u001b[0m eta: 1:53:26  iter: 64939  total_loss: 1.197  loss_cls: 0.3171  loss_box_reg: 0.3842  loss_mask: 0.2663  loss_rpn_cls: 0.07538  loss_rpn_loc: 0.1578  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:36:01 d2.utils.events]: \u001b[0m eta: 1:53:26  iter: 64959  total_loss: 1.12  loss_cls: 0.2886  loss_box_reg: 0.3558  loss_mask: 0.2682  loss_rpn_cls: 0.08698  loss_rpn_loc: 0.1515  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:36:05 d2.utils.events]: \u001b[0m eta: 1:53:14  iter: 64979  total_loss: 1.159  loss_cls: 0.2659  loss_box_reg: 0.3685  loss_mask: 0.2558  loss_rpn_cls: 0.06573  loss_rpn_loc: 0.1597  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:36:10 d2.utils.events]: \u001b[0m eta: 1:53:07  iter: 64999  total_loss: 1.155  loss_cls: 0.2669  loss_box_reg: 0.3707  loss_mask: 0.2485  loss_rpn_cls: 0.06513  loss_rpn_loc: 0.1502  time: 0.2237  data_time: 0.0141  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:36:14 d2.utils.events]: \u001b[0m eta: 1:52:57  iter: 65019  total_loss: 1.315  loss_cls: 0.3257  loss_box_reg: 0.4398  loss_mask: 0.2854  loss_rpn_cls: 0.1033  loss_rpn_loc: 0.1768  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:36:19 d2.utils.events]: \u001b[0m eta: 1:52:53  iter: 65039  total_loss: 1.197  loss_cls: 0.3073  loss_box_reg: 0.3758  loss_mask: 0.2507  loss_rpn_cls: 0.1092  loss_rpn_loc: 0.1684  time: 0.2237  data_time: 0.0153  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:36:24 d2.utils.events]: \u001b[0m eta: 1:52:48  iter: 65059  total_loss: 1.182  loss_cls: 0.309  loss_box_reg: 0.3618  loss_mask: 0.2596  loss_rpn_cls: 0.09376  loss_rpn_loc: 0.1663  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:36:28 d2.utils.events]: \u001b[0m eta: 1:52:46  iter: 65079  total_loss: 1.201  loss_cls: 0.2659  loss_box_reg: 0.3861  loss_mask: 0.2758  loss_rpn_cls: 0.09161  loss_rpn_loc: 0.1726  time: 0.2237  data_time: 0.0107  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:36:33 d2.utils.events]: \u001b[0m eta: 1:52:42  iter: 65099  total_loss: 1.177  loss_cls: 0.2921  loss_box_reg: 0.3627  loss_mask: 0.2662  loss_rpn_cls: 0.0693  loss_rpn_loc: 0.152  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:36:38 d2.utils.events]: \u001b[0m eta: 1:52:50  iter: 65119  total_loss: 1.173  loss_cls: 0.322  loss_box_reg: 0.3911  loss_mask: 0.2724  loss_rpn_cls: 0.104  loss_rpn_loc: 0.1891  time: 0.2237  data_time: 0.0100  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:36:42 d2.utils.events]: \u001b[0m eta: 1:52:47  iter: 65139  total_loss: 1.105  loss_cls: 0.2628  loss_box_reg: 0.3666  loss_mask: 0.2439  loss_rpn_cls: 0.05861  loss_rpn_loc: 0.1633  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:36:47 d2.utils.events]: \u001b[0m eta: 1:52:52  iter: 65159  total_loss: 1.224  loss_cls: 0.3094  loss_box_reg: 0.3741  loss_mask: 0.2541  loss_rpn_cls: 0.0854  loss_rpn_loc: 0.148  time: 0.2237  data_time: 0.0155  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:36:51 d2.utils.events]: \u001b[0m eta: 1:52:50  iter: 65179  total_loss: 1.236  loss_cls: 0.3207  loss_box_reg: 0.3919  loss_mask: 0.2746  loss_rpn_cls: 0.065  loss_rpn_loc: 0.1723  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:36:56 d2.utils.events]: \u001b[0m eta: 1:52:51  iter: 65199  total_loss: 1.179  loss_cls: 0.2733  loss_box_reg: 0.3288  loss_mask: 0.2623  loss_rpn_cls: 0.1093  loss_rpn_loc: 0.173  time: 0.2237  data_time: 0.0094  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:37:01 d2.utils.events]: \u001b[0m eta: 1:52:42  iter: 65219  total_loss: 1.111  loss_cls: 0.2668  loss_box_reg: 0.3612  loss_mask: 0.2456  loss_rpn_cls: 0.09713  loss_rpn_loc: 0.1671  time: 0.2237  data_time: 0.0159  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:37:05 d2.utils.events]: \u001b[0m eta: 1:52:42  iter: 65239  total_loss: 1.123  loss_cls: 0.2684  loss_box_reg: 0.4008  loss_mask: 0.2395  loss_rpn_cls: 0.05463  loss_rpn_loc: 0.1507  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:37:09 d2.utils.events]: \u001b[0m eta: 1:52:39  iter: 65259  total_loss: 1.108  loss_cls: 0.2511  loss_box_reg: 0.3419  loss_mask: 0.2597  loss_rpn_cls: 0.07456  loss_rpn_loc: 0.1562  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:37:14 d2.utils.events]: \u001b[0m eta: 1:52:33  iter: 65279  total_loss: 1.024  loss_cls: 0.2002  loss_box_reg: 0.3377  loss_mask: 0.2421  loss_rpn_cls: 0.06988  loss_rpn_loc: 0.1692  time: 0.2237  data_time: 0.0089  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:37:19 d2.utils.events]: \u001b[0m eta: 1:52:26  iter: 65299  total_loss: 1.104  loss_cls: 0.2539  loss_box_reg: 0.3453  loss_mask: 0.2619  loss_rpn_cls: 0.08166  loss_rpn_loc: 0.1757  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:37:23 d2.utils.events]: \u001b[0m eta: 1:52:27  iter: 65319  total_loss: 1.113  loss_cls: 0.2168  loss_box_reg: 0.3397  loss_mask: 0.2577  loss_rpn_cls: 0.06925  loss_rpn_loc: 0.1515  time: 0.2237  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:37:28 d2.utils.events]: \u001b[0m eta: 1:52:22  iter: 65339  total_loss: 1.077  loss_cls: 0.246  loss_box_reg: 0.3497  loss_mask: 0.2367  loss_rpn_cls: 0.06401  loss_rpn_loc: 0.1656  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:37:32 d2.utils.events]: \u001b[0m eta: 1:52:20  iter: 65359  total_loss: 1.206  loss_cls: 0.3043  loss_box_reg: 0.4068  loss_mask: 0.2611  loss_rpn_cls: 0.08603  loss_rpn_loc: 0.1516  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:37:37 d2.utils.events]: \u001b[0m eta: 1:52:11  iter: 65379  total_loss: 1.183  loss_cls: 0.2801  loss_box_reg: 0.3949  loss_mask: 0.2431  loss_rpn_cls: 0.08702  loss_rpn_loc: 0.1764  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:37:41 d2.utils.events]: \u001b[0m eta: 1:52:11  iter: 65399  total_loss: 1.136  loss_cls: 0.2629  loss_box_reg: 0.3744  loss_mask: 0.2669  loss_rpn_cls: 0.07257  loss_rpn_loc: 0.1828  time: 0.2237  data_time: 0.0177  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:37:46 d2.utils.events]: \u001b[0m eta: 1:52:03  iter: 65419  total_loss: 1.107  loss_cls: 0.2607  loss_box_reg: 0.3409  loss_mask: 0.2494  loss_rpn_cls: 0.07747  loss_rpn_loc: 0.1733  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:37:50 d2.utils.events]: \u001b[0m eta: 1:51:41  iter: 65439  total_loss: 1.147  loss_cls: 0.253  loss_box_reg: 0.4044  loss_mask: 0.2496  loss_rpn_cls: 0.05194  loss_rpn_loc: 0.1514  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:37:54 d2.utils.events]: \u001b[0m eta: 1:51:36  iter: 65459  total_loss: 1.312  loss_cls: 0.3176  loss_box_reg: 0.4001  loss_mask: 0.2962  loss_rpn_cls: 0.09052  loss_rpn_loc: 0.167  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:37:59 d2.utils.events]: \u001b[0m eta: 1:51:43  iter: 65479  total_loss: 1.2  loss_cls: 0.2878  loss_box_reg: 0.3591  loss_mask: 0.2594  loss_rpn_cls: 0.06606  loss_rpn_loc: 0.1672  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:38:03 d2.utils.events]: \u001b[0m eta: 1:51:38  iter: 65499  total_loss: 1.162  loss_cls: 0.282  loss_box_reg: 0.3947  loss_mask: 0.269  loss_rpn_cls: 0.06941  loss_rpn_loc: 0.1592  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:38:08 d2.utils.events]: \u001b[0m eta: 1:51:28  iter: 65519  total_loss: 1.148  loss_cls: 0.2644  loss_box_reg: 0.3674  loss_mask: 0.2677  loss_rpn_cls: 0.06317  loss_rpn_loc: 0.1668  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:38:12 d2.utils.events]: \u001b[0m eta: 1:51:20  iter: 65539  total_loss: 1.138  loss_cls: 0.2785  loss_box_reg: 0.3998  loss_mask: 0.2373  loss_rpn_cls: 0.07771  loss_rpn_loc: 0.1453  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:38:17 d2.utils.events]: \u001b[0m eta: 1:51:33  iter: 65559  total_loss: 1.285  loss_cls: 0.3049  loss_box_reg: 0.4027  loss_mask: 0.2689  loss_rpn_cls: 0.08005  loss_rpn_loc: 0.1559  time: 0.2237  data_time: 0.0155  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:38:21 d2.utils.events]: \u001b[0m eta: 1:51:24  iter: 65579  total_loss: 1.143  loss_cls: 0.2864  loss_box_reg: 0.3349  loss_mask: 0.2512  loss_rpn_cls: 0.1022  loss_rpn_loc: 0.1722  time: 0.2237  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:38:26 d2.utils.events]: \u001b[0m eta: 1:51:29  iter: 65599  total_loss: 1.035  loss_cls: 0.2576  loss_box_reg: 0.3543  loss_mask: 0.2452  loss_rpn_cls: 0.06738  loss_rpn_loc: 0.1566  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:38:30 d2.utils.events]: \u001b[0m eta: 1:51:22  iter: 65619  total_loss: 1.052  loss_cls: 0.2263  loss_box_reg: 0.3656  loss_mask: 0.2694  loss_rpn_cls: 0.07087  loss_rpn_loc: 0.1747  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:38:34 d2.utils.events]: \u001b[0m eta: 1:51:26  iter: 65639  total_loss: 1.167  loss_cls: 0.2737  loss_box_reg: 0.391  loss_mask: 0.2668  loss_rpn_cls: 0.06564  loss_rpn_loc: 0.1611  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:38:39 d2.utils.events]: \u001b[0m eta: 1:51:25  iter: 65659  total_loss: 1.092  loss_cls: 0.2493  loss_box_reg: 0.3529  loss_mask: 0.2475  loss_rpn_cls: 0.06054  loss_rpn_loc: 0.1588  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:38:44 d2.utils.events]: \u001b[0m eta: 1:51:21  iter: 65679  total_loss: 0.9972  loss_cls: 0.2053  loss_box_reg: 0.2957  loss_mask: 0.2582  loss_rpn_cls: 0.06585  loss_rpn_loc: 0.1581  time: 0.2237  data_time: 0.0161  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:38:48 d2.utils.events]: \u001b[0m eta: 1:51:17  iter: 65699  total_loss: 1.239  loss_cls: 0.3109  loss_box_reg: 0.4174  loss_mask: 0.2662  loss_rpn_cls: 0.07942  loss_rpn_loc: 0.1888  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:38:52 d2.utils.events]: \u001b[0m eta: 1:51:14  iter: 65719  total_loss: 1.209  loss_cls: 0.273  loss_box_reg: 0.3533  loss_mask: 0.2811  loss_rpn_cls: 0.07769  loss_rpn_loc: 0.1659  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:38:57 d2.utils.events]: \u001b[0m eta: 1:51:04  iter: 65739  total_loss: 1.146  loss_cls: 0.2626  loss_box_reg: 0.3513  loss_mask: 0.2471  loss_rpn_cls: 0.06755  loss_rpn_loc: 0.1561  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:39:02 d2.utils.events]: \u001b[0m eta: 1:50:57  iter: 65759  total_loss: 1.058  loss_cls: 0.2199  loss_box_reg: 0.3351  loss_mask: 0.2753  loss_rpn_cls: 0.08732  loss_rpn_loc: 0.16  time: 0.2237  data_time: 0.0255  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:39:06 d2.utils.events]: \u001b[0m eta: 1:50:55  iter: 65779  total_loss: 1.247  loss_cls: 0.3323  loss_box_reg: 0.4063  loss_mask: 0.267  loss_rpn_cls: 0.07697  loss_rpn_loc: 0.1732  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:39:11 d2.utils.events]: \u001b[0m eta: 1:50:54  iter: 65799  total_loss: 1.196  loss_cls: 0.3266  loss_box_reg: 0.404  loss_mask: 0.264  loss_rpn_cls: 0.06359  loss_rpn_loc: 0.1525  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:39:15 d2.utils.events]: \u001b[0m eta: 1:50:51  iter: 65819  total_loss: 1.275  loss_cls: 0.308  loss_box_reg: 0.4256  loss_mask: 0.2601  loss_rpn_cls: 0.08907  loss_rpn_loc: 0.1807  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:39:19 d2.utils.events]: \u001b[0m eta: 1:50:42  iter: 65839  total_loss: 1.155  loss_cls: 0.3045  loss_box_reg: 0.4126  loss_mask: 0.2588  loss_rpn_cls: 0.06555  loss_rpn_loc: 0.1662  time: 0.2237  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:39:24 d2.utils.events]: \u001b[0m eta: 1:50:45  iter: 65859  total_loss: 1.142  loss_cls: 0.2753  loss_box_reg: 0.3506  loss_mask: 0.2326  loss_rpn_cls: 0.05122  loss_rpn_loc: 0.1484  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:39:29 d2.utils.events]: \u001b[0m eta: 1:50:42  iter: 65879  total_loss: 1.128  loss_cls: 0.252  loss_box_reg: 0.3633  loss_mask: 0.2588  loss_rpn_cls: 0.07384  loss_rpn_loc: 0.1765  time: 0.2237  data_time: 0.0166  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:39:33 d2.utils.events]: \u001b[0m eta: 1:50:44  iter: 65899  total_loss: 1.172  loss_cls: 0.2645  loss_box_reg: 0.3559  loss_mask: 0.2665  loss_rpn_cls: 0.06625  loss_rpn_loc: 0.1683  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:39:37 d2.utils.events]: \u001b[0m eta: 1:50:33  iter: 65919  total_loss: 1.113  loss_cls: 0.2628  loss_box_reg: 0.3521  loss_mask: 0.2327  loss_rpn_cls: 0.05419  loss_rpn_loc: 0.1398  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:39:42 d2.utils.events]: \u001b[0m eta: 1:50:23  iter: 65939  total_loss: 1.223  loss_cls: 0.2757  loss_box_reg: 0.4079  loss_mask: 0.2773  loss_rpn_cls: 0.07036  loss_rpn_loc: 0.1689  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:39:46 d2.utils.events]: \u001b[0m eta: 1:50:19  iter: 65959  total_loss: 1.219  loss_cls: 0.3105  loss_box_reg: 0.4091  loss_mask: 0.2651  loss_rpn_cls: 0.06032  loss_rpn_loc: 0.1482  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:39:51 d2.utils.events]: \u001b[0m eta: 1:50:19  iter: 65979  total_loss: 1.122  loss_cls: 0.2972  loss_box_reg: 0.3715  loss_mask: 0.2608  loss_rpn_cls: 0.0596  loss_rpn_loc: 0.1697  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:39:55 d2.utils.events]: \u001b[0m eta: 1:50:14  iter: 65999  total_loss: 1.115  loss_cls: 0.2471  loss_box_reg: 0.3524  loss_mask: 0.267  loss_rpn_cls: 0.07093  loss_rpn_loc: 0.1672  time: 0.2237  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:39:59 d2.utils.events]: \u001b[0m eta: 1:50:08  iter: 66019  total_loss: 1.188  loss_cls: 0.3182  loss_box_reg: 0.3859  loss_mask: 0.2558  loss_rpn_cls: 0.06099  loss_rpn_loc: 0.169  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:40:04 d2.utils.events]: \u001b[0m eta: 1:50:02  iter: 66039  total_loss: 1.169  loss_cls: 0.2833  loss_box_reg: 0.3562  loss_mask: 0.2784  loss_rpn_cls: 0.06642  loss_rpn_loc: 0.1622  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:40:08 d2.utils.events]: \u001b[0m eta: 1:50:00  iter: 66059  total_loss: 1.087  loss_cls: 0.2483  loss_box_reg: 0.3512  loss_mask: 0.2451  loss_rpn_cls: 0.07682  loss_rpn_loc: 0.1499  time: 0.2237  data_time: 0.0162  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:40:13 d2.utils.events]: \u001b[0m eta: 1:49:56  iter: 66079  total_loss: 1.216  loss_cls: 0.3275  loss_box_reg: 0.3871  loss_mask: 0.257  loss_rpn_cls: 0.07291  loss_rpn_loc: 0.1681  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:40:17 d2.utils.events]: \u001b[0m eta: 1:49:52  iter: 66099  total_loss: 1.216  loss_cls: 0.2978  loss_box_reg: 0.4122  loss_mask: 0.2615  loss_rpn_cls: 0.06708  loss_rpn_loc: 0.164  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:40:22 d2.utils.events]: \u001b[0m eta: 1:49:45  iter: 66119  total_loss: 1.014  loss_cls: 0.2668  loss_box_reg: 0.3321  loss_mask: 0.2428  loss_rpn_cls: 0.04835  loss_rpn_loc: 0.1339  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:40:26 d2.utils.events]: \u001b[0m eta: 1:49:29  iter: 66139  total_loss: 1.25  loss_cls: 0.3269  loss_box_reg: 0.4002  loss_mask: 0.2535  loss_rpn_cls: 0.08149  loss_rpn_loc: 0.1726  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:40:30 d2.utils.events]: \u001b[0m eta: 1:49:19  iter: 66159  total_loss: 1.111  loss_cls: 0.2818  loss_box_reg: 0.3759  loss_mask: 0.2626  loss_rpn_cls: 0.07424  loss_rpn_loc: 0.1511  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:40:34 d2.utils.events]: \u001b[0m eta: 1:49:05  iter: 66179  total_loss: 1.144  loss_cls: 0.2844  loss_box_reg: 0.3751  loss_mask: 0.2641  loss_rpn_cls: 0.0526  loss_rpn_loc: 0.1544  time: 0.2237  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:40:39 d2.utils.events]: \u001b[0m eta: 1:49:02  iter: 66199  total_loss: 1.193  loss_cls: 0.3155  loss_box_reg: 0.3891  loss_mask: 0.2599  loss_rpn_cls: 0.09045  loss_rpn_loc: 0.1564  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:40:43 d2.utils.events]: \u001b[0m eta: 1:48:58  iter: 66219  total_loss: 1.026  loss_cls: 0.2344  loss_box_reg: 0.352  loss_mask: 0.2507  loss_rpn_cls: 0.05076  loss_rpn_loc: 0.1309  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:40:48 d2.utils.events]: \u001b[0m eta: 1:48:53  iter: 66239  total_loss: 1.096  loss_cls: 0.2683  loss_box_reg: 0.3163  loss_mask: 0.2505  loss_rpn_cls: 0.0663  loss_rpn_loc: 0.1672  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:40:52 d2.utils.events]: \u001b[0m eta: 1:48:50  iter: 66259  total_loss: 1.271  loss_cls: 0.3137  loss_box_reg: 0.3868  loss_mask: 0.2749  loss_rpn_cls: 0.07267  loss_rpn_loc: 0.1773  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:40:57 d2.utils.events]: \u001b[0m eta: 1:48:49  iter: 66279  total_loss: 1.318  loss_cls: 0.3397  loss_box_reg: 0.447  loss_mask: 0.2744  loss_rpn_cls: 0.05909  loss_rpn_loc: 0.1499  time: 0.2237  data_time: 0.0152  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:41:01 d2.utils.events]: \u001b[0m eta: 1:48:49  iter: 66299  total_loss: 1.173  loss_cls: 0.2924  loss_box_reg: 0.3641  loss_mask: 0.2623  loss_rpn_cls: 0.0743  loss_rpn_loc: 0.1801  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:41:06 d2.utils.events]: \u001b[0m eta: 1:48:37  iter: 66319  total_loss: 1.103  loss_cls: 0.2615  loss_box_reg: 0.3425  loss_mask: 0.247  loss_rpn_cls: 0.06244  loss_rpn_loc: 0.1552  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:41:10 d2.utils.events]: \u001b[0m eta: 1:48:40  iter: 66339  total_loss: 1.21  loss_cls: 0.2791  loss_box_reg: 0.3914  loss_mask: 0.2706  loss_rpn_cls: 0.07768  loss_rpn_loc: 0.1821  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:41:15 d2.utils.events]: \u001b[0m eta: 1:48:36  iter: 66359  total_loss: 1.185  loss_cls: 0.2789  loss_box_reg: 0.3685  loss_mask: 0.2698  loss_rpn_cls: 0.07296  loss_rpn_loc: 0.1711  time: 0.2237  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:41:19 d2.utils.events]: \u001b[0m eta: 1:48:41  iter: 66379  total_loss: 1.175  loss_cls: 0.303  loss_box_reg: 0.3737  loss_mask: 0.2661  loss_rpn_cls: 0.07486  loss_rpn_loc: 0.1609  time: 0.2237  data_time: 0.0097  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:41:24 d2.utils.events]: \u001b[0m eta: 1:48:43  iter: 66399  total_loss: 1.185  loss_cls: 0.2623  loss_box_reg: 0.3773  loss_mask: 0.2598  loss_rpn_cls: 0.08344  loss_rpn_loc: 0.1738  time: 0.2237  data_time: 0.0147  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:41:28 d2.utils.events]: \u001b[0m eta: 1:48:41  iter: 66419  total_loss: 1.203  loss_cls: 0.3208  loss_box_reg: 0.4017  loss_mask: 0.2675  loss_rpn_cls: 0.08096  loss_rpn_loc: 0.172  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:41:33 d2.utils.events]: \u001b[0m eta: 1:48:44  iter: 66439  total_loss: 1.075  loss_cls: 0.241  loss_box_reg: 0.3716  loss_mask: 0.2466  loss_rpn_cls: 0.07533  loss_rpn_loc: 0.1621  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:41:37 d2.utils.events]: \u001b[0m eta: 1:48:41  iter: 66459  total_loss: 1.196  loss_cls: 0.3003  loss_box_reg: 0.4041  loss_mask: 0.2743  loss_rpn_cls: 0.06509  loss_rpn_loc: 0.1763  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:41:42 d2.utils.events]: \u001b[0m eta: 1:48:37  iter: 66479  total_loss: 1.1  loss_cls: 0.2555  loss_box_reg: 0.3699  loss_mask: 0.2431  loss_rpn_cls: 0.0732  loss_rpn_loc: 0.1684  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:41:46 d2.utils.events]: \u001b[0m eta: 1:48:33  iter: 66499  total_loss: 1.184  loss_cls: 0.2938  loss_box_reg: 0.3702  loss_mask: 0.2834  loss_rpn_cls: 0.08256  loss_rpn_loc: 0.1634  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:41:51 d2.utils.events]: \u001b[0m eta: 1:48:29  iter: 66519  total_loss: 1.113  loss_cls: 0.2669  loss_box_reg: 0.3876  loss_mask: 0.2617  loss_rpn_cls: 0.07376  loss_rpn_loc: 0.1691  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:41:56 d2.utils.events]: \u001b[0m eta: 1:48:31  iter: 66539  total_loss: 1.335  loss_cls: 0.3593  loss_box_reg: 0.3947  loss_mask: 0.2745  loss_rpn_cls: 0.09351  loss_rpn_loc: 0.1663  time: 0.2237  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:42:00 d2.utils.events]: \u001b[0m eta: 1:48:25  iter: 66559  total_loss: 1.187  loss_cls: 0.2762  loss_box_reg: 0.3566  loss_mask: 0.2729  loss_rpn_cls: 0.07798  loss_rpn_loc: 0.1686  time: 0.2237  data_time: 0.0177  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:42:05 d2.utils.events]: \u001b[0m eta: 1:48:18  iter: 66579  total_loss: 1.118  loss_cls: 0.2903  loss_box_reg: 0.3658  loss_mask: 0.246  loss_rpn_cls: 0.06429  loss_rpn_loc: 0.1536  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:42:09 d2.utils.events]: \u001b[0m eta: 1:48:14  iter: 66599  total_loss: 1.104  loss_cls: 0.2808  loss_box_reg: 0.3518  loss_mask: 0.2424  loss_rpn_cls: 0.08786  loss_rpn_loc: 0.1596  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:42:14 d2.utils.events]: \u001b[0m eta: 1:48:12  iter: 66619  total_loss: 1.133  loss_cls: 0.2644  loss_box_reg: 0.3594  loss_mask: 0.2538  loss_rpn_cls: 0.08761  loss_rpn_loc: 0.1641  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:42:18 d2.utils.events]: \u001b[0m eta: 1:48:14  iter: 66639  total_loss: 1.124  loss_cls: 0.2844  loss_box_reg: 0.3712  loss_mask: 0.2606  loss_rpn_cls: 0.08445  loss_rpn_loc: 0.1652  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:42:23 d2.utils.events]: \u001b[0m eta: 1:48:05  iter: 66659  total_loss: 1.043  loss_cls: 0.2206  loss_box_reg: 0.3439  loss_mask: 0.2519  loss_rpn_cls: 0.07148  loss_rpn_loc: 0.1501  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:42:27 d2.utils.events]: \u001b[0m eta: 1:48:00  iter: 66679  total_loss: 1.062  loss_cls: 0.2488  loss_box_reg: 0.3442  loss_mask: 0.2615  loss_rpn_cls: 0.07982  loss_rpn_loc: 0.1789  time: 0.2237  data_time: 0.0173  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:42:32 d2.utils.events]: \u001b[0m eta: 1:47:56  iter: 66699  total_loss: 1.179  loss_cls: 0.3057  loss_box_reg: 0.4029  loss_mask: 0.254  loss_rpn_cls: 0.06909  loss_rpn_loc: 0.1572  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:42:36 d2.utils.events]: \u001b[0m eta: 1:47:46  iter: 66719  total_loss: 1.146  loss_cls: 0.2931  loss_box_reg: 0.3688  loss_mask: 0.2431  loss_rpn_cls: 0.0688  loss_rpn_loc: 0.1607  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:42:41 d2.utils.events]: \u001b[0m eta: 1:47:46  iter: 66739  total_loss: 1.231  loss_cls: 0.312  loss_box_reg: 0.3842  loss_mask: 0.2707  loss_rpn_cls: 0.05357  loss_rpn_loc: 0.1689  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:42:45 d2.utils.events]: \u001b[0m eta: 1:47:46  iter: 66759  total_loss: 1.093  loss_cls: 0.2976  loss_box_reg: 0.3567  loss_mask: 0.2508  loss_rpn_cls: 0.06232  loss_rpn_loc: 0.1782  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:42:50 d2.utils.events]: \u001b[0m eta: 1:47:33  iter: 66779  total_loss: 1.133  loss_cls: 0.2951  loss_box_reg: 0.339  loss_mask: 0.2634  loss_rpn_cls: 0.08303  loss_rpn_loc: 0.1618  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:42:54 d2.utils.events]: \u001b[0m eta: 1:47:37  iter: 66799  total_loss: 1.21  loss_cls: 0.2883  loss_box_reg: 0.4128  loss_mask: 0.2722  loss_rpn_cls: 0.07019  loss_rpn_loc: 0.1774  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:42:59 d2.utils.events]: \u001b[0m eta: 1:47:35  iter: 66819  total_loss: 1.245  loss_cls: 0.307  loss_box_reg: 0.4066  loss_mask: 0.2827  loss_rpn_cls: 0.09146  loss_rpn_loc: 0.1605  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:43:03 d2.utils.events]: \u001b[0m eta: 1:47:35  iter: 66839  total_loss: 1.159  loss_cls: 0.2709  loss_box_reg: 0.3843  loss_mask: 0.2775  loss_rpn_cls: 0.09523  loss_rpn_loc: 0.1872  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:43:08 d2.utils.events]: \u001b[0m eta: 1:47:31  iter: 66859  total_loss: 1.18  loss_cls: 0.3142  loss_box_reg: 0.3699  loss_mask: 0.2534  loss_rpn_cls: 0.0731  loss_rpn_loc: 0.1695  time: 0.2237  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:43:13 d2.utils.events]: \u001b[0m eta: 1:47:26  iter: 66879  total_loss: 1.193  loss_cls: 0.2806  loss_box_reg: 0.3663  loss_mask: 0.2575  loss_rpn_cls: 0.09277  loss_rpn_loc: 0.183  time: 0.2237  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:43:17 d2.utils.events]: \u001b[0m eta: 1:47:18  iter: 66899  total_loss: 1.241  loss_cls: 0.3058  loss_box_reg: 0.4186  loss_mask: 0.2582  loss_rpn_cls: 0.06696  loss_rpn_loc: 0.1629  time: 0.2237  data_time: 0.0168  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:43:21 d2.utils.events]: \u001b[0m eta: 1:47:13  iter: 66919  total_loss: 1.185  loss_cls: 0.2999  loss_box_reg: 0.4164  loss_mask: 0.2718  loss_rpn_cls: 0.09405  loss_rpn_loc: 0.1582  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:43:26 d2.utils.events]: \u001b[0m eta: 1:47:08  iter: 66939  total_loss: 1.088  loss_cls: 0.2502  loss_box_reg: 0.388  loss_mask: 0.2562  loss_rpn_cls: 0.05113  loss_rpn_loc: 0.1491  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:43:30 d2.utils.events]: \u001b[0m eta: 1:47:05  iter: 66959  total_loss: 1.144  loss_cls: 0.2633  loss_box_reg: 0.3612  loss_mask: 0.2598  loss_rpn_cls: 0.07753  loss_rpn_loc: 0.1597  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:43:35 d2.utils.events]: \u001b[0m eta: 1:47:11  iter: 66979  total_loss: 1.171  loss_cls: 0.275  loss_box_reg: 0.3693  loss_mask: 0.2641  loss_rpn_cls: 0.07833  loss_rpn_loc: 0.1693  time: 0.2237  data_time: 0.0174  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:43:39 d2.utils.events]: \u001b[0m eta: 1:47:03  iter: 66999  total_loss: 1.2  loss_cls: 0.2863  loss_box_reg: 0.3886  loss_mask: 0.2711  loss_rpn_cls: 0.07151  loss_rpn_loc: 0.1725  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:43:44 d2.utils.events]: \u001b[0m eta: 1:47:08  iter: 67019  total_loss: 1.199  loss_cls: 0.3103  loss_box_reg: 0.3796  loss_mask: 0.2636  loss_rpn_cls: 0.0724  loss_rpn_loc: 0.1764  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:43:48 d2.utils.events]: \u001b[0m eta: 1:47:05  iter: 67039  total_loss: 1.284  loss_cls: 0.3351  loss_box_reg: 0.4079  loss_mask: 0.275  loss_rpn_cls: 0.09109  loss_rpn_loc: 0.1722  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:43:53 d2.utils.events]: \u001b[0m eta: 1:46:50  iter: 67059  total_loss: 1.077  loss_cls: 0.2869  loss_box_reg: 0.3342  loss_mask: 0.2326  loss_rpn_cls: 0.05261  loss_rpn_loc: 0.1501  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:43:57 d2.utils.events]: \u001b[0m eta: 1:46:37  iter: 67079  total_loss: 1.175  loss_cls: 0.2978  loss_box_reg: 0.3791  loss_mask: 0.2413  loss_rpn_cls: 0.07141  loss_rpn_loc: 0.153  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:44:02 d2.utils.events]: \u001b[0m eta: 1:46:31  iter: 67099  total_loss: 1.101  loss_cls: 0.2916  loss_box_reg: 0.3534  loss_mask: 0.2602  loss_rpn_cls: 0.0814  loss_rpn_loc: 0.1631  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:44:06 d2.utils.events]: \u001b[0m eta: 1:46:21  iter: 67119  total_loss: 1.108  loss_cls: 0.2918  loss_box_reg: 0.389  loss_mask: 0.2366  loss_rpn_cls: 0.04958  loss_rpn_loc: 0.1393  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:44:10 d2.utils.events]: \u001b[0m eta: 1:46:25  iter: 67139  total_loss: 1.003  loss_cls: 0.2301  loss_box_reg: 0.3346  loss_mask: 0.2606  loss_rpn_cls: 0.0681  loss_rpn_loc: 0.1564  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:44:15 d2.utils.events]: \u001b[0m eta: 1:46:22  iter: 67159  total_loss: 1.179  loss_cls: 0.2733  loss_box_reg: 0.3596  loss_mask: 0.2567  loss_rpn_cls: 0.06548  loss_rpn_loc: 0.1627  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:44:19 d2.utils.events]: \u001b[0m eta: 1:46:34  iter: 67179  total_loss: 1.133  loss_cls: 0.2837  loss_box_reg: 0.3699  loss_mask: 0.2585  loss_rpn_cls: 0.06819  loss_rpn_loc: 0.1612  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:44:24 d2.utils.events]: \u001b[0m eta: 1:46:25  iter: 67199  total_loss: 1.194  loss_cls: 0.2901  loss_box_reg: 0.3657  loss_mask: 0.264  loss_rpn_cls: 0.06835  loss_rpn_loc: 0.1567  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:44:29 d2.utils.events]: \u001b[0m eta: 1:46:25  iter: 67219  total_loss: 1.157  loss_cls: 0.2786  loss_box_reg: 0.3637  loss_mask: 0.2409  loss_rpn_cls: 0.0622  loss_rpn_loc: 0.1526  time: 0.2237  data_time: 0.0213  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:44:33 d2.utils.events]: \u001b[0m eta: 1:46:16  iter: 67239  total_loss: 1.165  loss_cls: 0.2873  loss_box_reg: 0.3838  loss_mask: 0.2463  loss_rpn_cls: 0.06788  loss_rpn_loc: 0.1483  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:44:38 d2.utils.events]: \u001b[0m eta: 1:46:10  iter: 67259  total_loss: 1.144  loss_cls: 0.2705  loss_box_reg: 0.3486  loss_mask: 0.2583  loss_rpn_cls: 0.05591  loss_rpn_loc: 0.1667  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:44:42 d2.utils.events]: \u001b[0m eta: 1:46:10  iter: 67279  total_loss: 1.208  loss_cls: 0.2965  loss_box_reg: 0.3983  loss_mask: 0.2701  loss_rpn_cls: 0.07038  loss_rpn_loc: 0.1549  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:44:46 d2.utils.events]: \u001b[0m eta: 1:45:46  iter: 67299  total_loss: 1.227  loss_cls: 0.3148  loss_box_reg: 0.4094  loss_mask: 0.2674  loss_rpn_cls: 0.05176  loss_rpn_loc: 0.1554  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:44:51 d2.utils.events]: \u001b[0m eta: 1:45:48  iter: 67319  total_loss: 1.091  loss_cls: 0.267  loss_box_reg: 0.3483  loss_mask: 0.2487  loss_rpn_cls: 0.06589  loss_rpn_loc: 0.1724  time: 0.2237  data_time: 0.0220  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:44:56 d2.utils.events]: \u001b[0m eta: 1:45:39  iter: 67339  total_loss: 1.309  loss_cls: 0.3264  loss_box_reg: 0.381  loss_mask: 0.2841  loss_rpn_cls: 0.08877  loss_rpn_loc: 0.1886  time: 0.2237  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:45:00 d2.utils.events]: \u001b[0m eta: 1:45:31  iter: 67359  total_loss: 1.15  loss_cls: 0.2993  loss_box_reg: 0.4073  loss_mask: 0.2579  loss_rpn_cls: 0.05575  loss_rpn_loc: 0.1624  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:45:04 d2.utils.events]: \u001b[0m eta: 1:45:21  iter: 67379  total_loss: 1.155  loss_cls: 0.3003  loss_box_reg: 0.416  loss_mask: 0.2542  loss_rpn_cls: 0.07149  loss_rpn_loc: 0.1586  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:45:09 d2.utils.events]: \u001b[0m eta: 1:45:14  iter: 67399  total_loss: 1.205  loss_cls: 0.2925  loss_box_reg: 0.4058  loss_mask: 0.2663  loss_rpn_cls: 0.0751  loss_rpn_loc: 0.1628  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:45:13 d2.utils.events]: \u001b[0m eta: 1:45:08  iter: 67419  total_loss: 1.2  loss_cls: 0.2836  loss_box_reg: 0.3478  loss_mask: 0.2642  loss_rpn_cls: 0.06694  loss_rpn_loc: 0.1426  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:45:20 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.47 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 01:45:20 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 01:45:20 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 01:45:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 01:45:21 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 01:45:21 d2.data.common]: \u001b[0mSerialized dataset takes 84.20 MiB\n",
      "\u001b[32m[12/30 01:45:24 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.52 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 01:45:24 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 01:45:24 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 01:45:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/30 01:45:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0008 s/iter. Inference: 0.0615 s/iter. Eval: 0.1426 s/iter. Total: 0.2049 s/iter. ETA=0:01:54\n",
      "\u001b[32m[12/30 01:45:33 d2.evaluation.evaluator]: \u001b[0mInference done 38/570. Dataloading: 0.0009 s/iter. Inference: 0.0602 s/iter. Eval: 0.1284 s/iter. Total: 0.1895 s/iter. ETA=0:01:40\n",
      "\u001b[32m[12/30 01:45:38 d2.evaluation.evaluator]: \u001b[0mInference done 66/570. Dataloading: 0.0009 s/iter. Inference: 0.0574 s/iter. Eval: 0.1273 s/iter. Total: 0.1856 s/iter. ETA=0:01:33\n",
      "\u001b[32m[12/30 01:45:43 d2.evaluation.evaluator]: \u001b[0mInference done 92/570. Dataloading: 0.0009 s/iter. Inference: 0.0568 s/iter. Eval: 0.1307 s/iter. Total: 0.1884 s/iter. ETA=0:01:30\n",
      "\u001b[32m[12/30 01:45:48 d2.evaluation.evaluator]: \u001b[0mInference done 118/570. Dataloading: 0.0009 s/iter. Inference: 0.0566 s/iter. Eval: 0.1319 s/iter. Total: 0.1894 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/30 01:45:53 d2.evaluation.evaluator]: \u001b[0mInference done 142/570. Dataloading: 0.0009 s/iter. Inference: 0.0567 s/iter. Eval: 0.1354 s/iter. Total: 0.1930 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 01:45:58 d2.evaluation.evaluator]: \u001b[0mInference done 162/570. Dataloading: 0.0009 s/iter. Inference: 0.0569 s/iter. Eval: 0.1446 s/iter. Total: 0.2024 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 01:46:03 d2.evaluation.evaluator]: \u001b[0mInference done 175/570. Dataloading: 0.0009 s/iter. Inference: 0.0573 s/iter. Eval: 0.1595 s/iter. Total: 0.2177 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/30 01:46:08 d2.evaluation.evaluator]: \u001b[0mInference done 192/570. Dataloading: 0.0009 s/iter. Inference: 0.0575 s/iter. Eval: 0.1664 s/iter. Total: 0.2249 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/30 01:46:13 d2.evaluation.evaluator]: \u001b[0mInference done 208/570. Dataloading: 0.0009 s/iter. Inference: 0.0575 s/iter. Eval: 0.1738 s/iter. Total: 0.2322 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/30 01:46:19 d2.evaluation.evaluator]: \u001b[0mInference done 225/570. Dataloading: 0.0009 s/iter. Inference: 0.0578 s/iter. Eval: 0.1787 s/iter. Total: 0.2374 s/iter. ETA=0:01:21\n",
      "\u001b[32m[12/30 01:46:24 d2.evaluation.evaluator]: \u001b[0mInference done 236/570. Dataloading: 0.0009 s/iter. Inference: 0.0578 s/iter. Eval: 0.1902 s/iter. Total: 0.2489 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 01:46:29 d2.evaluation.evaluator]: \u001b[0mInference done 249/570. Dataloading: 0.0009 s/iter. Inference: 0.0578 s/iter. Eval: 0.1995 s/iter. Total: 0.2583 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 01:46:35 d2.evaluation.evaluator]: \u001b[0mInference done 266/570. Dataloading: 0.0009 s/iter. Inference: 0.0577 s/iter. Eval: 0.2041 s/iter. Total: 0.2627 s/iter. ETA=0:01:19\n",
      "\u001b[32m[12/30 01:46:40 d2.evaluation.evaluator]: \u001b[0mInference done 285/570. Dataloading: 0.0009 s/iter. Inference: 0.0578 s/iter. Eval: 0.2046 s/iter. Total: 0.2634 s/iter. ETA=0:01:15\n",
      "\u001b[32m[12/30 01:46:45 d2.evaluation.evaluator]: \u001b[0mInference done 299/570. Dataloading: 0.0009 s/iter. Inference: 0.0577 s/iter. Eval: 0.2097 s/iter. Total: 0.2684 s/iter. ETA=0:01:12\n",
      "\u001b[32m[12/30 01:46:50 d2.evaluation.evaluator]: \u001b[0mInference done 349/570. Dataloading: 0.0009 s/iter. Inference: 0.0561 s/iter. Eval: 0.1869 s/iter. Total: 0.2440 s/iter. ETA=0:00:53\n",
      "\u001b[32m[12/30 01:46:56 d2.evaluation.evaluator]: \u001b[0mInference done 377/570. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.1830 s/iter. Total: 0.2398 s/iter. ETA=0:00:46\n",
      "\u001b[32m[12/30 01:47:01 d2.evaluation.evaluator]: \u001b[0mInference done 399/570. Dataloading: 0.0009 s/iter. Inference: 0.0560 s/iter. Eval: 0.1824 s/iter. Total: 0.2393 s/iter. ETA=0:00:40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:47:06 d2.evaluation.evaluator]: \u001b[0mInference done 417/570. Dataloading: 0.0009 s/iter. Inference: 0.0560 s/iter. Eval: 0.1843 s/iter. Total: 0.2412 s/iter. ETA=0:00:36\n",
      "\u001b[32m[12/30 01:47:11 d2.evaluation.evaluator]: \u001b[0mInference done 436/570. Dataloading: 0.0009 s/iter. Inference: 0.0563 s/iter. Eval: 0.1850 s/iter. Total: 0.2422 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/30 01:47:16 d2.evaluation.evaluator]: \u001b[0mInference done 467/570. Dataloading: 0.0009 s/iter. Inference: 0.0561 s/iter. Eval: 0.1802 s/iter. Total: 0.2372 s/iter. ETA=0:00:24\n",
      "\u001b[32m[12/30 01:47:21 d2.evaluation.evaluator]: \u001b[0mInference done 496/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1771 s/iter. Total: 0.2338 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/30 01:47:26 d2.evaluation.evaluator]: \u001b[0mInference done 518/570. Dataloading: 0.0009 s/iter. Inference: 0.0556 s/iter. Eval: 0.1773 s/iter. Total: 0.2338 s/iter. ETA=0:00:12\n",
      "\u001b[32m[12/30 01:47:32 d2.evaluation.evaluator]: \u001b[0mInference done 541/570. Dataloading: 0.0009 s/iter. Inference: 0.0556 s/iter. Eval: 0.1772 s/iter. Total: 0.2337 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/30 01:47:37 d2.evaluation.evaluator]: \u001b[0mInference done 559/570. Dataloading: 0.0009 s/iter. Inference: 0.0558 s/iter. Eval: 0.1788 s/iter. Total: 0.2356 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/30 01:47:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:13.216341 (0.235781 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 01:47:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.055881 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 01:47:40 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/30 01:47:40 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2860958749684428\n",
      "\u001b[32m[12/30 01:47:40 d2.utils.events]: \u001b[0m eta: 1:45:00  iter: 67439  total_loss: 1.171  loss_cls: 0.2987  loss_box_reg: 0.4046  loss_mask: 0.268  loss_rpn_cls: 0.06304  loss_rpn_loc: 0.156  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:47:45 d2.utils.events]: \u001b[0m eta: 1:44:52  iter: 67459  total_loss: 1.111  loss_cls: 0.2675  loss_box_reg: 0.363  loss_mask: 0.2426  loss_rpn_cls: 0.05795  loss_rpn_loc: 0.1436  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:47:49 d2.utils.events]: \u001b[0m eta: 1:44:42  iter: 67479  total_loss: 1.153  loss_cls: 0.289  loss_box_reg: 0.3672  loss_mask: 0.2578  loss_rpn_cls: 0.06943  loss_rpn_loc: 0.1646  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:47:53 d2.utils.events]: \u001b[0m eta: 1:44:34  iter: 67499  total_loss: 1.184  loss_cls: 0.2582  loss_box_reg: 0.3632  loss_mask: 0.2599  loss_rpn_cls: 0.06717  loss_rpn_loc: 0.1554  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:47:58 d2.utils.events]: \u001b[0m eta: 1:44:25  iter: 67519  total_loss: 1.295  loss_cls: 0.2801  loss_box_reg: 0.4004  loss_mask: 0.2569  loss_rpn_cls: 0.07919  loss_rpn_loc: 0.1812  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:48:03 d2.utils.events]: \u001b[0m eta: 1:44:21  iter: 67539  total_loss: 1.175  loss_cls: 0.2548  loss_box_reg: 0.3462  loss_mask: 0.2371  loss_rpn_cls: 0.06109  loss_rpn_loc: 0.1728  time: 0.2237  data_time: 0.0222  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:48:07 d2.utils.events]: \u001b[0m eta: 1:44:21  iter: 67559  total_loss: 1.223  loss_cls: 0.3059  loss_box_reg: 0.3727  loss_mask: 0.2516  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.1765  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:48:12 d2.utils.events]: \u001b[0m eta: 1:44:16  iter: 67579  total_loss: 1.099  loss_cls: 0.2546  loss_box_reg: 0.3549  loss_mask: 0.2622  loss_rpn_cls: 0.07699  loss_rpn_loc: 0.172  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:48:16 d2.utils.events]: \u001b[0m eta: 1:44:14  iter: 67599  total_loss: 1.156  loss_cls: 0.2873  loss_box_reg: 0.3667  loss_mask: 0.2601  loss_rpn_cls: 0.05831  loss_rpn_loc: 0.1647  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:48:21 d2.utils.events]: \u001b[0m eta: 1:44:10  iter: 67619  total_loss: 1.237  loss_cls: 0.3112  loss_box_reg: 0.4  loss_mask: 0.2802  loss_rpn_cls: 0.07306  loss_rpn_loc: 0.1763  time: 0.2237  data_time: 0.0130  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:48:25 d2.utils.events]: \u001b[0m eta: 1:44:01  iter: 67639  total_loss: 1.143  loss_cls: 0.3131  loss_box_reg: 0.3625  loss_mask: 0.2319  loss_rpn_cls: 0.06863  loss_rpn_loc: 0.17  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:48:30 d2.utils.events]: \u001b[0m eta: 1:43:59  iter: 67659  total_loss: 1.243  loss_cls: 0.3005  loss_box_reg: 0.3679  loss_mask: 0.2935  loss_rpn_cls: 0.07791  loss_rpn_loc: 0.1745  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:48:34 d2.utils.events]: \u001b[0m eta: 1:43:53  iter: 67679  total_loss: 1.136  loss_cls: 0.2639  loss_box_reg: 0.3746  loss_mask: 0.2618  loss_rpn_cls: 0.08419  loss_rpn_loc: 0.1693  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:48:39 d2.utils.events]: \u001b[0m eta: 1:43:52  iter: 67699  total_loss: 1.187  loss_cls: 0.3057  loss_box_reg: 0.3524  loss_mask: 0.268  loss_rpn_cls: 0.08289  loss_rpn_loc: 0.1745  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:48:43 d2.utils.events]: \u001b[0m eta: 1:43:51  iter: 67719  total_loss: 1.161  loss_cls: 0.2782  loss_box_reg: 0.4034  loss_mask: 0.2621  loss_rpn_cls: 0.06245  loss_rpn_loc: 0.1532  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:48:48 d2.utils.events]: \u001b[0m eta: 1:43:52  iter: 67739  total_loss: 1.212  loss_cls: 0.302  loss_box_reg: 0.3818  loss_mask: 0.2819  loss_rpn_cls: 0.08972  loss_rpn_loc: 0.1791  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:48:52 d2.utils.events]: \u001b[0m eta: 1:43:35  iter: 67759  total_loss: 1.007  loss_cls: 0.2303  loss_box_reg: 0.3346  loss_mask: 0.2677  loss_rpn_cls: 0.0517  loss_rpn_loc: 0.1563  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:48:57 d2.utils.events]: \u001b[0m eta: 1:43:37  iter: 67779  total_loss: 1.141  loss_cls: 0.2616  loss_box_reg: 0.3414  loss_mask: 0.2596  loss_rpn_cls: 0.07526  loss_rpn_loc: 0.1697  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:49:01 d2.utils.events]: \u001b[0m eta: 1:43:24  iter: 67799  total_loss: 1.095  loss_cls: 0.2892  loss_box_reg: 0.3534  loss_mask: 0.2447  loss_rpn_cls: 0.05362  loss_rpn_loc: 0.1427  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:49:06 d2.utils.events]: \u001b[0m eta: 1:43:22  iter: 67819  total_loss: 1.112  loss_cls: 0.2635  loss_box_reg: 0.3923  loss_mask: 0.2479  loss_rpn_cls: 0.06576  loss_rpn_loc: 0.1508  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:49:10 d2.utils.events]: \u001b[0m eta: 1:43:16  iter: 67839  total_loss: 1.301  loss_cls: 0.3433  loss_box_reg: 0.4378  loss_mask: 0.2769  loss_rpn_cls: 0.06604  loss_rpn_loc: 0.1575  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:49:15 d2.utils.events]: \u001b[0m eta: 1:43:11  iter: 67859  total_loss: 1.176  loss_cls: 0.3152  loss_box_reg: 0.3857  loss_mask: 0.2423  loss_rpn_cls: 0.0656  loss_rpn_loc: 0.1514  time: 0.2237  data_time: 0.0160  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:49:19 d2.utils.events]: \u001b[0m eta: 1:43:08  iter: 67879  total_loss: 0.9831  loss_cls: 0.2338  loss_box_reg: 0.3213  loss_mask: 0.2346  loss_rpn_cls: 0.0608  loss_rpn_loc: 0.1464  time: 0.2237  data_time: 0.0089  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:49:24 d2.utils.events]: \u001b[0m eta: 1:43:11  iter: 67899  total_loss: 1.115  loss_cls: 0.273  loss_box_reg: 0.3753  loss_mask: 0.2468  loss_rpn_cls: 0.06414  loss_rpn_loc: 0.1573  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:49:28 d2.utils.events]: \u001b[0m eta: 1:43:12  iter: 67919  total_loss: 1.081  loss_cls: 0.274  loss_box_reg: 0.3705  loss_mask: 0.2461  loss_rpn_cls: 0.07162  loss_rpn_loc: 0.1378  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:49:33 d2.utils.events]: \u001b[0m eta: 1:43:09  iter: 67939  total_loss: 1.119  loss_cls: 0.2782  loss_box_reg: 0.3772  loss_mask: 0.2451  loss_rpn_cls: 0.05715  loss_rpn_loc: 0.153  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:49:37 d2.utils.events]: \u001b[0m eta: 1:43:10  iter: 67959  total_loss: 1.161  loss_cls: 0.2842  loss_box_reg: 0.3688  loss_mask: 0.2632  loss_rpn_cls: 0.07447  loss_rpn_loc: 0.1595  time: 0.2237  data_time: 0.0158  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:49:42 d2.utils.events]: \u001b[0m eta: 1:42:59  iter: 67979  total_loss: 1.251  loss_cls: 0.3236  loss_box_reg: 0.3893  loss_mask: 0.2753  loss_rpn_cls: 0.07354  loss_rpn_loc: 0.1626  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:49:47 d2.utils.events]: \u001b[0m eta: 1:42:59  iter: 67999  total_loss: 1.119  loss_cls: 0.2697  loss_box_reg: 0.3716  loss_mask: 0.261  loss_rpn_cls: 0.07325  loss_rpn_loc: 0.1568  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:49:51 d2.utils.events]: \u001b[0m eta: 1:42:51  iter: 68019  total_loss: 1.203  loss_cls: 0.3123  loss_box_reg: 0.3958  loss_mask: 0.2562  loss_rpn_cls: 0.07643  loss_rpn_loc: 0.1459  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:49:55 d2.utils.events]: \u001b[0m eta: 1:42:46  iter: 68039  total_loss: 1.108  loss_cls: 0.2677  loss_box_reg: 0.3686  loss_mask: 0.263  loss_rpn_cls: 0.06004  loss_rpn_loc: 0.1515  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:50:00 d2.utils.events]: \u001b[0m eta: 1:42:50  iter: 68059  total_loss: 1.102  loss_cls: 0.2619  loss_box_reg: 0.3673  loss_mask: 0.2564  loss_rpn_cls: 0.07311  loss_rpn_loc: 0.1596  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:50:05 d2.utils.events]: \u001b[0m eta: 1:42:54  iter: 68079  total_loss: 1.214  loss_cls: 0.2776  loss_box_reg: 0.3641  loss_mask: 0.2722  loss_rpn_cls: 0.08054  loss_rpn_loc: 0.1618  time: 0.2237  data_time: 0.0127  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:50:09 d2.utils.events]: \u001b[0m eta: 1:42:46  iter: 68099  total_loss: 1.215  loss_cls: 0.2554  loss_box_reg: 0.3164  loss_mask: 0.2551  loss_rpn_cls: 0.06403  loss_rpn_loc: 0.194  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:50:14 d2.utils.events]: \u001b[0m eta: 1:42:58  iter: 68119  total_loss: 1.129  loss_cls: 0.2912  loss_box_reg: 0.3443  loss_mask: 0.2561  loss_rpn_cls: 0.0533  loss_rpn_loc: 0.1577  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:50:18 d2.utils.events]: \u001b[0m eta: 1:42:47  iter: 68139  total_loss: 1.224  loss_cls: 0.3242  loss_box_reg: 0.4011  loss_mask: 0.2757  loss_rpn_cls: 0.0895  loss_rpn_loc: 0.1541  time: 0.2237  data_time: 0.0217  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:50:23 d2.utils.events]: \u001b[0m eta: 1:42:42  iter: 68159  total_loss: 1.15  loss_cls: 0.2948  loss_box_reg: 0.3662  loss_mask: 0.2556  loss_rpn_cls: 0.0763  loss_rpn_loc: 0.1564  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:50:28 d2.utils.events]: \u001b[0m eta: 1:42:45  iter: 68179  total_loss: 1.123  loss_cls: 0.2701  loss_box_reg: 0.3851  loss_mask: 0.2703  loss_rpn_cls: 0.0727  loss_rpn_loc: 0.155  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:50:32 d2.utils.events]: \u001b[0m eta: 1:42:42  iter: 68199  total_loss: 1.028  loss_cls: 0.2392  loss_box_reg: 0.3127  loss_mask: 0.2508  loss_rpn_cls: 0.06096  loss_rpn_loc: 0.1387  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:50:37 d2.utils.events]: \u001b[0m eta: 1:42:39  iter: 68219  total_loss: 1.238  loss_cls: 0.3158  loss_box_reg: 0.3681  loss_mask: 0.2705  loss_rpn_cls: 0.08019  loss_rpn_loc: 0.1538  time: 0.2237  data_time: 0.0165  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:50:41 d2.utils.events]: \u001b[0m eta: 1:42:35  iter: 68239  total_loss: 1.251  loss_cls: 0.3241  loss_box_reg: 0.4045  loss_mask: 0.2646  loss_rpn_cls: 0.08746  loss_rpn_loc: 0.1618  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:50:46 d2.utils.events]: \u001b[0m eta: 1:42:30  iter: 68259  total_loss: 1.189  loss_cls: 0.3087  loss_box_reg: 0.401  loss_mask: 0.2722  loss_rpn_cls: 0.06754  loss_rpn_loc: 0.1655  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:50:50 d2.utils.events]: \u001b[0m eta: 1:42:27  iter: 68279  total_loss: 1.179  loss_cls: 0.2865  loss_box_reg: 0.3769  loss_mask: 0.2684  loss_rpn_cls: 0.06025  loss_rpn_loc: 0.1606  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:50:55 d2.utils.events]: \u001b[0m eta: 1:42:30  iter: 68299  total_loss: 1.027  loss_cls: 0.2482  loss_box_reg: 0.324  loss_mask: 0.2509  loss_rpn_cls: 0.07392  loss_rpn_loc: 0.1484  time: 0.2237  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:50:59 d2.utils.events]: \u001b[0m eta: 1:42:19  iter: 68319  total_loss: 1.191  loss_cls: 0.2738  loss_box_reg: 0.3796  loss_mask: 0.26  loss_rpn_cls: 0.08119  loss_rpn_loc: 0.1746  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:51:04 d2.utils.events]: \u001b[0m eta: 1:42:16  iter: 68339  total_loss: 1.208  loss_cls: 0.2838  loss_box_reg: 0.3715  loss_mask: 0.25  loss_rpn_cls: 0.07403  loss_rpn_loc: 0.1752  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:51:08 d2.utils.events]: \u001b[0m eta: 1:42:14  iter: 68359  total_loss: 1.07  loss_cls: 0.2335  loss_box_reg: 0.3567  loss_mask: 0.2583  loss_rpn_cls: 0.04557  loss_rpn_loc: 0.1619  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:51:12 d2.utils.events]: \u001b[0m eta: 1:42:10  iter: 68379  total_loss: 1.139  loss_cls: 0.2813  loss_box_reg: 0.38  loss_mask: 0.2538  loss_rpn_cls: 0.0552  loss_rpn_loc: 0.1409  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:51:17 d2.utils.events]: \u001b[0m eta: 1:42:08  iter: 68399  total_loss: 1.294  loss_cls: 0.3226  loss_box_reg: 0.3643  loss_mask: 0.2556  loss_rpn_cls: 0.08859  loss_rpn_loc: 0.1716  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:51:21 d2.utils.events]: \u001b[0m eta: 1:42:08  iter: 68419  total_loss: 1.146  loss_cls: 0.2722  loss_box_reg: 0.3763  loss_mask: 0.263  loss_rpn_cls: 0.06694  loss_rpn_loc: 0.1701  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:51:25 d2.utils.events]: \u001b[0m eta: 1:42:10  iter: 68439  total_loss: 1.266  loss_cls: 0.3095  loss_box_reg: 0.4268  loss_mask: 0.2626  loss_rpn_cls: 0.06163  loss_rpn_loc: 0.1715  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:51:30 d2.utils.events]: \u001b[0m eta: 1:42:09  iter: 68459  total_loss: 1.095  loss_cls: 0.2549  loss_box_reg: 0.3577  loss_mask: 0.2577  loss_rpn_cls: 0.0687  loss_rpn_loc: 0.1479  time: 0.2237  data_time: 0.0200  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:51:35 d2.utils.events]: \u001b[0m eta: 1:42:03  iter: 68479  total_loss: 1.107  loss_cls: 0.2495  loss_box_reg: 0.3834  loss_mask: 0.2552  loss_rpn_cls: 0.06573  loss_rpn_loc: 0.1485  time: 0.2237  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:51:39 d2.utils.events]: \u001b[0m eta: 1:41:58  iter: 68499  total_loss: 1.214  loss_cls: 0.2937  loss_box_reg: 0.4183  loss_mask: 0.2799  loss_rpn_cls: 0.05306  loss_rpn_loc: 0.16  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:51:44 d2.utils.events]: \u001b[0m eta: 1:42:05  iter: 68519  total_loss: 1.198  loss_cls: 0.278  loss_box_reg: 0.3621  loss_mask: 0.2613  loss_rpn_cls: 0.06339  loss_rpn_loc: 0.1526  time: 0.2237  data_time: 0.0193  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:51:49 d2.utils.events]: \u001b[0m eta: 1:41:57  iter: 68539  total_loss: 1.173  loss_cls: 0.3072  loss_box_reg: 0.3613  loss_mask: 0.263  loss_rpn_cls: 0.1065  loss_rpn_loc: 0.205  time: 0.2237  data_time: 0.0097  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:51:53 d2.utils.events]: \u001b[0m eta: 1:41:37  iter: 68559  total_loss: 1.164  loss_cls: 0.314  loss_box_reg: 0.4049  loss_mask: 0.243  loss_rpn_cls: 0.07176  loss_rpn_loc: 0.1641  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:51:57 d2.utils.events]: \u001b[0m eta: 1:41:37  iter: 68579  total_loss: 1.222  loss_cls: 0.3168  loss_box_reg: 0.3833  loss_mask: 0.2528  loss_rpn_cls: 0.09001  loss_rpn_loc: 0.1569  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:52:02 d2.utils.events]: \u001b[0m eta: 1:41:19  iter: 68599  total_loss: 1.03  loss_cls: 0.2401  loss_box_reg: 0.3287  loss_mask: 0.2317  loss_rpn_cls: 0.05754  loss_rpn_loc: 0.1455  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:52:06 d2.utils.events]: \u001b[0m eta: 1:41:12  iter: 68619  total_loss: 1.183  loss_cls: 0.2679  loss_box_reg: 0.3564  loss_mask: 0.2682  loss_rpn_cls: 0.05534  loss_rpn_loc: 0.1603  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:52:10 d2.utils.events]: \u001b[0m eta: 1:41:13  iter: 68639  total_loss: 1.132  loss_cls: 0.264  loss_box_reg: 0.3625  loss_mask: 0.2578  loss_rpn_cls: 0.09704  loss_rpn_loc: 0.165  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:52:15 d2.utils.events]: \u001b[0m eta: 1:41:19  iter: 68659  total_loss: 1.091  loss_cls: 0.2551  loss_box_reg: 0.3274  loss_mask: 0.244  loss_rpn_cls: 0.07374  loss_rpn_loc: 0.1631  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:52:20 d2.utils.events]: \u001b[0m eta: 1:41:04  iter: 68679  total_loss: 1.138  loss_cls: 0.2654  loss_box_reg: 0.3719  loss_mask: 0.2488  loss_rpn_cls: 0.07196  loss_rpn_loc: 0.15  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:52:24 d2.utils.events]: \u001b[0m eta: 1:41:01  iter: 68699  total_loss: 1.08  loss_cls: 0.2438  loss_box_reg: 0.3309  loss_mask: 0.2476  loss_rpn_cls: 0.09938  loss_rpn_loc: 0.165  time: 0.2237  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:52:29 d2.utils.events]: \u001b[0m eta: 1:40:58  iter: 68719  total_loss: 1.093  loss_cls: 0.2494  loss_box_reg: 0.3373  loss_mask: 0.2343  loss_rpn_cls: 0.04926  loss_rpn_loc: 0.1359  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:52:33 d2.utils.events]: \u001b[0m eta: 1:40:49  iter: 68739  total_loss: 1.191  loss_cls: 0.2812  loss_box_reg: 0.3852  loss_mask: 0.2616  loss_rpn_cls: 0.05602  loss_rpn_loc: 0.1455  time: 0.2237  data_time: 0.0210  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:52:38 d2.utils.events]: \u001b[0m eta: 1:40:57  iter: 68759  total_loss: 1.194  loss_cls: 0.2867  loss_box_reg: 0.3614  loss_mask: 0.2555  loss_rpn_cls: 0.07846  loss_rpn_loc: 0.1604  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:52:42 d2.utils.events]: \u001b[0m eta: 1:40:55  iter: 68779  total_loss: 1.221  loss_cls: 0.3039  loss_box_reg: 0.4004  loss_mask: 0.2779  loss_rpn_cls: 0.06738  loss_rpn_loc: 0.1583  time: 0.2237  data_time: 0.0157  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:52:47 d2.utils.events]: \u001b[0m eta: 1:40:56  iter: 68799  total_loss: 1.178  loss_cls: 0.2833  loss_box_reg: 0.3673  loss_mask: 0.2663  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.189  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:52:51 d2.utils.events]: \u001b[0m eta: 1:40:49  iter: 68819  total_loss: 1.166  loss_cls: 0.2726  loss_box_reg: 0.3821  loss_mask: 0.2568  loss_rpn_cls: 0.06997  loss_rpn_loc: 0.1675  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:52:56 d2.utils.events]: \u001b[0m eta: 1:40:42  iter: 68839  total_loss: 1.062  loss_cls: 0.2339  loss_box_reg: 0.3566  loss_mask: 0.2541  loss_rpn_cls: 0.06879  loss_rpn_loc: 0.1676  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:53:00 d2.utils.events]: \u001b[0m eta: 1:40:36  iter: 68859  total_loss: 1.067  loss_cls: 0.2594  loss_box_reg: 0.3684  loss_mask: 0.2572  loss_rpn_cls: 0.06485  loss_rpn_loc: 0.1717  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:53:05 d2.utils.events]: \u001b[0m eta: 1:40:17  iter: 68879  total_loss: 1.188  loss_cls: 0.3117  loss_box_reg: 0.3929  loss_mask: 0.2718  loss_rpn_cls: 0.07776  loss_rpn_loc: 0.1826  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:53:09 d2.utils.events]: \u001b[0m eta: 1:40:06  iter: 68899  total_loss: 1.161  loss_cls: 0.2672  loss_box_reg: 0.3987  loss_mask: 0.2607  loss_rpn_cls: 0.08931  loss_rpn_loc: 0.1591  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:53:13 d2.utils.events]: \u001b[0m eta: 1:40:01  iter: 68919  total_loss: 1.184  loss_cls: 0.2658  loss_box_reg: 0.3819  loss_mask: 0.2574  loss_rpn_cls: 0.0854  loss_rpn_loc: 0.179  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:53:18 d2.utils.events]: \u001b[0m eta: 1:39:51  iter: 68939  total_loss: 1.066  loss_cls: 0.2599  loss_box_reg: 0.3474  loss_mask: 0.2457  loss_rpn_cls: 0.0613  loss_rpn_loc: 0.1503  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:53:22 d2.utils.events]: \u001b[0m eta: 1:39:29  iter: 68959  total_loss: 1.093  loss_cls: 0.2704  loss_box_reg: 0.3731  loss_mask: 0.2336  loss_rpn_cls: 0.05221  loss_rpn_loc: 0.1378  time: 0.2237  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:53:26 d2.utils.events]: \u001b[0m eta: 1:39:23  iter: 68979  total_loss: 1.244  loss_cls: 0.2855  loss_box_reg: 0.397  loss_mask: 0.2711  loss_rpn_cls: 0.0842  loss_rpn_loc: 0.1601  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:53:31 d2.utils.events]: \u001b[0m eta: 1:39:18  iter: 68999  total_loss: 1.17  loss_cls: 0.2662  loss_box_reg: 0.3773  loss_mask: 0.2609  loss_rpn_cls: 0.07685  loss_rpn_loc: 0.1641  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:53:35 d2.utils.events]: \u001b[0m eta: 1:39:13  iter: 69019  total_loss: 1.106  loss_cls: 0.2644  loss_box_reg: 0.3153  loss_mask: 0.2558  loss_rpn_cls: 0.0705  loss_rpn_loc: 0.1766  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:53:40 d2.utils.events]: \u001b[0m eta: 1:39:08  iter: 69039  total_loss: 1.178  loss_cls: 0.2741  loss_box_reg: 0.37  loss_mask: 0.2464  loss_rpn_cls: 0.05522  loss_rpn_loc: 0.1568  time: 0.2237  data_time: 0.0092  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:53:44 d2.utils.events]: \u001b[0m eta: 1:39:00  iter: 69059  total_loss: 1.06  loss_cls: 0.2431  loss_box_reg: 0.3295  loss_mask: 0.238  loss_rpn_cls: 0.07379  loss_rpn_loc: 0.1402  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:53:49 d2.utils.events]: \u001b[0m eta: 1:38:58  iter: 69079  total_loss: 1.262  loss_cls: 0.3141  loss_box_reg: 0.3982  loss_mask: 0.278  loss_rpn_cls: 0.08511  loss_rpn_loc: 0.174  time: 0.2237  data_time: 0.0180  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:53:53 d2.utils.events]: \u001b[0m eta: 1:38:49  iter: 69099  total_loss: 1.197  loss_cls: 0.3079  loss_box_reg: 0.4  loss_mask: 0.2656  loss_rpn_cls: 0.06945  loss_rpn_loc: 0.18  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:53:57 d2.utils.events]: \u001b[0m eta: 1:38:29  iter: 69119  total_loss: 1.174  loss_cls: 0.2767  loss_box_reg: 0.377  loss_mask: 0.2565  loss_rpn_cls: 0.07128  loss_rpn_loc: 0.1822  time: 0.2237  data_time: 0.0161  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:54:02 d2.utils.events]: \u001b[0m eta: 1:38:29  iter: 69139  total_loss: 1.211  loss_cls: 0.3091  loss_box_reg: 0.3545  loss_mask: 0.2592  loss_rpn_cls: 0.07737  loss_rpn_loc: 0.1685  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:54:06 d2.utils.events]: \u001b[0m eta: 1:38:24  iter: 69159  total_loss: 1.195  loss_cls: 0.3176  loss_box_reg: 0.395  loss_mask: 0.2564  loss_rpn_cls: 0.06255  loss_rpn_loc: 0.1586  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:54:11 d2.utils.events]: \u001b[0m eta: 1:38:15  iter: 69179  total_loss: 1.15  loss_cls: 0.277  loss_box_reg: 0.3479  loss_mask: 0.2538  loss_rpn_cls: 0.0627  loss_rpn_loc: 0.1615  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:54:15 d2.utils.events]: \u001b[0m eta: 1:38:09  iter: 69199  total_loss: 1.154  loss_cls: 0.2848  loss_box_reg: 0.3649  loss_mask: 0.2693  loss_rpn_cls: 0.07324  loss_rpn_loc: 0.1613  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:54:20 d2.utils.events]: \u001b[0m eta: 1:38:02  iter: 69219  total_loss: 1.207  loss_cls: 0.292  loss_box_reg: 0.3532  loss_mask: 0.2642  loss_rpn_cls: 0.07157  loss_rpn_loc: 0.1755  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:54:24 d2.utils.events]: \u001b[0m eta: 1:37:54  iter: 69239  total_loss: 1.006  loss_cls: 0.2465  loss_box_reg: 0.3398  loss_mask: 0.2458  loss_rpn_cls: 0.04702  loss_rpn_loc: 0.1315  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:54:28 d2.utils.events]: \u001b[0m eta: 1:37:46  iter: 69259  total_loss: 1.218  loss_cls: 0.3158  loss_box_reg: 0.3897  loss_mask: 0.2708  loss_rpn_cls: 0.06594  loss_rpn_loc: 0.1616  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:54:33 d2.utils.events]: \u001b[0m eta: 1:37:34  iter: 69279  total_loss: 1.123  loss_cls: 0.2586  loss_box_reg: 0.3809  loss_mask: 0.2536  loss_rpn_cls: 0.06204  loss_rpn_loc: 0.1532  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:54:37 d2.utils.events]: \u001b[0m eta: 1:37:28  iter: 69299  total_loss: 1.144  loss_cls: 0.2885  loss_box_reg: 0.3715  loss_mask: 0.2447  loss_rpn_cls: 0.07177  loss_rpn_loc: 0.145  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:54:41 d2.utils.events]: \u001b[0m eta: 1:37:21  iter: 69319  total_loss: 1.15  loss_cls: 0.276  loss_box_reg: 0.3761  loss_mask: 0.2555  loss_rpn_cls: 0.06378  loss_rpn_loc: 0.1619  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:54:46 d2.utils.events]: \u001b[0m eta: 1:37:19  iter: 69339  total_loss: 1.252  loss_cls: 0.287  loss_box_reg: 0.3808  loss_mask: 0.2577  loss_rpn_cls: 0.05542  loss_rpn_loc: 0.1604  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:54:50 d2.utils.events]: \u001b[0m eta: 1:37:16  iter: 69359  total_loss: 1.201  loss_cls: 0.3053  loss_box_reg: 0.3682  loss_mask: 0.2607  loss_rpn_cls: 0.07047  loss_rpn_loc: 0.1531  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:54:54 d2.utils.events]: \u001b[0m eta: 1:37:15  iter: 69379  total_loss: 1.161  loss_cls: 0.3368  loss_box_reg: 0.3565  loss_mask: 0.2537  loss_rpn_cls: 0.07649  loss_rpn_loc: 0.1591  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:54:59 d2.utils.events]: \u001b[0m eta: 1:37:14  iter: 69399  total_loss: 1.257  loss_cls: 0.3133  loss_box_reg: 0.3722  loss_mask: 0.2712  loss_rpn_cls: 0.09444  loss_rpn_loc: 0.1846  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:55:03 d2.utils.events]: \u001b[0m eta: 1:37:11  iter: 69419  total_loss: 1.159  loss_cls: 0.2744  loss_box_reg: 0.3717  loss_mask: 0.2519  loss_rpn_cls: 0.07702  loss_rpn_loc: 0.1604  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:55:08 d2.utils.events]: \u001b[0m eta: 1:37:08  iter: 69439  total_loss: 1.177  loss_cls: 0.2694  loss_box_reg: 0.3818  loss_mask: 0.2738  loss_rpn_cls: 0.06077  loss_rpn_loc: 0.1633  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:55:13 d2.utils.events]: \u001b[0m eta: 1:36:57  iter: 69459  total_loss: 1.134  loss_cls: 0.2735  loss_box_reg: 0.3748  loss_mask: 0.2662  loss_rpn_cls: 0.07207  loss_rpn_loc: 0.1638  time: 0.2237  data_time: 0.0261  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:55:17 d2.utils.events]: \u001b[0m eta: 1:36:55  iter: 69479  total_loss: 1.161  loss_cls: 0.2696  loss_box_reg: 0.3815  loss_mask: 0.263  loss_rpn_cls: 0.06021  loss_rpn_loc: 0.173  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:55:22 d2.utils.events]: \u001b[0m eta: 1:36:49  iter: 69499  total_loss: 1.278  loss_cls: 0.3203  loss_box_reg: 0.4462  loss_mask: 0.2651  loss_rpn_cls: 0.07776  loss_rpn_loc: 0.1693  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:55:26 d2.utils.events]: \u001b[0m eta: 1:36:38  iter: 69519  total_loss: 1.264  loss_cls: 0.2827  loss_box_reg: 0.3922  loss_mask: 0.2632  loss_rpn_cls: 0.07222  loss_rpn_loc: 0.1647  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:55:30 d2.utils.events]: \u001b[0m eta: 1:36:34  iter: 69539  total_loss: 1.017  loss_cls: 0.2121  loss_box_reg: 0.347  loss_mask: 0.2334  loss_rpn_cls: 0.046  loss_rpn_loc: 0.153  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:55:35 d2.utils.events]: \u001b[0m eta: 1:36:30  iter: 69559  total_loss: 1.212  loss_cls: 0.2913  loss_box_reg: 0.3906  loss_mask: 0.2652  loss_rpn_cls: 0.06936  loss_rpn_loc: 0.1789  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:55:39 d2.utils.events]: \u001b[0m eta: 1:36:25  iter: 69579  total_loss: 1.169  loss_cls: 0.2853  loss_box_reg: 0.3601  loss_mask: 0.2591  loss_rpn_cls: 0.07337  loss_rpn_loc: 0.1499  time: 0.2237  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:55:44 d2.utils.events]: \u001b[0m eta: 1:36:22  iter: 69599  total_loss: 1.224  loss_cls: 0.2821  loss_box_reg: 0.3911  loss_mask: 0.2773  loss_rpn_cls: 0.0702  loss_rpn_loc: 0.1773  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:55:48 d2.utils.events]: \u001b[0m eta: 1:36:25  iter: 69619  total_loss: 1.329  loss_cls: 0.3494  loss_box_reg: 0.4099  loss_mask: 0.2701  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.1895  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:55:52 d2.utils.events]: \u001b[0m eta: 1:36:11  iter: 69639  total_loss: 1.138  loss_cls: 0.2856  loss_box_reg: 0.3812  loss_mask: 0.2552  loss_rpn_cls: 0.06198  loss_rpn_loc: 0.1477  time: 0.2237  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:55:57 d2.utils.events]: \u001b[0m eta: 1:36:07  iter: 69659  total_loss: 1.15  loss_cls: 0.2611  loss_box_reg: 0.3674  loss_mask: 0.2647  loss_rpn_cls: 0.08269  loss_rpn_loc: 0.1679  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:56:01 d2.utils.events]: \u001b[0m eta: 1:36:04  iter: 69679  total_loss: 1.171  loss_cls: 0.2677  loss_box_reg: 0.3689  loss_mask: 0.279  loss_rpn_cls: 0.06875  loss_rpn_loc: 0.1616  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:56:06 d2.utils.events]: \u001b[0m eta: 1:35:59  iter: 69699  total_loss: 1.267  loss_cls: 0.3232  loss_box_reg: 0.3928  loss_mask: 0.271  loss_rpn_cls: 0.116  loss_rpn_loc: 0.1834  time: 0.2237  data_time: 0.0099  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:56:11 d2.utils.events]: \u001b[0m eta: 1:35:55  iter: 69719  total_loss: 1.166  loss_cls: 0.292  loss_box_reg: 0.3776  loss_mask: 0.2569  loss_rpn_cls: 0.06725  loss_rpn_loc: 0.1557  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:56:15 d2.utils.events]: \u001b[0m eta: 1:35:50  iter: 69739  total_loss: 1.362  loss_cls: 0.3486  loss_box_reg: 0.4361  loss_mask: 0.28  loss_rpn_cls: 0.0851  loss_rpn_loc: 0.1792  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:56:20 d2.utils.events]: \u001b[0m eta: 1:35:48  iter: 69759  total_loss: 0.9757  loss_cls: 0.2326  loss_box_reg: 0.3076  loss_mask: 0.2365  loss_rpn_cls: 0.06415  loss_rpn_loc: 0.1569  time: 0.2237  data_time: 0.0185  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:56:25 d2.utils.events]: \u001b[0m eta: 1:35:44  iter: 69779  total_loss: 1.248  loss_cls: 0.2881  loss_box_reg: 0.3887  loss_mask: 0.2654  loss_rpn_cls: 0.07982  loss_rpn_loc: 0.1671  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:56:29 d2.utils.events]: \u001b[0m eta: 1:35:38  iter: 69799  total_loss: 1.297  loss_cls: 0.3023  loss_box_reg: 0.3831  loss_mask: 0.2841  loss_rpn_cls: 0.09721  loss_rpn_loc: 0.1791  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:56:34 d2.utils.events]: \u001b[0m eta: 1:35:32  iter: 69819  total_loss: 1.177  loss_cls: 0.2678  loss_box_reg: 0.4294  loss_mask: 0.2629  loss_rpn_cls: 0.06034  loss_rpn_loc: 0.1654  time: 0.2237  data_time: 0.0215  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:56:39 d2.utils.events]: \u001b[0m eta: 1:35:28  iter: 69839  total_loss: 1.153  loss_cls: 0.2625  loss_box_reg: 0.3548  loss_mask: 0.282  loss_rpn_cls: 0.09019  loss_rpn_loc: 0.1778  time: 0.2237  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:56:43 d2.utils.events]: \u001b[0m eta: 1:35:23  iter: 69859  total_loss: 1.037  loss_cls: 0.2482  loss_box_reg: 0.3336  loss_mask: 0.2387  loss_rpn_cls: 0.04787  loss_rpn_loc: 0.1478  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:56:48 d2.utils.events]: \u001b[0m eta: 1:35:22  iter: 69879  total_loss: 1.308  loss_cls: 0.333  loss_box_reg: 0.386  loss_mask: 0.2723  loss_rpn_cls: 0.0958  loss_rpn_loc: 0.1638  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:56:52 d2.utils.events]: \u001b[0m eta: 1:35:22  iter: 69899  total_loss: 1.099  loss_cls: 0.2634  loss_box_reg: 0.3615  loss_mask: 0.2455  loss_rpn_cls: 0.05671  loss_rpn_loc: 0.1493  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:56:56 d2.utils.events]: \u001b[0m eta: 1:35:16  iter: 69919  total_loss: 1.162  loss_cls: 0.2646  loss_box_reg: 0.3682  loss_mask: 0.2548  loss_rpn_cls: 0.06962  loss_rpn_loc: 0.1779  time: 0.2237  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:57:01 d2.utils.events]: \u001b[0m eta: 1:35:19  iter: 69939  total_loss: 1.175  loss_cls: 0.2726  loss_box_reg: 0.3697  loss_mask: 0.2581  loss_rpn_cls: 0.09036  loss_rpn_loc: 0.1599  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:57:06 d2.utils.events]: \u001b[0m eta: 1:35:23  iter: 69959  total_loss: 1.087  loss_cls: 0.219  loss_box_reg: 0.3346  loss_mask: 0.2607  loss_rpn_cls: 0.08448  loss_rpn_loc: 0.1545  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:57:10 d2.utils.events]: \u001b[0m eta: 1:35:20  iter: 69979  total_loss: 1.195  loss_cls: 0.2812  loss_box_reg: 0.4023  loss_mask: 0.2586  loss_rpn_cls: 0.05836  loss_rpn_loc: 0.1544  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:57:14 d2.utils.events]: \u001b[0m eta: 1:35:10  iter: 69999  total_loss: 1.06  loss_cls: 0.2414  loss_box_reg: 0.35  loss_mask: 0.2514  loss_rpn_cls: 0.05484  loss_rpn_loc: 0.1565  time: 0.2237  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:57:19 d2.utils.events]: \u001b[0m eta: 1:35:02  iter: 70019  total_loss: 1.179  loss_cls: 0.2903  loss_box_reg: 0.3842  loss_mask: 0.2528  loss_rpn_cls: 0.0719  loss_rpn_loc: 0.1698  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:57:23 d2.utils.events]: \u001b[0m eta: 1:35:02  iter: 70039  total_loss: 1.241  loss_cls: 0.2996  loss_box_reg: 0.4015  loss_mask: 0.2811  loss_rpn_cls: 0.06728  loss_rpn_loc: 0.1605  time: 0.2237  data_time: 0.0153  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:57:28 d2.utils.events]: \u001b[0m eta: 1:34:56  iter: 70059  total_loss: 1.047  loss_cls: 0.2418  loss_box_reg: 0.3433  loss_mask: 0.2437  loss_rpn_cls: 0.05664  loss_rpn_loc: 0.1508  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:57:32 d2.utils.events]: \u001b[0m eta: 1:34:49  iter: 70079  total_loss: 1.235  loss_cls: 0.3298  loss_box_reg: 0.3728  loss_mask: 0.2541  loss_rpn_cls: 0.07063  loss_rpn_loc: 0.1552  time: 0.2237  data_time: 0.0212  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:57:37 d2.utils.events]: \u001b[0m eta: 1:34:47  iter: 70099  total_loss: 1.166  loss_cls: 0.31  loss_box_reg: 0.3907  loss_mask: 0.2575  loss_rpn_cls: 0.08207  loss_rpn_loc: 0.1529  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:57:41 d2.utils.events]: \u001b[0m eta: 1:34:39  iter: 70119  total_loss: 1.239  loss_cls: 0.3001  loss_box_reg: 0.4033  loss_mask: 0.2422  loss_rpn_cls: 0.06426  loss_rpn_loc: 0.1665  time: 0.2237  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:57:45 d2.utils.events]: \u001b[0m eta: 1:34:39  iter: 70139  total_loss: 1.178  loss_cls: 0.2669  loss_box_reg: 0.3552  loss_mask: 0.2664  loss_rpn_cls: 0.08952  loss_rpn_loc: 0.1879  time: 0.2237  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:57:50 d2.utils.events]: \u001b[0m eta: 1:34:33  iter: 70159  total_loss: 1.153  loss_cls: 0.2808  loss_box_reg: 0.3484  loss_mask: 0.2478  loss_rpn_cls: 0.07527  loss_rpn_loc: 0.1639  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:57:54 d2.utils.events]: \u001b[0m eta: 1:34:26  iter: 70179  total_loss: 1.18  loss_cls: 0.2814  loss_box_reg: 0.3591  loss_mask: 0.2591  loss_rpn_cls: 0.07547  loss_rpn_loc: 0.1552  time: 0.2237  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:57:59 d2.utils.events]: \u001b[0m eta: 1:34:20  iter: 70199  total_loss: 1.155  loss_cls: 0.2788  loss_box_reg: 0.3582  loss_mask: 0.2612  loss_rpn_cls: 0.07836  loss_rpn_loc: 0.1475  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:58:03 d2.utils.events]: \u001b[0m eta: 1:34:13  iter: 70219  total_loss: 1.091  loss_cls: 0.2513  loss_box_reg: 0.3451  loss_mask: 0.2525  loss_rpn_cls: 0.06216  loss_rpn_loc: 0.1461  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:58:08 d2.utils.events]: \u001b[0m eta: 1:34:13  iter: 70239  total_loss: 1.171  loss_cls: 0.3139  loss_box_reg: 0.3719  loss_mask: 0.2575  loss_rpn_cls: 0.06374  loss_rpn_loc: 0.162  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:58:12 d2.utils.events]: \u001b[0m eta: 1:34:20  iter: 70259  total_loss: 1.161  loss_cls: 0.2868  loss_box_reg: 0.38  loss_mask: 0.2516  loss_rpn_cls: 0.07111  loss_rpn_loc: 0.1512  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:58:17 d2.utils.events]: \u001b[0m eta: 1:34:24  iter: 70279  total_loss: 1.112  loss_cls: 0.2724  loss_box_reg: 0.3574  loss_mask: 0.2624  loss_rpn_cls: 0.063  loss_rpn_loc: 0.1472  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:58:21 d2.utils.events]: \u001b[0m eta: 1:34:22  iter: 70299  total_loss: 1.155  loss_cls: 0.2792  loss_box_reg: 0.3659  loss_mask: 0.2632  loss_rpn_cls: 0.085  loss_rpn_loc: 0.1867  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:58:26 d2.utils.events]: \u001b[0m eta: 1:34:18  iter: 70319  total_loss: 1.134  loss_cls: 0.2899  loss_box_reg: 0.3868  loss_mask: 0.253  loss_rpn_cls: 0.06296  loss_rpn_loc: 0.1548  time: 0.2237  data_time: 0.0158  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:58:30 d2.utils.events]: \u001b[0m eta: 1:34:10  iter: 70339  total_loss: 1.142  loss_cls: 0.2529  loss_box_reg: 0.4012  loss_mask: 0.2671  loss_rpn_cls: 0.05662  loss_rpn_loc: 0.1552  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:58:34 d2.utils.events]: \u001b[0m eta: 1:34:06  iter: 70359  total_loss: 1.329  loss_cls: 0.3077  loss_box_reg: 0.4214  loss_mask: 0.277  loss_rpn_cls: 0.07318  loss_rpn_loc: 0.1897  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:58:39 d2.utils.events]: \u001b[0m eta: 1:33:57  iter: 70379  total_loss: 1.157  loss_cls: 0.2861  loss_box_reg: 0.3687  loss_mask: 0.2582  loss_rpn_cls: 0.07097  loss_rpn_loc: 0.157  time: 0.2237  data_time: 0.0181  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:58:43 d2.utils.events]: \u001b[0m eta: 1:33:45  iter: 70399  total_loss: 1.122  loss_cls: 0.2695  loss_box_reg: 0.3892  loss_mask: 0.2577  loss_rpn_cls: 0.05941  loss_rpn_loc: 0.1563  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:58:48 d2.utils.events]: \u001b[0m eta: 1:33:43  iter: 70419  total_loss: 1.157  loss_cls: 0.2988  loss_box_reg: 0.3771  loss_mask: 0.2605  loss_rpn_cls: 0.05775  loss_rpn_loc: 0.1636  time: 0.2237  data_time: 0.0095  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:58:52 d2.utils.events]: \u001b[0m eta: 1:33:41  iter: 70439  total_loss: 1.158  loss_cls: 0.3012  loss_box_reg: 0.3838  loss_mask: 0.2681  loss_rpn_cls: 0.07999  loss_rpn_loc: 0.1469  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:58:57 d2.utils.events]: \u001b[0m eta: 1:33:42  iter: 70459  total_loss: 1.167  loss_cls: 0.2917  loss_box_reg: 0.3848  loss_mask: 0.2647  loss_rpn_cls: 0.09057  loss_rpn_loc: 0.1757  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:59:01 d2.utils.events]: \u001b[0m eta: 1:33:37  iter: 70479  total_loss: 1.218  loss_cls: 0.3002  loss_box_reg: 0.4166  loss_mask: 0.2724  loss_rpn_cls: 0.06974  loss_rpn_loc: 0.1578  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:59:06 d2.utils.events]: \u001b[0m eta: 1:33:38  iter: 70499  total_loss: 1.251  loss_cls: 0.3106  loss_box_reg: 0.4039  loss_mask: 0.2635  loss_rpn_cls: 0.08515  loss_rpn_loc: 0.1755  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:59:10 d2.utils.events]: \u001b[0m eta: 1:33:38  iter: 70519  total_loss: 1.136  loss_cls: 0.2457  loss_box_reg: 0.359  loss_mask: 0.2537  loss_rpn_cls: 0.07356  loss_rpn_loc: 0.1694  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:59:14 d2.utils.events]: \u001b[0m eta: 1:33:34  iter: 70539  total_loss: 1.16  loss_cls: 0.2719  loss_box_reg: 0.3677  loss_mask: 0.2727  loss_rpn_cls: 0.06999  loss_rpn_loc: 0.1703  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:59:19 d2.utils.events]: \u001b[0m eta: 1:33:37  iter: 70559  total_loss: 1.093  loss_cls: 0.2556  loss_box_reg: 0.3677  loss_mask: 0.2456  loss_rpn_cls: 0.05498  loss_rpn_loc: 0.1693  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:59:23 d2.utils.events]: \u001b[0m eta: 1:33:30  iter: 70579  total_loss: 1.166  loss_cls: 0.2661  loss_box_reg: 0.3625  loss_mask: 0.2675  loss_rpn_cls: 0.09199  loss_rpn_loc: 0.1715  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 01:59:28 d2.utils.events]: \u001b[0m eta: 1:33:21  iter: 70599  total_loss: 1.173  loss_cls: 0.2979  loss_box_reg: 0.392  loss_mask: 0.2626  loss_rpn_cls: 0.06949  loss_rpn_loc: 0.1604  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:59:32 d2.utils.events]: \u001b[0m eta: 1:33:18  iter: 70619  total_loss: 1.201  loss_cls: 0.3053  loss_box_reg: 0.3869  loss_mask: 0.2472  loss_rpn_cls: 0.06994  loss_rpn_loc: 0.1626  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:59:36 d2.utils.events]: \u001b[0m eta: 1:33:19  iter: 70639  total_loss: 1.065  loss_cls: 0.2509  loss_box_reg: 0.3396  loss_mask: 0.258  loss_rpn_cls: 0.05521  loss_rpn_loc: 0.1601  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:59:41 d2.utils.events]: \u001b[0m eta: 1:33:15  iter: 70659  total_loss: 1.206  loss_cls: 0.3039  loss_box_reg: 0.4033  loss_mask: 0.2482  loss_rpn_cls: 0.07256  loss_rpn_loc: 0.1503  time: 0.2237  data_time: 0.0168  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:59:46 d2.utils.events]: \u001b[0m eta: 1:33:11  iter: 70679  total_loss: 1.081  loss_cls: 0.2748  loss_box_reg: 0.3718  loss_mask: 0.2553  loss_rpn_cls: 0.0698  loss_rpn_loc: 0.1479  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:59:50 d2.utils.events]: \u001b[0m eta: 1:32:58  iter: 70699  total_loss: 1.214  loss_cls: 0.3206  loss_box_reg: 0.3896  loss_mask: 0.2719  loss_rpn_cls: 0.0654  loss_rpn_loc: 0.1679  time: 0.2237  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:59:55 d2.utils.events]: \u001b[0m eta: 1:33:01  iter: 70719  total_loss: 1.174  loss_cls: 0.277  loss_box_reg: 0.3729  loss_mask: 0.2793  loss_rpn_cls: 0.0883  loss_rpn_loc: 0.1781  time: 0.2237  data_time: 0.0259  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 01:59:59 d2.utils.events]: \u001b[0m eta: 1:32:58  iter: 70739  total_loss: 1.265  loss_cls: 0.346  loss_box_reg: 0.4215  loss_mask: 0.2801  loss_rpn_cls: 0.07728  loss_rpn_loc: 0.1717  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:00:04 d2.utils.events]: \u001b[0m eta: 1:32:52  iter: 70759  total_loss: 1.142  loss_cls: 0.2618  loss_box_reg: 0.3313  loss_mask: 0.2706  loss_rpn_cls: 0.08846  loss_rpn_loc: 0.1632  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:00:08 d2.utils.events]: \u001b[0m eta: 1:32:40  iter: 70779  total_loss: 1.167  loss_cls: 0.3104  loss_box_reg: 0.3955  loss_mask: 0.2672  loss_rpn_cls: 0.05324  loss_rpn_loc: 0.1449  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:00:13 d2.utils.events]: \u001b[0m eta: 1:32:37  iter: 70799  total_loss: 1.155  loss_cls: 0.3148  loss_box_reg: 0.3928  loss_mask: 0.2638  loss_rpn_cls: 0.0736  loss_rpn_loc: 0.1655  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:00:17 d2.utils.events]: \u001b[0m eta: 1:32:40  iter: 70819  total_loss: 1.097  loss_cls: 0.2595  loss_box_reg: 0.3516  loss_mask: 0.2624  loss_rpn_cls: 0.06978  loss_rpn_loc: 0.1766  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:00:22 d2.utils.events]: \u001b[0m eta: 1:32:36  iter: 70839  total_loss: 1.13  loss_cls: 0.2856  loss_box_reg: 0.3818  loss_mask: 0.2418  loss_rpn_cls: 0.07885  loss_rpn_loc: 0.1551  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:00:26 d2.utils.events]: \u001b[0m eta: 1:32:32  iter: 70859  total_loss: 1.151  loss_cls: 0.2736  loss_box_reg: 0.3958  loss_mask: 0.2732  loss_rpn_cls: 0.05798  loss_rpn_loc: 0.1601  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:00:31 d2.utils.events]: \u001b[0m eta: 1:32:27  iter: 70879  total_loss: 1.146  loss_cls: 0.2521  loss_box_reg: 0.3611  loss_mask: 0.2488  loss_rpn_cls: 0.06505  loss_rpn_loc: 0.156  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:00:35 d2.utils.events]: \u001b[0m eta: 1:32:23  iter: 70899  total_loss: 1.093  loss_cls: 0.2613  loss_box_reg: 0.388  loss_mask: 0.2487  loss_rpn_cls: 0.0705  loss_rpn_loc: 0.1502  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:00:39 d2.utils.events]: \u001b[0m eta: 1:32:18  iter: 70919  total_loss: 1.223  loss_cls: 0.3409  loss_box_reg: 0.3779  loss_mask: 0.2715  loss_rpn_cls: 0.07059  loss_rpn_loc: 0.1727  time: 0.2237  data_time: 0.0092  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:00:44 d2.utils.events]: \u001b[0m eta: 1:32:04  iter: 70939  total_loss: 1.12  loss_cls: 0.2622  loss_box_reg: 0.3464  loss_mask: 0.2444  loss_rpn_cls: 0.06683  loss_rpn_loc: 0.163  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:00:48 d2.utils.events]: \u001b[0m eta: 1:32:01  iter: 70959  total_loss: 1.167  loss_cls: 0.305  loss_box_reg: 0.3659  loss_mask: 0.2606  loss_rpn_cls: 0.06225  loss_rpn_loc: 0.1686  time: 0.2237  data_time: 0.0186  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:00:53 d2.utils.events]: \u001b[0m eta: 1:31:58  iter: 70979  total_loss: 1.122  loss_cls: 0.2434  loss_box_reg: 0.3591  loss_mask: 0.2628  loss_rpn_cls: 0.06561  loss_rpn_loc: 0.167  time: 0.2237  data_time: 0.0089  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:00:57 d2.utils.events]: \u001b[0m eta: 1:31:59  iter: 70999  total_loss: 1.125  loss_cls: 0.273  loss_box_reg: 0.3438  loss_mask: 0.2528  loss_rpn_cls: 0.09214  loss_rpn_loc: 0.1629  time: 0.2237  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:01:02 d2.utils.events]: \u001b[0m eta: 1:31:57  iter: 71019  total_loss: 1.102  loss_cls: 0.2837  loss_box_reg: 0.3496  loss_mask: 0.2527  loss_rpn_cls: 0.073  loss_rpn_loc: 0.1556  time: 0.2237  data_time: 0.0188  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:01:06 d2.utils.events]: \u001b[0m eta: 1:31:52  iter: 71039  total_loss: 1.157  loss_cls: 0.3025  loss_box_reg: 0.4142  loss_mask: 0.2635  loss_rpn_cls: 0.05576  loss_rpn_loc: 0.152  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:01:11 d2.utils.events]: \u001b[0m eta: 1:31:47  iter: 71059  total_loss: 1.084  loss_cls: 0.2786  loss_box_reg: 0.381  loss_mask: 0.2488  loss_rpn_cls: 0.0754  loss_rpn_loc: 0.1648  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:01:15 d2.utils.events]: \u001b[0m eta: 1:31:41  iter: 71079  total_loss: 1.202  loss_cls: 0.3355  loss_box_reg: 0.3802  loss_mask: 0.2497  loss_rpn_cls: 0.07112  loss_rpn_loc: 0.1459  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:01:19 d2.utils.events]: \u001b[0m eta: 1:31:39  iter: 71099  total_loss: 1.053  loss_cls: 0.2741  loss_box_reg: 0.3405  loss_mask: 0.2486  loss_rpn_cls: 0.06366  loss_rpn_loc: 0.1402  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:01:24 d2.utils.events]: \u001b[0m eta: 1:31:35  iter: 71119  total_loss: 1.13  loss_cls: 0.2442  loss_box_reg: 0.3736  loss_mask: 0.2464  loss_rpn_cls: 0.05885  loss_rpn_loc: 0.1685  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:01:28 d2.utils.events]: \u001b[0m eta: 1:31:31  iter: 71139  total_loss: 1.129  loss_cls: 0.2647  loss_box_reg: 0.3512  loss_mask: 0.2539  loss_rpn_cls: 0.06685  loss_rpn_loc: 0.1527  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:01:33 d2.utils.events]: \u001b[0m eta: 1:31:28  iter: 71159  total_loss: 1.198  loss_cls: 0.3119  loss_box_reg: 0.4023  loss_mask: 0.2524  loss_rpn_cls: 0.07484  loss_rpn_loc: 0.1678  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:01:37 d2.utils.events]: \u001b[0m eta: 1:31:22  iter: 71179  total_loss: 1.134  loss_cls: 0.2732  loss_box_reg: 0.3892  loss_mask: 0.2519  loss_rpn_cls: 0.07723  loss_rpn_loc: 0.1533  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:01:42 d2.utils.events]: \u001b[0m eta: 1:31:18  iter: 71199  total_loss: 1.17  loss_cls: 0.2573  loss_box_reg: 0.3497  loss_mask: 0.2579  loss_rpn_cls: 0.09945  loss_rpn_loc: 0.1702  time: 0.2237  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:01:46 d2.utils.events]: \u001b[0m eta: 1:31:14  iter: 71219  total_loss: 1.129  loss_cls: 0.2962  loss_box_reg: 0.3705  loss_mask: 0.2511  loss_rpn_cls: 0.05156  loss_rpn_loc: 0.1633  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:01:51 d2.utils.events]: \u001b[0m eta: 1:31:11  iter: 71239  total_loss: 1.189  loss_cls: 0.2923  loss_box_reg: 0.3844  loss_mask: 0.2686  loss_rpn_cls: 0.08488  loss_rpn_loc: 0.1571  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:01:55 d2.utils.events]: \u001b[0m eta: 1:31:04  iter: 71259  total_loss: 1.157  loss_cls: 0.2908  loss_box_reg: 0.3665  loss_mask: 0.2424  loss_rpn_cls: 0.06253  loss_rpn_loc: 0.1673  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:02:00 d2.utils.events]: \u001b[0m eta: 1:31:00  iter: 71279  total_loss: 1.106  loss_cls: 0.2742  loss_box_reg: 0.3627  loss_mask: 0.2541  loss_rpn_cls: 0.0955  loss_rpn_loc: 0.1658  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:02:04 d2.utils.events]: \u001b[0m eta: 1:30:56  iter: 71299  total_loss: 1.101  loss_cls: 0.2675  loss_box_reg: 0.3634  loss_mask: 0.2633  loss_rpn_cls: 0.06538  loss_rpn_loc: 0.1698  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:02:08 d2.utils.events]: \u001b[0m eta: 1:30:52  iter: 71319  total_loss: 1.119  loss_cls: 0.2833  loss_box_reg: 0.3569  loss_mask: 0.2663  loss_rpn_cls: 0.06136  loss_rpn_loc: 0.1478  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:02:13 d2.utils.events]: \u001b[0m eta: 1:30:51  iter: 71339  total_loss: 1.18  loss_cls: 0.2936  loss_box_reg: 0.3729  loss_mask: 0.2468  loss_rpn_cls: 0.087  loss_rpn_loc: 0.1619  time: 0.2237  data_time: 0.0157  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:02:17 d2.utils.events]: \u001b[0m eta: 1:30:45  iter: 71359  total_loss: 1.176  loss_cls: 0.2964  loss_box_reg: 0.403  loss_mask: 0.2575  loss_rpn_cls: 0.0867  loss_rpn_loc: 0.1569  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:02:22 d2.utils.events]: \u001b[0m eta: 1:30:42  iter: 71379  total_loss: 1.135  loss_cls: 0.2708  loss_box_reg: 0.3753  loss_mask: 0.246  loss_rpn_cls: 0.07067  loss_rpn_loc: 0.1623  time: 0.2237  data_time: 0.0229  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:02:26 d2.utils.events]: \u001b[0m eta: 1:30:37  iter: 71399  total_loss: 1.137  loss_cls: 0.2609  loss_box_reg: 0.3765  loss_mask: 0.2419  loss_rpn_cls: 0.05849  loss_rpn_loc: 0.163  time: 0.2237  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:02:31 d2.utils.events]: \u001b[0m eta: 1:30:31  iter: 71419  total_loss: 1.212  loss_cls: 0.3108  loss_box_reg: 0.4238  loss_mask: 0.2574  loss_rpn_cls: 0.07899  loss_rpn_loc: 0.1643  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:02:35 d2.utils.events]: \u001b[0m eta: 1:30:22  iter: 71439  total_loss: 1.167  loss_cls: 0.3185  loss_box_reg: 0.3961  loss_mask: 0.2518  loss_rpn_cls: 0.07655  loss_rpn_loc: 0.1569  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:02:40 d2.utils.events]: \u001b[0m eta: 1:30:18  iter: 71459  total_loss: 1.178  loss_cls: 0.2586  loss_box_reg: 0.3687  loss_mask: 0.2825  loss_rpn_cls: 0.07843  loss_rpn_loc: 0.1856  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:02:44 d2.utils.events]: \u001b[0m eta: 1:30:10  iter: 71479  total_loss: 1.244  loss_cls: 0.3068  loss_box_reg: 0.393  loss_mask: 0.269  loss_rpn_cls: 0.06898  loss_rpn_loc: 0.1624  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:02:49 d2.utils.events]: \u001b[0m eta: 1:30:06  iter: 71499  total_loss: 1.198  loss_cls: 0.3148  loss_box_reg: 0.3719  loss_mask: 0.2612  loss_rpn_cls: 0.08291  loss_rpn_loc: 0.1644  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:02:54 d2.utils.events]: \u001b[0m eta: 1:30:02  iter: 71519  total_loss: 1.258  loss_cls: 0.3318  loss_box_reg: 0.4578  loss_mask: 0.2776  loss_rpn_cls: 0.08016  loss_rpn_loc: 0.1729  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:02:58 d2.utils.events]: \u001b[0m eta: 1:30:01  iter: 71539  total_loss: 1.168  loss_cls: 0.2773  loss_box_reg: 0.3821  loss_mask: 0.2639  loss_rpn_cls: 0.07757  loss_rpn_loc: 0.1774  time: 0.2237  data_time: 0.0090  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:03:03 d2.utils.events]: \u001b[0m eta: 1:29:58  iter: 71559  total_loss: 1.204  loss_cls: 0.2898  loss_box_reg: 0.3862  loss_mask: 0.2738  loss_rpn_cls: 0.06326  loss_rpn_loc: 0.1703  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:03:07 d2.utils.events]: \u001b[0m eta: 1:29:56  iter: 71579  total_loss: 1.225  loss_cls: 0.3175  loss_box_reg: 0.3739  loss_mask: 0.2744  loss_rpn_cls: 0.07567  loss_rpn_loc: 0.1476  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:03:11 d2.utils.events]: \u001b[0m eta: 1:29:54  iter: 71599  total_loss: 1.016  loss_cls: 0.2276  loss_box_reg: 0.3319  loss_mask: 0.2458  loss_rpn_cls: 0.05019  loss_rpn_loc: 0.1455  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:03:16 d2.utils.events]: \u001b[0m eta: 1:29:49  iter: 71619  total_loss: 1.191  loss_cls: 0.2749  loss_box_reg: 0.3615  loss_mask: 0.2631  loss_rpn_cls: 0.07828  loss_rpn_loc: 0.1728  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:03:21 d2.utils.events]: \u001b[0m eta: 1:29:48  iter: 71639  total_loss: 1.077  loss_cls: 0.246  loss_box_reg: 0.3187  loss_mask: 0.2561  loss_rpn_cls: 0.07077  loss_rpn_loc: 0.1598  time: 0.2237  data_time: 0.0158  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:03:25 d2.utils.events]: \u001b[0m eta: 1:29:41  iter: 71659  total_loss: 1.194  loss_cls: 0.3058  loss_box_reg: 0.3849  loss_mask: 0.2712  loss_rpn_cls: 0.09251  loss_rpn_loc: 0.1617  time: 0.2237  data_time: 0.0163  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:03:30 d2.utils.events]: \u001b[0m eta: 1:29:37  iter: 71679  total_loss: 1.109  loss_cls: 0.2587  loss_box_reg: 0.3732  loss_mask: 0.2587  loss_rpn_cls: 0.06007  loss_rpn_loc: 0.1499  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:03:34 d2.utils.events]: \u001b[0m eta: 1:29:33  iter: 71699  total_loss: 1.209  loss_cls: 0.3087  loss_box_reg: 0.4126  loss_mask: 0.2752  loss_rpn_cls: 0.06827  loss_rpn_loc: 0.1651  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:03:38 d2.utils.events]: \u001b[0m eta: 1:29:20  iter: 71719  total_loss: 1.165  loss_cls: 0.275  loss_box_reg: 0.3898  loss_mask: 0.2676  loss_rpn_cls: 0.07468  loss_rpn_loc: 0.1653  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:03:43 d2.utils.events]: \u001b[0m eta: 1:29:17  iter: 71739  total_loss: 1.153  loss_cls: 0.2686  loss_box_reg: 0.3892  loss_mask: 0.2579  loss_rpn_cls: 0.05465  loss_rpn_loc: 0.1436  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:03:47 d2.utils.events]: \u001b[0m eta: 1:29:13  iter: 71759  total_loss: 1.164  loss_cls: 0.2916  loss_box_reg: 0.3869  loss_mask: 0.2653  loss_rpn_cls: 0.06959  loss_rpn_loc: 0.1669  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:03:51 d2.utils.events]: \u001b[0m eta: 1:29:14  iter: 71779  total_loss: 1.208  loss_cls: 0.3034  loss_box_reg: 0.3885  loss_mask: 0.2546  loss_rpn_cls: 0.06912  loss_rpn_loc: 0.1697  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:03:56 d2.utils.events]: \u001b[0m eta: 1:29:11  iter: 71799  total_loss: 1.194  loss_cls: 0.2801  loss_box_reg: 0.3737  loss_mask: 0.2731  loss_rpn_cls: 0.06619  loss_rpn_loc: 0.1647  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:04:00 d2.utils.events]: \u001b[0m eta: 1:29:04  iter: 71819  total_loss: 1.19  loss_cls: 0.3057  loss_box_reg: 0.359  loss_mask: 0.2762  loss_rpn_cls: 0.07757  loss_rpn_loc: 0.1688  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:04:05 d2.utils.events]: \u001b[0m eta: 1:28:57  iter: 71839  total_loss: 1.141  loss_cls: 0.2568  loss_box_reg: 0.3879  loss_mask: 0.2628  loss_rpn_cls: 0.09503  loss_rpn_loc: 0.1879  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:04:10 d2.utils.events]: \u001b[0m eta: 1:28:56  iter: 71859  total_loss: 1.226  loss_cls: 0.3282  loss_box_reg: 0.3888  loss_mask: 0.2773  loss_rpn_cls: 0.0781  loss_rpn_loc: 0.1715  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:04:14 d2.utils.events]: \u001b[0m eta: 1:28:53  iter: 71879  total_loss: 1.021  loss_cls: 0.2376  loss_box_reg: 0.3121  loss_mask: 0.2487  loss_rpn_cls: 0.06938  loss_rpn_loc: 0.1691  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:04:19 d2.utils.events]: \u001b[0m eta: 1:28:51  iter: 71899  total_loss: 1.156  loss_cls: 0.2439  loss_box_reg: 0.3509  loss_mask: 0.2512  loss_rpn_cls: 0.08167  loss_rpn_loc: 0.1669  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:04:23 d2.utils.events]: \u001b[0m eta: 1:28:49  iter: 71919  total_loss: 1.072  loss_cls: 0.256  loss_box_reg: 0.3477  loss_mask: 0.2467  loss_rpn_cls: 0.0602  loss_rpn_loc: 0.1596  time: 0.2237  data_time: 0.0230  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:04:28 d2.utils.events]: \u001b[0m eta: 1:28:51  iter: 71939  total_loss: 1.147  loss_cls: 0.2893  loss_box_reg: 0.3524  loss_mask: 0.2529  loss_rpn_cls: 0.07499  loss_rpn_loc: 0.1553  time: 0.2237  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:04:32 d2.utils.events]: \u001b[0m eta: 1:28:46  iter: 71959  total_loss: 0.9609  loss_cls: 0.2384  loss_box_reg: 0.3038  loss_mask: 0.2367  loss_rpn_cls: 0.06198  loss_rpn_loc: 0.1631  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:04:37 d2.utils.events]: \u001b[0m eta: 1:28:35  iter: 71979  total_loss: 1.103  loss_cls: 0.2627  loss_box_reg: 0.3644  loss_mask: 0.2598  loss_rpn_cls: 0.0483  loss_rpn_loc: 0.1309  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:04:42 d2.utils.events]: \u001b[0m eta: 1:28:31  iter: 71999  total_loss: 1.154  loss_cls: 0.2985  loss_box_reg: 0.393  loss_mask: 0.2712  loss_rpn_cls: 0.07115  loss_rpn_loc: 0.1709  time: 0.2237  data_time: 0.0237  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:04:46 d2.utils.events]: \u001b[0m eta: 1:28:27  iter: 72019  total_loss: 1.211  loss_cls: 0.2883  loss_box_reg: 0.4105  loss_mask: 0.2739  loss_rpn_cls: 0.07296  loss_rpn_loc: 0.1754  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:04:51 d2.utils.events]: \u001b[0m eta: 1:28:26  iter: 72039  total_loss: 1.226  loss_cls: 0.326  loss_box_reg: 0.3911  loss_mask: 0.2612  loss_rpn_cls: 0.07049  loss_rpn_loc: 0.1754  time: 0.2237  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:04:55 d2.utils.events]: \u001b[0m eta: 1:28:24  iter: 72059  total_loss: 1.054  loss_cls: 0.2544  loss_box_reg: 0.3185  loss_mask: 0.2384  loss_rpn_cls: 0.08601  loss_rpn_loc: 0.1647  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:05:00 d2.utils.events]: \u001b[0m eta: 1:28:24  iter: 72079  total_loss: 1.146  loss_cls: 0.2864  loss_box_reg: 0.3388  loss_mask: 0.2665  loss_rpn_cls: 0.08127  loss_rpn_loc: 0.1569  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:05:04 d2.utils.events]: \u001b[0m eta: 1:28:16  iter: 72099  total_loss: 1.241  loss_cls: 0.3093  loss_box_reg: 0.3878  loss_mask: 0.2697  loss_rpn_cls: 0.08334  loss_rpn_loc: 0.1628  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:05:08 d2.utils.events]: \u001b[0m eta: 1:28:12  iter: 72119  total_loss: 1.194  loss_cls: 0.3026  loss_box_reg: 0.373  loss_mask: 0.2654  loss_rpn_cls: 0.07078  loss_rpn_loc: 0.1481  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:05:13 d2.utils.events]: \u001b[0m eta: 1:28:07  iter: 72139  total_loss: 1.161  loss_cls: 0.2854  loss_box_reg: 0.3841  loss_mask: 0.2688  loss_rpn_cls: 0.07272  loss_rpn_loc: 0.1543  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:05:17 d2.utils.events]: \u001b[0m eta: 1:28:02  iter: 72159  total_loss: 1.122  loss_cls: 0.2553  loss_box_reg: 0.3451  loss_mask: 0.2491  loss_rpn_cls: 0.07807  loss_rpn_loc: 0.1626  time: 0.2237  data_time: 0.0123  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:05:22 d2.utils.events]: \u001b[0m eta: 1:27:58  iter: 72179  total_loss: 1.059  loss_cls: 0.2574  loss_box_reg: 0.3486  loss_mask: 0.2442  loss_rpn_cls: 0.07348  loss_rpn_loc: 0.1512  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:05:26 d2.utils.events]: \u001b[0m eta: 1:28:03  iter: 72199  total_loss: 1.076  loss_cls: 0.234  loss_box_reg: 0.3555  loss_mask: 0.2363  loss_rpn_cls: 0.05928  loss_rpn_loc: 0.1594  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:05:31 d2.utils.events]: \u001b[0m eta: 1:28:01  iter: 72219  total_loss: 1.069  loss_cls: 0.278  loss_box_reg: 0.3579  loss_mask: 0.2556  loss_rpn_cls: 0.05959  loss_rpn_loc: 0.154  time: 0.2237  data_time: 0.0169  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:05:36 d2.utils.events]: \u001b[0m eta: 1:27:56  iter: 72239  total_loss: 1.015  loss_cls: 0.2151  loss_box_reg: 0.3099  loss_mask: 0.227  loss_rpn_cls: 0.07376  loss_rpn_loc: 0.1574  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:05:42 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.52 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 02:05:42 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 02:05:42 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 02:05:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 02:05:43 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 02:05:43 d2.data.common]: \u001b[0mSerialized dataset takes 84.20 MiB\n",
      "\u001b[32m[12/30 02:05:46 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.58 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 02:05:46 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 02:05:46 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 02:05:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/30 02:05:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0007 s/iter. Inference: 0.0609 s/iter. Eval: 0.1433 s/iter. Total: 0.2050 s/iter. ETA=0:01:54\n",
      "\u001b[32m[12/30 02:05:54 d2.evaluation.evaluator]: \u001b[0mInference done 39/570. Dataloading: 0.0009 s/iter. Inference: 0.0572 s/iter. Eval: 0.1273 s/iter. Total: 0.1854 s/iter. ETA=0:01:38\n",
      "\u001b[32m[12/30 02:05:59 d2.evaluation.evaluator]: \u001b[0mInference done 66/570. Dataloading: 0.0009 s/iter. Inference: 0.0570 s/iter. Eval: 0.1280 s/iter. Total: 0.1860 s/iter. ETA=0:01:33\n",
      "\u001b[32m[12/30 02:06:04 d2.evaluation.evaluator]: \u001b[0mInference done 91/570. Dataloading: 0.0009 s/iter. Inference: 0.0575 s/iter. Eval: 0.1328 s/iter. Total: 0.1913 s/iter. ETA=0:01:31\n",
      "\u001b[32m[12/30 02:06:09 d2.evaluation.evaluator]: \u001b[0mInference done 118/570. Dataloading: 0.0009 s/iter. Inference: 0.0560 s/iter. Eval: 0.1331 s/iter. Total: 0.1900 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/30 02:06:14 d2.evaluation.evaluator]: \u001b[0mInference done 142/570. Dataloading: 0.0009 s/iter. Inference: 0.0556 s/iter. Eval: 0.1369 s/iter. Total: 0.1934 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 02:06:19 d2.evaluation.evaluator]: \u001b[0mInference done 161/570. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.1451 s/iter. Total: 0.2020 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 02:06:24 d2.evaluation.evaluator]: \u001b[0mInference done 174/570. Dataloading: 0.0009 s/iter. Inference: 0.0564 s/iter. Eval: 0.1588 s/iter. Total: 0.2161 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/30 02:06:30 d2.evaluation.evaluator]: \u001b[0mInference done 191/570. Dataloading: 0.0009 s/iter. Inference: 0.0568 s/iter. Eval: 0.1675 s/iter. Total: 0.2253 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/30 02:06:35 d2.evaluation.evaluator]: \u001b[0mInference done 207/570. Dataloading: 0.0009 s/iter. Inference: 0.0573 s/iter. Eval: 0.1749 s/iter. Total: 0.2330 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/30 02:06:40 d2.evaluation.evaluator]: \u001b[0mInference done 224/570. Dataloading: 0.0009 s/iter. Inference: 0.0573 s/iter. Eval: 0.1797 s/iter. Total: 0.2380 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 02:06:45 d2.evaluation.evaluator]: \u001b[0mInference done 233/570. Dataloading: 0.0009 s/iter. Inference: 0.0574 s/iter. Eval: 0.1922 s/iter. Total: 0.2505 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/30 02:06:50 d2.evaluation.evaluator]: \u001b[0mInference done 248/570. Dataloading: 0.0009 s/iter. Inference: 0.0575 s/iter. Eval: 0.1978 s/iter. Total: 0.2562 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 02:06:55 d2.evaluation.evaluator]: \u001b[0mInference done 261/570. Dataloading: 0.0009 s/iter. Inference: 0.0575 s/iter. Eval: 0.2044 s/iter. Total: 0.2629 s/iter. ETA=0:01:21\n",
      "\u001b[32m[12/30 02:07:00 d2.evaluation.evaluator]: \u001b[0mInference done 278/570. Dataloading: 0.0009 s/iter. Inference: 0.0575 s/iter. Eval: 0.2075 s/iter. Total: 0.2660 s/iter. ETA=0:01:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:07:06 d2.evaluation.evaluator]: \u001b[0mInference done 295/570. Dataloading: 0.0009 s/iter. Inference: 0.0574 s/iter. Eval: 0.2106 s/iter. Total: 0.2689 s/iter. ETA=0:01:13\n",
      "\u001b[32m[12/30 02:07:11 d2.evaluation.evaluator]: \u001b[0mInference done 335/570. Dataloading: 0.0009 s/iter. Inference: 0.0565 s/iter. Eval: 0.1942 s/iter. Total: 0.2516 s/iter. ETA=0:00:59\n",
      "\u001b[32m[12/30 02:07:16 d2.evaluation.evaluator]: \u001b[0mInference done 371/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1841 s/iter. Total: 0.2408 s/iter. ETA=0:00:47\n",
      "\u001b[32m[12/30 02:07:21 d2.evaluation.evaluator]: \u001b[0mInference done 392/570. Dataloading: 0.0009 s/iter. Inference: 0.0561 s/iter. Eval: 0.1843 s/iter. Total: 0.2413 s/iter. ETA=0:00:42\n",
      "\u001b[32m[12/30 02:07:26 d2.evaluation.evaluator]: \u001b[0mInference done 412/570. Dataloading: 0.0009 s/iter. Inference: 0.0561 s/iter. Eval: 0.1850 s/iter. Total: 0.2421 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/30 02:07:31 d2.evaluation.evaluator]: \u001b[0mInference done 430/570. Dataloading: 0.0009 s/iter. Inference: 0.0564 s/iter. Eval: 0.1862 s/iter. Total: 0.2436 s/iter. ETA=0:00:34\n",
      "\u001b[32m[12/30 02:07:36 d2.evaluation.evaluator]: \u001b[0mInference done 453/570. Dataloading: 0.0009 s/iter. Inference: 0.0565 s/iter. Eval: 0.1849 s/iter. Total: 0.2424 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/30 02:07:41 d2.evaluation.evaluator]: \u001b[0mInference done 490/570. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.1773 s/iter. Total: 0.2342 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/30 02:07:46 d2.evaluation.evaluator]: \u001b[0mInference done 509/570. Dataloading: 0.0009 s/iter. Inference: 0.0560 s/iter. Eval: 0.1784 s/iter. Total: 0.2353 s/iter. ETA=0:00:14\n",
      "\u001b[32m[12/30 02:07:51 d2.evaluation.evaluator]: \u001b[0mInference done 532/570. Dataloading: 0.0009 s/iter. Inference: 0.0560 s/iter. Eval: 0.1778 s/iter. Total: 0.2347 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/30 02:07:57 d2.evaluation.evaluator]: \u001b[0mInference done 550/570. Dataloading: 0.0009 s/iter. Inference: 0.0560 s/iter. Eval: 0.1795 s/iter. Total: 0.2365 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/30 02:08:02 d2.evaluation.evaluator]: \u001b[0mInference done 570/570. Dataloading: 0.0009 s/iter. Inference: 0.0561 s/iter. Eval: 0.1802 s/iter. Total: 0.2372 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/30 02:08:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:14.139234 (0.237415 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 02:08:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.056101 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 02:08:02 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/30 02:08:02 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.28209641645889194\n",
      "\u001b[32m[12/30 02:08:03 d2.utils.events]: \u001b[0m eta: 1:27:55  iter: 72259  total_loss: 1.161  loss_cls: 0.2407  loss_box_reg: 0.3854  loss_mask: 0.2511  loss_rpn_cls: 0.0646  loss_rpn_loc: 0.1595  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:08:08 d2.utils.events]: \u001b[0m eta: 1:27:53  iter: 72279  total_loss: 1.126  loss_cls: 0.2443  loss_box_reg: 0.337  loss_mask: 0.2558  loss_rpn_cls: 0.08924  loss_rpn_loc: 0.167  time: 0.2237  data_time: 0.0168  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:08:13 d2.utils.events]: \u001b[0m eta: 1:27:51  iter: 72299  total_loss: 1.145  loss_cls: 0.2943  loss_box_reg: 0.3912  loss_mask: 0.2509  loss_rpn_cls: 0.06029  loss_rpn_loc: 0.1593  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:08:17 d2.utils.events]: \u001b[0m eta: 1:27:42  iter: 72319  total_loss: 1.288  loss_cls: 0.3146  loss_box_reg: 0.4001  loss_mask: 0.2717  loss_rpn_cls: 0.06018  loss_rpn_loc: 0.1645  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:08:21 d2.utils.events]: \u001b[0m eta: 1:27:39  iter: 72339  total_loss: 1.102  loss_cls: 0.259  loss_box_reg: 0.359  loss_mask: 0.2497  loss_rpn_cls: 0.06046  loss_rpn_loc: 0.156  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:08:26 d2.utils.events]: \u001b[0m eta: 1:27:37  iter: 72359  total_loss: 1.107  loss_cls: 0.2575  loss_box_reg: 0.3794  loss_mask: 0.249  loss_rpn_cls: 0.0644  loss_rpn_loc: 0.1522  time: 0.2237  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:08:30 d2.utils.events]: \u001b[0m eta: 1:27:30  iter: 72379  total_loss: 1.188  loss_cls: 0.3011  loss_box_reg: 0.4111  loss_mask: 0.2539  loss_rpn_cls: 0.07367  loss_rpn_loc: 0.1569  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:08:35 d2.utils.events]: \u001b[0m eta: 1:27:25  iter: 72399  total_loss: 1.112  loss_cls: 0.2971  loss_box_reg: 0.3927  loss_mask: 0.247  loss_rpn_cls: 0.05466  loss_rpn_loc: 0.1447  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:08:39 d2.utils.events]: \u001b[0m eta: 1:27:21  iter: 72419  total_loss: 1.138  loss_cls: 0.2642  loss_box_reg: 0.3619  loss_mask: 0.2564  loss_rpn_cls: 0.05436  loss_rpn_loc: 0.1506  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:08:43 d2.utils.events]: \u001b[0m eta: 1:27:18  iter: 72439  total_loss: 1.203  loss_cls: 0.301  loss_box_reg: 0.385  loss_mask: 0.2604  loss_rpn_cls: 0.06709  loss_rpn_loc: 0.1767  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:08:48 d2.utils.events]: \u001b[0m eta: 1:27:15  iter: 72459  total_loss: 1.124  loss_cls: 0.256  loss_box_reg: 0.3392  loss_mask: 0.258  loss_rpn_cls: 0.07192  loss_rpn_loc: 0.1661  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:08:52 d2.utils.events]: \u001b[0m eta: 1:27:11  iter: 72479  total_loss: 1.151  loss_cls: 0.2834  loss_box_reg: 0.3755  loss_mask: 0.2552  loss_rpn_cls: 0.06598  loss_rpn_loc: 0.1563  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:08:57 d2.utils.events]: \u001b[0m eta: 1:27:04  iter: 72499  total_loss: 1.236  loss_cls: 0.2833  loss_box_reg: 0.415  loss_mask: 0.2564  loss_rpn_cls: 0.07413  loss_rpn_loc: 0.1655  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:09:01 d2.utils.events]: \u001b[0m eta: 1:26:58  iter: 72519  total_loss: 1.144  loss_cls: 0.2728  loss_box_reg: 0.3731  loss_mask: 0.2737  loss_rpn_cls: 0.06033  loss_rpn_loc: 0.1737  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:09:06 d2.utils.events]: \u001b[0m eta: 1:26:51  iter: 72539  total_loss: 1.216  loss_cls: 0.2803  loss_box_reg: 0.3938  loss_mask: 0.2604  loss_rpn_cls: 0.08456  loss_rpn_loc: 0.1722  time: 0.2237  data_time: 0.0243  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:09:10 d2.utils.events]: \u001b[0m eta: 1:26:37  iter: 72559  total_loss: 1.038  loss_cls: 0.2477  loss_box_reg: 0.3511  loss_mask: 0.2462  loss_rpn_cls: 0.05459  loss_rpn_loc: 0.1556  time: 0.2237  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:09:15 d2.utils.events]: \u001b[0m eta: 1:26:33  iter: 72579  total_loss: 1.135  loss_cls: 0.2777  loss_box_reg: 0.3656  loss_mask: 0.2703  loss_rpn_cls: 0.1171  loss_rpn_loc: 0.158  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:09:19 d2.utils.events]: \u001b[0m eta: 1:26:24  iter: 72599  total_loss: 1.068  loss_cls: 0.2497  loss_box_reg: 0.3453  loss_mask: 0.2538  loss_rpn_cls: 0.05001  loss_rpn_loc: 0.1434  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:09:23 d2.utils.events]: \u001b[0m eta: 1:26:23  iter: 72619  total_loss: 1.066  loss_cls: 0.2385  loss_box_reg: 0.3427  loss_mask: 0.249  loss_rpn_cls: 0.07137  loss_rpn_loc: 0.1538  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:09:28 d2.utils.events]: \u001b[0m eta: 1:26:14  iter: 72639  total_loss: 1.171  loss_cls: 0.2892  loss_box_reg: 0.3874  loss_mask: 0.2608  loss_rpn_cls: 0.05728  loss_rpn_loc: 0.1767  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:09:33 d2.utils.events]: \u001b[0m eta: 1:26:11  iter: 72659  total_loss: 1.027  loss_cls: 0.2232  loss_box_reg: 0.2958  loss_mask: 0.2588  loss_rpn_cls: 0.05442  loss_rpn_loc: 0.1542  time: 0.2237  data_time: 0.0227  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:09:37 d2.utils.events]: \u001b[0m eta: 1:26:05  iter: 72679  total_loss: 1.059  loss_cls: 0.254  loss_box_reg: 0.3486  loss_mask: 0.2477  loss_rpn_cls: 0.06294  loss_rpn_loc: 0.154  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:09:42 d2.utils.events]: \u001b[0m eta: 1:26:00  iter: 72699  total_loss: 1.155  loss_cls: 0.2915  loss_box_reg: 0.3668  loss_mask: 0.2626  loss_rpn_cls: 0.07138  loss_rpn_loc: 0.1529  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:09:46 d2.utils.events]: \u001b[0m eta: 1:25:53  iter: 72719  total_loss: 1.242  loss_cls: 0.3323  loss_box_reg: 0.3851  loss_mask: 0.2597  loss_rpn_cls: 0.06611  loss_rpn_loc: 0.1756  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:09:50 d2.utils.events]: \u001b[0m eta: 1:25:45  iter: 72739  total_loss: 1.203  loss_cls: 0.2633  loss_box_reg: 0.3749  loss_mask: 0.267  loss_rpn_cls: 0.07988  loss_rpn_loc: 0.178  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:09:55 d2.utils.events]: \u001b[0m eta: 1:25:40  iter: 72759  total_loss: 1.086  loss_cls: 0.2543  loss_box_reg: 0.3661  loss_mask: 0.251  loss_rpn_cls: 0.05903  loss_rpn_loc: 0.1525  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:09:59 d2.utils.events]: \u001b[0m eta: 1:25:29  iter: 72779  total_loss: 1.179  loss_cls: 0.2803  loss_box_reg: 0.3706  loss_mask: 0.2764  loss_rpn_cls: 0.07742  loss_rpn_loc: 0.1648  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:10:04 d2.utils.events]: \u001b[0m eta: 1:25:13  iter: 72799  total_loss: 1.247  loss_cls: 0.3059  loss_box_reg: 0.4072  loss_mask: 0.2575  loss_rpn_cls: 0.06592  loss_rpn_loc: 0.1621  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:10:08 d2.utils.events]: \u001b[0m eta: 1:25:08  iter: 72819  total_loss: 1.248  loss_cls: 0.287  loss_box_reg: 0.4045  loss_mask: 0.2833  loss_rpn_cls: 0.06738  loss_rpn_loc: 0.1693  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:10:12 d2.utils.events]: \u001b[0m eta: 1:25:02  iter: 72839  total_loss: 1.22  loss_cls: 0.3089  loss_box_reg: 0.3821  loss_mask: 0.2737  loss_rpn_cls: 0.08631  loss_rpn_loc: 0.1628  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:10:17 d2.utils.events]: \u001b[0m eta: 1:24:56  iter: 72859  total_loss: 1.063  loss_cls: 0.234  loss_box_reg: 0.3292  loss_mask: 0.2535  loss_rpn_cls: 0.05746  loss_rpn_loc: 0.1603  time: 0.2237  data_time: 0.0155  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:10:21 d2.utils.events]: \u001b[0m eta: 1:24:50  iter: 72879  total_loss: 1.204  loss_cls: 0.3037  loss_box_reg: 0.3787  loss_mask: 0.2606  loss_rpn_cls: 0.08836  loss_rpn_loc: 0.1689  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:10:26 d2.utils.events]: \u001b[0m eta: 1:24:47  iter: 72899  total_loss: 1.142  loss_cls: 0.2677  loss_box_reg: 0.3467  loss_mask: 0.2497  loss_rpn_cls: 0.06574  loss_rpn_loc: 0.1547  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:10:30 d2.utils.events]: \u001b[0m eta: 1:24:42  iter: 72919  total_loss: 1.108  loss_cls: 0.296  loss_box_reg: 0.3921  loss_mask: 0.2523  loss_rpn_cls: 0.05824  loss_rpn_loc: 0.1583  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:10:35 d2.utils.events]: \u001b[0m eta: 1:24:36  iter: 72939  total_loss: 1.05  loss_cls: 0.2411  loss_box_reg: 0.3403  loss_mask: 0.2311  loss_rpn_cls: 0.06353  loss_rpn_loc: 0.1488  time: 0.2237  data_time: 0.0142  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:10:39 d2.utils.events]: \u001b[0m eta: 1:24:32  iter: 72959  total_loss: 1.155  loss_cls: 0.3082  loss_box_reg: 0.3952  loss_mask: 0.2584  loss_rpn_cls: 0.08737  loss_rpn_loc: 0.1581  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:10:44 d2.utils.events]: \u001b[0m eta: 1:24:31  iter: 72979  total_loss: 1.162  loss_cls: 0.2724  loss_box_reg: 0.3498  loss_mask: 0.257  loss_rpn_cls: 0.07406  loss_rpn_loc: 0.1611  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:10:48 d2.utils.events]: \u001b[0m eta: 1:24:26  iter: 72999  total_loss: 1.044  loss_cls: 0.2715  loss_box_reg: 0.3736  loss_mask: 0.241  loss_rpn_cls: 0.05382  loss_rpn_loc: 0.1446  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:10:53 d2.utils.events]: \u001b[0m eta: 1:24:22  iter: 73019  total_loss: 1.116  loss_cls: 0.2846  loss_box_reg: 0.3536  loss_mask: 0.2481  loss_rpn_cls: 0.07236  loss_rpn_loc: 0.1607  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:10:57 d2.utils.events]: \u001b[0m eta: 1:24:14  iter: 73039  total_loss: 1.215  loss_cls: 0.2885  loss_box_reg: 0.3946  loss_mask: 0.2689  loss_rpn_cls: 0.05944  loss_rpn_loc: 0.1695  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:11:02 d2.utils.events]: \u001b[0m eta: 1:24:10  iter: 73059  total_loss: 1.282  loss_cls: 0.2972  loss_box_reg: 0.3921  loss_mask: 0.2725  loss_rpn_cls: 0.08774  loss_rpn_loc: 0.1853  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:11:06 d2.utils.events]: \u001b[0m eta: 1:24:06  iter: 73079  total_loss: 1.26  loss_cls: 0.3029  loss_box_reg: 0.3921  loss_mask: 0.2758  loss_rpn_cls: 0.07523  loss_rpn_loc: 0.1624  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:11:11 d2.utils.events]: \u001b[0m eta: 1:24:05  iter: 73099  total_loss: 1.186  loss_cls: 0.3114  loss_box_reg: 0.3462  loss_mask: 0.2566  loss_rpn_cls: 0.08372  loss_rpn_loc: 0.1917  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:11:16 d2.utils.events]: \u001b[0m eta: 1:24:02  iter: 73119  total_loss: 1.153  loss_cls: 0.2535  loss_box_reg: 0.3422  loss_mask: 0.266  loss_rpn_cls: 0.09521  loss_rpn_loc: 0.179  time: 0.2237  data_time: 0.0103  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:11:21 d2.utils.events]: \u001b[0m eta: 1:24:04  iter: 73139  total_loss: 1.118  loss_cls: 0.295  loss_box_reg: 0.3876  loss_mask: 0.2573  loss_rpn_cls: 0.06871  loss_rpn_loc: 0.1532  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:11:25 d2.utils.events]: \u001b[0m eta: 1:23:57  iter: 73159  total_loss: 1.163  loss_cls: 0.3035  loss_box_reg: 0.3965  loss_mask: 0.2505  loss_rpn_cls: 0.06338  loss_rpn_loc: 0.1551  time: 0.2237  data_time: 0.0238  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:11:30 d2.utils.events]: \u001b[0m eta: 1:24:02  iter: 73179  total_loss: 1.039  loss_cls: 0.2538  loss_box_reg: 0.3564  loss_mask: 0.2594  loss_rpn_cls: 0.06745  loss_rpn_loc: 0.1525  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:11:34 d2.utils.events]: \u001b[0m eta: 1:23:46  iter: 73199  total_loss: 1.051  loss_cls: 0.2523  loss_box_reg: 0.3592  loss_mask: 0.2398  loss_rpn_cls: 0.04728  loss_rpn_loc: 0.1417  time: 0.2237  data_time: 0.0057  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:11:39 d2.utils.events]: \u001b[0m eta: 1:23:42  iter: 73219  total_loss: 1.231  loss_cls: 0.2902  loss_box_reg: 0.3784  loss_mask: 0.2553  loss_rpn_cls: 0.06432  loss_rpn_loc: 0.1449  time: 0.2237  data_time: 0.0235  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:11:43 d2.utils.events]: \u001b[0m eta: 1:23:39  iter: 73239  total_loss: 1.168  loss_cls: 0.2818  loss_box_reg: 0.3769  loss_mask: 0.2681  loss_rpn_cls: 0.07549  loss_rpn_loc: 0.1675  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:11:48 d2.utils.events]: \u001b[0m eta: 1:23:38  iter: 73259  total_loss: 1.144  loss_cls: 0.2729  loss_box_reg: 0.3265  loss_mask: 0.2671  loss_rpn_cls: 0.065  loss_rpn_loc: 0.152  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:11:52 d2.utils.events]: \u001b[0m eta: 1:23:32  iter: 73279  total_loss: 1.296  loss_cls: 0.2844  loss_box_reg: 0.4001  loss_mask: 0.2769  loss_rpn_cls: 0.1085  loss_rpn_loc: 0.183  time: 0.2237  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:11:57 d2.utils.events]: \u001b[0m eta: 1:23:26  iter: 73299  total_loss: 1.094  loss_cls: 0.2903  loss_box_reg: 0.3874  loss_mask: 0.2594  loss_rpn_cls: 0.06425  loss_rpn_loc: 0.1633  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:12:01 d2.utils.events]: \u001b[0m eta: 1:23:24  iter: 73319  total_loss: 1.279  loss_cls: 0.3081  loss_box_reg: 0.3918  loss_mask: 0.2802  loss_rpn_cls: 0.07167  loss_rpn_loc: 0.1666  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:12:06 d2.utils.events]: \u001b[0m eta: 1:23:15  iter: 73339  total_loss: 1.094  loss_cls: 0.2636  loss_box_reg: 0.3734  loss_mask: 0.2611  loss_rpn_cls: 0.05654  loss_rpn_loc: 0.1565  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:12:10 d2.utils.events]: \u001b[0m eta: 1:23:12  iter: 73359  total_loss: 1.119  loss_cls: 0.258  loss_box_reg: 0.3648  loss_mask: 0.2469  loss_rpn_cls: 0.09184  loss_rpn_loc: 0.1546  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:12:15 d2.utils.events]: \u001b[0m eta: 1:23:09  iter: 73379  total_loss: 1.145  loss_cls: 0.2906  loss_box_reg: 0.3401  loss_mask: 0.2522  loss_rpn_cls: 0.07594  loss_rpn_loc: 0.1807  time: 0.2237  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:12:19 d2.utils.events]: \u001b[0m eta: 1:23:06  iter: 73399  total_loss: 1.2  loss_cls: 0.2875  loss_box_reg: 0.4199  loss_mask: 0.2678  loss_rpn_cls: 0.0805  loss_rpn_loc: 0.1727  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:12:23 d2.utils.events]: \u001b[0m eta: 1:23:08  iter: 73419  total_loss: 1.254  loss_cls: 0.3086  loss_box_reg: 0.4073  loss_mask: 0.274  loss_rpn_cls: 0.07991  loss_rpn_loc: 0.1619  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:12:28 d2.utils.events]: \u001b[0m eta: 1:23:11  iter: 73439  total_loss: 1.214  loss_cls: 0.2991  loss_box_reg: 0.3758  loss_mask: 0.2737  loss_rpn_cls: 0.09751  loss_rpn_loc: 0.1724  time: 0.2237  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:12:33 d2.utils.events]: \u001b[0m eta: 1:23:06  iter: 73459  total_loss: 1.139  loss_cls: 0.2928  loss_box_reg: 0.3803  loss_mask: 0.2532  loss_rpn_cls: 0.06663  loss_rpn_loc: 0.1736  time: 0.2237  data_time: 0.0123  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:12:37 d2.utils.events]: \u001b[0m eta: 1:23:02  iter: 73479  total_loss: 1.119  loss_cls: 0.2526  loss_box_reg: 0.3106  loss_mask: 0.2453  loss_rpn_cls: 0.08487  loss_rpn_loc: 0.1647  time: 0.2237  data_time: 0.0093  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:12:42 d2.utils.events]: \u001b[0m eta: 1:23:02  iter: 73499  total_loss: 1.173  loss_cls: 0.2716  loss_box_reg: 0.3721  loss_mask: 0.2618  loss_rpn_cls: 0.0524  loss_rpn_loc: 0.1432  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:12:46 d2.utils.events]: \u001b[0m eta: 1:22:53  iter: 73519  total_loss: 1.164  loss_cls: 0.3061  loss_box_reg: 0.3717  loss_mask: 0.2398  loss_rpn_cls: 0.08118  loss_rpn_loc: 0.1638  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:12:51 d2.utils.events]: \u001b[0m eta: 1:22:57  iter: 73539  total_loss: 1.146  loss_cls: 0.2871  loss_box_reg: 0.3742  loss_mask: 0.2634  loss_rpn_cls: 0.08123  loss_rpn_loc: 0.16  time: 0.2237  data_time: 0.0231  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:12:55 d2.utils.events]: \u001b[0m eta: 1:22:44  iter: 73559  total_loss: 1.202  loss_cls: 0.2821  loss_box_reg: 0.4379  loss_mask: 0.2661  loss_rpn_cls: 0.05657  loss_rpn_loc: 0.1568  time: 0.2237  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:13:00 d2.utils.events]: \u001b[0m eta: 1:22:40  iter: 73579  total_loss: 1.209  loss_cls: 0.2754  loss_box_reg: 0.3894  loss_mask: 0.2827  loss_rpn_cls: 0.07948  loss_rpn_loc: 0.156  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:13:04 d2.utils.events]: \u001b[0m eta: 1:22:47  iter: 73599  total_loss: 0.9853  loss_cls: 0.2452  loss_box_reg: 0.3366  loss_mask: 0.2256  loss_rpn_cls: 0.06137  loss_rpn_loc: 0.1521  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:13:09 d2.utils.events]: \u001b[0m eta: 1:22:47  iter: 73619  total_loss: 1.254  loss_cls: 0.3134  loss_box_reg: 0.4239  loss_mask: 0.2857  loss_rpn_cls: 0.08854  loss_rpn_loc: 0.17  time: 0.2237  data_time: 0.0097  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:13:14 d2.utils.events]: \u001b[0m eta: 1:22:54  iter: 73639  total_loss: 1.16  loss_cls: 0.2796  loss_box_reg: 0.3457  loss_mask: 0.2705  loss_rpn_cls: 0.07704  loss_rpn_loc: 0.1593  time: 0.2237  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:13:18 d2.utils.events]: \u001b[0m eta: 1:22:50  iter: 73659  total_loss: 1.092  loss_cls: 0.2527  loss_box_reg: 0.3822  loss_mask: 0.2691  loss_rpn_cls: 0.072  loss_rpn_loc: 0.1682  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:13:23 d2.utils.events]: \u001b[0m eta: 1:22:47  iter: 73679  total_loss: 1.214  loss_cls: 0.2968  loss_box_reg: 0.3455  loss_mask: 0.2569  loss_rpn_cls: 0.08111  loss_rpn_loc: 0.1726  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:13:27 d2.utils.events]: \u001b[0m eta: 1:22:40  iter: 73699  total_loss: 1.1  loss_cls: 0.2518  loss_box_reg: 0.3805  loss_mask: 0.2522  loss_rpn_cls: 0.04741  loss_rpn_loc: 0.1531  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:13:32 d2.utils.events]: \u001b[0m eta: 1:22:39  iter: 73719  total_loss: 1.131  loss_cls: 0.2782  loss_box_reg: 0.3811  loss_mask: 0.2454  loss_rpn_cls: 0.0669  loss_rpn_loc: 0.1631  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:13:36 d2.utils.events]: \u001b[0m eta: 1:22:34  iter: 73739  total_loss: 1.124  loss_cls: 0.2608  loss_box_reg: 0.368  loss_mask: 0.2619  loss_rpn_cls: 0.07012  loss_rpn_loc: 0.1654  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:13:41 d2.utils.events]: \u001b[0m eta: 1:22:26  iter: 73759  total_loss: 1.092  loss_cls: 0.2644  loss_box_reg: 0.3558  loss_mask: 0.2439  loss_rpn_cls: 0.05293  loss_rpn_loc: 0.1561  time: 0.2237  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:13:45 d2.utils.events]: \u001b[0m eta: 1:22:25  iter: 73779  total_loss: 1.234  loss_cls: 0.3208  loss_box_reg: 0.349  loss_mask: 0.2726  loss_rpn_cls: 0.101  loss_rpn_loc: 0.162  time: 0.2237  data_time: 0.0191  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:13:50 d2.utils.events]: \u001b[0m eta: 1:22:27  iter: 73799  total_loss: 1.031  loss_cls: 0.2505  loss_box_reg: 0.3693  loss_mask: 0.2471  loss_rpn_cls: 0.06532  loss_rpn_loc: 0.1581  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:13:54 d2.utils.events]: \u001b[0m eta: 1:22:23  iter: 73819  total_loss: 1.253  loss_cls: 0.3015  loss_box_reg: 0.4026  loss_mask: 0.2671  loss_rpn_cls: 0.05815  loss_rpn_loc: 0.1477  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:13:59 d2.utils.events]: \u001b[0m eta: 1:22:22  iter: 73839  total_loss: 1.234  loss_cls: 0.3018  loss_box_reg: 0.4206  loss_mask: 0.2731  loss_rpn_cls: 0.07039  loss_rpn_loc: 0.1651  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:14:03 d2.utils.events]: \u001b[0m eta: 1:22:23  iter: 73859  total_loss: 1.168  loss_cls: 0.287  loss_box_reg: 0.3896  loss_mask: 0.253  loss_rpn_cls: 0.06205  loss_rpn_loc: 0.1693  time: 0.2237  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:14:08 d2.utils.events]: \u001b[0m eta: 1:22:13  iter: 73879  total_loss: 1.089  loss_cls: 0.2354  loss_box_reg: 0.3564  loss_mask: 0.2752  loss_rpn_cls: 0.0738  loss_rpn_loc: 0.155  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:14:12 d2.utils.events]: \u001b[0m eta: 1:22:05  iter: 73899  total_loss: 1.091  loss_cls: 0.2461  loss_box_reg: 0.3578  loss_mask: 0.2605  loss_rpn_cls: 0.06489  loss_rpn_loc: 0.1362  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:14:17 d2.utils.events]: \u001b[0m eta: 1:22:05  iter: 73919  total_loss: 1.188  loss_cls: 0.3051  loss_box_reg: 0.3643  loss_mask: 0.252  loss_rpn_cls: 0.05556  loss_rpn_loc: 0.1493  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:14:21 d2.utils.events]: \u001b[0m eta: 1:21:57  iter: 73939  total_loss: 1.158  loss_cls: 0.2915  loss_box_reg: 0.3529  loss_mask: 0.254  loss_rpn_cls: 0.06285  loss_rpn_loc: 0.1622  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:14:25 d2.utils.events]: \u001b[0m eta: 1:21:53  iter: 73959  total_loss: 1.261  loss_cls: 0.3326  loss_box_reg: 0.4242  loss_mask: 0.2753  loss_rpn_cls: 0.08404  loss_rpn_loc: 0.1764  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:14:30 d2.utils.events]: \u001b[0m eta: 1:21:52  iter: 73979  total_loss: 1.049  loss_cls: 0.2382  loss_box_reg: 0.3314  loss_mask: 0.2435  loss_rpn_cls: 0.04936  loss_rpn_loc: 0.1542  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:14:34 d2.utils.events]: \u001b[0m eta: 1:21:52  iter: 73999  total_loss: 1.228  loss_cls: 0.2899  loss_box_reg: 0.379  loss_mask: 0.2575  loss_rpn_cls: 0.06475  loss_rpn_loc: 0.1699  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:14:39 d2.utils.events]: \u001b[0m eta: 1:21:41  iter: 74019  total_loss: 1.128  loss_cls: 0.2698  loss_box_reg: 0.3642  loss_mask: 0.2354  loss_rpn_cls: 0.07808  loss_rpn_loc: 0.1551  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:14:43 d2.utils.events]: \u001b[0m eta: 1:21:38  iter: 74039  total_loss: 1.08  loss_cls: 0.2673  loss_box_reg: 0.3639  loss_mask: 0.2539  loss_rpn_cls: 0.07368  loss_rpn_loc: 0.1601  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:14:48 d2.utils.events]: \u001b[0m eta: 1:21:29  iter: 74059  total_loss: 1.238  loss_cls: 0.3228  loss_box_reg: 0.4024  loss_mask: 0.2644  loss_rpn_cls: 0.06513  loss_rpn_loc: 0.1559  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:14:53 d2.utils.events]: \u001b[0m eta: 1:21:25  iter: 74079  total_loss: 1.175  loss_cls: 0.2724  loss_box_reg: 0.3622  loss_mask: 0.2604  loss_rpn_cls: 0.09604  loss_rpn_loc: 0.1841  time: 0.2237  data_time: 0.0187  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:14:57 d2.utils.events]: \u001b[0m eta: 1:21:10  iter: 74099  total_loss: 1.027  loss_cls: 0.2416  loss_box_reg: 0.365  loss_mask: 0.2267  loss_rpn_cls: 0.05322  loss_rpn_loc: 0.1505  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:15:01 d2.utils.events]: \u001b[0m eta: 1:21:10  iter: 74119  total_loss: 1.168  loss_cls: 0.2733  loss_box_reg: 0.3759  loss_mask: 0.2466  loss_rpn_cls: 0.0816  loss_rpn_loc: 0.1626  time: 0.2237  data_time: 0.0166  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:15:06 d2.utils.events]: \u001b[0m eta: 1:20:58  iter: 74139  total_loss: 1.086  loss_cls: 0.2705  loss_box_reg: 0.3791  loss_mask: 0.2459  loss_rpn_cls: 0.06098  loss_rpn_loc: 0.143  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:15:10 d2.utils.events]: \u001b[0m eta: 1:20:52  iter: 74159  total_loss: 1.101  loss_cls: 0.2573  loss_box_reg: 0.3428  loss_mask: 0.2483  loss_rpn_cls: 0.07426  loss_rpn_loc: 0.1786  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:15:15 d2.utils.events]: \u001b[0m eta: 1:20:41  iter: 74179  total_loss: 1.101  loss_cls: 0.2704  loss_box_reg: 0.3628  loss_mask: 0.2513  loss_rpn_cls: 0.05431  loss_rpn_loc: 0.1517  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:15:19 d2.utils.events]: \u001b[0m eta: 1:20:44  iter: 74199  total_loss: 1.084  loss_cls: 0.246  loss_box_reg: 0.3308  loss_mask: 0.2632  loss_rpn_cls: 0.07525  loss_rpn_loc: 0.1606  time: 0.2237  data_time: 0.0090  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:15:24 d2.utils.events]: \u001b[0m eta: 1:20:33  iter: 74219  total_loss: 1.042  loss_cls: 0.2681  loss_box_reg: 0.37  loss_mask: 0.2416  loss_rpn_cls: 0.04764  loss_rpn_loc: 0.1659  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:15:29 d2.utils.events]: \u001b[0m eta: 1:20:28  iter: 74239  total_loss: 1.151  loss_cls: 0.2885  loss_box_reg: 0.4016  loss_mask: 0.2674  loss_rpn_cls: 0.07846  loss_rpn_loc: 0.1642  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:15:33 d2.utils.events]: \u001b[0m eta: 1:20:27  iter: 74259  total_loss: 1.229  loss_cls: 0.3239  loss_box_reg: 0.3813  loss_mask: 0.2769  loss_rpn_cls: 0.07695  loss_rpn_loc: 0.1674  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:15:38 d2.utils.events]: \u001b[0m eta: 1:20:23  iter: 74279  total_loss: 1.216  loss_cls: 0.3098  loss_box_reg: 0.4056  loss_mask: 0.269  loss_rpn_cls: 0.08665  loss_rpn_loc: 0.1761  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:15:42 d2.utils.events]: \u001b[0m eta: 1:20:21  iter: 74299  total_loss: 1.204  loss_cls: 0.2854  loss_box_reg: 0.3901  loss_mask: 0.2628  loss_rpn_cls: 0.06375  loss_rpn_loc: 0.1532  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:15:47 d2.utils.events]: \u001b[0m eta: 1:20:19  iter: 74319  total_loss: 1.229  loss_cls: 0.2894  loss_box_reg: 0.3727  loss_mask: 0.2644  loss_rpn_cls: 0.06773  loss_rpn_loc: 0.1768  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:15:51 d2.utils.events]: \u001b[0m eta: 1:20:19  iter: 74339  total_loss: 1.181  loss_cls: 0.2906  loss_box_reg: 0.3852  loss_mask: 0.2601  loss_rpn_cls: 0.06208  loss_rpn_loc: 0.1609  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:15:55 d2.utils.events]: \u001b[0m eta: 1:20:17  iter: 74359  total_loss: 1.028  loss_cls: 0.2536  loss_box_reg: 0.3383  loss_mask: 0.238  loss_rpn_cls: 0.05786  loss_rpn_loc: 0.1483  time: 0.2237  data_time: 0.0145  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:16:00 d2.utils.events]: \u001b[0m eta: 1:20:05  iter: 74379  total_loss: 1.198  loss_cls: 0.2947  loss_box_reg: 0.3906  loss_mask: 0.2558  loss_rpn_cls: 0.06342  loss_rpn_loc: 0.1428  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:16:04 d2.utils.events]: \u001b[0m eta: 1:20:00  iter: 74399  total_loss: 1.181  loss_cls: 0.2834  loss_box_reg: 0.3486  loss_mask: 0.2504  loss_rpn_cls: 0.07976  loss_rpn_loc: 0.1736  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:16:09 d2.utils.events]: \u001b[0m eta: 1:19:56  iter: 74419  total_loss: 1.135  loss_cls: 0.2525  loss_box_reg: 0.3244  loss_mask: 0.2567  loss_rpn_cls: 0.1008  loss_rpn_loc: 0.1557  time: 0.2237  data_time: 0.0145  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:16:13 d2.utils.events]: \u001b[0m eta: 1:19:45  iter: 74439  total_loss: 1.241  loss_cls: 0.3459  loss_box_reg: 0.3737  loss_mask: 0.263  loss_rpn_cls: 0.09435  loss_rpn_loc: 0.1723  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:16:18 d2.utils.events]: \u001b[0m eta: 1:19:41  iter: 74459  total_loss: 1.234  loss_cls: 0.296  loss_box_reg: 0.3674  loss_mask: 0.2716  loss_rpn_cls: 0.07749  loss_rpn_loc: 0.1615  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:16:22 d2.utils.events]: \u001b[0m eta: 1:19:45  iter: 74479  total_loss: 1.207  loss_cls: 0.2968  loss_box_reg: 0.3615  loss_mask: 0.2748  loss_rpn_cls: 0.06654  loss_rpn_loc: 0.1708  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:16:27 d2.utils.events]: \u001b[0m eta: 1:19:44  iter: 74499  total_loss: 1.118  loss_cls: 0.2595  loss_box_reg: 0.3867  loss_mask: 0.2486  loss_rpn_cls: 0.05517  loss_rpn_loc: 0.1397  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:16:31 d2.utils.events]: \u001b[0m eta: 1:19:42  iter: 74519  total_loss: 1.154  loss_cls: 0.2765  loss_box_reg: 0.3999  loss_mask: 0.2757  loss_rpn_cls: 0.06851  loss_rpn_loc: 0.1665  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:16:36 d2.utils.events]: \u001b[0m eta: 1:19:35  iter: 74539  total_loss: 1.098  loss_cls: 0.273  loss_box_reg: 0.3314  loss_mask: 0.2435  loss_rpn_cls: 0.0636  loss_rpn_loc: 0.1525  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:16:40 d2.utils.events]: \u001b[0m eta: 1:19:37  iter: 74559  total_loss: 1.231  loss_cls: 0.3066  loss_box_reg: 0.4299  loss_mask: 0.257  loss_rpn_cls: 0.08179  loss_rpn_loc: 0.1553  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:16:44 d2.utils.events]: \u001b[0m eta: 1:19:27  iter: 74579  total_loss: 1.252  loss_cls: 0.3095  loss_box_reg: 0.3907  loss_mask: 0.2781  loss_rpn_cls: 0.06882  loss_rpn_loc: 0.1703  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:16:49 d2.utils.events]: \u001b[0m eta: 1:19:25  iter: 74599  total_loss: 1.209  loss_cls: 0.2943  loss_box_reg: 0.3904  loss_mask: 0.2728  loss_rpn_cls: 0.0692  loss_rpn_loc: 0.1783  time: 0.2237  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:16:54 d2.utils.events]: \u001b[0m eta: 1:19:14  iter: 74619  total_loss: 1.072  loss_cls: 0.2564  loss_box_reg: 0.3224  loss_mask: 0.2393  loss_rpn_cls: 0.06788  loss_rpn_loc: 0.1552  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:16:58 d2.utils.events]: \u001b[0m eta: 1:18:59  iter: 74639  total_loss: 1.149  loss_cls: 0.2898  loss_box_reg: 0.3606  loss_mask: 0.2527  loss_rpn_cls: 0.08213  loss_rpn_loc: 0.1688  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:17:03 d2.utils.events]: \u001b[0m eta: 1:18:50  iter: 74659  total_loss: 1.265  loss_cls: 0.3436  loss_box_reg: 0.3668  loss_mask: 0.273  loss_rpn_cls: 0.0914  loss_rpn_loc: 0.1596  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:17:07 d2.utils.events]: \u001b[0m eta: 1:18:50  iter: 74679  total_loss: 1.241  loss_cls: 0.2997  loss_box_reg: 0.4071  loss_mask: 0.2781  loss_rpn_cls: 0.09667  loss_rpn_loc: 0.1624  time: 0.2237  data_time: 0.0181  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:17:12 d2.utils.events]: \u001b[0m eta: 1:18:53  iter: 74699  total_loss: 1.182  loss_cls: 0.3172  loss_box_reg: 0.3976  loss_mask: 0.2552  loss_rpn_cls: 0.06868  loss_rpn_loc: 0.1628  time: 0.2237  data_time: 0.0166  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:17:16 d2.utils.events]: \u001b[0m eta: 1:18:35  iter: 74719  total_loss: 1.225  loss_cls: 0.2672  loss_box_reg: 0.3569  loss_mask: 0.2508  loss_rpn_cls: 0.07413  loss_rpn_loc: 0.1724  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:17:21 d2.utils.events]: \u001b[0m eta: 1:18:34  iter: 74739  total_loss: 1.099  loss_cls: 0.2765  loss_box_reg: 0.2988  loss_mask: 0.254  loss_rpn_cls: 0.08208  loss_rpn_loc: 0.1688  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:17:25 d2.utils.events]: \u001b[0m eta: 1:18:33  iter: 74759  total_loss: 1.283  loss_cls: 0.3176  loss_box_reg: 0.4373  loss_mask: 0.2673  loss_rpn_cls: 0.06232  loss_rpn_loc: 0.1574  time: 0.2237  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:17:29 d2.utils.events]: \u001b[0m eta: 1:18:22  iter: 74779  total_loss: 1.068  loss_cls: 0.2681  loss_box_reg: 0.3851  loss_mask: 0.2496  loss_rpn_cls: 0.07278  loss_rpn_loc: 0.1534  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:17:34 d2.utils.events]: \u001b[0m eta: 1:18:17  iter: 74799  total_loss: 1.06  loss_cls: 0.2876  loss_box_reg: 0.3473  loss_mask: 0.2491  loss_rpn_cls: 0.06891  loss_rpn_loc: 0.1494  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:17:38 d2.utils.events]: \u001b[0m eta: 1:18:18  iter: 74819  total_loss: 1.193  loss_cls: 0.2693  loss_box_reg: 0.3664  loss_mask: 0.2556  loss_rpn_cls: 0.06832  loss_rpn_loc: 0.1676  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:17:43 d2.utils.events]: \u001b[0m eta: 1:18:22  iter: 74839  total_loss: 1.195  loss_cls: 0.3062  loss_box_reg: 0.3777  loss_mask: 0.2719  loss_rpn_cls: 0.06585  loss_rpn_loc: 0.1689  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:17:48 d2.utils.events]: \u001b[0m eta: 1:18:09  iter: 74859  total_loss: 1.144  loss_cls: 0.3023  loss_box_reg: 0.3864  loss_mask: 0.249  loss_rpn_cls: 0.07528  loss_rpn_loc: 0.1677  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:17:52 d2.utils.events]: \u001b[0m eta: 1:18:12  iter: 74879  total_loss: 1.302  loss_cls: 0.3132  loss_box_reg: 0.3966  loss_mask: 0.2763  loss_rpn_cls: 0.08312  loss_rpn_loc: 0.1787  time: 0.2237  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:17:57 d2.utils.events]: \u001b[0m eta: 1:18:09  iter: 74899  total_loss: 1.13  loss_cls: 0.2622  loss_box_reg: 0.3629  loss_mask: 0.2468  loss_rpn_cls: 0.06751  loss_rpn_loc: 0.1564  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:18:01 d2.utils.events]: \u001b[0m eta: 1:18:05  iter: 74919  total_loss: 1.265  loss_cls: 0.2915  loss_box_reg: 0.4013  loss_mask: 0.2907  loss_rpn_cls: 0.09753  loss_rpn_loc: 0.1766  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:18:06 d2.utils.events]: \u001b[0m eta: 1:18:00  iter: 74939  total_loss: 1.239  loss_cls: 0.3003  loss_box_reg: 0.4053  loss_mask: 0.2667  loss_rpn_cls: 0.06811  loss_rpn_loc: 0.1789  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:18:10 d2.utils.events]: \u001b[0m eta: 1:17:56  iter: 74959  total_loss: 1.213  loss_cls: 0.2902  loss_box_reg: 0.375  loss_mask: 0.2645  loss_rpn_cls: 0.06002  loss_rpn_loc: 0.1526  time: 0.2237  data_time: 0.0193  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:18:15 d2.utils.events]: \u001b[0m eta: 1:17:51  iter: 74979  total_loss: 1.142  loss_cls: 0.2839  loss_box_reg: 0.3527  loss_mask: 0.2456  loss_rpn_cls: 0.06002  loss_rpn_loc: 0.1574  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:18:19 d2.utils.events]: \u001b[0m eta: 1:17:37  iter: 74999  total_loss: 1.287  loss_cls: 0.3135  loss_box_reg: 0.4008  loss_mask: 0.2625  loss_rpn_cls: 0.07331  loss_rpn_loc: 0.1564  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:18:24 d2.utils.events]: \u001b[0m eta: 1:17:38  iter: 75019  total_loss: 1.065  loss_cls: 0.2456  loss_box_reg: 0.3587  loss_mask: 0.2483  loss_rpn_cls: 0.06736  loss_rpn_loc: 0.1537  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:18:28 d2.utils.events]: \u001b[0m eta: 1:17:38  iter: 75039  total_loss: 1.082  loss_cls: 0.2503  loss_box_reg: 0.3827  loss_mask: 0.2634  loss_rpn_cls: 0.06337  loss_rpn_loc: 0.146  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:18:33 d2.utils.events]: \u001b[0m eta: 1:17:29  iter: 75059  total_loss: 1.195  loss_cls: 0.2948  loss_box_reg: 0.4077  loss_mask: 0.2666  loss_rpn_cls: 0.07303  loss_rpn_loc: 0.1698  time: 0.2237  data_time: 0.0139  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:18:37 d2.utils.events]: \u001b[0m eta: 1:17:23  iter: 75079  total_loss: 1.218  loss_cls: 0.2835  loss_box_reg: 0.3835  loss_mask: 0.2601  loss_rpn_cls: 0.08  loss_rpn_loc: 0.163  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:18:41 d2.utils.events]: \u001b[0m eta: 1:17:24  iter: 75099  total_loss: 1.226  loss_cls: 0.2815  loss_box_reg: 0.4148  loss_mask: 0.2739  loss_rpn_cls: 0.06468  loss_rpn_loc: 0.1568  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:18:46 d2.utils.events]: \u001b[0m eta: 1:17:09  iter: 75119  total_loss: 1.145  loss_cls: 0.2656  loss_box_reg: 0.3341  loss_mask: 0.2461  loss_rpn_cls: 0.05933  loss_rpn_loc: 0.1747  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:18:51 d2.utils.events]: \u001b[0m eta: 1:17:06  iter: 75139  total_loss: 1.073  loss_cls: 0.2545  loss_box_reg: 0.336  loss_mask: 0.2559  loss_rpn_cls: 0.06801  loss_rpn_loc: 0.1662  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:18:55 d2.utils.events]: \u001b[0m eta: 1:17:08  iter: 75159  total_loss: 1.132  loss_cls: 0.2789  loss_box_reg: 0.3575  loss_mask: 0.2561  loss_rpn_cls: 0.0559  loss_rpn_loc: 0.1756  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:18:59 d2.utils.events]: \u001b[0m eta: 1:16:57  iter: 75179  total_loss: 1.109  loss_cls: 0.2744  loss_box_reg: 0.3302  loss_mask: 0.2664  loss_rpn_cls: 0.04816  loss_rpn_loc: 0.1452  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:19:03 d2.utils.events]: \u001b[0m eta: 1:16:52  iter: 75199  total_loss: 1.111  loss_cls: 0.2829  loss_box_reg: 0.3893  loss_mask: 0.265  loss_rpn_cls: 0.06064  loss_rpn_loc: 0.1793  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:19:08 d2.utils.events]: \u001b[0m eta: 1:16:48  iter: 75219  total_loss: 1.12  loss_cls: 0.272  loss_box_reg: 0.349  loss_mask: 0.2415  loss_rpn_cls: 0.07586  loss_rpn_loc: 0.16  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:19:12 d2.utils.events]: \u001b[0m eta: 1:16:43  iter: 75239  total_loss: 1.217  loss_cls: 0.2893  loss_box_reg: 0.367  loss_mask: 0.2669  loss_rpn_cls: 0.07845  loss_rpn_loc: 0.1615  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:19:16 d2.utils.events]: \u001b[0m eta: 1:16:36  iter: 75259  total_loss: 1.157  loss_cls: 0.2829  loss_box_reg: 0.3513  loss_mask: 0.2519  loss_rpn_cls: 0.07186  loss_rpn_loc: 0.1521  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:19:21 d2.utils.events]: \u001b[0m eta: 1:16:32  iter: 75279  total_loss: 1.155  loss_cls: 0.2878  loss_box_reg: 0.3728  loss_mask: 0.238  loss_rpn_cls: 0.0853  loss_rpn_loc: 0.1674  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:19:25 d2.utils.events]: \u001b[0m eta: 1:16:30  iter: 75299  total_loss: 1.153  loss_cls: 0.2784  loss_box_reg: 0.3406  loss_mask: 0.2497  loss_rpn_cls: 0.07922  loss_rpn_loc: 0.1462  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:19:30 d2.utils.events]: \u001b[0m eta: 1:16:23  iter: 75319  total_loss: 1.301  loss_cls: 0.3347  loss_box_reg: 0.426  loss_mask: 0.2962  loss_rpn_cls: 0.07889  loss_rpn_loc: 0.1756  time: 0.2237  data_time: 0.0089  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:19:34 d2.utils.events]: \u001b[0m eta: 1:16:20  iter: 75339  total_loss: 1.11  loss_cls: 0.2496  loss_box_reg: 0.3816  loss_mask: 0.2701  loss_rpn_cls: 0.06833  loss_rpn_loc: 0.1627  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:19:39 d2.utils.events]: \u001b[0m eta: 1:16:16  iter: 75359  total_loss: 1.158  loss_cls: 0.32  loss_box_reg: 0.3489  loss_mask: 0.2318  loss_rpn_cls: 0.05497  loss_rpn_loc: 0.1506  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:19:43 d2.utils.events]: \u001b[0m eta: 1:16:12  iter: 75379  total_loss: 1.16  loss_cls: 0.3025  loss_box_reg: 0.3916  loss_mask: 0.2554  loss_rpn_cls: 0.0625  loss_rpn_loc: 0.1589  time: 0.2237  data_time: 0.0168  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:19:48 d2.utils.events]: \u001b[0m eta: 1:16:09  iter: 75399  total_loss: 1.05  loss_cls: 0.2468  loss_box_reg: 0.349  loss_mask: 0.2481  loss_rpn_cls: 0.05754  loss_rpn_loc: 0.1625  time: 0.2237  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:19:53 d2.utils.events]: \u001b[0m eta: 1:16:06  iter: 75419  total_loss: 1.056  loss_cls: 0.2499  loss_box_reg: 0.3404  loss_mask: 0.2444  loss_rpn_cls: 0.05456  loss_rpn_loc: 0.151  time: 0.2237  data_time: 0.0147  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:19:57 d2.utils.events]: \u001b[0m eta: 1:16:06  iter: 75439  total_loss: 1.214  loss_cls: 0.3265  loss_box_reg: 0.3994  loss_mask: 0.2515  loss_rpn_cls: 0.06754  loss_rpn_loc: 0.1513  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:20:02 d2.utils.events]: \u001b[0m eta: 1:16:01  iter: 75459  total_loss: 1.136  loss_cls: 0.2753  loss_box_reg: 0.3871  loss_mask: 0.2613  loss_rpn_cls: 0.06169  loss_rpn_loc: 0.1628  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:20:06 d2.utils.events]: \u001b[0m eta: 1:15:51  iter: 75479  total_loss: 1.107  loss_cls: 0.28  loss_box_reg: 0.3789  loss_mask: 0.2479  loss_rpn_cls: 0.07491  loss_rpn_loc: 0.1656  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:20:11 d2.utils.events]: \u001b[0m eta: 1:15:46  iter: 75499  total_loss: 1.147  loss_cls: 0.2834  loss_box_reg: 0.3623  loss_mask: 0.2542  loss_rpn_cls: 0.06472  loss_rpn_loc: 0.17  time: 0.2237  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:20:15 d2.utils.events]: \u001b[0m eta: 1:15:40  iter: 75519  total_loss: 1.197  loss_cls: 0.2834  loss_box_reg: 0.4087  loss_mask: 0.2696  loss_rpn_cls: 0.0755  loss_rpn_loc: 0.163  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:20:20 d2.utils.events]: \u001b[0m eta: 1:15:27  iter: 75539  total_loss: 1.127  loss_cls: 0.2732  loss_box_reg: 0.3267  loss_mask: 0.2376  loss_rpn_cls: 0.07096  loss_rpn_loc: 0.1695  time: 0.2237  data_time: 0.0153  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:20:24 d2.utils.events]: \u001b[0m eta: 1:15:29  iter: 75559  total_loss: 1.168  loss_cls: 0.2796  loss_box_reg: 0.3628  loss_mask: 0.2512  loss_rpn_cls: 0.0749  loss_rpn_loc: 0.1661  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:20:28 d2.utils.events]: \u001b[0m eta: 1:15:19  iter: 75579  total_loss: 1.204  loss_cls: 0.2816  loss_box_reg: 0.3932  loss_mask: 0.2427  loss_rpn_cls: 0.04359  loss_rpn_loc: 0.1651  time: 0.2237  data_time: 0.0057  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:20:33 d2.utils.events]: \u001b[0m eta: 1:15:15  iter: 75599  total_loss: 1.154  loss_cls: 0.281  loss_box_reg: 0.3406  loss_mask: 0.2569  loss_rpn_cls: 0.07013  loss_rpn_loc: 0.1717  time: 0.2237  data_time: 0.0133  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:20:37 d2.utils.events]: \u001b[0m eta: 1:15:09  iter: 75619  total_loss: 1.152  loss_cls: 0.2557  loss_box_reg: 0.3926  loss_mask: 0.2632  loss_rpn_cls: 0.06879  loss_rpn_loc: 0.1538  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:20:42 d2.utils.events]: \u001b[0m eta: 1:15:09  iter: 75639  total_loss: 1.185  loss_cls: 0.2765  loss_box_reg: 0.3732  loss_mask: 0.2678  loss_rpn_cls: 0.07193  loss_rpn_loc: 0.1669  time: 0.2237  data_time: 0.0178  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:20:46 d2.utils.events]: \u001b[0m eta: 1:15:07  iter: 75659  total_loss: 1.033  loss_cls: 0.2392  loss_box_reg: 0.3274  loss_mask: 0.2416  loss_rpn_cls: 0.06278  loss_rpn_loc: 0.1486  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:20:51 d2.utils.events]: \u001b[0m eta: 1:14:58  iter: 75679  total_loss: 1.079  loss_cls: 0.2397  loss_box_reg: 0.3272  loss_mask: 0.2645  loss_rpn_cls: 0.07883  loss_rpn_loc: 0.1681  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:20:56 d2.utils.events]: \u001b[0m eta: 1:14:59  iter: 75699  total_loss: 1.098  loss_cls: 0.2758  loss_box_reg: 0.3328  loss_mask: 0.2326  loss_rpn_cls: 0.05325  loss_rpn_loc: 0.1512  time: 0.2237  data_time: 0.0179  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:21:00 d2.utils.events]: \u001b[0m eta: 1:14:58  iter: 75719  total_loss: 1.174  loss_cls: 0.2702  loss_box_reg: 0.417  loss_mask: 0.248  loss_rpn_cls: 0.07331  loss_rpn_loc: 0.1555  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:21:05 d2.utils.events]: \u001b[0m eta: 1:14:55  iter: 75739  total_loss: 1.128  loss_cls: 0.2301  loss_box_reg: 0.3382  loss_mask: 0.2687  loss_rpn_cls: 0.1037  loss_rpn_loc: 0.174  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:21:10 d2.utils.events]: \u001b[0m eta: 1:14:59  iter: 75759  total_loss: 1.077  loss_cls: 0.2537  loss_box_reg: 0.3522  loss_mask: 0.251  loss_rpn_cls: 0.06694  loss_rpn_loc: 0.1634  time: 0.2237  data_time: 0.0133  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:21:14 d2.utils.events]: \u001b[0m eta: 1:14:52  iter: 75779  total_loss: 1.091  loss_cls: 0.2787  loss_box_reg: 0.3549  loss_mask: 0.2555  loss_rpn_cls: 0.06306  loss_rpn_loc: 0.154  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:21:19 d2.utils.events]: \u001b[0m eta: 1:14:53  iter: 75799  total_loss: 1.109  loss_cls: 0.2577  loss_box_reg: 0.3566  loss_mask: 0.2711  loss_rpn_cls: 0.05379  loss_rpn_loc: 0.1533  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:21:23 d2.utils.events]: \u001b[0m eta: 1:14:48  iter: 75819  total_loss: 1.103  loss_cls: 0.2512  loss_box_reg: 0.3202  loss_mask: 0.2511  loss_rpn_cls: 0.07917  loss_rpn_loc: 0.153  time: 0.2237  data_time: 0.0109  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:21:28 d2.utils.events]: \u001b[0m eta: 1:14:44  iter: 75839  total_loss: 1.145  loss_cls: 0.287  loss_box_reg: 0.3412  loss_mask: 0.2651  loss_rpn_cls: 0.106  loss_rpn_loc: 0.1707  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:21:32 d2.utils.events]: \u001b[0m eta: 1:14:41  iter: 75859  total_loss: 1.21  loss_cls: 0.2886  loss_box_reg: 0.3885  loss_mask: 0.2492  loss_rpn_cls: 0.06835  loss_rpn_loc: 0.1757  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:21:37 d2.utils.events]: \u001b[0m eta: 1:14:27  iter: 75879  total_loss: 1.287  loss_cls: 0.3337  loss_box_reg: 0.4306  loss_mask: 0.2688  loss_rpn_cls: 0.0679  loss_rpn_loc: 0.1646  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:21:41 d2.utils.events]: \u001b[0m eta: 1:14:28  iter: 75899  total_loss: 1.202  loss_cls: 0.3099  loss_box_reg: 0.3833  loss_mask: 0.2691  loss_rpn_cls: 0.08366  loss_rpn_loc: 0.1675  time: 0.2237  data_time: 0.0147  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:21:46 d2.utils.events]: \u001b[0m eta: 1:14:20  iter: 75919  total_loss: 1.087  loss_cls: 0.2626  loss_box_reg: 0.3591  loss_mask: 0.2569  loss_rpn_cls: 0.05784  loss_rpn_loc: 0.165  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:21:50 d2.utils.events]: \u001b[0m eta: 1:14:21  iter: 75939  total_loss: 1.224  loss_cls: 0.2897  loss_box_reg: 0.3713  loss_mask: 0.2725  loss_rpn_cls: 0.08131  loss_rpn_loc: 0.169  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:21:54 d2.utils.events]: \u001b[0m eta: 1:14:13  iter: 75959  total_loss: 1.327  loss_cls: 0.3293  loss_box_reg: 0.4231  loss_mask: 0.2772  loss_rpn_cls: 0.06125  loss_rpn_loc: 0.1719  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:21:59 d2.utils.events]: \u001b[0m eta: 1:14:04  iter: 75979  total_loss: 1.115  loss_cls: 0.2673  loss_box_reg: 0.3455  loss_mask: 0.2649  loss_rpn_cls: 0.06906  loss_rpn_loc: 0.1694  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:22:03 d2.utils.events]: \u001b[0m eta: 1:14:05  iter: 75999  total_loss: 1.115  loss_cls: 0.2604  loss_box_reg: 0.3453  loss_mask: 0.2602  loss_rpn_cls: 0.07355  loss_rpn_loc: 0.1566  time: 0.2237  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:22:08 d2.utils.events]: \u001b[0m eta: 1:14:02  iter: 76019  total_loss: 1.163  loss_cls: 0.2963  loss_box_reg: 0.3914  loss_mask: 0.257  loss_rpn_cls: 0.05531  loss_rpn_loc: 0.1595  time: 0.2237  data_time: 0.0159  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:22:12 d2.utils.events]: \u001b[0m eta: 1:14:00  iter: 76039  total_loss: 1.316  loss_cls: 0.3156  loss_box_reg: 0.4482  loss_mask: 0.2876  loss_rpn_cls: 0.09134  loss_rpn_loc: 0.1774  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:22:17 d2.utils.events]: \u001b[0m eta: 1:14:01  iter: 76059  total_loss: 1.147  loss_cls: 0.258  loss_box_reg: 0.3661  loss_mask: 0.272  loss_rpn_cls: 0.07752  loss_rpn_loc: 0.1597  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:22:22 d2.utils.events]: \u001b[0m eta: 1:14:01  iter: 76079  total_loss: 1.126  loss_cls: 0.2782  loss_box_reg: 0.3727  loss_mask: 0.2587  loss_rpn_cls: 0.07099  loss_rpn_loc: 0.1716  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:22:26 d2.utils.events]: \u001b[0m eta: 1:14:01  iter: 76099  total_loss: 0.9764  loss_cls: 0.2217  loss_box_reg: 0.3489  loss_mask: 0.2349  loss_rpn_cls: 0.04991  loss_rpn_loc: 0.1485  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:22:30 d2.utils.events]: \u001b[0m eta: 1:13:57  iter: 76119  total_loss: 1.115  loss_cls: 0.2597  loss_box_reg: 0.338  loss_mask: 0.2603  loss_rpn_cls: 0.07149  loss_rpn_loc: 0.1566  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:22:35 d2.utils.events]: \u001b[0m eta: 1:13:42  iter: 76139  total_loss: 1.102  loss_cls: 0.2758  loss_box_reg: 0.3782  loss_mask: 0.2571  loss_rpn_cls: 0.06482  loss_rpn_loc: 0.1509  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:22:39 d2.utils.events]: \u001b[0m eta: 1:13:39  iter: 76159  total_loss: 1.176  loss_cls: 0.3053  loss_box_reg: 0.4192  loss_mask: 0.2563  loss_rpn_cls: 0.07888  loss_rpn_loc: 0.1542  time: 0.2237  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:22:44 d2.utils.events]: \u001b[0m eta: 1:13:46  iter: 76179  total_loss: 1.128  loss_cls: 0.2669  loss_box_reg: 0.3209  loss_mask: 0.2723  loss_rpn_cls: 0.08752  loss_rpn_loc: 0.1675  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:22:48 d2.utils.events]: \u001b[0m eta: 1:13:43  iter: 76199  total_loss: 1.116  loss_cls: 0.2662  loss_box_reg: 0.3575  loss_mask: 0.2577  loss_rpn_cls: 0.05885  loss_rpn_loc: 0.1569  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:22:53 d2.utils.events]: \u001b[0m eta: 1:13:40  iter: 76219  total_loss: 1.295  loss_cls: 0.3472  loss_box_reg: 0.3933  loss_mask: 0.2632  loss_rpn_cls: 0.08385  loss_rpn_loc: 0.1855  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:22:57 d2.utils.events]: \u001b[0m eta: 1:13:31  iter: 76239  total_loss: 1.146  loss_cls: 0.2891  loss_box_reg: 0.3245  loss_mask: 0.251  loss_rpn_cls: 0.09072  loss_rpn_loc: 0.1649  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:23:02 d2.utils.events]: \u001b[0m eta: 1:13:35  iter: 76259  total_loss: 1.182  loss_cls: 0.2782  loss_box_reg: 0.3802  loss_mask: 0.2559  loss_rpn_cls: 0.0693  loss_rpn_loc: 0.1623  time: 0.2237  data_time: 0.0146  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:23:07 d2.utils.events]: \u001b[0m eta: 1:13:32  iter: 76279  total_loss: 1.153  loss_cls: 0.3006  loss_box_reg: 0.3597  loss_mask: 0.2453  loss_rpn_cls: 0.08709  loss_rpn_loc: 0.1519  time: 0.2237  data_time: 0.0159  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:23:11 d2.utils.events]: \u001b[0m eta: 1:13:27  iter: 76299  total_loss: 1.139  loss_cls: 0.2664  loss_box_reg: 0.357  loss_mask: 0.2616  loss_rpn_cls: 0.07079  loss_rpn_loc: 0.1547  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:23:16 d2.utils.events]: \u001b[0m eta: 1:13:24  iter: 76319  total_loss: 1.143  loss_cls: 0.2746  loss_box_reg: 0.3294  loss_mask: 0.2589  loss_rpn_cls: 0.06551  loss_rpn_loc: 0.1597  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:23:20 d2.utils.events]: \u001b[0m eta: 1:13:25  iter: 76339  total_loss: 1.119  loss_cls: 0.2918  loss_box_reg: 0.3739  loss_mask: 0.238  loss_rpn_cls: 0.07471  loss_rpn_loc: 0.1588  time: 0.2237  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:23:25 d2.utils.events]: \u001b[0m eta: 1:13:19  iter: 76359  total_loss: 1.115  loss_cls: 0.3153  loss_box_reg: 0.3615  loss_mask: 0.2349  loss_rpn_cls: 0.05454  loss_rpn_loc: 0.1529  time: 0.2237  data_time: 0.0090  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:23:30 d2.utils.events]: \u001b[0m eta: 1:13:16  iter: 76379  total_loss: 1.171  loss_cls: 0.3001  loss_box_reg: 0.3811  loss_mask: 0.2534  loss_rpn_cls: 0.07844  loss_rpn_loc: 0.1517  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:23:34 d2.utils.events]: \u001b[0m eta: 1:13:10  iter: 76399  total_loss: 1.036  loss_cls: 0.2513  loss_box_reg: 0.352  loss_mask: 0.2517  loss_rpn_cls: 0.05793  loss_rpn_loc: 0.1486  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:23:38 d2.utils.events]: \u001b[0m eta: 1:12:58  iter: 76419  total_loss: 1.259  loss_cls: 0.3167  loss_box_reg: 0.3644  loss_mask: 0.2729  loss_rpn_cls: 0.1029  loss_rpn_loc: 0.1774  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:23:43 d2.utils.events]: \u001b[0m eta: 1:12:53  iter: 76439  total_loss: 1.124  loss_cls: 0.2611  loss_box_reg: 0.3807  loss_mask: 0.2637  loss_rpn_cls: 0.06813  loss_rpn_loc: 0.1448  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:23:47 d2.utils.events]: \u001b[0m eta: 1:12:39  iter: 76459  total_loss: 1.183  loss_cls: 0.2793  loss_box_reg: 0.411  loss_mask: 0.2593  loss_rpn_cls: 0.06121  loss_rpn_loc: 0.1635  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:23:52 d2.utils.events]: \u001b[0m eta: 1:12:37  iter: 76479  total_loss: 1.114  loss_cls: 0.292  loss_box_reg: 0.3848  loss_mask: 0.2578  loss_rpn_cls: 0.0827  loss_rpn_loc: 0.1587  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:23:56 d2.utils.events]: \u001b[0m eta: 1:12:37  iter: 76499  total_loss: 1.148  loss_cls: 0.3084  loss_box_reg: 0.4163  loss_mask: 0.2358  loss_rpn_cls: 0.05699  loss_rpn_loc: 0.1477  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:24:01 d2.utils.events]: \u001b[0m eta: 1:12:30  iter: 76519  total_loss: 1.261  loss_cls: 0.3125  loss_box_reg: 0.3748  loss_mask: 0.2748  loss_rpn_cls: 0.07782  loss_rpn_loc: 0.1661  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:24:05 d2.utils.events]: \u001b[0m eta: 1:12:28  iter: 76539  total_loss: 1.288  loss_cls: 0.3196  loss_box_reg: 0.4189  loss_mask: 0.278  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.1727  time: 0.2237  data_time: 0.0133  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:24:10 d2.utils.events]: \u001b[0m eta: 1:12:26  iter: 76559  total_loss: 1.248  loss_cls: 0.334  loss_box_reg: 0.3759  loss_mask: 0.2871  loss_rpn_cls: 0.07866  loss_rpn_loc: 0.1736  time: 0.2237  data_time: 0.0168  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:24:14 d2.utils.events]: \u001b[0m eta: 1:12:25  iter: 76579  total_loss: 1.102  loss_cls: 0.2706  loss_box_reg: 0.3774  loss_mask: 0.2501  loss_rpn_cls: 0.06623  loss_rpn_loc: 0.1443  time: 0.2237  data_time: 0.0197  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:24:19 d2.utils.events]: \u001b[0m eta: 1:12:21  iter: 76599  total_loss: 1.188  loss_cls: 0.2975  loss_box_reg: 0.4084  loss_mask: 0.2639  loss_rpn_cls: 0.06272  loss_rpn_loc: 0.146  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:24:23 d2.utils.events]: \u001b[0m eta: 1:12:15  iter: 76619  total_loss: 1.128  loss_cls: 0.277  loss_box_reg: 0.3945  loss_mask: 0.2507  loss_rpn_cls: 0.05811  loss_rpn_loc: 0.1621  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:24:28 d2.utils.events]: \u001b[0m eta: 1:12:15  iter: 76639  total_loss: 1.223  loss_cls: 0.287  loss_box_reg: 0.3667  loss_mask: 0.2708  loss_rpn_cls: 0.074  loss_rpn_loc: 0.1774  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:24:32 d2.utils.events]: \u001b[0m eta: 1:12:12  iter: 76659  total_loss: 1.2  loss_cls: 0.2689  loss_box_reg: 0.3605  loss_mask: 0.2738  loss_rpn_cls: 0.0763  loss_rpn_loc: 0.1689  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:24:37 d2.utils.events]: \u001b[0m eta: 1:12:08  iter: 76679  total_loss: 1.079  loss_cls: 0.2283  loss_box_reg: 0.319  loss_mask: 0.2588  loss_rpn_cls: 0.06153  loss_rpn_loc: 0.1564  time: 0.2237  data_time: 0.0107  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:24:41 d2.utils.events]: \u001b[0m eta: 1:11:56  iter: 76699  total_loss: 1.167  loss_cls: 0.2761  loss_box_reg: 0.4002  loss_mask: 0.2587  loss_rpn_cls: 0.04551  loss_rpn_loc: 0.1507  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:24:46 d2.utils.events]: \u001b[0m eta: 1:11:52  iter: 76719  total_loss: 1.236  loss_cls: 0.3188  loss_box_reg: 0.4142  loss_mask: 0.2623  loss_rpn_cls: 0.05962  loss_rpn_loc: 0.1895  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:24:50 d2.utils.events]: \u001b[0m eta: 1:11:32  iter: 76739  total_loss: 0.9822  loss_cls: 0.2424  loss_box_reg: 0.3451  loss_mask: 0.2396  loss_rpn_cls: 0.06249  loss_rpn_loc: 0.1363  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:24:54 d2.utils.events]: \u001b[0m eta: 1:11:34  iter: 76759  total_loss: 1.147  loss_cls: 0.3086  loss_box_reg: 0.3667  loss_mask: 0.2659  loss_rpn_cls: 0.05733  loss_rpn_loc: 0.159  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:24:59 d2.utils.events]: \u001b[0m eta: 1:11:36  iter: 76779  total_loss: 1.139  loss_cls: 0.2906  loss_box_reg: 0.3167  loss_mask: 0.2365  loss_rpn_cls: 0.0582  loss_rpn_loc: 0.1561  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:25:03 d2.utils.events]: \u001b[0m eta: 1:11:19  iter: 76799  total_loss: 1.087  loss_cls: 0.2838  loss_box_reg: 0.3736  loss_mask: 0.2602  loss_rpn_cls: 0.06458  loss_rpn_loc: 0.1472  time: 0.2237  data_time: 0.0058  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:25:08 d2.utils.events]: \u001b[0m eta: 1:11:13  iter: 76819  total_loss: 1.236  loss_cls: 0.3049  loss_box_reg: 0.416  loss_mask: 0.2717  loss_rpn_cls: 0.0629  loss_rpn_loc: 0.15  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:25:12 d2.utils.events]: \u001b[0m eta: 1:11:08  iter: 76839  total_loss: 1.303  loss_cls: 0.2919  loss_box_reg: 0.3645  loss_mask: 0.2769  loss_rpn_cls: 0.0899  loss_rpn_loc: 0.1876  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:25:17 d2.utils.events]: \u001b[0m eta: 1:10:58  iter: 76859  total_loss: 1.114  loss_cls: 0.2958  loss_box_reg: 0.3996  loss_mask: 0.2457  loss_rpn_cls: 0.06164  loss_rpn_loc: 0.1497  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:25:21 d2.utils.events]: \u001b[0m eta: 1:10:56  iter: 76879  total_loss: 1.081  loss_cls: 0.2652  loss_box_reg: 0.3602  loss_mask: 0.2521  loss_rpn_cls: 0.04988  loss_rpn_loc: 0.1665  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:25:26 d2.utils.events]: \u001b[0m eta: 1:10:51  iter: 76899  total_loss: 1.148  loss_cls: 0.2664  loss_box_reg: 0.3676  loss_mask: 0.2611  loss_rpn_cls: 0.06613  loss_rpn_loc: 0.1733  time: 0.2237  data_time: 0.0174  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:25:30 d2.utils.events]: \u001b[0m eta: 1:10:45  iter: 76919  total_loss: 1.216  loss_cls: 0.2963  loss_box_reg: 0.3749  loss_mask: 0.276  loss_rpn_cls: 0.0808  loss_rpn_loc: 0.1586  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:25:35 d2.utils.events]: \u001b[0m eta: 1:10:36  iter: 76939  total_loss: 1.093  loss_cls: 0.2608  loss_box_reg: 0.3515  loss_mask: 0.2421  loss_rpn_cls: 0.05494  loss_rpn_loc: 0.1426  time: 0.2237  data_time: 0.0166  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:25:39 d2.utils.events]: \u001b[0m eta: 1:10:36  iter: 76959  total_loss: 1.151  loss_cls: 0.2849  loss_box_reg: 0.3947  loss_mask: 0.2594  loss_rpn_cls: 0.06183  loss_rpn_loc: 0.1553  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:25:44 d2.utils.events]: \u001b[0m eta: 1:10:34  iter: 76979  total_loss: 1.034  loss_cls: 0.2367  loss_box_reg: 0.3085  loss_mask: 0.2508  loss_rpn_cls: 0.08061  loss_rpn_loc: 0.158  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:25:48 d2.utils.events]: \u001b[0m eta: 1:10:27  iter: 76999  total_loss: 1.205  loss_cls: 0.3091  loss_box_reg: 0.3855  loss_mask: 0.2652  loss_rpn_cls: 0.08376  loss_rpn_loc: 0.1659  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:25:53 d2.utils.events]: \u001b[0m eta: 1:10:20  iter: 77019  total_loss: 1.129  loss_cls: 0.2808  loss_box_reg: 0.3362  loss_mask: 0.251  loss_rpn_cls: 0.07045  loss_rpn_loc: 0.1641  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:25:57 d2.utils.events]: \u001b[0m eta: 1:10:11  iter: 77039  total_loss: 1.063  loss_cls: 0.2582  loss_box_reg: 0.3301  loss_mask: 0.2509  loss_rpn_cls: 0.06554  loss_rpn_loc: 0.1681  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:26:02 d2.utils.events]: \u001b[0m eta: 1:10:02  iter: 77059  total_loss: 1.17  loss_cls: 0.3047  loss_box_reg: 0.3764  loss_mask: 0.2574  loss_rpn_cls: 0.106  loss_rpn_loc: 0.1773  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:26:08 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 3.01 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 02:26:08 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 02:26:08 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 02:26:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 02:26:09 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 02:26:09 d2.data.common]: \u001b[0mSerialized dataset takes 84.20 MiB\n",
      "\u001b[32m[12/30 02:26:12 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 3.01 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 02:26:12 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 02:26:12 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 02:26:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/30 02:26:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0007 s/iter. Inference: 0.0618 s/iter. Eval: 0.1454 s/iter. Total: 0.2079 s/iter. ETA=0:01:56\n",
      "\u001b[32m[12/30 02:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 39/570. Dataloading: 0.0008 s/iter. Inference: 0.0581 s/iter. Eval: 0.1268 s/iter. Total: 0.1858 s/iter. ETA=0:01:38\n",
      "\u001b[32m[12/30 02:26:25 d2.evaluation.evaluator]: \u001b[0mInference done 67/570. Dataloading: 0.0008 s/iter. Inference: 0.0556 s/iter. Eval: 0.1284 s/iter. Total: 0.1849 s/iter. ETA=0:01:33\n",
      "\u001b[32m[12/30 02:26:31 d2.evaluation.evaluator]: \u001b[0mInference done 93/570. Dataloading: 0.0008 s/iter. Inference: 0.0568 s/iter. Eval: 0.1328 s/iter. Total: 0.1906 s/iter. ETA=0:01:30\n",
      "\u001b[32m[12/30 02:26:36 d2.evaluation.evaluator]: \u001b[0mInference done 120/570. Dataloading: 0.0009 s/iter. Inference: 0.0562 s/iter. Eval: 0.1332 s/iter. Total: 0.1903 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/30 02:26:41 d2.evaluation.evaluator]: \u001b[0mInference done 145/570. Dataloading: 0.0009 s/iter. Inference: 0.0558 s/iter. Eval: 0.1362 s/iter. Total: 0.1930 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 02:26:46 d2.evaluation.evaluator]: \u001b[0mInference done 163/570. Dataloading: 0.0009 s/iter. Inference: 0.0560 s/iter. Eval: 0.1462 s/iter. Total: 0.2031 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 02:26:51 d2.evaluation.evaluator]: \u001b[0mInference done 175/570. Dataloading: 0.0009 s/iter. Inference: 0.0564 s/iter. Eval: 0.1614 s/iter. Total: 0.2187 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/30 02:26:56 d2.evaluation.evaluator]: \u001b[0mInference done 193/570. Dataloading: 0.0009 s/iter. Inference: 0.0567 s/iter. Eval: 0.1673 s/iter. Total: 0.2249 s/iter. ETA=0:01:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:27:01 d2.evaluation.evaluator]: \u001b[0mInference done 208/570. Dataloading: 0.0017 s/iter. Inference: 0.0569 s/iter. Eval: 0.1755 s/iter. Total: 0.2342 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/30 02:27:07 d2.evaluation.evaluator]: \u001b[0mInference done 225/570. Dataloading: 0.0022 s/iter. Inference: 0.0571 s/iter. Eval: 0.1813 s/iter. Total: 0.2406 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 02:27:12 d2.evaluation.evaluator]: \u001b[0mInference done 236/570. Dataloading: 0.0021 s/iter. Inference: 0.0572 s/iter. Eval: 0.1926 s/iter. Total: 0.2520 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/30 02:27:18 d2.evaluation.evaluator]: \u001b[0mInference done 249/570. Dataloading: 0.0021 s/iter. Inference: 0.0574 s/iter. Eval: 0.2021 s/iter. Total: 0.2617 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 02:27:23 d2.evaluation.evaluator]: \u001b[0mInference done 265/570. Dataloading: 0.0020 s/iter. Inference: 0.0575 s/iter. Eval: 0.2057 s/iter. Total: 0.2653 s/iter. ETA=0:01:20\n",
      "\u001b[32m[12/30 02:27:28 d2.evaluation.evaluator]: \u001b[0mInference done 283/570. Dataloading: 0.0019 s/iter. Inference: 0.0575 s/iter. Eval: 0.2074 s/iter. Total: 0.2668 s/iter. ETA=0:01:16\n",
      "\u001b[32m[12/30 02:27:34 d2.evaluation.evaluator]: \u001b[0mInference done 298/570. Dataloading: 0.0019 s/iter. Inference: 0.0576 s/iter. Eval: 0.2127 s/iter. Total: 0.2722 s/iter. ETA=0:01:14\n",
      "\u001b[32m[12/30 02:27:39 d2.evaluation.evaluator]: \u001b[0mInference done 345/570. Dataloading: 0.0017 s/iter. Inference: 0.0562 s/iter. Eval: 0.1915 s/iter. Total: 0.2495 s/iter. ETA=0:00:56\n",
      "\u001b[32m[12/30 02:27:44 d2.evaluation.evaluator]: \u001b[0mInference done 375/570. Dataloading: 0.0017 s/iter. Inference: 0.0558 s/iter. Eval: 0.1853 s/iter. Total: 0.2429 s/iter. ETA=0:00:47\n",
      "\u001b[32m[12/30 02:27:49 d2.evaluation.evaluator]: \u001b[0mInference done 397/570. Dataloading: 0.0016 s/iter. Inference: 0.0560 s/iter. Eval: 0.1847 s/iter. Total: 0.2424 s/iter. ETA=0:00:41\n",
      "\u001b[32m[12/30 02:27:54 d2.evaluation.evaluator]: \u001b[0mInference done 415/570. Dataloading: 0.0016 s/iter. Inference: 0.0560 s/iter. Eval: 0.1864 s/iter. Total: 0.2441 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/30 02:27:59 d2.evaluation.evaluator]: \u001b[0mInference done 434/570. Dataloading: 0.0016 s/iter. Inference: 0.0561 s/iter. Eval: 0.1872 s/iter. Total: 0.2450 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/30 02:28:04 d2.evaluation.evaluator]: \u001b[0mInference done 462/570. Dataloading: 0.0015 s/iter. Inference: 0.0559 s/iter. Eval: 0.1836 s/iter. Total: 0.2411 s/iter. ETA=0:00:26\n",
      "\u001b[32m[12/30 02:28:09 d2.evaluation.evaluator]: \u001b[0mInference done 494/570. Dataloading: 0.0015 s/iter. Inference: 0.0555 s/iter. Eval: 0.1785 s/iter. Total: 0.2356 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/30 02:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 514/570. Dataloading: 0.0015 s/iter. Inference: 0.0553 s/iter. Eval: 0.1795 s/iter. Total: 0.2363 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/30 02:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 538/570. Dataloading: 0.0014 s/iter. Inference: 0.0553 s/iter. Eval: 0.1785 s/iter. Total: 0.2353 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/30 02:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 555/570. Dataloading: 0.0014 s/iter. Inference: 0.0555 s/iter. Eval: 0.1804 s/iter. Total: 0.2374 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 02:28:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:14.548414 (0.238139 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 02:28:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.055636 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 02:28:28 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/30 02:28:28 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2881015995064645\n",
      "\u001b[32m[12/30 02:28:31 d2.utils.events]: \u001b[0m eta: 1:10:00  iter: 77079  total_loss: 1.172  loss_cls: 0.2741  loss_box_reg: 0.3386  loss_mask: 0.2725  loss_rpn_cls: 0.07931  loss_rpn_loc: 0.1628  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:28:35 d2.utils.events]: \u001b[0m eta: 1:09:55  iter: 77099  total_loss: 1.234  loss_cls: 0.2894  loss_box_reg: 0.3873  loss_mask: 0.2789  loss_rpn_cls: 0.07935  loss_rpn_loc: 0.181  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:28:40 d2.utils.events]: \u001b[0m eta: 1:09:54  iter: 77119  total_loss: 1.219  loss_cls: 0.2938  loss_box_reg: 0.3886  loss_mask: 0.2554  loss_rpn_cls: 0.06451  loss_rpn_loc: 0.1589  time: 0.2237  data_time: 0.0202  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:28:44 d2.utils.events]: \u001b[0m eta: 1:10:03  iter: 77139  total_loss: 1.182  loss_cls: 0.2868  loss_box_reg: 0.3552  loss_mask: 0.2558  loss_rpn_cls: 0.07601  loss_rpn_loc: 0.1464  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:28:49 d2.utils.events]: \u001b[0m eta: 1:09:56  iter: 77159  total_loss: 1.239  loss_cls: 0.3146  loss_box_reg: 0.4052  loss_mask: 0.2742  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.1589  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:28:53 d2.utils.events]: \u001b[0m eta: 1:09:56  iter: 77179  total_loss: 1.148  loss_cls: 0.2578  loss_box_reg: 0.3435  loss_mask: 0.267  loss_rpn_cls: 0.08458  loss_rpn_loc: 0.1635  time: 0.2237  data_time: 0.0089  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:28:58 d2.utils.events]: \u001b[0m eta: 1:09:50  iter: 77199  total_loss: 1.09  loss_cls: 0.2455  loss_box_reg: 0.3406  loss_mask: 0.2405  loss_rpn_cls: 0.08578  loss_rpn_loc: 0.1598  time: 0.2237  data_time: 0.0090  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:29:03 d2.utils.events]: \u001b[0m eta: 1:09:57  iter: 77219  total_loss: 1.148  loss_cls: 0.3121  loss_box_reg: 0.3515  loss_mask: 0.2704  loss_rpn_cls: 0.08297  loss_rpn_loc: 0.1728  time: 0.2237  data_time: 0.0153  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:29:07 d2.utils.events]: \u001b[0m eta: 1:09:52  iter: 77239  total_loss: 1.144  loss_cls: 0.329  loss_box_reg: 0.354  loss_mask: 0.2516  loss_rpn_cls: 0.06354  loss_rpn_loc: 0.1545  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:29:11 d2.utils.events]: \u001b[0m eta: 1:09:47  iter: 77259  total_loss: 1.095  loss_cls: 0.275  loss_box_reg: 0.3325  loss_mask: 0.2464  loss_rpn_cls: 0.05385  loss_rpn_loc: 0.1503  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:29:16 d2.utils.events]: \u001b[0m eta: 1:09:37  iter: 77279  total_loss: 1.078  loss_cls: 0.2661  loss_box_reg: 0.3384  loss_mask: 0.2561  loss_rpn_cls: 0.04943  loss_rpn_loc: 0.1482  time: 0.2237  data_time: 0.0102  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:29:20 d2.utils.events]: \u001b[0m eta: 1:09:25  iter: 77299  total_loss: 1.243  loss_cls: 0.3159  loss_box_reg: 0.4007  loss_mask: 0.2634  loss_rpn_cls: 0.07701  loss_rpn_loc: 0.1671  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:29:25 d2.utils.events]: \u001b[0m eta: 1:09:31  iter: 77319  total_loss: 1.142  loss_cls: 0.3132  loss_box_reg: 0.3671  loss_mask: 0.237  loss_rpn_cls: 0.0658  loss_rpn_loc: 0.1673  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:29:30 d2.utils.events]: \u001b[0m eta: 1:09:27  iter: 77339  total_loss: 1.179  loss_cls: 0.2924  loss_box_reg: 0.3339  loss_mask: 0.2581  loss_rpn_cls: 0.07087  loss_rpn_loc: 0.1599  time: 0.2237  data_time: 0.0089  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:29:35 d2.utils.events]: \u001b[0m eta: 1:09:25  iter: 77359  total_loss: 1.101  loss_cls: 0.2705  loss_box_reg: 0.3288  loss_mask: 0.2506  loss_rpn_cls: 0.06416  loss_rpn_loc: 0.1567  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:29:39 d2.utils.events]: \u001b[0m eta: 1:09:10  iter: 77379  total_loss: 1.31  loss_cls: 0.319  loss_box_reg: 0.4307  loss_mask: 0.2646  loss_rpn_cls: 0.07383  loss_rpn_loc: 0.1793  time: 0.2237  data_time: 0.0157  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:29:44 d2.utils.events]: \u001b[0m eta: 1:08:54  iter: 77399  total_loss: 1.093  loss_cls: 0.2643  loss_box_reg: 0.3617  loss_mask: 0.2476  loss_rpn_cls: 0.07664  loss_rpn_loc: 0.1703  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:29:48 d2.utils.events]: \u001b[0m eta: 1:08:48  iter: 77419  total_loss: 1.223  loss_cls: 0.3099  loss_box_reg: 0.3563  loss_mask: 0.2514  loss_rpn_cls: 0.0893  loss_rpn_loc: 0.1597  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:29:52 d2.utils.events]: \u001b[0m eta: 1:08:44  iter: 77439  total_loss: 1.141  loss_cls: 0.2814  loss_box_reg: 0.3632  loss_mask: 0.2694  loss_rpn_cls: 0.05517  loss_rpn_loc: 0.1619  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:29:57 d2.utils.events]: \u001b[0m eta: 1:08:41  iter: 77459  total_loss: 1.055  loss_cls: 0.2633  loss_box_reg: 0.3343  loss_mask: 0.2414  loss_rpn_cls: 0.06347  loss_rpn_loc: 0.1517  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:30:01 d2.utils.events]: \u001b[0m eta: 1:08:48  iter: 77479  total_loss: 1.038  loss_cls: 0.2435  loss_box_reg: 0.3538  loss_mask: 0.255  loss_rpn_cls: 0.05313  loss_rpn_loc: 0.1529  time: 0.2237  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:30:06 d2.utils.events]: \u001b[0m eta: 1:08:32  iter: 77499  total_loss: 1.133  loss_cls: 0.2791  loss_box_reg: 0.3808  loss_mask: 0.2412  loss_rpn_cls: 0.06206  loss_rpn_loc: 0.1415  time: 0.2237  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:30:10 d2.utils.events]: \u001b[0m eta: 1:08:31  iter: 77519  total_loss: 1.148  loss_cls: 0.2743  loss_box_reg: 0.3743  loss_mask: 0.261  loss_rpn_cls: 0.11  loss_rpn_loc: 0.1669  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:30:14 d2.utils.events]: \u001b[0m eta: 1:08:22  iter: 77539  total_loss: 1.147  loss_cls: 0.2516  loss_box_reg: 0.42  loss_mask: 0.2559  loss_rpn_cls: 0.06791  loss_rpn_loc: 0.1608  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:30:19 d2.utils.events]: \u001b[0m eta: 1:08:23  iter: 77559  total_loss: 1.157  loss_cls: 0.2721  loss_box_reg: 0.4089  loss_mask: 0.2537  loss_rpn_cls: 0.07588  loss_rpn_loc: 0.1549  time: 0.2237  data_time: 0.0169  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:30:24 d2.utils.events]: \u001b[0m eta: 1:08:18  iter: 77579  total_loss: 1.146  loss_cls: 0.2613  loss_box_reg: 0.3844  loss_mask: 0.25  loss_rpn_cls: 0.06144  loss_rpn_loc: 0.1575  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:30:28 d2.utils.events]: \u001b[0m eta: 1:08:07  iter: 77599  total_loss: 1.168  loss_cls: 0.284  loss_box_reg: 0.3809  loss_mask: 0.2601  loss_rpn_cls: 0.07353  loss_rpn_loc: 0.1783  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:30:33 d2.utils.events]: \u001b[0m eta: 1:08:14  iter: 77619  total_loss: 1.039  loss_cls: 0.2473  loss_box_reg: 0.3276  loss_mask: 0.248  loss_rpn_cls: 0.06127  loss_rpn_loc: 0.1448  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:30:37 d2.utils.events]: \u001b[0m eta: 1:08:09  iter: 77639  total_loss: 1.124  loss_cls: 0.293  loss_box_reg: 0.3666  loss_mask: 0.2513  loss_rpn_cls: 0.06429  loss_rpn_loc: 0.1513  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:30:42 d2.utils.events]: \u001b[0m eta: 1:07:56  iter: 77659  total_loss: 1.221  loss_cls: 0.286  loss_box_reg: 0.3808  loss_mask: 0.2745  loss_rpn_cls: 0.06556  loss_rpn_loc: 0.1634  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:30:46 d2.utils.events]: \u001b[0m eta: 1:08:00  iter: 77679  total_loss: 1.268  loss_cls: 0.283  loss_box_reg: 0.3968  loss_mask: 0.2832  loss_rpn_cls: 0.07633  loss_rpn_loc: 0.1704  time: 0.2237  data_time: 0.0107  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:30:51 d2.utils.events]: \u001b[0m eta: 1:08:00  iter: 77699  total_loss: 1.279  loss_cls: 0.3198  loss_box_reg: 0.4278  loss_mask: 0.2743  loss_rpn_cls: 0.07355  loss_rpn_loc: 0.1749  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:30:55 d2.utils.events]: \u001b[0m eta: 1:08:00  iter: 77719  total_loss: 1.062  loss_cls: 0.2776  loss_box_reg: 0.3554  loss_mask: 0.2554  loss_rpn_cls: 0.06004  loss_rpn_loc: 0.1483  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:31:00 d2.utils.events]: \u001b[0m eta: 1:08:02  iter: 77739  total_loss: 1.073  loss_cls: 0.2386  loss_box_reg: 0.3523  loss_mask: 0.2593  loss_rpn_cls: 0.06162  loss_rpn_loc: 0.1531  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:31:04 d2.utils.events]: \u001b[0m eta: 1:07:52  iter: 77759  total_loss: 1.133  loss_cls: 0.2597  loss_box_reg: 0.3344  loss_mask: 0.2322  loss_rpn_cls: 0.07443  loss_rpn_loc: 0.1606  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:31:09 d2.utils.events]: \u001b[0m eta: 1:07:49  iter: 77779  total_loss: 1.182  loss_cls: 0.2733  loss_box_reg: 0.3639  loss_mask: 0.2684  loss_rpn_cls: 0.06478  loss_rpn_loc: 0.1678  time: 0.2237  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:31:13 d2.utils.events]: \u001b[0m eta: 1:07:49  iter: 77799  total_loss: 1.197  loss_cls: 0.279  loss_box_reg: 0.3714  loss_mask: 0.251  loss_rpn_cls: 0.07504  loss_rpn_loc: 0.1716  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:31:18 d2.utils.events]: \u001b[0m eta: 1:07:47  iter: 77819  total_loss: 1.075  loss_cls: 0.2658  loss_box_reg: 0.3557  loss_mask: 0.2498  loss_rpn_cls: 0.07499  loss_rpn_loc: 0.1752  time: 0.2237  data_time: 0.0127  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:31:22 d2.utils.events]: \u001b[0m eta: 1:07:40  iter: 77839  total_loss: 0.9928  loss_cls: 0.2594  loss_box_reg: 0.3544  loss_mask: 0.2416  loss_rpn_cls: 0.06492  loss_rpn_loc: 0.1493  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:31:27 d2.utils.events]: \u001b[0m eta: 1:07:38  iter: 77859  total_loss: 1.192  loss_cls: 0.3227  loss_box_reg: 0.4016  loss_mask: 0.2542  loss_rpn_cls: 0.05648  loss_rpn_loc: 0.1633  time: 0.2237  data_time: 0.0132  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:31:32 d2.utils.events]: \u001b[0m eta: 1:07:44  iter: 77879  total_loss: 1.177  loss_cls: 0.3041  loss_box_reg: 0.355  loss_mask: 0.2614  loss_rpn_cls: 0.07203  loss_rpn_loc: 0.1706  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:31:36 d2.utils.events]: \u001b[0m eta: 1:07:38  iter: 77899  total_loss: 1.134  loss_cls: 0.2811  loss_box_reg: 0.3591  loss_mask: 0.2625  loss_rpn_cls: 0.06284  loss_rpn_loc: 0.1834  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:31:40 d2.utils.events]: \u001b[0m eta: 1:07:36  iter: 77919  total_loss: 1.061  loss_cls: 0.2619  loss_box_reg: 0.331  loss_mask: 0.2368  loss_rpn_cls: 0.04384  loss_rpn_loc: 0.1488  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:31:45 d2.utils.events]: \u001b[0m eta: 1:07:31  iter: 77939  total_loss: 1.027  loss_cls: 0.2695  loss_box_reg: 0.3441  loss_mask: 0.2419  loss_rpn_cls: 0.07798  loss_rpn_loc: 0.1648  time: 0.2237  data_time: 0.0157  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:31:50 d2.utils.events]: \u001b[0m eta: 1:07:25  iter: 77959  total_loss: 1.237  loss_cls: 0.3284  loss_box_reg: 0.3774  loss_mask: 0.2818  loss_rpn_cls: 0.0852  loss_rpn_loc: 0.1562  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:31:54 d2.utils.events]: \u001b[0m eta: 1:07:21  iter: 77979  total_loss: 1.173  loss_cls: 0.2981  loss_box_reg: 0.3793  loss_mask: 0.2606  loss_rpn_cls: 0.07144  loss_rpn_loc: 0.1598  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:31:58 d2.utils.events]: \u001b[0m eta: 1:07:08  iter: 77999  total_loss: 1.076  loss_cls: 0.2834  loss_box_reg: 0.3648  loss_mask: 0.2401  loss_rpn_cls: 0.06543  loss_rpn_loc: 0.1307  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:32:03 d2.utils.events]: \u001b[0m eta: 1:06:59  iter: 78019  total_loss: 1.176  loss_cls: 0.2926  loss_box_reg: 0.3955  loss_mask: 0.2802  loss_rpn_cls: 0.07249  loss_rpn_loc: 0.1556  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:32:07 d2.utils.events]: \u001b[0m eta: 1:06:49  iter: 78039  total_loss: 1.166  loss_cls: 0.2841  loss_box_reg: 0.3614  loss_mask: 0.2678  loss_rpn_cls: 0.0635  loss_rpn_loc: 0.161  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:32:12 d2.utils.events]: \u001b[0m eta: 1:06:48  iter: 78059  total_loss: 1.198  loss_cls: 0.2857  loss_box_reg: 0.4012  loss_mask: 0.2646  loss_rpn_cls: 0.08179  loss_rpn_loc: 0.1651  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:32:16 d2.utils.events]: \u001b[0m eta: 1:06:39  iter: 78079  total_loss: 1.172  loss_cls: 0.2563  loss_box_reg: 0.3728  loss_mask: 0.2509  loss_rpn_cls: 0.06079  loss_rpn_loc: 0.193  time: 0.2237  data_time: 0.0103  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:32:21 d2.utils.events]: \u001b[0m eta: 1:06:33  iter: 78099  total_loss: 1.22  loss_cls: 0.2983  loss_box_reg: 0.4047  loss_mask: 0.2664  loss_rpn_cls: 0.06475  loss_rpn_loc: 0.181  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:32:25 d2.utils.events]: \u001b[0m eta: 1:06:32  iter: 78119  total_loss: 1.248  loss_cls: 0.3146  loss_box_reg: 0.3883  loss_mask: 0.2695  loss_rpn_cls: 0.09086  loss_rpn_loc: 0.1654  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:32:30 d2.utils.events]: \u001b[0m eta: 1:06:22  iter: 78139  total_loss: 1.185  loss_cls: 0.3087  loss_box_reg: 0.3859  loss_mask: 0.2591  loss_rpn_cls: 0.07252  loss_rpn_loc: 0.1669  time: 0.2237  data_time: 0.0204  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:32:34 d2.utils.events]: \u001b[0m eta: 1:06:14  iter: 78159  total_loss: 1.145  loss_cls: 0.266  loss_box_reg: 0.3786  loss_mask: 0.2549  loss_rpn_cls: 0.05933  loss_rpn_loc: 0.1757  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:32:39 d2.utils.events]: \u001b[0m eta: 1:06:10  iter: 78179  total_loss: 1.121  loss_cls: 0.2549  loss_box_reg: 0.3388  loss_mask: 0.255  loss_rpn_cls: 0.05995  loss_rpn_loc: 0.1658  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:32:43 d2.utils.events]: \u001b[0m eta: 1:06:05  iter: 78199  total_loss: 1.143  loss_cls: 0.2653  loss_box_reg: 0.3649  loss_mask: 0.2532  loss_rpn_cls: 0.05736  loss_rpn_loc: 0.1716  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:32:48 d2.utils.events]: \u001b[0m eta: 1:05:52  iter: 78219  total_loss: 1.081  loss_cls: 0.2303  loss_box_reg: 0.3324  loss_mask: 0.2538  loss_rpn_cls: 0.0807  loss_rpn_loc: 0.1456  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:32:52 d2.utils.events]: \u001b[0m eta: 1:05:48  iter: 78239  total_loss: 1.189  loss_cls: 0.2925  loss_box_reg: 0.3805  loss_mask: 0.2803  loss_rpn_cls: 0.07432  loss_rpn_loc: 0.1708  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:32:57 d2.utils.events]: \u001b[0m eta: 1:05:43  iter: 78259  total_loss: 1.262  loss_cls: 0.3308  loss_box_reg: 0.4063  loss_mask: 0.2771  loss_rpn_cls: 0.06747  loss_rpn_loc: 0.1846  time: 0.2237  data_time: 0.0176  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:33:01 d2.utils.events]: \u001b[0m eta: 1:05:39  iter: 78279  total_loss: 1.158  loss_cls: 0.2771  loss_box_reg: 0.3602  loss_mask: 0.2712  loss_rpn_cls: 0.08289  loss_rpn_loc: 0.1557  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:33:06 d2.utils.events]: \u001b[0m eta: 1:05:35  iter: 78299  total_loss: 1.211  loss_cls: 0.2917  loss_box_reg: 0.3945  loss_mask: 0.249  loss_rpn_cls: 0.06573  loss_rpn_loc: 0.1669  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:33:10 d2.utils.events]: \u001b[0m eta: 1:05:20  iter: 78319  total_loss: 1.116  loss_cls: 0.2582  loss_box_reg: 0.3522  loss_mask: 0.2432  loss_rpn_cls: 0.03755  loss_rpn_loc: 0.1592  time: 0.2237  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:33:14 d2.utils.events]: \u001b[0m eta: 1:05:10  iter: 78339  total_loss: 1.089  loss_cls: 0.2694  loss_box_reg: 0.3656  loss_mask: 0.2506  loss_rpn_cls: 0.05356  loss_rpn_loc: 0.1427  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:33:19 d2.utils.events]: \u001b[0m eta: 1:05:06  iter: 78359  total_loss: 1.197  loss_cls: 0.277  loss_box_reg: 0.3217  loss_mask: 0.2679  loss_rpn_cls: 0.08502  loss_rpn_loc: 0.171  time: 0.2237  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:33:24 d2.utils.events]: \u001b[0m eta: 1:05:05  iter: 78379  total_loss: 1.227  loss_cls: 0.2983  loss_box_reg: 0.4041  loss_mask: 0.2598  loss_rpn_cls: 0.0671  loss_rpn_loc: 0.1722  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:33:28 d2.utils.events]: \u001b[0m eta: 1:05:05  iter: 78399  total_loss: 1.101  loss_cls: 0.2669  loss_box_reg: 0.3536  loss_mask: 0.2501  loss_rpn_cls: 0.0608  loss_rpn_loc: 0.1446  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:33:33 d2.utils.events]: \u001b[0m eta: 1:05:08  iter: 78419  total_loss: 1.119  loss_cls: 0.2734  loss_box_reg: 0.4041  loss_mask: 0.2653  loss_rpn_cls: 0.07096  loss_rpn_loc: 0.1514  time: 0.2237  data_time: 0.0239  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:33:38 d2.utils.events]: \u001b[0m eta: 1:05:08  iter: 78439  total_loss: 1.183  loss_cls: 0.2639  loss_box_reg: 0.3902  loss_mask: 0.2492  loss_rpn_cls: 0.0726  loss_rpn_loc: 0.1589  time: 0.2238  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:33:42 d2.utils.events]: \u001b[0m eta: 1:05:06  iter: 78459  total_loss: 1.242  loss_cls: 0.3234  loss_box_reg: 0.4115  loss_mask: 0.2678  loss_rpn_cls: 0.0771  loss_rpn_loc: 0.147  time: 0.2237  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:33:46 d2.utils.events]: \u001b[0m eta: 1:04:58  iter: 78479  total_loss: 1.224  loss_cls: 0.32  loss_box_reg: 0.4012  loss_mask: 0.2631  loss_rpn_cls: 0.07957  loss_rpn_loc: 0.1779  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:33:51 d2.utils.events]: \u001b[0m eta: 1:05:00  iter: 78499  total_loss: 1.191  loss_cls: 0.3005  loss_box_reg: 0.3418  loss_mask: 0.2687  loss_rpn_cls: 0.08207  loss_rpn_loc: 0.161  time: 0.2238  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:33:55 d2.utils.events]: \u001b[0m eta: 1:04:53  iter: 78519  total_loss: 1.126  loss_cls: 0.2543  loss_box_reg: 0.3594  loss_mask: 0.2411  loss_rpn_cls: 0.0545  loss_rpn_loc: 0.146  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:34:00 d2.utils.events]: \u001b[0m eta: 1:04:46  iter: 78539  total_loss: 1.097  loss_cls: 0.2646  loss_box_reg: 0.3726  loss_mask: 0.2523  loss_rpn_cls: 0.05419  loss_rpn_loc: 0.157  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:34:04 d2.utils.events]: \u001b[0m eta: 1:04:37  iter: 78559  total_loss: 1.167  loss_cls: 0.2602  loss_box_reg: 0.4105  loss_mask: 0.2596  loss_rpn_cls: 0.05211  loss_rpn_loc: 0.153  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:34:09 d2.utils.events]: \u001b[0m eta: 1:04:38  iter: 78579  total_loss: 1.207  loss_cls: 0.2943  loss_box_reg: 0.3628  loss_mask: 0.2736  loss_rpn_cls: 0.07259  loss_rpn_loc: 0.1704  time: 0.2237  data_time: 0.0202  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:34:13 d2.utils.events]: \u001b[0m eta: 1:04:35  iter: 78599  total_loss: 1.134  loss_cls: 0.2861  loss_box_reg: 0.3754  loss_mask: 0.2483  loss_rpn_cls: 0.05324  loss_rpn_loc: 0.1419  time: 0.2237  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:34:17 d2.utils.events]: \u001b[0m eta: 1:04:33  iter: 78619  total_loss: 1.228  loss_cls: 0.3093  loss_box_reg: 0.4071  loss_mask: 0.2758  loss_rpn_cls: 0.09292  loss_rpn_loc: 0.1647  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:34:22 d2.utils.events]: \u001b[0m eta: 1:04:25  iter: 78639  total_loss: 1.159  loss_cls: 0.2794  loss_box_reg: 0.3836  loss_mask: 0.2493  loss_rpn_cls: 0.06354  loss_rpn_loc: 0.1472  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:34:26 d2.utils.events]: \u001b[0m eta: 1:04:17  iter: 78659  total_loss: 1.157  loss_cls: 0.3067  loss_box_reg: 0.3752  loss_mask: 0.2517  loss_rpn_cls: 0.06523  loss_rpn_loc: 0.1531  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:34:31 d2.utils.events]: \u001b[0m eta: 1:04:13  iter: 78679  total_loss: 1.17  loss_cls: 0.2896  loss_box_reg: 0.3572  loss_mask: 0.2729  loss_rpn_cls: 0.06105  loss_rpn_loc: 0.1559  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:34:35 d2.utils.events]: \u001b[0m eta: 1:04:08  iter: 78699  total_loss: 1.265  loss_cls: 0.3066  loss_box_reg: 0.4201  loss_mask: 0.2804  loss_rpn_cls: 0.0619  loss_rpn_loc: 0.1662  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:34:39 d2.utils.events]: \u001b[0m eta: 1:04:03  iter: 78719  total_loss: 1.082  loss_cls: 0.2581  loss_box_reg: 0.3568  loss_mask: 0.2469  loss_rpn_cls: 0.0694  loss_rpn_loc: 0.1579  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:34:44 d2.utils.events]: \u001b[0m eta: 1:03:58  iter: 78739  total_loss: 1.093  loss_cls: 0.2667  loss_box_reg: 0.3466  loss_mask: 0.2506  loss_rpn_cls: 0.08332  loss_rpn_loc: 0.1746  time: 0.2237  data_time: 0.0207  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:34:49 d2.utils.events]: \u001b[0m eta: 1:03:56  iter: 78759  total_loss: 1.063  loss_cls: 0.2295  loss_box_reg: 0.333  loss_mask: 0.2585  loss_rpn_cls: 0.08511  loss_rpn_loc: 0.1613  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:34:53 d2.utils.events]: \u001b[0m eta: 1:03:49  iter: 78779  total_loss: 1.159  loss_cls: 0.2798  loss_box_reg: 0.3807  loss_mask: 0.25  loss_rpn_cls: 0.05095  loss_rpn_loc: 0.1421  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:34:57 d2.utils.events]: \u001b[0m eta: 1:03:36  iter: 78799  total_loss: 1.142  loss_cls: 0.2695  loss_box_reg: 0.3727  loss_mask: 0.2585  loss_rpn_cls: 0.06054  loss_rpn_loc: 0.1702  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:35:02 d2.utils.events]: \u001b[0m eta: 1:03:30  iter: 78819  total_loss: 1.174  loss_cls: 0.2651  loss_box_reg: 0.3578  loss_mask: 0.2855  loss_rpn_cls: 0.07046  loss_rpn_loc: 0.1655  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:35:06 d2.utils.events]: \u001b[0m eta: 1:03:29  iter: 78839  total_loss: 1.252  loss_cls: 0.3117  loss_box_reg: 0.403  loss_mask: 0.2714  loss_rpn_cls: 0.09392  loss_rpn_loc: 0.1701  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:35:11 d2.utils.events]: \u001b[0m eta: 1:03:27  iter: 78859  total_loss: 1.153  loss_cls: 0.266  loss_box_reg: 0.3984  loss_mask: 0.2588  loss_rpn_cls: 0.07736  loss_rpn_loc: 0.183  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:35:15 d2.utils.events]: \u001b[0m eta: 1:03:17  iter: 78879  total_loss: 1.14  loss_cls: 0.2654  loss_box_reg: 0.3569  loss_mask: 0.2423  loss_rpn_cls: 0.07569  loss_rpn_loc: 0.1568  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:35:20 d2.utils.events]: \u001b[0m eta: 1:03:18  iter: 78899  total_loss: 0.9677  loss_cls: 0.2336  loss_box_reg: 0.32  loss_mask: 0.2337  loss_rpn_cls: 0.08352  loss_rpn_loc: 0.1451  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:35:24 d2.utils.events]: \u001b[0m eta: 1:03:16  iter: 78919  total_loss: 1.172  loss_cls: 0.2826  loss_box_reg: 0.3811  loss_mask: 0.2394  loss_rpn_cls: 0.07315  loss_rpn_loc: 0.1509  time: 0.2237  data_time: 0.0130  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:35:29 d2.utils.events]: \u001b[0m eta: 1:03:11  iter: 78939  total_loss: 1.263  loss_cls: 0.3248  loss_box_reg: 0.4073  loss_mask: 0.2675  loss_rpn_cls: 0.07722  loss_rpn_loc: 0.1819  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:35:33 d2.utils.events]: \u001b[0m eta: 1:03:07  iter: 78959  total_loss: 1.099  loss_cls: 0.2707  loss_box_reg: 0.3715  loss_mask: 0.251  loss_rpn_cls: 0.05266  loss_rpn_loc: 0.162  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:35:38 d2.utils.events]: \u001b[0m eta: 1:02:59  iter: 78979  total_loss: 1.246  loss_cls: 0.3202  loss_box_reg: 0.4014  loss_mask: 0.2492  loss_rpn_cls: 0.09371  loss_rpn_loc: 0.1598  time: 0.2237  data_time: 0.0158  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:35:42 d2.utils.events]: \u001b[0m eta: 1:02:58  iter: 78999  total_loss: 1.103  loss_cls: 0.2683  loss_box_reg: 0.3562  loss_mask: 0.2485  loss_rpn_cls: 0.05313  loss_rpn_loc: 0.1491  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:35:46 d2.utils.events]: \u001b[0m eta: 1:02:55  iter: 79019  total_loss: 1.113  loss_cls: 0.2676  loss_box_reg: 0.3689  loss_mask: 0.2623  loss_rpn_cls: 0.07135  loss_rpn_loc: 0.175  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:35:51 d2.utils.events]: \u001b[0m eta: 1:02:51  iter: 79039  total_loss: 1.112  loss_cls: 0.2296  loss_box_reg: 0.3534  loss_mask: 0.2401  loss_rpn_cls: 0.07076  loss_rpn_loc: 0.1426  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:35:55 d2.utils.events]: \u001b[0m eta: 1:02:46  iter: 79059  total_loss: 1.206  loss_cls: 0.3061  loss_box_reg: 0.3677  loss_mask: 0.2708  loss_rpn_cls: 0.06978  loss_rpn_loc: 0.1644  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:36:00 d2.utils.events]: \u001b[0m eta: 1:02:42  iter: 79079  total_loss: 1.16  loss_cls: 0.2825  loss_box_reg: 0.3834  loss_mask: 0.2591  loss_rpn_cls: 0.06519  loss_rpn_loc: 0.1569  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:36:04 d2.utils.events]: \u001b[0m eta: 1:02:40  iter: 79099  total_loss: 1.034  loss_cls: 0.2094  loss_box_reg: 0.3069  loss_mask: 0.2513  loss_rpn_cls: 0.05228  loss_rpn_loc: 0.1403  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:36:09 d2.utils.events]: \u001b[0m eta: 1:02:34  iter: 79119  total_loss: 1.156  loss_cls: 0.2978  loss_box_reg: 0.3392  loss_mask: 0.2592  loss_rpn_cls: 0.0736  loss_rpn_loc: 0.1656  time: 0.2237  data_time: 0.0120  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:36:13 d2.utils.events]: \u001b[0m eta: 1:02:33  iter: 79139  total_loss: 1.144  loss_cls: 0.2695  loss_box_reg: 0.3775  loss_mask: 0.2494  loss_rpn_cls: 0.05778  loss_rpn_loc: 0.1632  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:36:18 d2.utils.events]: \u001b[0m eta: 1:02:32  iter: 79159  total_loss: 1.161  loss_cls: 0.2846  loss_box_reg: 0.3949  loss_mask: 0.2574  loss_rpn_cls: 0.06068  loss_rpn_loc: 0.1582  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:36:22 d2.utils.events]: \u001b[0m eta: 1:02:23  iter: 79179  total_loss: 1.176  loss_cls: 0.2615  loss_box_reg: 0.4089  loss_mask: 0.2657  loss_rpn_cls: 0.0632  loss_rpn_loc: 0.1673  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:36:27 d2.utils.events]: \u001b[0m eta: 1:02:20  iter: 79199  total_loss: 1.247  loss_cls: 0.3237  loss_box_reg: 0.4293  loss_mask: 0.2784  loss_rpn_cls: 0.07471  loss_rpn_loc: 0.1739  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:36:31 d2.utils.events]: \u001b[0m eta: 1:02:12  iter: 79219  total_loss: 1.145  loss_cls: 0.2567  loss_box_reg: 0.3834  loss_mask: 0.2667  loss_rpn_cls: 0.06821  loss_rpn_loc: 0.1667  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:36:36 d2.utils.events]: \u001b[0m eta: 1:02:08  iter: 79239  total_loss: 1.203  loss_cls: 0.2933  loss_box_reg: 0.3877  loss_mask: 0.2713  loss_rpn_cls: 0.08171  loss_rpn_loc: 0.1679  time: 0.2237  data_time: 0.0161  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:36:40 d2.utils.events]: \u001b[0m eta: 1:02:03  iter: 79259  total_loss: 1.184  loss_cls: 0.2927  loss_box_reg: 0.4042  loss_mask: 0.262  loss_rpn_cls: 0.06285  loss_rpn_loc: 0.1503  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:36:44 d2.utils.events]: \u001b[0m eta: 1:02:04  iter: 79279  total_loss: 1.034  loss_cls: 0.2342  loss_box_reg: 0.342  loss_mask: 0.2511  loss_rpn_cls: 0.06142  loss_rpn_loc: 0.1415  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:36:49 d2.utils.events]: \u001b[0m eta: 1:02:00  iter: 79299  total_loss: 1.153  loss_cls: 0.2676  loss_box_reg: 0.3981  loss_mask: 0.2558  loss_rpn_cls: 0.0799  loss_rpn_loc: 0.1532  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:36:54 d2.utils.events]: \u001b[0m eta: 1:01:59  iter: 79319  total_loss: 1.059  loss_cls: 0.2549  loss_box_reg: 0.3867  loss_mask: 0.2602  loss_rpn_cls: 0.05565  loss_rpn_loc: 0.1484  time: 0.2237  data_time: 0.0169  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:36:58 d2.utils.events]: \u001b[0m eta: 1:01:57  iter: 79339  total_loss: 1.091  loss_cls: 0.2667  loss_box_reg: 0.3889  loss_mask: 0.2525  loss_rpn_cls: 0.05899  loss_rpn_loc: 0.1517  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:37:02 d2.utils.events]: \u001b[0m eta: 1:01:48  iter: 79359  total_loss: 1.116  loss_cls: 0.276  loss_box_reg: 0.3825  loss_mask: 0.2437  loss_rpn_cls: 0.04748  loss_rpn_loc: 0.1594  time: 0.2237  data_time: 0.0109  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:37:07 d2.utils.events]: \u001b[0m eta: 1:01:43  iter: 79379  total_loss: 1.04  loss_cls: 0.2363  loss_box_reg: 0.3441  loss_mask: 0.2499  loss_rpn_cls: 0.05829  loss_rpn_loc: 0.1468  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:37:11 d2.utils.events]: \u001b[0m eta: 1:01:40  iter: 79399  total_loss: 1.254  loss_cls: 0.3118  loss_box_reg: 0.3802  loss_mask: 0.2775  loss_rpn_cls: 0.0932  loss_rpn_loc: 0.1701  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:37:16 d2.utils.events]: \u001b[0m eta: 1:01:35  iter: 79419  total_loss: 1.253  loss_cls: 0.3169  loss_box_reg: 0.3911  loss_mask: 0.2903  loss_rpn_cls: 0.08339  loss_rpn_loc: 0.1722  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:37:20 d2.utils.events]: \u001b[0m eta: 1:01:20  iter: 79439  total_loss: 1.13  loss_cls: 0.2883  loss_box_reg: 0.3829  loss_mask: 0.2536  loss_rpn_cls: 0.05657  loss_rpn_loc: 0.1553  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:37:24 d2.utils.events]: \u001b[0m eta: 1:01:15  iter: 79459  total_loss: 1.223  loss_cls: 0.3117  loss_box_reg: 0.4108  loss_mask: 0.2635  loss_rpn_cls: 0.06745  loss_rpn_loc: 0.1562  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:37:29 d2.utils.events]: \u001b[0m eta: 1:01:10  iter: 79479  total_loss: 1.272  loss_cls: 0.3364  loss_box_reg: 0.3915  loss_mask: 0.2785  loss_rpn_cls: 0.07137  loss_rpn_loc: 0.1856  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:37:34 d2.utils.events]: \u001b[0m eta: 1:01:07  iter: 79499  total_loss: 1.26  loss_cls: 0.3087  loss_box_reg: 0.3839  loss_mask: 0.2658  loss_rpn_cls: 0.09521  loss_rpn_loc: 0.1812  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:37:38 d2.utils.events]: \u001b[0m eta: 1:01:05  iter: 79519  total_loss: 1.114  loss_cls: 0.2635  loss_box_reg: 0.3532  loss_mask: 0.2593  loss_rpn_cls: 0.07329  loss_rpn_loc: 0.1574  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:37:42 d2.utils.events]: \u001b[0m eta: 1:01:02  iter: 79539  total_loss: 1.289  loss_cls: 0.3182  loss_box_reg: 0.3988  loss_mask: 0.2726  loss_rpn_cls: 0.0809  loss_rpn_loc: 0.178  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:37:47 d2.utils.events]: \u001b[0m eta: 1:00:58  iter: 79559  total_loss: 1.191  loss_cls: 0.2754  loss_box_reg: 0.3834  loss_mask: 0.2538  loss_rpn_cls: 0.07672  loss_rpn_loc: 0.1695  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:37:52 d2.utils.events]: \u001b[0m eta: 1:00:54  iter: 79579  total_loss: 1.139  loss_cls: 0.2857  loss_box_reg: 0.336  loss_mask: 0.2638  loss_rpn_cls: 0.08789  loss_rpn_loc: 0.1633  time: 0.2237  data_time: 0.0181  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:37:56 d2.utils.events]: \u001b[0m eta: 1:00:49  iter: 79599  total_loss: 1.131  loss_cls: 0.277  loss_box_reg: 0.3877  loss_mask: 0.2635  loss_rpn_cls: 0.06473  loss_rpn_loc: 0.1618  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:38:01 d2.utils.events]: \u001b[0m eta: 1:00:45  iter: 79619  total_loss: 0.931  loss_cls: 0.2191  loss_box_reg: 0.3157  loss_mask: 0.2396  loss_rpn_cls: 0.05373  loss_rpn_loc: 0.1466  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:38:05 d2.utils.events]: \u001b[0m eta: 1:00:46  iter: 79639  total_loss: 1.174  loss_cls: 0.2991  loss_box_reg: 0.3801  loss_mask: 0.2678  loss_rpn_cls: 0.06677  loss_rpn_loc: 0.1574  time: 0.2237  data_time: 0.0170  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:38:10 d2.utils.events]: \u001b[0m eta: 1:00:45  iter: 79659  total_loss: 1.122  loss_cls: 0.2596  loss_box_reg: 0.3727  loss_mask: 0.2643  loss_rpn_cls: 0.07523  loss_rpn_loc: 0.1609  time: 0.2237  data_time: 0.0097  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:38:14 d2.utils.events]: \u001b[0m eta: 1:00:36  iter: 79679  total_loss: 1.079  loss_cls: 0.2507  loss_box_reg: 0.3779  loss_mask: 0.2543  loss_rpn_cls: 0.07079  loss_rpn_loc: 0.1797  time: 0.2237  data_time: 0.0096  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:38:19 d2.utils.events]: \u001b[0m eta: 1:00:35  iter: 79699  total_loss: 1.129  loss_cls: 0.2709  loss_box_reg: 0.3772  loss_mask: 0.2707  loss_rpn_cls: 0.07799  loss_rpn_loc: 0.1653  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:38:23 d2.utils.events]: \u001b[0m eta: 1:00:34  iter: 79719  total_loss: 1.165  loss_cls: 0.2944  loss_box_reg: 0.3807  loss_mask: 0.2693  loss_rpn_cls: 0.06829  loss_rpn_loc: 0.1512  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:38:28 d2.utils.events]: \u001b[0m eta: 1:00:28  iter: 79739  total_loss: 1.185  loss_cls: 0.2858  loss_box_reg: 0.3697  loss_mask: 0.2595  loss_rpn_cls: 0.08251  loss_rpn_loc: 0.1542  time: 0.2237  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:38:32 d2.utils.events]: \u001b[0m eta: 1:00:25  iter: 79759  total_loss: 1.14  loss_cls: 0.2804  loss_box_reg: 0.3662  loss_mask: 0.2535  loss_rpn_cls: 0.08175  loss_rpn_loc: 0.1705  time: 0.2237  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:38:37 d2.utils.events]: \u001b[0m eta: 1:00:21  iter: 79779  total_loss: 1.169  loss_cls: 0.2799  loss_box_reg: 0.3714  loss_mask: 0.2767  loss_rpn_cls: 0.07578  loss_rpn_loc: 0.1571  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:38:41 d2.utils.events]: \u001b[0m eta: 1:00:17  iter: 79799  total_loss: 1.093  loss_cls: 0.2838  loss_box_reg: 0.3669  loss_mask: 0.2478  loss_rpn_cls: 0.09042  loss_rpn_loc: 0.1538  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:38:46 d2.utils.events]: \u001b[0m eta: 1:00:09  iter: 79819  total_loss: 1.197  loss_cls: 0.314  loss_box_reg: 0.3577  loss_mask: 0.2655  loss_rpn_cls: 0.08185  loss_rpn_loc: 0.151  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:38:50 d2.utils.events]: \u001b[0m eta: 1:00:05  iter: 79839  total_loss: 1.27  loss_cls: 0.3232  loss_box_reg: 0.4204  loss_mask: 0.2889  loss_rpn_cls: 0.06788  loss_rpn_loc: 0.1663  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:38:55 d2.utils.events]: \u001b[0m eta: 1:00:00  iter: 79859  total_loss: 1.156  loss_cls: 0.2642  loss_box_reg: 0.3587  loss_mask: 0.2527  loss_rpn_cls: 0.07912  loss_rpn_loc: 0.1652  time: 0.2237  data_time: 0.0241  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:39:00 d2.utils.events]: \u001b[0m eta: 0:59:56  iter: 79879  total_loss: 1.137  loss_cls: 0.2557  loss_box_reg: 0.3446  loss_mask: 0.2632  loss_rpn_cls: 0.08505  loss_rpn_loc: 0.1902  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:39:05 d2.utils.events]: \u001b[0m eta: 0:59:51  iter: 79899  total_loss: 1.161  loss_cls: 0.289  loss_box_reg: 0.3747  loss_mask: 0.2635  loss_rpn_cls: 0.07165  loss_rpn_loc: 0.1669  time: 0.2237  data_time: 0.0339  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:39:09 d2.utils.events]: \u001b[0m eta: 0:59:47  iter: 79919  total_loss: 1.119  loss_cls: 0.2823  loss_box_reg: 0.3356  loss_mask: 0.2471  loss_rpn_cls: 0.06286  loss_rpn_loc: 0.147  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:39:14 d2.utils.events]: \u001b[0m eta: 0:59:46  iter: 79939  total_loss: 1.092  loss_cls: 0.2531  loss_box_reg: 0.3075  loss_mask: 0.2604  loss_rpn_cls: 0.07562  loss_rpn_loc: 0.1701  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:39:18 d2.utils.events]: \u001b[0m eta: 0:59:41  iter: 79959  total_loss: 1.186  loss_cls: 0.3085  loss_box_reg: 0.4169  loss_mask: 0.2673  loss_rpn_cls: 0.08814  loss_rpn_loc: 0.1632  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:39:23 d2.utils.events]: \u001b[0m eta: 0:59:37  iter: 79979  total_loss: 1.306  loss_cls: 0.3267  loss_box_reg: 0.4022  loss_mask: 0.265  loss_rpn_cls: 0.07892  loss_rpn_loc: 0.1665  time: 0.2237  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:39:27 d2.utils.events]: \u001b[0m eta: 0:59:32  iter: 79999  total_loss: 1.085  loss_cls: 0.2627  loss_box_reg: 0.3698  loss_mask: 0.2514  loss_rpn_cls: 0.0431  loss_rpn_loc: 0.1622  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:39:31 d2.utils.events]: \u001b[0m eta: 0:59:25  iter: 80019  total_loss: 1.136  loss_cls: 0.2604  loss_box_reg: 0.3347  loss_mask: 0.2719  loss_rpn_cls: 0.0651  loss_rpn_loc: 0.1532  time: 0.2237  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:39:36 d2.utils.events]: \u001b[0m eta: 0:59:20  iter: 80039  total_loss: 1.129  loss_cls: 0.2744  loss_box_reg: 0.3627  loss_mask: 0.2472  loss_rpn_cls: 0.04579  loss_rpn_loc: 0.1486  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:39:40 d2.utils.events]: \u001b[0m eta: 0:59:11  iter: 80059  total_loss: 1.181  loss_cls: 0.2791  loss_box_reg: 0.3698  loss_mask: 0.2538  loss_rpn_cls: 0.06994  loss_rpn_loc: 0.1495  time: 0.2237  data_time: 0.0093  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:39:44 d2.utils.events]: \u001b[0m eta: 0:59:07  iter: 80079  total_loss: 1.143  loss_cls: 0.2805  loss_box_reg: 0.3885  loss_mask: 0.2546  loss_rpn_cls: 0.06721  loss_rpn_loc: 0.1664  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:39:49 d2.utils.events]: \u001b[0m eta: 0:58:59  iter: 80099  total_loss: 1.214  loss_cls: 0.2998  loss_box_reg: 0.3985  loss_mask: 0.2807  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.1742  time: 0.2237  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:39:54 d2.utils.events]: \u001b[0m eta: 0:58:54  iter: 80119  total_loss: 0.9596  loss_cls: 0.2286  loss_box_reg: 0.3197  loss_mask: 0.2056  loss_rpn_cls: 0.04858  loss_rpn_loc: 0.1385  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:39:58 d2.utils.events]: \u001b[0m eta: 0:58:50  iter: 80139  total_loss: 1.167  loss_cls: 0.2936  loss_box_reg: 0.3624  loss_mask: 0.2609  loss_rpn_cls: 0.06017  loss_rpn_loc: 0.1593  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:40:03 d2.utils.events]: \u001b[0m eta: 0:58:45  iter: 80159  total_loss: 1.004  loss_cls: 0.2366  loss_box_reg: 0.3645  loss_mask: 0.2382  loss_rpn_cls: 0.05762  loss_rpn_loc: 0.1524  time: 0.2237  data_time: 0.0154  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:40:07 d2.utils.events]: \u001b[0m eta: 0:58:44  iter: 80179  total_loss: 1.263  loss_cls: 0.3092  loss_box_reg: 0.3784  loss_mask: 0.2756  loss_rpn_cls: 0.07429  loss_rpn_loc: 0.1645  time: 0.2237  data_time: 0.0269  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:40:12 d2.utils.events]: \u001b[0m eta: 0:58:37  iter: 80199  total_loss: 1.185  loss_cls: 0.2954  loss_box_reg: 0.3649  loss_mask: 0.252  loss_rpn_cls: 0.05884  loss_rpn_loc: 0.157  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:40:16 d2.utils.events]: \u001b[0m eta: 0:58:36  iter: 80219  total_loss: 1.062  loss_cls: 0.2319  loss_box_reg: 0.3401  loss_mask: 0.251  loss_rpn_cls: 0.05627  loss_rpn_loc: 0.1478  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:40:21 d2.utils.events]: \u001b[0m eta: 0:58:32  iter: 80239  total_loss: 1.22  loss_cls: 0.3241  loss_box_reg: 0.412  loss_mask: 0.2581  loss_rpn_cls: 0.06187  loss_rpn_loc: 0.1725  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:40:25 d2.utils.events]: \u001b[0m eta: 0:58:28  iter: 80259  total_loss: 1.173  loss_cls: 0.2908  loss_box_reg: 0.3537  loss_mask: 0.2528  loss_rpn_cls: 0.06966  loss_rpn_loc: 0.1521  time: 0.2237  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:40:30 d2.utils.events]: \u001b[0m eta: 0:58:22  iter: 80279  total_loss: 1.063  loss_cls: 0.2236  loss_box_reg: 0.3627  loss_mask: 0.2453  loss_rpn_cls: 0.05671  loss_rpn_loc: 0.148  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:40:34 d2.utils.events]: \u001b[0m eta: 0:58:16  iter: 80299  total_loss: 1.164  loss_cls: 0.2897  loss_box_reg: 0.3885  loss_mask: 0.2795  loss_rpn_cls: 0.06923  loss_rpn_loc: 0.1513  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:40:38 d2.utils.events]: \u001b[0m eta: 0:58:09  iter: 80319  total_loss: 1.073  loss_cls: 0.2398  loss_box_reg: 0.3668  loss_mask: 0.2508  loss_rpn_cls: 0.0503  loss_rpn_loc: 0.158  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:40:43 d2.utils.events]: \u001b[0m eta: 0:58:05  iter: 80339  total_loss: 1.088  loss_cls: 0.2596  loss_box_reg: 0.3325  loss_mask: 0.2527  loss_rpn_cls: 0.08759  loss_rpn_loc: 0.1475  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:40:47 d2.utils.events]: \u001b[0m eta: 0:58:02  iter: 80359  total_loss: 1.09  loss_cls: 0.2784  loss_box_reg: 0.3593  loss_mask: 0.2657  loss_rpn_cls: 0.05742  loss_rpn_loc: 0.1644  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:40:51 d2.utils.events]: \u001b[0m eta: 0:57:58  iter: 80379  total_loss: 1.198  loss_cls: 0.2947  loss_box_reg: 0.3882  loss_mask: 0.2659  loss_rpn_cls: 0.07707  loss_rpn_loc: 0.1636  time: 0.2237  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:40:56 d2.utils.events]: \u001b[0m eta: 0:57:53  iter: 80399  total_loss: 1.259  loss_cls: 0.2965  loss_box_reg: 0.4047  loss_mask: 0.2871  loss_rpn_cls: 0.06902  loss_rpn_loc: 0.1676  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:41:00 d2.utils.events]: \u001b[0m eta: 0:57:48  iter: 80419  total_loss: 1.112  loss_cls: 0.2739  loss_box_reg: 0.3876  loss_mask: 0.2479  loss_rpn_cls: 0.06727  loss_rpn_loc: 0.1557  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:41:05 d2.utils.events]: \u001b[0m eta: 0:57:45  iter: 80439  total_loss: 1.203  loss_cls: 0.294  loss_box_reg: 0.3762  loss_mask: 0.2635  loss_rpn_cls: 0.07945  loss_rpn_loc: 0.1865  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:41:09 d2.utils.events]: \u001b[0m eta: 0:57:42  iter: 80459  total_loss: 1.235  loss_cls: 0.3159  loss_box_reg: 0.4038  loss_mask: 0.2679  loss_rpn_cls: 0.07179  loss_rpn_loc: 0.1629  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:41:14 d2.utils.events]: \u001b[0m eta: 0:57:38  iter: 80479  total_loss: 1.153  loss_cls: 0.2639  loss_box_reg: 0.3784  loss_mask: 0.2641  loss_rpn_cls: 0.08006  loss_rpn_loc: 0.1501  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:41:18 d2.utils.events]: \u001b[0m eta: 0:57:38  iter: 80499  total_loss: 1.094  loss_cls: 0.265  loss_box_reg: 0.3344  loss_mask: 0.265  loss_rpn_cls: 0.07969  loss_rpn_loc: 0.1731  time: 0.2237  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:41:23 d2.utils.events]: \u001b[0m eta: 0:57:32  iter: 80519  total_loss: 1.017  loss_cls: 0.2597  loss_box_reg: 0.3593  loss_mask: 0.2406  loss_rpn_cls: 0.04521  loss_rpn_loc: 0.1424  time: 0.2237  data_time: 0.0192  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:41:27 d2.utils.events]: \u001b[0m eta: 0:57:25  iter: 80539  total_loss: 1.087  loss_cls: 0.2756  loss_box_reg: 0.3506  loss_mask: 0.2327  loss_rpn_cls: 0.06236  loss_rpn_loc: 0.1396  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:41:32 d2.utils.events]: \u001b[0m eta: 0:57:21  iter: 80559  total_loss: 1.286  loss_cls: 0.327  loss_box_reg: 0.4169  loss_mask: 0.2648  loss_rpn_cls: 0.07058  loss_rpn_loc: 0.1661  time: 0.2237  data_time: 0.0147  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:41:36 d2.utils.events]: \u001b[0m eta: 0:57:10  iter: 80579  total_loss: 1.14  loss_cls: 0.2808  loss_box_reg: 0.3831  loss_mask: 0.2569  loss_rpn_cls: 0.05722  loss_rpn_loc: 0.1585  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:41:40 d2.utils.events]: \u001b[0m eta: 0:57:02  iter: 80599  total_loss: 1.127  loss_cls: 0.2817  loss_box_reg: 0.38  loss_mask: 0.2519  loss_rpn_cls: 0.06376  loss_rpn_loc: 0.1632  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:41:45 d2.utils.events]: \u001b[0m eta: 0:56:55  iter: 80619  total_loss: 1.277  loss_cls: 0.3233  loss_box_reg: 0.3995  loss_mask: 0.2678  loss_rpn_cls: 0.07137  loss_rpn_loc: 0.1629  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:41:49 d2.utils.events]: \u001b[0m eta: 0:56:51  iter: 80639  total_loss: 1.162  loss_cls: 0.2467  loss_box_reg: 0.3646  loss_mask: 0.2453  loss_rpn_cls: 0.05337  loss_rpn_loc: 0.1584  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:41:54 d2.utils.events]: \u001b[0m eta: 0:56:42  iter: 80659  total_loss: 1.239  loss_cls: 0.309  loss_box_reg: 0.4041  loss_mask: 0.2614  loss_rpn_cls: 0.08363  loss_rpn_loc: 0.1611  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:41:58 d2.utils.events]: \u001b[0m eta: 0:56:36  iter: 80679  total_loss: 1.18  loss_cls: 0.2858  loss_box_reg: 0.41  loss_mask: 0.2554  loss_rpn_cls: 0.06992  loss_rpn_loc: 0.1602  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:42:02 d2.utils.events]: \u001b[0m eta: 0:56:24  iter: 80699  total_loss: 1.1  loss_cls: 0.2936  loss_box_reg: 0.3786  loss_mask: 0.2448  loss_rpn_cls: 0.05212  loss_rpn_loc: 0.1366  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:42:06 d2.utils.events]: \u001b[0m eta: 0:56:16  iter: 80719  total_loss: 1.138  loss_cls: 0.275  loss_box_reg: 0.3546  loss_mask: 0.2443  loss_rpn_cls: 0.04827  loss_rpn_loc: 0.1491  time: 0.2237  data_time: 0.0057  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:42:11 d2.utils.events]: \u001b[0m eta: 0:56:16  iter: 80739  total_loss: 1.187  loss_cls: 0.2867  loss_box_reg: 0.4038  loss_mask: 0.2442  loss_rpn_cls: 0.06226  loss_rpn_loc: 0.1446  time: 0.2237  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:42:15 d2.utils.events]: \u001b[0m eta: 0:56:11  iter: 80759  total_loss: 1.163  loss_cls: 0.2783  loss_box_reg: 0.3589  loss_mask: 0.2647  loss_rpn_cls: 0.08023  loss_rpn_loc: 0.1642  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:42:20 d2.utils.events]: \u001b[0m eta: 0:56:08  iter: 80779  total_loss: 1.056  loss_cls: 0.2337  loss_box_reg: 0.3137  loss_mask: 0.2639  loss_rpn_cls: 0.07862  loss_rpn_loc: 0.1654  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:42:24 d2.utils.events]: \u001b[0m eta: 0:56:04  iter: 80799  total_loss: 1.096  loss_cls: 0.2858  loss_box_reg: 0.3352  loss_mask: 0.2549  loss_rpn_cls: 0.06612  loss_rpn_loc: 0.1698  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:42:29 d2.utils.events]: \u001b[0m eta: 0:56:03  iter: 80819  total_loss: 1.157  loss_cls: 0.283  loss_box_reg: 0.3825  loss_mask: 0.2791  loss_rpn_cls: 0.06397  loss_rpn_loc: 0.1609  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:42:33 d2.utils.events]: \u001b[0m eta: 0:56:01  iter: 80839  total_loss: 1.14  loss_cls: 0.2642  loss_box_reg: 0.3644  loss_mask: 0.2613  loss_rpn_cls: 0.08365  loss_rpn_loc: 0.1755  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:42:38 d2.utils.events]: \u001b[0m eta: 0:55:58  iter: 80859  total_loss: 1.192  loss_cls: 0.2759  loss_box_reg: 0.3656  loss_mask: 0.2644  loss_rpn_cls: 0.07051  loss_rpn_loc: 0.157  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:42:42 d2.utils.events]: \u001b[0m eta: 0:55:52  iter: 80879  total_loss: 1.187  loss_cls: 0.2872  loss_box_reg: 0.3746  loss_mask: 0.2626  loss_rpn_cls: 0.06892  loss_rpn_loc: 0.17  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:42:47 d2.utils.events]: \u001b[0m eta: 0:55:52  iter: 80899  total_loss: 1.074  loss_cls: 0.2463  loss_box_reg: 0.3559  loss_mask: 0.256  loss_rpn_cls: 0.0668  loss_rpn_loc: 0.15  time: 0.2237  data_time: 0.0231  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:42:52 d2.utils.events]: \u001b[0m eta: 0:55:44  iter: 80919  total_loss: 1.08  loss_cls: 0.2729  loss_box_reg: 0.3727  loss_mask: 0.2712  loss_rpn_cls: 0.06257  loss_rpn_loc: 0.1597  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:42:56 d2.utils.events]: \u001b[0m eta: 0:55:35  iter: 80939  total_loss: 1.036  loss_cls: 0.25  loss_box_reg: 0.3279  loss_mask: 0.2486  loss_rpn_cls: 0.06529  loss_rpn_loc: 0.1498  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:43:00 d2.utils.events]: \u001b[0m eta: 0:55:29  iter: 80959  total_loss: 1.253  loss_cls: 0.309  loss_box_reg: 0.4102  loss_mask: 0.262  loss_rpn_cls: 0.0776  loss_rpn_loc: 0.167  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:43:05 d2.utils.events]: \u001b[0m eta: 0:55:26  iter: 80979  total_loss: 1.173  loss_cls: 0.2822  loss_box_reg: 0.3794  loss_mask: 0.2489  loss_rpn_cls: 0.0768  loss_rpn_loc: 0.1704  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:43:09 d2.utils.events]: \u001b[0m eta: 0:55:27  iter: 80999  total_loss: 1.196  loss_cls: 0.2851  loss_box_reg: 0.3664  loss_mask: 0.2672  loss_rpn_cls: 0.07415  loss_rpn_loc: 0.1639  time: 0.2237  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:43:14 d2.utils.events]: \u001b[0m eta: 0:55:28  iter: 81019  total_loss: 1.136  loss_cls: 0.2724  loss_box_reg: 0.3836  loss_mask: 0.2424  loss_rpn_cls: 0.07366  loss_rpn_loc: 0.1693  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:43:19 d2.utils.events]: \u001b[0m eta: 0:55:27  iter: 81039  total_loss: 1.219  loss_cls: 0.3058  loss_box_reg: 0.3876  loss_mask: 0.2651  loss_rpn_cls: 0.08867  loss_rpn_loc: 0.1857  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:43:23 d2.utils.events]: \u001b[0m eta: 0:55:25  iter: 81059  total_loss: 1.125  loss_cls: 0.2713  loss_box_reg: 0.3416  loss_mask: 0.2735  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.1558  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:43:28 d2.utils.events]: \u001b[0m eta: 0:55:21  iter: 81079  total_loss: 1.156  loss_cls: 0.2532  loss_box_reg: 0.3672  loss_mask: 0.2563  loss_rpn_cls: 0.07242  loss_rpn_loc: 0.1568  time: 0.2237  data_time: 0.0138  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:43:32 d2.utils.events]: \u001b[0m eta: 0:55:17  iter: 81099  total_loss: 1.109  loss_cls: 0.2702  loss_box_reg: 0.3385  loss_mask: 0.2147  loss_rpn_cls: 0.07091  loss_rpn_loc: 0.1604  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:43:37 d2.utils.events]: \u001b[0m eta: 0:55:15  iter: 81119  total_loss: 1.133  loss_cls: 0.2964  loss_box_reg: 0.3673  loss_mask: 0.253  loss_rpn_cls: 0.05493  loss_rpn_loc: 0.1596  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:43:41 d2.utils.events]: \u001b[0m eta: 0:55:10  iter: 81139  total_loss: 1.189  loss_cls: 0.2984  loss_box_reg: 0.3911  loss_mask: 0.2525  loss_rpn_cls: 0.07848  loss_rpn_loc: 0.1578  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:43:46 d2.utils.events]: \u001b[0m eta: 0:55:05  iter: 81159  total_loss: 1.136  loss_cls: 0.2453  loss_box_reg: 0.3746  loss_mask: 0.2588  loss_rpn_cls: 0.08205  loss_rpn_loc: 0.1544  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:43:51 d2.utils.events]: \u001b[0m eta: 0:54:59  iter: 81179  total_loss: 1.248  loss_cls: 0.3223  loss_box_reg: 0.3999  loss_mask: 0.2705  loss_rpn_cls: 0.07134  loss_rpn_loc: 0.1831  time: 0.2237  data_time: 0.0190  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:43:55 d2.utils.events]: \u001b[0m eta: 0:54:55  iter: 81199  total_loss: 1.21  loss_cls: 0.3166  loss_box_reg: 0.3908  loss_mask: 0.2793  loss_rpn_cls: 0.06336  loss_rpn_loc: 0.1542  time: 0.2237  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:43:59 d2.utils.events]: \u001b[0m eta: 0:54:51  iter: 81219  total_loss: 1.216  loss_cls: 0.3001  loss_box_reg: 0.3909  loss_mask: 0.2677  loss_rpn_cls: 0.08793  loss_rpn_loc: 0.1781  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:44:04 d2.utils.events]: \u001b[0m eta: 0:54:47  iter: 81239  total_loss: 1.21  loss_cls: 0.2912  loss_box_reg: 0.3819  loss_mask: 0.2742  loss_rpn_cls: 0.08467  loss_rpn_loc: 0.1843  time: 0.2237  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:44:08 d2.utils.events]: \u001b[0m eta: 0:54:44  iter: 81259  total_loss: 1.123  loss_cls: 0.2603  loss_box_reg: 0.3472  loss_mask: 0.2704  loss_rpn_cls: 0.07381  loss_rpn_loc: 0.1579  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:44:13 d2.utils.events]: \u001b[0m eta: 0:54:44  iter: 81279  total_loss: 1.177  loss_cls: 0.3221  loss_box_reg: 0.3846  loss_mask: 0.2655  loss_rpn_cls: 0.08817  loss_rpn_loc: 0.1785  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:44:17 d2.utils.events]: \u001b[0m eta: 0:54:40  iter: 81299  total_loss: 1.161  loss_cls: 0.2717  loss_box_reg: 0.339  loss_mask: 0.2674  loss_rpn_cls: 0.07476  loss_rpn_loc: 0.1692  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:44:22 d2.utils.events]: \u001b[0m eta: 0:54:35  iter: 81319  total_loss: 1.104  loss_cls: 0.2555  loss_box_reg: 0.3728  loss_mask: 0.246  loss_rpn_cls: 0.07125  loss_rpn_loc: 0.169  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:44:26 d2.utils.events]: \u001b[0m eta: 0:54:32  iter: 81339  total_loss: 1.005  loss_cls: 0.2361  loss_box_reg: 0.3399  loss_mask: 0.2504  loss_rpn_cls: 0.07325  loss_rpn_loc: 0.1612  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:44:31 d2.utils.events]: \u001b[0m eta: 0:54:29  iter: 81359  total_loss: 1.224  loss_cls: 0.2932  loss_box_reg: 0.405  loss_mask: 0.2576  loss_rpn_cls: 0.07413  loss_rpn_loc: 0.1834  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:44:35 d2.utils.events]: \u001b[0m eta: 0:54:26  iter: 81379  total_loss: 1.146  loss_cls: 0.2491  loss_box_reg: 0.3574  loss_mask: 0.2694  loss_rpn_cls: 0.06261  loss_rpn_loc: 0.166  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:44:40 d2.utils.events]: \u001b[0m eta: 0:54:20  iter: 81399  total_loss: 1.146  loss_cls: 0.2876  loss_box_reg: 0.3736  loss_mask: 0.2679  loss_rpn_cls: 0.07572  loss_rpn_loc: 0.1609  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:44:44 d2.utils.events]: \u001b[0m eta: 0:54:08  iter: 81419  total_loss: 1.112  loss_cls: 0.2727  loss_box_reg: 0.3958  loss_mask: 0.2442  loss_rpn_cls: 0.06207  loss_rpn_loc: 0.1671  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:44:49 d2.utils.events]: \u001b[0m eta: 0:54:04  iter: 81439  total_loss: 1.131  loss_cls: 0.2612  loss_box_reg: 0.3435  loss_mask: 0.2593  loss_rpn_cls: 0.06129  loss_rpn_loc: 0.1766  time: 0.2237  data_time: 0.0191  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:44:53 d2.utils.events]: \u001b[0m eta: 0:54:07  iter: 81459  total_loss: 1.121  loss_cls: 0.2764  loss_box_reg: 0.3397  loss_mask: 0.2545  loss_rpn_cls: 0.05488  loss_rpn_loc: 0.1753  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:44:58 d2.utils.events]: \u001b[0m eta: 0:54:02  iter: 81479  total_loss: 1.095  loss_cls: 0.2692  loss_box_reg: 0.3522  loss_mask: 0.2499  loss_rpn_cls: 0.05279  loss_rpn_loc: 0.1462  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:45:02 d2.utils.events]: \u001b[0m eta: 0:53:49  iter: 81499  total_loss: 1.097  loss_cls: 0.2622  loss_box_reg: 0.3378  loss_mask: 0.2479  loss_rpn_cls: 0.05878  loss_rpn_loc: 0.1465  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:45:07 d2.utils.events]: \u001b[0m eta: 0:53:45  iter: 81519  total_loss: 1.187  loss_cls: 0.2833  loss_box_reg: 0.3857  loss_mask: 0.2531  loss_rpn_cls: 0.08822  loss_rpn_loc: 0.1641  time: 0.2237  data_time: 0.0203  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:45:11 d2.utils.events]: \u001b[0m eta: 0:53:45  iter: 81539  total_loss: 1.096  loss_cls: 0.2637  loss_box_reg: 0.3355  loss_mask: 0.2714  loss_rpn_cls: 0.06468  loss_rpn_loc: 0.1476  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:45:16 d2.utils.events]: \u001b[0m eta: 0:53:39  iter: 81559  total_loss: 1.118  loss_cls: 0.2793  loss_box_reg: 0.3601  loss_mask: 0.2414  loss_rpn_cls: 0.04488  loss_rpn_loc: 0.1385  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:45:20 d2.utils.events]: \u001b[0m eta: 0:53:36  iter: 81579  total_loss: 1.158  loss_cls: 0.2819  loss_box_reg: 0.3372  loss_mask: 0.2571  loss_rpn_cls: 0.0801  loss_rpn_loc: 0.1658  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:45:24 d2.utils.events]: \u001b[0m eta: 0:53:35  iter: 81599  total_loss: 1.107  loss_cls: 0.261  loss_box_reg: 0.3517  loss_mask: 0.2423  loss_rpn_cls: 0.05941  loss_rpn_loc: 0.158  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:45:29 d2.utils.events]: \u001b[0m eta: 0:53:34  iter: 81619  total_loss: 1.153  loss_cls: 0.3018  loss_box_reg: 0.4185  loss_mask: 0.259  loss_rpn_cls: 0.0805  loss_rpn_loc: 0.1661  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:45:33 d2.utils.events]: \u001b[0m eta: 0:53:28  iter: 81639  total_loss: 1.023  loss_cls: 0.2427  loss_box_reg: 0.3271  loss_mask: 0.2463  loss_rpn_cls: 0.05532  loss_rpn_loc: 0.1368  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:45:38 d2.utils.events]: \u001b[0m eta: 0:53:25  iter: 81659  total_loss: 1.309  loss_cls: 0.2785  loss_box_reg: 0.3767  loss_mask: 0.2762  loss_rpn_cls: 0.08845  loss_rpn_loc: 0.1675  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:45:43 d2.utils.events]: \u001b[0m eta: 0:53:28  iter: 81679  total_loss: 1.228  loss_cls: 0.3156  loss_box_reg: 0.3944  loss_mask: 0.2601  loss_rpn_cls: 0.0835  loss_rpn_loc: 0.1844  time: 0.2237  data_time: 0.0120  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:45:47 d2.utils.events]: \u001b[0m eta: 0:53:27  iter: 81699  total_loss: 1.109  loss_cls: 0.2694  loss_box_reg: 0.339  loss_mask: 0.2437  loss_rpn_cls: 0.05898  loss_rpn_loc: 0.169  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:45:51 d2.utils.events]: \u001b[0m eta: 0:53:25  iter: 81719  total_loss: 1.156  loss_cls: 0.29  loss_box_reg: 0.3948  loss_mask: 0.2645  loss_rpn_cls: 0.04753  loss_rpn_loc: 0.1603  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:45:56 d2.utils.events]: \u001b[0m eta: 0:53:23  iter: 81739  total_loss: 1.15  loss_cls: 0.2789  loss_box_reg: 0.3687  loss_mask: 0.2583  loss_rpn_cls: 0.08322  loss_rpn_loc: 0.159  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:46:00 d2.utils.events]: \u001b[0m eta: 0:53:12  iter: 81759  total_loss: 1.231  loss_cls: 0.3126  loss_box_reg: 0.4096  loss_mask: 0.2729  loss_rpn_cls: 0.08277  loss_rpn_loc: 0.1627  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:46:05 d2.utils.events]: \u001b[0m eta: 0:53:04  iter: 81779  total_loss: 1.065  loss_cls: 0.2528  loss_box_reg: 0.3789  loss_mask: 0.2405  loss_rpn_cls: 0.05257  loss_rpn_loc: 0.156  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:46:09 d2.utils.events]: \u001b[0m eta: 0:53:04  iter: 81799  total_loss: 1.192  loss_cls: 0.3028  loss_box_reg: 0.3577  loss_mask: 0.2563  loss_rpn_cls: 0.08523  loss_rpn_loc: 0.1735  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:46:13 d2.utils.events]: \u001b[0m eta: 0:53:00  iter: 81819  total_loss: 1.082  loss_cls: 0.282  loss_box_reg: 0.3677  loss_mask: 0.2564  loss_rpn_cls: 0.05941  loss_rpn_loc: 0.1577  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:46:18 d2.utils.events]: \u001b[0m eta: 0:52:46  iter: 81839  total_loss: 1.185  loss_cls: 0.2874  loss_box_reg: 0.3572  loss_mask: 0.2698  loss_rpn_cls: 0.05767  loss_rpn_loc: 0.1517  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:46:22 d2.utils.events]: \u001b[0m eta: 0:52:41  iter: 81859  total_loss: 1.414  loss_cls: 0.3984  loss_box_reg: 0.4076  loss_mask: 0.3  loss_rpn_cls: 0.1057  loss_rpn_loc: 0.1692  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:46:27 d2.utils.events]: \u001b[0m eta: 0:52:36  iter: 81879  total_loss: 1.146  loss_cls: 0.2603  loss_box_reg: 0.368  loss_mask: 0.2487  loss_rpn_cls: 0.07672  loss_rpn_loc: 0.1658  time: 0.2237  data_time: 0.0174  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:46:32 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 3.07 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 02:46:32 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 02:46:32 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 02:46:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 02:46:33 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 02:46:33 d2.data.common]: \u001b[0mSerialized dataset takes 84.20 MiB\n",
      "\u001b[32m[12/30 02:46:36 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.44 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 02:46:36 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 02:46:36 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 02:46:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/30 02:46:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0007 s/iter. Inference: 0.0622 s/iter. Eval: 0.1488 s/iter. Total: 0.2117 s/iter. ETA=0:01:58\n",
      "\u001b[32m[12/30 02:46:44 d2.evaluation.evaluator]: \u001b[0mInference done 39/570. Dataloading: 0.0008 s/iter. Inference: 0.0577 s/iter. Eval: 0.1281 s/iter. Total: 0.1866 s/iter. ETA=0:01:39\n",
      "\u001b[32m[12/30 02:46:50 d2.evaluation.evaluator]: \u001b[0mInference done 67/570. Dataloading: 0.0009 s/iter. Inference: 0.0547 s/iter. Eval: 0.1290 s/iter. Total: 0.1846 s/iter. ETA=0:01:32\n",
      "\u001b[32m[12/30 02:46:55 d2.evaluation.evaluator]: \u001b[0mInference done 93/570. Dataloading: 0.0009 s/iter. Inference: 0.0540 s/iter. Eval: 0.1327 s/iter. Total: 0.1876 s/iter. ETA=0:01:29\n",
      "\u001b[32m[12/30 02:47:00 d2.evaluation.evaluator]: \u001b[0mInference done 120/570. Dataloading: 0.0009 s/iter. Inference: 0.0537 s/iter. Eval: 0.1330 s/iter. Total: 0.1877 s/iter. ETA=0:01:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:47:05 d2.evaluation.evaluator]: \u001b[0mInference done 145/570. Dataloading: 0.0009 s/iter. Inference: 0.0536 s/iter. Eval: 0.1366 s/iter. Total: 0.1911 s/iter. ETA=0:01:21\n",
      "\u001b[32m[12/30 02:47:10 d2.evaluation.evaluator]: \u001b[0mInference done 164/570. Dataloading: 0.0009 s/iter. Inference: 0.0535 s/iter. Eval: 0.1477 s/iter. Total: 0.2021 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 02:47:16 d2.evaluation.evaluator]: \u001b[0mInference done 177/570. Dataloading: 0.0009 s/iter. Inference: 0.0540 s/iter. Eval: 0.1634 s/iter. Total: 0.2184 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/30 02:47:21 d2.evaluation.evaluator]: \u001b[0mInference done 197/570. Dataloading: 0.0009 s/iter. Inference: 0.0542 s/iter. Eval: 0.1672 s/iter. Total: 0.2224 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 02:47:26 d2.evaluation.evaluator]: \u001b[0mInference done 211/570. Dataloading: 0.0009 s/iter. Inference: 0.0545 s/iter. Eval: 0.1768 s/iter. Total: 0.2322 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 02:47:31 d2.evaluation.evaluator]: \u001b[0mInference done 227/570. Dataloading: 0.0009 s/iter. Inference: 0.0551 s/iter. Eval: 0.1838 s/iter. Total: 0.2399 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 02:47:37 d2.evaluation.evaluator]: \u001b[0mInference done 239/570. Dataloading: 0.0009 s/iter. Inference: 0.0553 s/iter. Eval: 0.1952 s/iter. Total: 0.2515 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 02:47:42 d2.evaluation.evaluator]: \u001b[0mInference done 252/570. Dataloading: 0.0009 s/iter. Inference: 0.0556 s/iter. Eval: 0.2042 s/iter. Total: 0.2607 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 02:47:48 d2.evaluation.evaluator]: \u001b[0mInference done 267/570. Dataloading: 0.0019 s/iter. Inference: 0.0556 s/iter. Eval: 0.2078 s/iter. Total: 0.2654 s/iter. ETA=0:01:20\n",
      "\u001b[32m[12/30 02:47:53 d2.evaluation.evaluator]: \u001b[0mInference done 288/570. Dataloading: 0.0018 s/iter. Inference: 0.0555 s/iter. Eval: 0.2082 s/iter. Total: 0.2655 s/iter. ETA=0:01:14\n",
      "\u001b[32m[12/30 02:47:58 d2.evaluation.evaluator]: \u001b[0mInference done 308/570. Dataloading: 0.0017 s/iter. Inference: 0.0555 s/iter. Eval: 0.2074 s/iter. Total: 0.2647 s/iter. ETA=0:01:09\n",
      "\u001b[32m[12/30 02:48:03 d2.evaluation.evaluator]: \u001b[0mInference done 361/570. Dataloading: 0.0016 s/iter. Inference: 0.0542 s/iter. Eval: 0.1838 s/iter. Total: 0.2396 s/iter. ETA=0:00:50\n",
      "\u001b[32m[12/30 02:48:09 d2.evaluation.evaluator]: \u001b[0mInference done 381/570. Dataloading: 0.0016 s/iter. Inference: 0.0544 s/iter. Eval: 0.1847 s/iter. Total: 0.2407 s/iter. ETA=0:00:45\n",
      "\u001b[32m[12/30 02:48:14 d2.evaluation.evaluator]: \u001b[0mInference done 403/570. Dataloading: 0.0015 s/iter. Inference: 0.0544 s/iter. Eval: 0.1842 s/iter. Total: 0.2403 s/iter. ETA=0:00:40\n",
      "\u001b[32m[12/30 02:48:19 d2.evaluation.evaluator]: \u001b[0mInference done 421/570. Dataloading: 0.0015 s/iter. Inference: 0.0547 s/iter. Eval: 0.1862 s/iter. Total: 0.2425 s/iter. ETA=0:00:36\n",
      "\u001b[32m[12/30 02:48:24 d2.evaluation.evaluator]: \u001b[0mInference done 441/570. Dataloading: 0.0019 s/iter. Inference: 0.0549 s/iter. Eval: 0.1865 s/iter. Total: 0.2434 s/iter. ETA=0:00:31\n",
      "\u001b[32m[12/30 02:48:29 d2.evaluation.evaluator]: \u001b[0mInference done 475/570. Dataloading: 0.0018 s/iter. Inference: 0.0545 s/iter. Eval: 0.1801 s/iter. Total: 0.2365 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/30 02:48:34 d2.evaluation.evaluator]: \u001b[0mInference done 501/570. Dataloading: 0.0018 s/iter. Inference: 0.0543 s/iter. Eval: 0.1783 s/iter. Total: 0.2345 s/iter. ETA=0:00:16\n",
      "\u001b[32m[12/30 02:48:39 d2.evaluation.evaluator]: \u001b[0mInference done 522/570. Dataloading: 0.0017 s/iter. Inference: 0.0545 s/iter. Eval: 0.1785 s/iter. Total: 0.2347 s/iter. ETA=0:00:11\n",
      "\u001b[32m[12/30 02:48:45 d2.evaluation.evaluator]: \u001b[0mInference done 544/570. Dataloading: 0.0017 s/iter. Inference: 0.0545 s/iter. Eval: 0.1783 s/iter. Total: 0.2345 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/30 02:48:50 d2.evaluation.evaluator]: \u001b[0mInference done 561/570. Dataloading: 0.0017 s/iter. Inference: 0.0547 s/iter. Eval: 0.1801 s/iter. Total: 0.2365 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/30 02:48:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:13.640802 (0.236532 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 02:48:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:30 (0.054723 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 02:48:52 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/30 02:48:52 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.28319082607534457\n",
      "\u001b[32m[12/30 02:48:54 d2.utils.events]: \u001b[0m eta: 0:52:27  iter: 81899  total_loss: 1.095  loss_cls: 0.2757  loss_box_reg: 0.3686  loss_mask: 0.2744  loss_rpn_cls: 0.05374  loss_rpn_loc: 0.1465  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:48:59 d2.utils.events]: \u001b[0m eta: 0:52:25  iter: 81919  total_loss: 1.189  loss_cls: 0.2976  loss_box_reg: 0.3554  loss_mask: 0.2553  loss_rpn_cls: 0.06733  loss_rpn_loc: 0.179  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:49:03 d2.utils.events]: \u001b[0m eta: 0:52:20  iter: 81939  total_loss: 1.13  loss_cls: 0.2833  loss_box_reg: 0.3673  loss_mask: 0.2527  loss_rpn_cls: 0.07564  loss_rpn_loc: 0.1558  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:49:08 d2.utils.events]: \u001b[0m eta: 0:52:18  iter: 81959  total_loss: 1.297  loss_cls: 0.3086  loss_box_reg: 0.4225  loss_mask: 0.2722  loss_rpn_cls: 0.08749  loss_rpn_loc: 0.1573  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:49:12 d2.utils.events]: \u001b[0m eta: 0:52:14  iter: 81979  total_loss: 1.159  loss_cls: 0.2556  loss_box_reg: 0.3779  loss_mask: 0.2624  loss_rpn_cls: 0.06777  loss_rpn_loc: 0.1499  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:49:16 d2.utils.events]: \u001b[0m eta: 0:52:07  iter: 81999  total_loss: 1.104  loss_cls: 0.2931  loss_box_reg: 0.3598  loss_mask: 0.2383  loss_rpn_cls: 0.04174  loss_rpn_loc: 0.1543  time: 0.2237  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:49:21 d2.utils.events]: \u001b[0m eta: 0:52:02  iter: 82019  total_loss: 1.101  loss_cls: 0.2586  loss_box_reg: 0.3364  loss_mask: 0.2556  loss_rpn_cls: 0.07121  loss_rpn_loc: 0.1757  time: 0.2237  data_time: 0.0141  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:49:25 d2.utils.events]: \u001b[0m eta: 0:51:54  iter: 82039  total_loss: 1.044  loss_cls: 0.2641  loss_box_reg: 0.3913  loss_mask: 0.2391  loss_rpn_cls: 0.04655  loss_rpn_loc: 0.145  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:49:30 d2.utils.events]: \u001b[0m eta: 0:51:49  iter: 82059  total_loss: 1.151  loss_cls: 0.2869  loss_box_reg: 0.349  loss_mask: 0.2527  loss_rpn_cls: 0.08559  loss_rpn_loc: 0.1362  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:49:34 d2.utils.events]: \u001b[0m eta: 0:51:45  iter: 82079  total_loss: 1.263  loss_cls: 0.2932  loss_box_reg: 0.3698  loss_mask: 0.2597  loss_rpn_cls: 0.07967  loss_rpn_loc: 0.1652  time: 0.2237  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:49:39 d2.utils.events]: \u001b[0m eta: 0:51:41  iter: 82099  total_loss: 1.139  loss_cls: 0.2713  loss_box_reg: 0.3701  loss_mask: 0.2615  loss_rpn_cls: 0.06241  loss_rpn_loc: 0.1604  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:49:43 d2.utils.events]: \u001b[0m eta: 0:51:34  iter: 82119  total_loss: 1.123  loss_cls: 0.2697  loss_box_reg: 0.3787  loss_mask: 0.2504  loss_rpn_cls: 0.06207  loss_rpn_loc: 0.164  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:49:48 d2.utils.events]: \u001b[0m eta: 0:51:31  iter: 82139  total_loss: 1.113  loss_cls: 0.2839  loss_box_reg: 0.3503  loss_mask: 0.2586  loss_rpn_cls: 0.07049  loss_rpn_loc: 0.1576  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:49:52 d2.utils.events]: \u001b[0m eta: 0:51:25  iter: 82159  total_loss: 1.187  loss_cls: 0.3126  loss_box_reg: 0.3741  loss_mask: 0.2743  loss_rpn_cls: 0.07071  loss_rpn_loc: 0.1627  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:49:57 d2.utils.events]: \u001b[0m eta: 0:51:23  iter: 82179  total_loss: 1.217  loss_cls: 0.3154  loss_box_reg: 0.3899  loss_mask: 0.2677  loss_rpn_cls: 0.05089  loss_rpn_loc: 0.1466  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:50:01 d2.utils.events]: \u001b[0m eta: 0:51:16  iter: 82199  total_loss: 1.173  loss_cls: 0.2882  loss_box_reg: 0.3758  loss_mask: 0.2603  loss_rpn_cls: 0.07449  loss_rpn_loc: 0.1639  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:50:05 d2.utils.events]: \u001b[0m eta: 0:51:11  iter: 82219  total_loss: 1.285  loss_cls: 0.341  loss_box_reg: 0.4599  loss_mask: 0.2798  loss_rpn_cls: 0.07432  loss_rpn_loc: 0.169  time: 0.2237  data_time: 0.0151  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:50:10 d2.utils.events]: \u001b[0m eta: 0:51:07  iter: 82239  total_loss: 1.147  loss_cls: 0.2658  loss_box_reg: 0.3738  loss_mask: 0.257  loss_rpn_cls: 0.09215  loss_rpn_loc: 0.1785  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:50:14 d2.utils.events]: \u001b[0m eta: 0:51:03  iter: 82259  total_loss: 1.105  loss_cls: 0.2802  loss_box_reg: 0.3681  loss_mask: 0.2637  loss_rpn_cls: 0.06875  loss_rpn_loc: 0.1529  time: 0.2237  data_time: 0.0113  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:50:19 d2.utils.events]: \u001b[0m eta: 0:50:57  iter: 82279  total_loss: 1.139  loss_cls: 0.2631  loss_box_reg: 0.373  loss_mask: 0.2413  loss_rpn_cls: 0.05385  loss_rpn_loc: 0.1485  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:50:23 d2.utils.events]: \u001b[0m eta: 0:50:54  iter: 82299  total_loss: 1.18  loss_cls: 0.2884  loss_box_reg: 0.3781  loss_mask: 0.2505  loss_rpn_cls: 0.09313  loss_rpn_loc: 0.1864  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:50:28 d2.utils.events]: \u001b[0m eta: 0:50:52  iter: 82319  total_loss: 1.089  loss_cls: 0.2398  loss_box_reg: 0.3912  loss_mask: 0.2535  loss_rpn_cls: 0.06869  loss_rpn_loc: 0.166  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:50:32 d2.utils.events]: \u001b[0m eta: 0:50:49  iter: 82339  total_loss: 1.098  loss_cls: 0.2552  loss_box_reg: 0.3636  loss_mask: 0.2653  loss_rpn_cls: 0.06829  loss_rpn_loc: 0.1644  time: 0.2237  data_time: 0.0091  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:50:37 d2.utils.events]: \u001b[0m eta: 0:50:46  iter: 82359  total_loss: 1.186  loss_cls: 0.2803  loss_box_reg: 0.3779  loss_mask: 0.2463  loss_rpn_cls: 0.0834  loss_rpn_loc: 0.1605  time: 0.2237  data_time: 0.0123  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:50:41 d2.utils.events]: \u001b[0m eta: 0:50:40  iter: 82379  total_loss: 1.238  loss_cls: 0.2958  loss_box_reg: 0.3907  loss_mask: 0.2704  loss_rpn_cls: 0.05586  loss_rpn_loc: 0.1535  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:50:46 d2.utils.events]: \u001b[0m eta: 0:50:39  iter: 82399  total_loss: 1.14  loss_cls: 0.2796  loss_box_reg: 0.3547  loss_mask: 0.2709  loss_rpn_cls: 0.07845  loss_rpn_loc: 0.1628  time: 0.2237  data_time: 0.0089  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:50:50 d2.utils.events]: \u001b[0m eta: 0:50:33  iter: 82419  total_loss: 1.123  loss_cls: 0.2854  loss_box_reg: 0.3775  loss_mask: 0.2509  loss_rpn_cls: 0.04868  loss_rpn_loc: 0.1624  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:50:55 d2.utils.events]: \u001b[0m eta: 0:50:32  iter: 82439  total_loss: 1.074  loss_cls: 0.265  loss_box_reg: 0.3395  loss_mask: 0.2606  loss_rpn_cls: 0.08904  loss_rpn_loc: 0.1607  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:50:59 d2.utils.events]: \u001b[0m eta: 0:50:26  iter: 82459  total_loss: 1.216  loss_cls: 0.3028  loss_box_reg: 0.3736  loss_mask: 0.267  loss_rpn_cls: 0.07932  loss_rpn_loc: 0.1745  time: 0.2237  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:51:04 d2.utils.events]: \u001b[0m eta: 0:50:20  iter: 82479  total_loss: 1.091  loss_cls: 0.2562  loss_box_reg: 0.3679  loss_mask: 0.2478  loss_rpn_cls: 0.06855  loss_rpn_loc: 0.1602  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:51:08 d2.utils.events]: \u001b[0m eta: 0:50:16  iter: 82499  total_loss: 1.299  loss_cls: 0.3182  loss_box_reg: 0.4054  loss_mask: 0.2824  loss_rpn_cls: 0.09703  loss_rpn_loc: 0.1727  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:51:13 d2.utils.events]: \u001b[0m eta: 0:50:09  iter: 82519  total_loss: 1.067  loss_cls: 0.2351  loss_box_reg: 0.341  loss_mask: 0.2466  loss_rpn_cls: 0.08965  loss_rpn_loc: 0.1431  time: 0.2237  data_time: 0.0175  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:51:17 d2.utils.events]: \u001b[0m eta: 0:50:05  iter: 82539  total_loss: 1.177  loss_cls: 0.2918  loss_box_reg: 0.3521  loss_mask: 0.2525  loss_rpn_cls: 0.06945  loss_rpn_loc: 0.1689  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:51:22 d2.utils.events]: \u001b[0m eta: 0:49:58  iter: 82559  total_loss: 1.117  loss_cls: 0.2817  loss_box_reg: 0.3857  loss_mask: 0.2589  loss_rpn_cls: 0.05445  loss_rpn_loc: 0.1639  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:51:26 d2.utils.events]: \u001b[0m eta: 0:49:51  iter: 82579  total_loss: 1.173  loss_cls: 0.2914  loss_box_reg: 0.4058  loss_mask: 0.2488  loss_rpn_cls: 0.06751  loss_rpn_loc: 0.1623  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:51:30 d2.utils.events]: \u001b[0m eta: 0:49:51  iter: 82599  total_loss: 1.224  loss_cls: 0.3353  loss_box_reg: 0.3977  loss_mask: 0.2623  loss_rpn_cls: 0.06873  loss_rpn_loc: 0.1583  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:51:35 d2.utils.events]: \u001b[0m eta: 0:49:42  iter: 82619  total_loss: 1.065  loss_cls: 0.2438  loss_box_reg: 0.333  loss_mask: 0.2476  loss_rpn_cls: 0.05468  loss_rpn_loc: 0.1502  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:51:39 d2.utils.events]: \u001b[0m eta: 0:49:36  iter: 82639  total_loss: 1.093  loss_cls: 0.3033  loss_box_reg: 0.3843  loss_mask: 0.2405  loss_rpn_cls: 0.06046  loss_rpn_loc: 0.1546  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:51:43 d2.utils.events]: \u001b[0m eta: 0:49:30  iter: 82659  total_loss: 0.9882  loss_cls: 0.2291  loss_box_reg: 0.3265  loss_mask: 0.2328  loss_rpn_cls: 0.04208  loss_rpn_loc: 0.1497  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:51:48 d2.utils.events]: \u001b[0m eta: 0:49:25  iter: 82679  total_loss: 1.124  loss_cls: 0.278  loss_box_reg: 0.3969  loss_mask: 0.2511  loss_rpn_cls: 0.05427  loss_rpn_loc: 0.1459  time: 0.2237  data_time: 0.0149  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:51:52 d2.utils.events]: \u001b[0m eta: 0:49:22  iter: 82699  total_loss: 1.19  loss_cls: 0.2733  loss_box_reg: 0.4014  loss_mask: 0.2869  loss_rpn_cls: 0.07614  loss_rpn_loc: 0.1727  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:51:57 d2.utils.events]: \u001b[0m eta: 0:49:17  iter: 82719  total_loss: 1.061  loss_cls: 0.2689  loss_box_reg: 0.3647  loss_mask: 0.2382  loss_rpn_cls: 0.05856  loss_rpn_loc: 0.1384  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:52:01 d2.utils.events]: \u001b[0m eta: 0:49:13  iter: 82739  total_loss: 1.197  loss_cls: 0.2725  loss_box_reg: 0.3336  loss_mask: 0.2486  loss_rpn_cls: 0.07736  loss_rpn_loc: 0.1706  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:52:06 d2.utils.events]: \u001b[0m eta: 0:49:14  iter: 82759  total_loss: 1.003  loss_cls: 0.2491  loss_box_reg: 0.3492  loss_mask: 0.2514  loss_rpn_cls: 0.06194  loss_rpn_loc: 0.1628  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:52:11 d2.utils.events]: \u001b[0m eta: 0:49:06  iter: 82779  total_loss: 1.039  loss_cls: 0.2577  loss_box_reg: 0.3575  loss_mask: 0.2577  loss_rpn_cls: 0.07019  loss_rpn_loc: 0.1506  time: 0.2237  data_time: 0.0119  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:52:16 d2.utils.events]: \u001b[0m eta: 0:49:04  iter: 82799  total_loss: 1.251  loss_cls: 0.3131  loss_box_reg: 0.3939  loss_mask: 0.281  loss_rpn_cls: 0.08207  loss_rpn_loc: 0.1614  time: 0.2237  data_time: 0.0147  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:52:20 d2.utils.events]: \u001b[0m eta: 0:48:58  iter: 82819  total_loss: 1.147  loss_cls: 0.2584  loss_box_reg: 0.3615  loss_mask: 0.2473  loss_rpn_cls: 0.07166  loss_rpn_loc: 0.1521  time: 0.2237  data_time: 0.0097  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:52:25 d2.utils.events]: \u001b[0m eta: 0:49:02  iter: 82839  total_loss: 1.163  loss_cls: 0.2828  loss_box_reg: 0.3826  loss_mask: 0.2666  loss_rpn_cls: 0.06546  loss_rpn_loc: 0.1552  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:52:29 d2.utils.events]: \u001b[0m eta: 0:48:58  iter: 82859  total_loss: 1.056  loss_cls: 0.2401  loss_box_reg: 0.3544  loss_mask: 0.2613  loss_rpn_cls: 0.07402  loss_rpn_loc: 0.1731  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:52:34 d2.utils.events]: \u001b[0m eta: 0:48:50  iter: 82879  total_loss: 1.157  loss_cls: 0.2661  loss_box_reg: 0.39  loss_mask: 0.2543  loss_rpn_cls: 0.0643  loss_rpn_loc: 0.1604  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:52:38 d2.utils.events]: \u001b[0m eta: 0:48:46  iter: 82899  total_loss: 1.265  loss_cls: 0.2877  loss_box_reg: 0.3856  loss_mask: 0.2792  loss_rpn_cls: 0.06703  loss_rpn_loc: 0.1887  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:52:42 d2.utils.events]: \u001b[0m eta: 0:48:43  iter: 82919  total_loss: 1.061  loss_cls: 0.2613  loss_box_reg: 0.3209  loss_mask: 0.2549  loss_rpn_cls: 0.05951  loss_rpn_loc: 0.1662  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:52:47 d2.utils.events]: \u001b[0m eta: 0:48:41  iter: 82939  total_loss: 1.125  loss_cls: 0.313  loss_box_reg: 0.341  loss_mask: 0.2523  loss_rpn_cls: 0.06572  loss_rpn_loc: 0.1602  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:52:51 d2.utils.events]: \u001b[0m eta: 0:48:36  iter: 82959  total_loss: 1.116  loss_cls: 0.2733  loss_box_reg: 0.3743  loss_mask: 0.264  loss_rpn_cls: 0.07222  loss_rpn_loc: 0.1603  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:52:56 d2.utils.events]: \u001b[0m eta: 0:48:35  iter: 82979  total_loss: 1.13  loss_cls: 0.2697  loss_box_reg: 0.3291  loss_mask: 0.2505  loss_rpn_cls: 0.0854  loss_rpn_loc: 0.174  time: 0.2237  data_time: 0.0092  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:53:01 d2.utils.events]: \u001b[0m eta: 0:48:33  iter: 82999  total_loss: 1.071  loss_cls: 0.2626  loss_box_reg: 0.3561  loss_mask: 0.2469  loss_rpn_cls: 0.05308  loss_rpn_loc: 0.1869  time: 0.2237  data_time: 0.0189  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:53:05 d2.utils.events]: \u001b[0m eta: 0:48:27  iter: 83019  total_loss: 1.049  loss_cls: 0.2451  loss_box_reg: 0.3652  loss_mask: 0.2437  loss_rpn_cls: 0.04846  loss_rpn_loc: 0.1489  time: 0.2237  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:53:10 d2.utils.events]: \u001b[0m eta: 0:48:25  iter: 83039  total_loss: 1.216  loss_cls: 0.2852  loss_box_reg: 0.3814  loss_mask: 0.2717  loss_rpn_cls: 0.09676  loss_rpn_loc: 0.1655  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:53:15 d2.utils.events]: \u001b[0m eta: 0:48:21  iter: 83059  total_loss: 1.168  loss_cls: 0.3029  loss_box_reg: 0.3837  loss_mask: 0.2658  loss_rpn_cls: 0.07064  loss_rpn_loc: 0.1609  time: 0.2237  data_time: 0.0144  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:53:19 d2.utils.events]: \u001b[0m eta: 0:48:17  iter: 83079  total_loss: 1.112  loss_cls: 0.2636  loss_box_reg: 0.3548  loss_mask: 0.2543  loss_rpn_cls: 0.08245  loss_rpn_loc: 0.153  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:53:24 d2.utils.events]: \u001b[0m eta: 0:48:11  iter: 83099  total_loss: 1.066  loss_cls: 0.2445  loss_box_reg: 0.3554  loss_mask: 0.2555  loss_rpn_cls: 0.07344  loss_rpn_loc: 0.1379  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:53:29 d2.utils.events]: \u001b[0m eta: 0:48:08  iter: 83119  total_loss: 1.027  loss_cls: 0.2206  loss_box_reg: 0.3193  loss_mask: 0.257  loss_rpn_cls: 0.07194  loss_rpn_loc: 0.1674  time: 0.2237  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:53:33 d2.utils.events]: \u001b[0m eta: 0:48:03  iter: 83139  total_loss: 1.093  loss_cls: 0.2365  loss_box_reg: 0.3816  loss_mask: 0.2558  loss_rpn_cls: 0.04848  loss_rpn_loc: 0.1496  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:53:38 d2.utils.events]: \u001b[0m eta: 0:47:59  iter: 83159  total_loss: 1.078  loss_cls: 0.2475  loss_box_reg: 0.3699  loss_mask: 0.2499  loss_rpn_cls: 0.05993  loss_rpn_loc: 0.154  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:53:42 d2.utils.events]: \u001b[0m eta: 0:47:54  iter: 83179  total_loss: 1.067  loss_cls: 0.2507  loss_box_reg: 0.3713  loss_mask: 0.2505  loss_rpn_cls: 0.04744  loss_rpn_loc: 0.1554  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:53:46 d2.utils.events]: \u001b[0m eta: 0:47:51  iter: 83199  total_loss: 1.161  loss_cls: 0.2818  loss_box_reg: 0.3834  loss_mask: 0.2694  loss_rpn_cls: 0.09077  loss_rpn_loc: 0.1591  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:53:51 d2.utils.events]: \u001b[0m eta: 0:47:48  iter: 83219  total_loss: 1.074  loss_cls: 0.2609  loss_box_reg: 0.3542  loss_mask: 0.2522  loss_rpn_cls: 0.07692  loss_rpn_loc: 0.1447  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:53:55 d2.utils.events]: \u001b[0m eta: 0:47:42  iter: 83239  total_loss: 1.157  loss_cls: 0.2904  loss_box_reg: 0.3575  loss_mask: 0.2558  loss_rpn_cls: 0.07707  loss_rpn_loc: 0.201  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:53:59 d2.utils.events]: \u001b[0m eta: 0:47:37  iter: 83259  total_loss: 1.23  loss_cls: 0.3264  loss_box_reg: 0.3847  loss_mask: 0.2532  loss_rpn_cls: 0.07895  loss_rpn_loc: 0.1508  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:54:04 d2.utils.events]: \u001b[0m eta: 0:47:33  iter: 83279  total_loss: 1.112  loss_cls: 0.2421  loss_box_reg: 0.3433  loss_mask: 0.244  loss_rpn_cls: 0.08054  loss_rpn_loc: 0.1673  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:54:09 d2.utils.events]: \u001b[0m eta: 0:47:27  iter: 83299  total_loss: 1.1  loss_cls: 0.2507  loss_box_reg: 0.3395  loss_mask: 0.2692  loss_rpn_cls: 0.0665  loss_rpn_loc: 0.157  time: 0.2237  data_time: 0.0262  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:54:14 d2.utils.events]: \u001b[0m eta: 0:47:24  iter: 83319  total_loss: 1.027  loss_cls: 0.2398  loss_box_reg: 0.2785  loss_mask: 0.251  loss_rpn_cls: 0.06781  loss_rpn_loc: 0.1703  time: 0.2237  data_time: 0.0121  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:54:18 d2.utils.events]: \u001b[0m eta: 0:47:19  iter: 83339  total_loss: 1.197  loss_cls: 0.2973  loss_box_reg: 0.3732  loss_mask: 0.2784  loss_rpn_cls: 0.07679  loss_rpn_loc: 0.1514  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:54:23 d2.utils.events]: \u001b[0m eta: 0:47:15  iter: 83359  total_loss: 1.317  loss_cls: 0.3336  loss_box_reg: 0.4137  loss_mask: 0.2906  loss_rpn_cls: 0.08066  loss_rpn_loc: 0.1747  time: 0.2237  data_time: 0.0128  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:54:27 d2.utils.events]: \u001b[0m eta: 0:47:06  iter: 83379  total_loss: 1.19  loss_cls: 0.3206  loss_box_reg: 0.417  loss_mask: 0.2479  loss_rpn_cls: 0.05808  loss_rpn_loc: 0.146  time: 0.2237  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:54:32 d2.utils.events]: \u001b[0m eta: 0:47:00  iter: 83399  total_loss: 1.081  loss_cls: 0.2436  loss_box_reg: 0.3759  loss_mask: 0.2567  loss_rpn_cls: 0.06293  loss_rpn_loc: 0.1603  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:54:36 d2.utils.events]: \u001b[0m eta: 0:47:02  iter: 83419  total_loss: 1.224  loss_cls: 0.2926  loss_box_reg: 0.3713  loss_mask: 0.2707  loss_rpn_cls: 0.06824  loss_rpn_loc: 0.1528  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:54:40 d2.utils.events]: \u001b[0m eta: 0:46:54  iter: 83439  total_loss: 1.064  loss_cls: 0.2458  loss_box_reg: 0.3547  loss_mask: 0.2494  loss_rpn_cls: 0.04034  loss_rpn_loc: 0.1585  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:54:45 d2.utils.events]: \u001b[0m eta: 0:46:46  iter: 83459  total_loss: 1.155  loss_cls: 0.2534  loss_box_reg: 0.3579  loss_mask: 0.2439  loss_rpn_cls: 0.05922  loss_rpn_loc: 0.1575  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:54:49 d2.utils.events]: \u001b[0m eta: 0:46:43  iter: 83479  total_loss: 1.203  loss_cls: 0.2813  loss_box_reg: 0.3805  loss_mask: 0.2748  loss_rpn_cls: 0.0671  loss_rpn_loc: 0.1544  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:54:54 d2.utils.events]: \u001b[0m eta: 0:46:41  iter: 83499  total_loss: 1.146  loss_cls: 0.2857  loss_box_reg: 0.3934  loss_mask: 0.2629  loss_rpn_cls: 0.08868  loss_rpn_loc: 0.1702  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:54:59 d2.utils.events]: \u001b[0m eta: 0:46:37  iter: 83519  total_loss: 1.258  loss_cls: 0.3026  loss_box_reg: 0.3923  loss_mask: 0.2577  loss_rpn_cls: 0.09177  loss_rpn_loc: 0.1893  time: 0.2237  data_time: 0.0244  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:55:03 d2.utils.events]: \u001b[0m eta: 0:46:30  iter: 83539  total_loss: 1.174  loss_cls: 0.3224  loss_box_reg: 0.3652  loss_mask: 0.2582  loss_rpn_cls: 0.07221  loss_rpn_loc: 0.1646  time: 0.2237  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:55:07 d2.utils.events]: \u001b[0m eta: 0:46:29  iter: 83559  total_loss: 1.117  loss_cls: 0.2786  loss_box_reg: 0.3934  loss_mask: 0.2495  loss_rpn_cls: 0.07839  loss_rpn_loc: 0.1496  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:55:12 d2.utils.events]: \u001b[0m eta: 0:46:27  iter: 83579  total_loss: 1.096  loss_cls: 0.2442  loss_box_reg: 0.3644  loss_mask: 0.2624  loss_rpn_cls: 0.07164  loss_rpn_loc: 0.1635  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:55:16 d2.utils.events]: \u001b[0m eta: 0:46:20  iter: 83599  total_loss: 1.129  loss_cls: 0.2511  loss_box_reg: 0.3612  loss_mask: 0.2573  loss_rpn_cls: 0.06772  loss_rpn_loc: 0.1729  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:55:20 d2.utils.events]: \u001b[0m eta: 0:46:16  iter: 83619  total_loss: 1.166  loss_cls: 0.28  loss_box_reg: 0.3533  loss_mask: 0.2729  loss_rpn_cls: 0.07006  loss_rpn_loc: 0.1638  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:55:25 d2.utils.events]: \u001b[0m eta: 0:46:12  iter: 83639  total_loss: 1.192  loss_cls: 0.2876  loss_box_reg: 0.4069  loss_mask: 0.2565  loss_rpn_cls: 0.07152  loss_rpn_loc: 0.16  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:55:29 d2.utils.events]: \u001b[0m eta: 0:46:10  iter: 83659  total_loss: 1.109  loss_cls: 0.2866  loss_box_reg: 0.3378  loss_mask: 0.2521  loss_rpn_cls: 0.08874  loss_rpn_loc: 0.1569  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:55:34 d2.utils.events]: \u001b[0m eta: 0:46:06  iter: 83679  total_loss: 1.007  loss_cls: 0.2338  loss_box_reg: 0.3347  loss_mask: 0.2419  loss_rpn_cls: 0.06027  loss_rpn_loc: 0.1618  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:55:39 d2.utils.events]: \u001b[0m eta: 0:46:01  iter: 83699  total_loss: 1.132  loss_cls: 0.2684  loss_box_reg: 0.3688  loss_mask: 0.2434  loss_rpn_cls: 0.08796  loss_rpn_loc: 0.157  time: 0.2237  data_time: 0.0180  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:55:43 d2.utils.events]: \u001b[0m eta: 0:45:54  iter: 83719  total_loss: 1.255  loss_cls: 0.3269  loss_box_reg: 0.4212  loss_mask: 0.2655  loss_rpn_cls: 0.08278  loss_rpn_loc: 0.1607  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:55:47 d2.utils.events]: \u001b[0m eta: 0:45:50  iter: 83739  total_loss: 1.128  loss_cls: 0.2762  loss_box_reg: 0.3471  loss_mask: 0.2568  loss_rpn_cls: 0.0633  loss_rpn_loc: 0.1606  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:55:52 d2.utils.events]: \u001b[0m eta: 0:45:43  iter: 83759  total_loss: 1.118  loss_cls: 0.2589  loss_box_reg: 0.3303  loss_mask: 0.2549  loss_rpn_cls: 0.06539  loss_rpn_loc: 0.1569  time: 0.2237  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:55:56 d2.utils.events]: \u001b[0m eta: 0:45:40  iter: 83779  total_loss: 1.125  loss_cls: 0.2685  loss_box_reg: 0.3717  loss_mask: 0.2554  loss_rpn_cls: 0.0808  loss_rpn_loc: 0.161  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:56:00 d2.utils.events]: \u001b[0m eta: 0:45:32  iter: 83799  total_loss: 1.114  loss_cls: 0.2637  loss_box_reg: 0.3583  loss_mask: 0.2601  loss_rpn_cls: 0.0688  loss_rpn_loc: 0.1579  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:56:05 d2.utils.events]: \u001b[0m eta: 0:45:30  iter: 83819  total_loss: 1.095  loss_cls: 0.2168  loss_box_reg: 0.3754  loss_mask: 0.2578  loss_rpn_cls: 0.06584  loss_rpn_loc: 0.157  time: 0.2237  data_time: 0.0095  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:56:10 d2.utils.events]: \u001b[0m eta: 0:45:22  iter: 83839  total_loss: 1.144  loss_cls: 0.285  loss_box_reg: 0.3791  loss_mask: 0.252  loss_rpn_cls: 0.07598  loss_rpn_loc: 0.1559  time: 0.2237  data_time: 0.0146  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:56:14 d2.utils.events]: \u001b[0m eta: 0:45:19  iter: 83859  total_loss: 1.086  loss_cls: 0.2657  loss_box_reg: 0.3545  loss_mask: 0.2526  loss_rpn_cls: 0.07398  loss_rpn_loc: 0.1453  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:56:18 d2.utils.events]: \u001b[0m eta: 0:45:14  iter: 83879  total_loss: 1.17  loss_cls: 0.2801  loss_box_reg: 0.3861  loss_mask: 0.2604  loss_rpn_cls: 0.06379  loss_rpn_loc: 0.1621  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:56:23 d2.utils.events]: \u001b[0m eta: 0:45:12  iter: 83899  total_loss: 1.211  loss_cls: 0.2957  loss_box_reg: 0.4026  loss_mask: 0.2757  loss_rpn_cls: 0.07764  loss_rpn_loc: 0.1692  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:56:27 d2.utils.events]: \u001b[0m eta: 0:45:06  iter: 83919  total_loss: 1.083  loss_cls: 0.2515  loss_box_reg: 0.3715  loss_mask: 0.2496  loss_rpn_cls: 0.04954  loss_rpn_loc: 0.1444  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:56:32 d2.utils.events]: \u001b[0m eta: 0:45:02  iter: 83939  total_loss: 1.157  loss_cls: 0.2768  loss_box_reg: 0.359  loss_mask: 0.264  loss_rpn_cls: 0.07242  loss_rpn_loc: 0.1582  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:56:37 d2.utils.events]: \u001b[0m eta: 0:45:03  iter: 83959  total_loss: 1.15  loss_cls: 0.2939  loss_box_reg: 0.3528  loss_mask: 0.2464  loss_rpn_cls: 0.07844  loss_rpn_loc: 0.1737  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:56:41 d2.utils.events]: \u001b[0m eta: 0:44:52  iter: 83979  total_loss: 1.2  loss_cls: 0.2845  loss_box_reg: 0.3755  loss_mask: 0.2833  loss_rpn_cls: 0.09424  loss_rpn_loc: 0.1714  time: 0.2237  data_time: 0.0154  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:56:45 d2.utils.events]: \u001b[0m eta: 0:44:47  iter: 83999  total_loss: 1.062  loss_cls: 0.2806  loss_box_reg: 0.3431  loss_mask: 0.2562  loss_rpn_cls: 0.05818  loss_rpn_loc: 0.1554  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:56:50 d2.utils.events]: \u001b[0m eta: 0:44:43  iter: 84019  total_loss: 1.087  loss_cls: 0.2374  loss_box_reg: 0.3522  loss_mask: 0.2521  loss_rpn_cls: 0.05241  loss_rpn_loc: 0.1673  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:56:55 d2.utils.events]: \u001b[0m eta: 0:44:37  iter: 84039  total_loss: 1.12  loss_cls: 0.2517  loss_box_reg: 0.3636  loss_mask: 0.2646  loss_rpn_cls: 0.07911  loss_rpn_loc: 0.1607  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:56:59 d2.utils.events]: \u001b[0m eta: 0:44:33  iter: 84059  total_loss: 1.176  loss_cls: 0.3245  loss_box_reg: 0.3944  loss_mask: 0.2574  loss_rpn_cls: 0.09358  loss_rpn_loc: 0.1751  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:57:03 d2.utils.events]: \u001b[0m eta: 0:44:29  iter: 84079  total_loss: 1.001  loss_cls: 0.2351  loss_box_reg: 0.3372  loss_mask: 0.2588  loss_rpn_cls: 0.04799  loss_rpn_loc: 0.1437  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:57:08 d2.utils.events]: \u001b[0m eta: 0:44:26  iter: 84099  total_loss: 1.116  loss_cls: 0.2521  loss_box_reg: 0.322  loss_mask: 0.2621  loss_rpn_cls: 0.07864  loss_rpn_loc: 0.1632  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:57:12 d2.utils.events]: \u001b[0m eta: 0:44:18  iter: 84119  total_loss: 1.149  loss_cls: 0.2996  loss_box_reg: 0.371  loss_mask: 0.2391  loss_rpn_cls: 0.0605  loss_rpn_loc: 0.1523  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:57:16 d2.utils.events]: \u001b[0m eta: 0:44:13  iter: 84139  total_loss: 1.077  loss_cls: 0.2482  loss_box_reg: 0.38  loss_mask: 0.2485  loss_rpn_cls: 0.03833  loss_rpn_loc: 0.1439  time: 0.2237  data_time: 0.0057  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:57:21 d2.utils.events]: \u001b[0m eta: 0:44:11  iter: 84159  total_loss: 1.175  loss_cls: 0.2965  loss_box_reg: 0.3424  loss_mask: 0.2593  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.1594  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:57:25 d2.utils.events]: \u001b[0m eta: 0:44:06  iter: 84179  total_loss: 1.183  loss_cls: 0.3141  loss_box_reg: 0.3925  loss_mask: 0.2513  loss_rpn_cls: 0.06579  loss_rpn_loc: 0.1679  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:57:29 d2.utils.events]: \u001b[0m eta: 0:43:57  iter: 84199  total_loss: 1.004  loss_cls: 0.2544  loss_box_reg: 0.323  loss_mask: 0.2446  loss_rpn_cls: 0.0643  loss_rpn_loc: 0.1786  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:57:34 d2.utils.events]: \u001b[0m eta: 0:43:49  iter: 84219  total_loss: 1.126  loss_cls: 0.2679  loss_box_reg: 0.3605  loss_mask: 0.2635  loss_rpn_cls: 0.05455  loss_rpn_loc: 0.1458  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:57:39 d2.utils.events]: \u001b[0m eta: 0:43:52  iter: 84239  total_loss: 1.262  loss_cls: 0.3163  loss_box_reg: 0.3728  loss_mask: 0.2648  loss_rpn_cls: 0.1032  loss_rpn_loc: 0.2063  time: 0.2237  data_time: 0.0212  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:57:43 d2.utils.events]: \u001b[0m eta: 0:43:47  iter: 84259  total_loss: 1.101  loss_cls: 0.2632  loss_box_reg: 0.3888  loss_mask: 0.2368  loss_rpn_cls: 0.06807  loss_rpn_loc: 0.1593  time: 0.2237  data_time: 0.0095  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:57:48 d2.utils.events]: \u001b[0m eta: 0:43:39  iter: 84279  total_loss: 1.095  loss_cls: 0.2593  loss_box_reg: 0.3519  loss_mask: 0.2608  loss_rpn_cls: 0.04509  loss_rpn_loc: 0.1583  time: 0.2237  data_time: 0.0238  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:57:52 d2.utils.events]: \u001b[0m eta: 0:43:35  iter: 84299  total_loss: 1.201  loss_cls: 0.3209  loss_box_reg: 0.371  loss_mask: 0.2651  loss_rpn_cls: 0.06708  loss_rpn_loc: 0.1657  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:57:57 d2.utils.events]: \u001b[0m eta: 0:43:23  iter: 84319  total_loss: 1.228  loss_cls: 0.3022  loss_box_reg: 0.3927  loss_mask: 0.2483  loss_rpn_cls: 0.08514  loss_rpn_loc: 0.1428  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:58:01 d2.utils.events]: \u001b[0m eta: 0:43:26  iter: 84339  total_loss: 1.098  loss_cls: 0.2694  loss_box_reg: 0.3467  loss_mask: 0.2474  loss_rpn_cls: 0.06726  loss_rpn_loc: 0.1503  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:58:05 d2.utils.events]: \u001b[0m eta: 0:43:20  iter: 84359  total_loss: 0.9927  loss_cls: 0.2438  loss_box_reg: 0.3341  loss_mask: 0.2507  loss_rpn_cls: 0.05647  loss_rpn_loc: 0.1476  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:58:10 d2.utils.events]: \u001b[0m eta: 0:43:18  iter: 84379  total_loss: 1.25  loss_cls: 0.3101  loss_box_reg: 0.4202  loss_mask: 0.2704  loss_rpn_cls: 0.07233  loss_rpn_loc: 0.1621  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:58:14 d2.utils.events]: \u001b[0m eta: 0:43:09  iter: 84399  total_loss: 1.242  loss_cls: 0.3235  loss_box_reg: 0.4029  loss_mask: 0.2561  loss_rpn_cls: 0.08402  loss_rpn_loc: 0.1477  time: 0.2237  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:58:18 d2.utils.events]: \u001b[0m eta: 0:43:00  iter: 84419  total_loss: 1.197  loss_cls: 0.3028  loss_box_reg: 0.3621  loss_mask: 0.2492  loss_rpn_cls: 0.07038  loss_rpn_loc: 0.1726  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:58:23 d2.utils.events]: \u001b[0m eta: 0:42:55  iter: 84439  total_loss: 1.041  loss_cls: 0.2262  loss_box_reg: 0.3381  loss_mask: 0.2446  loss_rpn_cls: 0.05565  loss_rpn_loc: 0.1603  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:58:27 d2.utils.events]: \u001b[0m eta: 0:42:55  iter: 84459  total_loss: 1.165  loss_cls: 0.2633  loss_box_reg: 0.3927  loss_mask: 0.2607  loss_rpn_cls: 0.06986  loss_rpn_loc: 0.1626  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:58:32 d2.utils.events]: \u001b[0m eta: 0:42:53  iter: 84479  total_loss: 1.401  loss_cls: 0.3413  loss_box_reg: 0.4191  loss_mask: 0.2759  loss_rpn_cls: 0.0896  loss_rpn_loc: 0.19  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:58:36 d2.utils.events]: \u001b[0m eta: 0:42:51  iter: 84499  total_loss: 1.098  loss_cls: 0.2562  loss_box_reg: 0.3113  loss_mask: 0.2465  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.1586  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:58:41 d2.utils.events]: \u001b[0m eta: 0:42:47  iter: 84519  total_loss: 1.048  loss_cls: 0.2582  loss_box_reg: 0.3489  loss_mask: 0.2326  loss_rpn_cls: 0.06861  loss_rpn_loc: 0.1514  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:58:45 d2.utils.events]: \u001b[0m eta: 0:42:43  iter: 84539  total_loss: 1.178  loss_cls: 0.2744  loss_box_reg: 0.4097  loss_mask: 0.2685  loss_rpn_cls: 0.06721  loss_rpn_loc: 0.1542  time: 0.2237  data_time: 0.0223  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:58:50 d2.utils.events]: \u001b[0m eta: 0:42:43  iter: 84559  total_loss: 1.107  loss_cls: 0.2227  loss_box_reg: 0.3659  loss_mask: 0.2562  loss_rpn_cls: 0.06956  loss_rpn_loc: 0.1642  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:58:54 d2.utils.events]: \u001b[0m eta: 0:42:35  iter: 84579  total_loss: 1.148  loss_cls: 0.2799  loss_box_reg: 0.3682  loss_mask: 0.246  loss_rpn_cls: 0.06235  loss_rpn_loc: 0.158  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:58:59 d2.utils.events]: \u001b[0m eta: 0:42:34  iter: 84599  total_loss: 1.266  loss_cls: 0.2974  loss_box_reg: 0.3971  loss_mask: 0.2724  loss_rpn_cls: 0.0871  loss_rpn_loc: 0.1768  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:59:04 d2.utils.events]: \u001b[0m eta: 0:42:31  iter: 84619  total_loss: 1.059  loss_cls: 0.2572  loss_box_reg: 0.3451  loss_mask: 0.2582  loss_rpn_cls: 0.06597  loss_rpn_loc: 0.1569  time: 0.2237  data_time: 0.0288  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:59:08 d2.utils.events]: \u001b[0m eta: 0:42:34  iter: 84639  total_loss: 1.175  loss_cls: 0.2752  loss_box_reg: 0.3801  loss_mask: 0.2595  loss_rpn_cls: 0.07969  loss_rpn_loc: 0.1591  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:59:13 d2.utils.events]: \u001b[0m eta: 0:42:28  iter: 84659  total_loss: 1.102  loss_cls: 0.2724  loss_box_reg: 0.3189  loss_mask: 0.2637  loss_rpn_cls: 0.05893  loss_rpn_loc: 0.1535  time: 0.2237  data_time: 0.0111  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:59:18 d2.utils.events]: \u001b[0m eta: 0:42:24  iter: 84679  total_loss: 0.9534  loss_cls: 0.2177  loss_box_reg: 0.2808  loss_mask: 0.2361  loss_rpn_cls: 0.04003  loss_rpn_loc: 0.1556  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:59:22 d2.utils.events]: \u001b[0m eta: 0:42:24  iter: 84699  total_loss: 1.068  loss_cls: 0.2371  loss_box_reg: 0.3192  loss_mask: 0.2578  loss_rpn_cls: 0.06896  loss_rpn_loc: 0.1735  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:59:27 d2.utils.events]: \u001b[0m eta: 0:42:23  iter: 84719  total_loss: 0.9804  loss_cls: 0.2408  loss_box_reg: 0.3256  loss_mask: 0.2352  loss_rpn_cls: 0.05292  loss_rpn_loc: 0.1478  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:59:32 d2.utils.events]: \u001b[0m eta: 0:42:22  iter: 84739  total_loss: 1.187  loss_cls: 0.2804  loss_box_reg: 0.3747  loss_mask: 0.2686  loss_rpn_cls: 0.07031  loss_rpn_loc: 0.1815  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:59:36 d2.utils.events]: \u001b[0m eta: 0:42:19  iter: 84759  total_loss: 1.214  loss_cls: 0.2916  loss_box_reg: 0.3961  loss_mask: 0.2827  loss_rpn_cls: 0.07844  loss_rpn_loc: 0.1679  time: 0.2237  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:59:40 d2.utils.events]: \u001b[0m eta: 0:42:13  iter: 84779  total_loss: 1.258  loss_cls: 0.3096  loss_box_reg: 0.4356  loss_mask: 0.2784  loss_rpn_cls: 0.07076  loss_rpn_loc: 0.1961  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:59:45 d2.utils.events]: \u001b[0m eta: 0:42:09  iter: 84799  total_loss: 1.264  loss_cls: 0.2973  loss_box_reg: 0.363  loss_mask: 0.2708  loss_rpn_cls: 0.08353  loss_rpn_loc: 0.175  time: 0.2237  data_time: 0.0160  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:59:49 d2.utils.events]: \u001b[0m eta: 0:42:04  iter: 84819  total_loss: 1.101  loss_cls: 0.2977  loss_box_reg: 0.4032  loss_mask: 0.2439  loss_rpn_cls: 0.05763  loss_rpn_loc: 0.1479  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 02:59:54 d2.utils.events]: \u001b[0m eta: 0:42:00  iter: 84839  total_loss: 1.074  loss_cls: 0.2727  loss_box_reg: 0.3251  loss_mask: 0.2492  loss_rpn_cls: 0.05828  loss_rpn_loc: 0.1551  time: 0.2237  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 02:59:59 d2.utils.events]: \u001b[0m eta: 0:41:56  iter: 84859  total_loss: 1.08  loss_cls: 0.3109  loss_box_reg: 0.3537  loss_mask: 0.249  loss_rpn_cls: 0.07994  loss_rpn_loc: 0.1499  time: 0.2237  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:00:04 d2.utils.events]: \u001b[0m eta: 0:41:55  iter: 84879  total_loss: 1.197  loss_cls: 0.2976  loss_box_reg: 0.4128  loss_mask: 0.264  loss_rpn_cls: 0.06376  loss_rpn_loc: 0.1575  time: 0.2237  data_time: 0.0274  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:00:08 d2.utils.events]: \u001b[0m eta: 0:41:47  iter: 84899  total_loss: 1.152  loss_cls: 0.2573  loss_box_reg: 0.3508  loss_mask: 0.2528  loss_rpn_cls: 0.05299  loss_rpn_loc: 0.1718  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:00:12 d2.utils.events]: \u001b[0m eta: 0:41:43  iter: 84919  total_loss: 1.02  loss_cls: 0.2299  loss_box_reg: 0.3383  loss_mask: 0.2404  loss_rpn_cls: 0.05305  loss_rpn_loc: 0.1706  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:00:17 d2.utils.events]: \u001b[0m eta: 0:41:41  iter: 84939  total_loss: 1.2  loss_cls: 0.2974  loss_box_reg: 0.3755  loss_mask: 0.2631  loss_rpn_cls: 0.09754  loss_rpn_loc: 0.1661  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:00:22 d2.utils.events]: \u001b[0m eta: 0:41:36  iter: 84959  total_loss: 1.192  loss_cls: 0.2926  loss_box_reg: 0.3745  loss_mask: 0.2577  loss_rpn_cls: 0.07167  loss_rpn_loc: 0.1653  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:00:26 d2.utils.events]: \u001b[0m eta: 0:41:31  iter: 84979  total_loss: 1.083  loss_cls: 0.2519  loss_box_reg: 0.3594  loss_mask: 0.2794  loss_rpn_cls: 0.04665  loss_rpn_loc: 0.1471  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:00:30 d2.utils.events]: \u001b[0m eta: 0:41:25  iter: 84999  total_loss: 1.206  loss_cls: 0.2744  loss_box_reg: 0.4085  loss_mask: 0.2543  loss_rpn_cls: 0.05414  loss_rpn_loc: 0.1617  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:00:35 d2.utils.events]: \u001b[0m eta: 0:41:21  iter: 85019  total_loss: 1.132  loss_cls: 0.248  loss_box_reg: 0.3508  loss_mask: 0.262  loss_rpn_cls: 0.06949  loss_rpn_loc: 0.1636  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:00:39 d2.utils.events]: \u001b[0m eta: 0:41:16  iter: 85039  total_loss: 1.161  loss_cls: 0.2793  loss_box_reg: 0.3737  loss_mask: 0.2616  loss_rpn_cls: 0.06137  loss_rpn_loc: 0.1448  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:00:44 d2.utils.events]: \u001b[0m eta: 0:41:11  iter: 85059  total_loss: 1.274  loss_cls: 0.3164  loss_box_reg: 0.4158  loss_mask: 0.2799  loss_rpn_cls: 0.09653  loss_rpn_loc: 0.181  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:00:48 d2.utils.events]: \u001b[0m eta: 0:41:06  iter: 85079  total_loss: 1.224  loss_cls: 0.3096  loss_box_reg: 0.3943  loss_mask: 0.254  loss_rpn_cls: 0.05439  loss_rpn_loc: 0.1801  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:00:53 d2.utils.events]: \u001b[0m eta: 0:40:59  iter: 85099  total_loss: 1.199  loss_cls: 0.2822  loss_box_reg: 0.3923  loss_mask: 0.2679  loss_rpn_cls: 0.07437  loss_rpn_loc: 0.175  time: 0.2237  data_time: 0.0180  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:00:57 d2.utils.events]: \u001b[0m eta: 0:40:57  iter: 85119  total_loss: 1.209  loss_cls: 0.3074  loss_box_reg: 0.3655  loss_mask: 0.2733  loss_rpn_cls: 0.09391  loss_rpn_loc: 0.1901  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:01:02 d2.utils.events]: \u001b[0m eta: 0:40:54  iter: 85139  total_loss: 1.302  loss_cls: 0.304  loss_box_reg: 0.3933  loss_mask: 0.2974  loss_rpn_cls: 0.1058  loss_rpn_loc: 0.1628  time: 0.2237  data_time: 0.0145  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:01:06 d2.utils.events]: \u001b[0m eta: 0:40:49  iter: 85159  total_loss: 1.04  loss_cls: 0.271  loss_box_reg: 0.327  loss_mask: 0.2436  loss_rpn_cls: 0.06425  loss_rpn_loc: 0.1453  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:01:10 d2.utils.events]: \u001b[0m eta: 0:40:44  iter: 85179  total_loss: 1.21  loss_cls: 0.2965  loss_box_reg: 0.3954  loss_mask: 0.2555  loss_rpn_cls: 0.05341  loss_rpn_loc: 0.1617  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:01:15 d2.utils.events]: \u001b[0m eta: 0:40:40  iter: 85199  total_loss: 1.111  loss_cls: 0.284  loss_box_reg: 0.3935  loss_mask: 0.2434  loss_rpn_cls: 0.06222  loss_rpn_loc: 0.1543  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:01:19 d2.utils.events]: \u001b[0m eta: 0:40:37  iter: 85219  total_loss: 1.234  loss_cls: 0.282  loss_box_reg: 0.3816  loss_mask: 0.2754  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.1844  time: 0.2237  data_time: 0.0089  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:01:24 d2.utils.events]: \u001b[0m eta: 0:40:33  iter: 85239  total_loss: 1.164  loss_cls: 0.2885  loss_box_reg: 0.3632  loss_mask: 0.2506  loss_rpn_cls: 0.08763  loss_rpn_loc: 0.1609  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:01:28 d2.utils.events]: \u001b[0m eta: 0:40:29  iter: 85259  total_loss: 1.073  loss_cls: 0.2441  loss_box_reg: 0.3544  loss_mask: 0.2538  loss_rpn_cls: 0.05992  loss_rpn_loc: 0.1519  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:01:33 d2.utils.events]: \u001b[0m eta: 0:40:26  iter: 85279  total_loss: 1.254  loss_cls: 0.3068  loss_box_reg: 0.3598  loss_mask: 0.268  loss_rpn_cls: 0.06876  loss_rpn_loc: 0.1633  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:01:37 d2.utils.events]: \u001b[0m eta: 0:40:25  iter: 85299  total_loss: 1.272  loss_cls: 0.3295  loss_box_reg: 0.4152  loss_mask: 0.2883  loss_rpn_cls: 0.07674  loss_rpn_loc: 0.1745  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:01:42 d2.utils.events]: \u001b[0m eta: 0:40:18  iter: 85319  total_loss: 1.118  loss_cls: 0.2921  loss_box_reg: 0.3747  loss_mask: 0.2479  loss_rpn_cls: 0.0527  loss_rpn_loc: 0.1518  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:01:46 d2.utils.events]: \u001b[0m eta: 0:40:13  iter: 85339  total_loss: 1.112  loss_cls: 0.286  loss_box_reg: 0.365  loss_mask: 0.2651  loss_rpn_cls: 0.07469  loss_rpn_loc: 0.165  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:01:50 d2.utils.events]: \u001b[0m eta: 0:40:09  iter: 85359  total_loss: 1.189  loss_cls: 0.295  loss_box_reg: 0.414  loss_mask: 0.2747  loss_rpn_cls: 0.08806  loss_rpn_loc: 0.1555  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:01:55 d2.utils.events]: \u001b[0m eta: 0:40:04  iter: 85379  total_loss: 1.107  loss_cls: 0.2585  loss_box_reg: 0.3694  loss_mask: 0.2583  loss_rpn_cls: 0.06928  loss_rpn_loc: 0.1506  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:01:59 d2.utils.events]: \u001b[0m eta: 0:40:00  iter: 85399  total_loss: 1.171  loss_cls: 0.2863  loss_box_reg: 0.3628  loss_mask: 0.2581  loss_rpn_cls: 0.06734  loss_rpn_loc: 0.1587  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:02:04 d2.utils.events]: \u001b[0m eta: 0:39:58  iter: 85419  total_loss: 1.234  loss_cls: 0.2842  loss_box_reg: 0.4106  loss_mask: 0.2884  loss_rpn_cls: 0.06625  loss_rpn_loc: 0.1591  time: 0.2237  data_time: 0.0261  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:02:08 d2.utils.events]: \u001b[0m eta: 0:39:52  iter: 85439  total_loss: 1.199  loss_cls: 0.2752  loss_box_reg: 0.3918  loss_mask: 0.2497  loss_rpn_cls: 0.06504  loss_rpn_loc: 0.1476  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:02:13 d2.utils.events]: \u001b[0m eta: 0:39:47  iter: 85459  total_loss: 1.233  loss_cls: 0.255  loss_box_reg: 0.413  loss_mask: 0.2714  loss_rpn_cls: 0.07745  loss_rpn_loc: 0.1688  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:02:18 d2.utils.events]: \u001b[0m eta: 0:39:43  iter: 85479  total_loss: 1.208  loss_cls: 0.293  loss_box_reg: 0.398  loss_mask: 0.2592  loss_rpn_cls: 0.08186  loss_rpn_loc: 0.1626  time: 0.2237  data_time: 0.0215  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:02:22 d2.utils.events]: \u001b[0m eta: 0:39:37  iter: 85499  total_loss: 1.086  loss_cls: 0.2698  loss_box_reg: 0.3404  loss_mask: 0.2516  loss_rpn_cls: 0.05341  loss_rpn_loc: 0.1509  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 03:02:27 d2.utils.events]: \u001b[0m eta: 0:39:33  iter: 85519  total_loss: 1.169  loss_cls: 0.3074  loss_box_reg: 0.3543  loss_mask: 0.262  loss_rpn_cls: 0.09451  loss_rpn_loc: 0.1532  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:02:31 d2.utils.events]: \u001b[0m eta: 0:39:30  iter: 85539  total_loss: 1.091  loss_cls: 0.2597  loss_box_reg: 0.3441  loss_mask: 0.2384  loss_rpn_cls: 0.05968  loss_rpn_loc: 0.1574  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:02:35 d2.utils.events]: \u001b[0m eta: 0:39:25  iter: 85559  total_loss: 1.173  loss_cls: 0.2941  loss_box_reg: 0.3522  loss_mask: 0.246  loss_rpn_cls: 0.07246  loss_rpn_loc: 0.1647  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:02:40 d2.utils.events]: \u001b[0m eta: 0:39:23  iter: 85579  total_loss: 1.159  loss_cls: 0.2779  loss_box_reg: 0.3823  loss_mask: 0.2502  loss_rpn_cls: 0.07513  loss_rpn_loc: 0.1594  time: 0.2237  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:02:44 d2.utils.events]: \u001b[0m eta: 0:39:17  iter: 85599  total_loss: 1.085  loss_cls: 0.2674  loss_box_reg: 0.3578  loss_mask: 0.254  loss_rpn_cls: 0.06571  loss_rpn_loc: 0.1525  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:02:49 d2.utils.events]: \u001b[0m eta: 0:39:13  iter: 85619  total_loss: 1.241  loss_cls: 0.2722  loss_box_reg: 0.3705  loss_mask: 0.2703  loss_rpn_cls: 0.09102  loss_rpn_loc: 0.1697  time: 0.2237  data_time: 0.0276  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:02:54 d2.utils.events]: \u001b[0m eta: 0:39:08  iter: 85639  total_loss: 1.156  loss_cls: 0.2969  loss_box_reg: 0.3423  loss_mask: 0.2556  loss_rpn_cls: 0.07516  loss_rpn_loc: 0.1827  time: 0.2237  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:02:58 d2.utils.events]: \u001b[0m eta: 0:39:02  iter: 85659  total_loss: 1.185  loss_cls: 0.3104  loss_box_reg: 0.3655  loss_mask: 0.2523  loss_rpn_cls: 0.06613  loss_rpn_loc: 0.1518  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:03:03 d2.utils.events]: \u001b[0m eta: 0:38:58  iter: 85679  total_loss: 1.224  loss_cls: 0.3032  loss_box_reg: 0.4122  loss_mask: 0.2602  loss_rpn_cls: 0.07847  loss_rpn_loc: 0.1564  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:03:07 d2.utils.events]: \u001b[0m eta: 0:38:51  iter: 85699  total_loss: 1.004  loss_cls: 0.2485  loss_box_reg: 0.3616  loss_mask: 0.2373  loss_rpn_cls: 0.06202  loss_rpn_loc: 0.1515  time: 0.2237  data_time: 0.0091  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:03:11 d2.utils.events]: \u001b[0m eta: 0:38:45  iter: 85719  total_loss: 1.296  loss_cls: 0.321  loss_box_reg: 0.3931  loss_mask: 0.2772  loss_rpn_cls: 0.08831  loss_rpn_loc: 0.1839  time: 0.2237  data_time: 0.0165  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:03:16 d2.utils.events]: \u001b[0m eta: 0:38:40  iter: 85739  total_loss: 1.117  loss_cls: 0.2779  loss_box_reg: 0.3486  loss_mask: 0.2547  loss_rpn_cls: 0.07019  loss_rpn_loc: 0.177  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:03:20 d2.utils.events]: \u001b[0m eta: 0:38:34  iter: 85759  total_loss: 1.162  loss_cls: 0.2865  loss_box_reg: 0.3872  loss_mask: 0.2528  loss_rpn_cls: 0.07047  loss_rpn_loc: 0.1664  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:03:25 d2.utils.events]: \u001b[0m eta: 0:38:32  iter: 85779  total_loss: 1.138  loss_cls: 0.2969  loss_box_reg: 0.3866  loss_mask: 0.2633  loss_rpn_cls: 0.08576  loss_rpn_loc: 0.1604  time: 0.2237  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:03:29 d2.utils.events]: \u001b[0m eta: 0:38:24  iter: 85799  total_loss: 1.25  loss_cls: 0.3428  loss_box_reg: 0.4118  loss_mask: 0.2674  loss_rpn_cls: 0.07312  loss_rpn_loc: 0.1586  time: 0.2237  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:03:33 d2.utils.events]: \u001b[0m eta: 0:38:17  iter: 85819  total_loss: 1.141  loss_cls: 0.2983  loss_box_reg: 0.351  loss_mask: 0.2461  loss_rpn_cls: 0.05905  loss_rpn_loc: 0.1471  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:03:38 d2.utils.events]: \u001b[0m eta: 0:38:13  iter: 85839  total_loss: 1.219  loss_cls: 0.2949  loss_box_reg: 0.3901  loss_mask: 0.2826  loss_rpn_cls: 0.07619  loss_rpn_loc: 0.1672  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:03:42 d2.utils.events]: \u001b[0m eta: 0:38:09  iter: 85859  total_loss: 1.033  loss_cls: 0.2332  loss_box_reg: 0.3213  loss_mask: 0.2581  loss_rpn_cls: 0.04957  loss_rpn_loc: 0.1496  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:03:47 d2.utils.events]: \u001b[0m eta: 0:38:04  iter: 85879  total_loss: 1.13  loss_cls: 0.2818  loss_box_reg: 0.3738  loss_mask: 0.244  loss_rpn_cls: 0.08735  loss_rpn_loc: 0.1663  time: 0.2237  data_time: 0.0166  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:03:51 d2.utils.events]: \u001b[0m eta: 0:37:59  iter: 85899  total_loss: 1.085  loss_cls: 0.2754  loss_box_reg: 0.3505  loss_mask: 0.2547  loss_rpn_cls: 0.06886  loss_rpn_loc: 0.1777  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:03:56 d2.utils.events]: \u001b[0m eta: 0:37:55  iter: 85919  total_loss: 1.206  loss_cls: 0.3138  loss_box_reg: 0.4191  loss_mask: 0.2724  loss_rpn_cls: 0.0627  loss_rpn_loc: 0.1537  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:04:00 d2.utils.events]: \u001b[0m eta: 0:37:47  iter: 85939  total_loss: 1.194  loss_cls: 0.3076  loss_box_reg: 0.4006  loss_mask: 0.2621  loss_rpn_cls: 0.06714  loss_rpn_loc: 0.1542  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:04:04 d2.utils.events]: \u001b[0m eta: 0:37:36  iter: 85959  total_loss: 1.095  loss_cls: 0.227  loss_box_reg: 0.3517  loss_mask: 0.2394  loss_rpn_cls: 0.05474  loss_rpn_loc: 0.1498  time: 0.2237  data_time: 0.0110  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:04:09 d2.utils.events]: \u001b[0m eta: 0:37:32  iter: 85979  total_loss: 1.106  loss_cls: 0.2927  loss_box_reg: 0.378  loss_mask: 0.2421  loss_rpn_cls: 0.04427  loss_rpn_loc: 0.1416  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:04:13 d2.utils.events]: \u001b[0m eta: 0:37:31  iter: 85999  total_loss: 1.198  loss_cls: 0.326  loss_box_reg: 0.4251  loss_mask: 0.2542  loss_rpn_cls: 0.06295  loss_rpn_loc: 0.1531  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:04:18 d2.utils.events]: \u001b[0m eta: 0:37:29  iter: 86019  total_loss: 1.109  loss_cls: 0.2607  loss_box_reg: 0.3621  loss_mask: 0.2544  loss_rpn_cls: 0.08248  loss_rpn_loc: 0.1689  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:04:22 d2.utils.events]: \u001b[0m eta: 0:37:27  iter: 86039  total_loss: 1.154  loss_cls: 0.2862  loss_box_reg: 0.3833  loss_mask: 0.2722  loss_rpn_cls: 0.03976  loss_rpn_loc: 0.1407  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:04:27 d2.utils.events]: \u001b[0m eta: 0:37:22  iter: 86059  total_loss: 1.067  loss_cls: 0.2577  loss_box_reg: 0.3608  loss_mask: 0.2489  loss_rpn_cls: 0.04907  loss_rpn_loc: 0.1482  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:04:31 d2.utils.events]: \u001b[0m eta: 0:37:20  iter: 86079  total_loss: 1.259  loss_cls: 0.3276  loss_box_reg: 0.3844  loss_mask: 0.2743  loss_rpn_cls: 0.08676  loss_rpn_loc: 0.1607  time: 0.2237  data_time: 0.0163  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:04:36 d2.utils.events]: \u001b[0m eta: 0:37:16  iter: 86099  total_loss: 1.229  loss_cls: 0.3331  loss_box_reg: 0.3721  loss_mask: 0.2677  loss_rpn_cls: 0.0974  loss_rpn_loc: 0.1827  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:04:40 d2.utils.events]: \u001b[0m eta: 0:37:12  iter: 86119  total_loss: 1.142  loss_cls: 0.2704  loss_box_reg: 0.364  loss_mask: 0.2549  loss_rpn_cls: 0.05952  loss_rpn_loc: 0.1585  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:04:45 d2.utils.events]: \u001b[0m eta: 0:37:07  iter: 86139  total_loss: 1.172  loss_cls: 0.3004  loss_box_reg: 0.3285  loss_mask: 0.2668  loss_rpn_cls: 0.07246  loss_rpn_loc: 0.1613  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:04:49 d2.utils.events]: \u001b[0m eta: 0:37:02  iter: 86159  total_loss: 1.158  loss_cls: 0.2889  loss_box_reg: 0.3744  loss_mask: 0.2768  loss_rpn_cls: 0.04937  loss_rpn_loc: 0.1487  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 03:04:53 d2.utils.events]: \u001b[0m eta: 0:36:58  iter: 86179  total_loss: 1.229  loss_cls: 0.2793  loss_box_reg: 0.3958  loss_mask: 0.2751  loss_rpn_cls: 0.0853  loss_rpn_loc: 0.1647  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:04:58 d2.utils.events]: \u001b[0m eta: 0:36:55  iter: 86199  total_loss: 1.276  loss_cls: 0.3015  loss_box_reg: 0.354  loss_mask: 0.2732  loss_rpn_cls: 0.09503  loss_rpn_loc: 0.179  time: 0.2237  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:05:03 d2.utils.events]: \u001b[0m eta: 0:36:49  iter: 86219  total_loss: 1.141  loss_cls: 0.284  loss_box_reg: 0.3567  loss_mask: 0.2745  loss_rpn_cls: 0.09716  loss_rpn_loc: 0.1745  time: 0.2237  data_time: 0.0177  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:05:07 d2.utils.events]: \u001b[0m eta: 0:36:43  iter: 86239  total_loss: 1.096  loss_cls: 0.2888  loss_box_reg: 0.3782  loss_mask: 0.2516  loss_rpn_cls: 0.04946  loss_rpn_loc: 0.1593  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:05:12 d2.utils.events]: \u001b[0m eta: 0:36:38  iter: 86259  total_loss: 1.021  loss_cls: 0.2348  loss_box_reg: 0.3134  loss_mask: 0.2466  loss_rpn_cls: 0.06312  loss_rpn_loc: 0.1518  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:05:17 d2.utils.events]: \u001b[0m eta: 0:36:34  iter: 86279  total_loss: 1.181  loss_cls: 0.2751  loss_box_reg: 0.3842  loss_mask: 0.2702  loss_rpn_cls: 0.07277  loss_rpn_loc: 0.1699  time: 0.2237  data_time: 0.0167  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:05:21 d2.utils.events]: \u001b[0m eta: 0:36:29  iter: 86299  total_loss: 1.124  loss_cls: 0.2426  loss_box_reg: 0.2942  loss_mask: 0.2617  loss_rpn_cls: 0.06455  loss_rpn_loc: 0.1632  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:05:26 d2.utils.events]: \u001b[0m eta: 0:36:26  iter: 86319  total_loss: 1.109  loss_cls: 0.2741  loss_box_reg: 0.3709  loss_mask: 0.2574  loss_rpn_cls: 0.05518  loss_rpn_loc: 0.1482  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:05:30 d2.utils.events]: \u001b[0m eta: 0:36:23  iter: 86339  total_loss: 1.14  loss_cls: 0.2745  loss_box_reg: 0.3404  loss_mask: 0.2719  loss_rpn_cls: 0.05996  loss_rpn_loc: 0.1399  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:05:35 d2.utils.events]: \u001b[0m eta: 0:36:18  iter: 86359  total_loss: 1.141  loss_cls: 0.2743  loss_box_reg: 0.3746  loss_mask: 0.2534  loss_rpn_cls: 0.05373  loss_rpn_loc: 0.1657  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:05:39 d2.utils.events]: \u001b[0m eta: 0:36:16  iter: 86379  total_loss: 0.9876  loss_cls: 0.2219  loss_box_reg: 0.2941  loss_mask: 0.2484  loss_rpn_cls: 0.06745  loss_rpn_loc: 0.1605  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:05:44 d2.utils.events]: \u001b[0m eta: 0:36:09  iter: 86399  total_loss: 1  loss_cls: 0.2371  loss_box_reg: 0.3219  loss_mask: 0.2394  loss_rpn_cls: 0.05828  loss_rpn_loc: 0.1396  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:05:48 d2.utils.events]: \u001b[0m eta: 0:36:05  iter: 86419  total_loss: 1.041  loss_cls: 0.2338  loss_box_reg: 0.3551  loss_mask: 0.2324  loss_rpn_cls: 0.04686  loss_rpn_loc: 0.1626  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:05:52 d2.utils.events]: \u001b[0m eta: 0:36:02  iter: 86439  total_loss: 1.113  loss_cls: 0.2752  loss_box_reg: 0.3581  loss_mask: 0.2423  loss_rpn_cls: 0.07297  loss_rpn_loc: 0.1656  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:05:57 d2.utils.events]: \u001b[0m eta: 0:35:55  iter: 86459  total_loss: 1.071  loss_cls: 0.2693  loss_box_reg: 0.367  loss_mask: 0.2377  loss_rpn_cls: 0.0489  loss_rpn_loc: 0.1399  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:06:01 d2.utils.events]: \u001b[0m eta: 0:35:48  iter: 86479  total_loss: 1.03  loss_cls: 0.2285  loss_box_reg: 0.324  loss_mask: 0.2568  loss_rpn_cls: 0.0509  loss_rpn_loc: 0.1422  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:06:05 d2.utils.events]: \u001b[0m eta: 0:35:46  iter: 86499  total_loss: 1.175  loss_cls: 0.2794  loss_box_reg: 0.344  loss_mask: 0.2573  loss_rpn_cls: 0.08704  loss_rpn_loc: 0.1732  time: 0.2237  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:06:10 d2.utils.events]: \u001b[0m eta: 0:35:39  iter: 86519  total_loss: 1.243  loss_cls: 0.2965  loss_box_reg: 0.4316  loss_mask: 0.2663  loss_rpn_cls: 0.07546  loss_rpn_loc: 0.1535  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:06:15 d2.utils.events]: \u001b[0m eta: 0:35:35  iter: 86539  total_loss: 1.165  loss_cls: 0.287  loss_box_reg: 0.3489  loss_mask: 0.2593  loss_rpn_cls: 0.0726  loss_rpn_loc: 0.1668  time: 0.2237  data_time: 0.0165  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:06:19 d2.utils.events]: \u001b[0m eta: 0:35:31  iter: 86559  total_loss: 1.208  loss_cls: 0.2965  loss_box_reg: 0.3554  loss_mask: 0.2719  loss_rpn_cls: 0.06658  loss_rpn_loc: 0.1737  time: 0.2237  data_time: 0.0089  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:06:23 d2.utils.events]: \u001b[0m eta: 0:35:28  iter: 86579  total_loss: 1.123  loss_cls: 0.2714  loss_box_reg: 0.384  loss_mask: 0.2709  loss_rpn_cls: 0.06045  loss_rpn_loc: 0.1554  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:06:28 d2.utils.events]: \u001b[0m eta: 0:35:22  iter: 86599  total_loss: 1.035  loss_cls: 0.2583  loss_box_reg: 0.3197  loss_mask: 0.2404  loss_rpn_cls: 0.04993  loss_rpn_loc: 0.1507  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:06:32 d2.utils.events]: \u001b[0m eta: 0:35:12  iter: 86619  total_loss: 1.02  loss_cls: 0.2257  loss_box_reg: 0.3306  loss_mask: 0.2611  loss_rpn_cls: 0.05428  loss_rpn_loc: 0.1448  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:06:37 d2.utils.events]: \u001b[0m eta: 0:35:04  iter: 86639  total_loss: 1.283  loss_cls: 0.3287  loss_box_reg: 0.4019  loss_mask: 0.2759  loss_rpn_cls: 0.06918  loss_rpn_loc: 0.1707  time: 0.2237  data_time: 0.0169  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:06:41 d2.utils.events]: \u001b[0m eta: 0:34:59  iter: 86659  total_loss: 1.183  loss_cls: 0.2918  loss_box_reg: 0.3751  loss_mask: 0.2607  loss_rpn_cls: 0.05749  loss_rpn_loc: 0.1573  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:06:45 d2.utils.events]: \u001b[0m eta: 0:34:58  iter: 86679  total_loss: 1.04  loss_cls: 0.233  loss_box_reg: 0.3435  loss_mask: 0.2525  loss_rpn_cls: 0.06715  loss_rpn_loc: 0.175  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:06:50 d2.utils.events]: \u001b[0m eta: 0:34:54  iter: 86699  total_loss: 1.146  loss_cls: 0.2785  loss_box_reg: 0.365  loss_mask: 0.2658  loss_rpn_cls: 0.06247  loss_rpn_loc: 0.1607  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:06:54 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.53 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 03:06:54 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 03:06:54 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 03:06:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 03:06:55 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 03:06:56 d2.data.common]: \u001b[0mSerialized dataset takes 84.20 MiB\n",
      "\u001b[32m[12/30 03:06:58 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.58 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 03:06:58 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 03:06:58 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 03:06:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/30 03:07:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0007 s/iter. Inference: 0.0625 s/iter. Eval: 0.1430 s/iter. Total: 0.2062 s/iter. ETA=0:01:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 03:07:07 d2.evaluation.evaluator]: \u001b[0mInference done 37/570. Dataloading: 0.0008 s/iter. Inference: 0.0627 s/iter. Eval: 0.1366 s/iter. Total: 0.2002 s/iter. ETA=0:01:46\n",
      "\u001b[32m[12/30 03:07:12 d2.evaluation.evaluator]: \u001b[0mInference done 62/570. Dataloading: 0.0009 s/iter. Inference: 0.0617 s/iter. Eval: 0.1380 s/iter. Total: 0.2007 s/iter. ETA=0:01:41\n",
      "\u001b[32m[12/30 03:07:17 d2.evaluation.evaluator]: \u001b[0mInference done 88/570. Dataloading: 0.0009 s/iter. Inference: 0.0607 s/iter. Eval: 0.1387 s/iter. Total: 0.2003 s/iter. ETA=0:01:36\n",
      "\u001b[32m[12/30 03:07:22 d2.evaluation.evaluator]: \u001b[0mInference done 112/570. Dataloading: 0.0009 s/iter. Inference: 0.0607 s/iter. Eval: 0.1419 s/iter. Total: 0.2035 s/iter. ETA=0:01:33\n",
      "\u001b[32m[12/30 03:07:27 d2.evaluation.evaluator]: \u001b[0mInference done 137/570. Dataloading: 0.0009 s/iter. Inference: 0.0597 s/iter. Eval: 0.1430 s/iter. Total: 0.2036 s/iter. ETA=0:01:28\n",
      "\u001b[32m[12/30 03:07:32 d2.evaluation.evaluator]: \u001b[0mInference done 157/570. Dataloading: 0.0009 s/iter. Inference: 0.0597 s/iter. Eval: 0.1500 s/iter. Total: 0.2106 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/30 03:07:37 d2.evaluation.evaluator]: \u001b[0mInference done 172/570. Dataloading: 0.0009 s/iter. Inference: 0.0599 s/iter. Eval: 0.1626 s/iter. Total: 0.2234 s/iter. ETA=0:01:28\n",
      "\u001b[32m[12/30 03:07:42 d2.evaluation.evaluator]: \u001b[0mInference done 186/570. Dataloading: 0.0032 s/iter. Inference: 0.0600 s/iter. Eval: 0.1706 s/iter. Total: 0.2338 s/iter. ETA=0:01:29\n",
      "\u001b[32m[12/30 03:07:47 d2.evaluation.evaluator]: \u001b[0mInference done 204/570. Dataloading: 0.0030 s/iter. Inference: 0.0593 s/iter. Eval: 0.1756 s/iter. Total: 0.2380 s/iter. ETA=0:01:27\n",
      "\u001b[32m[12/30 03:07:53 d2.evaluation.evaluator]: \u001b[0mInference done 219/570. Dataloading: 0.0028 s/iter. Inference: 0.0594 s/iter. Eval: 0.1827 s/iter. Total: 0.2450 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/30 03:07:59 d2.evaluation.evaluator]: \u001b[0mInference done 233/570. Dataloading: 0.0027 s/iter. Inference: 0.0593 s/iter. Eval: 0.1955 s/iter. Total: 0.2575 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/30 03:08:04 d2.evaluation.evaluator]: \u001b[0mInference done 248/570. Dataloading: 0.0026 s/iter. Inference: 0.0592 s/iter. Eval: 0.2013 s/iter. Total: 0.2632 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/30 03:08:09 d2.evaluation.evaluator]: \u001b[0mInference done 261/570. Dataloading: 0.0025 s/iter. Inference: 0.0592 s/iter. Eval: 0.2076 s/iter. Total: 0.2694 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 03:08:14 d2.evaluation.evaluator]: \u001b[0mInference done 278/570. Dataloading: 0.0024 s/iter. Inference: 0.0589 s/iter. Eval: 0.2107 s/iter. Total: 0.2721 s/iter. ETA=0:01:19\n",
      "\u001b[32m[12/30 03:08:20 d2.evaluation.evaluator]: \u001b[0mInference done 294/570. Dataloading: 0.0023 s/iter. Inference: 0.0587 s/iter. Eval: 0.2137 s/iter. Total: 0.2748 s/iter. ETA=0:01:15\n",
      "\u001b[32m[12/30 03:08:25 d2.evaluation.evaluator]: \u001b[0mInference done 331/570. Dataloading: 0.0022 s/iter. Inference: 0.0577 s/iter. Eval: 0.1992 s/iter. Total: 0.2591 s/iter. ETA=0:01:01\n",
      "\u001b[32m[12/30 03:08:30 d2.evaluation.evaluator]: \u001b[0mInference done 370/570. Dataloading: 0.0020 s/iter. Inference: 0.0567 s/iter. Eval: 0.1868 s/iter. Total: 0.2455 s/iter. ETA=0:00:49\n",
      "\u001b[32m[12/30 03:08:35 d2.evaluation.evaluator]: \u001b[0mInference done 391/570. Dataloading: 0.0020 s/iter. Inference: 0.0569 s/iter. Eval: 0.1866 s/iter. Total: 0.2455 s/iter. ETA=0:00:43\n",
      "\u001b[32m[12/30 03:08:40 d2.evaluation.evaluator]: \u001b[0mInference done 412/570. Dataloading: 0.0019 s/iter. Inference: 0.0568 s/iter. Eval: 0.1871 s/iter. Total: 0.2459 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/30 03:08:45 d2.evaluation.evaluator]: \u001b[0mInference done 431/570. Dataloading: 0.0019 s/iter. Inference: 0.0570 s/iter. Eval: 0.1883 s/iter. Total: 0.2472 s/iter. ETA=0:00:34\n",
      "\u001b[32m[12/30 03:08:51 d2.evaluation.evaluator]: \u001b[0mInference done 455/570. Dataloading: 0.0018 s/iter. Inference: 0.0570 s/iter. Eval: 0.1864 s/iter. Total: 0.2454 s/iter. ETA=0:00:28\n",
      "\u001b[32m[12/30 03:08:56 d2.evaluation.evaluator]: \u001b[0mInference done 493/570. Dataloading: 0.0017 s/iter. Inference: 0.0564 s/iter. Eval: 0.1792 s/iter. Total: 0.2373 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/30 03:09:01 d2.evaluation.evaluator]: \u001b[0mInference done 513/570. Dataloading: 0.0017 s/iter. Inference: 0.0562 s/iter. Eval: 0.1807 s/iter. Total: 0.2387 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/30 03:09:07 d2.evaluation.evaluator]: \u001b[0mInference done 538/570. Dataloading: 0.0017 s/iter. Inference: 0.0561 s/iter. Eval: 0.1796 s/iter. Total: 0.2375 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/30 03:09:12 d2.evaluation.evaluator]: \u001b[0mInference done 556/570. Dataloading: 0.0016 s/iter. Inference: 0.0563 s/iter. Eval: 0.1814 s/iter. Total: 0.2394 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 03:09:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:15.623604 (0.240042 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 03:09:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.056376 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 03:09:16 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/30 03:09:16 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2895154145481612\n",
      "\u001b[32m[12/30 03:09:19 d2.utils.events]: \u001b[0m eta: 0:34:56  iter: 86719  total_loss: 1.245  loss_cls: 0.3141  loss_box_reg: 0.3751  loss_mask: 0.2758  loss_rpn_cls: 0.06258  loss_rpn_loc: 0.1759  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:09:24 d2.utils.events]: \u001b[0m eta: 0:34:49  iter: 86739  total_loss: 1.102  loss_cls: 0.2868  loss_box_reg: 0.3603  loss_mask: 0.2455  loss_rpn_cls: 0.07276  loss_rpn_loc: 0.157  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:09:28 d2.utils.events]: \u001b[0m eta: 0:34:42  iter: 86759  total_loss: 1.116  loss_cls: 0.2743  loss_box_reg: 0.3566  loss_mask: 0.2646  loss_rpn_cls: 0.05933  loss_rpn_loc: 0.1661  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:09:33 d2.utils.events]: \u001b[0m eta: 0:34:40  iter: 86779  total_loss: 1.224  loss_cls: 0.304  loss_box_reg: 0.3932  loss_mask: 0.2552  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.1726  time: 0.2237  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:09:37 d2.utils.events]: \u001b[0m eta: 0:34:41  iter: 86799  total_loss: 1.135  loss_cls: 0.2736  loss_box_reg: 0.3888  loss_mask: 0.2528  loss_rpn_cls: 0.05687  loss_rpn_loc: 0.1535  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:09:42 d2.utils.events]: \u001b[0m eta: 0:34:37  iter: 86819  total_loss: 1.316  loss_cls: 0.3311  loss_box_reg: 0.4379  loss_mask: 0.2793  loss_rpn_cls: 0.07964  loss_rpn_loc: 0.1684  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:09:47 d2.utils.events]: \u001b[0m eta: 0:34:32  iter: 86839  total_loss: 1.008  loss_cls: 0.2517  loss_box_reg: 0.3401  loss_mask: 0.2574  loss_rpn_cls: 0.04807  loss_rpn_loc: 0.1448  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:09:51 d2.utils.events]: \u001b[0m eta: 0:34:28  iter: 86859  total_loss: 1.05  loss_cls: 0.2397  loss_box_reg: 0.3626  loss_mask: 0.2548  loss_rpn_cls: 0.05876  loss_rpn_loc: 0.1514  time: 0.2237  data_time: 0.0161  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:09:56 d2.utils.events]: \u001b[0m eta: 0:34:25  iter: 86879  total_loss: 1.054  loss_cls: 0.2451  loss_box_reg: 0.3369  loss_mask: 0.2633  loss_rpn_cls: 0.06431  loss_rpn_loc: 0.1513  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:10:00 d2.utils.events]: \u001b[0m eta: 0:34:21  iter: 86899  total_loss: 1.053  loss_cls: 0.2463  loss_box_reg: 0.3571  loss_mask: 0.2496  loss_rpn_cls: 0.04919  loss_rpn_loc: 0.14  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:10:05 d2.utils.events]: \u001b[0m eta: 0:34:19  iter: 86919  total_loss: 1.157  loss_cls: 0.2755  loss_box_reg: 0.3608  loss_mask: 0.2608  loss_rpn_cls: 0.08305  loss_rpn_loc: 0.17  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:10:09 d2.utils.events]: \u001b[0m eta: 0:34:15  iter: 86939  total_loss: 1.056  loss_cls: 0.2471  loss_box_reg: 0.3364  loss_mask: 0.2499  loss_rpn_cls: 0.06776  loss_rpn_loc: 0.1435  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:10:13 d2.utils.events]: \u001b[0m eta: 0:34:12  iter: 86959  total_loss: 1.101  loss_cls: 0.2678  loss_box_reg: 0.384  loss_mask: 0.2389  loss_rpn_cls: 0.04989  loss_rpn_loc: 0.1544  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 03:10:18 d2.utils.events]: \u001b[0m eta: 0:34:08  iter: 86979  total_loss: 1.157  loss_cls: 0.2751  loss_box_reg: 0.392  loss_mask: 0.269  loss_rpn_cls: 0.06175  loss_rpn_loc: 0.1491  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:10:22 d2.utils.events]: \u001b[0m eta: 0:34:03  iter: 86999  total_loss: 1.24  loss_cls: 0.2829  loss_box_reg: 0.3936  loss_mask: 0.2767  loss_rpn_cls: 0.07883  loss_rpn_loc: 0.1655  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:10:27 d2.utils.events]: \u001b[0m eta: 0:33:57  iter: 87019  total_loss: 1.117  loss_cls: 0.286  loss_box_reg: 0.328  loss_mask: 0.2517  loss_rpn_cls: 0.06394  loss_rpn_loc: 0.1638  time: 0.2237  data_time: 0.0158  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:10:31 d2.utils.events]: \u001b[0m eta: 0:33:52  iter: 87039  total_loss: 1.109  loss_cls: 0.2744  loss_box_reg: 0.3622  loss_mask: 0.2582  loss_rpn_cls: 0.05716  loss_rpn_loc: 0.1708  time: 0.2237  data_time: 0.0093  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:10:36 d2.utils.events]: \u001b[0m eta: 0:33:50  iter: 87059  total_loss: 1.078  loss_cls: 0.2467  loss_box_reg: 0.3416  loss_mask: 0.2576  loss_rpn_cls: 0.07142  loss_rpn_loc: 0.1678  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:10:40 d2.utils.events]: \u001b[0m eta: 0:33:44  iter: 87079  total_loss: 1.162  loss_cls: 0.2854  loss_box_reg: 0.3838  loss_mask: 0.2589  loss_rpn_cls: 0.07112  loss_rpn_loc: 0.1552  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:10:45 d2.utils.events]: \u001b[0m eta: 0:33:40  iter: 87099  total_loss: 1.042  loss_cls: 0.2483  loss_box_reg: 0.3205  loss_mask: 0.241  loss_rpn_cls: 0.05988  loss_rpn_loc: 0.1533  time: 0.2237  data_time: 0.0135  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:10:49 d2.utils.events]: \u001b[0m eta: 0:33:33  iter: 87119  total_loss: 1.12  loss_cls: 0.286  loss_box_reg: 0.3926  loss_mask: 0.2312  loss_rpn_cls: 0.04666  loss_rpn_loc: 0.1431  time: 0.2237  data_time: 0.0058  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:10:53 d2.utils.events]: \u001b[0m eta: 0:33:26  iter: 87139  total_loss: 1.221  loss_cls: 0.2907  loss_box_reg: 0.3642  loss_mask: 0.2569  loss_rpn_cls: 0.07026  loss_rpn_loc: 0.1824  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:10:58 d2.utils.events]: \u001b[0m eta: 0:33:23  iter: 87159  total_loss: 1.132  loss_cls: 0.2997  loss_box_reg: 0.3546  loss_mask: 0.2762  loss_rpn_cls: 0.05902  loss_rpn_loc: 0.1548  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:11:02 d2.utils.events]: \u001b[0m eta: 0:33:20  iter: 87179  total_loss: 1.142  loss_cls: 0.2678  loss_box_reg: 0.3429  loss_mask: 0.2548  loss_rpn_cls: 0.05522  loss_rpn_loc: 0.1646  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:11:07 d2.utils.events]: \u001b[0m eta: 0:33:16  iter: 87199  total_loss: 1.18  loss_cls: 0.2849  loss_box_reg: 0.3937  loss_mask: 0.2677  loss_rpn_cls: 0.05901  loss_rpn_loc: 0.1538  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:11:11 d2.utils.events]: \u001b[0m eta: 0:33:11  iter: 87219  total_loss: 1.209  loss_cls: 0.3063  loss_box_reg: 0.3824  loss_mask: 0.2679  loss_rpn_cls: 0.08129  loss_rpn_loc: 0.1585  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:11:16 d2.utils.events]: \u001b[0m eta: 0:33:09  iter: 87239  total_loss: 1.099  loss_cls: 0.2615  loss_box_reg: 0.3472  loss_mask: 0.253  loss_rpn_cls: 0.05807  loss_rpn_loc: 0.148  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:11:20 d2.utils.events]: \u001b[0m eta: 0:33:05  iter: 87259  total_loss: 1.102  loss_cls: 0.2654  loss_box_reg: 0.3364  loss_mask: 0.2579  loss_rpn_cls: 0.06386  loss_rpn_loc: 0.1665  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:11:25 d2.utils.events]: \u001b[0m eta: 0:32:58  iter: 87279  total_loss: 1.153  loss_cls: 0.2865  loss_box_reg: 0.4011  loss_mask: 0.2567  loss_rpn_cls: 0.06316  loss_rpn_loc: 0.1529  time: 0.2237  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:11:29 d2.utils.events]: \u001b[0m eta: 0:32:49  iter: 87299  total_loss: 1.28  loss_cls: 0.3173  loss_box_reg: 0.4325  loss_mask: 0.2626  loss_rpn_cls: 0.08039  loss_rpn_loc: 0.1788  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:11:33 d2.utils.events]: \u001b[0m eta: 0:32:44  iter: 87319  total_loss: 1.078  loss_cls: 0.2366  loss_box_reg: 0.3503  loss_mask: 0.2528  loss_rpn_cls: 0.06916  loss_rpn_loc: 0.1596  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:11:38 d2.utils.events]: \u001b[0m eta: 0:32:39  iter: 87339  total_loss: 1.191  loss_cls: 0.3028  loss_box_reg: 0.4095  loss_mask: 0.267  loss_rpn_cls: 0.06467  loss_rpn_loc: 0.152  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:11:42 d2.utils.events]: \u001b[0m eta: 0:32:35  iter: 87359  total_loss: 1.023  loss_cls: 0.212  loss_box_reg: 0.3514  loss_mask: 0.24  loss_rpn_cls: 0.06371  loss_rpn_loc: 0.1511  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:11:47 d2.utils.events]: \u001b[0m eta: 0:32:29  iter: 87379  total_loss: 1.237  loss_cls: 0.3018  loss_box_reg: 0.3682  loss_mask: 0.2525  loss_rpn_cls: 0.08938  loss_rpn_loc: 0.1658  time: 0.2237  data_time: 0.0174  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:11:51 d2.utils.events]: \u001b[0m eta: 0:32:26  iter: 87399  total_loss: 1.175  loss_cls: 0.2747  loss_box_reg: 0.3791  loss_mask: 0.2593  loss_rpn_cls: 0.08898  loss_rpn_loc: 0.1555  time: 0.2237  data_time: 0.0091  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:11:56 d2.utils.events]: \u001b[0m eta: 0:32:20  iter: 87419  total_loss: 1.166  loss_cls: 0.271  loss_box_reg: 0.383  loss_mask: 0.2569  loss_rpn_cls: 0.05576  loss_rpn_loc: 0.1475  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:12:00 d2.utils.events]: \u001b[0m eta: 0:32:14  iter: 87439  total_loss: 1.177  loss_cls: 0.3007  loss_box_reg: 0.3535  loss_mask: 0.2635  loss_rpn_cls: 0.06724  loss_rpn_loc: 0.1631  time: 0.2237  data_time: 0.0156  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:12:05 d2.utils.events]: \u001b[0m eta: 0:32:10  iter: 87459  total_loss: 1.2  loss_cls: 0.2733  loss_box_reg: 0.377  loss_mask: 0.2668  loss_rpn_cls: 0.06714  loss_rpn_loc: 0.1801  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:12:09 d2.utils.events]: \u001b[0m eta: 0:32:07  iter: 87479  total_loss: 1.253  loss_cls: 0.3273  loss_box_reg: 0.3963  loss_mask: 0.2766  loss_rpn_cls: 0.09015  loss_rpn_loc: 0.1729  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:12:13 d2.utils.events]: \u001b[0m eta: 0:32:02  iter: 87499  total_loss: 1.166  loss_cls: 0.2738  loss_box_reg: 0.3887  loss_mask: 0.2567  loss_rpn_cls: 0.06636  loss_rpn_loc: 0.1593  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:12:18 d2.utils.events]: \u001b[0m eta: 0:32:01  iter: 87519  total_loss: 1.144  loss_cls: 0.2812  loss_box_reg: 0.3535  loss_mask: 0.249  loss_rpn_cls: 0.07002  loss_rpn_loc: 0.147  time: 0.2237  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:12:22 d2.utils.events]: \u001b[0m eta: 0:31:55  iter: 87539  total_loss: 1.188  loss_cls: 0.28  loss_box_reg: 0.3678  loss_mask: 0.2488  loss_rpn_cls: 0.08226  loss_rpn_loc: 0.1578  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:12:27 d2.utils.events]: \u001b[0m eta: 0:31:51  iter: 87559  total_loss: 1.28  loss_cls: 0.3388  loss_box_reg: 0.3831  loss_mask: 0.2631  loss_rpn_cls: 0.05969  loss_rpn_loc: 0.1723  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:12:31 d2.utils.events]: \u001b[0m eta: 0:31:45  iter: 87579  total_loss: 1.082  loss_cls: 0.2632  loss_box_reg: 0.3591  loss_mask: 0.2367  loss_rpn_cls: 0.06805  loss_rpn_loc: 0.1555  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:12:36 d2.utils.events]: \u001b[0m eta: 0:31:40  iter: 87599  total_loss: 1.093  loss_cls: 0.2816  loss_box_reg: 0.3879  loss_mask: 0.2549  loss_rpn_cls: 0.07535  loss_rpn_loc: 0.1449  time: 0.2237  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:12:40 d2.utils.events]: \u001b[0m eta: 0:31:38  iter: 87619  total_loss: 1.103  loss_cls: 0.2561  loss_box_reg: 0.3399  loss_mask: 0.2603  loss_rpn_cls: 0.07957  loss_rpn_loc: 0.1504  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 03:12:45 d2.utils.events]: \u001b[0m eta: 0:31:34  iter: 87639  total_loss: 1.007  loss_cls: 0.2257  loss_box_reg: 0.3558  loss_mask: 0.2314  loss_rpn_cls: 0.04279  loss_rpn_loc: 0.1441  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:12:50 d2.utils.events]: \u001b[0m eta: 0:31:31  iter: 87659  total_loss: 1.105  loss_cls: 0.2246  loss_box_reg: 0.3449  loss_mask: 0.2711  loss_rpn_cls: 0.08674  loss_rpn_loc: 0.1673  time: 0.2237  data_time: 0.0253  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:12:54 d2.utils.events]: \u001b[0m eta: 0:31:26  iter: 87679  total_loss: 1.135  loss_cls: 0.2486  loss_box_reg: 0.3761  loss_mask: 0.2591  loss_rpn_cls: 0.06818  loss_rpn_loc: 0.1717  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:12:58 d2.utils.events]: \u001b[0m eta: 0:31:21  iter: 87699  total_loss: 1.087  loss_cls: 0.2633  loss_box_reg: 0.369  loss_mask: 0.2394  loss_rpn_cls: 0.06495  loss_rpn_loc: 0.1506  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:13:03 d2.utils.events]: \u001b[0m eta: 0:31:15  iter: 87719  total_loss: 1.287  loss_cls: 0.3255  loss_box_reg: 0.4292  loss_mask: 0.2612  loss_rpn_cls: 0.07573  loss_rpn_loc: 0.1503  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:13:07 d2.utils.events]: \u001b[0m eta: 0:31:12  iter: 87739  total_loss: 1.119  loss_cls: 0.2593  loss_box_reg: 0.3446  loss_mask: 0.2531  loss_rpn_cls: 0.06676  loss_rpn_loc: 0.1594  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:13:12 d2.utils.events]: \u001b[0m eta: 0:31:07  iter: 87759  total_loss: 1.129  loss_cls: 0.2493  loss_box_reg: 0.3631  loss_mask: 0.2475  loss_rpn_cls: 0.07906  loss_rpn_loc: 0.1812  time: 0.2237  data_time: 0.0166  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:13:16 d2.utils.events]: \u001b[0m eta: 0:31:01  iter: 87779  total_loss: 1.194  loss_cls: 0.2723  loss_box_reg: 0.3857  loss_mask: 0.254  loss_rpn_cls: 0.08214  loss_rpn_loc: 0.1611  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:13:21 d2.utils.events]: \u001b[0m eta: 0:30:56  iter: 87799  total_loss: 1.14  loss_cls: 0.2558  loss_box_reg: 0.35  loss_mask: 0.2483  loss_rpn_cls: 0.07298  loss_rpn_loc: 0.1606  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:13:25 d2.utils.events]: \u001b[0m eta: 0:30:52  iter: 87819  total_loss: 1.062  loss_cls: 0.2786  loss_box_reg: 0.3731  loss_mask: 0.2311  loss_rpn_cls: 0.06275  loss_rpn_loc: 0.1414  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:13:29 d2.utils.events]: \u001b[0m eta: 0:30:47  iter: 87839  total_loss: 1.055  loss_cls: 0.2257  loss_box_reg: 0.3631  loss_mask: 0.2583  loss_rpn_cls: 0.05857  loss_rpn_loc: 0.153  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:13:34 d2.utils.events]: \u001b[0m eta: 0:30:41  iter: 87859  total_loss: 1.166  loss_cls: 0.2621  loss_box_reg: 0.358  loss_mask: 0.2699  loss_rpn_cls: 0.0486  loss_rpn_loc: 0.1644  time: 0.2237  data_time: 0.0099  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:13:39 d2.utils.events]: \u001b[0m eta: 0:30:36  iter: 87879  total_loss: 1.035  loss_cls: 0.2109  loss_box_reg: 0.3163  loss_mask: 0.2446  loss_rpn_cls: 0.07885  loss_rpn_loc: 0.1561  time: 0.2237  data_time: 0.0095  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:13:43 d2.utils.events]: \u001b[0m eta: 0:30:32  iter: 87899  total_loss: 1.113  loss_cls: 0.2251  loss_box_reg: 0.3459  loss_mask: 0.2683  loss_rpn_cls: 0.06513  loss_rpn_loc: 0.1666  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:13:47 d2.utils.events]: \u001b[0m eta: 0:30:26  iter: 87919  total_loss: 1.165  loss_cls: 0.2536  loss_box_reg: 0.3612  loss_mask: 0.2524  loss_rpn_cls: 0.08043  loss_rpn_loc: 0.1687  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:13:52 d2.utils.events]: \u001b[0m eta: 0:30:21  iter: 87939  total_loss: 1.112  loss_cls: 0.2429  loss_box_reg: 0.355  loss_mask: 0.2448  loss_rpn_cls: 0.04722  loss_rpn_loc: 0.1429  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:13:56 d2.utils.events]: \u001b[0m eta: 0:30:17  iter: 87959  total_loss: 1.075  loss_cls: 0.2618  loss_box_reg: 0.3349  loss_mask: 0.255  loss_rpn_cls: 0.06599  loss_rpn_loc: 0.15  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:14:01 d2.utils.events]: \u001b[0m eta: 0:30:14  iter: 87979  total_loss: 1.213  loss_cls: 0.2586  loss_box_reg: 0.3765  loss_mask: 0.2734  loss_rpn_cls: 0.06441  loss_rpn_loc: 0.1742  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:14:05 d2.utils.events]: \u001b[0m eta: 0:30:11  iter: 87999  total_loss: 1.241  loss_cls: 0.3074  loss_box_reg: 0.3521  loss_mask: 0.277  loss_rpn_cls: 0.09187  loss_rpn_loc: 0.1622  time: 0.2237  data_time: 0.0156  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:14:10 d2.utils.events]: \u001b[0m eta: 0:30:08  iter: 88019  total_loss: 1.264  loss_cls: 0.3002  loss_box_reg: 0.3669  loss_mask: 0.273  loss_rpn_cls: 0.1216  loss_rpn_loc: 0.1667  time: 0.2237  data_time: 0.0296  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:14:15 d2.utils.events]: \u001b[0m eta: 0:30:06  iter: 88039  total_loss: 1.139  loss_cls: 0.3046  loss_box_reg: 0.3564  loss_mask: 0.2599  loss_rpn_cls: 0.07899  loss_rpn_loc: 0.1648  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:14:19 d2.utils.events]: \u001b[0m eta: 0:29:59  iter: 88059  total_loss: 1.035  loss_cls: 0.2712  loss_box_reg: 0.3492  loss_mask: 0.2302  loss_rpn_cls: 0.04224  loss_rpn_loc: 0.1405  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:14:24 d2.utils.events]: \u001b[0m eta: 0:29:53  iter: 88079  total_loss: 1.228  loss_cls: 0.3064  loss_box_reg: 0.4055  loss_mask: 0.2484  loss_rpn_cls: 0.07099  loss_rpn_loc: 0.1845  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:14:28 d2.utils.events]: \u001b[0m eta: 0:29:49  iter: 88099  total_loss: 1.159  loss_cls: 0.2672  loss_box_reg: 0.3649  loss_mask: 0.2598  loss_rpn_cls: 0.07801  loss_rpn_loc: 0.1659  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:14:33 d2.utils.events]: \u001b[0m eta: 0:29:48  iter: 88119  total_loss: 1.095  loss_cls: 0.2606  loss_box_reg: 0.3276  loss_mask: 0.2375  loss_rpn_cls: 0.04833  loss_rpn_loc: 0.1341  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:14:37 d2.utils.events]: \u001b[0m eta: 0:29:47  iter: 88139  total_loss: 1.036  loss_cls: 0.2141  loss_box_reg: 0.3424  loss_mask: 0.255  loss_rpn_cls: 0.07077  loss_rpn_loc: 0.1513  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:14:42 d2.utils.events]: \u001b[0m eta: 0:29:43  iter: 88159  total_loss: 1.19  loss_cls: 0.3237  loss_box_reg: 0.3603  loss_mask: 0.2684  loss_rpn_cls: 0.09416  loss_rpn_loc: 0.1634  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:14:46 d2.utils.events]: \u001b[0m eta: 0:29:39  iter: 88179  total_loss: 1.191  loss_cls: 0.3149  loss_box_reg: 0.3942  loss_mask: 0.264  loss_rpn_cls: 0.07137  loss_rpn_loc: 0.1586  time: 0.2237  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:14:51 d2.utils.events]: \u001b[0m eta: 0:29:33  iter: 88199  total_loss: 1.21  loss_cls: 0.3015  loss_box_reg: 0.3949  loss_mask: 0.2683  loss_rpn_cls: 0.07455  loss_rpn_loc: 0.1685  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:14:55 d2.utils.events]: \u001b[0m eta: 0:29:30  iter: 88219  total_loss: 1.153  loss_cls: 0.28  loss_box_reg: 0.3283  loss_mask: 0.2475  loss_rpn_cls: 0.06417  loss_rpn_loc: 0.1522  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:15:00 d2.utils.events]: \u001b[0m eta: 0:29:25  iter: 88239  total_loss: 1.264  loss_cls: 0.3247  loss_box_reg: 0.447  loss_mask: 0.2726  loss_rpn_cls: 0.08551  loss_rpn_loc: 0.1735  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:15:04 d2.utils.events]: \u001b[0m eta: 0:29:20  iter: 88259  total_loss: 1.208  loss_cls: 0.2669  loss_box_reg: 0.3355  loss_mask: 0.264  loss_rpn_cls: 0.08045  loss_rpn_loc: 0.1715  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:15:09 d2.utils.events]: \u001b[0m eta: 0:29:17  iter: 88279  total_loss: 1.184  loss_cls: 0.3071  loss_box_reg: 0.3664  loss_mask: 0.2616  loss_rpn_cls: 0.08627  loss_rpn_loc: 0.1663  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 03:15:13 d2.utils.events]: \u001b[0m eta: 0:29:18  iter: 88299  total_loss: 1.247  loss_cls: 0.3131  loss_box_reg: 0.3971  loss_mask: 0.2749  loss_rpn_cls: 0.08356  loss_rpn_loc: 0.1748  time: 0.2237  data_time: 0.0172  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:15:18 d2.utils.events]: \u001b[0m eta: 0:29:14  iter: 88319  total_loss: 1.062  loss_cls: 0.2528  loss_box_reg: 0.3729  loss_mask: 0.2483  loss_rpn_cls: 0.07359  loss_rpn_loc: 0.1447  time: 0.2237  data_time: 0.0179  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:15:23 d2.utils.events]: \u001b[0m eta: 0:29:09  iter: 88339  total_loss: 1.145  loss_cls: 0.2814  loss_box_reg: 0.366  loss_mask: 0.2473  loss_rpn_cls: 0.08401  loss_rpn_loc: 0.1804  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:15:27 d2.utils.events]: \u001b[0m eta: 0:29:07  iter: 88359  total_loss: 1.097  loss_cls: 0.1934  loss_box_reg: 0.3567  loss_mask: 0.2406  loss_rpn_cls: 0.06918  loss_rpn_loc: 0.176  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:15:31 d2.utils.events]: \u001b[0m eta: 0:29:01  iter: 88379  total_loss: 1.152  loss_cls: 0.2846  loss_box_reg: 0.3605  loss_mask: 0.2443  loss_rpn_cls: 0.05817  loss_rpn_loc: 0.154  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:15:36 d2.utils.events]: \u001b[0m eta: 0:28:55  iter: 88399  total_loss: 1.1  loss_cls: 0.2467  loss_box_reg: 0.3476  loss_mask: 0.2522  loss_rpn_cls: 0.07291  loss_rpn_loc: 0.1541  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:15:40 d2.utils.events]: \u001b[0m eta: 0:28:52  iter: 88419  total_loss: 1.136  loss_cls: 0.2957  loss_box_reg: 0.3792  loss_mask: 0.2577  loss_rpn_cls: 0.07717  loss_rpn_loc: 0.1677  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:15:44 d2.utils.events]: \u001b[0m eta: 0:28:50  iter: 88439  total_loss: 1.12  loss_cls: 0.2417  loss_box_reg: 0.3645  loss_mask: 0.251  loss_rpn_cls: 0.05067  loss_rpn_loc: 0.1345  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:15:49 d2.utils.events]: \u001b[0m eta: 0:28:46  iter: 88459  total_loss: 1.09  loss_cls: 0.2774  loss_box_reg: 0.3601  loss_mask: 0.2559  loss_rpn_cls: 0.06294  loss_rpn_loc: 0.1515  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:15:53 d2.utils.events]: \u001b[0m eta: 0:28:40  iter: 88479  total_loss: 1.246  loss_cls: 0.314  loss_box_reg: 0.4027  loss_mask: 0.2513  loss_rpn_cls: 0.08757  loss_rpn_loc: 0.1633  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:15:58 d2.utils.events]: \u001b[0m eta: 0:28:37  iter: 88499  total_loss: 1.244  loss_cls: 0.2865  loss_box_reg: 0.3855  loss_mask: 0.2649  loss_rpn_cls: 0.08399  loss_rpn_loc: 0.1829  time: 0.2237  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:16:02 d2.utils.events]: \u001b[0m eta: 0:28:32  iter: 88519  total_loss: 1.248  loss_cls: 0.3147  loss_box_reg: 0.4092  loss_mask: 0.2621  loss_rpn_cls: 0.07509  loss_rpn_loc: 0.17  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:16:07 d2.utils.events]: \u001b[0m eta: 0:28:28  iter: 88539  total_loss: 1.148  loss_cls: 0.2737  loss_box_reg: 0.3559  loss_mask: 0.2596  loss_rpn_cls: 0.05219  loss_rpn_loc: 0.1624  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:16:11 d2.utils.events]: \u001b[0m eta: 0:28:24  iter: 88559  total_loss: 1.116  loss_cls: 0.2281  loss_box_reg: 0.3595  loss_mask: 0.2541  loss_rpn_cls: 0.07338  loss_rpn_loc: 0.1647  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:16:16 d2.utils.events]: \u001b[0m eta: 0:28:22  iter: 88579  total_loss: 1.208  loss_cls: 0.3095  loss_box_reg: 0.4088  loss_mask: 0.2778  loss_rpn_cls: 0.08219  loss_rpn_loc: 0.1574  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:16:21 d2.utils.events]: \u001b[0m eta: 0:28:21  iter: 88599  total_loss: 1.091  loss_cls: 0.2499  loss_box_reg: 0.3138  loss_mask: 0.245  loss_rpn_cls: 0.08452  loss_rpn_loc: 0.1615  time: 0.2237  data_time: 0.0164  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:16:25 d2.utils.events]: \u001b[0m eta: 0:28:15  iter: 88619  total_loss: 1.074  loss_cls: 0.2294  loss_box_reg: 0.3652  loss_mask: 0.2538  loss_rpn_cls: 0.05339  loss_rpn_loc: 0.1472  time: 0.2237  data_time: 0.0199  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:16:30 d2.utils.events]: \u001b[0m eta: 0:28:13  iter: 88639  total_loss: 1.223  loss_cls: 0.3366  loss_box_reg: 0.4115  loss_mask: 0.2617  loss_rpn_cls: 0.06567  loss_rpn_loc: 0.1545  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:16:34 d2.utils.events]: \u001b[0m eta: 0:28:08  iter: 88659  total_loss: 1.12  loss_cls: 0.2801  loss_box_reg: 0.3542  loss_mask: 0.2707  loss_rpn_cls: 0.0729  loss_rpn_loc: 0.1626  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:16:39 d2.utils.events]: \u001b[0m eta: 0:28:04  iter: 88679  total_loss: 1.187  loss_cls: 0.2468  loss_box_reg: 0.3495  loss_mask: 0.251  loss_rpn_cls: 0.07963  loss_rpn_loc: 0.157  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:16:43 d2.utils.events]: \u001b[0m eta: 0:28:01  iter: 88699  total_loss: 1.077  loss_cls: 0.2326  loss_box_reg: 0.328  loss_mask: 0.2454  loss_rpn_cls: 0.05277  loss_rpn_loc: 0.158  time: 0.2237  data_time: 0.0098  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:16:48 d2.utils.events]: \u001b[0m eta: 0:27:56  iter: 88719  total_loss: 1.154  loss_cls: 0.2944  loss_box_reg: 0.3824  loss_mask: 0.2595  loss_rpn_cls: 0.0753  loss_rpn_loc: 0.1651  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:16:53 d2.utils.events]: \u001b[0m eta: 0:27:51  iter: 88739  total_loss: 1.054  loss_cls: 0.2482  loss_box_reg: 0.3671  loss_mask: 0.2529  loss_rpn_cls: 0.09239  loss_rpn_loc: 0.1467  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:16:57 d2.utils.events]: \u001b[0m eta: 0:27:47  iter: 88759  total_loss: 0.9887  loss_cls: 0.2422  loss_box_reg: 0.3161  loss_mask: 0.2543  loss_rpn_cls: 0.07929  loss_rpn_loc: 0.1678  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:17:02 d2.utils.events]: \u001b[0m eta: 0:27:43  iter: 88779  total_loss: 1.141  loss_cls: 0.2592  loss_box_reg: 0.3674  loss_mask: 0.2627  loss_rpn_cls: 0.05798  loss_rpn_loc: 0.1689  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:17:06 d2.utils.events]: \u001b[0m eta: 0:27:38  iter: 88799  total_loss: 1.23  loss_cls: 0.2824  loss_box_reg: 0.3975  loss_mask: 0.2661  loss_rpn_cls: 0.0871  loss_rpn_loc: 0.1741  time: 0.2237  data_time: 0.0089  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:17:11 d2.utils.events]: \u001b[0m eta: 0:27:34  iter: 88819  total_loss: 1.178  loss_cls: 0.2819  loss_box_reg: 0.3947  loss_mask: 0.2612  loss_rpn_cls: 0.0778  loss_rpn_loc: 0.1707  time: 0.2237  data_time: 0.0096  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:17:15 d2.utils.events]: \u001b[0m eta: 0:27:29  iter: 88839  total_loss: 1.158  loss_cls: 0.294  loss_box_reg: 0.3791  loss_mask: 0.2428  loss_rpn_cls: 0.06066  loss_rpn_loc: 0.1417  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:17:19 d2.utils.events]: \u001b[0m eta: 0:27:24  iter: 88859  total_loss: 1.041  loss_cls: 0.2482  loss_box_reg: 0.3598  loss_mask: 0.2497  loss_rpn_cls: 0.03948  loss_rpn_loc: 0.1442  time: 0.2237  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:17:23 d2.utils.events]: \u001b[0m eta: 0:27:20  iter: 88879  total_loss: 1.156  loss_cls: 0.2923  loss_box_reg: 0.3567  loss_mask: 0.2574  loss_rpn_cls: 0.0635  loss_rpn_loc: 0.1593  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:17:28 d2.utils.events]: \u001b[0m eta: 0:27:16  iter: 88899  total_loss: 1.288  loss_cls: 0.3172  loss_box_reg: 0.3475  loss_mask: 0.2844  loss_rpn_cls: 0.1138  loss_rpn_loc: 0.1793  time: 0.2237  data_time: 0.0235  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:17:33 d2.utils.events]: \u001b[0m eta: 0:27:13  iter: 88919  total_loss: 1.099  loss_cls: 0.2685  loss_box_reg: 0.3701  loss_mask: 0.2762  loss_rpn_cls: 0.08619  loss_rpn_loc: 0.1726  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:17:37 d2.utils.events]: \u001b[0m eta: 0:27:07  iter: 88939  total_loss: 1.31  loss_cls: 0.3284  loss_box_reg: 0.429  loss_mask: 0.2736  loss_rpn_cls: 0.06367  loss_rpn_loc: 0.1691  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 03:17:41 d2.utils.events]: \u001b[0m eta: 0:27:02  iter: 88959  total_loss: 1.088  loss_cls: 0.2767  loss_box_reg: 0.3506  loss_mask: 0.248  loss_rpn_cls: 0.04685  loss_rpn_loc: 0.1333  time: 0.2237  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:17:46 d2.utils.events]: \u001b[0m eta: 0:26:56  iter: 88979  total_loss: 1.175  loss_cls: 0.2533  loss_box_reg: 0.3388  loss_mask: 0.2594  loss_rpn_cls: 0.08302  loss_rpn_loc: 0.1649  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:17:50 d2.utils.events]: \u001b[0m eta: 0:26:50  iter: 88999  total_loss: 1.11  loss_cls: 0.2791  loss_box_reg: 0.3653  loss_mask: 0.2612  loss_rpn_cls: 0.08089  loss_rpn_loc: 0.1495  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:17:55 d2.utils.events]: \u001b[0m eta: 0:26:43  iter: 89019  total_loss: 1.181  loss_cls: 0.2935  loss_box_reg: 0.3846  loss_mask: 0.2516  loss_rpn_cls: 0.07884  loss_rpn_loc: 0.1521  time: 0.2237  data_time: 0.0062  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:17:59 d2.utils.events]: \u001b[0m eta: 0:26:39  iter: 89039  total_loss: 1.186  loss_cls: 0.2873  loss_box_reg: 0.3567  loss_mask: 0.2658  loss_rpn_cls: 0.08216  loss_rpn_loc: 0.1724  time: 0.2237  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:18:04 d2.utils.events]: \u001b[0m eta: 0:26:35  iter: 89059  total_loss: 1.179  loss_cls: 0.2809  loss_box_reg: 0.3562  loss_mask: 0.278  loss_rpn_cls: 0.08792  loss_rpn_loc: 0.1797  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:18:08 d2.utils.events]: \u001b[0m eta: 0:26:34  iter: 89079  total_loss: 1.086  loss_cls: 0.2367  loss_box_reg: 0.3247  loss_mask: 0.2649  loss_rpn_cls: 0.1007  loss_rpn_loc: 0.1548  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:18:13 d2.utils.events]: \u001b[0m eta: 0:26:27  iter: 89099  total_loss: 1.137  loss_cls: 0.2708  loss_box_reg: 0.3646  loss_mask: 0.2684  loss_rpn_cls: 0.07414  loss_rpn_loc: 0.1689  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:18:17 d2.utils.events]: \u001b[0m eta: 0:26:24  iter: 89119  total_loss: 1.095  loss_cls: 0.2679  loss_box_reg: 0.3488  loss_mask: 0.245  loss_rpn_cls: 0.06223  loss_rpn_loc: 0.1585  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:18:22 d2.utils.events]: \u001b[0m eta: 0:26:19  iter: 89139  total_loss: 1.186  loss_cls: 0.2993  loss_box_reg: 0.3467  loss_mask: 0.2689  loss_rpn_cls: 0.08543  loss_rpn_loc: 0.1678  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:18:27 d2.utils.events]: \u001b[0m eta: 0:26:15  iter: 89159  total_loss: 1.092  loss_cls: 0.2773  loss_box_reg: 0.3303  loss_mask: 0.2564  loss_rpn_cls: 0.06887  loss_rpn_loc: 0.1553  time: 0.2237  data_time: 0.0225  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:18:31 d2.utils.events]: \u001b[0m eta: 0:26:09  iter: 89179  total_loss: 1.052  loss_cls: 0.2463  loss_box_reg: 0.386  loss_mask: 0.2309  loss_rpn_cls: 0.05754  loss_rpn_loc: 0.1368  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:18:36 d2.utils.events]: \u001b[0m eta: 0:26:07  iter: 89199  total_loss: 1.221  loss_cls: 0.298  loss_box_reg: 0.4247  loss_mask: 0.2836  loss_rpn_cls: 0.08592  loss_rpn_loc: 0.1585  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:18:40 d2.utils.events]: \u001b[0m eta: 0:26:00  iter: 89219  total_loss: 1.121  loss_cls: 0.2643  loss_box_reg: 0.3362  loss_mask: 0.2488  loss_rpn_cls: 0.07008  loss_rpn_loc: 0.1578  time: 0.2237  data_time: 0.0149  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:18:45 d2.utils.events]: \u001b[0m eta: 0:25:58  iter: 89239  total_loss: 1.012  loss_cls: 0.2302  loss_box_reg: 0.3483  loss_mask: 0.257  loss_rpn_cls: 0.07947  loss_rpn_loc: 0.1481  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:18:50 d2.utils.events]: \u001b[0m eta: 0:25:52  iter: 89259  total_loss: 1.045  loss_cls: 0.2686  loss_box_reg: 0.3608  loss_mask: 0.2383  loss_rpn_cls: 0.04923  loss_rpn_loc: 0.135  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:18:54 d2.utils.events]: \u001b[0m eta: 0:25:42  iter: 89279  total_loss: 1.041  loss_cls: 0.2384  loss_box_reg: 0.3427  loss_mask: 0.2317  loss_rpn_cls: 0.05483  loss_rpn_loc: 0.1487  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:18:58 d2.utils.events]: \u001b[0m eta: 0:25:36  iter: 89299  total_loss: 1.227  loss_cls: 0.3002  loss_box_reg: 0.4037  loss_mask: 0.2636  loss_rpn_cls: 0.08691  loss_rpn_loc: 0.1621  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:19:03 d2.utils.events]: \u001b[0m eta: 0:25:31  iter: 89319  total_loss: 1.166  loss_cls: 0.2829  loss_box_reg: 0.3847  loss_mask: 0.2576  loss_rpn_cls: 0.0667  loss_rpn_loc: 0.1513  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:19:07 d2.utils.events]: \u001b[0m eta: 0:25:27  iter: 89339  total_loss: 1.289  loss_cls: 0.3232  loss_box_reg: 0.3994  loss_mask: 0.2757  loss_rpn_cls: 0.08803  loss_rpn_loc: 0.1645  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:19:12 d2.utils.events]: \u001b[0m eta: 0:25:23  iter: 89359  total_loss: 1.193  loss_cls: 0.3018  loss_box_reg: 0.3763  loss_mask: 0.2764  loss_rpn_cls: 0.09146  loss_rpn_loc: 0.1805  time: 0.2237  data_time: 0.0088  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:19:16 d2.utils.events]: \u001b[0m eta: 0:25:20  iter: 89379  total_loss: 1.253  loss_cls: 0.3053  loss_box_reg: 0.4395  loss_mask: 0.265  loss_rpn_cls: 0.07666  loss_rpn_loc: 0.1645  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:19:21 d2.utils.events]: \u001b[0m eta: 0:25:16  iter: 89399  total_loss: 1.045  loss_cls: 0.2391  loss_box_reg: 0.331  loss_mask: 0.2372  loss_rpn_cls: 0.07975  loss_rpn_loc: 0.1649  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:19:25 d2.utils.events]: \u001b[0m eta: 0:25:11  iter: 89419  total_loss: 1.067  loss_cls: 0.2795  loss_box_reg: 0.3446  loss_mask: 0.2532  loss_rpn_cls: 0.06817  loss_rpn_loc: 0.1449  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:19:30 d2.utils.events]: \u001b[0m eta: 0:25:06  iter: 89439  total_loss: 1.124  loss_cls: 0.2653  loss_box_reg: 0.3649  loss_mask: 0.2639  loss_rpn_cls: 0.05895  loss_rpn_loc: 0.1466  time: 0.2237  data_time: 0.0097  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:19:34 d2.utils.events]: \u001b[0m eta: 0:25:01  iter: 89459  total_loss: 1.067  loss_cls: 0.253  loss_box_reg: 0.3408  loss_mask: 0.2444  loss_rpn_cls: 0.05426  loss_rpn_loc: 0.1385  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:19:39 d2.utils.events]: \u001b[0m eta: 0:24:58  iter: 89479  total_loss: 1.139  loss_cls: 0.2424  loss_box_reg: 0.3442  loss_mask: 0.2538  loss_rpn_cls: 0.06844  loss_rpn_loc: 0.1628  time: 0.2237  data_time: 0.0185  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:19:43 d2.utils.events]: \u001b[0m eta: 0:24:54  iter: 89499  total_loss: 1.052  loss_cls: 0.2652  loss_box_reg: 0.3312  loss_mask: 0.2474  loss_rpn_cls: 0.06989  loss_rpn_loc: 0.1468  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:19:48 d2.utils.events]: \u001b[0m eta: 0:24:48  iter: 89519  total_loss: 1.111  loss_cls: 0.2583  loss_box_reg: 0.3748  loss_mask: 0.2584  loss_rpn_cls: 0.06286  loss_rpn_loc: 0.1467  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:19:52 d2.utils.events]: \u001b[0m eta: 0:24:44  iter: 89539  total_loss: 1.096  loss_cls: 0.2712  loss_box_reg: 0.3544  loss_mask: 0.2546  loss_rpn_cls: 0.07617  loss_rpn_loc: 0.1673  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:19:57 d2.utils.events]: \u001b[0m eta: 0:24:40  iter: 89559  total_loss: 1.175  loss_cls: 0.2709  loss_box_reg: 0.3801  loss_mask: 0.2675  loss_rpn_cls: 0.09164  loss_rpn_loc: 0.1591  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:20:02 d2.utils.events]: \u001b[0m eta: 0:24:36  iter: 89579  total_loss: 1.037  loss_cls: 0.2442  loss_box_reg: 0.303  loss_mask: 0.2671  loss_rpn_cls: 0.09269  loss_rpn_loc: 0.1715  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:20:06 d2.utils.events]: \u001b[0m eta: 0:24:32  iter: 89599  total_loss: 1.203  loss_cls: 0.2644  loss_box_reg: 0.3752  loss_mask: 0.2837  loss_rpn_cls: 0.08839  loss_rpn_loc: 0.1659  time: 0.2237  data_time: 0.0109  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 03:20:11 d2.utils.events]: \u001b[0m eta: 0:24:28  iter: 89619  total_loss: 1.186  loss_cls: 0.2939  loss_box_reg: 0.3937  loss_mask: 0.2636  loss_rpn_cls: 0.08488  loss_rpn_loc: 0.1695  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:20:15 d2.utils.events]: \u001b[0m eta: 0:24:24  iter: 89639  total_loss: 1.159  loss_cls: 0.278  loss_box_reg: 0.365  loss_mask: 0.2587  loss_rpn_cls: 0.07944  loss_rpn_loc: 0.1716  time: 0.2237  data_time: 0.0121  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:20:20 d2.utils.events]: \u001b[0m eta: 0:24:19  iter: 89659  total_loss: 1.068  loss_cls: 0.2571  loss_box_reg: 0.3527  loss_mask: 0.2548  loss_rpn_cls: 0.05259  loss_rpn_loc: 0.164  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:20:24 d2.utils.events]: \u001b[0m eta: 0:24:15  iter: 89679  total_loss: 1.184  loss_cls: 0.2941  loss_box_reg: 0.3865  loss_mask: 0.2525  loss_rpn_cls: 0.08042  loss_rpn_loc: 0.1707  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:20:29 d2.utils.events]: \u001b[0m eta: 0:24:11  iter: 89699  total_loss: 1.22  loss_cls: 0.2994  loss_box_reg: 0.3924  loss_mask: 0.2681  loss_rpn_cls: 0.0801  loss_rpn_loc: 0.1831  time: 0.2237  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:20:33 d2.utils.events]: \u001b[0m eta: 0:24:06  iter: 89719  total_loss: 0.9891  loss_cls: 0.2384  loss_box_reg: 0.3225  loss_mask: 0.2309  loss_rpn_cls: 0.04849  loss_rpn_loc: 0.1345  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:20:38 d2.utils.events]: \u001b[0m eta: 0:24:02  iter: 89739  total_loss: 1.082  loss_cls: 0.2571  loss_box_reg: 0.3466  loss_mask: 0.2714  loss_rpn_cls: 0.05817  loss_rpn_loc: 0.1497  time: 0.2237  data_time: 0.0143  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:20:42 d2.utils.events]: \u001b[0m eta: 0:23:57  iter: 89759  total_loss: 1.112  loss_cls: 0.2762  loss_box_reg: 0.3478  loss_mask: 0.2379  loss_rpn_cls: 0.05425  loss_rpn_loc: 0.1547  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:20:47 d2.utils.events]: \u001b[0m eta: 0:23:52  iter: 89779  total_loss: 1.173  loss_cls: 0.2828  loss_box_reg: 0.3846  loss_mask: 0.2739  loss_rpn_cls: 0.05444  loss_rpn_loc: 0.1483  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:20:51 d2.utils.events]: \u001b[0m eta: 0:23:49  iter: 89799  total_loss: 1.202  loss_cls: 0.2692  loss_box_reg: 0.3414  loss_mask: 0.2729  loss_rpn_cls: 0.08803  loss_rpn_loc: 0.1683  time: 0.2237  data_time: 0.0171  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:20:56 d2.utils.events]: \u001b[0m eta: 0:23:45  iter: 89819  total_loss: 1.272  loss_cls: 0.3316  loss_box_reg: 0.3935  loss_mask: 0.2663  loss_rpn_cls: 0.07993  loss_rpn_loc: 0.1827  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:21:00 d2.utils.events]: \u001b[0m eta: 0:23:41  iter: 89839  total_loss: 1.189  loss_cls: 0.2852  loss_box_reg: 0.3751  loss_mask: 0.2533  loss_rpn_cls: 0.07632  loss_rpn_loc: 0.1852  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:21:05 d2.utils.events]: \u001b[0m eta: 0:23:36  iter: 89859  total_loss: 1.271  loss_cls: 0.2961  loss_box_reg: 0.423  loss_mask: 0.2613  loss_rpn_cls: 0.04332  loss_rpn_loc: 0.1539  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:21:09 d2.utils.events]: \u001b[0m eta: 0:23:35  iter: 89879  total_loss: 1.191  loss_cls: 0.2895  loss_box_reg: 0.3725  loss_mask: 0.2634  loss_rpn_cls: 0.07368  loss_rpn_loc: 0.1636  time: 0.2237  data_time: 0.0107  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:21:13 d2.utils.events]: \u001b[0m eta: 0:23:27  iter: 89899  total_loss: 1.109  loss_cls: 0.2491  loss_box_reg: 0.3723  loss_mask: 0.2537  loss_rpn_cls: 0.03997  loss_rpn_loc: 0.1332  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:21:18 d2.utils.events]: \u001b[0m eta: 0:23:19  iter: 89919  total_loss: 1.13  loss_cls: 0.2713  loss_box_reg: 0.3634  loss_mask: 0.2527  loss_rpn_cls: 0.05222  loss_rpn_loc: 0.159  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:21:22 d2.utils.events]: \u001b[0m eta: 0:23:17  iter: 89939  total_loss: 1.034  loss_cls: 0.2448  loss_box_reg: 0.3329  loss_mask: 0.257  loss_rpn_cls: 0.06201  loss_rpn_loc: 0.1555  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:21:26 d2.utils.events]: \u001b[0m eta: 0:23:14  iter: 89959  total_loss: 1.081  loss_cls: 0.2582  loss_box_reg: 0.3544  loss_mask: 0.2477  loss_rpn_cls: 0.07531  loss_rpn_loc: 0.1539  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:21:31 d2.utils.events]: \u001b[0m eta: 0:23:09  iter: 89979  total_loss: 1.174  loss_cls: 0.31  loss_box_reg: 0.3544  loss_mask: 0.2624  loss_rpn_cls: 0.07413  loss_rpn_loc: 0.1674  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:21:35 d2.utils.events]: \u001b[0m eta: 0:23:04  iter: 89999  total_loss: 1.116  loss_cls: 0.2744  loss_box_reg: 0.402  loss_mask: 0.2437  loss_rpn_cls: 0.07205  loss_rpn_loc: 0.165  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:21:40 d2.utils.events]: \u001b[0m eta: 0:22:59  iter: 90019  total_loss: 1.119  loss_cls: 0.2634  loss_box_reg: 0.3741  loss_mask: 0.2601  loss_rpn_cls: 0.06452  loss_rpn_loc: 0.1649  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:21:44 d2.utils.events]: \u001b[0m eta: 0:22:53  iter: 90039  total_loss: 1.075  loss_cls: 0.2442  loss_box_reg: 0.3656  loss_mask: 0.2692  loss_rpn_cls: 0.06639  loss_rpn_loc: 0.1725  time: 0.2237  data_time: 0.0094  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:21:49 d2.utils.events]: \u001b[0m eta: 0:22:48  iter: 90059  total_loss: 1.297  loss_cls: 0.3069  loss_box_reg: 0.4104  loss_mask: 0.2634  loss_rpn_cls: 0.06237  loss_rpn_loc: 0.1569  time: 0.2237  data_time: 0.0196  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:21:53 d2.utils.events]: \u001b[0m eta: 0:22:43  iter: 90079  total_loss: 1.226  loss_cls: 0.2826  loss_box_reg: 0.3983  loss_mask: 0.2724  loss_rpn_cls: 0.06013  loss_rpn_loc: 0.167  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:21:58 d2.utils.events]: \u001b[0m eta: 0:22:39  iter: 90099  total_loss: 1.041  loss_cls: 0.243  loss_box_reg: 0.3653  loss_mask: 0.2394  loss_rpn_cls: 0.06237  loss_rpn_loc: 0.1664  time: 0.2237  data_time: 0.0213  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:22:02 d2.utils.events]: \u001b[0m eta: 0:22:34  iter: 90119  total_loss: 1.059  loss_cls: 0.2586  loss_box_reg: 0.3593  loss_mask: 0.2574  loss_rpn_cls: 0.05753  loss_rpn_loc: 0.143  time: 0.2237  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:22:07 d2.utils.events]: \u001b[0m eta: 0:22:29  iter: 90139  total_loss: 1.144  loss_cls: 0.2794  loss_box_reg: 0.4044  loss_mask: 0.2378  loss_rpn_cls: 0.06204  loss_rpn_loc: 0.1577  time: 0.2237  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:22:11 d2.utils.events]: \u001b[0m eta: 0:22:23  iter: 90159  total_loss: 1.067  loss_cls: 0.2416  loss_box_reg: 0.374  loss_mask: 0.25  loss_rpn_cls: 0.06666  loss_rpn_loc: 0.1564  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:22:15 d2.utils.events]: \u001b[0m eta: 0:22:20  iter: 90179  total_loss: 1.078  loss_cls: 0.2676  loss_box_reg: 0.3444  loss_mask: 0.2499  loss_rpn_cls: 0.06617  loss_rpn_loc: 0.1636  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:22:20 d2.utils.events]: \u001b[0m eta: 0:22:16  iter: 90199  total_loss: 1.204  loss_cls: 0.3115  loss_box_reg: 0.3649  loss_mask: 0.2547  loss_rpn_cls: 0.08002  loss_rpn_loc: 0.1645  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:22:24 d2.utils.events]: \u001b[0m eta: 0:22:12  iter: 90219  total_loss: 1.092  loss_cls: 0.2538  loss_box_reg: 0.3642  loss_mask: 0.2569  loss_rpn_cls: 0.0622  loss_rpn_loc: 0.1538  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:22:29 d2.utils.events]: \u001b[0m eta: 0:22:03  iter: 90239  total_loss: 1.154  loss_cls: 0.2515  loss_box_reg: 0.3676  loss_mask: 0.2689  loss_rpn_cls: 0.05099  loss_rpn_loc: 0.1701  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:22:33 d2.utils.events]: \u001b[0m eta: 0:22:02  iter: 90259  total_loss: 1.233  loss_cls: 0.2977  loss_box_reg: 0.3985  loss_mask: 0.273  loss_rpn_cls: 0.0723  loss_rpn_loc: 0.169  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 03:22:38 d2.utils.events]: \u001b[0m eta: 0:22:01  iter: 90279  total_loss: 1.22  loss_cls: 0.3071  loss_box_reg: 0.392  loss_mask: 0.2603  loss_rpn_cls: 0.06932  loss_rpn_loc: 0.1619  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:22:42 d2.utils.events]: \u001b[0m eta: 0:21:59  iter: 90299  total_loss: 1.16  loss_cls: 0.2443  loss_box_reg: 0.3577  loss_mask: 0.267  loss_rpn_cls: 0.07724  loss_rpn_loc: 0.1776  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:22:46 d2.utils.events]: \u001b[0m eta: 0:21:55  iter: 90319  total_loss: 1.019  loss_cls: 0.2413  loss_box_reg: 0.3881  loss_mask: 0.2427  loss_rpn_cls: 0.05822  loss_rpn_loc: 0.1462  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:22:51 d2.utils.events]: \u001b[0m eta: 0:21:51  iter: 90339  total_loss: 1.106  loss_cls: 0.2638  loss_box_reg: 0.3612  loss_mask: 0.254  loss_rpn_cls: 0.0653  loss_rpn_loc: 0.1541  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:22:55 d2.utils.events]: \u001b[0m eta: 0:21:45  iter: 90359  total_loss: 1.179  loss_cls: 0.3222  loss_box_reg: 0.3695  loss_mask: 0.2493  loss_rpn_cls: 0.07379  loss_rpn_loc: 0.1577  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:23:00 d2.utils.events]: \u001b[0m eta: 0:21:42  iter: 90379  total_loss: 1.157  loss_cls: 0.3004  loss_box_reg: 0.3846  loss_mask: 0.2818  loss_rpn_cls: 0.06541  loss_rpn_loc: 0.1589  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:23:05 d2.utils.events]: \u001b[0m eta: 0:21:38  iter: 90399  total_loss: 1.237  loss_cls: 0.2957  loss_box_reg: 0.3771  loss_mask: 0.2636  loss_rpn_cls: 0.08404  loss_rpn_loc: 0.1815  time: 0.2237  data_time: 0.0160  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:23:09 d2.utils.events]: \u001b[0m eta: 0:21:34  iter: 90419  total_loss: 1.145  loss_cls: 0.2815  loss_box_reg: 0.3636  loss_mask: 0.2441  loss_rpn_cls: 0.06628  loss_rpn_loc: 0.1471  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:23:14 d2.utils.events]: \u001b[0m eta: 0:21:31  iter: 90439  total_loss: 1.247  loss_cls: 0.329  loss_box_reg: 0.4052  loss_mask: 0.273  loss_rpn_cls: 0.0773  loss_rpn_loc: 0.1842  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:23:18 d2.utils.events]: \u001b[0m eta: 0:21:28  iter: 90459  total_loss: 0.9784  loss_cls: 0.2366  loss_box_reg: 0.333  loss_mask: 0.2561  loss_rpn_cls: 0.06509  loss_rpn_loc: 0.1586  time: 0.2237  data_time: 0.0183  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:23:23 d2.utils.events]: \u001b[0m eta: 0:21:23  iter: 90479  total_loss: 1.193  loss_cls: 0.2781  loss_box_reg: 0.4008  loss_mask: 0.2728  loss_rpn_cls: 0.07033  loss_rpn_loc: 0.1563  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:23:27 d2.utils.events]: \u001b[0m eta: 0:21:16  iter: 90499  total_loss: 1.205  loss_cls: 0.2903  loss_box_reg: 0.38  loss_mask: 0.2725  loss_rpn_cls: 0.07028  loss_rpn_loc: 0.1671  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:23:32 d2.utils.events]: \u001b[0m eta: 0:21:12  iter: 90519  total_loss: 0.9958  loss_cls: 0.2473  loss_box_reg: 0.3363  loss_mask: 0.2361  loss_rpn_cls: 0.05691  loss_rpn_loc: 0.1565  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:23:36 d2.utils.events]: \u001b[0m eta: 0:21:08  iter: 90539  total_loss: 1.162  loss_cls: 0.2687  loss_box_reg: 0.3767  loss_mask: 0.249  loss_rpn_cls: 0.06249  loss_rpn_loc: 0.1544  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:23:41 d2.utils.events]: \u001b[0m eta: 0:21:03  iter: 90559  total_loss: 1.135  loss_cls: 0.2643  loss_box_reg: 0.3637  loss_mask: 0.2682  loss_rpn_cls: 0.07096  loss_rpn_loc: 0.1566  time: 0.2237  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:23:45 d2.utils.events]: \u001b[0m eta: 0:20:58  iter: 90579  total_loss: 1.086  loss_cls: 0.2718  loss_box_reg: 0.3396  loss_mask: 0.2438  loss_rpn_cls: 0.06438  loss_rpn_loc: 0.1593  time: 0.2237  data_time: 0.0060  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:23:49 d2.utils.events]: \u001b[0m eta: 0:20:52  iter: 90599  total_loss: 1.141  loss_cls: 0.2973  loss_box_reg: 0.3677  loss_mask: 0.2641  loss_rpn_cls: 0.06107  loss_rpn_loc: 0.1662  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:23:54 d2.utils.events]: \u001b[0m eta: 0:20:50  iter: 90619  total_loss: 1.103  loss_cls: 0.2761  loss_box_reg: 0.3569  loss_mask: 0.2596  loss_rpn_cls: 0.05867  loss_rpn_loc: 0.155  time: 0.2237  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:23:58 d2.utils.events]: \u001b[0m eta: 0:20:45  iter: 90639  total_loss: 1.065  loss_cls: 0.2375  loss_box_reg: 0.3659  loss_mask: 0.2411  loss_rpn_cls: 0.06675  loss_rpn_loc: 0.1505  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:24:03 d2.utils.events]: \u001b[0m eta: 0:20:40  iter: 90659  total_loss: 1.216  loss_cls: 0.2615  loss_box_reg: 0.3652  loss_mask: 0.2601  loss_rpn_cls: 0.07395  loss_rpn_loc: 0.1669  time: 0.2237  data_time: 0.0121  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:24:08 d2.utils.events]: \u001b[0m eta: 0:20:35  iter: 90679  total_loss: 1.224  loss_cls: 0.293  loss_box_reg: 0.4285  loss_mask: 0.283  loss_rpn_cls: 0.05547  loss_rpn_loc: 0.1706  time: 0.2237  data_time: 0.0170  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:24:12 d2.utils.events]: \u001b[0m eta: 0:20:30  iter: 90699  total_loss: 1.04  loss_cls: 0.2392  loss_box_reg: 0.345  loss_mask: 0.2566  loss_rpn_cls: 0.06661  loss_rpn_loc: 0.1603  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:24:17 d2.utils.events]: \u001b[0m eta: 0:20:28  iter: 90719  total_loss: 1.042  loss_cls: 0.2279  loss_box_reg: 0.3598  loss_mask: 0.2475  loss_rpn_cls: 0.06074  loss_rpn_loc: 0.1485  time: 0.2237  data_time: 0.0145  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:24:21 d2.utils.events]: \u001b[0m eta: 0:20:23  iter: 90739  total_loss: 1.188  loss_cls: 0.3048  loss_box_reg: 0.3841  loss_mask: 0.2542  loss_rpn_cls: 0.06002  loss_rpn_loc: 0.1542  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:24:26 d2.utils.events]: \u001b[0m eta: 0:20:18  iter: 90759  total_loss: 1.298  loss_cls: 0.3101  loss_box_reg: 0.4105  loss_mask: 0.3011  loss_rpn_cls: 0.05516  loss_rpn_loc: 0.1909  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:24:30 d2.utils.events]: \u001b[0m eta: 0:20:15  iter: 90779  total_loss: 1.122  loss_cls: 0.2775  loss_box_reg: 0.3636  loss_mask: 0.2499  loss_rpn_cls: 0.05127  loss_rpn_loc: 0.1682  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:24:35 d2.utils.events]: \u001b[0m eta: 0:20:10  iter: 90799  total_loss: 1.278  loss_cls: 0.3124  loss_box_reg: 0.4299  loss_mask: 0.2654  loss_rpn_cls: 0.06999  loss_rpn_loc: 0.1698  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:24:39 d2.utils.events]: \u001b[0m eta: 0:20:06  iter: 90819  total_loss: 1.091  loss_cls: 0.2483  loss_box_reg: 0.3382  loss_mask: 0.2517  loss_rpn_cls: 0.06115  loss_rpn_loc: 0.1641  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:24:44 d2.utils.events]: \u001b[0m eta: 0:20:00  iter: 90839  total_loss: 1.199  loss_cls: 0.2812  loss_box_reg: 0.3688  loss_mask: 0.2519  loss_rpn_cls: 0.08064  loss_rpn_loc: 0.1505  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:24:48 d2.utils.events]: \u001b[0m eta: 0:19:56  iter: 90859  total_loss: 1.103  loss_cls: 0.2378  loss_box_reg: 0.3568  loss_mask: 0.2524  loss_rpn_cls: 0.05801  loss_rpn_loc: 0.1494  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:24:52 d2.utils.events]: \u001b[0m eta: 0:19:51  iter: 90879  total_loss: 1.105  loss_cls: 0.2613  loss_box_reg: 0.3496  loss_mask: 0.2522  loss_rpn_cls: 0.05888  loss_rpn_loc: 0.1552  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:24:57 d2.utils.events]: \u001b[0m eta: 0:19:47  iter: 90899  total_loss: 1.08  loss_cls: 0.2922  loss_box_reg: 0.368  loss_mask: 0.2655  loss_rpn_cls: 0.08273  loss_rpn_loc: 0.1796  time: 0.2237  data_time: 0.0107  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:25:02 d2.utils.events]: \u001b[0m eta: 0:19:45  iter: 90919  total_loss: 1.05  loss_cls: 0.2485  loss_box_reg: 0.336  loss_mask: 0.2426  loss_rpn_cls: 0.06342  loss_rpn_loc: 0.1466  time: 0.2237  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 03:25:06 d2.utils.events]: \u001b[0m eta: 0:19:41  iter: 90939  total_loss: 1.054  loss_cls: 0.2646  loss_box_reg: 0.3638  loss_mask: 0.2265  loss_rpn_cls: 0.04373  loss_rpn_loc: 0.1385  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:25:11 d2.utils.events]: \u001b[0m eta: 0:19:38  iter: 90959  total_loss: 1.104  loss_cls: 0.2516  loss_box_reg: 0.3663  loss_mask: 0.2525  loss_rpn_cls: 0.08805  loss_rpn_loc: 0.1738  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:25:15 d2.utils.events]: \u001b[0m eta: 0:19:35  iter: 90979  total_loss: 0.9859  loss_cls: 0.2332  loss_box_reg: 0.3388  loss_mask: 0.2432  loss_rpn_cls: 0.06591  loss_rpn_loc: 0.1561  time: 0.2237  data_time: 0.0091  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:25:20 d2.utils.events]: \u001b[0m eta: 0:19:31  iter: 90999  total_loss: 1.088  loss_cls: 0.2405  loss_box_reg: 0.3243  loss_mask: 0.2692  loss_rpn_cls: 0.04814  loss_rpn_loc: 0.1403  time: 0.2237  data_time: 0.0206  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:25:25 d2.utils.events]: \u001b[0m eta: 0:19:28  iter: 91019  total_loss: 1.161  loss_cls: 0.2669  loss_box_reg: 0.3836  loss_mask: 0.2604  loss_rpn_cls: 0.0682  loss_rpn_loc: 0.1649  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:25:30 d2.utils.events]: \u001b[0m eta: 0:19:23  iter: 91039  total_loss: 1.171  loss_cls: 0.2645  loss_box_reg: 0.3551  loss_mask: 0.2763  loss_rpn_cls: 0.0777  loss_rpn_loc: 0.1602  time: 0.2237  data_time: 0.0193  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:25:34 d2.utils.events]: \u001b[0m eta: 0:19:18  iter: 91059  total_loss: 1.036  loss_cls: 0.2551  loss_box_reg: 0.3743  loss_mask: 0.229  loss_rpn_cls: 0.041  loss_rpn_loc: 0.1583  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:25:38 d2.utils.events]: \u001b[0m eta: 0:19:15  iter: 91079  total_loss: 1.074  loss_cls: 0.2467  loss_box_reg: 0.344  loss_mask: 0.2399  loss_rpn_cls: 0.0527  loss_rpn_loc: 0.1404  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:25:43 d2.utils.events]: \u001b[0m eta: 0:19:09  iter: 91099  total_loss: 1.327  loss_cls: 0.3487  loss_box_reg: 0.3937  loss_mask: 0.2697  loss_rpn_cls: 0.08049  loss_rpn_loc: 0.1499  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:25:47 d2.utils.events]: \u001b[0m eta: 0:19:05  iter: 91119  total_loss: 1.198  loss_cls: 0.3115  loss_box_reg: 0.3487  loss_mask: 0.2581  loss_rpn_cls: 0.06579  loss_rpn_loc: 0.1509  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:25:52 d2.utils.events]: \u001b[0m eta: 0:19:03  iter: 91139  total_loss: 1.131  loss_cls: 0.2559  loss_box_reg: 0.353  loss_mask: 0.2487  loss_rpn_cls: 0.07262  loss_rpn_loc: 0.1528  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:25:56 d2.utils.events]: \u001b[0m eta: 0:18:59  iter: 91159  total_loss: 1.118  loss_cls: 0.2437  loss_box_reg: 0.3359  loss_mask: 0.2559  loss_rpn_cls: 0.09299  loss_rpn_loc: 0.1656  time: 0.2237  data_time: 0.0094  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:26:00 d2.utils.events]: \u001b[0m eta: 0:18:55  iter: 91179  total_loss: 1.319  loss_cls: 0.3198  loss_box_reg: 0.4238  loss_mask: 0.2519  loss_rpn_cls: 0.0725  loss_rpn_loc: 0.1899  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:26:05 d2.utils.events]: \u001b[0m eta: 0:18:50  iter: 91199  total_loss: 1.124  loss_cls: 0.234  loss_box_reg: 0.3537  loss_mask: 0.2478  loss_rpn_cls: 0.06072  loss_rpn_loc: 0.1738  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:26:10 d2.utils.events]: \u001b[0m eta: 0:18:46  iter: 91219  total_loss: 1.156  loss_cls: 0.239  loss_box_reg: 0.3672  loss_mask: 0.2561  loss_rpn_cls: 0.08635  loss_rpn_loc: 0.1922  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:26:14 d2.utils.events]: \u001b[0m eta: 0:18:42  iter: 91239  total_loss: 1.162  loss_cls: 0.2521  loss_box_reg: 0.3724  loss_mask: 0.2476  loss_rpn_cls: 0.06817  loss_rpn_loc: 0.1485  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:26:18 d2.utils.events]: \u001b[0m eta: 0:18:37  iter: 91259  total_loss: 1.021  loss_cls: 0.2836  loss_box_reg: 0.358  loss_mask: 0.2433  loss_rpn_cls: 0.06631  loss_rpn_loc: 0.1488  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:26:22 d2.utils.events]: \u001b[0m eta: 0:18:31  iter: 91279  total_loss: 1.118  loss_cls: 0.2547  loss_box_reg: 0.357  loss_mask: 0.2389  loss_rpn_cls: 0.05353  loss_rpn_loc: 0.1594  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:26:27 d2.utils.events]: \u001b[0m eta: 0:18:25  iter: 91299  total_loss: 1.097  loss_cls: 0.2735  loss_box_reg: 0.3278  loss_mask: 0.252  loss_rpn_cls: 0.04591  loss_rpn_loc: 0.1684  time: 0.2237  data_time: 0.0163  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:26:31 d2.utils.events]: \u001b[0m eta: 0:18:21  iter: 91319  total_loss: 1.306  loss_cls: 0.3345  loss_box_reg: 0.4157  loss_mask: 0.2688  loss_rpn_cls: 0.0787  loss_rpn_loc: 0.1671  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:26:36 d2.utils.events]: \u001b[0m eta: 0:18:18  iter: 91339  total_loss: 1.089  loss_cls: 0.2787  loss_box_reg: 0.3297  loss_mask: 0.242  loss_rpn_cls: 0.05665  loss_rpn_loc: 0.1561  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:26:41 d2.utils.events]: \u001b[0m eta: 0:18:15  iter: 91359  total_loss: 1.182  loss_cls: 0.2992  loss_box_reg: 0.3573  loss_mask: 0.2542  loss_rpn_cls: 0.08337  loss_rpn_loc: 0.1627  time: 0.2237  data_time: 0.0171  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:26:45 d2.utils.events]: \u001b[0m eta: 0:18:08  iter: 91379  total_loss: 1.17  loss_cls: 0.2715  loss_box_reg: 0.3745  loss_mask: 0.2546  loss_rpn_cls: 0.06866  loss_rpn_loc: 0.176  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:26:50 d2.utils.events]: \u001b[0m eta: 0:18:05  iter: 91399  total_loss: 1.216  loss_cls: 0.2878  loss_box_reg: 0.3665  loss_mask: 0.2627  loss_rpn_cls: 0.09039  loss_rpn_loc: 0.1799  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:26:54 d2.utils.events]: \u001b[0m eta: 0:17:59  iter: 91419  total_loss: 1.095  loss_cls: 0.2887  loss_box_reg: 0.318  loss_mask: 0.2579  loss_rpn_cls: 0.07364  loss_rpn_loc: 0.1455  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:26:58 d2.utils.events]: \u001b[0m eta: 0:17:56  iter: 91439  total_loss: 1.176  loss_cls: 0.2679  loss_box_reg: 0.3833  loss_mask: 0.2501  loss_rpn_cls: 0.06025  loss_rpn_loc: 0.1764  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:27:03 d2.utils.events]: \u001b[0m eta: 0:17:52  iter: 91459  total_loss: 1.139  loss_cls: 0.2974  loss_box_reg: 0.3742  loss_mask: 0.258  loss_rpn_cls: 0.06157  loss_rpn_loc: 0.1578  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:27:08 d2.utils.events]: \u001b[0m eta: 0:17:49  iter: 91479  total_loss: 1.177  loss_cls: 0.2742  loss_box_reg: 0.4101  loss_mask: 0.2669  loss_rpn_cls: 0.08246  loss_rpn_loc: 0.1779  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:27:12 d2.utils.events]: \u001b[0m eta: 0:17:45  iter: 91499  total_loss: 1.148  loss_cls: 0.2985  loss_box_reg: 0.3853  loss_mask: 0.2534  loss_rpn_cls: 0.08765  loss_rpn_loc: 0.1564  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:27:17 d2.utils.events]: \u001b[0m eta: 0:17:41  iter: 91519  total_loss: 1.118  loss_cls: 0.2635  loss_box_reg: 0.3688  loss_mask: 0.2498  loss_rpn_cls: 0.05661  loss_rpn_loc: 0.1422  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:27:20 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 3.09 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 03:27:20 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 03:27:20 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 03:27:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 03:27:21 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 03:27:21 d2.data.common]: \u001b[0mSerialized dataset takes 84.20 MiB\n",
      "\u001b[32m[12/30 03:27:24 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.45 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 03:27:24 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 03:27:24 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 03:27:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/30 03:27:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0007 s/iter. Inference: 0.0623 s/iter. Eval: 0.1452 s/iter. Total: 0.2083 s/iter. ETA=0:01:56\n",
      "\u001b[32m[12/30 03:27:33 d2.evaluation.evaluator]: \u001b[0mInference done 39/570. Dataloading: 0.0008 s/iter. Inference: 0.0582 s/iter. Eval: 0.1264 s/iter. Total: 0.1855 s/iter. ETA=0:01:38\n",
      "\u001b[32m[12/30 03:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 66/570. Dataloading: 0.0009 s/iter. Inference: 0.0558 s/iter. Eval: 0.1297 s/iter. Total: 0.1865 s/iter. ETA=0:01:33\n",
      "\u001b[32m[12/30 03:27:43 d2.evaluation.evaluator]: \u001b[0mInference done 92/570. Dataloading: 0.0009 s/iter. Inference: 0.0548 s/iter. Eval: 0.1332 s/iter. Total: 0.1889 s/iter. ETA=0:01:30\n",
      "\u001b[32m[12/30 03:27:48 d2.evaluation.evaluator]: \u001b[0mInference done 118/570. Dataloading: 0.0009 s/iter. Inference: 0.0547 s/iter. Eval: 0.1340 s/iter. Total: 0.1897 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/30 03:27:53 d2.evaluation.evaluator]: \u001b[0mInference done 143/570. Dataloading: 0.0009 s/iter. Inference: 0.0545 s/iter. Eval: 0.1369 s/iter. Total: 0.1924 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 03:27:58 d2.evaluation.evaluator]: \u001b[0mInference done 162/570. Dataloading: 0.0009 s/iter. Inference: 0.0547 s/iter. Eval: 0.1465 s/iter. Total: 0.2020 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 03:28:03 d2.evaluation.evaluator]: \u001b[0mInference done 175/570. Dataloading: 0.0009 s/iter. Inference: 0.0551 s/iter. Eval: 0.1618 s/iter. Total: 0.2179 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/30 03:28:08 d2.evaluation.evaluator]: \u001b[0mInference done 192/570. Dataloading: 0.0009 s/iter. Inference: 0.0556 s/iter. Eval: 0.1691 s/iter. Total: 0.2256 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/30 03:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 208/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1767 s/iter. Total: 0.2333 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/30 03:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 225/570. Dataloading: 0.0009 s/iter. Inference: 0.0561 s/iter. Eval: 0.1819 s/iter. Total: 0.2390 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 03:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 236/570. Dataloading: 0.0009 s/iter. Inference: 0.0563 s/iter. Eval: 0.1934 s/iter. Total: 0.2506 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 03:28:30 d2.evaluation.evaluator]: \u001b[0mInference done 249/570. Dataloading: 0.0028 s/iter. Inference: 0.0564 s/iter. Eval: 0.2024 s/iter. Total: 0.2617 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/30 03:28:35 d2.evaluation.evaluator]: \u001b[0mInference done 265/570. Dataloading: 0.0027 s/iter. Inference: 0.0566 s/iter. Eval: 0.2058 s/iter. Total: 0.2652 s/iter. ETA=0:01:20\n",
      "\u001b[32m[12/30 03:28:40 d2.evaluation.evaluator]: \u001b[0mInference done 283/570. Dataloading: 0.0026 s/iter. Inference: 0.0566 s/iter. Eval: 0.2072 s/iter. Total: 0.2664 s/iter. ETA=0:01:16\n",
      "\u001b[32m[12/30 03:28:46 d2.evaluation.evaluator]: \u001b[0mInference done 298/570. Dataloading: 0.0025 s/iter. Inference: 0.0566 s/iter. Eval: 0.2123 s/iter. Total: 0.2716 s/iter. ETA=0:01:13\n",
      "\u001b[32m[12/30 03:28:51 d2.evaluation.evaluator]: \u001b[0mInference done 345/570. Dataloading: 0.0023 s/iter. Inference: 0.0555 s/iter. Eval: 0.1910 s/iter. Total: 0.2488 s/iter. ETA=0:00:55\n",
      "\u001b[32m[12/30 03:28:56 d2.evaluation.evaluator]: \u001b[0mInference done 374/570. Dataloading: 0.0031 s/iter. Inference: 0.0552 s/iter. Eval: 0.1850 s/iter. Total: 0.2433 s/iter. ETA=0:00:47\n",
      "\u001b[32m[12/30 03:29:01 d2.evaluation.evaluator]: \u001b[0mInference done 395/570. Dataloading: 0.0030 s/iter. Inference: 0.0554 s/iter. Eval: 0.1847 s/iter. Total: 0.2431 s/iter. ETA=0:00:42\n",
      "\u001b[32m[12/30 03:29:06 d2.evaluation.evaluator]: \u001b[0mInference done 414/570. Dataloading: 0.0029 s/iter. Inference: 0.0554 s/iter. Eval: 0.1862 s/iter. Total: 0.2446 s/iter. ETA=0:00:38\n",
      "\u001b[32m[12/30 03:29:11 d2.evaluation.evaluator]: \u001b[0mInference done 433/570. Dataloading: 0.0028 s/iter. Inference: 0.0556 s/iter. Eval: 0.1872 s/iter. Total: 0.2457 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/30 03:29:17 d2.evaluation.evaluator]: \u001b[0mInference done 460/570. Dataloading: 0.0027 s/iter. Inference: 0.0555 s/iter. Eval: 0.1840 s/iter. Total: 0.2422 s/iter. ETA=0:00:26\n",
      "\u001b[32m[12/30 03:29:22 d2.evaluation.evaluator]: \u001b[0mInference done 494/570. Dataloading: 0.0026 s/iter. Inference: 0.0550 s/iter. Eval: 0.1783 s/iter. Total: 0.2360 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/30 03:29:27 d2.evaluation.evaluator]: \u001b[0mInference done 513/570. Dataloading: 0.0025 s/iter. Inference: 0.0549 s/iter. Eval: 0.1796 s/iter. Total: 0.2371 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/30 03:29:32 d2.evaluation.evaluator]: \u001b[0mInference done 538/570. Dataloading: 0.0024 s/iter. Inference: 0.0548 s/iter. Eval: 0.1786 s/iter. Total: 0.2359 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/30 03:29:37 d2.evaluation.evaluator]: \u001b[0mInference done 555/570. Dataloading: 0.0024 s/iter. Inference: 0.0550 s/iter. Eval: 0.1803 s/iter. Total: 0.2378 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 03:29:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:14.775524 (0.238541 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 03:29:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.055169 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 03:29:41 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/30 03:29:41 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.28902438654942436\n",
      "\u001b[32m[12/30 03:29:45 d2.utils.events]: \u001b[0m eta: 0:17:37  iter: 91539  total_loss: 1.138  loss_cls: 0.2911  loss_box_reg: 0.3576  loss_mask: 0.2471  loss_rpn_cls: 0.04438  loss_rpn_loc: 0.1523  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:29:49 d2.utils.events]: \u001b[0m eta: 0:17:31  iter: 91559  total_loss: 1.19  loss_cls: 0.2624  loss_box_reg: 0.3999  loss_mask: 0.2637  loss_rpn_cls: 0.05997  loss_rpn_loc: 0.1716  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:29:53 d2.utils.events]: \u001b[0m eta: 0:17:26  iter: 91579  total_loss: 1.093  loss_cls: 0.2731  loss_box_reg: 0.3519  loss_mask: 0.2495  loss_rpn_cls: 0.06089  loss_rpn_loc: 0.1484  time: 0.2237  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:29:58 d2.utils.events]: \u001b[0m eta: 0:17:22  iter: 91599  total_loss: 1.051  loss_cls: 0.2543  loss_box_reg: 0.3518  loss_mask: 0.2473  loss_rpn_cls: 0.0704  loss_rpn_loc: 0.1557  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:30:03 d2.utils.events]: \u001b[0m eta: 0:17:15  iter: 91619  total_loss: 1.151  loss_cls: 0.2757  loss_box_reg: 0.3633  loss_mask: 0.2498  loss_rpn_cls: 0.08656  loss_rpn_loc: 0.1728  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:30:07 d2.utils.events]: \u001b[0m eta: 0:17:09  iter: 91639  total_loss: 1.052  loss_cls: 0.246  loss_box_reg: 0.3407  loss_mask: 0.2483  loss_rpn_cls: 0.05987  loss_rpn_loc: 0.1479  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:30:12 d2.utils.events]: \u001b[0m eta: 0:17:08  iter: 91659  total_loss: 1.212  loss_cls: 0.2828  loss_box_reg: 0.3755  loss_mask: 0.2638  loss_rpn_cls: 0.09742  loss_rpn_loc: 0.1772  time: 0.2237  data_time: 0.0114  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:30:16 d2.utils.events]: \u001b[0m eta: 0:17:04  iter: 91679  total_loss: 1.196  loss_cls: 0.257  loss_box_reg: 0.3794  loss_mask: 0.2575  loss_rpn_cls: 0.06653  loss_rpn_loc: 0.1671  time: 0.2237  data_time: 0.0176  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:30:21 d2.utils.events]: \u001b[0m eta: 0:16:59  iter: 91699  total_loss: 1.207  loss_cls: 0.3016  loss_box_reg: 0.4126  loss_mask: 0.2764  loss_rpn_cls: 0.06744  loss_rpn_loc: 0.1555  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 03:30:25 d2.utils.events]: \u001b[0m eta: 0:16:52  iter: 91719  total_loss: 1.174  loss_cls: 0.2831  loss_box_reg: 0.41  loss_mask: 0.2558  loss_rpn_cls: 0.05963  loss_rpn_loc: 0.1607  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:30:30 d2.utils.events]: \u001b[0m eta: 0:16:49  iter: 91739  total_loss: 1.049  loss_cls: 0.2454  loss_box_reg: 0.3439  loss_mask: 0.242  loss_rpn_cls: 0.07595  loss_rpn_loc: 0.1753  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:30:34 d2.utils.events]: \u001b[0m eta: 0:16:46  iter: 91759  total_loss: 1.153  loss_cls: 0.2836  loss_box_reg: 0.361  loss_mask: 0.2414  loss_rpn_cls: 0.05786  loss_rpn_loc: 0.1848  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:30:39 d2.utils.events]: \u001b[0m eta: 0:16:40  iter: 91779  total_loss: 1.165  loss_cls: 0.2727  loss_box_reg: 0.3979  loss_mask: 0.2529  loss_rpn_cls: 0.05422  loss_rpn_loc: 0.1576  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:30:43 d2.utils.events]: \u001b[0m eta: 0:16:36  iter: 91799  total_loss: 1.115  loss_cls: 0.2901  loss_box_reg: 0.3658  loss_mask: 0.2542  loss_rpn_cls: 0.05682  loss_rpn_loc: 0.1543  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:30:48 d2.utils.events]: \u001b[0m eta: 0:16:30  iter: 91819  total_loss: 1.148  loss_cls: 0.284  loss_box_reg: 0.3866  loss_mask: 0.2568  loss_rpn_cls: 0.06234  loss_rpn_loc: 0.1743  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:30:52 d2.utils.events]: \u001b[0m eta: 0:16:26  iter: 91839  total_loss: 1.127  loss_cls: 0.2914  loss_box_reg: 0.3597  loss_mask: 0.2777  loss_rpn_cls: 0.06239  loss_rpn_loc: 0.1632  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:30:57 d2.utils.events]: \u001b[0m eta: 0:16:24  iter: 91859  total_loss: 1.201  loss_cls: 0.296  loss_box_reg: 0.3662  loss_mask: 0.2535  loss_rpn_cls: 0.07439  loss_rpn_loc: 0.1717  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:31:01 d2.utils.events]: \u001b[0m eta: 0:16:20  iter: 91879  total_loss: 1.205  loss_cls: 0.2886  loss_box_reg: 0.389  loss_mask: 0.2779  loss_rpn_cls: 0.07852  loss_rpn_loc: 0.1813  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:31:06 d2.utils.events]: \u001b[0m eta: 0:16:16  iter: 91899  total_loss: 1.145  loss_cls: 0.2613  loss_box_reg: 0.3613  loss_mask: 0.2725  loss_rpn_cls: 0.1155  loss_rpn_loc: 0.1699  time: 0.2237  data_time: 0.0188  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:31:11 d2.utils.events]: \u001b[0m eta: 0:16:11  iter: 91919  total_loss: 1.217  loss_cls: 0.2633  loss_box_reg: 0.376  loss_mask: 0.2625  loss_rpn_cls: 0.07275  loss_rpn_loc: 0.175  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:31:16 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 91939  total_loss: 1.091  loss_cls: 0.2388  loss_box_reg: 0.3766  loss_mask: 0.2634  loss_rpn_cls: 0.06098  loss_rpn_loc: 0.1712  time: 0.2237  data_time: 0.0259  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:31:20 d2.utils.events]: \u001b[0m eta: 0:16:02  iter: 91959  total_loss: 1.083  loss_cls: 0.2473  loss_box_reg: 0.3565  loss_mask: 0.2617  loss_rpn_cls: 0.08277  loss_rpn_loc: 0.1623  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:31:25 d2.utils.events]: \u001b[0m eta: 0:15:58  iter: 91979  total_loss: 1.244  loss_cls: 0.307  loss_box_reg: 0.4084  loss_mask: 0.2685  loss_rpn_cls: 0.07561  loss_rpn_loc: 0.1813  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:31:29 d2.utils.events]: \u001b[0m eta: 0:15:53  iter: 91999  total_loss: 1.146  loss_cls: 0.2806  loss_box_reg: 0.3585  loss_mask: 0.2465  loss_rpn_cls: 0.06161  loss_rpn_loc: 0.1497  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:31:34 d2.utils.events]: \u001b[0m eta: 0:15:48  iter: 92019  total_loss: 1.114  loss_cls: 0.2441  loss_box_reg: 0.3852  loss_mask: 0.2609  loss_rpn_cls: 0.05595  loss_rpn_loc: 0.1633  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:31:38 d2.utils.events]: \u001b[0m eta: 0:15:44  iter: 92039  total_loss: 1.068  loss_cls: 0.2416  loss_box_reg: 0.3403  loss_mask: 0.2467  loss_rpn_cls: 0.07191  loss_rpn_loc: 0.1607  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:31:43 d2.utils.events]: \u001b[0m eta: 0:15:40  iter: 92059  total_loss: 1.049  loss_cls: 0.2573  loss_box_reg: 0.3472  loss_mask: 0.2676  loss_rpn_cls: 0.06392  loss_rpn_loc: 0.1469  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:31:47 d2.utils.events]: \u001b[0m eta: 0:15:36  iter: 92079  total_loss: 0.9957  loss_cls: 0.206  loss_box_reg: 0.3168  loss_mask: 0.2364  loss_rpn_cls: 0.04587  loss_rpn_loc: 0.1447  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:31:52 d2.utils.events]: \u001b[0m eta: 0:15:32  iter: 92099  total_loss: 1.152  loss_cls: 0.2744  loss_box_reg: 0.368  loss_mask: 0.2655  loss_rpn_cls: 0.06687  loss_rpn_loc: 0.1596  time: 0.2237  data_time: 0.0094  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:31:56 d2.utils.events]: \u001b[0m eta: 0:15:28  iter: 92119  total_loss: 1.2  loss_cls: 0.2732  loss_box_reg: 0.3726  loss_mask: 0.2564  loss_rpn_cls: 0.08786  loss_rpn_loc: 0.1529  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:32:01 d2.utils.events]: \u001b[0m eta: 0:15:24  iter: 92139  total_loss: 1.194  loss_cls: 0.3112  loss_box_reg: 0.3879  loss_mask: 0.2677  loss_rpn_cls: 0.07373  loss_rpn_loc: 0.17  time: 0.2237  data_time: 0.0153  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:32:06 d2.utils.events]: \u001b[0m eta: 0:15:19  iter: 92159  total_loss: 1.154  loss_cls: 0.2999  loss_box_reg: 0.3759  loss_mask: 0.2478  loss_rpn_cls: 0.05494  loss_rpn_loc: 0.1704  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:32:10 d2.utils.events]: \u001b[0m eta: 0:15:14  iter: 92179  total_loss: 1.043  loss_cls: 0.248  loss_box_reg: 0.3376  loss_mask: 0.2526  loss_rpn_cls: 0.05921  loss_rpn_loc: 0.1516  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:32:14 d2.utils.events]: \u001b[0m eta: 0:15:10  iter: 92199  total_loss: 1.09  loss_cls: 0.288  loss_box_reg: 0.3691  loss_mask: 0.235  loss_rpn_cls: 0.06587  loss_rpn_loc: 0.1479  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:32:19 d2.utils.events]: \u001b[0m eta: 0:15:05  iter: 92219  total_loss: 1.171  loss_cls: 0.2925  loss_box_reg: 0.3541  loss_mask: 0.261  loss_rpn_cls: 0.08134  loss_rpn_loc: 0.1463  time: 0.2237  data_time: 0.0158  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:32:23 d2.utils.events]: \u001b[0m eta: 0:15:01  iter: 92239  total_loss: 1.214  loss_cls: 0.2824  loss_box_reg: 0.3845  loss_mask: 0.2499  loss_rpn_cls: 0.07815  loss_rpn_loc: 0.1677  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:32:28 d2.utils.events]: \u001b[0m eta: 0:14:56  iter: 92259  total_loss: 1.225  loss_cls: 0.3108  loss_box_reg: 0.3848  loss_mask: 0.2623  loss_rpn_cls: 0.08828  loss_rpn_loc: 0.1726  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:32:32 d2.utils.events]: \u001b[0m eta: 0:14:52  iter: 92279  total_loss: 1.138  loss_cls: 0.2716  loss_box_reg: 0.3453  loss_mask: 0.2422  loss_rpn_cls: 0.06682  loss_rpn_loc: 0.1598  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:32:37 d2.utils.events]: \u001b[0m eta: 0:14:48  iter: 92299  total_loss: 1.221  loss_cls: 0.2892  loss_box_reg: 0.3715  loss_mask: 0.2683  loss_rpn_cls: 0.08324  loss_rpn_loc: 0.1742  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:32:41 d2.utils.events]: \u001b[0m eta: 0:14:43  iter: 92319  total_loss: 1.081  loss_cls: 0.2643  loss_box_reg: 0.3331  loss_mask: 0.2346  loss_rpn_cls: 0.05824  loss_rpn_loc: 0.1509  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:32:46 d2.utils.events]: \u001b[0m eta: 0:14:39  iter: 92339  total_loss: 1.109  loss_cls: 0.2938  loss_box_reg: 0.3742  loss_mask: 0.2492  loss_rpn_cls: 0.0656  loss_rpn_loc: 0.1543  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:32:50 d2.utils.events]: \u001b[0m eta: 0:14:33  iter: 92359  total_loss: 1.075  loss_cls: 0.2804  loss_box_reg: 0.378  loss_mask: 0.2457  loss_rpn_cls: 0.07007  loss_rpn_loc: 0.166  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 03:32:54 d2.utils.events]: \u001b[0m eta: 0:14:30  iter: 92379  total_loss: 1.169  loss_cls: 0.2679  loss_box_reg: 0.3772  loss_mask: 0.2598  loss_rpn_cls: 0.05381  loss_rpn_loc: 0.1607  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:32:59 d2.utils.events]: \u001b[0m eta: 0:14:25  iter: 92399  total_loss: 1.164  loss_cls: 0.2832  loss_box_reg: 0.3895  loss_mask: 0.2498  loss_rpn_cls: 0.09018  loss_rpn_loc: 0.1622  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:33:03 d2.utils.events]: \u001b[0m eta: 0:14:21  iter: 92419  total_loss: 1.135  loss_cls: 0.2715  loss_box_reg: 0.3648  loss_mask: 0.2578  loss_rpn_cls: 0.06456  loss_rpn_loc: 0.1506  time: 0.2237  data_time: 0.0110  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:33:08 d2.utils.events]: \u001b[0m eta: 0:14:17  iter: 92439  total_loss: 1.244  loss_cls: 0.2945  loss_box_reg: 0.4116  loss_mask: 0.2711  loss_rpn_cls: 0.08334  loss_rpn_loc: 0.1757  time: 0.2237  data_time: 0.0285  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:33:13 d2.utils.events]: \u001b[0m eta: 0:14:11  iter: 92459  total_loss: 1.217  loss_cls: 0.3131  loss_box_reg: 0.3852  loss_mask: 0.263  loss_rpn_cls: 0.06753  loss_rpn_loc: 0.1793  time: 0.2237  data_time: 0.0243  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:33:18 d2.utils.events]: \u001b[0m eta: 0:14:06  iter: 92479  total_loss: 1.208  loss_cls: 0.3087  loss_box_reg: 0.3494  loss_mask: 0.2566  loss_rpn_cls: 0.05712  loss_rpn_loc: 0.1477  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:33:23 d2.utils.events]: \u001b[0m eta: 0:14:03  iter: 92499  total_loss: 1.067  loss_cls: 0.2378  loss_box_reg: 0.3254  loss_mask: 0.2503  loss_rpn_cls: 0.08568  loss_rpn_loc: 0.1684  time: 0.2237  data_time: 0.0167  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:33:27 d2.utils.events]: \u001b[0m eta: 0:13:58  iter: 92519  total_loss: 1.15  loss_cls: 0.2755  loss_box_reg: 0.3811  loss_mask: 0.2676  loss_rpn_cls: 0.06053  loss_rpn_loc: 0.15  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:33:31 d2.utils.events]: \u001b[0m eta: 0:13:54  iter: 92539  total_loss: 1.098  loss_cls: 0.2387  loss_box_reg: 0.3291  loss_mask: 0.249  loss_rpn_cls: 0.08187  loss_rpn_loc: 0.1491  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:33:36 d2.utils.events]: \u001b[0m eta: 0:13:50  iter: 92559  total_loss: 1.185  loss_cls: 0.2939  loss_box_reg: 0.35  loss_mask: 0.265  loss_rpn_cls: 0.08764  loss_rpn_loc: 0.1722  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:33:40 d2.utils.events]: \u001b[0m eta: 0:13:46  iter: 92579  total_loss: 1.121  loss_cls: 0.2969  loss_box_reg: 0.3947  loss_mask: 0.258  loss_rpn_cls: 0.06925  loss_rpn_loc: 0.1599  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:33:45 d2.utils.events]: \u001b[0m eta: 0:13:41  iter: 92599  total_loss: 1.172  loss_cls: 0.2833  loss_box_reg: 0.363  loss_mask: 0.277  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.1798  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:33:49 d2.utils.events]: \u001b[0m eta: 0:13:36  iter: 92619  total_loss: 1.173  loss_cls: 0.2733  loss_box_reg: 0.3422  loss_mask: 0.2617  loss_rpn_cls: 0.07811  loss_rpn_loc: 0.1408  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:33:53 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 92639  total_loss: 1.172  loss_cls: 0.2875  loss_box_reg: 0.3964  loss_mask: 0.2757  loss_rpn_cls: 0.06183  loss_rpn_loc: 0.15  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:33:58 d2.utils.events]: \u001b[0m eta: 0:13:27  iter: 92659  total_loss: 1.15  loss_cls: 0.2701  loss_box_reg: 0.3686  loss_mask: 0.2596  loss_rpn_cls: 0.05755  loss_rpn_loc: 0.1561  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:34:02 d2.utils.events]: \u001b[0m eta: 0:13:22  iter: 92679  total_loss: 1.124  loss_cls: 0.2905  loss_box_reg: 0.3732  loss_mask: 0.2492  loss_rpn_cls: 0.04496  loss_rpn_loc: 0.1604  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:34:07 d2.utils.events]: \u001b[0m eta: 0:13:17  iter: 92699  total_loss: 1.097  loss_cls: 0.2875  loss_box_reg: 0.3586  loss_mask: 0.231  loss_rpn_cls: 0.06308  loss_rpn_loc: 0.1584  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:34:11 d2.utils.events]: \u001b[0m eta: 0:13:13  iter: 92719  total_loss: 1.061  loss_cls: 0.25  loss_box_reg: 0.3425  loss_mask: 0.2462  loss_rpn_cls: 0.0632  loss_rpn_loc: 0.1517  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:34:16 d2.utils.events]: \u001b[0m eta: 0:13:09  iter: 92739  total_loss: 1.124  loss_cls: 0.2651  loss_box_reg: 0.3755  loss_mask: 0.2622  loss_rpn_cls: 0.0701  loss_rpn_loc: 0.1665  time: 0.2237  data_time: 0.0196  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:34:20 d2.utils.events]: \u001b[0m eta: 0:13:04  iter: 92759  total_loss: 1.126  loss_cls: 0.2559  loss_box_reg: 0.3542  loss_mask: 0.2624  loss_rpn_cls: 0.07735  loss_rpn_loc: 0.1553  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:34:25 d2.utils.events]: \u001b[0m eta: 0:13:00  iter: 92779  total_loss: 1.143  loss_cls: 0.2929  loss_box_reg: 0.3833  loss_mask: 0.2621  loss_rpn_cls: 0.07123  loss_rpn_loc: 0.1462  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:34:29 d2.utils.events]: \u001b[0m eta: 0:12:56  iter: 92799  total_loss: 1.233  loss_cls: 0.2965  loss_box_reg: 0.3862  loss_mask: 0.2755  loss_rpn_cls: 0.09803  loss_rpn_loc: 0.1746  time: 0.2237  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:34:34 d2.utils.events]: \u001b[0m eta: 0:12:51  iter: 92819  total_loss: 1.12  loss_cls: 0.2798  loss_box_reg: 0.3762  loss_mask: 0.2471  loss_rpn_cls: 0.05752  loss_rpn_loc: 0.1594  time: 0.2237  data_time: 0.0143  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:34:38 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 92839  total_loss: 1.213  loss_cls: 0.3099  loss_box_reg: 0.3697  loss_mask: 0.2682  loss_rpn_cls: 0.0815  loss_rpn_loc: 0.1631  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:34:42 d2.utils.events]: \u001b[0m eta: 0:12:41  iter: 92859  total_loss: 0.983  loss_cls: 0.233  loss_box_reg: 0.3176  loss_mask: 0.2173  loss_rpn_cls: 0.04461  loss_rpn_loc: 0.1272  time: 0.2237  data_time: 0.0055  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:34:47 d2.utils.events]: \u001b[0m eta: 0:12:37  iter: 92879  total_loss: 1.14  loss_cls: 0.2797  loss_box_reg: 0.3673  loss_mask: 0.2596  loss_rpn_cls: 0.05405  loss_rpn_loc: 0.1573  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:34:51 d2.utils.events]: \u001b[0m eta: 0:12:32  iter: 92899  total_loss: 1.17  loss_cls: 0.2857  loss_box_reg: 0.3789  loss_mask: 0.2902  loss_rpn_cls: 0.08826  loss_rpn_loc: 0.1642  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:34:56 d2.utils.events]: \u001b[0m eta: 0:12:28  iter: 92919  total_loss: 1.024  loss_cls: 0.2463  loss_box_reg: 0.343  loss_mask: 0.2405  loss_rpn_cls: 0.06255  loss_rpn_loc: 0.1543  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:35:00 d2.utils.events]: \u001b[0m eta: 0:12:24  iter: 92939  total_loss: 1.114  loss_cls: 0.2962  loss_box_reg: 0.3363  loss_mask: 0.2538  loss_rpn_cls: 0.08129  loss_rpn_loc: 0.1753  time: 0.2237  data_time: 0.0093  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:35:05 d2.utils.events]: \u001b[0m eta: 0:12:19  iter: 92959  total_loss: 1.285  loss_cls: 0.3433  loss_box_reg: 0.4076  loss_mask: 0.2686  loss_rpn_cls: 0.08631  loss_rpn_loc: 0.1593  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:35:09 d2.utils.events]: \u001b[0m eta: 0:12:14  iter: 92979  total_loss: 1.154  loss_cls: 0.2623  loss_box_reg: 0.3824  loss_mask: 0.2701  loss_rpn_cls: 0.06745  loss_rpn_loc: 0.1571  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:35:14 d2.utils.events]: \u001b[0m eta: 0:12:09  iter: 92999  total_loss: 1.197  loss_cls: 0.2822  loss_box_reg: 0.3593  loss_mask: 0.2664  loss_rpn_cls: 0.05903  loss_rpn_loc: 0.1568  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:35:18 d2.utils.events]: \u001b[0m eta: 0:12:05  iter: 93019  total_loss: 1.108  loss_cls: 0.2572  loss_box_reg: 0.3713  loss_mask: 0.2591  loss_rpn_cls: 0.06541  loss_rpn_loc: 0.1523  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 03:35:22 d2.utils.events]: \u001b[0m eta: 0:12:01  iter: 93039  total_loss: 1.144  loss_cls: 0.2702  loss_box_reg: 0.3982  loss_mask: 0.2648  loss_rpn_cls: 0.06986  loss_rpn_loc: 0.1568  time: 0.2237  data_time: 0.0086  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:35:27 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 93059  total_loss: 1.051  loss_cls: 0.2686  loss_box_reg: 0.3435  loss_mask: 0.2553  loss_rpn_cls: 0.06199  loss_rpn_loc: 0.1423  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:35:32 d2.utils.events]: \u001b[0m eta: 0:11:52  iter: 93079  total_loss: 1.127  loss_cls: 0.2363  loss_box_reg: 0.3362  loss_mask: 0.2438  loss_rpn_cls: 0.0756  loss_rpn_loc: 0.1624  time: 0.2237  data_time: 0.0176  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:35:36 d2.utils.events]: \u001b[0m eta: 0:11:47  iter: 93099  total_loss: 1.107  loss_cls: 0.2621  loss_box_reg: 0.3657  loss_mask: 0.2465  loss_rpn_cls: 0.07414  loss_rpn_loc: 0.1564  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:35:40 d2.utils.events]: \u001b[0m eta: 0:11:43  iter: 93119  total_loss: 1.103  loss_cls: 0.2619  loss_box_reg: 0.3675  loss_mask: 0.2672  loss_rpn_cls: 0.06894  loss_rpn_loc: 0.1618  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:35:45 d2.utils.events]: \u001b[0m eta: 0:11:38  iter: 93139  total_loss: 1.22  loss_cls: 0.316  loss_box_reg: 0.3832  loss_mask: 0.2532  loss_rpn_cls: 0.07415  loss_rpn_loc: 0.1634  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:35:50 d2.utils.events]: \u001b[0m eta: 0:11:34  iter: 93159  total_loss: 1.067  loss_cls: 0.2455  loss_box_reg: 0.3522  loss_mask: 0.2382  loss_rpn_cls: 0.07484  loss_rpn_loc: 0.1518  time: 0.2237  data_time: 0.0175  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:35:54 d2.utils.events]: \u001b[0m eta: 0:11:30  iter: 93179  total_loss: 1.079  loss_cls: 0.2695  loss_box_reg: 0.3593  loss_mask: 0.2283  loss_rpn_cls: 0.07242  loss_rpn_loc: 0.1558  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:35:58 d2.utils.events]: \u001b[0m eta: 0:11:26  iter: 93199  total_loss: 1.047  loss_cls: 0.2468  loss_box_reg: 0.331  loss_mask: 0.2327  loss_rpn_cls: 0.04816  loss_rpn_loc: 0.1366  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:36:03 d2.utils.events]: \u001b[0m eta: 0:11:21  iter: 93219  total_loss: 1.219  loss_cls: 0.2958  loss_box_reg: 0.3824  loss_mask: 0.2767  loss_rpn_cls: 0.0822  loss_rpn_loc: 0.1714  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:36:07 d2.utils.events]: \u001b[0m eta: 0:11:17  iter: 93239  total_loss: 1.077  loss_cls: 0.2574  loss_box_reg: 0.3571  loss_mask: 0.2457  loss_rpn_cls: 0.05678  loss_rpn_loc: 0.1634  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:36:12 d2.utils.events]: \u001b[0m eta: 0:11:12  iter: 93259  total_loss: 1.184  loss_cls: 0.3165  loss_box_reg: 0.3184  loss_mask: 0.257  loss_rpn_cls: 0.0783  loss_rpn_loc: 0.1544  time: 0.2237  data_time: 0.0180  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:36:16 d2.utils.events]: \u001b[0m eta: 0:11:07  iter: 93279  total_loss: 1.162  loss_cls: 0.2672  loss_box_reg: 0.3859  loss_mask: 0.262  loss_rpn_cls: 0.07082  loss_rpn_loc: 0.1537  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:36:21 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 93299  total_loss: 1.201  loss_cls: 0.2939  loss_box_reg: 0.3814  loss_mask: 0.2625  loss_rpn_cls: 0.04885  loss_rpn_loc: 0.1547  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:36:25 d2.utils.events]: \u001b[0m eta: 0:10:57  iter: 93319  total_loss: 1.175  loss_cls: 0.304  loss_box_reg: 0.4006  loss_mask: 0.2645  loss_rpn_cls: 0.07195  loss_rpn_loc: 0.1637  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:36:29 d2.utils.events]: \u001b[0m eta: 0:10:52  iter: 93339  total_loss: 1.187  loss_cls: 0.2618  loss_box_reg: 0.3673  loss_mask: 0.2496  loss_rpn_cls: 0.0879  loss_rpn_loc: 0.1537  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:36:34 d2.utils.events]: \u001b[0m eta: 0:10:48  iter: 93359  total_loss: 1.156  loss_cls: 0.3047  loss_box_reg: 0.3569  loss_mask: 0.2808  loss_rpn_cls: 0.07667  loss_rpn_loc: 0.1726  time: 0.2237  data_time: 0.0162  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:36:38 d2.utils.events]: \u001b[0m eta: 0:10:44  iter: 93379  total_loss: 1.201  loss_cls: 0.2677  loss_box_reg: 0.3927  loss_mask: 0.265  loss_rpn_cls: 0.05493  loss_rpn_loc: 0.1537  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:36:43 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 93399  total_loss: 1.238  loss_cls: 0.302  loss_box_reg: 0.3627  loss_mask: 0.2733  loss_rpn_cls: 0.08592  loss_rpn_loc: 0.1628  time: 0.2237  data_time: 0.0087  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:36:47 d2.utils.events]: \u001b[0m eta: 0:10:34  iter: 93419  total_loss: 1.227  loss_cls: 0.3228  loss_box_reg: 0.3548  loss_mask: 0.2521  loss_rpn_cls: 0.07472  loss_rpn_loc: 0.1659  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:36:52 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 93439  total_loss: 1.24  loss_cls: 0.3343  loss_box_reg: 0.3739  loss_mask: 0.255  loss_rpn_cls: 0.07921  loss_rpn_loc: 0.1464  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:36:56 d2.utils.events]: \u001b[0m eta: 0:10:25  iter: 93459  total_loss: 1.138  loss_cls: 0.2788  loss_box_reg: 0.3705  loss_mask: 0.2576  loss_rpn_cls: 0.06736  loss_rpn_loc: 0.1725  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:37:01 d2.utils.events]: \u001b[0m eta: 0:10:20  iter: 93479  total_loss: 1.116  loss_cls: 0.2418  loss_box_reg: 0.3693  loss_mask: 0.2398  loss_rpn_cls: 0.06355  loss_rpn_loc: 0.1578  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:37:05 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 93499  total_loss: 0.9744  loss_cls: 0.2297  loss_box_reg: 0.3338  loss_mask: 0.2312  loss_rpn_cls: 0.05961  loss_rpn_loc: 0.1373  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:37:10 d2.utils.events]: \u001b[0m eta: 0:10:11  iter: 93519  total_loss: 0.9599  loss_cls: 0.2473  loss_box_reg: 0.3397  loss_mask: 0.2475  loss_rpn_cls: 0.04036  loss_rpn_loc: 0.1481  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:37:14 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 93539  total_loss: 1.088  loss_cls: 0.2374  loss_box_reg: 0.375  loss_mask: 0.2512  loss_rpn_cls: 0.04344  loss_rpn_loc: 0.1492  time: 0.2237  data_time: 0.0147  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:37:18 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 93559  total_loss: 1.005  loss_cls: 0.2376  loss_box_reg: 0.336  loss_mask: 0.242  loss_rpn_cls: 0.0613  loss_rpn_loc: 0.1462  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:37:23 d2.utils.events]: \u001b[0m eta: 0:09:58  iter: 93579  total_loss: 1.166  loss_cls: 0.2644  loss_box_reg: 0.3913  loss_mask: 0.2765  loss_rpn_cls: 0.05219  loss_rpn_loc: 0.1657  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:37:27 d2.utils.events]: \u001b[0m eta: 0:09:53  iter: 93599  total_loss: 1.23  loss_cls: 0.3103  loss_box_reg: 0.4353  loss_mask: 0.2599  loss_rpn_cls: 0.07065  loss_rpn_loc: 0.1633  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:37:32 d2.utils.events]: \u001b[0m eta: 0:09:50  iter: 93619  total_loss: 1.114  loss_cls: 0.2652  loss_box_reg: 0.3643  loss_mask: 0.2603  loss_rpn_cls: 0.09065  loss_rpn_loc: 0.1664  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:37:37 d2.utils.events]: \u001b[0m eta: 0:09:46  iter: 93639  total_loss: 1.091  loss_cls: 0.263  loss_box_reg: 0.336  loss_mask: 0.2598  loss_rpn_cls: 0.09573  loss_rpn_loc: 0.1646  time: 0.2237  data_time: 0.0198  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:37:42 d2.utils.events]: \u001b[0m eta: 0:09:42  iter: 93659  total_loss: 1.173  loss_cls: 0.2872  loss_box_reg: 0.3168  loss_mask: 0.2773  loss_rpn_cls: 0.0754  loss_rpn_loc: 0.1761  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:37:46 d2.utils.events]: \u001b[0m eta: 0:09:38  iter: 93679  total_loss: 1.093  loss_cls: 0.2755  loss_box_reg: 0.3611  loss_mask: 0.2565  loss_rpn_cls: 0.07562  loss_rpn_loc: 0.1541  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 03:37:51 d2.utils.events]: \u001b[0m eta: 0:09:35  iter: 93699  total_loss: 1.062  loss_cls: 0.2744  loss_box_reg: 0.3698  loss_mask: 0.2389  loss_rpn_cls: 0.05288  loss_rpn_loc: 0.1466  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:37:55 d2.utils.events]: \u001b[0m eta: 0:09:30  iter: 93719  total_loss: 1.214  loss_cls: 0.2794  loss_box_reg: 0.3876  loss_mask: 0.2779  loss_rpn_cls: 0.09147  loss_rpn_loc: 0.18  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:37:59 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 93739  total_loss: 1.104  loss_cls: 0.2453  loss_box_reg: 0.3345  loss_mask: 0.2689  loss_rpn_cls: 0.06828  loss_rpn_loc: 0.1693  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:38:04 d2.utils.events]: \u001b[0m eta: 0:09:22  iter: 93759  total_loss: 1.054  loss_cls: 0.2407  loss_box_reg: 0.3475  loss_mask: 0.2422  loss_rpn_cls: 0.06383  loss_rpn_loc: 0.1426  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:38:08 d2.utils.events]: \u001b[0m eta: 0:09:17  iter: 93779  total_loss: 1.144  loss_cls: 0.3039  loss_box_reg: 0.3436  loss_mask: 0.2477  loss_rpn_cls: 0.08138  loss_rpn_loc: 0.1779  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:38:13 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 93799  total_loss: 1.105  loss_cls: 0.2565  loss_box_reg: 0.3782  loss_mask: 0.2622  loss_rpn_cls: 0.04861  loss_rpn_loc: 0.1636  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:38:17 d2.utils.events]: \u001b[0m eta: 0:09:09  iter: 93819  total_loss: 1.106  loss_cls: 0.2691  loss_box_reg: 0.375  loss_mask: 0.2547  loss_rpn_cls: 0.06643  loss_rpn_loc: 0.15  time: 0.2237  data_time: 0.0158  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:38:22 d2.utils.events]: \u001b[0m eta: 0:09:04  iter: 93839  total_loss: 1.136  loss_cls: 0.2841  loss_box_reg: 0.3773  loss_mask: 0.2756  loss_rpn_cls: 0.07462  loss_rpn_loc: 0.1492  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:38:26 d2.utils.events]: \u001b[0m eta: 0:09:00  iter: 93859  total_loss: 1.413  loss_cls: 0.3348  loss_box_reg: 0.4239  loss_mask: 0.2804  loss_rpn_cls: 0.1363  loss_rpn_loc: 0.195  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:38:30 d2.utils.events]: \u001b[0m eta: 0:08:55  iter: 93879  total_loss: 1.114  loss_cls: 0.2726  loss_box_reg: 0.3573  loss_mask: 0.2507  loss_rpn_cls: 0.05206  loss_rpn_loc: 0.1485  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:38:35 d2.utils.events]: \u001b[0m eta: 0:08:50  iter: 93899  total_loss: 1.195  loss_cls: 0.2797  loss_box_reg: 0.3311  loss_mask: 0.2549  loss_rpn_cls: 0.1032  loss_rpn_loc: 0.1672  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:38:40 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 93919  total_loss: 1.203  loss_cls: 0.2775  loss_box_reg: 0.3837  loss_mask: 0.2797  loss_rpn_cls: 0.07086  loss_rpn_loc: 0.1575  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:38:44 d2.utils.events]: \u001b[0m eta: 0:08:40  iter: 93939  total_loss: 1.17  loss_cls: 0.303  loss_box_reg: 0.3807  loss_mask: 0.2341  loss_rpn_cls: 0.0863  loss_rpn_loc: 0.1742  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:38:48 d2.utils.events]: \u001b[0m eta: 0:08:35  iter: 93959  total_loss: 1.038  loss_cls: 0.2472  loss_box_reg: 0.3541  loss_mask: 0.2429  loss_rpn_cls: 0.05144  loss_rpn_loc: 0.143  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:38:53 d2.utils.events]: \u001b[0m eta: 0:08:32  iter: 93979  total_loss: 1.107  loss_cls: 0.2874  loss_box_reg: 0.3386  loss_mask: 0.2563  loss_rpn_cls: 0.0871  loss_rpn_loc: 0.1627  time: 0.2237  data_time: 0.0176  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:38:57 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 93999  total_loss: 1.171  loss_cls: 0.2772  loss_box_reg: 0.382  loss_mask: 0.2726  loss_rpn_cls: 0.06888  loss_rpn_loc: 0.1701  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:39:02 d2.utils.events]: \u001b[0m eta: 0:08:23  iter: 94019  total_loss: 1.006  loss_cls: 0.2129  loss_box_reg: 0.3436  loss_mask: 0.2491  loss_rpn_cls: 0.0619  loss_rpn_loc: 0.1662  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:39:06 d2.utils.events]: \u001b[0m eta: 0:08:19  iter: 94039  total_loss: 1.173  loss_cls: 0.2585  loss_box_reg: 0.3667  loss_mask: 0.2506  loss_rpn_cls: 0.08145  loss_rpn_loc: 0.1688  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:39:11 d2.utils.events]: \u001b[0m eta: 0:08:14  iter: 94059  total_loss: 1.106  loss_cls: 0.2963  loss_box_reg: 0.3626  loss_mask: 0.2385  loss_rpn_cls: 0.06518  loss_rpn_loc: 0.1637  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:39:15 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 94079  total_loss: 1.118  loss_cls: 0.2696  loss_box_reg: 0.3452  loss_mask: 0.2632  loss_rpn_cls: 0.0808  loss_rpn_loc: 0.1757  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:39:20 d2.utils.events]: \u001b[0m eta: 0:08:08  iter: 94099  total_loss: 1.117  loss_cls: 0.2813  loss_box_reg: 0.3439  loss_mask: 0.2558  loss_rpn_cls: 0.07284  loss_rpn_loc: 0.1682  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:39:24 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 94119  total_loss: 1.192  loss_cls: 0.3109  loss_box_reg: 0.4037  loss_mask: 0.2565  loss_rpn_cls: 0.08056  loss_rpn_loc: 0.1559  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:39:29 d2.utils.events]: \u001b[0m eta: 0:07:59  iter: 94139  total_loss: 1.129  loss_cls: 0.2782  loss_box_reg: 0.3503  loss_mask: 0.2606  loss_rpn_cls: 0.07015  loss_rpn_loc: 0.1605  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:39:34 d2.utils.events]: \u001b[0m eta: 0:07:55  iter: 94159  total_loss: 1.113  loss_cls: 0.231  loss_box_reg: 0.3551  loss_mask: 0.2658  loss_rpn_cls: 0.07991  loss_rpn_loc: 0.1628  time: 0.2237  data_time: 0.0132  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:39:38 d2.utils.events]: \u001b[0m eta: 0:07:50  iter: 94179  total_loss: 1.182  loss_cls: 0.2799  loss_box_reg: 0.3613  loss_mask: 0.2574  loss_rpn_cls: 0.08286  loss_rpn_loc: 0.1614  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:39:43 d2.utils.events]: \u001b[0m eta: 0:07:46  iter: 94199  total_loss: 1.08  loss_cls: 0.2507  loss_box_reg: 0.3486  loss_mask: 0.2462  loss_rpn_cls: 0.0552  loss_rpn_loc: 0.1565  time: 0.2237  data_time: 0.0155  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:39:47 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 94219  total_loss: 1.198  loss_cls: 0.2902  loss_box_reg: 0.3951  loss_mask: 0.2611  loss_rpn_cls: 0.06605  loss_rpn_loc: 0.1539  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:39:51 d2.utils.events]: \u001b[0m eta: 0:07:37  iter: 94239  total_loss: 1.12  loss_cls: 0.2658  loss_box_reg: 0.3761  loss_mask: 0.2777  loss_rpn_cls: 0.07315  loss_rpn_loc: 0.1559  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:39:56 d2.utils.events]: \u001b[0m eta: 0:07:33  iter: 94259  total_loss: 1.077  loss_cls: 0.2487  loss_box_reg: 0.3531  loss_mask: 0.2435  loss_rpn_cls: 0.06703  loss_rpn_loc: 0.1645  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:40:00 d2.utils.events]: \u001b[0m eta: 0:07:29  iter: 94279  total_loss: 1.157  loss_cls: 0.3043  loss_box_reg: 0.3777  loss_mask: 0.2408  loss_rpn_cls: 0.06665  loss_rpn_loc: 0.1437  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:40:05 d2.utils.events]: \u001b[0m eta: 0:07:25  iter: 94299  total_loss: 1.134  loss_cls: 0.2957  loss_box_reg: 0.3744  loss_mask: 0.2548  loss_rpn_cls: 0.06349  loss_rpn_loc: 0.1574  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:40:10 d2.utils.events]: \u001b[0m eta: 0:07:21  iter: 94319  total_loss: 1.071  loss_cls: 0.2496  loss_box_reg: 0.3309  loss_mask: 0.2413  loss_rpn_cls: 0.05709  loss_rpn_loc: 0.1491  time: 0.2237  data_time: 0.0132  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:40:14 d2.utils.events]: \u001b[0m eta: 0:07:16  iter: 94339  total_loss: 1.138  loss_cls: 0.2967  loss_box_reg: 0.4075  loss_mask: 0.2368  loss_rpn_cls: 0.07052  loss_rpn_loc: 0.1524  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 03:40:19 d2.utils.events]: \u001b[0m eta: 0:07:12  iter: 94359  total_loss: 1.088  loss_cls: 0.2509  loss_box_reg: 0.3494  loss_mask: 0.2643  loss_rpn_cls: 0.05909  loss_rpn_loc: 0.1624  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:40:23 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 94379  total_loss: 1.213  loss_cls: 0.2768  loss_box_reg: 0.3752  loss_mask: 0.2564  loss_rpn_cls: 0.07053  loss_rpn_loc: 0.1538  time: 0.2237  data_time: 0.0102  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:40:27 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 94399  total_loss: 1.055  loss_cls: 0.2441  loss_box_reg: 0.3147  loss_mask: 0.2475  loss_rpn_cls: 0.05754  loss_rpn_loc: 0.1583  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:40:32 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 94419  total_loss: 1.163  loss_cls: 0.2853  loss_box_reg: 0.3648  loss_mask: 0.2586  loss_rpn_cls: 0.06214  loss_rpn_loc: 0.1681  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:40:36 d2.utils.events]: \u001b[0m eta: 0:06:55  iter: 94439  total_loss: 1.199  loss_cls: 0.313  loss_box_reg: 0.4068  loss_mask: 0.2675  loss_rpn_cls: 0.06561  loss_rpn_loc: 0.1583  time: 0.2237  data_time: 0.0191  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:40:41 d2.utils.events]: \u001b[0m eta: 0:06:51  iter: 94459  total_loss: 1.181  loss_cls: 0.2999  loss_box_reg: 0.3365  loss_mask: 0.2571  loss_rpn_cls: 0.07374  loss_rpn_loc: 0.1543  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:40:45 d2.utils.events]: \u001b[0m eta: 0:06:47  iter: 94479  total_loss: 1.211  loss_cls: 0.3091  loss_box_reg: 0.3655  loss_mask: 0.2603  loss_rpn_cls: 0.07107  loss_rpn_loc: 0.1615  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:40:49 d2.utils.events]: \u001b[0m eta: 0:06:42  iter: 94499  total_loss: 1.121  loss_cls: 0.2983  loss_box_reg: 0.3896  loss_mask: 0.2492  loss_rpn_cls: 0.06471  loss_rpn_loc: 0.1494  time: 0.2237  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:40:54 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 94519  total_loss: 1.278  loss_cls: 0.3423  loss_box_reg: 0.372  loss_mask: 0.2613  loss_rpn_cls: 0.06153  loss_rpn_loc: 0.1682  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:40:58 d2.utils.events]: \u001b[0m eta: 0:06:33  iter: 94539  total_loss: 1.201  loss_cls: 0.308  loss_box_reg: 0.411  loss_mask: 0.2516  loss_rpn_cls: 0.05744  loss_rpn_loc: 0.1523  time: 0.2237  data_time: 0.0063  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:41:03 d2.utils.events]: \u001b[0m eta: 0:06:29  iter: 94559  total_loss: 1.139  loss_cls: 0.2591  loss_box_reg: 0.3328  loss_mask: 0.2722  loss_rpn_cls: 0.05695  loss_rpn_loc: 0.1568  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:41:07 d2.utils.events]: \u001b[0m eta: 0:06:25  iter: 94579  total_loss: 1.195  loss_cls: 0.2768  loss_box_reg: 0.338  loss_mask: 0.2593  loss_rpn_cls: 0.08849  loss_rpn_loc: 0.17  time: 0.2237  data_time: 0.0151  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:41:12 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 94599  total_loss: 1.152  loss_cls: 0.2961  loss_box_reg: 0.3754  loss_mask: 0.2564  loss_rpn_cls: 0.07244  loss_rpn_loc: 0.1501  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:41:16 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 94619  total_loss: 1.164  loss_cls: 0.3006  loss_box_reg: 0.3704  loss_mask: 0.2629  loss_rpn_cls: 0.07032  loss_rpn_loc: 0.1544  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:41:21 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 94639  total_loss: 1.048  loss_cls: 0.2567  loss_box_reg: 0.3552  loss_mask: 0.242  loss_rpn_cls: 0.06828  loss_rpn_loc: 0.1559  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:41:25 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 94659  total_loss: 1.017  loss_cls: 0.2433  loss_box_reg: 0.3286  loss_mask: 0.2365  loss_rpn_cls: 0.08259  loss_rpn_loc: 0.1542  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:41:29 d2.utils.events]: \u001b[0m eta: 0:06:02  iter: 94679  total_loss: 1.242  loss_cls: 0.3183  loss_box_reg: 0.3935  loss_mask: 0.264  loss_rpn_cls: 0.07626  loss_rpn_loc: 0.1749  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:41:34 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 94699  total_loss: 1.085  loss_cls: 0.2393  loss_box_reg: 0.3391  loss_mask: 0.2438  loss_rpn_cls: 0.04758  loss_rpn_loc: 0.144  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:41:38 d2.utils.events]: \u001b[0m eta: 0:05:54  iter: 94719  total_loss: 1.183  loss_cls: 0.3099  loss_box_reg: 0.4069  loss_mask: 0.263  loss_rpn_cls: 0.08696  loss_rpn_loc: 0.1683  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:41:43 d2.utils.events]: \u001b[0m eta: 0:05:50  iter: 94739  total_loss: 1.152  loss_cls: 0.2705  loss_box_reg: 0.3929  loss_mask: 0.2768  loss_rpn_cls: 0.05056  loss_rpn_loc: 0.1546  time: 0.2237  data_time: 0.0185  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:41:47 d2.utils.events]: \u001b[0m eta: 0:05:45  iter: 94759  total_loss: 1.251  loss_cls: 0.306  loss_box_reg: 0.4119  loss_mask: 0.2819  loss_rpn_cls: 0.08552  loss_rpn_loc: 0.1589  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:41:52 d2.utils.events]: \u001b[0m eta: 0:05:40  iter: 94779  total_loss: 1.157  loss_cls: 0.3066  loss_box_reg: 0.3882  loss_mask: 0.2449  loss_rpn_cls: 0.0555  loss_rpn_loc: 0.1446  time: 0.2237  data_time: 0.0061  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:41:56 d2.utils.events]: \u001b[0m eta: 0:05:36  iter: 94799  total_loss: 1.081  loss_cls: 0.2695  loss_box_reg: 0.3416  loss_mask: 0.2492  loss_rpn_cls: 0.0526  loss_rpn_loc: 0.153  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:42:00 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 94819  total_loss: 1.144  loss_cls: 0.2657  loss_box_reg: 0.3568  loss_mask: 0.2713  loss_rpn_cls: 0.06797  loss_rpn_loc: 0.1752  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:42:05 d2.utils.events]: \u001b[0m eta: 0:05:27  iter: 94839  total_loss: 1.155  loss_cls: 0.2916  loss_box_reg: 0.3661  loss_mask: 0.2527  loss_rpn_cls: 0.05704  loss_rpn_loc: 0.1511  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:42:09 d2.utils.events]: \u001b[0m eta: 0:05:23  iter: 94859  total_loss: 1.161  loss_cls: 0.2861  loss_box_reg: 0.3618  loss_mask: 0.249  loss_rpn_cls: 0.07657  loss_rpn_loc: 0.1575  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:42:14 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 94879  total_loss: 1.297  loss_cls: 0.3193  loss_box_reg: 0.4065  loss_mask: 0.2849  loss_rpn_cls: 0.08712  loss_rpn_loc: 0.1925  time: 0.2237  data_time: 0.0085  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:42:19 d2.utils.events]: \u001b[0m eta: 0:05:14  iter: 94899  total_loss: 1.096  loss_cls: 0.2539  loss_box_reg: 0.3631  loss_mask: 0.2601  loss_rpn_cls: 0.07254  loss_rpn_loc: 0.1542  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:42:23 d2.utils.events]: \u001b[0m eta: 0:05:10  iter: 94919  total_loss: 1.173  loss_cls: 0.2963  loss_box_reg: 0.3476  loss_mask: 0.274  loss_rpn_cls: 0.09425  loss_rpn_loc: 0.1599  time: 0.2237  data_time: 0.0103  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:42:28 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 94939  total_loss: 1.15  loss_cls: 0.2779  loss_box_reg: 0.3562  loss_mask: 0.26  loss_rpn_cls: 0.06891  loss_rpn_loc: 0.1571  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:42:33 d2.utils.events]: \u001b[0m eta: 0:05:02  iter: 94959  total_loss: 1.077  loss_cls: 0.2342  loss_box_reg: 0.3351  loss_mask: 0.2425  loss_rpn_cls: 0.0651  loss_rpn_loc: 0.1517  time: 0.2237  data_time: 0.0136  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:42:37 d2.utils.events]: \u001b[0m eta: 0:04:57  iter: 94979  total_loss: 1.134  loss_cls: 0.2783  loss_box_reg: 0.3756  loss_mask: 0.262  loss_rpn_cls: 0.08434  loss_rpn_loc: 0.1598  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:42:42 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 94999  total_loss: 1.112  loss_cls: 0.2671  loss_box_reg: 0.3621  loss_mask: 0.2547  loss_rpn_cls: 0.07033  loss_rpn_loc: 0.1575  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 03:42:46 d2.utils.events]: \u001b[0m eta: 0:04:49  iter: 95019  total_loss: 1.156  loss_cls: 0.2992  loss_box_reg: 0.359  loss_mask: 0.2588  loss_rpn_cls: 0.07122  loss_rpn_loc: 0.152  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:42:51 d2.utils.events]: \u001b[0m eta: 0:04:44  iter: 95039  total_loss: 1.113  loss_cls: 0.2765  loss_box_reg: 0.3421  loss_mask: 0.2494  loss_rpn_cls: 0.07668  loss_rpn_loc: 0.1377  time: 0.2237  data_time: 0.0202  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:42:55 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 95059  total_loss: 1.095  loss_cls: 0.2528  loss_box_reg: 0.3645  loss_mask: 0.2491  loss_rpn_cls: 0.06525  loss_rpn_loc: 0.135  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:43:00 d2.utils.events]: \u001b[0m eta: 0:04:35  iter: 95079  total_loss: 1.295  loss_cls: 0.3293  loss_box_reg: 0.4075  loss_mask: 0.2789  loss_rpn_cls: 0.08958  loss_rpn_loc: 0.1871  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:43:04 d2.utils.events]: \u001b[0m eta: 0:04:30  iter: 95099  total_loss: 1.215  loss_cls: 0.3085  loss_box_reg: 0.3991  loss_mask: 0.2411  loss_rpn_cls: 0.05874  loss_rpn_loc: 0.1558  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:43:09 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 95119  total_loss: 1.053  loss_cls: 0.2705  loss_box_reg: 0.3557  loss_mask: 0.2477  loss_rpn_cls: 0.0513  loss_rpn_loc: 0.1512  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:43:13 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 95139  total_loss: 1.133  loss_cls: 0.2634  loss_box_reg: 0.3587  loss_mask: 0.2503  loss_rpn_cls: 0.08162  loss_rpn_loc: 0.1562  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:43:18 d2.utils.events]: \u001b[0m eta: 0:04:17  iter: 95159  total_loss: 1.159  loss_cls: 0.2564  loss_box_reg: 0.3374  loss_mask: 0.2639  loss_rpn_cls: 0.08333  loss_rpn_loc: 0.1557  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:43:22 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 95179  total_loss: 0.9702  loss_cls: 0.2087  loss_box_reg: 0.2905  loss_mask: 0.2331  loss_rpn_cls: 0.06326  loss_rpn_loc: 0.1509  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:43:27 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 95199  total_loss: 1.045  loss_cls: 0.2169  loss_box_reg: 0.3551  loss_mask: 0.2497  loss_rpn_cls: 0.04373  loss_rpn_loc: 0.1463  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:43:31 d2.utils.events]: \u001b[0m eta: 0:04:04  iter: 95219  total_loss: 1.151  loss_cls: 0.2684  loss_box_reg: 0.3712  loss_mask: 0.2518  loss_rpn_cls: 0.06327  loss_rpn_loc: 0.1768  time: 0.2237  data_time: 0.0083  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:43:36 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 95239  total_loss: 1.213  loss_cls: 0.3025  loss_box_reg: 0.389  loss_mask: 0.2627  loss_rpn_cls: 0.06337  loss_rpn_loc: 0.1643  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:43:40 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 95259  total_loss: 1.183  loss_cls: 0.3015  loss_box_reg: 0.3927  loss_mask: 0.2697  loss_rpn_cls: 0.06862  loss_rpn_loc: 0.1496  time: 0.2237  data_time: 0.0125  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:43:44 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 95279  total_loss: 1.126  loss_cls: 0.2557  loss_box_reg: 0.3645  loss_mask: 0.2497  loss_rpn_cls: 0.06518  loss_rpn_loc: 0.1452  time: 0.2237  data_time: 0.0078  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:43:49 d2.utils.events]: \u001b[0m eta: 0:03:47  iter: 95299  total_loss: 1.294  loss_cls: 0.3372  loss_box_reg: 0.3984  loss_mask: 0.2637  loss_rpn_cls: 0.08466  loss_rpn_loc: 0.1706  time: 0.2237  data_time: 0.0081  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:43:53 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 95319  total_loss: 1.22  loss_cls: 0.3273  loss_box_reg: 0.3724  loss_mask: 0.2675  loss_rpn_cls: 0.08067  loss_rpn_loc: 0.1666  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:43:58 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 95339  total_loss: 1.14  loss_cls: 0.2657  loss_box_reg: 0.3772  loss_mask: 0.2545  loss_rpn_cls: 0.06664  loss_rpn_loc: 0.1495  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:44:02 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 95359  total_loss: 1.101  loss_cls: 0.2493  loss_box_reg: 0.3601  loss_mask: 0.2614  loss_rpn_cls: 0.0637  loss_rpn_loc: 0.1594  time: 0.2237  data_time: 0.0221  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:44:07 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 95379  total_loss: 1.105  loss_cls: 0.2529  loss_box_reg: 0.3549  loss_mask: 0.2532  loss_rpn_cls: 0.06084  loss_rpn_loc: 0.1604  time: 0.2237  data_time: 0.0070  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:44:11 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 95399  total_loss: 1.164  loss_cls: 0.2818  loss_box_reg: 0.3819  loss_mask: 0.2629  loss_rpn_cls: 0.05922  loss_rpn_loc: 0.1517  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:44:16 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 95419  total_loss: 1.285  loss_cls: 0.3076  loss_box_reg: 0.4222  loss_mask: 0.2612  loss_rpn_cls: 0.07367  loss_rpn_loc: 0.1715  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:44:20 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 95439  total_loss: 1.117  loss_cls: 0.271  loss_box_reg: 0.3979  loss_mask: 0.2601  loss_rpn_cls: 0.06671  loss_rpn_loc: 0.1602  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:44:24 d2.utils.events]: \u001b[0m eta: 0:03:11  iter: 95459  total_loss: 1.135  loss_cls: 0.2701  loss_box_reg: 0.366  loss_mask: 0.2401  loss_rpn_cls: 0.06861  loss_rpn_loc: 0.146  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:44:29 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 95479  total_loss: 1.123  loss_cls: 0.2481  loss_box_reg: 0.351  loss_mask: 0.2694  loss_rpn_cls: 0.09517  loss_rpn_loc: 0.1541  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:44:33 d2.utils.events]: \u001b[0m eta: 0:03:03  iter: 95499  total_loss: 1.069  loss_cls: 0.2401  loss_box_reg: 0.3393  loss_mask: 0.248  loss_rpn_cls: 0.06317  loss_rpn_loc: 0.1633  time: 0.2237  data_time: 0.0077  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:44:38 d2.utils.events]: \u001b[0m eta: 0:02:58  iter: 95519  total_loss: 1.091  loss_cls: 0.249  loss_box_reg: 0.3914  loss_mask: 0.2476  loss_rpn_cls: 0.05431  loss_rpn_loc: 0.1413  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:44:42 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 95539  total_loss: 1.151  loss_cls: 0.2797  loss_box_reg: 0.3639  loss_mask: 0.2496  loss_rpn_cls: 0.06977  loss_rpn_loc: 0.1447  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:44:47 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 95559  total_loss: 1.17  loss_cls: 0.2704  loss_box_reg: 0.3674  loss_mask: 0.2618  loss_rpn_cls: 0.07871  loss_rpn_loc: 0.1562  time: 0.2237  data_time: 0.0073  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:44:51 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 95579  total_loss: 1.23  loss_cls: 0.2982  loss_box_reg: 0.435  loss_mask: 0.2762  loss_rpn_cls: 0.07933  loss_rpn_loc: 0.1558  time: 0.2237  data_time: 0.0065  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:44:55 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 95599  total_loss: 1.147  loss_cls: 0.2747  loss_box_reg: 0.3523  loss_mask: 0.241  loss_rpn_cls: 0.05908  loss_rpn_loc: 0.1677  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:45:00 d2.utils.events]: \u001b[0m eta: 0:02:36  iter: 95619  total_loss: 1.117  loss_cls: 0.2697  loss_box_reg: 0.3875  loss_mask: 0.2564  loss_rpn_cls: 0.07272  loss_rpn_loc: 0.1524  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:45:04 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 95639  total_loss: 1.226  loss_cls: 0.3111  loss_box_reg: 0.3494  loss_mask: 0.2701  loss_rpn_cls: 0.1057  loss_rpn_loc: 0.1805  time: 0.2237  data_time: 0.0149  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:45:09 d2.utils.events]: \u001b[0m eta: 0:02:28  iter: 95659  total_loss: 1.111  loss_cls: 0.2655  loss_box_reg: 0.3893  loss_mask: 0.261  loss_rpn_cls: 0.05077  loss_rpn_loc: 0.1571  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 03:45:13 d2.utils.events]: \u001b[0m eta: 0:02:23  iter: 95679  total_loss: 1.017  loss_cls: 0.2267  loss_box_reg: 0.3483  loss_mask: 0.2453  loss_rpn_cls: 0.0707  loss_rpn_loc: 0.1675  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:45:18 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 95699  total_loss: 1.08  loss_cls: 0.2543  loss_box_reg: 0.3381  loss_mask: 0.2429  loss_rpn_cls: 0.05703  loss_rpn_loc: 0.1529  time: 0.2237  data_time: 0.0245  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:45:22 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 95719  total_loss: 1.175  loss_cls: 0.3113  loss_box_reg: 0.3856  loss_mask: 0.2728  loss_rpn_cls: 0.08695  loss_rpn_loc: 0.1644  time: 0.2237  data_time: 0.0080  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:45:27 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 95739  total_loss: 1.221  loss_cls: 0.2891  loss_box_reg: 0.3882  loss_mask: 0.2765  loss_rpn_cls: 0.07242  loss_rpn_loc: 0.16  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:45:32 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 95759  total_loss: 1.171  loss_cls: 0.2921  loss_box_reg: 0.3628  loss_mask: 0.2676  loss_rpn_cls: 0.05619  loss_rpn_loc: 0.151  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:45:36 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 95779  total_loss: 1.199  loss_cls: 0.2782  loss_box_reg: 0.3831  loss_mask: 0.2626  loss_rpn_cls: 0.08335  loss_rpn_loc: 0.1899  time: 0.2237  data_time: 0.0084  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:45:41 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 95799  total_loss: 1.202  loss_cls: 0.3286  loss_box_reg: 0.3968  loss_mask: 0.2612  loss_rpn_cls: 0.05851  loss_rpn_loc: 0.1649  time: 0.2237  data_time: 0.0064  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:45:46 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 95819  total_loss: 1.071  loss_cls: 0.2328  loss_box_reg: 0.3208  loss_mask: 0.2507  loss_rpn_cls: 0.08646  loss_rpn_loc: 0.172  time: 0.2237  data_time: 0.0090  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:45:50 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 95839  total_loss: 1.116  loss_cls: 0.2649  loss_box_reg: 0.3953  loss_mask: 0.2681  loss_rpn_cls: 0.05152  loss_rpn_loc: 0.1586  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:45:55 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 95859  total_loss: 1.183  loss_cls: 0.2732  loss_box_reg: 0.3665  loss_mask: 0.25  loss_rpn_cls: 0.0489  loss_rpn_loc: 0.1524  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:45:59 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 95879  total_loss: 1.113  loss_cls: 0.2737  loss_box_reg: 0.3604  loss_mask: 0.2538  loss_rpn_cls: 0.05873  loss_rpn_loc: 0.1557  time: 0.2237  data_time: 0.0169  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:46:04 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 95899  total_loss: 1.053  loss_cls: 0.2428  loss_box_reg: 0.3213  loss_mask: 0.2352  loss_rpn_cls: 0.05434  loss_rpn_loc: 0.1789  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:46:08 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 95919  total_loss: 1.18  loss_cls: 0.3075  loss_box_reg: 0.3875  loss_mask: 0.2544  loss_rpn_cls: 0.08116  loss_rpn_loc: 0.1674  time: 0.2237  data_time: 0.0132  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:46:13 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 95939  total_loss: 1.122  loss_cls: 0.2849  loss_box_reg: 0.3633  loss_mask: 0.2518  loss_rpn_cls: 0.07232  loss_rpn_loc: 0.1555  time: 0.2237  data_time: 0.0074  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:46:18 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 95959  total_loss: 1.186  loss_cls: 0.2702  loss_box_reg: 0.367  loss_mask: 0.2601  loss_rpn_cls: 0.07797  loss_rpn_loc: 0.1565  time: 0.2237  data_time: 0.0176  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:46:22 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 95979  total_loss: 1.114  loss_cls: 0.2644  loss_box_reg: 0.3209  loss_mask: 0.2543  loss_rpn_cls: 0.06625  loss_rpn_loc: 0.1638  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:46:27 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 95999  total_loss: 1.142  loss_cls: 0.2735  loss_box_reg: 0.3709  loss_mask: 0.2444  loss_rpn_cls: 0.06881  loss_rpn_loc: 0.1497  time: 0.2237  data_time: 0.0072  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:46:31 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 96019  total_loss: 1.113  loss_cls: 0.2763  loss_box_reg: 0.3722  loss_mask: 0.2585  loss_rpn_cls: 0.05373  loss_rpn_loc: 0.1848  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:46:36 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 96039  total_loss: 1.141  loss_cls: 0.2791  loss_box_reg: 0.3704  loss_mask: 0.2551  loss_rpn_cls: 0.0629  loss_rpn_loc: 0.1535  time: 0.2237  data_time: 0.0079  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:46:40 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 96059  total_loss: 1.117  loss_cls: 0.26  loss_box_reg: 0.345  loss_mask: 0.2532  loss_rpn_cls: 0.06022  loss_rpn_loc: 0.1487  time: 0.2237  data_time: 0.0082  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:46:45 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 96079  total_loss: 1.021  loss_cls: 0.2438  loss_box_reg: 0.3217  loss_mask: 0.2438  loss_rpn_cls: 0.05321  loss_rpn_loc: 0.1495  time: 0.2237  data_time: 0.0090  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:46:49 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 96099  total_loss: 1.064  loss_cls: 0.2545  loss_box_reg: 0.3127  loss_mask: 0.244  loss_rpn_cls: 0.07288  loss_rpn_loc: 0.1486  time: 0.2237  data_time: 0.0075  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:46:54 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 96119  total_loss: 1.136  loss_cls: 0.2612  loss_box_reg: 0.3755  loss_mask: 0.2596  loss_rpn_cls: 0.07759  loss_rpn_loc: 0.1653  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:46:58 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 96139  total_loss: 1.075  loss_cls: 0.2572  loss_box_reg: 0.3524  loss_mask: 0.2394  loss_rpn_cls: 0.0586  loss_rpn_loc: 0.1534  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:47:03 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 96159  total_loss: 1.202  loss_cls: 0.2738  loss_box_reg: 0.3746  loss_mask: 0.2532  loss_rpn_cls: 0.06765  loss_rpn_loc: 0.1611  time: 0.2237  data_time: 0.0068  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:47:07 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 96179  total_loss: 1.086  loss_cls: 0.2595  loss_box_reg: 0.3657  loss_mask: 0.2503  loss_rpn_cls: 0.07921  loss_rpn_loc: 0.1659  time: 0.2237  data_time: 0.0167  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:47:12 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 96199  total_loss: 1.154  loss_cls: 0.258  loss_box_reg: 0.3818  loss_mask: 0.2688  loss_rpn_cls: 0.07063  loss_rpn_loc: 0.1535  time: 0.2237  data_time: 0.0066  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:47:16 d2.utils.events]: \u001b[0m eta: 0:00:26  iter: 96219  total_loss: 1.144  loss_cls: 0.2715  loss_box_reg: 0.3748  loss_mask: 0.2493  loss_rpn_cls: 0.06522  loss_rpn_loc: 0.1761  time: 0.2237  data_time: 0.0216  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:47:21 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 96239  total_loss: 1.199  loss_cls: 0.3009  loss_box_reg: 0.3832  loss_mask: 0.2568  loss_rpn_cls: 0.05422  loss_rpn_loc: 0.1414  time: 0.2237  data_time: 0.0059  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:47:25 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 96259  total_loss: 1.173  loss_cls: 0.2688  loss_box_reg: 0.3799  loss_mask: 0.262  loss_rpn_cls: 0.07439  loss_rpn_loc: 0.1793  time: 0.2237  data_time: 0.0076  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:47:30 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 96279  total_loss: 1.106  loss_cls: 0.2803  loss_box_reg: 0.3618  loss_mask: 0.2431  loss_rpn_cls: 0.05942  loss_rpn_loc: 0.145  time: 0.2237  data_time: 0.0142  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:47:34 d2.utils.events]: \u001b[0m eta: 0:00:08  iter: 96299  total_loss: 1.03  loss_cls: 0.2372  loss_box_reg: 0.3467  loss_mask: 0.2421  loss_rpn_cls: 0.05286  loss_rpn_loc: 0.155  time: 0.2237  data_time: 0.0069  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:47:39 d2.utils.events]: \u001b[0m eta: 0:00:04  iter: 96319  total_loss: 1.162  loss_cls: 0.261  loss_box_reg: 0.3459  loss_mask: 0.2586  loss_rpn_cls: 0.06466  loss_rpn_loc: 0.1588  time: 0.2237  data_time: 0.0071  lr: 0.00125  max_mem: 16883M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 03:47:43 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 96339  total_loss: 1.096  loss_cls: 0.2714  loss_box_reg: 0.3186  loss_mask: 0.2467  loss_rpn_cls: 0.07908  loss_rpn_loc: 0.1489  time: 0.2237  data_time: 0.0067  lr: 0.00125  max_mem: 16883M\n",
      "\u001b[32m[12/30 03:47:44 d2.engine.hooks]: \u001b[0mOverall training speed: 89114 iterations in 5:32:16 (0.2237 s / it)\n",
      "\u001b[32m[12/30 03:47:44 d2.engine.hooks]: \u001b[0mTotal training time: 6:16:12 (0:43:55 on hooks)\n",
      "\u001b[32m[12/30 03:47:46 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.61 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 03:47:46 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 03:47:46 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 03:47:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 03:47:47 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 03:47:48 d2.data.common]: \u001b[0mSerialized dataset takes 84.20 MiB\n",
      "\u001b[32m[12/30 03:47:50 d2.data.datasets.coco]: \u001b[0mLoading livecell/livecell_annotations_val.json takes 2.59 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/30 03:47:50 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/30 03:47:51 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/30 03:47:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/30 03:47:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0007 s/iter. Inference: 0.0624 s/iter. Eval: 0.1481 s/iter. Total: 0.2112 s/iter. ETA=0:01:58\n",
      "\u001b[32m[12/30 03:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 39/570. Dataloading: 0.0009 s/iter. Inference: 0.0576 s/iter. Eval: 0.1268 s/iter. Total: 0.1854 s/iter. ETA=0:01:38\n",
      "\u001b[32m[12/30 03:48:04 d2.evaluation.evaluator]: \u001b[0mInference done 67/570. Dataloading: 0.0009 s/iter. Inference: 0.0565 s/iter. Eval: 0.1278 s/iter. Total: 0.1853 s/iter. ETA=0:01:33\n",
      "\u001b[32m[12/30 03:48:10 d2.evaluation.evaluator]: \u001b[0mInference done 93/570. Dataloading: 0.0009 s/iter. Inference: 0.0568 s/iter. Eval: 0.1322 s/iter. Total: 0.1898 s/iter. ETA=0:01:30\n",
      "\u001b[32m[12/30 03:48:15 d2.evaluation.evaluator]: \u001b[0mInference done 120/570. Dataloading: 0.0009 s/iter. Inference: 0.0561 s/iter. Eval: 0.1322 s/iter. Total: 0.1893 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/30 03:48:20 d2.evaluation.evaluator]: \u001b[0mInference done 145/570. Dataloading: 0.0009 s/iter. Inference: 0.0556 s/iter. Eval: 0.1351 s/iter. Total: 0.1916 s/iter. ETA=0:01:21\n",
      "\u001b[32m[12/30 03:48:25 d2.evaluation.evaluator]: \u001b[0mInference done 163/570. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.1450 s/iter. Total: 0.2018 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 03:48:30 d2.evaluation.evaluator]: \u001b[0mInference done 176/570. Dataloading: 0.0009 s/iter. Inference: 0.0564 s/iter. Eval: 0.1606 s/iter. Total: 0.2180 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/30 03:48:35 d2.evaluation.evaluator]: \u001b[0mInference done 195/570. Dataloading: 0.0009 s/iter. Inference: 0.0569 s/iter. Eval: 0.1659 s/iter. Total: 0.2238 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 03:48:41 d2.evaluation.evaluator]: \u001b[0mInference done 210/570. Dataloading: 0.0009 s/iter. Inference: 0.0572 s/iter. Eval: 0.1739 s/iter. Total: 0.2320 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 03:48:46 d2.evaluation.evaluator]: \u001b[0mInference done 226/570. Dataloading: 0.0009 s/iter. Inference: 0.0573 s/iter. Eval: 0.1805 s/iter. Total: 0.2388 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 03:48:51 d2.evaluation.evaluator]: \u001b[0mInference done 237/570. Dataloading: 0.0009 s/iter. Inference: 0.0574 s/iter. Eval: 0.1918 s/iter. Total: 0.2501 s/iter. ETA=0:01:23\n",
      "\u001b[32m[12/30 03:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 250/570. Dataloading: 0.0009 s/iter. Inference: 0.0574 s/iter. Eval: 0.2002 s/iter. Total: 0.2585 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/30 03:49:02 d2.evaluation.evaluator]: \u001b[0mInference done 266/570. Dataloading: 0.0009 s/iter. Inference: 0.0574 s/iter. Eval: 0.2046 s/iter. Total: 0.2629 s/iter. ETA=0:01:19\n",
      "\u001b[32m[12/30 03:49:07 d2.evaluation.evaluator]: \u001b[0mInference done 285/570. Dataloading: 0.0009 s/iter. Inference: 0.0572 s/iter. Eval: 0.2050 s/iter. Total: 0.2631 s/iter. ETA=0:01:14\n",
      "\u001b[32m[12/30 03:49:12 d2.evaluation.evaluator]: \u001b[0mInference done 298/570. Dataloading: 0.0009 s/iter. Inference: 0.0572 s/iter. Eval: 0.2104 s/iter. Total: 0.2685 s/iter. ETA=0:01:13\n",
      "\u001b[32m[12/30 03:49:17 d2.evaluation.evaluator]: \u001b[0mInference done 347/570. Dataloading: 0.0009 s/iter. Inference: 0.0558 s/iter. Eval: 0.1882 s/iter. Total: 0.2449 s/iter. ETA=0:00:54\n",
      "\u001b[32m[12/30 03:49:22 d2.evaluation.evaluator]: \u001b[0mInference done 376/570. Dataloading: 0.0009 s/iter. Inference: 0.0555 s/iter. Eval: 0.1831 s/iter. Total: 0.2395 s/iter. ETA=0:00:46\n",
      "\u001b[32m[12/30 03:49:27 d2.evaluation.evaluator]: \u001b[0mInference done 398/570. Dataloading: 0.0009 s/iter. Inference: 0.0556 s/iter. Eval: 0.1824 s/iter. Total: 0.2390 s/iter. ETA=0:00:41\n",
      "\u001b[32m[12/30 03:49:32 d2.evaluation.evaluator]: \u001b[0mInference done 416/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1842 s/iter. Total: 0.2409 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/30 03:49:37 d2.evaluation.evaluator]: \u001b[0mInference done 436/570. Dataloading: 0.0009 s/iter. Inference: 0.0559 s/iter. Eval: 0.1848 s/iter. Total: 0.2417 s/iter. ETA=0:00:32\n",
      "\u001b[32m[12/30 03:49:42 d2.evaluation.evaluator]: \u001b[0mInference done 467/570. Dataloading: 0.0009 s/iter. Inference: 0.0557 s/iter. Eval: 0.1801 s/iter. Total: 0.2367 s/iter. ETA=0:00:24\n",
      "\u001b[32m[12/30 03:49:47 d2.evaluation.evaluator]: \u001b[0mInference done 496/570. Dataloading: 0.0009 s/iter. Inference: 0.0553 s/iter. Eval: 0.1768 s/iter. Total: 0.2330 s/iter. ETA=0:00:17\n",
      "\u001b[32m[12/30 03:49:52 d2.evaluation.evaluator]: \u001b[0mInference done 517/570. Dataloading: 0.0009 s/iter. Inference: 0.0553 s/iter. Eval: 0.1771 s/iter. Total: 0.2334 s/iter. ETA=0:00:12\n",
      "\u001b[32m[12/30 03:49:58 d2.evaluation.evaluator]: \u001b[0mInference done 540/570. Dataloading: 0.0009 s/iter. Inference: 0.0551 s/iter. Eval: 0.1769 s/iter. Total: 0.2330 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/30 03:50:03 d2.evaluation.evaluator]: \u001b[0mInference done 559/570. Dataloading: 0.0009 s/iter. Inference: 0.0553 s/iter. Eval: 0.1786 s/iter. Total: 0.2349 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/30 03:50:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:12.930389 (0.235275 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 03:50:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:31 (0.055349 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 03:50:06 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/30 03:50:06 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2889137063160539\n"
     ]
    }
   ],
   "source": [
    "trainModelLiveCell50()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on dataset on challenge data\n",
    "\n",
    "Now that we pretrained the model on livecell we can train the model on the dataset provided by the challenge. We defined the model again for the two different sized backends: ResNet50 and ResNet101. As the pretraining with LiveCell worked best with the ResNet50 we went with it here too.\n",
    "\n",
    "In addition we defined a parameter `classNum` which when defined only uses one celltype, the one which is associated with the index number, for training. This functionality we used to train three different models to build an **ensemble classifier**. As the Detectron2 model only showed pretty bad results when training on single classes, we did not use the ensemble classifier approach in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "oJ3E_fDIn1AX"
   },
   "outputs": [],
   "source": [
    "def trainModel(classNum=None, withWeights=False):\n",
    "  torch.cuda.empty_cache()\n",
    "  cfg = get_cfg()\n",
    "  cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "\n",
    "  cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "  cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "  if classNum is None:\n",
    "    cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "    cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "    cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH  # Once per epoch\n",
    "  else:\n",
    "    cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get(f'sartorius_train_{classNum}')) // cfg.SOLVER.IMS_PER_BATCH  # Once per epoch\n",
    "    cfg.DATASETS.TRAIN = (f\"sartorius_train_{classNum}\",)\n",
    "    cfg.DATASETS.TEST = (f\"sartorius_val_{classNum}\",)\n",
    "\n",
    "  cfg.DATALOADER.NUM_WORKERS = 2\n",
    "  if not withWeights:\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "  else:\n",
    "    cfg.MODEL.WEIGHTS = '/livecell/model_final.pth'\n",
    "  cfg.SOLVER.BASE_LR = 0.01 * 2 / 16\n",
    "  cfg.SOLVER.MAX_ITER = 10000\n",
    "  cfg.SOLVER.CHECKPOINT_PERIOD = 300\n",
    "  cfg.SOLVER.STEPS = []\n",
    "  cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "  if (classNum is None):\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "  else:\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "    cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS=False\n",
    "  cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "  cfg.OUTPUT_DIR = './output'\n",
    "  cfg.OUTPUT_DIR = os.path.join(cfg.OUTPUT_DIR, f'/{classNum}')\n",
    "  print(cfg.OUTPUT_DIR)\n",
    "  os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "  trainer = Trainer(cfg) \n",
    "  trainer.resume_or_load(resume=False)\n",
    "  trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel50():\n",
    "  torch.cuda.empty_cache()\n",
    "  cfg = get_cfg()\n",
    "  cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "\n",
    "  cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "  cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "  cfg.DATASETS.TRAIN = (\"sartorius_train\",)\n",
    "  cfg.DATASETS.TEST = (\"sartorius_val\",)\n",
    "  cfg.TEST.EVAL_PERIOD = len(DatasetCatalog.get('sartorius_train')) // cfg.SOLVER.IMS_PER_BATCH  # Once per epoch\n",
    "\n",
    "  cfg.DATALOADER.NUM_WORKERS = 2\n",
    "  # Ise the pretrained weights from LiveCell\n",
    "  cfg.MODEL.WEIGHTS = './output/livecell50/model_final.pth'\n",
    "  cfg.SOLVER.BASE_LR = 0.01 * 2 / 16\n",
    "  cfg.SOLVER.MAX_ITER = 50000\n",
    "  cfg.SOLVER.CHECKPOINT_PERIOD = 300\n",
    "  cfg.SOLVER.STEPS = []\n",
    "  cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "  cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "  cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "  cfg.OUTPUT_DIR = './output50'\n",
    "  print(cfg.OUTPUT_DIR)\n",
    "  os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "  trainer = Trainer(cfg) \n",
    "  trainer.resume_or_load(resume=True)\n",
    "  trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output50\n",
      "\u001b[32m[12/30 11:08:48 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 11:08:48 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 545 images left.\n",
      "\u001b[32m[12/30 11:08:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[12/30 11:08:48 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/30 11:08:48 d2.data.common]: \u001b[0mSerializing 545 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 11:08:48 d2.data.common]: \u001b[0mSerialized dataset takes 7.77 MiB\n",
      "\u001b[32m[12/30 11:08:48 d2.engine.hooks]: \u001b[0mLoading scheduler from state_dict ...\n",
      "\u001b[32m[12/30 11:08:48 d2.engine.train_loop]: \u001b[0mStarting training from iteration 8100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272168290/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 11:08:59 d2.utils.events]: \u001b[0m eta: 2:39:19  iter: 8119  total_loss: 1.005  loss_cls: 0.2023  loss_box_reg: 0.2744  loss_mask: 0.2495  loss_rpn_cls: 0.05173  loss_rpn_loc: 0.1976  time: 0.5341  data_time: 0.3167  lr: 0.00125  max_mem: 4229M\n",
      "\u001b[32m[12/30 11:09:13 d2.utils.events]: \u001b[0m eta: 3:42:30  iter: 8139  total_loss: 1.109  loss_cls: 0.1953  loss_box_reg: 0.3039  loss_mask: 0.2641  loss_rpn_cls: 0.07148  loss_rpn_loc: 0.1996  time: 0.6105  data_time: 0.4632  lr: 0.00125  max_mem: 4273M\n",
      "\u001b[32m[12/30 11:09:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 11:09:26 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 11:09:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 11:09:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 11:09:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0445 s/iter. Eval: 0.0144 s/iter. Total: 0.0597 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/30 11:09:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.151969 (0.056285 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:09:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043567 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:09:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 11:09:29 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06578692322865837\n",
      "\u001b[32m[12/30 11:09:29 d2.utils.events]: \u001b[0m eta: 3:10:43  iter: 8159  total_loss: 0.9768  loss_cls: 0.1834  loss_box_reg: 0.1925  loss_mask: 0.2929  loss_rpn_cls: 0.07159  loss_rpn_loc: 0.1999  time: 0.6210  data_time: 0.4324  lr: 0.00125  max_mem: 4273M\n",
      "\u001b[32m[12/30 11:09:39 d2.utils.events]: \u001b[0m eta: 3:06:57  iter: 8179  total_loss: 1.031  loss_cls: 0.1831  loss_box_reg: 0.1808  loss_mask: 0.2863  loss_rpn_cls: 0.06938  loss_rpn_loc: 0.2006  time: 0.5852  data_time: 0.2685  lr: 0.00125  max_mem: 5476M\n",
      "\u001b[32m[12/30 11:09:54 d2.utils.events]: \u001b[0m eta: 3:03:24  iter: 8199  total_loss: 0.9823  loss_cls: 0.1822  loss_box_reg: 0.1475  loss_mask: 0.2676  loss_rpn_cls: 0.07494  loss_rpn_loc: 0.2122  time: 0.6158  data_time: 0.5215  lr: 0.00125  max_mem: 5476M\n",
      "\u001b[32m[12/30 11:10:09 d2.utils.events]: \u001b[0m eta: 3:03:19  iter: 8219  total_loss: 1.022  loss_cls: 0.1938  loss_box_reg: 0.2483  loss_mask: 0.265  loss_rpn_cls: 0.06938  loss_rpn_loc: 0.2098  time: 0.6384  data_time: 0.5309  lr: 0.00125  max_mem: 5476M\n",
      "\u001b[32m[12/30 11:10:20 d2.utils.events]: \u001b[0m eta: 2:54:58  iter: 8239  total_loss: 0.6598  loss_cls: 0.1199  loss_box_reg: 0.1406  loss_mask: 0.1889  loss_rpn_cls: 0.03888  loss_rpn_loc: 0.1773  time: 0.6317  data_time: 0.3839  lr: 0.00125  max_mem: 5476M\n",
      "\u001b[32m[12/30 11:10:35 d2.utils.events]: \u001b[0m eta: 2:51:00  iter: 8259  total_loss: 0.9999  loss_cls: 0.1608  loss_box_reg: 0.1921  loss_mask: 0.2662  loss_rpn_cls: 0.07266  loss_rpn_loc: 0.209  time: 0.6420  data_time: 0.5008  lr: 0.00125  max_mem: 5476M\n",
      "\u001b[32m[12/30 11:10:48 d2.utils.events]: \u001b[0m eta: 2:54:48  iter: 8279  total_loss: 0.9825  loss_cls: 0.18  loss_box_reg: 0.247  loss_mask: 0.2472  loss_rpn_cls: 0.06868  loss_rpn_loc: 0.2052  time: 0.6427  data_time: 0.4350  lr: 0.00125  max_mem: 5476M\n",
      "\u001b[32m[12/30 11:11:01 d2.utils.events]: \u001b[0m eta: 3:00:07  iter: 8299  total_loss: 1.108  loss_cls: 0.205  loss_box_reg: 0.2598  loss_mask: 0.2829  loss_rpn_cls: 0.07753  loss_rpn_loc: 0.2005  time: 0.6437  data_time: 0.4390  lr: 0.00125  max_mem: 5476M\n",
      "\u001b[32m[12/30 11:11:12 d2.utils.events]: \u001b[0m eta: 2:50:45  iter: 8319  total_loss: 1.063  loss_cls: 0.1851  loss_box_reg: 0.2242  loss_mask: 0.2734  loss_rpn_cls: 0.06517  loss_rpn_loc: 0.2021  time: 0.6366  data_time: 0.3563  lr: 0.00125  max_mem: 5476M\n",
      "\u001b[32m[12/30 11:11:26 d2.utils.events]: \u001b[0m eta: 2:59:56  iter: 8339  total_loss: 1.124  loss_cls: 0.2177  loss_box_reg: 0.2607  loss_mask: 0.286  loss_rpn_cls: 0.08986  loss_rpn_loc: 0.2145  time: 0.6424  data_time: 0.4793  lr: 0.00125  max_mem: 5476M\n",
      "\u001b[32m[12/30 11:11:36 d2.utils.events]: \u001b[0m eta: 3:02:42  iter: 8359  total_loss: 1.047  loss_cls: 0.2223  loss_box_reg: 0.2739  loss_mask: 0.2788  loss_rpn_cls: 0.07183  loss_rpn_loc: 0.2  time: 0.6325  data_time: 0.3007  lr: 0.00125  max_mem: 5476M\n",
      "\u001b[32m[12/30 11:11:54 d2.utils.events]: \u001b[0m eta: 3:06:44  iter: 8379  total_loss: 1.107  loss_cls: 0.2054  loss_box_reg: 0.2764  loss_mask: 0.2705  loss_rpn_cls: 0.1033  loss_rpn_loc: 0.2279  time: 0.6502  data_time: 0.6492  lr: 0.00125  max_mem: 5476M\n",
      "\u001b[32m[12/30 11:12:07 d2.utils.events]: \u001b[0m eta: 3:06:39  iter: 8399  total_loss: 1.066  loss_cls: 0.1868  loss_box_reg: 0.2387  loss_mask: 0.2534  loss_rpn_cls: 0.08647  loss_rpn_loc: 0.2019  time: 0.6492  data_time: 0.4241  lr: 0.00125  max_mem: 5476M\n",
      "\u001b[32m[12/30 11:12:18 d2.utils.events]: \u001b[0m eta: 3:06:33  iter: 8419  total_loss: 1.107  loss_cls: 0.2212  loss_box_reg: 0.2505  loss_mask: 0.2953  loss_rpn_cls: 0.07356  loss_rpn_loc: 0.213  time: 0.6439  data_time: 0.3572  lr: 0.00125  max_mem: 5476M\n",
      "\u001b[32m[12/30 11:12:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 11:12:26 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 11:12:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 11:12:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 11:12:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0006 s/iter. Inference: 0.0439 s/iter. Eval: 0.0148 s/iter. Total: 0.0593 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/30 11:12:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.075304 (0.054916 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:12:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.042768 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:12:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 11:12:29 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06172472190377988\n",
      "\u001b[32m[12/30 11:12:35 d2.utils.events]: \u001b[0m eta: 3:06:28  iter: 8439  total_loss: 0.9932  loss_cls: 0.1795  loss_box_reg: 0.2076  loss_mask: 0.2854  loss_rpn_cls: 0.07386  loss_rpn_loc: 0.2056  time: 0.6443  data_time: 0.4335  lr: 0.00125  max_mem: 5476M\n",
      "\u001b[32m[12/30 11:12:47 d2.utils.events]: \u001b[0m eta: 3:10:40  iter: 8459  total_loss: 1.003  loss_cls: 0.2045  loss_box_reg: 0.2743  loss_mask: 0.2771  loss_rpn_cls: 0.07361  loss_rpn_loc: 0.1964  time: 0.6430  data_time: 0.4091  lr: 0.00125  max_mem: 5476M\n",
      "\u001b[32m[12/30 11:12:59 d2.utils.events]: \u001b[0m eta: 3:08:28  iter: 8479  total_loss: 0.9334  loss_cls: 0.1766  loss_box_reg: 0.2349  loss_mask: 0.2497  loss_rpn_cls: 0.06275  loss_rpn_loc: 0.2009  time: 0.6389  data_time: 0.3619  lr: 0.00125  max_mem: 5476M\n",
      "\u001b[32m[12/30 11:13:11 d2.utils.events]: \u001b[0m eta: 3:09:42  iter: 8499  total_loss: 0.9875  loss_cls: 0.1639  loss_box_reg: 0.2248  loss_mask: 0.2746  loss_rpn_cls: 0.07736  loss_rpn_loc: 0.2117  time: 0.6386  data_time: 0.4151  lr: 0.00125  max_mem: 5476M\n",
      "\u001b[32m[12/30 11:13:25 d2.utils.events]: \u001b[0m eta: 3:09:36  iter: 8519  total_loss: 1.043  loss_cls: 0.1821  loss_box_reg: 0.2394  loss_mask: 0.2835  loss_rpn_cls: 0.0675  loss_rpn_loc: 0.21  time: 0.6396  data_time: 0.4359  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:13:41 d2.utils.events]: \u001b[0m eta: 3:10:18  iter: 8539  total_loss: 1.025  loss_cls: 0.1888  loss_box_reg: 0.2473  loss_mask: 0.2938  loss_rpn_cls: 0.07534  loss_rpn_loc: 0.2039  time: 0.6485  data_time: 0.6172  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:13:50 d2.utils.events]: \u001b[0m eta: 3:04:15  iter: 8559  total_loss: 0.2219  loss_cls: 0.000212  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04099  loss_rpn_loc: 0.1811  time: 0.6381  data_time: 0.2171  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:14:06 d2.utils.events]: \u001b[0m eta: 3:05:50  iter: 8579  total_loss: 1.04  loss_cls: 0.2004  loss_box_reg: 0.2375  loss_mask: 0.2745  loss_rpn_cls: 0.07721  loss_rpn_loc: 0.2062  time: 0.6462  data_time: 0.6094  lr: 0.00125  max_mem: 6363M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 11:14:21 d2.utils.events]: \u001b[0m eta: 3:05:45  iter: 8599  total_loss: 1.09  loss_cls: 0.2111  loss_box_reg: 0.2555  loss_mask: 0.2601  loss_rpn_cls: 0.06863  loss_rpn_loc: 0.2071  time: 0.6491  data_time: 0.5081  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:14:34 d2.utils.events]: \u001b[0m eta: 3:04:24  iter: 8619  total_loss: 0.9754  loss_cls: 0.1716  loss_box_reg: 0.2256  loss_mask: 0.2844  loss_rpn_cls: 0.05925  loss_rpn_loc: 0.194  time: 0.6505  data_time: 0.4672  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:14:46 d2.utils.events]: \u001b[0m eta: 3:03:54  iter: 8639  total_loss: 1.105  loss_cls: 0.1773  loss_box_reg: 0.2622  loss_mask: 0.2615  loss_rpn_cls: 0.07716  loss_rpn_loc: 0.2113  time: 0.6485  data_time: 0.3866  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:14:58 d2.utils.events]: \u001b[0m eta: 3:04:13  iter: 8659  total_loss: 1.105  loss_cls: 0.2295  loss_box_reg: 0.2991  loss_mask: 0.254  loss_rpn_cls: 0.09088  loss_rpn_loc: 0.2075  time: 0.6456  data_time: 0.3455  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:15:13 d2.utils.events]: \u001b[0m eta: 3:06:35  iter: 8679  total_loss: 1.048  loss_cls: 0.1994  loss_box_reg: 0.2459  loss_mask: 0.2886  loss_rpn_cls: 0.06572  loss_rpn_loc: 0.2128  time: 0.6505  data_time: 0.5602  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:15:26 d2.utils.events]: \u001b[0m eta: 3:08:26  iter: 8699  total_loss: 1.097  loss_cls: 0.2178  loss_box_reg: 0.285  loss_mask: 0.2738  loss_rpn_cls: 0.07644  loss_rpn_loc: 0.2028  time: 0.6492  data_time: 0.3977  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:15:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 11:15:27 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 11:15:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 11:15:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 11:15:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0196 s/iter. Total: 0.0651 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 11:15:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.301433 (0.058954 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:15:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043338 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:15:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 11:15:31 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07073278966299586\n",
      "\u001b[32m[12/30 11:15:42 d2.utils.events]: \u001b[0m eta: 3:10:58  iter: 8719  total_loss: 1.031  loss_cls: 0.1675  loss_box_reg: 0.2308  loss_mask: 0.2964  loss_rpn_cls: 0.08683  loss_rpn_loc: 0.2386  time: 0.6473  data_time: 0.3711  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:15:56 d2.utils.events]: \u001b[0m eta: 3:09:23  iter: 8739  total_loss: 0.9657  loss_cls: 0.1692  loss_box_reg: 0.1988  loss_mask: 0.2717  loss_rpn_cls: 0.08067  loss_rpn_loc: 0.1935  time: 0.6499  data_time: 0.5102  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:16:10 d2.utils.events]: \u001b[0m eta: 3:07:11  iter: 8759  total_loss: 0.9885  loss_cls: 0.1895  loss_box_reg: 0.2093  loss_mask: 0.2529  loss_rpn_cls: 0.05632  loss_rpn_loc: 0.2052  time: 0.6504  data_time: 0.4509  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:16:24 d2.utils.events]: \u001b[0m eta: 3:08:25  iter: 8779  total_loss: 1.084  loss_cls: 0.1978  loss_box_reg: 0.2291  loss_mask: 0.3003  loss_rpn_cls: 0.1041  loss_rpn_loc: 0.2363  time: 0.6532  data_time: 0.5201  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:16:32 d2.utils.events]: \u001b[0m eta: 3:05:51  iter: 8799  total_loss: 0.8667  loss_cls: 0.1686  loss_box_reg: 0.2485  loss_mask: 0.2052  loss_rpn_cls: 0.06091  loss_rpn_loc: 0.1867  time: 0.6458  data_time: 0.1931  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:16:47 d2.utils.events]: \u001b[0m eta: 3:05:57  iter: 8819  total_loss: 1.041  loss_cls: 0.197  loss_box_reg: 0.2678  loss_mask: 0.2693  loss_rpn_cls: 0.05502  loss_rpn_loc: 0.2129  time: 0.6475  data_time: 0.4825  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:17:01 d2.utils.events]: \u001b[0m eta: 3:06:49  iter: 8839  total_loss: 1.056  loss_cls: 0.1947  loss_box_reg: 0.2265  loss_mask: 0.2944  loss_rpn_cls: 0.07565  loss_rpn_loc: 0.2205  time: 0.6498  data_time: 0.5187  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:17:14 d2.utils.events]: \u001b[0m eta: 3:05:35  iter: 8859  total_loss: 0.8918  loss_cls: 0.1687  loss_box_reg: 0.1598  loss_mask: 0.2421  loss_rpn_cls: 0.05323  loss_rpn_loc: 0.1892  time: 0.6494  data_time: 0.4298  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:17:27 d2.utils.events]: \u001b[0m eta: 3:05:41  iter: 8879  total_loss: 1.023  loss_cls: 0.2035  loss_box_reg: 0.2755  loss_mask: 0.2757  loss_rpn_cls: 0.05339  loss_rpn_loc: 0.1921  time: 0.6497  data_time: 0.4513  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:17:40 d2.utils.events]: \u001b[0m eta: 3:03:28  iter: 8899  total_loss: 1.002  loss_cls: 0.1805  loss_box_reg: 0.2339  loss_mask: 0.2671  loss_rpn_cls: 0.04604  loss_rpn_loc: 0.1877  time: 0.6498  data_time: 0.4329  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:17:51 d2.utils.events]: \u001b[0m eta: 3:04:23  iter: 8919  total_loss: 0.9735  loss_cls: 0.1779  loss_box_reg: 0.2049  loss_mask: 0.2486  loss_rpn_cls: 0.06244  loss_rpn_loc: 0.1966  time: 0.6475  data_time: 0.3479  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:18:02 d2.utils.events]: \u001b[0m eta: 3:02:58  iter: 8939  total_loss: 1.013  loss_cls: 0.1668  loss_box_reg: 0.2131  loss_mask: 0.2502  loss_rpn_cls: 0.06831  loss_rpn_loc: 0.2094  time: 0.6452  data_time: 0.3508  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:18:17 d2.utils.events]: \u001b[0m eta: 3:02:22  iter: 8959  total_loss: 1.031  loss_cls: 0.1852  loss_box_reg: 0.2166  loss_mask: 0.2909  loss_rpn_cls: 0.07059  loss_rpn_loc: 0.2176  time: 0.6477  data_time: 0.5300  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:18:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 11:18:28 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 11:18:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 11:18:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 11:18:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0459 s/iter. Eval: 0.0188 s/iter. Total: 0.0655 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 11:18:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.243705 (0.057923 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:18:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043604 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:18:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 11:18:32 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06808039013174863\n",
      "\u001b[32m[12/30 11:18:34 d2.utils.events]: \u001b[0m eta: 3:01:37  iter: 8979  total_loss: 0.8659  loss_cls: 0.1548  loss_box_reg: 0.1123  loss_mask: 0.2309  loss_rpn_cls: 0.0736  loss_rpn_loc: 0.1802  time: 0.6475  data_time: 0.4256  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:18:46 d2.utils.events]: \u001b[0m eta: 3:00:41  iter: 8999  total_loss: 1.03  loss_cls: 0.1769  loss_box_reg: 0.2284  loss_mask: 0.2818  loss_rpn_cls: 0.06326  loss_rpn_loc: 0.1938  time: 0.6463  data_time: 0.3876  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:18:58 d2.utils.events]: \u001b[0m eta: 3:02:06  iter: 9019  total_loss: 1.13  loss_cls: 0.2161  loss_box_reg: 0.3089  loss_mask: 0.3056  loss_rpn_cls: 0.07426  loss_rpn_loc: 0.2008  time: 0.6453  data_time: 0.3874  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:19:07 d2.utils.events]: \u001b[0m eta: 3:01:21  iter: 9039  total_loss: 0.9271  loss_cls: 0.1643  loss_box_reg: 0.2192  loss_mask: 0.2439  loss_rpn_cls: 0.05134  loss_rpn_loc: 0.1808  time: 0.6410  data_time: 0.2438  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:19:23 d2.utils.events]: \u001b[0m eta: 3:01:55  iter: 9059  total_loss: 1.087  loss_cls: 0.2181  loss_box_reg: 0.2711  loss_mask: 0.269  loss_rpn_cls: 0.09343  loss_rpn_loc: 0.2421  time: 0.6447  data_time: 0.5846  lr: 0.00125  max_mem: 6363M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 11:19:34 d2.utils.events]: \u001b[0m eta: 3:01:10  iter: 9079  total_loss: 0.9738  loss_cls: 0.1753  loss_box_reg: 0.2352  loss_mask: 0.2509  loss_rpn_cls: 0.07401  loss_rpn_loc: 0.1825  time: 0.6418  data_time: 0.3096  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:19:49 d2.utils.events]: \u001b[0m eta: 3:01:53  iter: 9099  total_loss: 1.089  loss_cls: 0.2162  loss_box_reg: 0.2683  loss_mask: 0.3022  loss_rpn_cls: 0.08352  loss_rpn_loc: 0.1883  time: 0.6449  data_time: 0.5653  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:20:00 d2.utils.events]: \u001b[0m eta: 3:02:10  iter: 9119  total_loss: 1.113  loss_cls: 0.2211  loss_box_reg: 0.2626  loss_mask: 0.2842  loss_rpn_cls: 0.09516  loss_rpn_loc: 0.2061  time: 0.6431  data_time: 0.3366  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:20:13 d2.utils.events]: \u001b[0m eta: 3:01:16  iter: 9139  total_loss: 1.026  loss_cls: 0.1949  loss_box_reg: 0.2768  loss_mask: 0.3085  loss_rpn_cls: 0.08065  loss_rpn_loc: 0.2028  time: 0.6426  data_time: 0.4002  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:20:27 d2.utils.events]: \u001b[0m eta: 3:01:37  iter: 9159  total_loss: 1.103  loss_cls: 0.2089  loss_box_reg: 0.2563  loss_mask: 0.2877  loss_rpn_cls: 0.08226  loss_rpn_loc: 0.2174  time: 0.6437  data_time: 0.4902  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:20:42 d2.utils.events]: \u001b[0m eta: 3:04:20  iter: 9179  total_loss: 1.039  loss_cls: 0.1958  loss_box_reg: 0.2301  loss_mask: 0.2945  loss_rpn_cls: 0.08822  loss_rpn_loc: 0.2189  time: 0.6457  data_time: 0.5301  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:20:57 d2.utils.events]: \u001b[0m eta: 3:04:14  iter: 9199  total_loss: 0.9147  loss_cls: 0.1784  loss_box_reg: 0.2262  loss_mask: 0.2267  loss_rpn_cls: 0.06935  loss_rpn_loc: 0.2032  time: 0.6476  data_time: 0.5300  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:21:12 d2.utils.events]: \u001b[0m eta: 3:06:03  iter: 9219  total_loss: 1.184  loss_cls: 0.2634  loss_box_reg: 0.2637  loss_mask: 0.2683  loss_rpn_cls: 0.09144  loss_rpn_loc: 0.2274  time: 0.6495  data_time: 0.5305  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:21:28 d2.utils.events]: \u001b[0m eta: 3:09:15  iter: 9239  total_loss: 0.9946  loss_cls: 0.1619  loss_box_reg: 0.1977  loss_mask: 0.2828  loss_rpn_cls: 0.0884  loss_rpn_loc: 0.2274  time: 0.6519  data_time: 0.5735  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:21:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 11:21:34 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 11:21:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 11:21:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 11:21:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0188 s/iter. Total: 0.0643 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 11:21:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.158573 (0.056403 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:21:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043127 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:21:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 11:21:37 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.064174794422206\n",
      "\u001b[32m[12/30 11:21:44 d2.utils.events]: \u001b[0m eta: 3:09:10  iter: 9259  total_loss: 1.12  loss_cls: 0.2334  loss_box_reg: 0.2709  loss_mask: 0.266  loss_rpn_cls: 0.08762  loss_rpn_loc: 0.2008  time: 0.6515  data_time: 0.4074  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:21:53 d2.utils.events]: \u001b[0m eta: 3:08:30  iter: 9279  total_loss: 1.009  loss_cls: 0.1946  loss_box_reg: 0.2133  loss_mask: 0.2892  loss_rpn_cls: 0.06288  loss_rpn_loc: 0.2119  time: 0.6482  data_time: 0.2644  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:22:05 d2.utils.events]: \u001b[0m eta: 3:08:24  iter: 9299  total_loss: 1.046  loss_cls: 0.1881  loss_box_reg: 0.2659  loss_mask: 0.266  loss_rpn_cls: 0.05897  loss_rpn_loc: 0.2065  time: 0.6473  data_time: 0.3810  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:22:17 d2.utils.events]: \u001b[0m eta: 3:08:19  iter: 9319  total_loss: 0.9878  loss_cls: 0.2149  loss_box_reg: 0.2217  loss_mask: 0.2591  loss_rpn_cls: 0.06304  loss_rpn_loc: 0.2143  time: 0.6459  data_time: 0.3606  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:22:26 d2.utils.events]: \u001b[0m eta: 3:05:30  iter: 9339  total_loss: 0.9636  loss_cls: 0.1881  loss_box_reg: 0.2554  loss_mask: 0.2573  loss_rpn_cls: 0.06632  loss_rpn_loc: 0.1941  time: 0.6430  data_time: 0.2639  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:22:34 d2.utils.events]: \u001b[0m eta: 2:58:13  iter: 9359  total_loss: 0.2357  loss_cls: 0.0003351  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03435  loss_rpn_loc: 0.1788  time: 0.6390  data_time: 0.1992  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:22:46 d2.utils.events]: \u001b[0m eta: 2:56:27  iter: 9379  total_loss: 1.039  loss_cls: 0.2106  loss_box_reg: 0.2249  loss_mask: 0.2566  loss_rpn_cls: 0.0883  loss_rpn_loc: 0.2049  time: 0.6388  data_time: 0.4189  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:23:05 d2.utils.events]: \u001b[0m eta: 2:59:50  iter: 9399  total_loss: 1.034  loss_cls: 0.1809  loss_box_reg: 0.2106  loss_mask: 0.2895  loss_rpn_cls: 0.1099  loss_rpn_loc: 0.2214  time: 0.6436  data_time: 0.7163  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:23:21 d2.utils.events]: \u001b[0m eta: 2:59:45  iter: 9419  total_loss: 1.037  loss_cls: 0.2135  loss_box_reg: 0.2304  loss_mask: 0.3026  loss_rpn_cls: 0.08354  loss_rpn_loc: 0.1868  time: 0.6457  data_time: 0.5527  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:23:33 d2.utils.events]: \u001b[0m eta: 3:00:01  iter: 9439  total_loss: 0.9862  loss_cls: 0.1905  loss_box_reg: 0.2511  loss_mask: 0.2744  loss_rpn_cls: 0.06973  loss_rpn_loc: 0.1846  time: 0.6447  data_time: 0.3733  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:23:47 d2.utils.events]: \u001b[0m eta: 2:57:11  iter: 9459  total_loss: 1.037  loss_cls: 0.2049  loss_box_reg: 0.2527  loss_mask: 0.2933  loss_rpn_cls: 0.07902  loss_rpn_loc: 0.203  time: 0.6458  data_time: 0.4892  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:24:00 d2.utils.events]: \u001b[0m eta: 2:57:30  iter: 9479  total_loss: 1.107  loss_cls: 0.1899  loss_box_reg: 0.2466  loss_mask: 0.2988  loss_rpn_cls: 0.09438  loss_rpn_loc: 0.213  time: 0.6458  data_time: 0.4350  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:24:11 d2.utils.events]: \u001b[0m eta: 2:55:30  iter: 9499  total_loss: 0.9017  loss_cls: 0.1664  loss_box_reg: 0.1917  loss_mask: 0.2475  loss_rpn_cls: 0.05466  loss_rpn_loc: 0.2013  time: 0.6444  data_time: 0.3339  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:24:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 11:24:22 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 11:24:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 11:24:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 11:24:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0457 s/iter. Eval: 0.0248 s/iter. Total: 0.0713 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 11:24:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.260320 (0.058220 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:24:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043606 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:24:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 11:24:26 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06716202072935715\n",
      "\u001b[32m[12/30 11:24:26 d2.utils.events]: \u001b[0m eta: 2:54:32  iter: 9519  total_loss: 0.8101  loss_cls: 0.1471  loss_box_reg: 0.1842  loss_mask: 0.2218  loss_rpn_cls: 0.04982  loss_rpn_loc: 0.1815  time: 0.6434  data_time: 0.3758  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:24:35 d2.utils.events]: \u001b[0m eta: 2:53:19  iter: 9539  total_loss: 1.057  loss_cls: 0.2044  loss_box_reg: 0.2717  loss_mask: 0.28  loss_rpn_cls: 0.0671  loss_rpn_loc: 0.1965  time: 0.6406  data_time: 0.2349  lr: 0.00125  max_mem: 6363M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 11:24:51 d2.utils.events]: \u001b[0m eta: 2:55:56  iter: 9559  total_loss: 1.049  loss_cls: 0.1894  loss_box_reg: 0.1892  loss_mask: 0.2721  loss_rpn_cls: 0.09371  loss_rpn_loc: 0.2195  time: 0.6428  data_time: 0.5808  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:25:08 d2.utils.events]: \u001b[0m eta: 2:56:39  iter: 9579  total_loss: 0.9599  loss_cls: 0.1667  loss_box_reg: 0.1708  loss_mask: 0.2831  loss_rpn_cls: 0.07314  loss_rpn_loc: 0.2041  time: 0.6456  data_time: 0.6147  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:25:22 d2.utils.events]: \u001b[0m eta: 2:57:10  iter: 9599  total_loss: 1.059  loss_cls: 0.1952  loss_box_reg: 0.2639  loss_mask: 0.2936  loss_rpn_cls: 0.08707  loss_rpn_loc: 0.2124  time: 0.6463  data_time: 0.4846  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:25:36 d2.utils.events]: \u001b[0m eta: 2:56:53  iter: 9619  total_loss: 1.054  loss_cls: 0.2289  loss_box_reg: 0.27  loss_mask: 0.2573  loss_rpn_cls: 0.0584  loss_rpn_loc: 0.1848  time: 0.6465  data_time: 0.4471  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:25:46 d2.utils.events]: \u001b[0m eta: 2:59:48  iter: 9639  total_loss: 1.039  loss_cls: 0.2148  loss_box_reg: 0.2725  loss_mask: 0.276  loss_rpn_cls: 0.05995  loss_rpn_loc: 0.2019  time: 0.6452  data_time: 0.3278  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:26:01 d2.utils.events]: \u001b[0m eta: 3:03:06  iter: 9659  total_loss: 1.037  loss_cls: 0.1799  loss_box_reg: 0.2297  loss_mask: 0.2802  loss_rpn_cls: 0.08144  loss_rpn_loc: 0.2365  time: 0.6462  data_time: 0.5022  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:26:11 d2.utils.events]: \u001b[0m eta: 2:58:59  iter: 9679  total_loss: 1.095  loss_cls: 0.209  loss_box_reg: 0.2508  loss_mask: 0.2617  loss_rpn_cls: 0.0622  loss_rpn_loc: 0.1956  time: 0.6446  data_time: 0.3089  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:26:23 d2.utils.events]: \u001b[0m eta: 2:57:35  iter: 9699  total_loss: 1.071  loss_cls: 0.204  loss_box_reg: 0.2767  loss_mask: 0.299  loss_rpn_cls: 0.08196  loss_rpn_loc: 0.2152  time: 0.6438  data_time: 0.3651  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:26:35 d2.utils.events]: \u001b[0m eta: 2:55:32  iter: 9719  total_loss: 0.9997  loss_cls: 0.19  loss_box_reg: 0.2434  loss_mask: 0.2568  loss_rpn_cls: 0.06065  loss_rpn_loc: 0.1915  time: 0.6433  data_time: 0.3927  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:26:48 d2.utils.events]: \u001b[0m eta: 2:54:27  iter: 9739  total_loss: 0.9985  loss_cls: 0.2037  loss_box_reg: 0.2445  loss_mask: 0.2937  loss_rpn_cls: 0.07162  loss_rpn_loc: 0.1903  time: 0.6431  data_time: 0.4169  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:26:59 d2.utils.events]: \u001b[0m eta: 2:55:22  iter: 9759  total_loss: 0.5568  loss_cls: 0.06942  loss_box_reg: 0.09492  loss_mask: 0.1091  loss_rpn_cls: 0.04832  loss_rpn_loc: 0.1974  time: 0.6422  data_time: 0.3655  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:27:13 d2.utils.events]: \u001b[0m eta: 2:53:51  iter: 9779  total_loss: 0.9754  loss_cls: 0.176  loss_box_reg: 0.1973  loss_mask: 0.2571  loss_rpn_cls: 0.06426  loss_rpn_loc: 0.2106  time: 0.6427  data_time: 0.4603  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:27:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 11:27:16 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 11:27:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 11:27:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 11:27:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0457 s/iter. Eval: 0.0216 s/iter. Total: 0.0681 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 11:27:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.300707 (0.058941 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:27:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043697 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:27:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 11:27:20 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0691227572048334\n",
      "\u001b[32m[12/30 11:27:26 d2.utils.events]: \u001b[0m eta: 2:55:11  iter: 9799  total_loss: 0.9932  loss_cls: 0.1771  loss_box_reg: 0.2649  loss_mask: 0.2716  loss_rpn_cls: 0.06388  loss_rpn_loc: 0.1947  time: 0.6405  data_time: 0.2517  lr: 0.00125  max_mem: 6363M\n",
      "\u001b[32m[12/30 11:27:37 d2.utils.events]: \u001b[0m eta: 2:53:41  iter: 9819  total_loss: 0.9855  loss_cls: 0.1793  loss_box_reg: 0.202  loss_mask: 0.2698  loss_rpn_cls: 0.07027  loss_rpn_loc: 0.2182  time: 0.6399  data_time: 0.3723  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:27:50 d2.utils.events]: \u001b[0m eta: 2:53:18  iter: 9839  total_loss: 0.9653  loss_cls: 0.2054  loss_box_reg: 0.2537  loss_mask: 0.2549  loss_rpn_cls: 0.06214  loss_rpn_loc: 0.1977  time: 0.6396  data_time: 0.4000  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:28:03 d2.utils.events]: \u001b[0m eta: 2:56:01  iter: 9859  total_loss: 0.9807  loss_cls: 0.1803  loss_box_reg: 0.221  loss_mask: 0.2769  loss_rpn_cls: 0.07549  loss_rpn_loc: 0.2108  time: 0.6401  data_time: 0.4571  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:28:18 d2.utils.events]: \u001b[0m eta: 2:55:39  iter: 9879  total_loss: 1.027  loss_cls: 0.1736  loss_box_reg: 0.164  loss_mask: 0.2799  loss_rpn_cls: 0.06855  loss_rpn_loc: 0.2145  time: 0.6410  data_time: 0.5008  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:28:30 d2.utils.events]: \u001b[0m eta: 2:55:52  iter: 9899  total_loss: 1.069  loss_cls: 0.1812  loss_box_reg: 0.2864  loss_mask: 0.2848  loss_rpn_cls: 0.07384  loss_rpn_loc: 0.22  time: 0.6404  data_time: 0.3751  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:28:42 d2.utils.events]: \u001b[0m eta: 2:55:28  iter: 9919  total_loss: 1.006  loss_cls: 0.1886  loss_box_reg: 0.258  loss_mask: 0.2682  loss_rpn_cls: 0.08347  loss_rpn_loc: 0.184  time: 0.6398  data_time: 0.3696  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:28:56 d2.utils.events]: \u001b[0m eta: 2:56:06  iter: 9939  total_loss: 0.9923  loss_cls: 0.1857  loss_box_reg: 0.2375  loss_mask: 0.2637  loss_rpn_cls: 0.0763  loss_rpn_loc: 0.2178  time: 0.6407  data_time: 0.4977  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:29:07 d2.utils.events]: \u001b[0m eta: 2:56:49  iter: 9959  total_loss: 0.996  loss_cls: 0.2237  loss_box_reg: 0.2501  loss_mask: 0.2629  loss_rpn_cls: 0.05613  loss_rpn_loc: 0.1853  time: 0.6397  data_time: 0.3395  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:29:18 d2.utils.events]: \u001b[0m eta: 2:56:43  iter: 9979  total_loss: 1.039  loss_cls: 0.1914  loss_box_reg: 0.2484  loss_mask: 0.2688  loss_rpn_cls: 0.07993  loss_rpn_loc: 0.2124  time: 0.6387  data_time: 0.3351  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:29:31 d2.utils.events]: \u001b[0m eta: 2:56:38  iter: 9999  total_loss: 1.059  loss_cls: 0.1665  loss_box_reg: 0.2389  loss_mask: 0.2561  loss_rpn_cls: 0.06048  loss_rpn_loc: 0.2115  time: 0.6386  data_time: 0.4213  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:29:42 d2.utils.events]: \u001b[0m eta: 2:54:15  iter: 10019  total_loss: 0.9433  loss_cls: 0.1635  loss_box_reg: 0.2253  loss_mask: 0.2554  loss_rpn_cls: 0.05866  loss_rpn_loc: 0.1919  time: 0.6381  data_time: 0.3811  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:29:58 d2.utils.events]: \u001b[0m eta: 2:55:15  iter: 10039  total_loss: 1.054  loss_cls: 0.1853  loss_box_reg: 0.2267  loss_mask: 0.2793  loss_rpn_cls: 0.07919  loss_rpn_loc: 0.2075  time: 0.6394  data_time: 0.5505  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:30:09 d2.utils.events]: \u001b[0m eta: 2:54:11  iter: 10059  total_loss: 0.9909  loss_cls: 0.2148  loss_box_reg: 0.258  loss_mask: 0.2638  loss_rpn_cls: 0.061  loss_rpn_loc: 0.1889  time: 0.6385  data_time: 0.3351  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:30:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 11:30:12 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 11:30:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 11:30:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 11:30:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0454 s/iter. Eval: 0.0162 s/iter. Total: 0.0624 s/iter. ETA=0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 11:30:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.185527 (0.056884 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:30:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043409 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:30:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 11:30:15 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06407121036946614\n",
      "\u001b[32m[12/30 11:30:23 d2.utils.events]: \u001b[0m eta: 2:54:33  iter: 10079  total_loss: 1.054  loss_cls: 0.199  loss_box_reg: 0.2344  loss_mask: 0.2892  loss_rpn_cls: 0.06577  loss_rpn_loc: 0.2185  time: 0.6374  data_time: 0.3170  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:30:39 d2.utils.events]: \u001b[0m eta: 2:54:28  iter: 10099  total_loss: 0.9856  loss_cls: 0.1572  loss_box_reg: 0.1734  loss_mask: 0.265  loss_rpn_cls: 0.09262  loss_rpn_loc: 0.2257  time: 0.6388  data_time: 0.5569  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:30:54 d2.utils.events]: \u001b[0m eta: 2:54:36  iter: 10119  total_loss: 1.031  loss_cls: 0.1897  loss_box_reg: 0.2301  loss_mask: 0.2896  loss_rpn_cls: 0.08631  loss_rpn_loc: 0.1999  time: 0.6399  data_time: 0.5285  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:31:06 d2.utils.events]: \u001b[0m eta: 2:53:50  iter: 10139  total_loss: 1.067  loss_cls: 0.1605  loss_box_reg: 0.2484  loss_mask: 0.2779  loss_rpn_cls: 0.107  loss_rpn_loc: 0.2204  time: 0.6395  data_time: 0.3893  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:31:22 d2.utils.events]: \u001b[0m eta: 2:54:25  iter: 10159  total_loss: 1.071  loss_cls: 0.2011  loss_box_reg: 0.2644  loss_mask: 0.2857  loss_rpn_cls: 0.07486  loss_rpn_loc: 0.2233  time: 0.6410  data_time: 0.5742  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:31:36 d2.utils.events]: \u001b[0m eta: 2:53:06  iter: 10179  total_loss: 1.067  loss_cls: 0.1797  loss_box_reg: 0.2078  loss_mask: 0.2687  loss_rpn_cls: 0.09434  loss_rpn_loc: 0.2101  time: 0.6416  data_time: 0.4895  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:31:46 d2.utils.events]: \u001b[0m eta: 2:52:41  iter: 10199  total_loss: 0.9684  loss_cls: 0.1561  loss_box_reg: 0.2346  loss_mask: 0.2649  loss_rpn_cls: 0.05473  loss_rpn_loc: 0.1831  time: 0.6405  data_time: 0.3157  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:31:58 d2.utils.events]: \u001b[0m eta: 2:52:39  iter: 10219  total_loss: 0.9838  loss_cls: 0.1926  loss_box_reg: 0.2285  loss_mask: 0.2705  loss_rpn_cls: 0.07512  loss_rpn_loc: 0.1763  time: 0.6399  data_time: 0.3678  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:32:09 d2.utils.events]: \u001b[0m eta: 2:53:24  iter: 10239  total_loss: 1.02  loss_cls: 0.1928  loss_box_reg: 0.2462  loss_mask: 0.2734  loss_rpn_cls: 0.06887  loss_rpn_loc: 0.1926  time: 0.6392  data_time: 0.3571  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:32:21 d2.utils.events]: \u001b[0m eta: 2:54:13  iter: 10259  total_loss: 0.9677  loss_cls: 0.1712  loss_box_reg: 0.2242  loss_mask: 0.2507  loss_rpn_cls: 0.06581  loss_rpn_loc: 0.189  time: 0.6389  data_time: 0.3903  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:32:33 d2.utils.events]: \u001b[0m eta: 2:54:07  iter: 10279  total_loss: 1.025  loss_cls: 0.1957  loss_box_reg: 0.2406  loss_mask: 0.2835  loss_rpn_cls: 0.06151  loss_rpn_loc: 0.1938  time: 0.6383  data_time: 0.3653  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:32:40 d2.utils.events]: \u001b[0m eta: 2:52:15  iter: 10299  total_loss: 0.8974  loss_cls: 0.1764  loss_box_reg: 0.2426  loss_mask: 0.2377  loss_rpn_cls: 0.04807  loss_rpn_loc: 0.1759  time: 0.6355  data_time: 0.1419  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:32:49 d2.utils.events]: \u001b[0m eta: 2:52:10  iter: 10319  total_loss: 0.4811  loss_cls: 0.07493  loss_box_reg: 0.08177  loss_mask: 0.1072  loss_rpn_cls: 0.04395  loss_rpn_loc: 0.1849  time: 0.6340  data_time: 0.2688  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:33:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 11:33:01 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 11:33:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 11:33:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 11:33:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0446 s/iter. Eval: 0.0182 s/iter. Total: 0.0636 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 11:33:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.203277 (0.057201 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:33:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043374 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:33:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 11:33:05 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07002362324988233\n",
      "\u001b[32m[12/30 11:33:07 d2.utils.events]: \u001b[0m eta: 2:52:58  iter: 10339  total_loss: 1.058  loss_cls: 0.1928  loss_box_reg: 0.2573  loss_mask: 0.2873  loss_rpn_cls: 0.06812  loss_rpn_loc: 0.1966  time: 0.6348  data_time: 0.4953  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:33:26 d2.utils.events]: \u001b[0m eta: 2:55:03  iter: 10359  total_loss: 1.118  loss_cls: 0.2402  loss_box_reg: 0.2902  loss_mask: 0.2822  loss_rpn_cls: 0.1092  loss_rpn_loc: 0.225  time: 0.6377  data_time: 0.7346  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:33:40 d2.utils.events]: \u001b[0m eta: 2:54:57  iter: 10379  total_loss: 0.9909  loss_cls: 0.1696  loss_box_reg: 0.2377  loss_mask: 0.2579  loss_rpn_cls: 0.06681  loss_rpn_loc: 0.2053  time: 0.6382  data_time: 0.4687  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:33:53 d2.utils.events]: \u001b[0m eta: 2:53:36  iter: 10399  total_loss: 0.9489  loss_cls: 0.1891  loss_box_reg: 0.2405  loss_mask: 0.2687  loss_rpn_cls: 0.04207  loss_rpn_loc: 0.1929  time: 0.6381  data_time: 0.4093  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:34:07 d2.utils.events]: \u001b[0m eta: 2:53:35  iter: 10419  total_loss: 0.9478  loss_cls: 0.1731  loss_box_reg: 0.2204  loss_mask: 0.2415  loss_rpn_cls: 0.07659  loss_rpn_loc: 0.1785  time: 0.6387  data_time: 0.5058  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:34:16 d2.utils.events]: \u001b[0m eta: 2:53:15  iter: 10439  total_loss: 0.913  loss_cls: 0.1613  loss_box_reg: 0.1615  loss_mask: 0.2351  loss_rpn_cls: 0.05352  loss_rpn_loc: 0.1938  time: 0.6370  data_time: 0.2296  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:34:29 d2.utils.events]: \u001b[0m eta: 2:53:25  iter: 10459  total_loss: 1.067  loss_cls: 0.2016  loss_box_reg: 0.2652  loss_mask: 0.2727  loss_rpn_cls: 0.06303  loss_rpn_loc: 0.1942  time: 0.6370  data_time: 0.4213  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:34:41 d2.utils.events]: \u001b[0m eta: 2:53:47  iter: 10479  total_loss: 0.9251  loss_cls: 0.1855  loss_box_reg: 0.2481  loss_mask: 0.2592  loss_rpn_cls: 0.04509  loss_rpn_loc: 0.1779  time: 0.6367  data_time: 0.3996  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:34:55 d2.utils.events]: \u001b[0m eta: 2:55:24  iter: 10499  total_loss: 1.008  loss_cls: 0.1837  loss_box_reg: 0.2349  loss_mask: 0.2429  loss_rpn_cls: 0.06685  loss_rpn_loc: 0.2109  time: 0.6372  data_time: 0.4764  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:35:08 d2.utils.events]: \u001b[0m eta: 2:55:19  iter: 10519  total_loss: 0.9124  loss_cls: 0.1591  loss_box_reg: 0.2132  loss_mask: 0.2476  loss_rpn_cls: 0.05911  loss_rpn_loc: 0.2035  time: 0.6374  data_time: 0.4622  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:35:23 d2.utils.events]: \u001b[0m eta: 2:58:11  iter: 10539  total_loss: 1.021  loss_cls: 0.21  loss_box_reg: 0.228  loss_mask: 0.2778  loss_rpn_cls: 0.08229  loss_rpn_loc: 0.2157  time: 0.6384  data_time: 0.5385  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:35:36 d2.utils.events]: \u001b[0m eta: 2:56:33  iter: 10559  total_loss: 0.8629  loss_cls: 0.1536  loss_box_reg: 0.2023  loss_mask: 0.2414  loss_rpn_cls: 0.06243  loss_rpn_loc: 0.1829  time: 0.6382  data_time: 0.4122  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:35:49 d2.utils.events]: \u001b[0m eta: 2:56:16  iter: 10579  total_loss: 0.973  loss_cls: 0.1812  loss_box_reg: 0.201  loss_mask: 0.2809  loss_rpn_cls: 0.05153  loss_rpn_loc: 0.177  time: 0.6386  data_time: 0.4585  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:36:02 d2.utils.events]: \u001b[0m eta: 2:52:48  iter: 10599  total_loss: 0.4021  loss_cls: 0.03741  loss_box_reg: 0.0756  loss_mask: 0.1098  loss_rpn_cls: 0.03844  loss_rpn_loc: 0.1923  time: 0.6385  data_time: 0.4170  lr: 0.00125  max_mem: 6404M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 11:36:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 11:36:08 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 11:36:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 11:36:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 11:36:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0446 s/iter. Eval: 0.0166 s/iter. Total: 0.0619 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 11:36:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.215406 (0.057418 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:36:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043323 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:36:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 11:36:11 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07086962249426068\n",
      "\u001b[32m[12/30 11:36:22 d2.utils.events]: \u001b[0m eta: 2:55:52  iter: 10619  total_loss: 1.099  loss_cls: 0.2054  loss_box_reg: 0.261  loss_mask: 0.2854  loss_rpn_cls: 0.109  loss_rpn_loc: 0.2234  time: 0.6401  data_time: 0.6122  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:36:35 d2.utils.events]: \u001b[0m eta: 2:52:33  iter: 10639  total_loss: 0.6393  loss_cls: 0.07713  loss_box_reg: 0.09366  loss_mask: 0.1336  loss_rpn_cls: 0.05029  loss_rpn_loc: 0.192  time: 0.6400  data_time: 0.4190  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:36:52 d2.utils.events]: \u001b[0m eta: 2:52:27  iter: 10659  total_loss: 1.023  loss_cls: 0.1932  loss_box_reg: 0.2318  loss_mask: 0.2822  loss_rpn_cls: 0.07775  loss_rpn_loc: 0.227  time: 0.6416  data_time: 0.6168  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:37:06 d2.utils.events]: \u001b[0m eta: 2:52:27  iter: 10679  total_loss: 0.9427  loss_cls: 0.1591  loss_box_reg: 0.2269  loss_mask: 0.2768  loss_rpn_cls: 0.06939  loss_rpn_loc: 0.2062  time: 0.6420  data_time: 0.4772  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:37:15 d2.utils.events]: \u001b[0m eta: 2:51:55  iter: 10699  total_loss: 0.8349  loss_cls: 0.1279  loss_box_reg: 0.1634  loss_mask: 0.2176  loss_rpn_cls: 0.06558  loss_rpn_loc: 0.1938  time: 0.6406  data_time: 0.2645  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:37:25 d2.utils.events]: \u001b[0m eta: 2:51:50  iter: 10719  total_loss: 0.9009  loss_cls: 0.1779  loss_box_reg: 0.198  loss_mask: 0.2476  loss_rpn_cls: 0.05307  loss_rpn_loc: 0.1906  time: 0.6394  data_time: 0.2789  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:37:38 d2.utils.events]: \u001b[0m eta: 2:52:39  iter: 10739  total_loss: 1.051  loss_cls: 0.2125  loss_box_reg: 0.2789  loss_mask: 0.2821  loss_rpn_cls: 0.06384  loss_rpn_loc: 0.1989  time: 0.6395  data_time: 0.4470  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:37:52 d2.utils.events]: \u001b[0m eta: 2:53:12  iter: 10759  total_loss: 0.9931  loss_cls: 0.2126  loss_box_reg: 0.2584  loss_mask: 0.274  loss_rpn_cls: 0.08602  loss_rpn_loc: 0.2077  time: 0.6400  data_time: 0.4803  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:38:04 d2.utils.events]: \u001b[0m eta: 2:54:24  iter: 10779  total_loss: 1.106  loss_cls: 0.2183  loss_box_reg: 0.2609  loss_mask: 0.2686  loss_rpn_cls: 0.08913  loss_rpn_loc: 0.2133  time: 0.6396  data_time: 0.3830  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:38:17 d2.utils.events]: \u001b[0m eta: 2:56:58  iter: 10799  total_loss: 1.007  loss_cls: 0.188  loss_box_reg: 0.2357  loss_mask: 0.2617  loss_rpn_cls: 0.07239  loss_rpn_loc: 0.2042  time: 0.6398  data_time: 0.4482  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:38:31 d2.utils.events]: \u001b[0m eta: 2:57:11  iter: 10819  total_loss: 0.9818  loss_cls: 0.1802  loss_box_reg: 0.2064  loss_mask: 0.2794  loss_rpn_cls: 0.07888  loss_rpn_loc: 0.1953  time: 0.6401  data_time: 0.4679  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:38:45 d2.utils.events]: \u001b[0m eta: 2:57:06  iter: 10839  total_loss: 0.9516  loss_cls: 0.1714  loss_box_reg: 0.1992  loss_mask: 0.2617  loss_rpn_cls: 0.07993  loss_rpn_loc: 0.1965  time: 0.6406  data_time: 0.4894  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:38:57 d2.utils.events]: \u001b[0m eta: 2:55:00  iter: 10859  total_loss: 0.9668  loss_cls: 0.1454  loss_box_reg: 0.1895  loss_mask: 0.2742  loss_rpn_cls: 0.05901  loss_rpn_loc: 0.2056  time: 0.6402  data_time: 0.3725  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:39:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 11:39:10 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 11:39:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 11:39:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 11:39:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0442 s/iter. Eval: 0.0192 s/iter. Total: 0.0641 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 11:39:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.218192 (0.057468 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:39:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043042 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:39:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 11:39:14 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0709451173373096\n",
      "\u001b[32m[12/30 11:39:14 d2.utils.events]: \u001b[0m eta: 2:55:07  iter: 10879  total_loss: 1.012  loss_cls: 0.18  loss_box_reg: 0.2333  loss_mask: 0.2592  loss_rpn_cls: 0.06764  loss_rpn_loc: 0.2085  time: 0.6404  data_time: 0.4431  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:39:28 d2.utils.events]: \u001b[0m eta: 2:54:50  iter: 10899  total_loss: 1.003  loss_cls: 0.1622  loss_box_reg: 0.267  loss_mask: 0.2609  loss_rpn_cls: 0.05529  loss_rpn_loc: 0.1891  time: 0.6410  data_time: 0.5023  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:39:42 d2.utils.events]: \u001b[0m eta: 2:56:44  iter: 10919  total_loss: 1.04  loss_cls: 0.2128  loss_box_reg: 0.2311  loss_mask: 0.2777  loss_rpn_cls: 0.06828  loss_rpn_loc: 0.2077  time: 0.6414  data_time: 0.4890  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:39:58 d2.utils.events]: \u001b[0m eta: 2:57:03  iter: 10939  total_loss: 1.12  loss_cls: 0.1956  loss_box_reg: 0.1969  loss_mask: 0.2582  loss_rpn_cls: 0.07857  loss_rpn_loc: 0.2246  time: 0.6423  data_time: 0.5397  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:40:14 d2.utils.events]: \u001b[0m eta: 3:01:23  iter: 10959  total_loss: 1.077  loss_cls: 0.2008  loss_box_reg: 0.2415  loss_mask: 0.2835  loss_rpn_cls: 0.09351  loss_rpn_loc: 0.2021  time: 0.6433  data_time: 0.5590  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:40:21 d2.utils.events]: \u001b[0m eta: 3:01:18  iter: 10979  total_loss: 0.9824  loss_cls: 0.1846  loss_box_reg: 0.2354  loss_mask: 0.2521  loss_rpn_cls: 0.05573  loss_rpn_loc: 0.1955  time: 0.6415  data_time: 0.1794  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:40:34 d2.utils.events]: \u001b[0m eta: 3:01:28  iter: 10999  total_loss: 0.9427  loss_cls: 0.1562  loss_box_reg: 0.2006  loss_mask: 0.2871  loss_rpn_cls: 0.04732  loss_rpn_loc: 0.174  time: 0.6416  data_time: 0.4502  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:40:46 d2.utils.events]: \u001b[0m eta: 3:02:10  iter: 11019  total_loss: 1.031  loss_cls: 0.1912  loss_box_reg: 0.2516  loss_mask: 0.2771  loss_rpn_cls: 0.06524  loss_rpn_loc: 0.197  time: 0.6411  data_time: 0.3520  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:40:57 d2.utils.events]: \u001b[0m eta: 3:01:46  iter: 11039  total_loss: 1.025  loss_cls: 0.1752  loss_box_reg: 0.2107  loss_mask: 0.2874  loss_rpn_cls: 0.07412  loss_rpn_loc: 0.2078  time: 0.6406  data_time: 0.3641  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:41:14 d2.utils.events]: \u001b[0m eta: 3:03:31  iter: 11059  total_loss: 1.037  loss_cls: 0.1816  loss_box_reg: 0.2475  loss_mask: 0.2705  loss_rpn_cls: 0.08396  loss_rpn_loc: 0.1976  time: 0.6420  data_time: 0.6158  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:41:25 d2.utils.events]: \u001b[0m eta: 3:04:20  iter: 11079  total_loss: 0.9039  loss_cls: 0.1579  loss_box_reg: 0.2138  loss_mask: 0.2359  loss_rpn_cls: 0.05232  loss_rpn_loc: 0.2135  time: 0.6413  data_time: 0.3410  lr: 0.00125  max_mem: 6404M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 11:41:37 d2.utils.events]: \u001b[0m eta: 3:01:48  iter: 11099  total_loss: 0.9436  loss_cls: 0.1771  loss_box_reg: 0.2469  loss_mask: 0.2689  loss_rpn_cls: 0.06367  loss_rpn_loc: 0.192  time: 0.6411  data_time: 0.3944  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:41:49 d2.utils.events]: \u001b[0m eta: 3:01:40  iter: 11119  total_loss: 1.033  loss_cls: 0.1845  loss_box_reg: 0.1976  loss_mask: 0.2665  loss_rpn_cls: 0.06789  loss_rpn_loc: 0.2066  time: 0.6406  data_time: 0.3551  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:41:58 d2.utils.events]: \u001b[0m eta: 3:00:21  iter: 11139  total_loss: 0.971  loss_cls: 0.1718  loss_box_reg: 0.2448  loss_mask: 0.2748  loss_rpn_cls: 0.04313  loss_rpn_loc: 0.1759  time: 0.6393  data_time: 0.2406  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:42:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 11:42:08 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 11:42:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 11:42:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 11:42:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0447 s/iter. Eval: 0.0144 s/iter. Total: 0.0598 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/30 11:42:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.170003 (0.056607 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:42:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043498 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:42:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 11:42:11 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06642223902156187\n",
      "\u001b[32m[12/30 11:42:13 d2.utils.events]: \u001b[0m eta: 2:58:28  iter: 11159  total_loss: 1.013  loss_cls: 0.1828  loss_box_reg: 0.2536  loss_mask: 0.2853  loss_rpn_cls: 0.08719  loss_rpn_loc: 0.1967  time: 0.6391  data_time: 0.3964  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:42:27 d2.utils.events]: \u001b[0m eta: 3:00:10  iter: 11179  total_loss: 1.076  loss_cls: 0.2237  loss_box_reg: 0.2284  loss_mask: 0.2547  loss_rpn_cls: 0.07044  loss_rpn_loc: 0.2066  time: 0.6394  data_time: 0.4609  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:42:39 d2.utils.events]: \u001b[0m eta: 3:00:30  iter: 11199  total_loss: 0.9268  loss_cls: 0.1826  loss_box_reg: 0.1948  loss_mask: 0.2573  loss_rpn_cls: 0.05946  loss_rpn_loc: 0.1805  time: 0.6392  data_time: 0.3987  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:42:50 d2.utils.events]: \u001b[0m eta: 2:56:48  iter: 11219  total_loss: 0.8256  loss_cls: 0.1394  loss_box_reg: 0.1925  loss_mask: 0.2189  loss_rpn_cls: 0.05783  loss_rpn_loc: 0.1966  time: 0.6386  data_time: 0.3462  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:43:08 d2.utils.events]: \u001b[0m eta: 2:58:06  iter: 11239  total_loss: 1.11  loss_cls: 0.1919  loss_box_reg: 0.2452  loss_mask: 0.3042  loss_rpn_cls: 0.09594  loss_rpn_loc: 0.219  time: 0.6403  data_time: 0.6615  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:43:22 d2.utils.events]: \u001b[0m eta: 2:55:26  iter: 11259  total_loss: 1.006  loss_cls: 0.1883  loss_box_reg: 0.2139  loss_mask: 0.2748  loss_rpn_cls: 0.07813  loss_rpn_loc: 0.197  time: 0.6405  data_time: 0.4573  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:43:37 d2.utils.events]: \u001b[0m eta: 2:57:55  iter: 11279  total_loss: 0.9629  loss_cls: 0.1926  loss_box_reg: 0.2093  loss_mask: 0.2582  loss_rpn_cls: 0.068  loss_rpn_loc: 0.2103  time: 0.6413  data_time: 0.5611  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:43:51 d2.utils.events]: \u001b[0m eta: 3:00:33  iter: 11299  total_loss: 0.9912  loss_cls: 0.1784  loss_box_reg: 0.2477  loss_mask: 0.3051  loss_rpn_cls: 0.06414  loss_rpn_loc: 0.2029  time: 0.6418  data_time: 0.5031  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:44:05 d2.utils.events]: \u001b[0m eta: 3:00:46  iter: 11319  total_loss: 0.9788  loss_cls: 0.1817  loss_box_reg: 0.215  loss_mask: 0.2631  loss_rpn_cls: 0.08005  loss_rpn_loc: 0.201  time: 0.6419  data_time: 0.4447  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:44:19 d2.utils.events]: \u001b[0m eta: 3:00:22  iter: 11339  total_loss: 1.055  loss_cls: 0.1916  loss_box_reg: 0.28  loss_mask: 0.2823  loss_rpn_cls: 0.07229  loss_rpn_loc: 0.1996  time: 0.6424  data_time: 0.5051  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:44:31 d2.utils.events]: \u001b[0m eta: 2:58:36  iter: 11359  total_loss: 1.017  loss_cls: 0.2067  loss_box_reg: 0.2545  loss_mask: 0.2781  loss_rpn_cls: 0.06035  loss_rpn_loc: 0.2177  time: 0.6422  data_time: 0.3945  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:44:45 d2.utils.events]: \u001b[0m eta: 2:57:34  iter: 11379  total_loss: 0.8924  loss_cls: 0.1493  loss_box_reg: 0.1679  loss_mask: 0.2512  loss_rpn_cls: 0.04798  loss_rpn_loc: 0.2163  time: 0.6424  data_time: 0.4558  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:44:56 d2.utils.events]: \u001b[0m eta: 2:56:59  iter: 11399  total_loss: 0.8296  loss_cls: 0.1606  loss_box_reg: 0.1795  loss_mask: 0.226  loss_rpn_cls: 0.05273  loss_rpn_loc: 0.187  time: 0.6417  data_time: 0.3220  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:45:06 d2.utils.events]: \u001b[0m eta: 2:55:54  iter: 11419  total_loss: 1.02  loss_cls: 0.1971  loss_box_reg: 0.265  loss_mask: 0.2409  loss_rpn_cls: 0.0607  loss_rpn_loc: 0.2018  time: 0.6409  data_time: 0.3035  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:45:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 11:45:10 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 11:45:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 11:45:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 11:45:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0452 s/iter. Eval: 0.0275 s/iter. Total: 0.0735 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 11:45:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.295475 (0.058848 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:45:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043400 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:45:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 11:45:14 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06939897545975794\n",
      "\u001b[32m[12/30 11:45:23 d2.utils.events]: \u001b[0m eta: 2:57:18  iter: 11439  total_loss: 0.9454  loss_cls: 0.1725  loss_box_reg: 0.2331  loss_mask: 0.2696  loss_rpn_cls: 0.06822  loss_rpn_loc: 0.1904  time: 0.6409  data_time: 0.4221  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:45:35 d2.utils.events]: \u001b[0m eta: 2:55:32  iter: 11459  total_loss: 0.9822  loss_cls: 0.1979  loss_box_reg: 0.2332  loss_mask: 0.2769  loss_rpn_cls: 0.05483  loss_rpn_loc: 0.1832  time: 0.6407  data_time: 0.3897  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:45:48 d2.utils.events]: \u001b[0m eta: 2:54:35  iter: 11479  total_loss: 1.045  loss_cls: 0.1749  loss_box_reg: 0.2574  loss_mask: 0.2706  loss_rpn_cls: 0.0615  loss_rpn_loc: 0.1942  time: 0.6407  data_time: 0.4212  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:46:01 d2.utils.events]: \u001b[0m eta: 2:53:36  iter: 11499  total_loss: 0.9772  loss_cls: 0.1824  loss_box_reg: 0.2161  loss_mask: 0.2869  loss_rpn_cls: 0.06091  loss_rpn_loc: 0.1998  time: 0.6409  data_time: 0.4617  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:46:18 d2.utils.events]: \u001b[0m eta: 2:54:24  iter: 11519  total_loss: 0.9973  loss_cls: 0.184  loss_box_reg: 0.2447  loss_mask: 0.2861  loss_rpn_cls: 0.06831  loss_rpn_loc: 0.2195  time: 0.6421  data_time: 0.6106  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:46:34 d2.utils.events]: \u001b[0m eta: 2:54:19  iter: 11539  total_loss: 1  loss_cls: 0.1858  loss_box_reg: 0.2297  loss_mask: 0.2772  loss_rpn_cls: 0.08454  loss_rpn_loc: 0.2093  time: 0.6431  data_time: 0.5970  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:46:48 d2.utils.events]: \u001b[0m eta: 2:54:33  iter: 11559  total_loss: 1.021  loss_cls: 0.1923  loss_box_reg: 0.2087  loss_mask: 0.2687  loss_rpn_cls: 0.08188  loss_rpn_loc: 0.2167  time: 0.6433  data_time: 0.4704  lr: 0.00125  max_mem: 6404M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 11:47:02 d2.utils.events]: \u001b[0m eta: 2:54:28  iter: 11579  total_loss: 0.98  loss_cls: 0.1973  loss_box_reg: 0.2117  loss_mask: 0.2742  loss_rpn_cls: 0.09755  loss_rpn_loc: 0.2008  time: 0.6438  data_time: 0.5109  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:47:15 d2.utils.events]: \u001b[0m eta: 2:56:34  iter: 11599  total_loss: 1.002  loss_cls: 0.1568  loss_box_reg: 0.1887  loss_mask: 0.2686  loss_rpn_cls: 0.06155  loss_rpn_loc: 0.1997  time: 0.6435  data_time: 0.3950  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:47:25 d2.utils.events]: \u001b[0m eta: 2:54:48  iter: 11619  total_loss: 0.9929  loss_cls: 0.1579  loss_box_reg: 0.2133  loss_mask: 0.2364  loss_rpn_cls: 0.0497  loss_rpn_loc: 0.2004  time: 0.6429  data_time: 0.3346  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:47:39 d2.utils.events]: \u001b[0m eta: 2:54:43  iter: 11639  total_loss: 0.932  loss_cls: 0.1619  loss_box_reg: 0.2099  loss_mask: 0.2482  loss_rpn_cls: 0.05563  loss_rpn_loc: 0.1869  time: 0.6432  data_time: 0.4816  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:47:55 d2.utils.events]: \u001b[0m eta: 2:54:06  iter: 11659  total_loss: 1.001  loss_cls: 0.2032  loss_box_reg: 0.2573  loss_mask: 0.2678  loss_rpn_cls: 0.07924  loss_rpn_loc: 0.2174  time: 0.6441  data_time: 0.5731  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:48:08 d2.utils.events]: \u001b[0m eta: 2:55:11  iter: 11679  total_loss: 0.9427  loss_cls: 0.1801  loss_box_reg: 0.2448  loss_mask: 0.2649  loss_rpn_cls: 0.04833  loss_rpn_loc: 0.2005  time: 0.6441  data_time: 0.4270  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:48:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 11:48:14 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 11:48:14 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 11:48:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 11:48:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0447 s/iter. Eval: 0.0201 s/iter. Total: 0.0655 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 11:48:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.229336 (0.057667 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:48:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043414 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:48:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 11:48:18 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06665569790743595\n",
      "\u001b[32m[12/30 11:48:23 d2.utils.events]: \u001b[0m eta: 2:55:36  iter: 11699  total_loss: 0.8809  loss_cls: 0.1638  loss_box_reg: 0.2122  loss_mask: 0.2458  loss_rpn_cls: 0.04278  loss_rpn_loc: 0.1833  time: 0.6435  data_time: 0.3198  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:48:36 d2.utils.events]: \u001b[0m eta: 2:58:53  iter: 11719  total_loss: 1.093  loss_cls: 0.2181  loss_box_reg: 0.2677  loss_mask: 0.2821  loss_rpn_cls: 0.0852  loss_rpn_loc: 0.2256  time: 0.6436  data_time: 0.4401  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:48:49 d2.utils.events]: \u001b[0m eta: 2:58:14  iter: 11739  total_loss: 0.9925  loss_cls: 0.1578  loss_box_reg: 0.166  loss_mask: 0.2697  loss_rpn_cls: 0.1024  loss_rpn_loc: 0.2031  time: 0.6435  data_time: 0.4275  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:49:05 d2.utils.events]: \u001b[0m eta: 2:58:46  iter: 11759  total_loss: 0.9541  loss_cls: 0.2014  loss_box_reg: 0.2284  loss_mask: 0.272  loss_rpn_cls: 0.08025  loss_rpn_loc: 0.2055  time: 0.6445  data_time: 0.6040  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:49:14 d2.utils.events]: \u001b[0m eta: 2:55:14  iter: 11779  total_loss: 0.9546  loss_cls: 0.1681  loss_box_reg: 0.2303  loss_mask: 0.2604  loss_rpn_cls: 0.05587  loss_rpn_loc: 0.1997  time: 0.6434  data_time: 0.2456  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:51:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 11:51:11 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 11:51:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 11:51:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 11:51:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0452 s/iter. Eval: 0.0242 s/iter. Total: 0.0701 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 11:51:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.276203 (0.058504 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:51:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043084 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:51:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 11:51:15 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06643523664198119\n",
      "\u001b[32m[12/30 11:51:23 d2.utils.events]: \u001b[0m eta: 2:45:24  iter: 11979  total_loss: 1.01  loss_cls: 0.1926  loss_box_reg: 0.2552  loss_mask: 0.265  loss_rpn_cls: 0.06676  loss_rpn_loc: 0.1932  time: 0.6424  data_time: 0.4552  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:51:35 d2.utils.events]: \u001b[0m eta: 2:44:46  iter: 11999  total_loss: 1.114  loss_cls: 0.2086  loss_box_reg: 0.2589  loss_mask: 0.2825  loss_rpn_cls: 0.09397  loss_rpn_loc: 0.2325  time: 0.6423  data_time: 0.4015  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:51:49 d2.utils.events]: \u001b[0m eta: 2:45:09  iter: 12019  total_loss: 1.039  loss_cls: 0.189  loss_box_reg: 0.2555  loss_mask: 0.2798  loss_rpn_cls: 0.07124  loss_rpn_loc: 0.2167  time: 0.6425  data_time: 0.4775  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:52:03 d2.utils.events]: \u001b[0m eta: 2:46:08  iter: 12039  total_loss: 1.041  loss_cls: 0.1832  loss_box_reg: 0.2454  loss_mask: 0.2766  loss_rpn_cls: 0.06158  loss_rpn_loc: 0.1995  time: 0.6429  data_time: 0.4911  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:52:20 d2.utils.events]: \u001b[0m eta: 2:45:27  iter: 12059  total_loss: 0.9696  loss_cls: 0.1688  loss_box_reg: 0.1991  loss_mask: 0.2827  loss_rpn_cls: 0.06947  loss_rpn_loc: 0.1927  time: 0.6437  data_time: 0.5918  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:52:31 d2.utils.events]: \u001b[0m eta: 2:45:19  iter: 12079  total_loss: 0.9651  loss_cls: 0.1599  loss_box_reg: 0.1551  loss_mask: 0.2725  loss_rpn_cls: 0.06016  loss_rpn_loc: 0.2018  time: 0.6434  data_time: 0.3822  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:52:44 d2.utils.events]: \u001b[0m eta: 2:44:59  iter: 12099  total_loss: 0.8458  loss_cls: 0.1563  loss_box_reg: 0.1956  loss_mask: 0.2226  loss_rpn_cls: 0.05704  loss_rpn_loc: 0.1891  time: 0.6434  data_time: 0.4241  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:52:56 d2.utils.events]: \u001b[0m eta: 2:47:36  iter: 12119  total_loss: 1.045  loss_cls: 0.1966  loss_box_reg: 0.2479  loss_mask: 0.2831  loss_rpn_cls: 0.0921  loss_rpn_loc: 0.2006  time: 0.6432  data_time: 0.3928  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:53:12 d2.utils.events]: \u001b[0m eta: 2:49:24  iter: 12139  total_loss: 1.089  loss_cls: 0.2357  loss_box_reg: 0.2799  loss_mask: 0.2784  loss_rpn_cls: 0.08429  loss_rpn_loc: 0.1997  time: 0.6438  data_time: 0.5518  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:53:22 d2.utils.events]: \u001b[0m eta: 2:47:25  iter: 12159  total_loss: 0.9405  loss_cls: 0.1834  loss_box_reg: 0.2304  loss_mask: 0.2492  loss_rpn_cls: 0.0467  loss_rpn_loc: 0.184  time: 0.6432  data_time: 0.3097  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:53:36 d2.utils.events]: \u001b[0m eta: 2:47:20  iter: 12179  total_loss: 1.006  loss_cls: 0.1841  loss_box_reg: 0.1954  loss_mask: 0.2901  loss_rpn_cls: 0.07945  loss_rpn_loc: 0.2289  time: 0.6436  data_time: 0.4994  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:53:51 d2.utils.events]: \u001b[0m eta: 2:48:34  iter: 12199  total_loss: 0.6419  loss_cls: 0.08694  loss_box_reg: 0.08781  loss_mask: 0.1219  loss_rpn_cls: 0.07176  loss_rpn_loc: 0.2011  time: 0.6440  data_time: 0.5170  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:54:07 d2.utils.events]: \u001b[0m eta: 2:51:42  iter: 12219  total_loss: 1.124  loss_cls: 0.215  loss_box_reg: 0.2787  loss_mask: 0.296  loss_rpn_cls: 0.07526  loss_rpn_loc: 0.214  time: 0.6448  data_time: 0.5919  lr: 0.00125  max_mem: 6404M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 11:54:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 11:54:20 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 11:54:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 11:54:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 11:54:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0455 s/iter. Eval: 0.0254 s/iter. Total: 0.0718 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 11:54:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.256924 (0.058159 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:54:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043407 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:54:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 11:54:23 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06721012405655706\n",
      "\u001b[32m[12/30 11:54:23 d2.utils.events]: \u001b[0m eta: 2:49:09  iter: 12239  total_loss: 0.9262  loss_cls: 0.1725  loss_box_reg: 0.2433  loss_mask: 0.2749  loss_rpn_cls: 0.05918  loss_rpn_loc: 0.1937  time: 0.6447  data_time: 0.4059  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:54:42 d2.utils.events]: \u001b[0m eta: 2:51:31  iter: 12259  total_loss: 1.007  loss_cls: 0.1768  loss_box_reg: 0.2298  loss_mask: 0.29  loss_rpn_cls: 0.07603  loss_rpn_loc: 0.2045  time: 0.6462  data_time: 0.7168  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:54:57 d2.utils.events]: \u001b[0m eta: 2:51:04  iter: 12279  total_loss: 0.9743  loss_cls: 0.1816  loss_box_reg: 0.2355  loss_mask: 0.2665  loss_rpn_cls: 0.05524  loss_rpn_loc: 0.1904  time: 0.6466  data_time: 0.5132  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:55:05 d2.utils.events]: \u001b[0m eta: 2:48:53  iter: 12299  total_loss: 0.7979  loss_cls: 0.0986  loss_box_reg: 0.1634  loss_mask: 0.1959  loss_rpn_cls: 0.05508  loss_rpn_loc: 0.1989  time: 0.6453  data_time: 0.1835  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:55:17 d2.utils.events]: \u001b[0m eta: 2:49:25  iter: 12319  total_loss: 1.044  loss_cls: 0.1967  loss_box_reg: 0.2541  loss_mask: 0.2742  loss_rpn_cls: 0.06412  loss_rpn_loc: 0.2183  time: 0.6450  data_time: 0.3732  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:55:30 d2.utils.events]: \u001b[0m eta: 2:49:26  iter: 12339  total_loss: 0.9708  loss_cls: 0.1686  loss_box_reg: 0.1898  loss_mask: 0.2708  loss_rpn_cls: 0.06698  loss_rpn_loc: 0.205  time: 0.6450  data_time: 0.4181  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:55:38 d2.utils.events]: \u001b[0m eta: 2:47:51  iter: 12359  total_loss: 0.9027  loss_cls: 0.1608  loss_box_reg: 0.2247  loss_mask: 0.2437  loss_rpn_cls: 0.05176  loss_rpn_loc: 0.1939  time: 0.6440  data_time: 0.2277  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:55:56 d2.utils.events]: \u001b[0m eta: 2:49:16  iter: 12379  total_loss: 1.073  loss_cls: 0.2016  loss_box_reg: 0.2282  loss_mask: 0.2854  loss_rpn_cls: 0.09135  loss_rpn_loc: 0.203  time: 0.6451  data_time: 0.6670  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:56:10 d2.utils.events]: \u001b[0m eta: 2:50:32  iter: 12399  total_loss: 0.8826  loss_cls: 0.1913  loss_box_reg: 0.1956  loss_mask: 0.2426  loss_rpn_cls: 0.05443  loss_rpn_loc: 0.191  time: 0.6453  data_time: 0.4612  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:56:19 d2.utils.events]: \u001b[0m eta: 2:49:59  iter: 12419  total_loss: 1.03  loss_cls: 0.1689  loss_box_reg: 0.2347  loss_mask: 0.2585  loss_rpn_cls: 0.06273  loss_rpn_loc: 0.1837  time: 0.6446  data_time: 0.2919  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:56:31 d2.utils.events]: \u001b[0m eta: 2:49:53  iter: 12439  total_loss: 0.9886  loss_cls: 0.1912  loss_box_reg: 0.2338  loss_mask: 0.2707  loss_rpn_cls: 0.0661  loss_rpn_loc: 0.1907  time: 0.6443  data_time: 0.3626  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:56:44 d2.utils.events]: \u001b[0m eta: 2:50:02  iter: 12459  total_loss: 0.9564  loss_cls: 0.1591  loss_box_reg: 0.1951  loss_mask: 0.2743  loss_rpn_cls: 0.05442  loss_rpn_loc: 0.1801  time: 0.6444  data_time: 0.4488  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:56:55 d2.utils.events]: \u001b[0m eta: 2:49:57  iter: 12479  total_loss: 0.8346  loss_cls: 0.152  loss_box_reg: 0.138  loss_mask: 0.2542  loss_rpn_cls: 0.0548  loss_rpn_loc: 0.182  time: 0.6439  data_time: 0.3258  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:57:09 d2.utils.events]: \u001b[0m eta: 2:49:52  iter: 12499  total_loss: 0.9904  loss_cls: 0.197  loss_box_reg: 0.2544  loss_mask: 0.2753  loss_rpn_cls: 0.05995  loss_rpn_loc: 0.1864  time: 0.6442  data_time: 0.5002  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:57:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 11:57:19 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 11:57:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 11:57:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 11:57:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0448 s/iter. Eval: 0.0192 s/iter. Total: 0.0648 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 11:57:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.213826 (0.057390 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:57:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043138 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 11:57:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 11:57:22 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07060612750261859\n",
      "\u001b[32m[12/30 11:57:25 d2.utils.events]: \u001b[0m eta: 2:49:46  iter: 12519  total_loss: 0.9972  loss_cls: 0.1874  loss_box_reg: 0.2051  loss_mask: 0.2561  loss_rpn_cls: 0.08224  loss_rpn_loc: 0.2044  time: 0.6441  data_time: 0.3991  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:57:40 d2.utils.events]: \u001b[0m eta: 2:49:26  iter: 12539  total_loss: 1.004  loss_cls: 0.1748  loss_box_reg: 0.2096  loss_mask: 0.2776  loss_rpn_cls: 0.08527  loss_rpn_loc: 0.2094  time: 0.6445  data_time: 0.5141  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:57:56 d2.utils.events]: \u001b[0m eta: 2:49:35  iter: 12559  total_loss: 0.9712  loss_cls: 0.1692  loss_box_reg: 0.2372  loss_mask: 0.2854  loss_rpn_cls: 0.06589  loss_rpn_loc: 0.2168  time: 0.6452  data_time: 0.5771  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:58:03 d2.utils.events]: \u001b[0m eta: 2:46:48  iter: 12579  total_loss: 0.2981  loss_cls: 0.0001106  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04051  loss_rpn_loc: 0.1824  time: 0.6438  data_time: 0.1382  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:58:15 d2.utils.events]: \u001b[0m eta: 2:47:16  iter: 12599  total_loss: 0.8603  loss_cls: 0.1567  loss_box_reg: 0.2094  loss_mask: 0.2433  loss_rpn_cls: 0.06862  loss_rpn_loc: 0.1939  time: 0.6437  data_time: 0.4148  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:58:30 d2.utils.events]: \u001b[0m eta: 2:48:11  iter: 12619  total_loss: 0.9873  loss_cls: 0.1744  loss_box_reg: 0.2141  loss_mask: 0.2852  loss_rpn_cls: 0.08517  loss_rpn_loc: 0.2132  time: 0.6440  data_time: 0.5008  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:58:39 d2.utils.events]: \u001b[0m eta: 2:46:32  iter: 12639  total_loss: 0.7681  loss_cls: 0.1605  loss_box_reg: 0.2241  loss_mask: 0.1963  loss_rpn_cls: 0.05101  loss_rpn_loc: 0.1818  time: 0.6432  data_time: 0.2636  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:58:52 d2.utils.events]: \u001b[0m eta: 2:45:53  iter: 12659  total_loss: 1.016  loss_cls: 0.1793  loss_box_reg: 0.1877  loss_mask: 0.2866  loss_rpn_cls: 0.06737  loss_rpn_loc: 0.2077  time: 0.6431  data_time: 0.4087  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:59:04 d2.utils.events]: \u001b[0m eta: 2:45:41  iter: 12679  total_loss: 1.027  loss_cls: 0.1804  loss_box_reg: 0.2668  loss_mask: 0.2878  loss_rpn_cls: 0.05936  loss_rpn_loc: 0.1922  time: 0.6430  data_time: 0.4073  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:59:22 d2.utils.events]: \u001b[0m eta: 2:46:16  iter: 12699  total_loss: 1.206  loss_cls: 0.2126  loss_box_reg: 0.329  loss_mask: 0.3013  loss_rpn_cls: 0.09148  loss_rpn_loc: 0.2184  time: 0.6442  data_time: 0.6800  lr: 0.00125  max_mem: 6404M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 11:59:32 d2.utils.events]: \u001b[0m eta: 2:44:40  iter: 12719  total_loss: 0.8799  loss_cls: 0.1471  loss_box_reg: 0.2223  loss_mask: 0.244  loss_rpn_cls: 0.03994  loss_rpn_loc: 0.1898  time: 0.6434  data_time: 0.2630  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:59:46 d2.utils.events]: \u001b[0m eta: 2:44:48  iter: 12739  total_loss: 1.087  loss_cls: 0.2428  loss_box_reg: 0.2503  loss_mask: 0.2627  loss_rpn_cls: 0.09323  loss_rpn_loc: 0.2111  time: 0.6437  data_time: 0.4757  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 11:59:58 d2.utils.events]: \u001b[0m eta: 2:44:43  iter: 12759  total_loss: 0.9833  loss_cls: 0.1858  loss_box_reg: 0.2107  loss_mask: 0.2678  loss_rpn_cls: 0.08707  loss_rpn_loc: 0.2078  time: 0.6436  data_time: 0.4142  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:00:09 d2.utils.events]: \u001b[0m eta: 2:45:25  iter: 12779  total_loss: 0.9042  loss_cls: 0.1751  loss_box_reg: 0.237  loss_mask: 0.228  loss_rpn_cls: 0.06455  loss_rpn_loc: 0.1823  time: 0.6431  data_time: 0.3140  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:00:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 12:00:11 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 12:00:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 12:00:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 12:00:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0006 s/iter. Inference: 0.0438 s/iter. Eval: 0.0148 s/iter. Total: 0.0592 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/30 12:00:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.090178 (0.055182 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:00:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.042899 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:00:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 12:00:15 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06556903375797205\n",
      "\u001b[32m[12/30 12:00:23 d2.utils.events]: \u001b[0m eta: 2:44:19  iter: 12799  total_loss: 0.894  loss_cls: 0.1567  loss_box_reg: 0.2283  loss_mask: 0.2663  loss_rpn_cls: 0.05258  loss_rpn_loc: 0.1941  time: 0.6426  data_time: 0.3152  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:00:37 d2.utils.events]: \u001b[0m eta: 2:45:08  iter: 12819  total_loss: 0.9718  loss_cls: 0.1817  loss_box_reg: 0.2183  loss_mask: 0.2862  loss_rpn_cls: 0.07517  loss_rpn_loc: 0.2081  time: 0.6428  data_time: 0.4860  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:00:47 d2.utils.events]: \u001b[0m eta: 2:45:39  iter: 12839  total_loss: 0.9582  loss_cls: 0.1993  loss_box_reg: 0.2463  loss_mask: 0.2472  loss_rpn_cls: 0.06014  loss_rpn_loc: 0.2014  time: 0.6423  data_time: 0.3116  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:01:00 d2.utils.events]: \u001b[0m eta: 2:44:39  iter: 12859  total_loss: 1.046  loss_cls: 0.1917  loss_box_reg: 0.2543  loss_mask: 0.2603  loss_rpn_cls: 0.06962  loss_rpn_loc: 0.2091  time: 0.6422  data_time: 0.4031  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:01:10 d2.utils.events]: \u001b[0m eta: 2:44:00  iter: 12879  total_loss: 0.9615  loss_cls: 0.1779  loss_box_reg: 0.2253  loss_mask: 0.2554  loss_rpn_cls: 0.03355  loss_rpn_loc: 0.1881  time: 0.6417  data_time: 0.3139  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:01:24 d2.utils.events]: \u001b[0m eta: 2:43:34  iter: 12899  total_loss: 1.042  loss_cls: 0.1907  loss_box_reg: 0.2473  loss_mask: 0.2838  loss_rpn_cls: 0.08346  loss_rpn_loc: 0.1953  time: 0.6418  data_time: 0.4432  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:01:35 d2.utils.events]: \u001b[0m eta: 2:42:25  iter: 12919  total_loss: 1.056  loss_cls: 0.1931  loss_box_reg: 0.2442  loss_mask: 0.2754  loss_rpn_cls: 0.06437  loss_rpn_loc: 0.1979  time: 0.6414  data_time: 0.3478  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:01:48 d2.utils.events]: \u001b[0m eta: 2:43:32  iter: 12939  total_loss: 0.9737  loss_cls: 0.1715  loss_box_reg: 0.1992  loss_mask: 0.2724  loss_rpn_cls: 0.06123  loss_rpn_loc: 0.1991  time: 0.6414  data_time: 0.4270  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:02:04 d2.utils.events]: \u001b[0m eta: 2:43:39  iter: 12959  total_loss: 0.9901  loss_cls: 0.155  loss_box_reg: 0.185  loss_mask: 0.2788  loss_rpn_cls: 0.07128  loss_rpn_loc: 0.1962  time: 0.6422  data_time: 0.6001  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:02:16 d2.utils.events]: \u001b[0m eta: 2:43:31  iter: 12979  total_loss: 0.9395  loss_cls: 0.1663  loss_box_reg: 0.2233  loss_mask: 0.2663  loss_rpn_cls: 0.04944  loss_rpn_loc: 0.1955  time: 0.6421  data_time: 0.3962  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:02:29 d2.utils.events]: \u001b[0m eta: 2:43:39  iter: 12999  total_loss: 0.9807  loss_cls: 0.1823  loss_box_reg: 0.1753  loss_mask: 0.2698  loss_rpn_cls: 0.06851  loss_rpn_loc: 0.2091  time: 0.6420  data_time: 0.4138  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:02:43 d2.utils.events]: \u001b[0m eta: 2:43:56  iter: 13019  total_loss: 0.9981  loss_cls: 0.1833  loss_box_reg: 0.1904  loss_mask: 0.2754  loss_rpn_cls: 0.08103  loss_rpn_loc: 0.1942  time: 0.6422  data_time: 0.4639  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:02:57 d2.utils.events]: \u001b[0m eta: 2:43:17  iter: 13039  total_loss: 1.088  loss_cls: 0.1778  loss_box_reg: 0.276  loss_mask: 0.2996  loss_rpn_cls: 0.05983  loss_rpn_loc: 0.1896  time: 0.6425  data_time: 0.5109  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:03:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 12:03:08 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 12:03:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 12:03:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 12:03:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0449 s/iter. Eval: 0.0166 s/iter. Total: 0.0622 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 12:03:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.237642 (0.057815 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:03:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043367 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:03:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 12:03:12 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07249161267739594\n",
      "\u001b[32m[12/30 12:03:14 d2.utils.events]: \u001b[0m eta: 2:43:10  iter: 13059  total_loss: 1.001  loss_cls: 0.1929  loss_box_reg: 0.2405  loss_mask: 0.2565  loss_rpn_cls: 0.06513  loss_rpn_loc: 0.199  time: 0.6425  data_time: 0.4306  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:03:24 d2.utils.events]: \u001b[0m eta: 2:43:05  iter: 13079  total_loss: 0.8349  loss_cls: 0.1615  loss_box_reg: 0.2094  loss_mask: 0.265  loss_rpn_cls: 0.0369  loss_rpn_loc: 0.1814  time: 0.6420  data_time: 0.3062  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:03:37 d2.utils.events]: \u001b[0m eta: 2:43:23  iter: 13099  total_loss: 0.9623  loss_cls: 0.1626  loss_box_reg: 0.2055  loss_mask: 0.2465  loss_rpn_cls: 0.06167  loss_rpn_loc: 0.1979  time: 0.6421  data_time: 0.4437  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:03:51 d2.utils.events]: \u001b[0m eta: 2:42:52  iter: 13119  total_loss: 1  loss_cls: 0.1868  loss_box_reg: 0.2147  loss_mask: 0.2759  loss_rpn_cls: 0.06061  loss_rpn_loc: 0.1937  time: 0.6423  data_time: 0.4818  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:04:09 d2.utils.events]: \u001b[0m eta: 2:43:12  iter: 13139  total_loss: 1.123  loss_cls: 0.2006  loss_box_reg: 0.2332  loss_mask: 0.2834  loss_rpn_cls: 0.1114  loss_rpn_loc: 0.2171  time: 0.6433  data_time: 0.6631  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:04:24 d2.utils.events]: \u001b[0m eta: 2:45:02  iter: 13159  total_loss: 1.045  loss_cls: 0.2065  loss_box_reg: 0.2802  loss_mask: 0.3003  loss_rpn_cls: 0.08126  loss_rpn_loc: 0.2029  time: 0.6437  data_time: 0.5137  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:04:29 d2.utils.events]: \u001b[0m eta: 2:42:36  iter: 13179  total_loss: 0.2435  loss_cls: 0.0001571  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03372  loss_rpn_loc: 0.1703  time: 0.6422  data_time: 0.0884  lr: 0.00125  max_mem: 6404M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 12:04:42 d2.utils.events]: \u001b[0m eta: 2:42:09  iter: 13199  total_loss: 1.045  loss_cls: 0.1806  loss_box_reg: 0.2644  loss_mask: 0.2777  loss_rpn_cls: 0.06346  loss_rpn_loc: 0.1919  time: 0.6421  data_time: 0.3869  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:04:56 d2.utils.events]: \u001b[0m eta: 2:42:04  iter: 13219  total_loss: 1.086  loss_cls: 0.2278  loss_box_reg: 0.2729  loss_mask: 0.2864  loss_rpn_cls: 0.0862  loss_rpn_loc: 0.1912  time: 0.6423  data_time: 0.4879  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:05:11 d2.utils.events]: \u001b[0m eta: 2:41:16  iter: 13239  total_loss: 1.026  loss_cls: 0.1876  loss_box_reg: 0.2307  loss_mask: 0.2604  loss_rpn_cls: 0.07407  loss_rpn_loc: 0.2039  time: 0.6428  data_time: 0.5440  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:05:19 d2.utils.events]: \u001b[0m eta: 2:39:05  iter: 13259  total_loss: 0.9509  loss_cls: 0.1713  loss_box_reg: 0.2215  loss_mask: 0.2536  loss_rpn_cls: 0.05285  loss_rpn_loc: 0.1907  time: 0.6419  data_time: 0.2009  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:05:31 d2.utils.events]: \u001b[0m eta: 2:37:58  iter: 13279  total_loss: 0.9561  loss_cls: 0.1541  loss_box_reg: 0.1987  loss_mask: 0.2715  loss_rpn_cls: 0.07938  loss_rpn_loc: 0.2106  time: 0.6417  data_time: 0.3797  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:05:43 d2.utils.events]: \u001b[0m eta: 2:40:25  iter: 13299  total_loss: 1.005  loss_cls: 0.1811  loss_box_reg: 0.1778  loss_mask: 0.275  loss_rpn_cls: 0.0697  loss_rpn_loc: 0.2108  time: 0.6416  data_time: 0.3972  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:05:52 d2.utils.events]: \u001b[0m eta: 2:39:10  iter: 13319  total_loss: 0.6637  loss_cls: 0.08127  loss_box_reg: 0.1204  loss_mask: 0.2022  loss_rpn_cls: 0.04554  loss_rpn_loc: 0.1963  time: 0.6408  data_time: 0.2557  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:05:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 12:05:57 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 12:05:57 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 12:05:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 12:05:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0442 s/iter. Eval: 0.0155 s/iter. Total: 0.0604 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 12:06:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.171615 (0.056636 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:06:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043141 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:06:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 12:06:00 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06843502128291784\n",
      "\u001b[32m[12/30 12:06:07 d2.utils.events]: \u001b[0m eta: 2:40:03  iter: 13339  total_loss: 0.9832  loss_cls: 0.1748  loss_box_reg: 0.257  loss_mask: 0.2689  loss_rpn_cls: 0.05562  loss_rpn_loc: 0.1788  time: 0.6405  data_time: 0.3379  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:06:24 d2.utils.events]: \u001b[0m eta: 2:40:24  iter: 13359  total_loss: 1.081  loss_cls: 0.1884  loss_box_reg: 0.2348  loss_mask: 0.2604  loss_rpn_cls: 0.06541  loss_rpn_loc: 0.1917  time: 0.6412  data_time: 0.6059  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:06:31 d2.utils.events]: \u001b[0m eta: 2:38:46  iter: 13379  total_loss: 0.8527  loss_cls: 0.1624  loss_box_reg: 0.2129  loss_mask: 0.2163  loss_rpn_cls: 0.04563  loss_rpn_loc: 0.1874  time: 0.6401  data_time: 0.1477  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:06:47 d2.utils.events]: \u001b[0m eta: 2:38:41  iter: 13399  total_loss: 0.9875  loss_cls: 0.1799  loss_box_reg: 0.239  loss_mask: 0.2813  loss_rpn_cls: 0.08166  loss_rpn_loc: 0.2061  time: 0.6408  data_time: 0.6171  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:07:04 d2.utils.events]: \u001b[0m eta: 2:38:44  iter: 13419  total_loss: 1.042  loss_cls: 0.2032  loss_box_reg: 0.225  loss_mask: 0.2907  loss_rpn_cls: 0.07034  loss_rpn_loc: 0.1902  time: 0.6415  data_time: 0.6031  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:07:17 d2.utils.events]: \u001b[0m eta: 2:38:23  iter: 13439  total_loss: 0.9709  loss_cls: 0.1628  loss_box_reg: 0.2374  loss_mask: 0.2781  loss_rpn_cls: 0.06872  loss_rpn_loc: 0.2056  time: 0.6416  data_time: 0.4378  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:07:31 d2.utils.events]: \u001b[0m eta: 2:38:33  iter: 13459  total_loss: 1.131  loss_cls: 0.2193  loss_box_reg: 0.309  loss_mask: 0.2829  loss_rpn_cls: 0.08178  loss_rpn_loc: 0.1974  time: 0.6418  data_time: 0.4740  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:07:40 d2.utils.events]: \u001b[0m eta: 2:38:26  iter: 13479  total_loss: 0.6917  loss_cls: 0.1255  loss_box_reg: 0.2184  loss_mask: 0.2125  loss_rpn_cls: 0.04742  loss_rpn_loc: 0.1834  time: 0.6411  data_time: 0.2484  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:07:56 d2.utils.events]: \u001b[0m eta: 2:38:21  iter: 13499  total_loss: 1.126  loss_cls: 0.1815  loss_box_reg: 0.242  loss_mask: 0.2691  loss_rpn_cls: 0.09283  loss_rpn_loc: 0.1939  time: 0.6417  data_time: 0.5648  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:08:08 d2.utils.events]: \u001b[0m eta: 2:38:02  iter: 13519  total_loss: 0.8688  loss_cls: 0.1791  loss_box_reg: 0.2166  loss_mask: 0.249  loss_rpn_cls: 0.0581  loss_rpn_loc: 0.1907  time: 0.6414  data_time: 0.3540  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:08:19 d2.utils.events]: \u001b[0m eta: 2:36:38  iter: 13539  total_loss: 1.097  loss_cls: 0.2261  loss_box_reg: 0.2607  loss_mask: 0.2918  loss_rpn_cls: 0.08216  loss_rpn_loc: 0.1843  time: 0.6412  data_time: 0.3771  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:08:30 d2.utils.events]: \u001b[0m eta: 2:36:11  iter: 13559  total_loss: 0.9039  loss_cls: 0.1535  loss_box_reg: 0.217  loss_mask: 0.2392  loss_rpn_cls: 0.04774  loss_rpn_loc: 0.1865  time: 0.6408  data_time: 0.3268  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:08:44 d2.utils.events]: \u001b[0m eta: 2:36:41  iter: 13579  total_loss: 1.042  loss_cls: 0.1947  loss_box_reg: 0.2672  loss_mask: 0.2587  loss_rpn_cls: 0.08058  loss_rpn_loc: 0.2284  time: 0.6410  data_time: 0.4735  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:08:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 12:08:56 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 12:08:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 12:08:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 12:08:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0446 s/iter. Eval: 0.0154 s/iter. Total: 0.0607 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 12:08:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.140778 (0.056085 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:08:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043007 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:08:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 12:08:59 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06218086840397261\n",
      "\u001b[32m[12/30 12:08:59 d2.utils.events]: \u001b[0m eta: 2:36:01  iter: 13599  total_loss: 0.8601  loss_cls: 0.1565  loss_box_reg: 0.2229  loss_mask: 0.2484  loss_rpn_cls: 0.04442  loss_rpn_loc: 0.1794  time: 0.6408  data_time: 0.3757  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:09:15 d2.utils.events]: \u001b[0m eta: 2:36:19  iter: 13619  total_loss: 1.045  loss_cls: 0.1983  loss_box_reg: 0.267  loss_mask: 0.3025  loss_rpn_cls: 0.08802  loss_rpn_loc: 0.2171  time: 0.6414  data_time: 0.5608  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:09:29 d2.utils.events]: \u001b[0m eta: 2:37:44  iter: 13639  total_loss: 1.076  loss_cls: 0.1845  loss_box_reg: 0.2101  loss_mask: 0.289  loss_rpn_cls: 0.07884  loss_rpn_loc: 0.2038  time: 0.6415  data_time: 0.4612  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:09:41 d2.utils.events]: \u001b[0m eta: 2:37:35  iter: 13659  total_loss: 0.9609  loss_cls: 0.165  loss_box_reg: 0.2273  loss_mask: 0.2327  loss_rpn_cls: 0.06204  loss_rpn_loc: 0.1915  time: 0.6413  data_time: 0.3670  lr: 0.00125  max_mem: 6404M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 12:09:53 d2.utils.events]: \u001b[0m eta: 2:36:15  iter: 13679  total_loss: 0.5157  loss_cls: 0.07796  loss_box_reg: 0.08655  loss_mask: 0.1234  loss_rpn_cls: 0.0469  loss_rpn_loc: 0.1963  time: 0.6412  data_time: 0.3983  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:10:01 d2.utils.events]: \u001b[0m eta: 2:34:49  iter: 13699  total_loss: 0.8986  loss_cls: 0.1683  loss_box_reg: 0.2133  loss_mask: 0.2483  loss_rpn_cls: 0.06137  loss_rpn_loc: 0.1793  time: 0.6403  data_time: 0.1956  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:10:11 d2.utils.events]: \u001b[0m eta: 2:36:05  iter: 13719  total_loss: 0.9982  loss_cls: 0.1793  loss_box_reg: 0.2379  loss_mask: 0.2631  loss_rpn_cls: 0.06762  loss_rpn_loc: 0.1868  time: 0.6398  data_time: 0.2929  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:10:25 d2.utils.events]: \u001b[0m eta: 2:36:00  iter: 13739  total_loss: 1.036  loss_cls: 0.1936  loss_box_reg: 0.2437  loss_mask: 0.2718  loss_rpn_cls: 0.06523  loss_rpn_loc: 0.1967  time: 0.6401  data_time: 0.4905  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:10:36 d2.utils.events]: \u001b[0m eta: 2:35:04  iter: 13759  total_loss: 0.9922  loss_cls: 0.1896  loss_box_reg: 0.2698  loss_mask: 0.2843  loss_rpn_cls: 0.04517  loss_rpn_loc: 0.1751  time: 0.6398  data_time: 0.3374  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:12:47 d2.utils.events]: \u001b[0m eta: 2:37:24  iter: 13959  total_loss: 0.9291  loss_cls: 0.1632  loss_box_reg: 0.213  loss_mask: 0.2759  loss_rpn_cls: 0.06096  loss_rpn_loc: 0.2154  time: 0.6396  data_time: 0.4245  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:13:00 d2.utils.events]: \u001b[0m eta: 2:38:31  iter: 13979  total_loss: 1.205  loss_cls: 0.2573  loss_box_reg: 0.3176  loss_mask: 0.2813  loss_rpn_cls: 0.08932  loss_rpn_loc: 0.2263  time: 0.6396  data_time: 0.4455  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:13:12 d2.utils.events]: \u001b[0m eta: 2:36:17  iter: 13999  total_loss: 0.7941  loss_cls: 0.1401  loss_box_reg: 0.1897  loss_mask: 0.2263  loss_rpn_cls: 0.04434  loss_rpn_loc: 0.1633  time: 0.6395  data_time: 0.3778  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:13:22 d2.utils.events]: \u001b[0m eta: 2:36:07  iter: 14019  total_loss: 0.9228  loss_cls: 0.1612  loss_box_reg: 0.2438  loss_mask: 0.2568  loss_rpn_cls: 0.04067  loss_rpn_loc: 0.1729  time: 0.6389  data_time: 0.2786  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:13:37 d2.utils.events]: \u001b[0m eta: 2:36:36  iter: 14039  total_loss: 1.003  loss_cls: 0.1816  loss_box_reg: 0.2173  loss_mask: 0.2743  loss_rpn_cls: 0.07518  loss_rpn_loc: 0.2012  time: 0.6393  data_time: 0.5230  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:13:50 d2.utils.events]: \u001b[0m eta: 2:35:58  iter: 14059  total_loss: 0.8784  loss_cls: 0.1743  loss_box_reg: 0.2068  loss_mask: 0.2661  loss_rpn_cls: 0.05659  loss_rpn_loc: 0.1877  time: 0.6393  data_time: 0.4344  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:14:00 d2.utils.events]: \u001b[0m eta: 2:35:53  iter: 14079  total_loss: 0.9235  loss_cls: 0.166  loss_box_reg: 0.2121  loss_mask: 0.2441  loss_rpn_cls: 0.05406  loss_rpn_loc: 0.1882  time: 0.6389  data_time: 0.3112  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:14:14 d2.utils.events]: \u001b[0m eta: 2:35:51  iter: 14099  total_loss: 0.9434  loss_cls: 0.1772  loss_box_reg: 0.224  loss_mask: 0.27  loss_rpn_cls: 0.07786  loss_rpn_loc: 0.1904  time: 0.6391  data_time: 0.4843  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:14:27 d2.utils.events]: \u001b[0m eta: 2:36:55  iter: 14119  total_loss: 0.9417  loss_cls: 0.173  loss_box_reg: 0.2371  loss_mask: 0.2561  loss_rpn_cls: 0.0689  loss_rpn_loc: 0.1961  time: 0.6390  data_time: 0.4218  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:14:39 d2.utils.events]: \u001b[0m eta: 2:35:34  iter: 14139  total_loss: 0.9823  loss_cls: 0.1783  loss_box_reg: 0.191  loss_mask: 0.2468  loss_rpn_cls: 0.06597  loss_rpn_loc: 0.1775  time: 0.6390  data_time: 0.4339  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:14:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 12:14:44 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 12:14:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 12:14:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 12:14:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0439 s/iter. Eval: 0.0149 s/iter. Total: 0.0595 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/30 12:14:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.150910 (0.056266 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:14:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043156 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:14:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 12:14:47 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06779996468199787\n",
      "\u001b[32m[12/30 12:14:58 d2.utils.events]: \u001b[0m eta: 2:35:25  iter: 14159  total_loss: 0.9901  loss_cls: 0.1868  loss_box_reg: 0.2516  loss_mask: 0.2884  loss_rpn_cls: 0.07301  loss_rpn_loc: 0.2124  time: 0.6394  data_time: 0.5168  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:15:12 d2.utils.events]: \u001b[0m eta: 2:37:24  iter: 14179  total_loss: 1.022  loss_cls: 0.1721  loss_box_reg: 0.2054  loss_mask: 0.2994  loss_rpn_cls: 0.06073  loss_rpn_loc: 0.1955  time: 0.6397  data_time: 0.5045  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:15:25 d2.utils.events]: \u001b[0m eta: 2:38:57  iter: 14199  total_loss: 1.026  loss_cls: 0.1883  loss_box_reg: 0.2172  loss_mask: 0.2568  loss_rpn_cls: 0.08911  loss_rpn_loc: 0.204  time: 0.6396  data_time: 0.4078  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:15:40 d2.utils.events]: \u001b[0m eta: 2:37:48  iter: 14219  total_loss: 0.9881  loss_cls: 0.1878  loss_box_reg: 0.218  loss_mask: 0.2723  loss_rpn_cls: 0.0639  loss_rpn_loc: 0.2048  time: 0.6400  data_time: 0.5555  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:15:52 d2.utils.events]: \u001b[0m eta: 2:37:08  iter: 14239  total_loss: 1.001  loss_cls: 0.1988  loss_box_reg: 0.2498  loss_mask: 0.262  loss_rpn_cls: 0.05477  loss_rpn_loc: 0.1797  time: 0.6399  data_time: 0.3794  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:16:05 d2.utils.events]: \u001b[0m eta: 2:39:12  iter: 14259  total_loss: 1.033  loss_cls: 0.1932  loss_box_reg: 0.2254  loss_mask: 0.2847  loss_rpn_cls: 0.07188  loss_rpn_loc: 0.2151  time: 0.6399  data_time: 0.4339  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:16:17 d2.utils.events]: \u001b[0m eta: 2:39:07  iter: 14279  total_loss: 1.07  loss_cls: 0.1961  loss_box_reg: 0.1929  loss_mask: 0.3067  loss_rpn_cls: 0.0845  loss_rpn_loc: 0.2117  time: 0.6398  data_time: 0.3873  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:16:29 d2.utils.events]: \u001b[0m eta: 2:37:33  iter: 14299  total_loss: 1.033  loss_cls: 0.2146  loss_box_reg: 0.2625  loss_mask: 0.279  loss_rpn_cls: 0.07036  loss_rpn_loc: 0.2044  time: 0.6396  data_time: 0.3681  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:16:41 d2.utils.events]: \u001b[0m eta: 2:37:45  iter: 14319  total_loss: 0.838  loss_cls: 0.1418  loss_box_reg: 0.2384  loss_mask: 0.2455  loss_rpn_cls: 0.04269  loss_rpn_loc: 0.1895  time: 0.6396  data_time: 0.4039  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:16:52 d2.utils.events]: \u001b[0m eta: 2:37:22  iter: 14339  total_loss: 0.9691  loss_cls: 0.1826  loss_box_reg: 0.2326  loss_mask: 0.2508  loss_rpn_cls: 0.05173  loss_rpn_loc: 0.1774  time: 0.6393  data_time: 0.3409  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:17:03 d2.utils.events]: \u001b[0m eta: 2:37:17  iter: 14359  total_loss: 0.9993  loss_cls: 0.2086  loss_box_reg: 0.2712  loss_mask: 0.2638  loss_rpn_cls: 0.04207  loss_rpn_loc: 0.1837  time: 0.6389  data_time: 0.3087  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:17:17 d2.utils.events]: \u001b[0m eta: 2:38:09  iter: 14379  total_loss: 0.9547  loss_cls: 0.1813  loss_box_reg: 0.2293  loss_mask: 0.262  loss_rpn_cls: 0.04272  loss_rpn_loc: 0.1762  time: 0.6392  data_time: 0.5150  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:17:29 d2.utils.events]: \u001b[0m eta: 2:37:06  iter: 14399  total_loss: 0.654  loss_cls: 0.1228  loss_box_reg: 0.142  loss_mask: 0.2281  loss_rpn_cls: 0.05654  loss_rpn_loc: 0.217  time: 0.6389  data_time: 0.3394  lr: 0.00125  max_mem: 6404M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 12:17:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 12:17:38 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 12:17:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 12:17:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 12:17:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0441 s/iter. Eval: 0.0174 s/iter. Total: 0.0623 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 12:17:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.192853 (0.057015 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:17:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043063 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:17:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 12:17:42 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06743978979175702\n",
      "\u001b[32m[12/30 12:17:43 d2.utils.events]: \u001b[0m eta: 2:34:59  iter: 14419  total_loss: 0.8805  loss_cls: 0.1618  loss_box_reg: 0.1916  loss_mask: 0.2593  loss_rpn_cls: 0.04293  loss_rpn_loc: 0.2124  time: 0.6385  data_time: 0.3265  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:17:55 d2.utils.events]: \u001b[0m eta: 2:34:28  iter: 14439  total_loss: 0.9609  loss_cls: 0.1456  loss_box_reg: 0.177  loss_mask: 0.2748  loss_rpn_cls: 0.06846  loss_rpn_loc: 0.197  time: 0.6385  data_time: 0.4079  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:18:11 d2.utils.events]: \u001b[0m eta: 2:34:23  iter: 14459  total_loss: 1.032  loss_cls: 0.192  loss_box_reg: 0.2132  loss_mask: 0.2685  loss_rpn_cls: 0.06997  loss_rpn_loc: 0.186  time: 0.6389  data_time: 0.5348  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:18:23 d2.utils.events]: \u001b[0m eta: 2:34:43  iter: 14479  total_loss: 0.7837  loss_cls: 0.1354  loss_box_reg: 0.2085  loss_mask: 0.2373  loss_rpn_cls: 0.04401  loss_rpn_loc: 0.1601  time: 0.6388  data_time: 0.4018  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:18:40 d2.utils.events]: \u001b[0m eta: 2:34:38  iter: 14499  total_loss: 0.9858  loss_cls: 0.195  loss_box_reg: 0.1977  loss_mask: 0.2596  loss_rpn_cls: 0.07731  loss_rpn_loc: 0.2119  time: 0.6394  data_time: 0.6379  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:18:53 d2.utils.events]: \u001b[0m eta: 2:36:28  iter: 14519  total_loss: 0.9878  loss_cls: 0.1859  loss_box_reg: 0.2346  loss_mask: 0.2682  loss_rpn_cls: 0.0778  loss_rpn_loc: 0.2068  time: 0.6394  data_time: 0.4152  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:19:05 d2.utils.events]: \u001b[0m eta: 2:35:05  iter: 14539  total_loss: 0.9354  loss_cls: 0.1598  loss_box_reg: 0.2304  loss_mask: 0.2624  loss_rpn_cls: 0.04892  loss_rpn_loc: 0.1716  time: 0.6393  data_time: 0.4009  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:19:22 d2.utils.events]: \u001b[0m eta: 2:36:18  iter: 14559  total_loss: 1.031  loss_cls: 0.1972  loss_box_reg: 0.255  loss_mask: 0.286  loss_rpn_cls: 0.07632  loss_rpn_loc: 0.2025  time: 0.6400  data_time: 0.6384  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:19:35 d2.utils.events]: \u001b[0m eta: 2:36:19  iter: 14579  total_loss: 0.9942  loss_cls: 0.1976  loss_box_reg: 0.2824  loss_mask: 0.2615  loss_rpn_cls: 0.05628  loss_rpn_loc: 0.1865  time: 0.6400  data_time: 0.4125  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:19:46 d2.utils.events]: \u001b[0m eta: 2:37:41  iter: 14599  total_loss: 1.042  loss_cls: 0.2067  loss_box_reg: 0.2442  loss_mask: 0.2499  loss_rpn_cls: 0.06881  loss_rpn_loc: 0.2087  time: 0.6398  data_time: 0.3818  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:19:58 d2.utils.events]: \u001b[0m eta: 2:37:47  iter: 14619  total_loss: 1.112  loss_cls: 0.2549  loss_box_reg: 0.28  loss_mask: 0.2643  loss_rpn_cls: 0.07842  loss_rpn_loc: 0.1888  time: 0.6396  data_time: 0.3546  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:20:13 d2.utils.events]: \u001b[0m eta: 2:36:15  iter: 14639  total_loss: 0.9819  loss_cls: 0.1672  loss_box_reg: 0.2032  loss_mask: 0.2832  loss_rpn_cls: 0.04553  loss_rpn_loc: 0.179  time: 0.6399  data_time: 0.5207  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:20:26 d2.utils.events]: \u001b[0m eta: 2:37:36  iter: 14659  total_loss: 0.9837  loss_cls: 0.1922  loss_box_reg: 0.2481  loss_mask: 0.2588  loss_rpn_cls: 0.06359  loss_rpn_loc: 0.1956  time: 0.6400  data_time: 0.4379  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:20:38 d2.utils.events]: \u001b[0m eta: 2:39:08  iter: 14679  total_loss: 0.9262  loss_cls: 0.1819  loss_box_reg: 0.2163  loss_mask: 0.2528  loss_rpn_cls: 0.04697  loss_rpn_loc: 0.1879  time: 0.6399  data_time: 0.4033  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:20:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 12:20:45 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 12:20:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 12:20:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 12:20:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0447 s/iter. Eval: 0.0175 s/iter. Total: 0.0629 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 12:20:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.220627 (0.057511 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:20:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043315 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:20:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 12:20:49 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06898381713209559\n",
      "\u001b[32m[12/30 12:20:57 d2.utils.events]: \u001b[0m eta: 2:40:26  iter: 14699  total_loss: 1.039  loss_cls: 0.1684  loss_box_reg: 0.2244  loss_mask: 0.2723  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.2198  time: 0.6402  data_time: 0.5267  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:21:11 d2.utils.events]: \u001b[0m eta: 2:40:11  iter: 14719  total_loss: 1.004  loss_cls: 0.184  loss_box_reg: 0.2389  loss_mask: 0.2575  loss_rpn_cls: 0.04961  loss_rpn_loc: 0.1933  time: 0.6404  data_time: 0.4705  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:21:20 d2.utils.events]: \u001b[0m eta: 2:38:52  iter: 14739  total_loss: 0.7029  loss_cls: 0.1152  loss_box_reg: 0.1887  loss_mask: 0.2107  loss_rpn_cls: 0.04723  loss_rpn_loc: 0.1858  time: 0.6398  data_time: 0.2523  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:21:33 d2.utils.events]: \u001b[0m eta: 2:38:59  iter: 14759  total_loss: 0.9108  loss_cls: 0.174  loss_box_reg: 0.1984  loss_mask: 0.2164  loss_rpn_cls: 0.06304  loss_rpn_loc: 0.1986  time: 0.6398  data_time: 0.4102  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:21:43 d2.utils.events]: \u001b[0m eta: 2:38:26  iter: 14779  total_loss: 0.9271  loss_cls: 0.1777  loss_box_reg: 0.2193  loss_mask: 0.2327  loss_rpn_cls: 0.05706  loss_rpn_loc: 0.1708  time: 0.6395  data_time: 0.3235  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:21:58 d2.utils.events]: \u001b[0m eta: 2:39:23  iter: 14799  total_loss: 0.9752  loss_cls: 0.1759  loss_box_reg: 0.2353  loss_mask: 0.271  loss_rpn_cls: 0.06406  loss_rpn_loc: 0.1858  time: 0.6398  data_time: 0.5370  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:22:14 d2.utils.events]: \u001b[0m eta: 2:39:44  iter: 14819  total_loss: 0.9564  loss_cls: 0.1734  loss_box_reg: 0.2033  loss_mask: 0.2683  loss_rpn_cls: 0.06445  loss_rpn_loc: 0.1832  time: 0.6403  data_time: 0.5717  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:22:28 d2.utils.events]: \u001b[0m eta: 2:39:39  iter: 14839  total_loss: 0.9488  loss_cls: 0.1648  loss_box_reg: 0.2174  loss_mask: 0.2673  loss_rpn_cls: 0.0622  loss_rpn_loc: 0.1999  time: 0.6404  data_time: 0.4742  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:22:43 d2.utils.events]: \u001b[0m eta: 2:39:33  iter: 14859  total_loss: 1.083  loss_cls: 0.214  loss_box_reg: 0.2804  loss_mask: 0.2861  loss_rpn_cls: 0.08417  loss_rpn_loc: 0.1952  time: 0.6408  data_time: 0.5288  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:22:53 d2.utils.events]: \u001b[0m eta: 2:39:37  iter: 14879  total_loss: 0.9163  loss_cls: 0.1755  loss_box_reg: 0.2238  loss_mask: 0.2598  loss_rpn_cls: 0.05466  loss_rpn_loc: 0.185  time: 0.6403  data_time: 0.2744  lr: 0.00125  max_mem: 6404M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 12:23:06 d2.utils.events]: \u001b[0m eta: 2:37:54  iter: 14899  total_loss: 0.9519  loss_cls: 0.1531  loss_box_reg: 0.1754  loss_mask: 0.2616  loss_rpn_cls: 0.06544  loss_rpn_loc: 0.2126  time: 0.6404  data_time: 0.4719  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:23:19 d2.utils.events]: \u001b[0m eta: 2:39:26  iter: 14919  total_loss: 1.014  loss_cls: 0.2025  loss_box_reg: 0.2575  loss_mask: 0.2692  loss_rpn_cls: 0.07783  loss_rpn_loc: 0.2031  time: 0.6404  data_time: 0.4252  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:23:33 d2.utils.events]: \u001b[0m eta: 2:39:11  iter: 14939  total_loss: 1.008  loss_cls: 0.2053  loss_box_reg: 0.212  loss_mask: 0.2359  loss_rpn_cls: 0.0722  loss_rpn_loc: 0.1833  time: 0.6405  data_time: 0.4586  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:23:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 12:23:44 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 12:23:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 12:23:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 12:23:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0440 s/iter. Eval: 0.0143 s/iter. Total: 0.0590 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/30 12:23:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.129342 (0.055881 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:23:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043079 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:23:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 12:23:48 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06294029345026707\n",
      "\u001b[32m[12/30 12:23:48 d2.utils.events]: \u001b[0m eta: 2:38:03  iter: 14959  total_loss: 0.9633  loss_cls: 0.1697  loss_box_reg: 0.1852  loss_mask: 0.2365  loss_rpn_cls: 0.05963  loss_rpn_loc: 0.1926  time: 0.6403  data_time: 0.3744  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:23:57 d2.utils.events]: \u001b[0m eta: 2:37:32  iter: 14979  total_loss: 0.9532  loss_cls: 0.2065  loss_box_reg: 0.2343  loss_mask: 0.2565  loss_rpn_cls: 0.07613  loss_rpn_loc: 0.1946  time: 0.6398  data_time: 0.2506  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:24:11 d2.utils.events]: \u001b[0m eta: 2:39:21  iter: 14999  total_loss: 1.046  loss_cls: 0.2052  loss_box_reg: 0.2571  loss_mask: 0.2691  loss_rpn_cls: 0.08528  loss_rpn_loc: 0.2052  time: 0.6400  data_time: 0.4702  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:24:23 d2.utils.events]: \u001b[0m eta: 2:39:39  iter: 15019  total_loss: 0.8131  loss_cls: 0.1513  loss_box_reg: 0.2071  loss_mask: 0.2551  loss_rpn_cls: 0.04152  loss_rpn_loc: 0.1631  time: 0.6398  data_time: 0.3784  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:24:37 d2.utils.events]: \u001b[0m eta: 2:37:41  iter: 15039  total_loss: 0.8063  loss_cls: 0.1481  loss_box_reg: 0.199  loss_mask: 0.2057  loss_rpn_cls: 0.04441  loss_rpn_loc: 0.1759  time: 0.6399  data_time: 0.4428  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:24:46 d2.utils.events]: \u001b[0m eta: 2:36:15  iter: 15059  total_loss: 0.8817  loss_cls: 0.1477  loss_box_reg: 0.19  loss_mask: 0.2437  loss_rpn_cls: 0.04025  loss_rpn_loc: 0.1802  time: 0.6394  data_time: 0.2825  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:24:59 d2.utils.events]: \u001b[0m eta: 2:36:51  iter: 15079  total_loss: 0.9364  loss_cls: 0.1305  loss_box_reg: 0.1777  loss_mask: 0.2879  loss_rpn_cls: 0.03989  loss_rpn_loc: 0.2011  time: 0.6394  data_time: 0.4134  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:25:14 d2.utils.events]: \u001b[0m eta: 2:36:33  iter: 15099  total_loss: 0.9118  loss_cls: 0.1674  loss_box_reg: 0.1981  loss_mask: 0.2697  loss_rpn_cls: 0.07418  loss_rpn_loc: 0.186  time: 0.6397  data_time: 0.5207  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:25:29 d2.utils.events]: \u001b[0m eta: 2:37:56  iter: 15119  total_loss: 1.039  loss_cls: 0.1876  loss_box_reg: 0.2141  loss_mask: 0.2758  loss_rpn_cls: 0.07718  loss_rpn_loc: 0.2082  time: 0.6400  data_time: 0.5188  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:25:42 d2.utils.events]: \u001b[0m eta: 2:38:17  iter: 15139  total_loss: 0.9008  loss_cls: 0.1706  loss_box_reg: 0.2048  loss_mask: 0.2591  loss_rpn_cls: 0.06371  loss_rpn_loc: 0.2019  time: 0.6400  data_time: 0.4413  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:25:55 d2.utils.events]: \u001b[0m eta: 2:38:37  iter: 15159  total_loss: 0.9756  loss_cls: 0.1815  loss_box_reg: 0.2396  loss_mask: 0.2672  loss_rpn_cls: 0.05082  loss_rpn_loc: 0.2025  time: 0.6400  data_time: 0.4324  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:26:10 d2.utils.events]: \u001b[0m eta: 2:38:17  iter: 15179  total_loss: 1.009  loss_cls: 0.1677  loss_box_reg: 0.239  loss_mask: 0.2788  loss_rpn_cls: 0.05686  loss_rpn_loc: 0.1904  time: 0.6404  data_time: 0.5441  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:26:22 d2.utils.events]: \u001b[0m eta: 2:36:19  iter: 15199  total_loss: 0.8699  loss_cls: 0.1594  loss_box_reg: 0.2366  loss_mask: 0.2634  loss_rpn_cls: 0.04364  loss_rpn_loc: 0.1672  time: 0.6403  data_time: 0.3878  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:26:33 d2.utils.events]: \u001b[0m eta: 2:36:40  iter: 15219  total_loss: 0.905  loss_cls: 0.1768  loss_box_reg: 0.2111  loss_mask: 0.2645  loss_rpn_cls: 0.0512  loss_rpn_loc: 0.1917  time: 0.6400  data_time: 0.3451  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:26:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 12:26:36 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 12:26:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 12:26:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 12:26:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0451 s/iter. Eval: 0.0173 s/iter. Total: 0.0631 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 12:26:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.252992 (0.058089 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:26:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043493 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:26:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 12:26:40 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0688802604288823\n",
      "\u001b[32m[12/30 12:26:45 d2.utils.events]: \u001b[0m eta: 2:35:56  iter: 15239  total_loss: 0.7616  loss_cls: 0.1368  loss_box_reg: 0.1904  loss_mask: 0.2228  loss_rpn_cls: 0.0568  loss_rpn_loc: 0.1749  time: 0.6394  data_time: 0.2151  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:26:53 d2.utils.events]: \u001b[0m eta: 2:33:29  iter: 15259  total_loss: 0.4659  loss_cls: 0.06619  loss_box_reg: 0.07535  loss_mask: 0.08686  loss_rpn_cls: 0.03912  loss_rpn_loc: 0.1968  time: 0.6388  data_time: 0.2268  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:27:07 d2.utils.events]: \u001b[0m eta: 2:33:04  iter: 15279  total_loss: 1.032  loss_cls: 0.1748  loss_box_reg: 0.2475  loss_mask: 0.2892  loss_rpn_cls: 0.05923  loss_rpn_loc: 0.1985  time: 0.6389  data_time: 0.4700  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:27:21 d2.utils.events]: \u001b[0m eta: 2:35:04  iter: 15299  total_loss: 1.069  loss_cls: 0.2  loss_box_reg: 0.2466  loss_mask: 0.2975  loss_rpn_cls: 0.06761  loss_rpn_loc: 0.2008  time: 0.6391  data_time: 0.4672  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:27:40 d2.utils.events]: \u001b[0m eta: 2:36:01  iter: 15319  total_loss: 1.081  loss_cls: 0.1934  loss_box_reg: 0.2373  loss_mask: 0.2993  loss_rpn_cls: 0.1055  loss_rpn_loc: 0.2062  time: 0.6399  data_time: 0.7038  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:27:49 d2.utils.events]: \u001b[0m eta: 2:35:41  iter: 15339  total_loss: 0.8619  loss_cls: 0.1604  loss_box_reg: 0.2105  loss_mask: 0.2547  loss_rpn_cls: 0.03965  loss_rpn_loc: 0.1981  time: 0.6394  data_time: 0.2680  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:28:03 d2.utils.events]: \u001b[0m eta: 2:36:50  iter: 15359  total_loss: 1.067  loss_cls: 0.1872  loss_box_reg: 0.2371  loss_mask: 0.3113  loss_rpn_cls: 0.08912  loss_rpn_loc: 0.2137  time: 0.6396  data_time: 0.4849  lr: 0.00125  max_mem: 6404M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 12:28:14 d2.utils.events]: \u001b[0m eta: 2:37:08  iter: 15379  total_loss: 1.095  loss_cls: 0.194  loss_box_reg: 0.2604  loss_mask: 0.2712  loss_rpn_cls: 0.06019  loss_rpn_loc: 0.1887  time: 0.6393  data_time: 0.3219  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:28:30 d2.utils.events]: \u001b[0m eta: 2:37:06  iter: 15399  total_loss: 1.035  loss_cls: 0.1727  loss_box_reg: 0.2377  loss_mask: 0.2797  loss_rpn_cls: 0.0767  loss_rpn_loc: 0.2115  time: 0.6397  data_time: 0.5764  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:28:47 d2.utils.events]: \u001b[0m eta: 2:37:26  iter: 15419  total_loss: 0.9254  loss_cls: 0.1433  loss_box_reg: 0.1806  loss_mask: 0.2413  loss_rpn_cls: 0.08105  loss_rpn_loc: 0.2056  time: 0.6404  data_time: 0.6378  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:29:02 d2.utils.events]: \u001b[0m eta: 2:37:44  iter: 15439  total_loss: 1.07  loss_cls: 0.2139  loss_box_reg: 0.2501  loss_mask: 0.2645  loss_rpn_cls: 0.06753  loss_rpn_loc: 0.2133  time: 0.6406  data_time: 0.5174  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:29:12 d2.utils.events]: \u001b[0m eta: 2:35:48  iter: 15459  total_loss: 0.2906  loss_cls: 0.0001731  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03079  loss_rpn_loc: 0.1814  time: 0.6402  data_time: 0.2927  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:29:24 d2.utils.events]: \u001b[0m eta: 2:37:03  iter: 15479  total_loss: 1.085  loss_cls: 0.187  loss_box_reg: 0.2847  loss_mask: 0.2954  loss_rpn_cls: 0.07388  loss_rpn_loc: 0.195  time: 0.6401  data_time: 0.3759  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:29:41 d2.utils.events]: \u001b[0m eta: 2:36:44  iter: 15499  total_loss: 0.9589  loss_cls: 0.1858  loss_box_reg: 0.2252  loss_mask: 0.2885  loss_rpn_cls: 0.05637  loss_rpn_loc: 0.1864  time: 0.6406  data_time: 0.6305  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:29:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 12:29:46 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 12:29:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 12:29:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 12:29:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0443 s/iter. Eval: 0.0164 s/iter. Total: 0.0615 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 12:29:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.163532 (0.056492 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:29:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043122 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:29:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 12:29:50 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06482021772370239\n",
      "\u001b[32m[12/30 12:29:58 d2.utils.events]: \u001b[0m eta: 2:36:33  iter: 15519  total_loss: 1.01  loss_cls: 0.1709  loss_box_reg: 0.2299  loss_mask: 0.2684  loss_rpn_cls: 0.07578  loss_rpn_loc: 0.1868  time: 0.6407  data_time: 0.4444  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:30:09 d2.utils.events]: \u001b[0m eta: 2:37:16  iter: 15539  total_loss: 0.9569  loss_cls: 0.1555  loss_box_reg: 0.2185  loss_mask: 0.2695  loss_rpn_cls: 0.05571  loss_rpn_loc: 0.1861  time: 0.6405  data_time: 0.3591  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:30:24 d2.utils.events]: \u001b[0m eta: 2:36:27  iter: 15559  total_loss: 1.015  loss_cls: 0.1963  loss_box_reg: 0.2188  loss_mask: 0.2676  loss_rpn_cls: 0.07229  loss_rpn_loc: 0.1844  time: 0.6408  data_time: 0.5106  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:30:33 d2.utils.events]: \u001b[0m eta: 2:34:37  iter: 15579  total_loss: 0.7642  loss_cls: 0.1427  loss_box_reg: 0.1959  loss_mask: 0.2236  loss_rpn_cls: 0.0345  loss_rpn_loc: 0.1761  time: 0.6403  data_time: 0.2637  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:30:46 d2.utils.events]: \u001b[0m eta: 2:34:19  iter: 15599  total_loss: 0.9447  loss_cls: 0.1538  loss_box_reg: 0.2116  loss_mask: 0.2716  loss_rpn_cls: 0.0662  loss_rpn_loc: 0.1866  time: 0.6402  data_time: 0.3931  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:31:03 d2.utils.events]: \u001b[0m eta: 2:33:38  iter: 15619  total_loss: 0.9315  loss_cls: 0.1582  loss_box_reg: 0.2193  loss_mask: 0.268  loss_rpn_cls: 0.06776  loss_rpn_loc: 0.201  time: 0.6408  data_time: 0.6319  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:31:16 d2.utils.events]: \u001b[0m eta: 2:35:22  iter: 15639  total_loss: 1.07  loss_cls: 0.1716  loss_box_reg: 0.2525  loss_mask: 0.2848  loss_rpn_cls: 0.04775  loss_rpn_loc: 0.1975  time: 0.6408  data_time: 0.4349  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:31:29 d2.utils.events]: \u001b[0m eta: 2:34:15  iter: 15659  total_loss: 0.8867  loss_cls: 0.1576  loss_box_reg: 0.2211  loss_mask: 0.2513  loss_rpn_cls: 0.04462  loss_rpn_loc: 0.2104  time: 0.6408  data_time: 0.4244  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:31:40 d2.utils.events]: \u001b[0m eta: 2:32:12  iter: 15679  total_loss: 0.9267  loss_cls: 0.1608  loss_box_reg: 0.2291  loss_mask: 0.2484  loss_rpn_cls: 0.05611  loss_rpn_loc: 0.1888  time: 0.6407  data_time: 0.3818  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:31:51 d2.utils.events]: \u001b[0m eta: 2:31:20  iter: 15699  total_loss: 0.8801  loss_cls: 0.1559  loss_box_reg: 0.1917  loss_mask: 0.2519  loss_rpn_cls: 0.04094  loss_rpn_loc: 0.1822  time: 0.6403  data_time: 0.3037  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:32:04 d2.utils.events]: \u001b[0m eta: 2:32:01  iter: 15719  total_loss: 1.029  loss_cls: 0.1785  loss_box_reg: 0.2529  loss_mask: 0.2759  loss_rpn_cls: 0.05653  loss_rpn_loc: 0.1868  time: 0.6403  data_time: 0.4376  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:32:15 d2.utils.events]: \u001b[0m eta: 2:33:06  iter: 15739  total_loss: 0.9102  loss_cls: 0.1707  loss_box_reg: 0.2025  loss_mask: 0.2581  loss_rpn_cls: 0.05122  loss_rpn_loc: 0.1891  time: 0.6402  data_time: 0.3679  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:32:29 d2.utils.events]: \u001b[0m eta: 2:33:29  iter: 15759  total_loss: 0.9344  loss_cls: 0.1578  loss_box_reg: 0.2607  loss_mask: 0.2841  loss_rpn_cls: 0.07012  loss_rpn_loc: 0.1943  time: 0.6403  data_time: 0.4533  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:32:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 12:32:40 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 12:32:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 12:32:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 12:32:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0006 s/iter. Inference: 0.0444 s/iter. Eval: 0.0164 s/iter. Total: 0.0615 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 12:32:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.253908 (0.058105 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:32:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043286 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:32:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 12:32:44 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06660905182532847\n",
      "\u001b[32m[12/30 12:32:45 d2.utils.events]: \u001b[0m eta: 2:32:37  iter: 15779  total_loss: 0.7771  loss_cls: 0.139  loss_box_reg: 0.1857  loss_mask: 0.2439  loss_rpn_cls: 0.04654  loss_rpn_loc: 0.2005  time: 0.6402  data_time: 0.4269  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:32:56 d2.utils.events]: \u001b[0m eta: 2:31:40  iter: 15799  total_loss: 0.9211  loss_cls: 0.1588  loss_box_reg: 0.2276  loss_mask: 0.2628  loss_rpn_cls: 0.06127  loss_rpn_loc: 0.1812  time: 0.6400  data_time: 0.3405  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:33:12 d2.utils.events]: \u001b[0m eta: 2:32:45  iter: 15819  total_loss: 1.018  loss_cls: 0.1848  loss_box_reg: 0.2412  loss_mask: 0.2562  loss_rpn_cls: 0.07378  loss_rpn_loc: 0.2007  time: 0.6404  data_time: 0.5845  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:33:25 d2.utils.events]: \u001b[0m eta: 2:33:40  iter: 15839  total_loss: 1.017  loss_cls: 0.1653  loss_box_reg: 0.2278  loss_mask: 0.2764  loss_rpn_cls: 0.07537  loss_rpn_loc: 0.2007  time: 0.6404  data_time: 0.4193  lr: 0.00125  max_mem: 6404M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 12:33:38 d2.utils.events]: \u001b[0m eta: 2:32:15  iter: 15859  total_loss: 1.019  loss_cls: 0.1699  loss_box_reg: 0.237  loss_mask: 0.2707  loss_rpn_cls: 0.05307  loss_rpn_loc: 0.194  time: 0.6405  data_time: 0.4582  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:33:48 d2.utils.events]: \u001b[0m eta: 2:30:33  iter: 15879  total_loss: 0.8927  loss_cls: 0.1527  loss_box_reg: 0.2  loss_mask: 0.244  loss_rpn_cls: 0.05665  loss_rpn_loc: 0.1877  time: 0.6401  data_time: 0.2795  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:34:05 d2.utils.events]: \u001b[0m eta: 2:30:30  iter: 15899  total_loss: 1.04  loss_cls: 0.1812  loss_box_reg: 0.2337  loss_mask: 0.2736  loss_rpn_cls: 0.0726  loss_rpn_loc: 0.1915  time: 0.6406  data_time: 0.6057  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:34:20 d2.utils.events]: \u001b[0m eta: 2:30:15  iter: 15919  total_loss: 0.9459  loss_cls: 0.1641  loss_box_reg: 0.2209  loss_mask: 0.2638  loss_rpn_cls: 0.06465  loss_rpn_loc: 0.1888  time: 0.6408  data_time: 0.5107  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:34:34 d2.utils.events]: \u001b[0m eta: 2:29:50  iter: 15939  total_loss: 1.051  loss_cls: 0.1813  loss_box_reg: 0.241  loss_mask: 0.2867  loss_rpn_cls: 0.07585  loss_rpn_loc: 0.1976  time: 0.6410  data_time: 0.4819  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:34:44 d2.utils.events]: \u001b[0m eta: 2:29:20  iter: 15959  total_loss: 0.942  loss_cls: 0.1804  loss_box_reg: 0.2532  loss_mask: 0.2698  loss_rpn_cls: 0.05006  loss_rpn_loc: 0.1837  time: 0.6407  data_time: 0.3006  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:34:56 d2.utils.events]: \u001b[0m eta: 2:28:50  iter: 15979  total_loss: 0.7897  loss_cls: 0.1329  loss_box_reg: 0.1642  loss_mask: 0.2018  loss_rpn_cls: 0.05277  loss_rpn_loc: 0.1779  time: 0.6406  data_time: 0.3924  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:35:14 d2.utils.events]: \u001b[0m eta: 2:28:35  iter: 15999  total_loss: 1.084  loss_cls: 0.1992  loss_box_reg: 0.263  loss_mask: 0.294  loss_rpn_cls: 0.09257  loss_rpn_loc: 0.2041  time: 0.6412  data_time: 0.6430  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:35:29 d2.utils.events]: \u001b[0m eta: 2:28:39  iter: 16019  total_loss: 0.9446  loss_cls: 0.1663  loss_box_reg: 0.2009  loss_mask: 0.2615  loss_rpn_cls: 0.06628  loss_rpn_loc: 0.2256  time: 0.6415  data_time: 0.5385  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:35:41 d2.utils.events]: \u001b[0m eta: 2:29:31  iter: 16039  total_loss: 0.9908  loss_cls: 0.176  loss_box_reg: 0.2044  loss_mask: 0.2832  loss_rpn_cls: 0.07033  loss_rpn_loc: 0.2029  time: 0.6413  data_time: 0.3782  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:35:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 12:35:44 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 12:35:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 12:35:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 12:35:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0447 s/iter. Eval: 0.0168 s/iter. Total: 0.0622 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 12:35:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.199944 (0.057142 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:35:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043341 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:35:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 12:35:48 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06606127665446745\n",
      "\u001b[32m[12/30 12:35:55 d2.utils.events]: \u001b[0m eta: 2:31:32  iter: 16059  total_loss: 1.022  loss_cls: 0.1865  loss_box_reg: 0.2396  loss_mask: 0.2803  loss_rpn_cls: 0.06724  loss_rpn_loc: 0.1861  time: 0.6411  data_time: 0.3257  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:36:06 d2.utils.events]: \u001b[0m eta: 2:30:25  iter: 16079  total_loss: 0.8627  loss_cls: 0.1512  loss_box_reg: 0.1545  loss_mask: 0.2364  loss_rpn_cls: 0.04648  loss_rpn_loc: 0.1878  time: 0.6409  data_time: 0.3586  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:36:18 d2.utils.events]: \u001b[0m eta: 2:30:20  iter: 16099  total_loss: 1.025  loss_cls: 0.1975  loss_box_reg: 0.2536  loss_mask: 0.2911  loss_rpn_cls: 0.06597  loss_rpn_loc: 0.2158  time: 0.6408  data_time: 0.3612  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:36:37 d2.utils.events]: \u001b[0m eta: 2:28:46  iter: 16119  total_loss: 1.066  loss_cls: 0.1924  loss_box_reg: 0.2267  loss_mask: 0.3076  loss_rpn_cls: 0.08263  loss_rpn_loc: 0.213  time: 0.6415  data_time: 0.6880  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:36:51 d2.utils.events]: \u001b[0m eta: 2:29:05  iter: 16139  total_loss: 1.06  loss_cls: 0.2176  loss_box_reg: 0.2687  loss_mask: 0.2849  loss_rpn_cls: 0.07522  loss_rpn_loc: 0.1957  time: 0.6416  data_time: 0.4925  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:37:00 d2.utils.events]: \u001b[0m eta: 2:28:12  iter: 16159  total_loss: 0.8998  loss_cls: 0.1555  loss_box_reg: 0.2249  loss_mask: 0.243  loss_rpn_cls: 0.04543  loss_rpn_loc: 0.1761  time: 0.6412  data_time: 0.2487  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:37:13 d2.utils.events]: \u001b[0m eta: 2:27:32  iter: 16179  total_loss: 0.8769  loss_cls: 0.147  loss_box_reg: 0.2106  loss_mask: 0.2481  loss_rpn_cls: 0.04468  loss_rpn_loc: 0.1781  time: 0.6412  data_time: 0.4629  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:37:27 d2.utils.events]: \u001b[0m eta: 2:28:49  iter: 16199  total_loss: 0.967  loss_cls: 0.1675  loss_box_reg: 0.2231  loss_mask: 0.2427  loss_rpn_cls: 0.05454  loss_rpn_loc: 0.202  time: 0.6413  data_time: 0.4592  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:37:39 d2.utils.events]: \u001b[0m eta: 2:29:05  iter: 16219  total_loss: 0.9816  loss_cls: 0.1828  loss_box_reg: 0.2424  loss_mask: 0.2761  loss_rpn_cls: 0.07852  loss_rpn_loc: 0.172  time: 0.6412  data_time: 0.3917  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:37:57 d2.utils.events]: \u001b[0m eta: 2:32:40  iter: 16239  total_loss: 0.9822  loss_cls: 0.1649  loss_box_reg: 0.2064  loss_mask: 0.2829  loss_rpn_cls: 0.06516  loss_rpn_loc: 0.2087  time: 0.6418  data_time: 0.6429  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:38:09 d2.utils.events]: \u001b[0m eta: 2:34:56  iter: 16259  total_loss: 1.031  loss_cls: 0.1747  loss_box_reg: 0.24  loss_mask: 0.2833  loss_rpn_cls: 0.0708  loss_rpn_loc: 0.1966  time: 0.6417  data_time: 0.3905  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:38:20 d2.utils.events]: \u001b[0m eta: 2:33:28  iter: 16279  total_loss: 0.239  loss_cls: 5.077e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04455  loss_rpn_loc: 0.1869  time: 0.6415  data_time: 0.3302  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:38:32 d2.utils.events]: \u001b[0m eta: 2:28:57  iter: 16299  total_loss: 0.9211  loss_cls: 0.1764  loss_box_reg: 0.2023  loss_mask: 0.2571  loss_rpn_cls: 0.05601  loss_rpn_loc: 0.1984  time: 0.6414  data_time: 0.4110  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:38:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 12:38:44 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 12:38:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 12:38:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 12:38:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0448 s/iter. Eval: 0.0179 s/iter. Total: 0.0635 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 12:38:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.221893 (0.057534 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:38:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043120 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:38:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 12:38:48 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06982459067722284\n",
      "\u001b[32m[12/30 12:38:48 d2.utils.events]: \u001b[0m eta: 2:27:30  iter: 16319  total_loss: 0.947  loss_cls: 0.1704  loss_box_reg: 0.2344  loss_mask: 0.245  loss_rpn_cls: 0.05795  loss_rpn_loc: 0.1958  time: 0.6413  data_time: 0.3861  lr: 0.00125  max_mem: 6404M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 12:38:56 d2.utils.events]: \u001b[0m eta: 2:27:24  iter: 16339  total_loss: 0.945  loss_cls: 0.183  loss_box_reg: 0.2393  loss_mask: 0.2671  loss_rpn_cls: 0.0432  loss_rpn_loc: 0.171  time: 0.6407  data_time: 0.2058  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:39:11 d2.utils.events]: \u001b[0m eta: 2:27:19  iter: 16359  total_loss: 0.9479  loss_cls: 0.1729  loss_box_reg: 0.1768  loss_mask: 0.2682  loss_rpn_cls: 0.05654  loss_rpn_loc: 0.1897  time: 0.6410  data_time: 0.5296  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:39:24 d2.utils.events]: \u001b[0m eta: 2:27:30  iter: 16379  total_loss: 0.9379  loss_cls: 0.1584  loss_box_reg: 0.2156  loss_mask: 0.2499  loss_rpn_cls: 0.05598  loss_rpn_loc: 0.1872  time: 0.6410  data_time: 0.4371  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:39:33 d2.utils.events]: \u001b[0m eta: 2:26:34  iter: 16399  total_loss: 0.7935  loss_cls: 0.1285  loss_box_reg: 0.1867  loss_mask: 0.2232  loss_rpn_cls: 0.04395  loss_rpn_loc: 0.1729  time: 0.6406  data_time: 0.2526  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:39:46 d2.utils.events]: \u001b[0m eta: 2:25:10  iter: 16419  total_loss: 0.931  loss_cls: 0.1509  loss_box_reg: 0.2112  loss_mask: 0.2512  loss_rpn_cls: 0.04645  loss_rpn_loc: 0.1948  time: 0.6406  data_time: 0.4215  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:39:58 d2.utils.events]: \u001b[0m eta: 2:24:38  iter: 16439  total_loss: 1.016  loss_cls: 0.1756  loss_box_reg: 0.2369  loss_mask: 0.272  loss_rpn_cls: 0.07256  loss_rpn_loc: 0.1928  time: 0.6405  data_time: 0.3887  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:40:12 d2.utils.events]: \u001b[0m eta: 2:25:00  iter: 16459  total_loss: 1.01  loss_cls: 0.191  loss_box_reg: 0.2264  loss_mask: 0.261  loss_rpn_cls: 0.05125  loss_rpn_loc: 0.1879  time: 0.6406  data_time: 0.4968  lr: 0.00125  max_mem: 6404M\n",
      "\u001b[32m[12/30 12:40:27 d2.utils.events]: \u001b[0m eta: 2:24:22  iter: 16479  total_loss: 1.02  loss_cls: 0.1943  loss_box_reg: 0.249  loss_mask: 0.2628  loss_rpn_cls: 0.06889  loss_rpn_loc: 0.1984  time: 0.6409  data_time: 0.5151  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:40:41 d2.utils.events]: \u001b[0m eta: 2:24:17  iter: 16499  total_loss: 0.9981  loss_cls: 0.1677  loss_box_reg: 0.2628  loss_mask: 0.2749  loss_rpn_cls: 0.06564  loss_rpn_loc: 0.2213  time: 0.6410  data_time: 0.4652  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:40:53 d2.utils.events]: \u001b[0m eta: 2:22:48  iter: 16519  total_loss: 0.9338  loss_cls: 0.1702  loss_box_reg: 0.2135  loss_mask: 0.2438  loss_rpn_cls: 0.05469  loss_rpn_loc: 0.2007  time: 0.6408  data_time: 0.3627  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:41:06 d2.utils.events]: \u001b[0m eta: 2:23:03  iter: 16539  total_loss: 0.9312  loss_cls: 0.1567  loss_box_reg: 0.1822  loss_mask: 0.2631  loss_rpn_cls: 0.05777  loss_rpn_loc: 0.2195  time: 0.6409  data_time: 0.4716  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:41:18 d2.utils.events]: \u001b[0m eta: 2:23:37  iter: 16559  total_loss: 1.112  loss_cls: 0.2054  loss_box_reg: 0.2614  loss_mask: 0.2761  loss_rpn_cls: 0.071  loss_rpn_loc: 0.203  time: 0.6408  data_time: 0.3878  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:41:33 d2.utils.events]: \u001b[0m eta: 2:24:43  iter: 16579  total_loss: 0.9759  loss_cls: 0.1627  loss_box_reg: 0.2339  loss_mask: 0.275  loss_rpn_cls: 0.07329  loss_rpn_loc: 0.2027  time: 0.6410  data_time: 0.4955  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:41:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 12:41:39 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 12:41:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 12:41:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 12:41:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0006 s/iter. Inference: 0.0446 s/iter. Eval: 0.0185 s/iter. Total: 0.0637 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 12:41:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.242310 (0.057898 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:41:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043425 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:41:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 12:41:42 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06416129825125606\n",
      "\u001b[32m[12/30 12:41:49 d2.utils.events]: \u001b[0m eta: 2:23:53  iter: 16599  total_loss: 0.9269  loss_cls: 0.1492  loss_box_reg: 0.1724  loss_mask: 0.2584  loss_rpn_cls: 0.05195  loss_rpn_loc: 0.1872  time: 0.6410  data_time: 0.4135  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:41:57 d2.utils.events]: \u001b[0m eta: 2:23:38  iter: 16619  total_loss: 0.975  loss_cls: 0.1773  loss_box_reg: 0.2831  loss_mask: 0.2797  loss_rpn_cls: 0.04978  loss_rpn_loc: 0.1857  time: 0.6405  data_time: 0.2169  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:42:13 d2.utils.events]: \u001b[0m eta: 2:23:41  iter: 16639  total_loss: 1.063  loss_cls: 0.2047  loss_box_reg: 0.2446  loss_mask: 0.2745  loss_rpn_cls: 0.07345  loss_rpn_loc: 0.1734  time: 0.6408  data_time: 0.5763  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:42:25 d2.utils.events]: \u001b[0m eta: 2:24:13  iter: 16659  total_loss: 1.006  loss_cls: 0.1918  loss_box_reg: 0.2248  loss_mask: 0.2769  loss_rpn_cls: 0.07754  loss_rpn_loc: 0.2072  time: 0.6407  data_time: 0.3839  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:42:39 d2.utils.events]: \u001b[0m eta: 2:26:07  iter: 16679  total_loss: 0.9908  loss_cls: 0.1669  loss_box_reg: 0.2339  loss_mask: 0.2933  loss_rpn_cls: 0.05777  loss_rpn_loc: 0.2004  time: 0.6409  data_time: 0.4873  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:42:55 d2.utils.events]: \u001b[0m eta: 2:28:12  iter: 16699  total_loss: 0.976  loss_cls: 0.155  loss_box_reg: 0.2218  loss_mask: 0.2775  loss_rpn_cls: 0.06597  loss_rpn_loc: 0.2296  time: 0.6412  data_time: 0.5591  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:43:10 d2.utils.events]: \u001b[0m eta: 2:28:07  iter: 16719  total_loss: 0.9437  loss_cls: 0.1712  loss_box_reg: 0.1991  loss_mask: 0.2363  loss_rpn_cls: 0.07088  loss_rpn_loc: 0.2097  time: 0.6414  data_time: 0.5366  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:43:24 d2.utils.events]: \u001b[0m eta: 2:28:11  iter: 16739  total_loss: 1.017  loss_cls: 0.2001  loss_box_reg: 0.2219  loss_mask: 0.2415  loss_rpn_cls: 0.05969  loss_rpn_loc: 0.1905  time: 0.6416  data_time: 0.4938  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:43:36 d2.utils.events]: \u001b[0m eta: 2:27:09  iter: 16759  total_loss: 0.9575  loss_cls: 0.1691  loss_box_reg: 0.2013  loss_mask: 0.2774  loss_rpn_cls: 0.05298  loss_rpn_loc: 0.2079  time: 0.6415  data_time: 0.3780  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:43:50 d2.utils.events]: \u001b[0m eta: 2:30:36  iter: 16779  total_loss: 0.9902  loss_cls: 0.183  loss_box_reg: 0.231  loss_mask: 0.275  loss_rpn_cls: 0.08274  loss_rpn_loc: 0.1962  time: 0.6416  data_time: 0.4867  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:44:00 d2.utils.events]: \u001b[0m eta: 2:27:55  iter: 16799  total_loss: 0.7438  loss_cls: 0.1237  loss_box_reg: 0.1777  loss_mask: 0.1883  loss_rpn_cls: 0.036  loss_rpn_loc: 0.1609  time: 0.6412  data_time: 0.2551  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:44:11 d2.utils.events]: \u001b[0m eta: 2:26:14  iter: 16819  total_loss: 0.9638  loss_cls: 0.1839  loss_box_reg: 0.2301  loss_mask: 0.2492  loss_rpn_cls: 0.05687  loss_rpn_loc: 0.1803  time: 0.6410  data_time: 0.3553  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:44:28 d2.utils.events]: \u001b[0m eta: 2:25:25  iter: 16839  total_loss: 1.019  loss_cls: 0.1884  loss_box_reg: 0.2103  loss_mask: 0.2564  loss_rpn_cls: 0.08459  loss_rpn_loc: 0.2107  time: 0.6415  data_time: 0.6053  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:44:43 d2.utils.events]: \u001b[0m eta: 2:26:43  iter: 16859  total_loss: 1.089  loss_cls: 0.2017  loss_box_reg: 0.2535  loss_mask: 0.2846  loss_rpn_cls: 0.06321  loss_rpn_loc: 0.2041  time: 0.6418  data_time: 0.5536  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:44:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 12:44:47 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 12:44:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 12:44:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 12:44:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0181 s/iter. Total: 0.0636 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 12:44:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.246047 (0.057965 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:44:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043474 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:44:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 12:44:50 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06873327141787151\n",
      "\u001b[32m[12/30 12:44:57 d2.utils.events]: \u001b[0m eta: 2:26:37  iter: 16879  total_loss: 0.8831  loss_cls: 0.1563  loss_box_reg: 0.2103  loss_mask: 0.2312  loss_rpn_cls: 0.05475  loss_rpn_loc: 0.1736  time: 0.6415  data_time: 0.2954  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:45:13 d2.utils.events]: \u001b[0m eta: 2:29:11  iter: 16899  total_loss: 0.9715  loss_cls: 0.1911  loss_box_reg: 0.2412  loss_mask: 0.2725  loss_rpn_cls: 0.07291  loss_rpn_loc: 0.1984  time: 0.6418  data_time: 0.5890  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:45:27 d2.utils.events]: \u001b[0m eta: 2:27:23  iter: 16919  total_loss: 0.7989  loss_cls: 0.1372  loss_box_reg: 0.1772  loss_mask: 0.2285  loss_rpn_cls: 0.04231  loss_rpn_loc: 0.1778  time: 0.6419  data_time: 0.4603  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:45:40 d2.utils.events]: \u001b[0m eta: 2:29:00  iter: 16939  total_loss: 1.072  loss_cls: 0.2179  loss_box_reg: 0.2739  loss_mask: 0.3018  loss_rpn_cls: 0.07055  loss_rpn_loc: 0.1847  time: 0.6420  data_time: 0.4460  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:45:51 d2.utils.events]: \u001b[0m eta: 2:29:47  iter: 16959  total_loss: 0.782  loss_cls: 0.1249  loss_box_reg: 0.1871  loss_mask: 0.2278  loss_rpn_cls: 0.04113  loss_rpn_loc: 0.1926  time: 0.6417  data_time: 0.3299  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:46:07 d2.utils.events]: \u001b[0m eta: 2:32:19  iter: 16979  total_loss: 0.9949  loss_cls: 0.1899  loss_box_reg: 0.2201  loss_mask: 0.2681  loss_rpn_cls: 0.06288  loss_rpn_loc: 0.1962  time: 0.6421  data_time: 0.5961  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:46:22 d2.utils.events]: \u001b[0m eta: 2:29:37  iter: 16999  total_loss: 0.894  loss_cls: 0.1354  loss_box_reg: 0.2078  loss_mask: 0.2717  loss_rpn_cls: 0.05784  loss_rpn_loc: 0.1985  time: 0.6423  data_time: 0.4987  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:46:30 d2.utils.events]: \u001b[0m eta: 2:27:43  iter: 17019  total_loss: 0.7698  loss_cls: 0.1252  loss_box_reg: 0.1903  loss_mask: 0.1985  loss_rpn_cls: 0.04413  loss_rpn_loc: 0.1717  time: 0.6418  data_time: 0.2135  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:46:42 d2.utils.events]: \u001b[0m eta: 2:26:08  iter: 17039  total_loss: 0.957  loss_cls: 0.1778  loss_box_reg: 0.2318  loss_mask: 0.2597  loss_rpn_cls: 0.05321  loss_rpn_loc: 0.1776  time: 0.6417  data_time: 0.4069  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:46:58 d2.utils.events]: \u001b[0m eta: 2:30:13  iter: 17059  total_loss: 1.024  loss_cls: 0.1896  loss_box_reg: 0.2384  loss_mask: 0.2843  loss_rpn_cls: 0.06299  loss_rpn_loc: 0.2088  time: 0.6421  data_time: 0.5632  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:47:09 d2.utils.events]: \u001b[0m eta: 2:27:27  iter: 17079  total_loss: 0.8628  loss_cls: 0.1526  loss_box_reg: 0.2038  loss_mask: 0.2443  loss_rpn_cls: 0.06945  loss_rpn_loc: 0.1738  time: 0.6419  data_time: 0.3494  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:47:24 d2.utils.events]: \u001b[0m eta: 2:29:51  iter: 17099  total_loss: 0.9859  loss_cls: 0.2013  loss_box_reg: 0.2425  loss_mask: 0.2791  loss_rpn_cls: 0.07608  loss_rpn_loc: 0.2109  time: 0.6421  data_time: 0.5004  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:47:38 d2.utils.events]: \u001b[0m eta: 2:28:12  iter: 17119  total_loss: 0.895  loss_cls: 0.144  loss_box_reg: 0.1919  loss_mask: 0.2503  loss_rpn_cls: 0.04443  loss_rpn_loc: 0.1773  time: 0.6422  data_time: 0.4679  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:47:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 12:47:47 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 12:47:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 12:47:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 12:47:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0443 s/iter. Eval: 0.0147 s/iter. Total: 0.0598 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/30 12:47:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.138597 (0.056046 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:47:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.042773 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:47:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 12:47:51 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0664061654143667\n",
      "\u001b[32m[12/30 12:47:52 d2.utils.events]: \u001b[0m eta: 2:26:24  iter: 17139  total_loss: 0.8656  loss_cls: 0.1362  loss_box_reg: 0.2138  loss_mask: 0.2272  loss_rpn_cls: 0.05025  loss_rpn_loc: 0.164  time: 0.6419  data_time: 0.3207  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:48:07 d2.utils.events]: \u001b[0m eta: 2:30:05  iter: 17159  total_loss: 0.971  loss_cls: 0.1654  loss_box_reg: 0.2143  loss_mask: 0.2585  loss_rpn_cls: 0.08056  loss_rpn_loc: 0.1865  time: 0.6422  data_time: 0.5341  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:48:22 d2.utils.events]: \u001b[0m eta: 2:32:06  iter: 17179  total_loss: 1.037  loss_cls: 0.1874  loss_box_reg: 0.263  loss_mask: 0.2808  loss_rpn_cls: 0.0626  loss_rpn_loc: 0.2091  time: 0.6424  data_time: 0.5412  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:48:37 d2.utils.events]: \u001b[0m eta: 2:29:54  iter: 17199  total_loss: 0.9997  loss_cls: 0.1687  loss_box_reg: 0.215  loss_mask: 0.2752  loss_rpn_cls: 0.05942  loss_rpn_loc: 0.1858  time: 0.6427  data_time: 0.5146  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:48:47 d2.utils.events]: \u001b[0m eta: 2:26:03  iter: 17219  total_loss: 0.9453  loss_cls: 0.1696  loss_box_reg: 0.2226  loss_mask: 0.2722  loss_rpn_cls: 0.04591  loss_rpn_loc: 0.1883  time: 0.6423  data_time: 0.2865  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:49:03 d2.utils.events]: \u001b[0m eta: 2:25:58  iter: 17239  total_loss: 0.9859  loss_cls: 0.1543  loss_box_reg: 0.1998  loss_mask: 0.2953  loss_rpn_cls: 0.08127  loss_rpn_loc: 0.2181  time: 0.6427  data_time: 0.5811  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:49:19 d2.utils.events]: \u001b[0m eta: 2:27:20  iter: 17259  total_loss: 0.9637  loss_cls: 0.1772  loss_box_reg: 0.2427  loss_mask: 0.2656  loss_rpn_cls: 0.07424  loss_rpn_loc: 0.1836  time: 0.6430  data_time: 0.5581  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:49:30 d2.utils.events]: \u001b[0m eta: 2:27:15  iter: 17279  total_loss: 0.7913  loss_cls: 0.1356  loss_box_reg: 0.1643  loss_mask: 0.2213  loss_rpn_cls: 0.03787  loss_rpn_loc: 0.1812  time: 0.6428  data_time: 0.3670  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:49:42 d2.utils.events]: \u001b[0m eta: 2:27:10  iter: 17299  total_loss: 0.9286  loss_cls: 0.1438  loss_box_reg: 0.1953  loss_mask: 0.2563  loss_rpn_cls: 0.04339  loss_rpn_loc: 0.1752  time: 0.6427  data_time: 0.3919  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:50:00 d2.utils.events]: \u001b[0m eta: 2:31:27  iter: 17319  total_loss: 0.9063  loss_cls: 0.1536  loss_box_reg: 0.2062  loss_mask: 0.2652  loss_rpn_cls: 0.05997  loss_rpn_loc: 0.2022  time: 0.6432  data_time: 0.6471  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:50:12 d2.utils.events]: \u001b[0m eta: 2:32:16  iter: 17339  total_loss: 0.9427  loss_cls: 0.1491  loss_box_reg: 0.209  loss_mask: 0.2474  loss_rpn_cls: 0.08184  loss_rpn_loc: 0.1933  time: 0.6432  data_time: 0.4115  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:50:26 d2.utils.events]: \u001b[0m eta: 2:30:34  iter: 17359  total_loss: 1.017  loss_cls: 0.1958  loss_box_reg: 0.2177  loss_mask: 0.2986  loss_rpn_cls: 0.05285  loss_rpn_loc: 0.1966  time: 0.6433  data_time: 0.4847  lr: 0.00125  max_mem: 6607M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 12:50:36 d2.utils.events]: \u001b[0m eta: 2:27:45  iter: 17379  total_loss: 0.9795  loss_cls: 0.1774  loss_box_reg: 0.2503  loss_mask: 0.2613  loss_rpn_cls: 0.04887  loss_rpn_loc: 0.1665  time: 0.6430  data_time: 0.2799  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:50:49 d2.utils.events]: \u001b[0m eta: 2:26:41  iter: 17399  total_loss: 0.7916  loss_cls: 0.1345  loss_box_reg: 0.179  loss_mask: 0.2216  loss_rpn_cls: 0.0538  loss_rpn_loc: 0.1821  time: 0.6430  data_time: 0.4433  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:50:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 12:50:52 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 12:50:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 12:50:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 12:50:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0450 s/iter. Eval: 0.0177 s/iter. Total: 0.0634 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 12:50:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.290940 (0.058767 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:50:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043539 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:50:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 12:50:56 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06962572333151808\n",
      "\u001b[32m[12/30 12:51:01 d2.utils.events]: \u001b[0m eta: 2:24:16  iter: 17419  total_loss: 0.6355  loss_cls: 0.1129  loss_box_reg: 0.1583  loss_mask: 0.1797  loss_rpn_cls: 0.02887  loss_rpn_loc: 0.1628  time: 0.6424  data_time: 0.1889  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:51:12 d2.utils.events]: \u001b[0m eta: 2:24:11  iter: 17439  total_loss: 0.9717  loss_cls: 0.1672  loss_box_reg: 0.2007  loss_mask: 0.2424  loss_rpn_cls: 0.04577  loss_rpn_loc: 0.1767  time: 0.6422  data_time: 0.3324  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:51:25 d2.utils.events]: \u001b[0m eta: 2:24:16  iter: 17459  total_loss: 1.045  loss_cls: 0.1907  loss_box_reg: 0.2459  loss_mask: 0.2561  loss_rpn_cls: 0.07524  loss_rpn_loc: 0.2  time: 0.6423  data_time: 0.4261  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:51:38 d2.utils.events]: \u001b[0m eta: 2:23:47  iter: 17479  total_loss: 0.9553  loss_cls: 0.1677  loss_box_reg: 0.2577  loss_mask: 0.2584  loss_rpn_cls: 0.04899  loss_rpn_loc: 0.1895  time: 0.6423  data_time: 0.4646  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:51:53 d2.utils.events]: \u001b[0m eta: 2:23:23  iter: 17499  total_loss: 0.7954  loss_cls: 0.1332  loss_box_reg: 0.1812  loss_mask: 0.2341  loss_rpn_cls: 0.03505  loss_rpn_loc: 0.1842  time: 0.6425  data_time: 0.4925  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:52:07 d2.utils.events]: \u001b[0m eta: 2:24:41  iter: 17519  total_loss: 1.052  loss_cls: 0.1772  loss_box_reg: 0.2172  loss_mask: 0.297  loss_rpn_cls: 0.08472  loss_rpn_loc: 0.2217  time: 0.6427  data_time: 0.5008  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:52:21 d2.utils.events]: \u001b[0m eta: 2:26:10  iter: 17539  total_loss: 1.047  loss_cls: 0.1974  loss_box_reg: 0.2452  loss_mask: 0.2559  loss_rpn_cls: 0.06202  loss_rpn_loc: 0.1811  time: 0.6428  data_time: 0.4815  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:52:32 d2.utils.events]: \u001b[0m eta: 2:24:30  iter: 17559  total_loss: 0.8457  loss_cls: 0.1388  loss_box_reg: 0.145  loss_mask: 0.246  loss_rpn_cls: 0.03737  loss_rpn_loc: 0.1713  time: 0.6425  data_time: 0.3196  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:52:43 d2.utils.events]: \u001b[0m eta: 2:23:16  iter: 17579  total_loss: 0.9731  loss_cls: 0.1891  loss_box_reg: 0.2297  loss_mask: 0.2781  loss_rpn_cls: 0.05519  loss_rpn_loc: 0.1973  time: 0.6424  data_time: 0.3633  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:52:56 d2.utils.events]: \u001b[0m eta: 2:23:28  iter: 17599  total_loss: 1.004  loss_cls: 0.1779  loss_box_reg: 0.2302  loss_mask: 0.256  loss_rpn_cls: 0.06339  loss_rpn_loc: 0.1939  time: 0.6424  data_time: 0.4445  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:53:13 d2.utils.events]: \u001b[0m eta: 2:24:52  iter: 17619  total_loss: 1.049  loss_cls: 0.1917  loss_box_reg: 0.2518  loss_mask: 0.2819  loss_rpn_cls: 0.08002  loss_rpn_loc: 0.2144  time: 0.6428  data_time: 0.5901  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:53:29 d2.utils.events]: \u001b[0m eta: 2:29:30  iter: 17639  total_loss: 1.05  loss_cls: 0.204  loss_box_reg: 0.2464  loss_mask: 0.2757  loss_rpn_cls: 0.08488  loss_rpn_loc: 0.2152  time: 0.6432  data_time: 0.5901  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:53:43 d2.utils.events]: \u001b[0m eta: 2:26:29  iter: 17659  total_loss: 0.9694  loss_cls: 0.1796  loss_box_reg: 0.2398  loss_mask: 0.2613  loss_rpn_cls: 0.0581  loss_rpn_loc: 0.191  time: 0.6432  data_time: 0.4636  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:54:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 12:54:00 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 12:54:00 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 12:54:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 12:54:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0452 s/iter. Eval: 0.0186 s/iter. Total: 0.0645 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 12:54:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.356345 (0.059935 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:54:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043833 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:54:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 12:54:03 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07213730384665318\n",
      "\u001b[32m[12/30 12:54:03 d2.utils.events]: \u001b[0m eta: 2:27:46  iter: 17679  total_loss: 1.058  loss_cls: 0.1881  loss_box_reg: 0.2887  loss_mask: 0.2709  loss_rpn_cls: 0.06274  loss_rpn_loc: 0.196  time: 0.6437  data_time: 0.6102  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:54:15 d2.utils.events]: \u001b[0m eta: 2:24:57  iter: 17699  total_loss: 0.9571  loss_cls: 0.1912  loss_box_reg: 0.2437  loss_mask: 0.2606  loss_rpn_cls: 0.04578  loss_rpn_loc: 0.2008  time: 0.6435  data_time: 0.3684  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:54:32 d2.utils.events]: \u001b[0m eta: 2:24:51  iter: 17719  total_loss: 1.022  loss_cls: 0.1848  loss_box_reg: 0.2211  loss_mask: 0.2849  loss_rpn_cls: 0.06027  loss_rpn_loc: 0.2057  time: 0.6439  data_time: 0.6046  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:54:43 d2.utils.events]: \u001b[0m eta: 2:24:46  iter: 17739  total_loss: 0.9645  loss_cls: 0.1841  loss_box_reg: 0.1995  loss_mask: 0.2696  loss_rpn_cls: 0.05873  loss_rpn_loc: 0.1884  time: 0.6437  data_time: 0.3353  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:54:55 d2.utils.events]: \u001b[0m eta: 2:26:51  iter: 17759  total_loss: 0.9581  loss_cls: 0.1628  loss_box_reg: 0.2214  loss_mask: 0.2368  loss_rpn_cls: 0.05074  loss_rpn_loc: 0.1953  time: 0.6436  data_time: 0.3993  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:55:08 d2.utils.events]: \u001b[0m eta: 2:23:21  iter: 17779  total_loss: 0.8553  loss_cls: 0.1601  loss_box_reg: 0.1702  loss_mask: 0.2412  loss_rpn_cls: 0.04656  loss_rpn_loc: 0.1763  time: 0.6436  data_time: 0.4158  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:55:19 d2.utils.events]: \u001b[0m eta: 2:25:20  iter: 17799  total_loss: 1.003  loss_cls: 0.176  loss_box_reg: 0.2572  loss_mask: 0.2784  loss_rpn_cls: 0.05541  loss_rpn_loc: 0.1757  time: 0.6434  data_time: 0.3612  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:55:31 d2.utils.events]: \u001b[0m eta: 2:24:25  iter: 17819  total_loss: 0.9047  loss_cls: 0.1459  loss_box_reg: 0.1413  loss_mask: 0.2603  loss_rpn_cls: 0.05103  loss_rpn_loc: 0.2003  time: 0.6434  data_time: 0.3860  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:55:44 d2.utils.events]: \u001b[0m eta: 2:23:53  iter: 17839  total_loss: 0.8981  loss_cls: 0.1657  loss_box_reg: 0.2157  loss_mask: 0.2534  loss_rpn_cls: 0.0515  loss_rpn_loc: 0.1819  time: 0.6434  data_time: 0.4313  lr: 0.00125  max_mem: 6607M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 12:55:57 d2.utils.events]: \u001b[0m eta: 2:22:11  iter: 17859  total_loss: 0.9852  loss_cls: 0.161  loss_box_reg: 0.201  loss_mask: 0.2491  loss_rpn_cls: 0.07277  loss_rpn_loc: 0.1817  time: 0.6434  data_time: 0.4375  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:56:15 d2.utils.events]: \u001b[0m eta: 2:26:36  iter: 17879  total_loss: 1.083  loss_cls: 0.2029  loss_box_reg: 0.2574  loss_mask: 0.2889  loss_rpn_cls: 0.09422  loss_rpn_loc: 0.2159  time: 0.6438  data_time: 0.6330  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:56:29 d2.utils.events]: \u001b[0m eta: 2:24:53  iter: 17899  total_loss: 1.039  loss_cls: 0.1764  loss_box_reg: 0.2498  loss_mask: 0.2754  loss_rpn_cls: 0.06431  loss_rpn_loc: 0.1964  time: 0.6440  data_time: 0.4959  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:56:40 d2.utils.events]: \u001b[0m eta: 2:23:58  iter: 17919  total_loss: 0.7588  loss_cls: 0.1388  loss_box_reg: 0.1903  loss_mask: 0.2085  loss_rpn_cls: 0.03228  loss_rpn_loc: 0.1678  time: 0.6438  data_time: 0.3422  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:56:53 d2.utils.events]: \u001b[0m eta: 2:21:49  iter: 17939  total_loss: 0.876  loss_cls: 0.1341  loss_box_reg: 0.1312  loss_mask: 0.2499  loss_rpn_cls: 0.05991  loss_rpn_loc: 0.1829  time: 0.6438  data_time: 0.4448  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:56:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 12:56:59 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 12:56:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 12:56:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 12:57:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0457 s/iter. Eval: 0.0252 s/iter. Total: 0.0717 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 12:57:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.343426 (0.059704 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:57:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043804 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 12:57:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 12:57:02 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0684209389178396\n",
      "\u001b[32m[12/30 12:57:09 d2.utils.events]: \u001b[0m eta: 2:23:21  iter: 17959  total_loss: 0.9595  loss_cls: 0.2006  loss_box_reg: 0.2353  loss_mask: 0.2481  loss_rpn_cls: 0.06057  loss_rpn_loc: 0.1995  time: 0.6437  data_time: 0.3872  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:57:21 d2.utils.events]: \u001b[0m eta: 2:23:41  iter: 17979  total_loss: 0.991  loss_cls: 0.1707  loss_box_reg: 0.2139  loss_mask: 0.2665  loss_rpn_cls: 0.06947  loss_rpn_loc: 0.1805  time: 0.6436  data_time: 0.3811  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:57:34 d2.utils.events]: \u001b[0m eta: 2:25:16  iter: 17999  total_loss: 1.067  loss_cls: 0.2052  loss_box_reg: 0.302  loss_mask: 0.2565  loss_rpn_cls: 0.06374  loss_rpn_loc: 0.2034  time: 0.6437  data_time: 0.4455  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:57:48 d2.utils.events]: \u001b[0m eta: 2:23:31  iter: 18019  total_loss: 0.9364  loss_cls: 0.1391  loss_box_reg: 0.1606  loss_mask: 0.2418  loss_rpn_cls: 0.05957  loss_rpn_loc: 0.1838  time: 0.6438  data_time: 0.4799  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:58:03 d2.utils.events]: \u001b[0m eta: 2:24:15  iter: 18039  total_loss: 1.012  loss_cls: 0.1545  loss_box_reg: 0.2174  loss_mask: 0.252  loss_rpn_cls: 0.0626  loss_rpn_loc: 0.2065  time: 0.6440  data_time: 0.5330  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:58:13 d2.utils.events]: \u001b[0m eta: 2:21:09  iter: 18059  total_loss: 1.003  loss_cls: 0.1723  loss_box_reg: 0.244  loss_mask: 0.2633  loss_rpn_cls: 0.06403  loss_rpn_loc: 0.1865  time: 0.6437  data_time: 0.3068  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:58:29 d2.utils.events]: \u001b[0m eta: 2:23:34  iter: 18079  total_loss: 0.9492  loss_cls: 0.1851  loss_box_reg: 0.2008  loss_mask: 0.2429  loss_rpn_cls: 0.04511  loss_rpn_loc: 0.1848  time: 0.6440  data_time: 0.5510  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:58:43 d2.utils.events]: \u001b[0m eta: 2:22:44  iter: 18099  total_loss: 0.9115  loss_cls: 0.1614  loss_box_reg: 0.189  loss_mask: 0.2647  loss_rpn_cls: 0.06802  loss_rpn_loc: 0.1814  time: 0.6441  data_time: 0.4998  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:58:58 d2.utils.events]: \u001b[0m eta: 2:22:38  iter: 18119  total_loss: 0.9619  loss_cls: 0.1821  loss_box_reg: 0.2297  loss_mask: 0.2729  loss_rpn_cls: 0.0435  loss_rpn_loc: 0.1768  time: 0.6443  data_time: 0.5468  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:59:12 d2.utils.events]: \u001b[0m eta: 2:22:58  iter: 18139  total_loss: 0.9289  loss_cls: 0.1622  loss_box_reg: 0.2269  loss_mask: 0.2608  loss_rpn_cls: 0.05345  loss_rpn_loc: 0.1914  time: 0.6444  data_time: 0.4519  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:59:26 d2.utils.events]: \u001b[0m eta: 2:24:14  iter: 18159  total_loss: 0.961  loss_cls: 0.181  loss_box_reg: 0.2381  loss_mask: 0.2653  loss_rpn_cls: 0.07427  loss_rpn_loc: 0.1934  time: 0.6445  data_time: 0.4912  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:59:38 d2.utils.events]: \u001b[0m eta: 2:22:22  iter: 18179  total_loss: 0.9406  loss_cls: 0.1571  loss_box_reg: 0.2397  loss_mask: 0.2687  loss_rpn_cls: 0.05358  loss_rpn_loc: 0.1735  time: 0.6444  data_time: 0.3848  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 12:59:48 d2.utils.events]: \u001b[0m eta: 2:22:00  iter: 18199  total_loss: 0.926  loss_cls: 0.1663  loss_box_reg: 0.2249  loss_mask: 0.2654  loss_rpn_cls: 0.03689  loss_rpn_loc: 0.1691  time: 0.6441  data_time: 0.2708  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:00:00 d2.utils.events]: \u001b[0m eta: 2:21:55  iter: 18219  total_loss: 0.428  loss_cls: 0.05841  loss_box_reg: 0.07978  loss_mask: 0.09047  loss_rpn_cls: 0.04011  loss_rpn_loc: 0.1763  time: 0.6441  data_time: 0.4202  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:02:01 d2.utils.events]: \u001b[0m eta: 2:20:37  iter: 18399  total_loss: 0.9781  loss_cls: 0.1906  loss_box_reg: 0.2159  loss_mask: 0.2715  loss_rpn_cls: 0.06672  loss_rpn_loc: 0.2031  time: 0.6442  data_time: 0.4168  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:02:13 d2.utils.events]: \u001b[0m eta: 2:20:44  iter: 18419  total_loss: 0.892  loss_cls: 0.1306  loss_box_reg: 0.181  loss_mask: 0.2206  loss_rpn_cls: 0.04199  loss_rpn_loc: 0.1861  time: 0.6440  data_time: 0.3727  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:02:32 d2.utils.events]: \u001b[0m eta: 2:23:16  iter: 18439  total_loss: 1.015  loss_cls: 0.2028  loss_box_reg: 0.2466  loss_mask: 0.2742  loss_rpn_cls: 0.07208  loss_rpn_loc: 0.1916  time: 0.6446  data_time: 0.7065  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:02:43 d2.utils.events]: \u001b[0m eta: 2:23:53  iter: 18459  total_loss: 0.9531  loss_cls: 0.1592  loss_box_reg: 0.2167  loss_mask: 0.2412  loss_rpn_cls: 0.07113  loss_rpn_loc: 0.1862  time: 0.6445  data_time: 0.3441  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:02:58 d2.utils.events]: \u001b[0m eta: 2:24:25  iter: 18479  total_loss: 0.9825  loss_cls: 0.1967  loss_box_reg: 0.208  loss_mask: 0.2682  loss_rpn_cls: 0.04185  loss_rpn_loc: 0.1786  time: 0.6447  data_time: 0.5275  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:03:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 13:03:03 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 13:03:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 13:03:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 13:03:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0449 s/iter. Eval: 0.0166 s/iter. Total: 0.0622 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 13:03:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.259176 (0.058200 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:03:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043644 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:03:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 13:03:06 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06956908584539297\n",
      "\u001b[32m[12/30 13:03:08 d2.utils.events]: \u001b[0m eta: 2:22:37  iter: 18499  total_loss: 0.8244  loss_cls: 0.1468  loss_box_reg: 0.2125  loss_mask: 0.2274  loss_rpn_cls: 0.04816  loss_rpn_loc: 0.1666  time: 0.6440  data_time: 0.1106  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:03:22 d2.utils.events]: \u001b[0m eta: 2:23:36  iter: 18519  total_loss: 0.97  loss_cls: 0.1712  loss_box_reg: 0.2186  loss_mask: 0.2684  loss_rpn_cls: 0.07333  loss_rpn_loc: 0.2171  time: 0.6441  data_time: 0.4940  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:03:36 d2.utils.events]: \u001b[0m eta: 2:22:48  iter: 18539  total_loss: 1.092  loss_cls: 0.1949  loss_box_reg: 0.2551  loss_mask: 0.2872  loss_rpn_cls: 0.07824  loss_rpn_loc: 0.2216  time: 0.6443  data_time: 0.4956  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:03:46 d2.utils.events]: \u001b[0m eta: 2:22:43  iter: 18559  total_loss: 0.8717  loss_cls: 0.1632  loss_box_reg: 0.2249  loss_mask: 0.251  loss_rpn_cls: 0.04828  loss_rpn_loc: 0.1745  time: 0.6440  data_time: 0.2729  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:03:56 d2.utils.events]: \u001b[0m eta: 2:23:31  iter: 18579  total_loss: 0.9247  loss_cls: 0.1522  loss_box_reg: 0.2152  loss_mask: 0.2577  loss_rpn_cls: 0.04728  loss_rpn_loc: 0.1824  time: 0.6437  data_time: 0.3051  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:04:10 d2.utils.events]: \u001b[0m eta: 2:23:02  iter: 18599  total_loss: 0.9304  loss_cls: 0.1704  loss_box_reg: 0.1768  loss_mask: 0.2563  loss_rpn_cls: 0.04811  loss_rpn_loc: 0.1947  time: 0.6437  data_time: 0.4235  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:04:27 d2.utils.events]: \u001b[0m eta: 2:23:47  iter: 18619  total_loss: 1.05  loss_cls: 0.2051  loss_box_reg: 0.2532  loss_mask: 0.2983  loss_rpn_cls: 0.09331  loss_rpn_loc: 0.2013  time: 0.6442  data_time: 0.6583  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:04:40 d2.utils.events]: \u001b[0m eta: 2:22:52  iter: 18639  total_loss: 0.9982  loss_cls: 0.173  loss_box_reg: 0.2271  loss_mask: 0.2784  loss_rpn_cls: 0.04283  loss_rpn_loc: 0.181  time: 0.6441  data_time: 0.3995  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:04:51 d2.utils.events]: \u001b[0m eta: 2:22:16  iter: 18659  total_loss: 0.9029  loss_cls: 0.1382  loss_box_reg: 0.184  loss_mask: 0.2569  loss_rpn_cls: 0.05623  loss_rpn_loc: 0.1676  time: 0.6440  data_time: 0.3681  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:05:02 d2.utils.events]: \u001b[0m eta: 2:21:17  iter: 18679  total_loss: 1.013  loss_cls: 0.1944  loss_box_reg: 0.2482  loss_mask: 0.2535  loss_rpn_cls: 0.05362  loss_rpn_loc: 0.1894  time: 0.6438  data_time: 0.3187  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:05:15 d2.utils.events]: \u001b[0m eta: 2:21:37  iter: 18699  total_loss: 0.9178  loss_cls: 0.1402  loss_box_reg: 0.2383  loss_mask: 0.2633  loss_rpn_cls: 0.04289  loss_rpn_loc: 0.1785  time: 0.6438  data_time: 0.4656  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:05:32 d2.utils.events]: \u001b[0m eta: 2:21:21  iter: 18719  total_loss: 0.849  loss_cls: 0.1419  loss_box_reg: 0.1947  loss_mask: 0.2392  loss_rpn_cls: 0.06556  loss_rpn_loc: 0.201  time: 0.6442  data_time: 0.6190  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:05:47 d2.utils.events]: \u001b[0m eta: 2:21:15  iter: 18739  total_loss: 0.9154  loss_cls: 0.165  loss_box_reg: 0.1754  loss_mask: 0.2736  loss_rpn_cls: 0.04821  loss_rpn_loc: 0.1869  time: 0.6444  data_time: 0.5031  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:06:01 d2.utils.events]: \u001b[0m eta: 2:21:21  iter: 18759  total_loss: 1.052  loss_cls: 0.1934  loss_box_reg: 0.2726  loss_mask: 0.2791  loss_rpn_cls: 0.07564  loss_rpn_loc: 0.1968  time: 0.6445  data_time: 0.4924  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:06:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 13:06:03 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 13:06:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 13:06:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 13:06:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0443 s/iter. Eval: 0.0155 s/iter. Total: 0.0606 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 13:06:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.217223 (0.057450 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:06:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043444 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:06:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 13:06:07 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0679036861497713\n",
      "\u001b[32m[12/30 13:06:12 d2.utils.events]: \u001b[0m eta: 2:20:42  iter: 18779  total_loss: 0.8867  loss_cls: 0.1683  loss_box_reg: 0.2148  loss_mask: 0.2526  loss_rpn_cls: 0.04355  loss_rpn_loc: 0.1655  time: 0.6440  data_time: 0.1712  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:06:25 d2.utils.events]: \u001b[0m eta: 2:20:37  iter: 18799  total_loss: 0.908  loss_cls: 0.1635  loss_box_reg: 0.1793  loss_mask: 0.2745  loss_rpn_cls: 0.05781  loss_rpn_loc: 0.1977  time: 0.6440  data_time: 0.4329  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:06:36 d2.utils.events]: \u001b[0m eta: 2:20:54  iter: 18819  total_loss: 0.9231  loss_cls: 0.1652  loss_box_reg: 0.1999  loss_mask: 0.2659  loss_rpn_cls: 0.05365  loss_rpn_loc: 0.1884  time: 0.6438  data_time: 0.3270  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:06:49 d2.utils.events]: \u001b[0m eta: 2:19:40  iter: 18839  total_loss: 0.6536  loss_cls: 0.09037  loss_box_reg: 0.178  loss_mask: 0.2235  loss_rpn_cls: 0.03251  loss_rpn_loc: 0.1731  time: 0.6438  data_time: 0.4627  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:07:01 d2.utils.events]: \u001b[0m eta: 2:18:59  iter: 18859  total_loss: 0.9613  loss_cls: 0.1685  loss_box_reg: 0.214  loss_mask: 0.2675  loss_rpn_cls: 0.06753  loss_rpn_loc: 0.1982  time: 0.6438  data_time: 0.3910  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:07:17 d2.utils.events]: \u001b[0m eta: 2:18:29  iter: 18879  total_loss: 0.9861  loss_cls: 0.1596  loss_box_reg: 0.2299  loss_mask: 0.2738  loss_rpn_cls: 0.07065  loss_rpn_loc: 0.2015  time: 0.6440  data_time: 0.5630  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:07:33 d2.utils.events]: \u001b[0m eta: 2:18:35  iter: 18899  total_loss: 0.9626  loss_cls: 0.1392  loss_box_reg: 0.1924  loss_mask: 0.2823  loss_rpn_cls: 0.05182  loss_rpn_loc: 0.2051  time: 0.6443  data_time: 0.5683  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:07:44 d2.utils.events]: \u001b[0m eta: 2:20:04  iter: 18919  total_loss: 0.9491  loss_cls: 0.1796  loss_box_reg: 0.2631  loss_mask: 0.2653  loss_rpn_cls: 0.05362  loss_rpn_loc: 0.1862  time: 0.6441  data_time: 0.3406  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:08:00 d2.utils.events]: \u001b[0m eta: 2:20:21  iter: 18939  total_loss: 0.9934  loss_cls: 0.1876  loss_box_reg: 0.2538  loss_mask: 0.2562  loss_rpn_cls: 0.04399  loss_rpn_loc: 0.1838  time: 0.6444  data_time: 0.5782  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:08:17 d2.utils.events]: \u001b[0m eta: 2:20:26  iter: 18959  total_loss: 0.9838  loss_cls: 0.1809  loss_box_reg: 0.2161  loss_mask: 0.2604  loss_rpn_cls: 0.04668  loss_rpn_loc: 0.2034  time: 0.6448  data_time: 0.6240  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:08:29 d2.utils.events]: \u001b[0m eta: 2:18:27  iter: 18979  total_loss: 0.8246  loss_cls: 0.153  loss_box_reg: 0.21  loss_mask: 0.254  loss_rpn_cls: 0.04884  loss_rpn_loc: 0.1871  time: 0.6447  data_time: 0.3741  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:08:43 d2.utils.events]: \u001b[0m eta: 2:19:43  iter: 18999  total_loss: 0.9883  loss_cls: 0.1843  loss_box_reg: 0.2273  loss_mask: 0.2862  loss_rpn_cls: 0.08567  loss_rpn_loc: 0.2136  time: 0.6448  data_time: 0.4732  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:08:52 d2.utils.events]: \u001b[0m eta: 2:20:14  iter: 19019  total_loss: 0.8722  loss_cls: 0.1426  loss_box_reg: 0.2262  loss_mask: 0.2542  loss_rpn_cls: 0.04895  loss_rpn_loc: 0.1882  time: 0.6444  data_time: 0.2501  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:09:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 13:09:04 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 13:09:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 13:09:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 13:09:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0452 s/iter. Eval: 0.0176 s/iter. Total: 0.0636 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 13:09:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.285023 (0.058661 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:09:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043802 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:09:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 13:09:08 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07254279492538358\n",
      "\u001b[32m[12/30 13:09:08 d2.utils.events]: \u001b[0m eta: 2:19:32  iter: 19039  total_loss: 0.9298  loss_cls: 0.167  loss_box_reg: 0.2306  loss_mask: 0.2454  loss_rpn_cls: 0.037  loss_rpn_loc: 0.1872  time: 0.6444  data_time: 0.4123  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:09:22 d2.utils.events]: \u001b[0m eta: 2:19:49  iter: 19059  total_loss: 1.073  loss_cls: 0.196  loss_box_reg: 0.259  loss_mask: 0.2984  loss_rpn_cls: 0.09019  loss_rpn_loc: 0.2022  time: 0.6445  data_time: 0.4846  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:09:37 d2.utils.events]: \u001b[0m eta: 2:19:43  iter: 19079  total_loss: 1.003  loss_cls: 0.1793  loss_box_reg: 0.2171  loss_mask: 0.2714  loss_rpn_cls: 0.05679  loss_rpn_loc: 0.185  time: 0.6446  data_time: 0.5184  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:09:48 d2.utils.events]: \u001b[0m eta: 2:18:00  iter: 19099  total_loss: 0.6902  loss_cls: 0.1196  loss_box_reg: 0.18  loss_mask: 0.2085  loss_rpn_cls: 0.03995  loss_rpn_loc: 0.1831  time: 0.6445  data_time: 0.3749  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:10:04 d2.utils.events]: \u001b[0m eta: 2:17:54  iter: 19119  total_loss: 1.01  loss_cls: 0.194  loss_box_reg: 0.2561  loss_mask: 0.2659  loss_rpn_cls: 0.06181  loss_rpn_loc: 0.2036  time: 0.6448  data_time: 0.5552  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:10:15 d2.utils.events]: \u001b[0m eta: 2:17:40  iter: 19139  total_loss: 0.8874  loss_cls: 0.1525  loss_box_reg: 0.231  loss_mask: 0.2546  loss_rpn_cls: 0.05636  loss_rpn_loc: 0.1991  time: 0.6446  data_time: 0.3542  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:10:27 d2.utils.events]: \u001b[0m eta: 2:16:55  iter: 19159  total_loss: 0.8976  loss_cls: 0.1205  loss_box_reg: 0.2026  loss_mask: 0.2728  loss_rpn_cls: 0.04672  loss_rpn_loc: 0.1884  time: 0.6445  data_time: 0.3571  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:10:42 d2.utils.events]: \u001b[0m eta: 2:17:13  iter: 19179  total_loss: 1.045  loss_cls: 0.2014  loss_box_reg: 0.232  loss_mask: 0.2583  loss_rpn_cls: 0.0914  loss_rpn_loc: 0.1918  time: 0.6447  data_time: 0.5644  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:10:55 d2.utils.events]: \u001b[0m eta: 2:17:22  iter: 19199  total_loss: 0.9665  loss_cls: 0.1642  loss_box_reg: 0.2106  loss_mask: 0.2375  loss_rpn_cls: 0.06426  loss_rpn_loc: 0.1747  time: 0.6447  data_time: 0.3863  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:11:03 d2.utils.events]: \u001b[0m eta: 2:16:49  iter: 19219  total_loss: 0.6575  loss_cls: 0.09536  loss_box_reg: 0.1788  loss_mask: 0.1988  loss_rpn_cls: 0.03714  loss_rpn_loc: 0.1681  time: 0.6443  data_time: 0.2446  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:11:20 d2.utils.events]: \u001b[0m eta: 2:18:00  iter: 19239  total_loss: 1.059  loss_cls: 0.1977  loss_box_reg: 0.2353  loss_mask: 0.2763  loss_rpn_cls: 0.06724  loss_rpn_loc: 0.2026  time: 0.6446  data_time: 0.5711  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:11:31 d2.utils.events]: \u001b[0m eta: 2:18:39  iter: 19259  total_loss: 1.038  loss_cls: 0.193  loss_box_reg: 0.2388  loss_mask: 0.2724  loss_rpn_cls: 0.06182  loss_rpn_loc: 0.1897  time: 0.6444  data_time: 0.3498  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:11:44 d2.utils.events]: \u001b[0m eta: 2:17:49  iter: 19279  total_loss: 0.9792  loss_cls: 0.2021  loss_box_reg: 0.2569  loss_mask: 0.2685  loss_rpn_cls: 0.05874  loss_rpn_loc: 0.1948  time: 0.6444  data_time: 0.4326  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:11:56 d2.utils.events]: \u001b[0m eta: 2:17:46  iter: 19299  total_loss: 0.9042  loss_cls: 0.1656  loss_box_reg: 0.1846  loss_mask: 0.2528  loss_rpn_cls: 0.0878  loss_rpn_loc: 0.1918  time: 0.6444  data_time: 0.3983  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:12:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 13:12:05 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 13:12:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 13:12:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 13:12:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0456 s/iter. Eval: 0.0255 s/iter. Total: 0.0719 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 13:12:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.310015 (0.059107 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:12:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043723 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:12:09 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 13:12:09 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07037300285550085\n",
      "\u001b[32m[12/30 13:12:13 d2.utils.events]: \u001b[0m eta: 2:19:18  iter: 19319  total_loss: 0.9867  loss_cls: 0.1812  loss_box_reg: 0.256  loss_mask: 0.2694  loss_rpn_cls: 0.08524  loss_rpn_loc: 0.1991  time: 0.6444  data_time: 0.4614  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:12:30 d2.utils.events]: \u001b[0m eta: 2:21:35  iter: 19339  total_loss: 0.9289  loss_cls: 0.161  loss_box_reg: 0.1796  loss_mask: 0.2753  loss_rpn_cls: 0.06571  loss_rpn_loc: 0.2004  time: 0.6447  data_time: 0.5949  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:12:41 d2.utils.events]: \u001b[0m eta: 2:20:25  iter: 19359  total_loss: 0.9038  loss_cls: 0.1445  loss_box_reg: 0.2121  loss_mask: 0.2537  loss_rpn_cls: 0.04373  loss_rpn_loc: 0.2012  time: 0.6446  data_time: 0.3608  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:12:58 d2.utils.events]: \u001b[0m eta: 2:22:26  iter: 19379  total_loss: 0.9579  loss_cls: 0.1636  loss_box_reg: 0.2039  loss_mask: 0.2673  loss_rpn_cls: 0.06962  loss_rpn_loc: 0.1849  time: 0.6449  data_time: 0.6083  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:13:10 d2.utils.events]: \u001b[0m eta: 2:19:42  iter: 19399  total_loss: 0.8883  loss_cls: 0.1377  loss_box_reg: 0.1784  loss_mask: 0.2725  loss_rpn_cls: 0.03953  loss_rpn_loc: 0.1692  time: 0.6449  data_time: 0.4073  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:13:20 d2.utils.events]: \u001b[0m eta: 2:20:15  iter: 19419  total_loss: 0.833  loss_cls: 0.1394  loss_box_reg: 0.2081  loss_mask: 0.2848  loss_rpn_cls: 0.03409  loss_rpn_loc: 0.1714  time: 0.6446  data_time: 0.2795  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:13:34 d2.utils.events]: \u001b[0m eta: 2:18:19  iter: 19439  total_loss: 0.9924  loss_cls: 0.1749  loss_box_reg: 0.2312  loss_mask: 0.2782  loss_rpn_cls: 0.06218  loss_rpn_loc: 0.1797  time: 0.6447  data_time: 0.4910  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:13:45 d2.utils.events]: \u001b[0m eta: 2:18:05  iter: 19459  total_loss: 0.9281  loss_cls: 0.1645  loss_box_reg: 0.1909  loss_mask: 0.2706  loss_rpn_cls: 0.0553  loss_rpn_loc: 0.1732  time: 0.6446  data_time: 0.3569  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:13:55 d2.utils.events]: \u001b[0m eta: 2:17:39  iter: 19479  total_loss: 0.7744  loss_cls: 0.1311  loss_box_reg: 0.1873  loss_mask: 0.2164  loss_rpn_cls: 0.03683  loss_rpn_loc: 0.1787  time: 0.6443  data_time: 0.2979  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:14:08 d2.utils.events]: \u001b[0m eta: 2:18:29  iter: 19499  total_loss: 0.8919  loss_cls: 0.177  loss_box_reg: 0.2169  loss_mask: 0.2629  loss_rpn_cls: 0.0582  loss_rpn_loc: 0.2032  time: 0.6442  data_time: 0.4013  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:14:25 d2.utils.events]: \u001b[0m eta: 2:18:01  iter: 19519  total_loss: 1.051  loss_cls: 0.1952  loss_box_reg: 0.2245  loss_mask: 0.2615  loss_rpn_cls: 0.07286  loss_rpn_loc: 0.2149  time: 0.6447  data_time: 0.6577  lr: 0.00125  max_mem: 6607M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 13:14:39 d2.utils.events]: \u001b[0m eta: 2:17:44  iter: 19539  total_loss: 0.9684  loss_cls: 0.1692  loss_box_reg: 0.2193  loss_mask: 0.284  loss_rpn_cls: 0.05853  loss_rpn_loc: 0.1833  time: 0.6447  data_time: 0.4705  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:14:55 d2.utils.events]: \u001b[0m eta: 2:19:37  iter: 19559  total_loss: 0.9719  loss_cls: 0.1775  loss_box_reg: 0.2501  loss_mask: 0.2801  loss_rpn_cls: 0.06623  loss_rpn_loc: 0.2028  time: 0.6450  data_time: 0.5734  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:15:09 d2.utils.events]: \u001b[0m eta: 2:19:31  iter: 19579  total_loss: 0.9259  loss_cls: 0.1462  loss_box_reg: 0.1351  loss_mask: 0.2442  loss_rpn_cls: 0.05978  loss_rpn_loc: 0.2  time: 0.6451  data_time: 0.4998  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:15:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 13:15:13 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 13:15:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 13:15:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 13:15:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0448 s/iter. Eval: 0.0171 s/iter. Total: 0.0627 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 13:15:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.232648 (0.057726 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:15:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043743 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:15:17 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 13:15:17 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06594450132337004\n",
      "\u001b[32m[12/30 13:15:27 d2.utils.events]: \u001b[0m eta: 2:21:25  iter: 19599  total_loss: 1.015  loss_cls: 0.1729  loss_box_reg: 0.2113  loss_mask: 0.2738  loss_rpn_cls: 0.09417  loss_rpn_loc: 0.2341  time: 0.6452  data_time: 0.4923  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:15:38 d2.utils.events]: \u001b[0m eta: 2:16:20  iter: 19619  total_loss: 0.6559  loss_cls: 0.1024  loss_box_reg: 0.1822  loss_mask: 0.2152  loss_rpn_cls: 0.0316  loss_rpn_loc: 0.1778  time: 0.6450  data_time: 0.3257  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:15:53 d2.utils.events]: \u001b[0m eta: 2:16:56  iter: 19639  total_loss: 1.153  loss_cls: 0.2422  loss_box_reg: 0.3281  loss_mask: 0.2598  loss_rpn_cls: 0.07843  loss_rpn_loc: 0.1952  time: 0.6452  data_time: 0.5416  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:16:05 d2.utils.events]: \u001b[0m eta: 2:17:00  iter: 19659  total_loss: 0.9315  loss_cls: 0.1728  loss_box_reg: 0.2195  loss_mask: 0.2662  loss_rpn_cls: 0.06321  loss_rpn_loc: 0.1869  time: 0.6452  data_time: 0.3943  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:16:17 d2.utils.events]: \u001b[0m eta: 2:16:45  iter: 19679  total_loss: 0.8703  loss_cls: 0.1559  loss_box_reg: 0.2217  loss_mask: 0.2444  loss_rpn_cls: 0.04173  loss_rpn_loc: 0.188  time: 0.6451  data_time: 0.3869  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:16:25 d2.utils.events]: \u001b[0m eta: 2:15:12  iter: 19699  total_loss: 0.7845  loss_cls: 0.1379  loss_box_reg: 0.2058  loss_mask: 0.2289  loss_rpn_cls: 0.03973  loss_rpn_loc: 0.1862  time: 0.6446  data_time: 0.2106  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:16:38 d2.utils.events]: \u001b[0m eta: 2:14:55  iter: 19719  total_loss: 0.9286  loss_cls: 0.1352  loss_box_reg: 0.2006  loss_mask: 0.2785  loss_rpn_cls: 0.03923  loss_rpn_loc: 0.1972  time: 0.6447  data_time: 0.4464  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:16:51 d2.utils.events]: \u001b[0m eta: 2:14:11  iter: 19739  total_loss: 0.7964  loss_cls: 0.1264  loss_box_reg: 0.1869  loss_mask: 0.2373  loss_rpn_cls: 0.03634  loss_rpn_loc: 0.1684  time: 0.6447  data_time: 0.4407  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:17:03 d2.utils.events]: \u001b[0m eta: 2:12:11  iter: 19759  total_loss: 0.9415  loss_cls: 0.1674  loss_box_reg: 0.1873  loss_mask: 0.2559  loss_rpn_cls: 0.06867  loss_rpn_loc: 0.1828  time: 0.6446  data_time: 0.4108  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:17:17 d2.utils.events]: \u001b[0m eta: 2:14:58  iter: 19779  total_loss: 1.1  loss_cls: 0.2138  loss_box_reg: 0.2745  loss_mask: 0.27  loss_rpn_cls: 0.08134  loss_rpn_loc: 0.2252  time: 0.6447  data_time: 0.4530  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:17:29 d2.utils.events]: \u001b[0m eta: 2:14:46  iter: 19799  total_loss: 0.9152  loss_cls: 0.1398  loss_box_reg: 0.2002  loss_mask: 0.2503  loss_rpn_cls: 0.06547  loss_rpn_loc: 0.1824  time: 0.6446  data_time: 0.4044  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:17:41 d2.utils.events]: \u001b[0m eta: 2:15:26  iter: 19819  total_loss: 0.989  loss_cls: 0.2006  loss_box_reg: 0.2581  loss_mask: 0.2675  loss_rpn_cls: 0.06966  loss_rpn_loc: 0.1928  time: 0.6445  data_time: 0.3836  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:18:00 d2.utils.events]: \u001b[0m eta: 2:16:22  iter: 19839  total_loss: 0.9902  loss_cls: 0.1771  loss_box_reg: 0.2106  loss_mask: 0.2826  loss_rpn_cls: 0.07215  loss_rpn_loc: 0.2057  time: 0.6450  data_time: 0.6911  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:18:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 13:18:07 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 13:18:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 13:18:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 13:18:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0448 s/iter. Eval: 0.0170 s/iter. Total: 0.0625 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 13:18:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.364931 (0.060088 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:18:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043665 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:18:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 13:18:11 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06479235268246046\n",
      "\u001b[32m[12/30 13:18:12 d2.utils.events]: \u001b[0m eta: 2:17:51  iter: 19859  total_loss: 0.8063  loss_cls: 0.1668  loss_box_reg: 0.1742  loss_mask: 0.2032  loss_rpn_cls: 0.04708  loss_rpn_loc: 0.1749  time: 0.6446  data_time: 0.2163  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:18:28 d2.utils.events]: \u001b[0m eta: 2:18:40  iter: 19879  total_loss: 1.013  loss_cls: 0.19  loss_box_reg: 0.1883  loss_mask: 0.2589  loss_rpn_cls: 0.06689  loss_rpn_loc: 0.2048  time: 0.6449  data_time: 0.5727  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:18:38 d2.utils.events]: \u001b[0m eta: 2:18:35  iter: 19899  total_loss: 0.948  loss_cls: 0.1779  loss_box_reg: 0.2433  loss_mask: 0.2645  loss_rpn_cls: 0.05951  loss_rpn_loc: 0.1926  time: 0.6447  data_time: 0.3083  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:18:50 d2.utils.events]: \u001b[0m eta: 2:18:06  iter: 19919  total_loss: 0.9584  loss_cls: 0.1608  loss_box_reg: 0.2424  loss_mask: 0.2818  loss_rpn_cls: 0.04713  loss_rpn_loc: 0.1874  time: 0.6446  data_time: 0.3516  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:19:01 d2.utils.events]: \u001b[0m eta: 2:17:29  iter: 19939  total_loss: 0.9598  loss_cls: 0.1641  loss_box_reg: 0.2412  loss_mask: 0.2879  loss_rpn_cls: 0.05677  loss_rpn_loc: 0.2009  time: 0.6444  data_time: 0.3714  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:19:16 d2.utils.events]: \u001b[0m eta: 2:17:55  iter: 19959  total_loss: 1.046  loss_cls: 0.1897  loss_box_reg: 0.2297  loss_mask: 0.26  loss_rpn_cls: 0.0566  loss_rpn_loc: 0.1983  time: 0.6445  data_time: 0.4973  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:19:29 d2.utils.events]: \u001b[0m eta: 2:18:13  iter: 19979  total_loss: 1.027  loss_cls: 0.1933  loss_box_reg: 0.2337  loss_mask: 0.2571  loss_rpn_cls: 0.06466  loss_rpn_loc: 0.1794  time: 0.6446  data_time: 0.4467  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:19:41 d2.utils.events]: \u001b[0m eta: 2:15:58  iter: 19999  total_loss: 0.9076  loss_cls: 0.1688  loss_box_reg: 0.2344  loss_mask: 0.2535  loss_rpn_cls: 0.04869  loss_rpn_loc: 0.1777  time: 0.6445  data_time: 0.3763  lr: 0.00125  max_mem: 6607M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 13:19:56 d2.utils.events]: \u001b[0m eta: 2:15:24  iter: 20019  total_loss: 0.8861  loss_cls: 0.1535  loss_box_reg: 0.1549  loss_mask: 0.2516  loss_rpn_cls: 0.04521  loss_rpn_loc: 0.2046  time: 0.6447  data_time: 0.5378  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:20:07 d2.utils.events]: \u001b[0m eta: 2:16:23  iter: 20039  total_loss: 0.8963  loss_cls: 0.1547  loss_box_reg: 0.1839  loss_mask: 0.2375  loss_rpn_cls: 0.05326  loss_rpn_loc: 0.1898  time: 0.6445  data_time: 0.3599  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:20:18 d2.utils.events]: \u001b[0m eta: 2:15:41  iter: 20059  total_loss: 0.9048  loss_cls: 0.1386  loss_box_reg: 0.2007  loss_mask: 0.253  loss_rpn_cls: 0.0531  loss_rpn_loc: 0.1849  time: 0.6444  data_time: 0.3350  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:20:28 d2.utils.events]: \u001b[0m eta: 2:14:59  iter: 20079  total_loss: 0.9612  loss_cls: 0.1644  loss_box_reg: 0.208  loss_mask: 0.2617  loss_rpn_cls: 0.03833  loss_rpn_loc: 0.1777  time: 0.6441  data_time: 0.2887  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:20:46 d2.utils.events]: \u001b[0m eta: 2:16:06  iter: 20099  total_loss: 0.9699  loss_cls: 0.1605  loss_box_reg: 0.2161  loss_mask: 0.2817  loss_rpn_cls: 0.07637  loss_rpn_loc: 0.1986  time: 0.6445  data_time: 0.6506  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:22:51 d2.utils.events]: \u001b[0m eta: 2:14:25  iter: 20299  total_loss: 0.9331  loss_cls: 0.1685  loss_box_reg: 0.2027  loss_mask: 0.2952  loss_rpn_cls: 0.06703  loss_rpn_loc: 0.1795  time: 0.6439  data_time: 0.4590  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:23:04 d2.utils.events]: \u001b[0m eta: 2:12:06  iter: 20319  total_loss: 0.9426  loss_cls: 0.1845  loss_box_reg: 0.2461  loss_mask: 0.2566  loss_rpn_cls: 0.05694  loss_rpn_loc: 0.1789  time: 0.6439  data_time: 0.4255  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:23:16 d2.utils.events]: \u001b[0m eta: 2:10:48  iter: 20339  total_loss: 0.9206  loss_cls: 0.1651  loss_box_reg: 0.1963  loss_mask: 0.2756  loss_rpn_cls: 0.05477  loss_rpn_loc: 0.1927  time: 0.6438  data_time: 0.3900  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:23:28 d2.utils.events]: \u001b[0m eta: 2:09:51  iter: 20359  total_loss: 0.9226  loss_cls: 0.1623  loss_box_reg: 0.184  loss_mask: 0.2316  loss_rpn_cls: 0.06222  loss_rpn_loc: 0.2007  time: 0.6437  data_time: 0.3800  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:23:47 d2.utils.events]: \u001b[0m eta: 2:10:37  iter: 20379  total_loss: 1.035  loss_cls: 0.1917  loss_box_reg: 0.3001  loss_mask: 0.2837  loss_rpn_cls: 0.08231  loss_rpn_loc: 0.2119  time: 0.6442  data_time: 0.7147  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:24:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 13:24:01 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 13:24:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 13:24:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 13:24:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0452 s/iter. Eval: 0.0169 s/iter. Total: 0.0627 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 13:24:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.206145 (0.057253 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:24:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043301 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:24:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 13:24:05 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06440143583353197\n",
      "\u001b[32m[12/30 13:24:05 d2.utils.events]: \u001b[0m eta: 2:08:58  iter: 20399  total_loss: 0.8032  loss_cls: 0.1296  loss_box_reg: 0.2118  loss_mask: 0.2235  loss_rpn_cls: 0.04367  loss_rpn_loc: 0.1648  time: 0.6443  data_time: 0.4564  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:24:17 d2.utils.events]: \u001b[0m eta: 2:09:35  iter: 20419  total_loss: 0.9576  loss_cls: 0.1773  loss_box_reg: 0.2007  loss_mask: 0.2582  loss_rpn_cls: 0.05849  loss_rpn_loc: 0.2039  time: 0.6442  data_time: 0.4220  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:24:30 d2.utils.events]: \u001b[0m eta: 2:11:08  iter: 20439  total_loss: 0.9922  loss_cls: 0.1964  loss_box_reg: 0.2114  loss_mask: 0.2759  loss_rpn_cls: 0.06612  loss_rpn_loc: 0.2053  time: 0.6442  data_time: 0.4196  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:24:43 d2.utils.events]: \u001b[0m eta: 2:12:48  iter: 20459  total_loss: 1.026  loss_cls: 0.1826  loss_box_reg: 0.2605  loss_mask: 0.2831  loss_rpn_cls: 0.06264  loss_rpn_loc: 0.2077  time: 0.6442  data_time: 0.4275  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:24:55 d2.utils.events]: \u001b[0m eta: 2:15:09  iter: 20479  total_loss: 0.9523  loss_cls: 0.1611  loss_box_reg: 0.2004  loss_mask: 0.2411  loss_rpn_cls: 0.06183  loss_rpn_loc: 0.1827  time: 0.6442  data_time: 0.4021  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:25:07 d2.utils.events]: \u001b[0m eta: 2:14:25  iter: 20499  total_loss: 0.2137  loss_cls: 0.0002043  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0308  loss_rpn_loc: 0.1709  time: 0.6441  data_time: 0.3654  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:25:19 d2.utils.events]: \u001b[0m eta: 2:09:19  iter: 20519  total_loss: 0.889  loss_cls: 0.129  loss_box_reg: 0.1954  loss_mask: 0.275  loss_rpn_cls: 0.04447  loss_rpn_loc: 0.1765  time: 0.6440  data_time: 0.3887  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:25:31 d2.utils.events]: \u001b[0m eta: 2:08:39  iter: 20539  total_loss: 0.9167  loss_cls: 0.1578  loss_box_reg: 0.2012  loss_mask: 0.247  loss_rpn_cls: 0.05144  loss_rpn_loc: 0.1874  time: 0.6439  data_time: 0.3894  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:25:44 d2.utils.events]: \u001b[0m eta: 2:08:53  iter: 20559  total_loss: 1.067  loss_cls: 0.231  loss_box_reg: 0.2623  loss_mask: 0.2714  loss_rpn_cls: 0.09717  loss_rpn_loc: 0.1897  time: 0.6440  data_time: 0.4622  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:25:53 d2.utils.events]: \u001b[0m eta: 2:08:23  iter: 20579  total_loss: 0.7793  loss_cls: 0.1317  loss_box_reg: 0.1471  loss_mask: 0.2206  loss_rpn_cls: 0.03307  loss_rpn_loc: 0.1798  time: 0.6437  data_time: 0.2441  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:26:13 d2.utils.events]: \u001b[0m eta: 2:08:43  iter: 20599  total_loss: 1.129  loss_cls: 0.2066  loss_box_reg: 0.2454  loss_mask: 0.278  loss_rpn_cls: 0.1105  loss_rpn_loc: 0.2227  time: 0.6442  data_time: 0.7353  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:26:25 d2.utils.events]: \u001b[0m eta: 2:09:34  iter: 20619  total_loss: 0.8688  loss_cls: 0.1568  loss_box_reg: 0.2036  loss_mask: 0.2425  loss_rpn_cls: 0.05692  loss_rpn_loc: 0.1696  time: 0.6441  data_time: 0.4048  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:26:36 d2.utils.events]: \u001b[0m eta: 2:09:28  iter: 20639  total_loss: 0.9801  loss_cls: 0.1799  loss_box_reg: 0.2598  loss_mask: 0.2788  loss_rpn_cls: 0.07928  loss_rpn_loc: 0.1874  time: 0.6440  data_time: 0.3697  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:26:47 d2.utils.events]: \u001b[0m eta: 2:08:42  iter: 20659  total_loss: 0.8801  loss_cls: 0.1612  loss_box_reg: 0.1526  loss_mask: 0.2583  loss_rpn_cls: 0.03787  loss_rpn_loc: 0.1971  time: 0.6439  data_time: 0.3512  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:26:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 13:26:55 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 13:26:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 13:26:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 13:26:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0168 s/iter. Total: 0.0623 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 13:26:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.254542 (0.058117 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:26:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043727 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:26:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 13:26:59 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06795207638578242\n",
      "\u001b[32m[12/30 13:27:03 d2.utils.events]: \u001b[0m eta: 2:09:51  iter: 20679  total_loss: 0.9223  loss_cls: 0.1717  loss_box_reg: 0.2046  loss_mask: 0.2624  loss_rpn_cls: 0.05989  loss_rpn_loc: 0.2057  time: 0.6438  data_time: 0.3721  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:27:18 d2.utils.events]: \u001b[0m eta: 2:13:55  iter: 20699  total_loss: 1.049  loss_cls: 0.1704  loss_box_reg: 0.2708  loss_mask: 0.2897  loss_rpn_cls: 0.08602  loss_rpn_loc: 0.1982  time: 0.6440  data_time: 0.5229  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:27:31 d2.utils.events]: \u001b[0m eta: 2:14:03  iter: 20719  total_loss: 0.8592  loss_cls: 0.1435  loss_box_reg: 0.213  loss_mask: 0.2482  loss_rpn_cls: 0.04256  loss_rpn_loc: 0.1734  time: 0.6439  data_time: 0.3880  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:27:41 d2.utils.events]: \u001b[0m eta: 2:14:24  iter: 20739  total_loss: 0.8448  loss_cls: 0.1342  loss_box_reg: 0.188  loss_mask: 0.2217  loss_rpn_cls: 0.03981  loss_rpn_loc: 0.1804  time: 0.6437  data_time: 0.3245  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:27:53 d2.utils.events]: \u001b[0m eta: 2:14:19  iter: 20759  total_loss: 0.9388  loss_cls: 0.1695  loss_box_reg: 0.1838  loss_mask: 0.2469  loss_rpn_cls: 0.04396  loss_rpn_loc: 0.1662  time: 0.6437  data_time: 0.3934  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:28:07 d2.utils.events]: \u001b[0m eta: 2:13:54  iter: 20779  total_loss: 1.042  loss_cls: 0.1971  loss_box_reg: 0.245  loss_mask: 0.2726  loss_rpn_cls: 0.06723  loss_rpn_loc: 0.2158  time: 0.6438  data_time: 0.4847  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:28:23 d2.utils.events]: \u001b[0m eta: 2:13:48  iter: 20799  total_loss: 0.9927  loss_cls: 0.1762  loss_box_reg: 0.2678  loss_mask: 0.2775  loss_rpn_cls: 0.05195  loss_rpn_loc: 0.1856  time: 0.6440  data_time: 0.5569  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:28:35 d2.utils.events]: \u001b[0m eta: 2:12:44  iter: 20819  total_loss: 0.7933  loss_cls: 0.1196  loss_box_reg: 0.1934  loss_mask: 0.2518  loss_rpn_cls: 0.05057  loss_rpn_loc: 0.1842  time: 0.6439  data_time: 0.3955  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:28:45 d2.utils.events]: \u001b[0m eta: 2:12:01  iter: 20839  total_loss: 0.9418  loss_cls: 0.158  loss_box_reg: 0.2326  loss_mask: 0.2492  loss_rpn_cls: 0.04237  loss_rpn_loc: 0.1809  time: 0.6437  data_time: 0.2552  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:28:56 d2.utils.events]: \u001b[0m eta: 2:07:49  iter: 20859  total_loss: 0.8282  loss_cls: 0.1539  loss_box_reg: 0.2175  loss_mask: 0.2436  loss_rpn_cls: 0.02767  loss_rpn_loc: 0.1442  time: 0.6435  data_time: 0.3492  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:29:07 d2.utils.events]: \u001b[0m eta: 2:07:09  iter: 20879  total_loss: 1.007  loss_cls: 0.184  loss_box_reg: 0.267  loss_mask: 0.2518  loss_rpn_cls: 0.04034  loss_rpn_loc: 0.1879  time: 0.6434  data_time: 0.3406  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:29:20 d2.utils.events]: \u001b[0m eta: 2:06:30  iter: 20899  total_loss: 0.9951  loss_cls: 0.1736  loss_box_reg: 0.2218  loss_mask: 0.2863  loss_rpn_cls: 0.06081  loss_rpn_loc: 0.1801  time: 0.6434  data_time: 0.4236  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:29:33 d2.utils.events]: \u001b[0m eta: 2:06:52  iter: 20919  total_loss: 0.9139  loss_cls: 0.1453  loss_box_reg: 0.1171  loss_mask: 0.2725  loss_rpn_cls: 0.04359  loss_rpn_loc: 0.1866  time: 0.6434  data_time: 0.4501  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:29:46 d2.utils.events]: \u001b[0m eta: 2:06:47  iter: 20939  total_loss: 0.9099  loss_cls: 0.1534  loss_box_reg: 0.1927  loss_mask: 0.2533  loss_rpn_cls: 0.05968  loss_rpn_loc: 0.1982  time: 0.6434  data_time: 0.4063  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:29:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 13:29:47 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 13:29:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 13:29:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 13:29:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0006 s/iter. Inference: 0.0445 s/iter. Eval: 0.0155 s/iter. Total: 0.0606 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 13:29:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.203373 (0.057203 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:29:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043198 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:29:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 13:29:51 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06665057878392558\n",
      "\u001b[32m[12/30 13:29:58 d2.utils.events]: \u001b[0m eta: 2:05:41  iter: 20959  total_loss: 0.4055  loss_cls: 0.04248  loss_box_reg: 0.1007  loss_mask: 0.1345  loss_rpn_cls: 0.0242  loss_rpn_loc: 0.1624  time: 0.6431  data_time: 0.2476  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:30:15 d2.utils.events]: \u001b[0m eta: 2:05:38  iter: 20979  total_loss: 0.9842  loss_cls: 0.1723  loss_box_reg: 0.2205  loss_mask: 0.2609  loss_rpn_cls: 0.05172  loss_rpn_loc: 0.1864  time: 0.6434  data_time: 0.5981  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:30:30 d2.utils.events]: \u001b[0m eta: 2:06:33  iter: 20999  total_loss: 1.079  loss_cls: 0.2244  loss_box_reg: 0.3536  loss_mask: 0.2831  loss_rpn_cls: 0.084  loss_rpn_loc: 0.2148  time: 0.6435  data_time: 0.5092  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:30:44 d2.utils.events]: \u001b[0m eta: 2:06:33  iter: 21019  total_loss: 0.8887  loss_cls: 0.1356  loss_box_reg: 0.2032  loss_mask: 0.2541  loss_rpn_cls: 0.05813  loss_rpn_loc: 0.1781  time: 0.6436  data_time: 0.4854  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:30:55 d2.utils.events]: \u001b[0m eta: 2:06:22  iter: 21039  total_loss: 0.921  loss_cls: 0.1353  loss_box_reg: 0.2281  loss_mask: 0.2372  loss_rpn_cls: 0.06769  loss_rpn_loc: 0.1816  time: 0.6435  data_time: 0.3664  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:31:09 d2.utils.events]: \u001b[0m eta: 2:06:18  iter: 21059  total_loss: 1.014  loss_cls: 0.1886  loss_box_reg: 0.2365  loss_mask: 0.2935  loss_rpn_cls: 0.06785  loss_rpn_loc: 0.1965  time: 0.6435  data_time: 0.4361  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:31:21 d2.utils.events]: \u001b[0m eta: 2:07:53  iter: 21079  total_loss: 0.9415  loss_cls: 0.1467  loss_box_reg: 0.1905  loss_mask: 0.2546  loss_rpn_cls: 0.05186  loss_rpn_loc: 0.1776  time: 0.6435  data_time: 0.4088  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:31:31 d2.utils.events]: \u001b[0m eta: 2:05:15  iter: 21099  total_loss: 0.778  loss_cls: 0.1349  loss_box_reg: 0.1873  loss_mask: 0.2165  loss_rpn_cls: 0.0376  loss_rpn_loc: 0.1694  time: 0.6433  data_time: 0.2979  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:31:40 d2.utils.events]: \u001b[0m eta: 2:04:21  iter: 21119  total_loss: 0.8158  loss_cls: 0.1632  loss_box_reg: 0.2161  loss_mask: 0.252  loss_rpn_cls: 0.04545  loss_rpn_loc: 0.1785  time: 0.6430  data_time: 0.2626  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:31:56 d2.utils.events]: \u001b[0m eta: 2:04:56  iter: 21139  total_loss: 1.036  loss_cls: 0.2036  loss_box_reg: 0.2346  loss_mask: 0.2791  loss_rpn_cls: 0.07182  loss_rpn_loc: 0.1849  time: 0.6432  data_time: 0.5512  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:32:08 d2.utils.events]: \u001b[0m eta: 2:05:50  iter: 21159  total_loss: 1.012  loss_cls: 0.1616  loss_box_reg: 0.2115  loss_mask: 0.289  loss_rpn_cls: 0.07149  loss_rpn_loc: 0.2149  time: 0.6432  data_time: 0.3851  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:32:20 d2.utils.events]: \u001b[0m eta: 2:05:22  iter: 21179  total_loss: 0.9497  loss_cls: 0.1687  loss_box_reg: 0.2508  loss_mask: 0.2523  loss_rpn_cls: 0.05998  loss_rpn_loc: 0.1889  time: 0.6431  data_time: 0.3789  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:32:31 d2.utils.events]: \u001b[0m eta: 2:05:42  iter: 21199  total_loss: 0.8241  loss_cls: 0.1412  loss_box_reg: 0.1825  loss_mask: 0.2287  loss_rpn_cls: 0.03674  loss_rpn_loc: 0.1878  time: 0.6430  data_time: 0.3470  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:32:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 13:32:44 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 13:32:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 13:32:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 13:32:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0452 s/iter. Eval: 0.0183 s/iter. Total: 0.0642 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 13:32:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.273733 (0.058460 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:32:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043664 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:32:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 13:32:48 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06930182980481875\n",
      "\u001b[32m[12/30 13:32:50 d2.utils.events]: \u001b[0m eta: 2:05:51  iter: 21219  total_loss: 0.9652  loss_cls: 0.1784  loss_box_reg: 0.2115  loss_mask: 0.2758  loss_rpn_cls: 0.06911  loss_rpn_loc: 0.2055  time: 0.6431  data_time: 0.5199  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:33:02 d2.utils.events]: \u001b[0m eta: 2:05:06  iter: 21239  total_loss: 0.9722  loss_cls: 0.1656  loss_box_reg: 0.2456  loss_mask: 0.2705  loss_rpn_cls: 0.05908  loss_rpn_loc: 0.1766  time: 0.6430  data_time: 0.3821  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:33:12 d2.utils.events]: \u001b[0m eta: 2:04:26  iter: 21259  total_loss: 0.6852  loss_cls: 0.1041  loss_box_reg: 0.1624  loss_mask: 0.2149  loss_rpn_cls: 0.03433  loss_rpn_loc: 0.18  time: 0.6428  data_time: 0.3282  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:33:26 d2.utils.events]: \u001b[0m eta: 2:05:35  iter: 21279  total_loss: 1.014  loss_cls: 0.181  loss_box_reg: 0.2432  loss_mask: 0.2773  loss_rpn_cls: 0.04741  loss_rpn_loc: 0.1888  time: 0.6429  data_time: 0.4664  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:33:38 d2.utils.events]: \u001b[0m eta: 2:04:51  iter: 21299  total_loss: 0.938  loss_cls: 0.1671  loss_box_reg: 0.225  loss_mask: 0.2586  loss_rpn_cls: 0.05747  loss_rpn_loc: 0.1759  time: 0.6428  data_time: 0.3555  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:33:50 d2.utils.events]: \u001b[0m eta: 2:04:11  iter: 21319  total_loss: 0.8407  loss_cls: 0.124  loss_box_reg: 0.1859  loss_mask: 0.2333  loss_rpn_cls: 0.05388  loss_rpn_loc: 0.2211  time: 0.6428  data_time: 0.4104  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:34:02 d2.utils.events]: \u001b[0m eta: 2:04:39  iter: 21339  total_loss: 0.9756  loss_cls: 0.1777  loss_box_reg: 0.2315  loss_mask: 0.2746  loss_rpn_cls: 0.05586  loss_rpn_loc: 0.1825  time: 0.6427  data_time: 0.3724  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:34:13 d2.utils.events]: \u001b[0m eta: 2:04:33  iter: 21359  total_loss: 0.9069  loss_cls: 0.1625  loss_box_reg: 0.1931  loss_mask: 0.2478  loss_rpn_cls: 0.04389  loss_rpn_loc: 0.1735  time: 0.6426  data_time: 0.3812  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:34:28 d2.utils.events]: \u001b[0m eta: 2:03:47  iter: 21379  total_loss: 0.9288  loss_cls: 0.1619  loss_box_reg: 0.2131  loss_mask: 0.2665  loss_rpn_cls: 0.03697  loss_rpn_loc: 0.1564  time: 0.6427  data_time: 0.5187  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:34:41 d2.utils.events]: \u001b[0m eta: 2:03:57  iter: 21399  total_loss: 0.9247  loss_cls: 0.1897  loss_box_reg: 0.2318  loss_mask: 0.2673  loss_rpn_cls: 0.05338  loss_rpn_loc: 0.1832  time: 0.6427  data_time: 0.4145  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:34:53 d2.utils.events]: \u001b[0m eta: 2:03:45  iter: 21419  total_loss: 0.9914  loss_cls: 0.1753  loss_box_reg: 0.2545  loss_mask: 0.2599  loss_rpn_cls: 0.04663  loss_rpn_loc: 0.1865  time: 0.6426  data_time: 0.3576  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:35:05 d2.utils.events]: \u001b[0m eta: 2:04:13  iter: 21439  total_loss: 0.9438  loss_cls: 0.1774  loss_box_reg: 0.2299  loss_mask: 0.2709  loss_rpn_cls: 0.06359  loss_rpn_loc: 0.1829  time: 0.6426  data_time: 0.3870  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:35:18 d2.utils.events]: \u001b[0m eta: 2:04:07  iter: 21459  total_loss: 1.081  loss_cls: 0.2209  loss_box_reg: 0.2756  loss_mask: 0.2648  loss_rpn_cls: 0.07881  loss_rpn_loc: 0.2045  time: 0.6426  data_time: 0.4524  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:35:27 d2.utils.events]: \u001b[0m eta: 2:02:48  iter: 21479  total_loss: 0.6869  loss_cls: 0.09843  loss_box_reg: 0.1628  loss_mask: 0.2371  loss_rpn_cls: 0.03007  loss_rpn_loc: 0.1608  time: 0.6423  data_time: 0.2310  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:35:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 13:35:35 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 13:35:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 13:35:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 13:35:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0454 s/iter. Eval: 0.0215 s/iter. Total: 0.0677 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 13:35:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.339605 (0.059636 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:35:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043687 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:35:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 13:35:39 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07378247792706147\n",
      "\u001b[32m[12/30 13:35:47 d2.utils.events]: \u001b[0m eta: 2:03:57  iter: 21499  total_loss: 1.065  loss_cls: 0.1876  loss_box_reg: 0.2073  loss_mask: 0.2743  loss_rpn_cls: 0.07699  loss_rpn_loc: 0.2293  time: 0.6425  data_time: 0.5802  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:36:00 d2.utils.events]: \u001b[0m eta: 2:04:23  iter: 21519  total_loss: 0.9132  loss_cls: 0.1554  loss_box_reg: 0.1909  loss_mask: 0.2483  loss_rpn_cls: 0.05845  loss_rpn_loc: 0.189  time: 0.6426  data_time: 0.4463  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:36:15 d2.utils.events]: \u001b[0m eta: 2:06:19  iter: 21539  total_loss: 0.944  loss_cls: 0.178  loss_box_reg: 0.2125  loss_mask: 0.2638  loss_rpn_cls: 0.04598  loss_rpn_loc: 0.2165  time: 0.6428  data_time: 0.5387  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:36:30 d2.utils.events]: \u001b[0m eta: 2:04:12  iter: 21559  total_loss: 0.9767  loss_cls: 0.1766  loss_box_reg: 0.2144  loss_mask: 0.2775  loss_rpn_cls: 0.06969  loss_rpn_loc: 0.2181  time: 0.6429  data_time: 0.5144  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:36:45 d2.utils.events]: \u001b[0m eta: 2:09:19  iter: 21579  total_loss: 0.9448  loss_cls: 0.1841  loss_box_reg: 0.2786  loss_mask: 0.2736  loss_rpn_cls: 0.06708  loss_rpn_loc: 0.1934  time: 0.6430  data_time: 0.4847  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:37:02 d2.utils.events]: \u001b[0m eta: 2:08:16  iter: 21599  total_loss: 1.09  loss_cls: 0.2177  loss_box_reg: 0.2657  loss_mask: 0.2623  loss_rpn_cls: 0.09219  loss_rpn_loc: 0.1933  time: 0.6433  data_time: 0.6405  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:37:16 d2.utils.events]: \u001b[0m eta: 2:08:48  iter: 21619  total_loss: 0.7871  loss_cls: 0.1144  loss_box_reg: 0.1633  loss_mask: 0.239  loss_rpn_cls: 0.05713  loss_rpn_loc: 0.1824  time: 0.6434  data_time: 0.4654  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:37:27 d2.utils.events]: \u001b[0m eta: 2:05:52  iter: 21639  total_loss: 0.9855  loss_cls: 0.1758  loss_box_reg: 0.2192  loss_mask: 0.2525  loss_rpn_cls: 0.04853  loss_rpn_loc: 0.1883  time: 0.6433  data_time: 0.3583  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:37:38 d2.utils.events]: \u001b[0m eta: 2:05:47  iter: 21659  total_loss: 0.953  loss_cls: 0.1707  loss_box_reg: 0.2035  loss_mask: 0.2664  loss_rpn_cls: 0.04595  loss_rpn_loc: 0.1868  time: 0.6431  data_time: 0.3197  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:37:51 d2.utils.events]: \u001b[0m eta: 2:05:41  iter: 21679  total_loss: 0.957  loss_cls: 0.1745  loss_box_reg: 0.2091  loss_mask: 0.279  loss_rpn_cls: 0.06454  loss_rpn_loc: 0.1814  time: 0.6432  data_time: 0.4812  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:38:03 d2.utils.events]: \u001b[0m eta: 2:03:36  iter: 21699  total_loss: 0.9434  loss_cls: 0.1769  loss_box_reg: 0.228  loss_mask: 0.2449  loss_rpn_cls: 0.03816  loss_rpn_loc: 0.1697  time: 0.6431  data_time: 0.3892  lr: 0.00125  max_mem: 6607M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 13:38:13 d2.utils.events]: \u001b[0m eta: 2:03:30  iter: 21719  total_loss: 0.871  loss_cls: 0.144  loss_box_reg: 0.1843  loss_mask: 0.2498  loss_rpn_cls: 0.04604  loss_rpn_loc: 0.1584  time: 0.6429  data_time: 0.2727  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:38:21 d2.utils.events]: \u001b[0m eta: 2:03:25  iter: 21739  total_loss: 0.8112  loss_cls: 0.1207  loss_box_reg: 0.1969  loss_mask: 0.2312  loss_rpn_cls: 0.03024  loss_rpn_loc: 0.1691  time: 0.6425  data_time: 0.2118  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:38:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 13:38:34 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 13:38:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 13:38:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 13:38:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0453 s/iter. Eval: 0.0245 s/iter. Total: 0.0706 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 13:38:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.273858 (0.058462 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:38:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043528 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:38:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 13:38:38 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06413417693882921\n",
      "\u001b[32m[12/30 13:38:38 d2.utils.events]: \u001b[0m eta: 2:03:56  iter: 21759  total_loss: 1.025  loss_cls: 0.1716  loss_box_reg: 0.2196  loss_mask: 0.2935  loss_rpn_cls: 0.07097  loss_rpn_loc: 0.1922  time: 0.6425  data_time: 0.4203  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:38:49 d2.utils.events]: \u001b[0m eta: 2:02:48  iter: 21779  total_loss: 0.9714  loss_cls: 0.1931  loss_box_reg: 0.2292  loss_mask: 0.2853  loss_rpn_cls: 0.05803  loss_rpn_loc: 0.2006  time: 0.6424  data_time: 0.3639  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:38:57 d2.utils.events]: \u001b[0m eta: 2:02:23  iter: 21799  total_loss: 0.7706  loss_cls: 0.133  loss_box_reg: 0.1898  loss_mask: 0.235  loss_rpn_cls: 0.03444  loss_rpn_loc: 0.1571  time: 0.6421  data_time: 0.1974  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:39:09 d2.utils.events]: \u001b[0m eta: 2:02:37  iter: 21819  total_loss: 1.026  loss_cls: 0.1878  loss_box_reg: 0.275  loss_mask: 0.2655  loss_rpn_cls: 0.05863  loss_rpn_loc: 0.1911  time: 0.6420  data_time: 0.4055  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:39:30 d2.utils.events]: \u001b[0m eta: 2:02:53  iter: 21839  total_loss: 0.9297  loss_cls: 0.1605  loss_box_reg: 0.2079  loss_mask: 0.2759  loss_rpn_cls: 0.06259  loss_rpn_loc: 0.2008  time: 0.6426  data_time: 0.7839  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:39:41 d2.utils.events]: \u001b[0m eta: 2:03:30  iter: 21859  total_loss: 0.8326  loss_cls: 0.15  loss_box_reg: 0.1984  loss_mask: 0.2471  loss_rpn_cls: 0.04518  loss_rpn_loc: 0.1581  time: 0.6424  data_time: 0.3389  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:39:52 d2.utils.events]: \u001b[0m eta: 2:02:44  iter: 21879  total_loss: 0.9831  loss_cls: 0.1524  loss_box_reg: 0.2304  loss_mask: 0.2424  loss_rpn_cls: 0.04967  loss_rpn_loc: 0.2136  time: 0.6423  data_time: 0.3589  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:40:08 d2.utils.events]: \u001b[0m eta: 2:03:19  iter: 21899  total_loss: 1.029  loss_cls: 0.1835  loss_box_reg: 0.2273  loss_mask: 0.2734  loss_rpn_cls: 0.07006  loss_rpn_loc: 0.2083  time: 0.6425  data_time: 0.5506  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:40:21 d2.utils.events]: \u001b[0m eta: 2:03:54  iter: 21919  total_loss: 0.9819  loss_cls: 0.1935  loss_box_reg: 0.1834  loss_mask: 0.2609  loss_rpn_cls: 0.0695  loss_rpn_loc: 0.2131  time: 0.6425  data_time: 0.4109  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:40:38 d2.utils.events]: \u001b[0m eta: 2:04:02  iter: 21939  total_loss: 0.8626  loss_cls: 0.1359  loss_box_reg: 0.1634  loss_mask: 0.2324  loss_rpn_cls: 0.0425  loss_rpn_loc: 0.1759  time: 0.6428  data_time: 0.6563  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:40:49 d2.utils.events]: \u001b[0m eta: 2:04:55  iter: 21959  total_loss: 0.8773  loss_cls: 0.1494  loss_box_reg: 0.1783  loss_mask: 0.2612  loss_rpn_cls: 0.04979  loss_rpn_loc: 0.1713  time: 0.6427  data_time: 0.3493  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:41:03 d2.utils.events]: \u001b[0m eta: 2:05:30  iter: 21979  total_loss: 0.9615  loss_cls: 0.1772  loss_box_reg: 0.2581  loss_mask: 0.2735  loss_rpn_cls: 0.04494  loss_rpn_loc: 0.1923  time: 0.6427  data_time: 0.4612  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:41:14 d2.utils.events]: \u001b[0m eta: 2:02:17  iter: 21999  total_loss: 0.9224  loss_cls: 0.1399  loss_box_reg: 0.2273  loss_mask: 0.264  loss_rpn_cls: 0.05228  loss_rpn_loc: 0.1938  time: 0.6426  data_time: 0.3568  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:41:27 d2.utils.events]: \u001b[0m eta: 2:03:28  iter: 22019  total_loss: 0.928  loss_cls: 0.1603  loss_box_reg: 0.2181  loss_mask: 0.2848  loss_rpn_cls: 0.06604  loss_rpn_loc: 0.1919  time: 0.6426  data_time: 0.4110  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:41:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 13:41:35 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 13:41:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 13:41:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 13:41:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0446 s/iter. Eval: 0.0180 s/iter. Total: 0.0634 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 13:41:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.424409 (0.061150 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:41:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043730 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:41:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 13:41:39 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06647422196001189\n",
      "\u001b[32m[12/30 13:41:43 d2.utils.events]: \u001b[0m eta: 2:03:22  iter: 22039  total_loss: 0.9718  loss_cls: 0.1702  loss_box_reg: 0.2051  loss_mask: 0.2336  loss_rpn_cls: 0.04743  loss_rpn_loc: 0.1839  time: 0.6426  data_time: 0.4094  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:41:55 d2.utils.events]: \u001b[0m eta: 2:02:01  iter: 22059  total_loss: 0.8411  loss_cls: 0.1529  loss_box_reg: 0.2145  loss_mask: 0.2394  loss_rpn_cls: 0.03643  loss_rpn_loc: 0.1641  time: 0.6425  data_time: 0.3941  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:42:07 d2.utils.events]: \u001b[0m eta: 2:01:04  iter: 22079  total_loss: 0.8318  loss_cls: 0.1443  loss_box_reg: 0.1702  loss_mask: 0.2356  loss_rpn_cls: 0.03242  loss_rpn_loc: 0.1698  time: 0.6424  data_time: 0.3677  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:42:20 d2.utils.events]: \u001b[0m eta: 2:01:43  iter: 22099  total_loss: 0.9737  loss_cls: 0.1804  loss_box_reg: 0.2324  loss_mask: 0.2561  loss_rpn_cls: 0.05779  loss_rpn_loc: 0.1797  time: 0.6425  data_time: 0.4353  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:42:32 d2.utils.events]: \u001b[0m eta: 2:01:38  iter: 22119  total_loss: 0.9179  loss_cls: 0.1439  loss_box_reg: 0.1842  loss_mask: 0.2349  loss_rpn_cls: 0.03194  loss_rpn_loc: 0.1735  time: 0.6424  data_time: 0.3933  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:42:42 d2.utils.events]: \u001b[0m eta: 2:00:33  iter: 22139  total_loss: 0.8913  loss_cls: 0.1431  loss_box_reg: 0.2213  loss_mask: 0.2787  loss_rpn_cls: 0.04745  loss_rpn_loc: 0.1803  time: 0.6422  data_time: 0.2888  lr: 0.00125  max_mem: 6607M\n",
      "\u001b[32m[12/30 13:42:55 d2.utils.events]: \u001b[0m eta: 2:00:43  iter: 22159  total_loss: 0.9453  loss_cls: 0.1475  loss_box_reg: 0.1948  loss_mask: 0.2732  loss_rpn_cls: 0.06643  loss_rpn_loc: 0.1924  time: 0.6422  data_time: 0.4634  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:43:12 d2.utils.events]: \u001b[0m eta: 2:01:45  iter: 22179  total_loss: 0.9572  loss_cls: 0.1579  loss_box_reg: 0.1764  loss_mask: 0.2978  loss_rpn_cls: 0.0821  loss_rpn_loc: 0.2173  time: 0.6425  data_time: 0.6267  lr: 0.00125  max_mem: 6691M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 13:43:22 d2.utils.events]: \u001b[0m eta: 2:01:40  iter: 22199  total_loss: 0.8797  loss_cls: 0.1328  loss_box_reg: 0.219  loss_mask: 0.2558  loss_rpn_cls: 0.05748  loss_rpn_loc: 0.1966  time: 0.6423  data_time: 0.2861  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:43:35 d2.utils.events]: \u001b[0m eta: 2:00:57  iter: 22219  total_loss: 0.9138  loss_cls: 0.1705  loss_box_reg: 0.2247  loss_mask: 0.2796  loss_rpn_cls: 0.05381  loss_rpn_loc: 0.1893  time: 0.6423  data_time: 0.4081  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:43:50 d2.utils.events]: \u001b[0m eta: 2:02:01  iter: 22239  total_loss: 0.9533  loss_cls: 0.1833  loss_box_reg: 0.2214  loss_mask: 0.2793  loss_rpn_cls: 0.05919  loss_rpn_loc: 0.1911  time: 0.6425  data_time: 0.5416  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:44:04 d2.utils.events]: \u001b[0m eta: 2:02:57  iter: 22259  total_loss: 0.97  loss_cls: 0.1769  loss_box_reg: 0.2141  loss_mask: 0.2542  loss_rpn_cls: 0.0695  loss_rpn_loc: 0.2003  time: 0.6425  data_time: 0.4750  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:44:14 d2.utils.events]: \u001b[0m eta: 2:02:32  iter: 22279  total_loss: 0.8213  loss_cls: 0.1399  loss_box_reg: 0.1948  loss_mask: 0.239  loss_rpn_cls: 0.0474  loss_rpn_loc: 0.1665  time: 0.6424  data_time: 0.3026  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:44:26 d2.utils.events]: \u001b[0m eta: 2:04:04  iter: 22299  total_loss: 0.8783  loss_cls: 0.1574  loss_box_reg: 0.1967  loss_mask: 0.2283  loss_rpn_cls: 0.04369  loss_rpn_loc: 0.1875  time: 0.6422  data_time: 0.3609  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:44:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 13:44:27 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 13:44:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 13:44:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 13:44:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0445 s/iter. Eval: 0.0178 s/iter. Total: 0.0630 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 13:44:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.255002 (0.058125 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:44:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043532 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:44:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 13:44:31 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06823685848144319\n",
      "\u001b[32m[12/30 13:44:43 d2.utils.events]: \u001b[0m eta: 2:05:57  iter: 22319  total_loss: 1.133  loss_cls: 0.2744  loss_box_reg: 0.3036  loss_mask: 0.25  loss_rpn_cls: 0.06879  loss_rpn_loc: 0.1967  time: 0.6423  data_time: 0.4264  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:44:57 d2.utils.events]: \u001b[0m eta: 2:05:51  iter: 22339  total_loss: 0.9142  loss_cls: 0.1557  loss_box_reg: 0.2152  loss_mask: 0.2487  loss_rpn_cls: 0.06122  loss_rpn_loc: 0.1816  time: 0.6424  data_time: 0.4947  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:45:10 d2.utils.events]: \u001b[0m eta: 2:06:40  iter: 22359  total_loss: 0.9572  loss_cls: 0.1653  loss_box_reg: 0.2416  loss_mask: 0.263  loss_rpn_cls: 0.04432  loss_rpn_loc: 0.1825  time: 0.6424  data_time: 0.4384  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:45:23 d2.utils.events]: \u001b[0m eta: 2:07:46  iter: 22379  total_loss: 0.8991  loss_cls: 0.1397  loss_box_reg: 0.166  loss_mask: 0.2255  loss_rpn_cls: 0.04676  loss_rpn_loc: 0.1815  time: 0.6424  data_time: 0.4198  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:45:38 d2.utils.events]: \u001b[0m eta: 2:07:19  iter: 22399  total_loss: 0.839  loss_cls: 0.1404  loss_box_reg: 0.1887  loss_mask: 0.2486  loss_rpn_cls: 0.03715  loss_rpn_loc: 0.1879  time: 0.6425  data_time: 0.5290  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:45:51 d2.utils.events]: \u001b[0m eta: 2:06:24  iter: 22419  total_loss: 0.9672  loss_cls: 0.163  loss_box_reg: 0.2236  loss_mask: 0.2575  loss_rpn_cls: 0.05195  loss_rpn_loc: 0.1911  time: 0.6425  data_time: 0.4476  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:46:01 d2.utils.events]: \u001b[0m eta: 2:05:07  iter: 22439  total_loss: 0.9889  loss_cls: 0.1815  loss_box_reg: 0.2548  loss_mask: 0.2585  loss_rpn_cls: 0.06315  loss_rpn_loc: 0.1849  time: 0.6424  data_time: 0.3300  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:46:17 d2.utils.events]: \u001b[0m eta: 2:04:08  iter: 22459  total_loss: 0.9507  loss_cls: 0.199  loss_box_reg: 0.2171  loss_mask: 0.2731  loss_rpn_cls: 0.07711  loss_rpn_loc: 0.1881  time: 0.6426  data_time: 0.5660  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:46:33 d2.utils.events]: \u001b[0m eta: 2:04:30  iter: 22479  total_loss: 0.8502  loss_cls: 0.1493  loss_box_reg: 0.2024  loss_mask: 0.2769  loss_rpn_cls: 0.04437  loss_rpn_loc: 0.1839  time: 0.6428  data_time: 0.5646  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:46:49 d2.utils.events]: \u001b[0m eta: 2:04:51  iter: 22499  total_loss: 0.9427  loss_cls: 0.1518  loss_box_reg: 0.2161  loss_mask: 0.2564  loss_rpn_cls: 0.06228  loss_rpn_loc: 0.1823  time: 0.6430  data_time: 0.5836  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:47:00 d2.utils.events]: \u001b[0m eta: 2:03:52  iter: 22519  total_loss: 0.8311  loss_cls: 0.1284  loss_box_reg: 0.1938  loss_mask: 0.2617  loss_rpn_cls: 0.02751  loss_rpn_loc: 0.1695  time: 0.6429  data_time: 0.3370  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:47:11 d2.utils.events]: \u001b[0m eta: 2:02:10  iter: 22539  total_loss: 0.9474  loss_cls: 0.1568  loss_box_reg: 0.2007  loss_mask: 0.2782  loss_rpn_cls: 0.05465  loss_rpn_loc: 0.1804  time: 0.6427  data_time: 0.3150  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:47:23 d2.utils.events]: \u001b[0m eta: 2:01:10  iter: 22559  total_loss: 0.9507  loss_cls: 0.1761  loss_box_reg: 0.2197  loss_mask: 0.2551  loss_rpn_cls: 0.03857  loss_rpn_loc: 0.1758  time: 0.6426  data_time: 0.3861  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:47:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 13:47:37 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 13:47:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 13:47:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 13:47:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0440 s/iter. Eval: 0.0156 s/iter. Total: 0.0603 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 13:47:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.147350 (0.056203 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:47:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043177 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:47:41 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 13:47:41 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0635444303755027\n",
      "\u001b[32m[12/30 13:47:43 d2.utils.events]: \u001b[0m eta: 1:59:47  iter: 22579  total_loss: 1.047  loss_cls: 0.2198  loss_box_reg: 0.273  loss_mask: 0.2884  loss_rpn_cls: 0.08039  loss_rpn_loc: 0.1883  time: 0.6429  data_time: 0.5988  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:47:58 d2.utils.events]: \u001b[0m eta: 1:59:42  iter: 22599  total_loss: 0.9894  loss_cls: 0.1567  loss_box_reg: 0.2137  loss_mask: 0.2726  loss_rpn_cls: 0.07388  loss_rpn_loc: 0.1994  time: 0.6431  data_time: 0.5545  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:48:10 d2.utils.events]: \u001b[0m eta: 1:59:16  iter: 22619  total_loss: 1.018  loss_cls: 0.1691  loss_box_reg: 0.2337  loss_mask: 0.2616  loss_rpn_cls: 0.06537  loss_rpn_loc: 0.1969  time: 0.6430  data_time: 0.3983  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:48:26 d2.utils.events]: \u001b[0m eta: 1:59:32  iter: 22639  total_loss: 0.8574  loss_cls: 0.1453  loss_box_reg: 0.1948  loss_mask: 0.2627  loss_rpn_cls: 0.04775  loss_rpn_loc: 0.1697  time: 0.6432  data_time: 0.5733  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:48:45 d2.utils.events]: \u001b[0m eta: 2:00:11  iter: 22659  total_loss: 1.048  loss_cls: 0.2356  loss_box_reg: 0.1995  loss_mask: 0.3014  loss_rpn_cls: 0.07934  loss_rpn_loc: 0.2095  time: 0.6436  data_time: 0.7076  lr: 0.00125  max_mem: 6691M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 13:48:57 d2.utils.events]: \u001b[0m eta: 2:00:05  iter: 22679  total_loss: 0.989  loss_cls: 0.1808  loss_box_reg: 0.2061  loss_mask: 0.2803  loss_rpn_cls: 0.05002  loss_rpn_loc: 0.1892  time: 0.6436  data_time: 0.3678  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:49:07 d2.utils.events]: \u001b[0m eta: 1:59:02  iter: 22699  total_loss: 0.7826  loss_cls: 0.1446  loss_box_reg: 0.1642  loss_mask: 0.2152  loss_rpn_cls: 0.04952  loss_rpn_loc: 0.1772  time: 0.6434  data_time: 0.3061  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:49:19 d2.utils.events]: \u001b[0m eta: 1:59:30  iter: 22719  total_loss: 0.907  loss_cls: 0.1637  loss_box_reg: 0.2214  loss_mask: 0.2384  loss_rpn_cls: 0.05488  loss_rpn_loc: 0.1872  time: 0.6433  data_time: 0.3785  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:49:29 d2.utils.events]: \u001b[0m eta: 1:59:40  iter: 22739  total_loss: 0.7806  loss_cls: 0.1333  loss_box_reg: 0.2292  loss_mask: 0.2242  loss_rpn_cls: 0.02862  loss_rpn_loc: 0.157  time: 0.6431  data_time: 0.2939  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:49:42 d2.utils.events]: \u001b[0m eta: 1:59:35  iter: 22759  total_loss: 0.9008  loss_cls: 0.1587  loss_box_reg: 0.2181  loss_mask: 0.2674  loss_rpn_cls: 0.04849  loss_rpn_loc: 0.1893  time: 0.6431  data_time: 0.4086  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:49:53 d2.utils.events]: \u001b[0m eta: 1:59:29  iter: 22779  total_loss: 0.9458  loss_cls: 0.1719  loss_box_reg: 0.2306  loss_mask: 0.2716  loss_rpn_cls: 0.05039  loss_rpn_loc: 0.1899  time: 0.6430  data_time: 0.3759  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:50:06 d2.utils.events]: \u001b[0m eta: 1:59:53  iter: 22799  total_loss: 0.9173  loss_cls: 0.1571  loss_box_reg: 0.2073  loss_mask: 0.2631  loss_rpn_cls: 0.06319  loss_rpn_loc: 0.1787  time: 0.6430  data_time: 0.3926  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:50:19 d2.utils.events]: \u001b[0m eta: 1:59:28  iter: 22819  total_loss: 0.8791  loss_cls: 0.1764  loss_box_reg: 0.2118  loss_mask: 0.2311  loss_rpn_cls: 0.03757  loss_rpn_loc: 0.1757  time: 0.6430  data_time: 0.4507  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:50:35 d2.utils.events]: \u001b[0m eta: 1:57:43  iter: 22839  total_loss: 0.8776  loss_cls: 0.1445  loss_box_reg: 0.1645  loss_mask: 0.2177  loss_rpn_cls: 0.05473  loss_rpn_loc: 0.1927  time: 0.6432  data_time: 0.5867  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:50:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 13:50:39 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 13:50:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 13:50:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 13:50:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0444 s/iter. Eval: 0.0177 s/iter. Total: 0.0629 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 13:50:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.274385 (0.058471 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:50:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043333 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:50:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 13:50:43 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07320747785045016\n",
      "\u001b[32m[12/30 13:50:52 d2.utils.events]: \u001b[0m eta: 1:57:37  iter: 22859  total_loss: 0.9001  loss_cls: 0.1596  loss_box_reg: 0.2294  loss_mask: 0.267  loss_rpn_cls: 0.04694  loss_rpn_loc: 0.1838  time: 0.6432  data_time: 0.4279  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:51:05 d2.utils.events]: \u001b[0m eta: 1:57:15  iter: 22879  total_loss: 0.9513  loss_cls: 0.1665  loss_box_reg: 0.2145  loss_mask: 0.2464  loss_rpn_cls: 0.03913  loss_rpn_loc: 0.1773  time: 0.6432  data_time: 0.4327  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:51:21 d2.utils.events]: \u001b[0m eta: 1:57:10  iter: 22899  total_loss: 0.971  loss_cls: 0.1603  loss_box_reg: 0.1796  loss_mask: 0.2725  loss_rpn_cls: 0.05816  loss_rpn_loc: 0.1859  time: 0.6434  data_time: 0.5624  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:51:31 d2.utils.events]: \u001b[0m eta: 1:56:19  iter: 22919  total_loss: 0.7639  loss_cls: 0.1282  loss_box_reg: 0.2048  loss_mask: 0.2468  loss_rpn_cls: 0.03597  loss_rpn_loc: 0.1769  time: 0.6433  data_time: 0.3115  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:51:46 d2.utils.events]: \u001b[0m eta: 1:56:53  iter: 22939  total_loss: 0.9339  loss_cls: 0.1921  loss_box_reg: 0.1987  loss_mask: 0.2628  loss_rpn_cls: 0.07166  loss_rpn_loc: 0.2066  time: 0.6434  data_time: 0.5412  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:51:58 d2.utils.events]: \u001b[0m eta: 1:57:50  iter: 22959  total_loss: 0.9384  loss_cls: 0.1778  loss_box_reg: 0.2425  loss_mask: 0.2509  loss_rpn_cls: 0.05449  loss_rpn_loc: 0.1708  time: 0.6434  data_time: 0.3867  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:52:09 d2.utils.events]: \u001b[0m eta: 1:56:49  iter: 22979  total_loss: 0.734  loss_cls: 0.1045  loss_box_reg: 0.1943  loss_mask: 0.2326  loss_rpn_cls: 0.03817  loss_rpn_loc: 0.174  time: 0.6432  data_time: 0.3348  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:52:25 d2.utils.events]: \u001b[0m eta: 1:58:05  iter: 22999  total_loss: 1.03  loss_cls: 0.1819  loss_box_reg: 0.2257  loss_mask: 0.2612  loss_rpn_cls: 0.08348  loss_rpn_loc: 0.1918  time: 0.6434  data_time: 0.5571  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:52:35 d2.utils.events]: \u001b[0m eta: 1:57:01  iter: 23019  total_loss: 0.8807  loss_cls: 0.1757  loss_box_reg: 0.1777  loss_mask: 0.2394  loss_rpn_cls: 0.05569  loss_rpn_loc: 0.183  time: 0.6432  data_time: 0.3038  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:52:43 d2.utils.events]: \u001b[0m eta: 1:56:34  iter: 23039  total_loss: 0.7886  loss_cls: 0.1322  loss_box_reg: 0.1869  loss_mask: 0.2268  loss_rpn_cls: 0.03198  loss_rpn_loc: 0.1593  time: 0.6429  data_time: 0.2172  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:52:58 d2.utils.events]: \u001b[0m eta: 1:56:22  iter: 23059  total_loss: 0.8778  loss_cls: 0.1317  loss_box_reg: 0.2238  loss_mask: 0.252  loss_rpn_cls: 0.05395  loss_rpn_loc: 0.1861  time: 0.6430  data_time: 0.4911  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:53:15 d2.utils.events]: \u001b[0m eta: 1:57:57  iter: 23079  total_loss: 0.9896  loss_cls: 0.1793  loss_box_reg: 0.1976  loss_mask: 0.2625  loss_rpn_cls: 0.08059  loss_rpn_loc: 0.2115  time: 0.6433  data_time: 0.6370  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:53:28 d2.utils.events]: \u001b[0m eta: 1:58:12  iter: 23099  total_loss: 0.8457  loss_cls: 0.1487  loss_box_reg: 0.1694  loss_mask: 0.2472  loss_rpn_cls: 0.05178  loss_rpn_loc: 0.1893  time: 0.6433  data_time: 0.4280  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:53:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 13:53:40 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 13:53:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 13:53:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 13:53:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0450 s/iter. Eval: 0.0170 s/iter. Total: 0.0628 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 13:53:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.273949 (0.058463 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:53:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043478 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:53:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 13:53:44 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06861417984710136\n",
      "\u001b[32m[12/30 13:53:44 d2.utils.events]: \u001b[0m eta: 1:58:17  iter: 23119  total_loss: 0.9317  loss_cls: 0.1539  loss_box_reg: 0.1912  loss_mask: 0.2508  loss_rpn_cls: 0.05776  loss_rpn_loc: 0.1869  time: 0.6433  data_time: 0.3902  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:53:57 d2.utils.events]: \u001b[0m eta: 1:58:23  iter: 23139  total_loss: 0.8783  loss_cls: 0.1518  loss_box_reg: 0.2194  loss_mask: 0.2577  loss_rpn_cls: 0.05024  loss_rpn_loc: 0.2016  time: 0.6433  data_time: 0.4337  lr: 0.00125  max_mem: 6691M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 13:54:10 d2.utils.events]: \u001b[0m eta: 1:58:18  iter: 23159  total_loss: 0.9346  loss_cls: 0.1604  loss_box_reg: 0.2057  loss_mask: 0.2621  loss_rpn_cls: 0.06604  loss_rpn_loc: 0.1973  time: 0.6433  data_time: 0.4602  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:54:19 d2.utils.events]: \u001b[0m eta: 1:55:57  iter: 23179  total_loss: 0.7195  loss_cls: 0.1111  loss_box_reg: 0.1809  loss_mask: 0.2007  loss_rpn_cls: 0.0302  loss_rpn_loc: 0.168  time: 0.6430  data_time: 0.2355  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:54:35 d2.utils.events]: \u001b[0m eta: 1:57:34  iter: 23199  total_loss: 0.9682  loss_cls: 0.1713  loss_box_reg: 0.2031  loss_mask: 0.2685  loss_rpn_cls: 0.06571  loss_rpn_loc: 0.202  time: 0.6432  data_time: 0.5573  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:54:42 d2.utils.events]: \u001b[0m eta: 1:56:42  iter: 23219  total_loss: 0.8601  loss_cls: 0.1476  loss_box_reg: 0.2444  loss_mask: 0.2276  loss_rpn_cls: 0.0336  loss_rpn_loc: 0.172  time: 0.6429  data_time: 0.1904  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:55:00 d2.utils.events]: \u001b[0m eta: 1:57:25  iter: 23239  total_loss: 1.05  loss_cls: 0.2117  loss_box_reg: 0.2591  loss_mask: 0.2683  loss_rpn_cls: 0.07827  loss_rpn_loc: 0.1978  time: 0.6432  data_time: 0.6518  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:55:17 d2.utils.events]: \u001b[0m eta: 1:56:58  iter: 23259  total_loss: 1.013  loss_cls: 0.2004  loss_box_reg: 0.2362  loss_mask: 0.2752  loss_rpn_cls: 0.04977  loss_rpn_loc: 0.1772  time: 0.6435  data_time: 0.6335  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:55:27 d2.utils.events]: \u001b[0m eta: 1:56:34  iter: 23279  total_loss: 0.8875  loss_cls: 0.1598  loss_box_reg: 0.2082  loss_mask: 0.2483  loss_rpn_cls: 0.04782  loss_rpn_loc: 0.168  time: 0.6432  data_time: 0.2503  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:55:42 d2.utils.events]: \u001b[0m eta: 1:57:41  iter: 23299  total_loss: 1.05  loss_cls: 0.2119  loss_box_reg: 0.2132  loss_mask: 0.2692  loss_rpn_cls: 0.08516  loss_rpn_loc: 0.1946  time: 0.6434  data_time: 0.5689  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:55:58 d2.utils.events]: \u001b[0m eta: 1:56:00  iter: 23319  total_loss: 0.8651  loss_cls: 0.1525  loss_box_reg: 0.2245  loss_mask: 0.2737  loss_rpn_cls: 0.05757  loss_rpn_loc: 0.1829  time: 0.6436  data_time: 0.5466  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:56:13 d2.utils.events]: \u001b[0m eta: 1:56:35  iter: 23339  total_loss: 1.013  loss_cls: 0.1534  loss_box_reg: 0.2224  loss_mask: 0.286  loss_rpn_cls: 0.07098  loss_rpn_loc: 0.2072  time: 0.6437  data_time: 0.5340  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:56:22 d2.utils.events]: \u001b[0m eta: 1:56:13  iter: 23359  total_loss: 0.7777  loss_cls: 0.1429  loss_box_reg: 0.2097  loss_mask: 0.2235  loss_rpn_cls: 0.03762  loss_rpn_loc: 0.1584  time: 0.6435  data_time: 0.2386  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:56:33 d2.utils.events]: \u001b[0m eta: 1:56:48  iter: 23379  total_loss: 0.963  loss_cls: 0.179  loss_box_reg: 0.2363  loss_mask: 0.2662  loss_rpn_cls: 0.07212  loss_rpn_loc: 0.1859  time: 0.6434  data_time: 0.3607  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:56:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 13:56:40 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 13:56:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 13:56:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 13:56:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0450 s/iter. Eval: 0.0210 s/iter. Total: 0.0667 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 13:56:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.484724 (0.062227 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:56:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043683 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:56:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 13:56:44 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0747759404285031\n",
      "\u001b[32m[12/30 13:56:49 d2.utils.events]: \u001b[0m eta: 1:56:43  iter: 23399  total_loss: 0.8111  loss_cls: 0.1479  loss_box_reg: 0.196  loss_mask: 0.2372  loss_rpn_cls: 0.04577  loss_rpn_loc: 0.1766  time: 0.6433  data_time: 0.3470  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:56:59 d2.utils.events]: \u001b[0m eta: 1:56:38  iter: 23419  total_loss: 0.8112  loss_cls: 0.126  loss_box_reg: 0.2032  loss_mask: 0.2223  loss_rpn_cls: 0.03341  loss_rpn_loc: 0.1784  time: 0.6431  data_time: 0.3110  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:57:16 d2.utils.events]: \u001b[0m eta: 1:57:15  iter: 23439  total_loss: 0.9101  loss_cls: 0.1666  loss_box_reg: 0.2455  loss_mask: 0.2433  loss_rpn_cls: 0.05688  loss_rpn_loc: 0.1716  time: 0.6434  data_time: 0.6324  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:57:28 d2.utils.events]: \u001b[0m eta: 1:57:25  iter: 23459  total_loss: 1.001  loss_cls: 0.1798  loss_box_reg: 0.2277  loss_mask: 0.2538  loss_rpn_cls: 0.06256  loss_rpn_loc: 0.1825  time: 0.6433  data_time: 0.3957  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:57:44 d2.utils.events]: \u001b[0m eta: 1:58:07  iter: 23479  total_loss: 0.9765  loss_cls: 0.1936  loss_box_reg: 0.2522  loss_mask: 0.2699  loss_rpn_cls: 0.06361  loss_rpn_loc: 0.1986  time: 0.6435  data_time: 0.5270  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:57:55 d2.utils.events]: \u001b[0m eta: 1:57:09  iter: 23499  total_loss: 0.9119  loss_cls: 0.1578  loss_box_reg: 0.214  loss_mask: 0.242  loss_rpn_cls: 0.05094  loss_rpn_loc: 0.1856  time: 0.6434  data_time: 0.3821  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:58:08 d2.utils.events]: \u001b[0m eta: 1:57:43  iter: 23519  total_loss: 0.9497  loss_cls: 0.1756  loss_box_reg: 0.2141  loss_mask: 0.2659  loss_rpn_cls: 0.03195  loss_rpn_loc: 0.1683  time: 0.6434  data_time: 0.4302  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:58:22 d2.utils.events]: \u001b[0m eta: 1:57:58  iter: 23539  total_loss: 0.8809  loss_cls: 0.1687  loss_box_reg: 0.2361  loss_mask: 0.2706  loss_rpn_cls: 0.05343  loss_rpn_loc: 0.175  time: 0.6434  data_time: 0.4414  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:58:29 d2.utils.events]: \u001b[0m eta: 1:57:52  iter: 23559  total_loss: 0.6658  loss_cls: 0.09105  loss_box_reg: 0.172  loss_mask: 0.1897  loss_rpn_cls: 0.02609  loss_rpn_loc: 0.1785  time: 0.6431  data_time: 0.1809  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:58:40 d2.utils.events]: \u001b[0m eta: 1:57:40  iter: 23579  total_loss: 0.8565  loss_cls: 0.1573  loss_box_reg: 0.1927  loss_mask: 0.2402  loss_rpn_cls: 0.03213  loss_rpn_loc: 0.1649  time: 0.6429  data_time: 0.3214  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:58:55 d2.utils.events]: \u001b[0m eta: 1:57:45  iter: 23599  total_loss: 1.017  loss_cls: 0.1884  loss_box_reg: 0.2298  loss_mask: 0.2809  loss_rpn_cls: 0.07148  loss_rpn_loc: 0.1999  time: 0.6431  data_time: 0.5200  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:59:08 d2.utils.events]: \u001b[0m eta: 1:58:04  iter: 23619  total_loss: 0.954  loss_cls: 0.1685  loss_box_reg: 0.2083  loss_mask: 0.2776  loss_rpn_cls: 0.07247  loss_rpn_loc: 0.2039  time: 0.6431  data_time: 0.4656  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:59:25 d2.utils.events]: \u001b[0m eta: 1:58:16  iter: 23639  total_loss: 1.013  loss_cls: 0.1832  loss_box_reg: 0.2551  loss_mask: 0.2961  loss_rpn_cls: 0.07538  loss_rpn_loc: 0.198  time: 0.6434  data_time: 0.6096  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:59:37 d2.utils.events]: \u001b[0m eta: 1:57:33  iter: 23659  total_loss: 0.9055  loss_cls: 0.1706  loss_box_reg: 0.2268  loss_mask: 0.2562  loss_rpn_cls: 0.04153  loss_rpn_loc: 0.1798  time: 0.6434  data_time: 0.4026  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 13:59:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 13:59:40 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 13:59:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 13:59:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 13:59:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0445 s/iter. Eval: 0.0176 s/iter. Total: 0.0628 s/iter. ETA=0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 13:59:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.150897 (0.056266 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:59:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.042903 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 13:59:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 13:59:44 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06219784288336912\n",
      "\u001b[32m[12/30 13:59:53 d2.utils.events]: \u001b[0m eta: 1:57:20  iter: 23679  total_loss: 0.7261  loss_cls: 0.1012  loss_box_reg: 0.2188  loss_mask: 0.2324  loss_rpn_cls: 0.04548  loss_rpn_loc: 0.1825  time: 0.6433  data_time: 0.3557  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:00:04 d2.utils.events]: \u001b[0m eta: 1:57:22  iter: 23699  total_loss: 0.9468  loss_cls: 0.1475  loss_box_reg: 0.1961  loss_mask: 0.2876  loss_rpn_cls: 0.05123  loss_rpn_loc: 0.1829  time: 0.6431  data_time: 0.3406  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:00:18 d2.utils.events]: \u001b[0m eta: 1:57:11  iter: 23719  total_loss: 0.76  loss_cls: 0.1411  loss_box_reg: 0.1762  loss_mask: 0.2236  loss_rpn_cls: 0.06105  loss_rpn_loc: 0.1882  time: 0.6432  data_time: 0.4774  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:00:32 d2.utils.events]: \u001b[0m eta: 1:57:05  iter: 23739  total_loss: 1.028  loss_cls: 0.1582  loss_box_reg: 0.2163  loss_mask: 0.2567  loss_rpn_cls: 0.04867  loss_rpn_loc: 0.1958  time: 0.6433  data_time: 0.5292  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:00:44 d2.utils.events]: \u001b[0m eta: 1:57:00  iter: 23759  total_loss: 0.9287  loss_cls: 0.1868  loss_box_reg: 0.2591  loss_mask: 0.2723  loss_rpn_cls: 0.05123  loss_rpn_loc: 0.1736  time: 0.6433  data_time: 0.3867  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:00:58 d2.utils.events]: \u001b[0m eta: 1:56:47  iter: 23779  total_loss: 0.7094  loss_cls: 0.1308  loss_box_reg: 0.17  loss_mask: 0.1986  loss_rpn_cls: 0.04096  loss_rpn_loc: 0.1639  time: 0.6433  data_time: 0.4454  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:01:11 d2.utils.events]: \u001b[0m eta: 1:56:23  iter: 23799  total_loss: 0.8479  loss_cls: 0.1399  loss_box_reg: 0.1995  loss_mask: 0.2055  loss_rpn_cls: 0.03847  loss_rpn_loc: 0.1689  time: 0.6433  data_time: 0.4392  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:01:24 d2.utils.events]: \u001b[0m eta: 1:56:43  iter: 23819  total_loss: 0.9679  loss_cls: 0.1965  loss_box_reg: 0.2203  loss_mask: 0.2482  loss_rpn_cls: 0.07571  loss_rpn_loc: 0.2039  time: 0.6433  data_time: 0.4381  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:01:34 d2.utils.events]: \u001b[0m eta: 1:56:41  iter: 23839  total_loss: 0.8288  loss_cls: 0.149  loss_box_reg: 0.205  loss_mask: 0.2494  loss_rpn_cls: 0.03958  loss_rpn_loc: 0.1721  time: 0.6431  data_time: 0.3090  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:01:54 d2.utils.events]: \u001b[0m eta: 1:56:39  iter: 23859  total_loss: 0.952  loss_cls: 0.1918  loss_box_reg: 0.2578  loss_mask: 0.2504  loss_rpn_cls: 0.07359  loss_rpn_loc: 0.2145  time: 0.6436  data_time: 0.7319  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:02:05 d2.utils.events]: \u001b[0m eta: 1:56:54  iter: 23879  total_loss: 0.9965  loss_cls: 0.1927  loss_box_reg: 0.2378  loss_mask: 0.2626  loss_rpn_cls: 0.0458  loss_rpn_loc: 0.1936  time: 0.6435  data_time: 0.3607  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:02:13 d2.utils.events]: \u001b[0m eta: 1:56:21  iter: 23899  total_loss: 0.3014  loss_cls: 0.0001771  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04017  loss_rpn_loc: 0.1514  time: 0.6431  data_time: 0.1805  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:02:25 d2.utils.events]: \u001b[0m eta: 1:56:29  iter: 23919  total_loss: 0.8853  loss_cls: 0.1764  loss_box_reg: 0.1841  loss_mask: 0.2498  loss_rpn_cls: 0.06064  loss_rpn_loc: 0.1741  time: 0.6431  data_time: 0.3939  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:02:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:02:35 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:02:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:02:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:02:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0461 s/iter. Eval: 0.0182 s/iter. Total: 0.0651 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 14:02:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.298231 (0.058897 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:02:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043557 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:02:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 14:02:39 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06866738590946952\n",
      "\u001b[32m[12/30 14:02:42 d2.utils.events]: \u001b[0m eta: 1:56:14  iter: 23939  total_loss: 1.005  loss_cls: 0.1919  loss_box_reg: 0.2278  loss_mask: 0.2441  loss_rpn_cls: 0.04957  loss_rpn_loc: 0.1797  time: 0.6431  data_time: 0.4495  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:02:54 d2.utils.events]: \u001b[0m eta: 1:56:05  iter: 23959  total_loss: 0.9364  loss_cls: 0.1769  loss_box_reg: 0.234  loss_mask: 0.2733  loss_rpn_cls: 0.06747  loss_rpn_loc: 0.1938  time: 0.6431  data_time: 0.3942  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:03:04 d2.utils.events]: \u001b[0m eta: 1:55:09  iter: 23979  total_loss: 0.556  loss_cls: 0.07725  loss_box_reg: 0.1581  loss_mask: 0.1579  loss_rpn_cls: 0.02573  loss_rpn_loc: 0.1535  time: 0.6429  data_time: 0.2938  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:03:17 d2.utils.events]: \u001b[0m eta: 1:55:30  iter: 23999  total_loss: 0.946  loss_cls: 0.1657  loss_box_reg: 0.2264  loss_mask: 0.271  loss_rpn_cls: 0.06539  loss_rpn_loc: 0.1858  time: 0.6429  data_time: 0.4256  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:03:30 d2.utils.events]: \u001b[0m eta: 1:55:31  iter: 24019  total_loss: 1.031  loss_cls: 0.1912  loss_box_reg: 0.2237  loss_mask: 0.2789  loss_rpn_cls: 0.07178  loss_rpn_loc: 0.1964  time: 0.6429  data_time: 0.4514  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:03:45 d2.utils.events]: \u001b[0m eta: 1:55:57  iter: 24039  total_loss: 1.023  loss_cls: 0.1921  loss_box_reg: 0.2348  loss_mask: 0.2787  loss_rpn_cls: 0.08356  loss_rpn_loc: 0.2085  time: 0.6430  data_time: 0.5209  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:04:02 d2.utils.events]: \u001b[0m eta: 1:57:28  iter: 24059  total_loss: 1.026  loss_cls: 0.1716  loss_box_reg: 0.2156  loss_mask: 0.2937  loss_rpn_cls: 0.08123  loss_rpn_loc: 0.2279  time: 0.6433  data_time: 0.6106  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:04:16 d2.utils.events]: \u001b[0m eta: 1:55:46  iter: 24079  total_loss: 1.005  loss_cls: 0.1771  loss_box_reg: 0.2579  loss_mask: 0.2783  loss_rpn_cls: 0.06072  loss_rpn_loc: 0.2021  time: 0.6433  data_time: 0.4508  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:04:27 d2.utils.events]: \u001b[0m eta: 1:55:29  iter: 24099  total_loss: 1.003  loss_cls: 0.146  loss_box_reg: 0.2312  loss_mask: 0.2464  loss_rpn_cls: 0.06048  loss_rpn_loc: 0.1977  time: 0.6432  data_time: 0.3362  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:04:38 d2.utils.events]: \u001b[0m eta: 1:55:20  iter: 24119  total_loss: 0.7327  loss_cls: 0.1121  loss_box_reg: 0.14  loss_mask: 0.2335  loss_rpn_cls: 0.03542  loss_rpn_loc: 0.1698  time: 0.6431  data_time: 0.3481  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:04:51 d2.utils.events]: \u001b[0m eta: 1:55:09  iter: 24139  total_loss: 0.9389  loss_cls: 0.1502  loss_box_reg: 0.1636  loss_mask: 0.2384  loss_rpn_cls: 0.05947  loss_rpn_loc: 0.1958  time: 0.6431  data_time: 0.4655  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:05:02 d2.utils.events]: \u001b[0m eta: 1:55:03  iter: 24159  total_loss: 0.9558  loss_cls: 0.1682  loss_box_reg: 0.2222  loss_mask: 0.2465  loss_rpn_cls: 0.04945  loss_rpn_loc: 0.185  time: 0.6430  data_time: 0.3166  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:05:13 d2.utils.events]: \u001b[0m eta: 1:55:19  iter: 24179  total_loss: 0.8875  loss_cls: 0.1565  loss_box_reg: 0.1903  loss_mask: 0.2522  loss_rpn_cls: 0.04602  loss_rpn_loc: 0.1743  time: 0.6429  data_time: 0.3446  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:05:28 d2.utils.events]: \u001b[0m eta: 1:55:02  iter: 24199  total_loss: 1.015  loss_cls: 0.22  loss_box_reg: 0.2549  loss_mask: 0.2614  loss_rpn_cls: 0.08036  loss_rpn_loc: 0.2029  time: 0.6430  data_time: 0.5402  lr: 0.00125  max_mem: 6691M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 14:05:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:05:33 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:05:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:05:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:05:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0173 s/iter. Total: 0.0628 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 14:05:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.315901 (0.059213 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:05:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043891 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:05:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 14:05:37 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06887057817933553\n",
      "\u001b[32m[12/30 14:05:46 d2.utils.events]: \u001b[0m eta: 1:55:54  iter: 24219  total_loss: 0.9292  loss_cls: 0.1625  loss_box_reg: 0.188  loss_mask: 0.2759  loss_rpn_cls: 0.05477  loss_rpn_loc: 0.1858  time: 0.6431  data_time: 0.4923  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:06:01 d2.utils.events]: \u001b[0m eta: 1:54:51  iter: 24239  total_loss: 0.9714  loss_cls: 0.1679  loss_box_reg: 0.2316  loss_mask: 0.2867  loss_rpn_cls: 0.03873  loss_rpn_loc: 0.1764  time: 0.6432  data_time: 0.5012  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:06:12 d2.utils.events]: \u001b[0m eta: 1:54:45  iter: 24259  total_loss: 0.8924  loss_cls: 0.1345  loss_box_reg: 0.1921  loss_mask: 0.2484  loss_rpn_cls: 0.048  loss_rpn_loc: 0.18  time: 0.6432  data_time: 0.3957  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:06:23 d2.utils.events]: \u001b[0m eta: 1:54:43  iter: 24279  total_loss: 0.8873  loss_cls: 0.1516  loss_box_reg: 0.1691  loss_mask: 0.2399  loss_rpn_cls: 0.04318  loss_rpn_loc: 0.1584  time: 0.6430  data_time: 0.3296  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:06:38 d2.utils.events]: \u001b[0m eta: 1:54:38  iter: 24299  total_loss: 1.025  loss_cls: 0.2033  loss_box_reg: 0.2363  loss_mask: 0.273  loss_rpn_cls: 0.06686  loss_rpn_loc: 0.1798  time: 0.6431  data_time: 0.5284  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:06:53 d2.utils.events]: \u001b[0m eta: 1:54:33  iter: 24319  total_loss: 0.9577  loss_cls: 0.1432  loss_box_reg: 0.1722  loss_mask: 0.2643  loss_rpn_cls: 0.06612  loss_rpn_loc: 0.1987  time: 0.6432  data_time: 0.4878  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:07:04 d2.utils.events]: \u001b[0m eta: 1:54:15  iter: 24339  total_loss: 0.6921  loss_cls: 0.1088  loss_box_reg: 0.1515  loss_mask: 0.2208  loss_rpn_cls: 0.03923  loss_rpn_loc: 0.1755  time: 0.6431  data_time: 0.3448  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:07:14 d2.utils.events]: \u001b[0m eta: 1:54:19  iter: 24359  total_loss: 0.8676  loss_cls: 0.1289  loss_box_reg: 0.2176  loss_mask: 0.2613  loss_rpn_cls: 0.04965  loss_rpn_loc: 0.1781  time: 0.6430  data_time: 0.3408  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:07:27 d2.utils.events]: \u001b[0m eta: 1:54:04  iter: 24379  total_loss: 0.9332  loss_cls: 0.1622  loss_box_reg: 0.2216  loss_mask: 0.2644  loss_rpn_cls: 0.05854  loss_rpn_loc: 0.1681  time: 0.6430  data_time: 0.4003  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:07:37 d2.utils.events]: \u001b[0m eta: 1:54:06  iter: 24399  total_loss: 0.9213  loss_cls: 0.1679  loss_box_reg: 0.2422  loss_mask: 0.2447  loss_rpn_cls: 0.04471  loss_rpn_loc: 0.1816  time: 0.6428  data_time: 0.3078  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:07:51 d2.utils.events]: \u001b[0m eta: 1:54:49  iter: 24419  total_loss: 0.9271  loss_cls: 0.165  loss_box_reg: 0.1905  loss_mask: 0.2608  loss_rpn_cls: 0.03981  loss_rpn_loc: 0.1628  time: 0.6429  data_time: 0.4699  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:08:07 d2.utils.events]: \u001b[0m eta: 1:55:22  iter: 24439  total_loss: 0.9858  loss_cls: 0.1768  loss_box_reg: 0.2327  loss_mask: 0.2632  loss_rpn_cls: 0.06214  loss_rpn_loc: 0.1995  time: 0.6430  data_time: 0.5704  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:08:20 d2.utils.events]: \u001b[0m eta: 1:53:50  iter: 24459  total_loss: 0.8876  loss_cls: 0.1602  loss_box_reg: 0.2268  loss_mask: 0.2772  loss_rpn_cls: 0.0473  loss_rpn_loc: 0.1739  time: 0.6430  data_time: 0.4345  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:08:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:08:32 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:08:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:08:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:08:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0006 s/iter. Inference: 0.0442 s/iter. Eval: 0.0166 s/iter. Total: 0.0614 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 14:08:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.220519 (0.057509 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:08:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043407 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:08:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 14:08:35 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06944758053393454\n",
      "\u001b[32m[12/30 14:08:35 d2.utils.events]: \u001b[0m eta: 1:55:11  iter: 24479  total_loss: 0.9656  loss_cls: 0.1855  loss_box_reg: 0.2318  loss_mask: 0.2747  loss_rpn_cls: 0.04982  loss_rpn_loc: 0.1794  time: 0.6430  data_time: 0.3813  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:08:49 d2.utils.events]: \u001b[0m eta: 1:55:05  iter: 24499  total_loss: 1.006  loss_cls: 0.1748  loss_box_reg: 0.2238  loss_mask: 0.2672  loss_rpn_cls: 0.06851  loss_rpn_loc: 0.1926  time: 0.6430  data_time: 0.4518  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:09:01 d2.utils.events]: \u001b[0m eta: 1:54:13  iter: 24519  total_loss: 0.7968  loss_cls: 0.1316  loss_box_reg: 0.2034  loss_mask: 0.2372  loss_rpn_cls: 0.03852  loss_rpn_loc: 0.1748  time: 0.6430  data_time: 0.3652  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:09:15 d2.utils.events]: \u001b[0m eta: 1:53:28  iter: 24539  total_loss: 1.039  loss_cls: 0.2166  loss_box_reg: 0.2815  loss_mask: 0.2461  loss_rpn_cls: 0.0728  loss_rpn_loc: 0.1959  time: 0.6431  data_time: 0.5229  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:09:23 d2.utils.events]: \u001b[0m eta: 1:53:08  iter: 24559  total_loss: 0.8475  loss_cls: 0.1505  loss_box_reg: 0.1993  loss_mask: 0.2159  loss_rpn_cls: 0.03605  loss_rpn_loc: 0.1517  time: 0.6427  data_time: 0.1750  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:09:37 d2.utils.events]: \u001b[0m eta: 1:53:33  iter: 24579  total_loss: 0.8904  loss_cls: 0.1591  loss_box_reg: 0.2119  loss_mask: 0.2612  loss_rpn_cls: 0.04589  loss_rpn_loc: 0.185  time: 0.6428  data_time: 0.4995  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:09:49 d2.utils.events]: \u001b[0m eta: 1:51:58  iter: 24599  total_loss: 0.7831  loss_cls: 0.1119  loss_box_reg: 0.2004  loss_mask: 0.2382  loss_rpn_cls: 0.04246  loss_rpn_loc: 0.1701  time: 0.6428  data_time: 0.3688  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:10:01 d2.utils.events]: \u001b[0m eta: 1:51:29  iter: 24619  total_loss: 0.8967  loss_cls: 0.1594  loss_box_reg: 0.2082  loss_mask: 0.2457  loss_rpn_cls: 0.05132  loss_rpn_loc: 0.1804  time: 0.6427  data_time: 0.3851  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:10:16 d2.utils.events]: \u001b[0m eta: 1:51:25  iter: 24639  total_loss: 1.044  loss_cls: 0.1851  loss_box_reg: 0.2599  loss_mask: 0.2715  loss_rpn_cls: 0.06938  loss_rpn_loc: 0.2066  time: 0.6428  data_time: 0.5072  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:10:29 d2.utils.events]: \u001b[0m eta: 1:51:20  iter: 24659  total_loss: 0.6992  loss_cls: 0.1081  loss_box_reg: 0.1296  loss_mask: 0.2227  loss_rpn_cls: 0.03704  loss_rpn_loc: 0.1679  time: 0.6428  data_time: 0.4467  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:10:43 d2.utils.events]: \u001b[0m eta: 1:51:37  iter: 24679  total_loss: 0.9757  loss_cls: 0.1739  loss_box_reg: 0.2  loss_mask: 0.2572  loss_rpn_cls: 0.0656  loss_rpn_loc: 0.1974  time: 0.6429  data_time: 0.5058  lr: 0.00125  max_mem: 6691M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 14:10:56 d2.utils.events]: \u001b[0m eta: 1:52:07  iter: 24699  total_loss: 1.045  loss_cls: 0.1656  loss_box_reg: 0.2495  loss_mask: 0.2751  loss_rpn_cls: 0.06342  loss_rpn_loc: 0.1956  time: 0.6429  data_time: 0.4010  lr: 0.00125  max_mem: 6691M\n",
      "\u001b[32m[12/30 14:11:08 d2.utils.events]: \u001b[0m eta: 1:51:04  iter: 24719  total_loss: 0.8992  loss_cls: 0.1455  loss_box_reg: 0.223  loss_mask: 0.265  loss_rpn_cls: 0.04802  loss_rpn_loc: 0.1874  time: 0.6428  data_time: 0.3885  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:11:18 d2.utils.events]: \u001b[0m eta: 1:50:58  iter: 24739  total_loss: 0.596  loss_cls: 0.08497  loss_box_reg: 0.1622  loss_mask: 0.1953  loss_rpn_cls: 0.04  loss_rpn_loc: 0.1744  time: 0.6427  data_time: 0.3221  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:11:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:11:29 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:11:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:11:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:11:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0459 s/iter. Eval: 0.0181 s/iter. Total: 0.0648 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 14:11:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.364687 (0.060084 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:11:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.044062 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:11:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 14:11:33 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06751223379817173\n",
      "\u001b[32m[12/30 14:11:36 d2.utils.events]: \u001b[0m eta: 1:51:16  iter: 24759  total_loss: 1.05  loss_cls: 0.1976  loss_box_reg: 0.2577  loss_mask: 0.291  loss_rpn_cls: 0.05969  loss_rpn_loc: 0.2106  time: 0.6427  data_time: 0.4585  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:11:48 d2.utils.events]: \u001b[0m eta: 1:51:41  iter: 24779  total_loss: 0.76  loss_cls: 0.1251  loss_box_reg: 0.1835  loss_mask: 0.2346  loss_rpn_cls: 0.04902  loss_rpn_loc: 0.1576  time: 0.6427  data_time: 0.3991  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:12:01 d2.utils.events]: \u001b[0m eta: 1:51:36  iter: 24799  total_loss: 0.8984  loss_cls: 0.1455  loss_box_reg: 0.2131  loss_mask: 0.2445  loss_rpn_cls: 0.05241  loss_rpn_loc: 0.1899  time: 0.6427  data_time: 0.4445  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:12:15 d2.utils.events]: \u001b[0m eta: 1:50:38  iter: 24819  total_loss: 0.8101  loss_cls: 0.1322  loss_box_reg: 0.1755  loss_mask: 0.2472  loss_rpn_cls: 0.0443  loss_rpn_loc: 0.1748  time: 0.6428  data_time: 0.4708  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:12:26 d2.utils.events]: \u001b[0m eta: 1:49:59  iter: 24839  total_loss: 0.7999  loss_cls: 0.1155  loss_box_reg: 0.1501  loss_mask: 0.2494  loss_rpn_cls: 0.03703  loss_rpn_loc: 0.1544  time: 0.6427  data_time: 0.3473  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:12:41 d2.utils.events]: \u001b[0m eta: 1:49:54  iter: 24859  total_loss: 1.062  loss_cls: 0.2169  loss_box_reg: 0.2546  loss_mask: 0.2715  loss_rpn_cls: 0.09776  loss_rpn_loc: 0.1956  time: 0.6428  data_time: 0.5256  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:12:55 d2.utils.events]: \u001b[0m eta: 1:50:07  iter: 24879  total_loss: 0.9349  loss_cls: 0.1713  loss_box_reg: 0.2078  loss_mask: 0.261  loss_rpn_cls: 0.06616  loss_rpn_loc: 0.1831  time: 0.6429  data_time: 0.4932  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:13:09 d2.utils.events]: \u001b[0m eta: 1:52:04  iter: 24899  total_loss: 0.976  loss_cls: 0.1574  loss_box_reg: 0.2399  loss_mask: 0.2674  loss_rpn_cls: 0.06319  loss_rpn_loc: 0.185  time: 0.6429  data_time: 0.4558  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:13:23 d2.utils.events]: \u001b[0m eta: 1:51:16  iter: 24919  total_loss: 0.9165  loss_cls: 0.1788  loss_box_reg: 0.2104  loss_mask: 0.2689  loss_rpn_cls: 0.06099  loss_rpn_loc: 0.1831  time: 0.6430  data_time: 0.4675  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:13:38 d2.utils.events]: \u001b[0m eta: 1:50:06  iter: 24939  total_loss: 0.867  loss_cls: 0.1492  loss_box_reg: 0.2126  loss_mask: 0.2485  loss_rpn_cls: 0.04667  loss_rpn_loc: 0.1712  time: 0.6431  data_time: 0.5355  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:13:52 d2.utils.events]: \u001b[0m eta: 1:49:46  iter: 24959  total_loss: 0.9211  loss_cls: 0.1546  loss_box_reg: 0.1966  loss_mask: 0.2343  loss_rpn_cls: 0.0392  loss_rpn_loc: 0.1822  time: 0.6431  data_time: 0.4729  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:14:00 d2.utils.events]: \u001b[0m eta: 1:49:55  iter: 24979  total_loss: 0.773  loss_cls: 0.1414  loss_box_reg: 0.2152  loss_mask: 0.2349  loss_rpn_cls: 0.03774  loss_rpn_loc: 0.1612  time: 0.6429  data_time: 0.2052  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:14:14 d2.utils.events]: \u001b[0m eta: 1:50:42  iter: 24999  total_loss: 0.9819  loss_cls: 0.1718  loss_box_reg: 0.2182  loss_mask: 0.2844  loss_rpn_cls: 0.06126  loss_rpn_loc: 0.2103  time: 0.6430  data_time: 0.5078  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:14:25 d2.utils.events]: \u001b[0m eta: 1:50:07  iter: 25019  total_loss: 1.011  loss_cls: 0.1999  loss_box_reg: 0.2369  loss_mask: 0.2334  loss_rpn_cls: 0.04929  loss_rpn_loc: 0.1877  time: 0.6429  data_time: 0.3455  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:14:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:14:27 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:14:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:14:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:14:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0447 s/iter. Eval: 0.0176 s/iter. Total: 0.0630 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 14:14:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.298095 (0.058895 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:14:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043791 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:14:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 14:14:31 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07106532922595385\n",
      "\u001b[32m[12/30 14:14:46 d2.utils.events]: \u001b[0m eta: 1:50:44  iter: 25039  total_loss: 1.025  loss_cls: 0.1889  loss_box_reg: 0.209  loss_mask: 0.2846  loss_rpn_cls: 0.07875  loss_rpn_loc: 0.2201  time: 0.6431  data_time: 0.6069  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:15:00 d2.utils.events]: \u001b[0m eta: 1:50:24  iter: 25059  total_loss: 1.034  loss_cls: 0.1749  loss_box_reg: 0.2042  loss_mask: 0.2777  loss_rpn_cls: 0.06846  loss_rpn_loc: 0.2153  time: 0.6432  data_time: 0.4945  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:15:15 d2.utils.events]: \u001b[0m eta: 1:51:34  iter: 25079  total_loss: 0.9711  loss_cls: 0.1614  loss_box_reg: 0.2348  loss_mask: 0.2677  loss_rpn_cls: 0.06989  loss_rpn_loc: 0.1808  time: 0.6433  data_time: 0.5252  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:15:28 d2.utils.events]: \u001b[0m eta: 1:52:14  iter: 25099  total_loss: 0.8586  loss_cls: 0.152  loss_box_reg: 0.2124  loss_mask: 0.2705  loss_rpn_cls: 0.03341  loss_rpn_loc: 0.1748  time: 0.6433  data_time: 0.4045  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:15:38 d2.utils.events]: \u001b[0m eta: 1:52:29  iter: 25119  total_loss: 0.7595  loss_cls: 0.1488  loss_box_reg: 0.1903  loss_mask: 0.2189  loss_rpn_cls: 0.03422  loss_rpn_loc: 0.1707  time: 0.6431  data_time: 0.3221  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:15:48 d2.utils.events]: \u001b[0m eta: 1:52:04  iter: 25139  total_loss: 0.6395  loss_cls: 0.09885  loss_box_reg: 0.1831  loss_mask: 0.1985  loss_rpn_cls: 0.03762  loss_rpn_loc: 0.1656  time: 0.6429  data_time: 0.2635  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:16:05 d2.utils.events]: \u001b[0m eta: 1:52:18  iter: 25159  total_loss: 0.9194  loss_cls: 0.1539  loss_box_reg: 0.2052  loss_mask: 0.2642  loss_rpn_cls: 0.06116  loss_rpn_loc: 0.1973  time: 0.6432  data_time: 0.6517  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 14:16:18 d2.utils.events]: \u001b[0m eta: 1:53:03  iter: 25179  total_loss: 0.8692  loss_cls: 0.1566  loss_box_reg: 0.1431  loss_mask: 0.2518  loss_rpn_cls: 0.063  loss_rpn_loc: 0.1927  time: 0.6432  data_time: 0.4029  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:16:33 d2.utils.events]: \u001b[0m eta: 1:51:47  iter: 25199  total_loss: 0.8647  loss_cls: 0.1516  loss_box_reg: 0.2043  loss_mask: 0.2697  loss_rpn_cls: 0.05829  loss_rpn_loc: 0.1789  time: 0.6433  data_time: 0.5090  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:16:44 d2.utils.events]: \u001b[0m eta: 1:52:02  iter: 25219  total_loss: 0.9665  loss_cls: 0.2  loss_box_reg: 0.2449  loss_mask: 0.2739  loss_rpn_cls: 0.0495  loss_rpn_loc: 0.1654  time: 0.6432  data_time: 0.3741  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:17:00 d2.utils.events]: \u001b[0m eta: 1:50:51  iter: 25239  total_loss: 1.037  loss_cls: 0.1829  loss_box_reg: 0.2335  loss_mask: 0.2583  loss_rpn_cls: 0.07869  loss_rpn_loc: 0.2044  time: 0.6434  data_time: 0.5709  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:17:09 d2.utils.events]: \u001b[0m eta: 1:49:45  iter: 25259  total_loss: 0.6413  loss_cls: 0.1037  loss_box_reg: 0.1579  loss_mask: 0.1824  loss_rpn_cls: 0.0318  loss_rpn_loc: 0.1667  time: 0.6432  data_time: 0.2619  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:17:23 d2.utils.events]: \u001b[0m eta: 1:49:52  iter: 25279  total_loss: 0.8974  loss_cls: 0.1542  loss_box_reg: 0.2011  loss_mask: 0.2677  loss_rpn_cls: 0.03545  loss_rpn_loc: 0.1719  time: 0.6432  data_time: 0.4720  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:17:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:17:36 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:17:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:17:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:17:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0447 s/iter. Eval: 0.0179 s/iter. Total: 0.0633 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 14:17:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.317720 (0.059245 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:17:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043513 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:17:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 14:17:40 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06957985701953831\n",
      "\u001b[32m[12/30 14:17:42 d2.utils.events]: \u001b[0m eta: 1:49:20  iter: 25299  total_loss: 0.9865  loss_cls: 0.1776  loss_box_reg: 0.2533  loss_mask: 0.2645  loss_rpn_cls: 0.08056  loss_rpn_loc: 0.1808  time: 0.6434  data_time: 0.5299  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:17:52 d2.utils.events]: \u001b[0m eta: 1:48:08  iter: 25319  total_loss: 0.787  loss_cls: 0.1281  loss_box_reg: 0.1638  loss_mask: 0.2132  loss_rpn_cls: 0.02686  loss_rpn_loc: 0.1787  time: 0.6432  data_time: 0.2838  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:18:01 d2.utils.events]: \u001b[0m eta: 1:47:36  iter: 25339  total_loss: 0.7303  loss_cls: 0.1165  loss_box_reg: 0.1518  loss_mask: 0.2209  loss_rpn_cls: 0.03394  loss_rpn_loc: 0.1615  time: 0.6430  data_time: 0.2654  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:18:15 d2.utils.events]: \u001b[0m eta: 1:47:41  iter: 25359  total_loss: 1.002  loss_cls: 0.1735  loss_box_reg: 0.2458  loss_mask: 0.2607  loss_rpn_cls: 0.06003  loss_rpn_loc: 0.2028  time: 0.6430  data_time: 0.4679  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:18:28 d2.utils.events]: \u001b[0m eta: 1:46:47  iter: 25379  total_loss: 0.9436  loss_cls: 0.1633  loss_box_reg: 0.241  loss_mask: 0.2571  loss_rpn_cls: 0.031  loss_rpn_loc: 0.169  time: 0.6430  data_time: 0.4174  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:18:43 d2.utils.events]: \u001b[0m eta: 1:46:47  iter: 25399  total_loss: 0.9399  loss_cls: 0.193  loss_box_reg: 0.2579  loss_mask: 0.2659  loss_rpn_cls: 0.05086  loss_rpn_loc: 0.198  time: 0.6431  data_time: 0.5183  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:18:56 d2.utils.events]: \u001b[0m eta: 1:47:20  iter: 25419  total_loss: 0.9598  loss_cls: 0.1542  loss_box_reg: 0.2136  loss_mask: 0.272  loss_rpn_cls: 0.0583  loss_rpn_loc: 0.2069  time: 0.6432  data_time: 0.4413  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:19:10 d2.utils.events]: \u001b[0m eta: 1:46:37  iter: 25439  total_loss: 0.8159  loss_cls: 0.1484  loss_box_reg: 0.174  loss_mask: 0.2318  loss_rpn_cls: 0.0661  loss_rpn_loc: 0.2081  time: 0.6432  data_time: 0.4623  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:19:22 d2.utils.events]: \u001b[0m eta: 1:46:47  iter: 25459  total_loss: 0.8983  loss_cls: 0.1618  loss_box_reg: 0.1987  loss_mask: 0.2544  loss_rpn_cls: 0.05582  loss_rpn_loc: 0.1975  time: 0.6432  data_time: 0.4297  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:19:38 d2.utils.events]: \u001b[0m eta: 1:45:24  iter: 25479  total_loss: 1.033  loss_cls: 0.1701  loss_box_reg: 0.1917  loss_mask: 0.2602  loss_rpn_cls: 0.05065  loss_rpn_loc: 0.1839  time: 0.6434  data_time: 0.5842  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:19:53 d2.utils.events]: \u001b[0m eta: 1:46:16  iter: 25499  total_loss: 0.8826  loss_cls: 0.1464  loss_box_reg: 0.1732  loss_mask: 0.2568  loss_rpn_cls: 0.0529  loss_rpn_loc: 0.1908  time: 0.6435  data_time: 0.5203  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:20:06 d2.utils.events]: \u001b[0m eta: 1:45:54  iter: 25519  total_loss: 0.8497  loss_cls: 0.1663  loss_box_reg: 0.2281  loss_mask: 0.2464  loss_rpn_cls: 0.03525  loss_rpn_loc: 0.1627  time: 0.6434  data_time: 0.3970  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:20:19 d2.utils.events]: \u001b[0m eta: 1:45:48  iter: 25539  total_loss: 0.9672  loss_cls: 0.1757  loss_box_reg: 0.1992  loss_mask: 0.272  loss_rpn_cls: 0.05976  loss_rpn_loc: 0.175  time: 0.6435  data_time: 0.4726  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:20:29 d2.utils.events]: \u001b[0m eta: 1:46:21  iter: 25559  total_loss: 0.941  loss_cls: 0.197  loss_box_reg: 0.2379  loss_mask: 0.2473  loss_rpn_cls: 0.04303  loss_rpn_loc: 0.1666  time: 0.6433  data_time: 0.2807  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:20:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:20:36 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:20:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:20:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:20:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0442 s/iter. Eval: 0.0170 s/iter. Total: 0.0620 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 14:20:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.223016 (0.057554 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:20:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043328 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:20:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 14:20:39 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06831481990864259\n",
      "\u001b[32m[12/30 14:20:47 d2.utils.events]: \u001b[0m eta: 1:45:38  iter: 25579  total_loss: 0.777  loss_cls: 0.1468  loss_box_reg: 0.2035  loss_mask: 0.2576  loss_rpn_cls: 0.04835  loss_rpn_loc: 0.1623  time: 0.6434  data_time: 0.4989  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:20:59 d2.utils.events]: \u001b[0m eta: 1:45:50  iter: 25599  total_loss: 0.6372  loss_cls: 0.09474  loss_box_reg: 0.1737  loss_mask: 0.1967  loss_rpn_cls: 0.02743  loss_rpn_loc: 0.1626  time: 0.6433  data_time: 0.3572  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:21:14 d2.utils.events]: \u001b[0m eta: 1:46:22  iter: 25619  total_loss: 1.06  loss_cls: 0.2016  loss_box_reg: 0.2828  loss_mask: 0.2692  loss_rpn_cls: 0.06209  loss_rpn_loc: 0.2146  time: 0.6435  data_time: 0.5634  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:21:28 d2.utils.events]: \u001b[0m eta: 1:45:04  iter: 25639  total_loss: 0.9581  loss_cls: 0.1683  loss_box_reg: 0.1833  loss_mask: 0.2414  loss_rpn_cls: 0.04524  loss_rpn_loc: 0.1911  time: 0.6435  data_time: 0.4824  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 14:21:38 d2.utils.events]: \u001b[0m eta: 1:45:17  iter: 25659  total_loss: 0.8097  loss_cls: 0.1429  loss_box_reg: 0.2071  loss_mask: 0.236  loss_rpn_cls: 0.04321  loss_rpn_loc: 0.1731  time: 0.6434  data_time: 0.2864  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:21:51 d2.utils.events]: \u001b[0m eta: 1:45:26  iter: 25679  total_loss: 0.8855  loss_cls: 0.1616  loss_box_reg: 0.2303  loss_mask: 0.2557  loss_rpn_cls: 0.04216  loss_rpn_loc: 0.1747  time: 0.6434  data_time: 0.4113  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:22:05 d2.utils.events]: \u001b[0m eta: 1:44:35  iter: 25699  total_loss: 0.7594  loss_cls: 0.1333  loss_box_reg: 0.2069  loss_mask: 0.2219  loss_rpn_cls: 0.03871  loss_rpn_loc: 0.1698  time: 0.6434  data_time: 0.4754  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:22:14 d2.utils.events]: \u001b[0m eta: 1:44:30  iter: 25719  total_loss: 0.6248  loss_cls: 0.09862  loss_box_reg: 0.1617  loss_mask: 0.2089  loss_rpn_cls: 0.0263  loss_rpn_loc: 0.1412  time: 0.6432  data_time: 0.2564  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:22:27 d2.utils.events]: \u001b[0m eta: 1:44:57  iter: 25739  total_loss: 0.8726  loss_cls: 0.1514  loss_box_reg: 0.1975  loss_mask: 0.2593  loss_rpn_cls: 0.04357  loss_rpn_loc: 0.1795  time: 0.6432  data_time: 0.4486  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:22:45 d2.utils.events]: \u001b[0m eta: 1:44:33  iter: 25759  total_loss: 0.9365  loss_cls: 0.1805  loss_box_reg: 0.2249  loss_mask: 0.2761  loss_rpn_cls: 0.06502  loss_rpn_loc: 0.1974  time: 0.6435  data_time: 0.6547  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:23:00 d2.utils.events]: \u001b[0m eta: 1:45:04  iter: 25779  total_loss: 0.9519  loss_cls: 0.1481  loss_box_reg: 0.1997  loss_mask: 0.2588  loss_rpn_cls: 0.07901  loss_rpn_loc: 0.1992  time: 0.6436  data_time: 0.5569  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:23:13 d2.utils.events]: \u001b[0m eta: 1:44:59  iter: 25799  total_loss: 0.9782  loss_cls: 0.1619  loss_box_reg: 0.2314  loss_mask: 0.2731  loss_rpn_cls: 0.0735  loss_rpn_loc: 0.2023  time: 0.6436  data_time: 0.4170  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:23:24 d2.utils.events]: \u001b[0m eta: 1:44:53  iter: 25819  total_loss: 0.7925  loss_cls: 0.1412  loss_box_reg: 0.1679  loss_mask: 0.2251  loss_rpn_cls: 0.04708  loss_rpn_loc: 0.1768  time: 0.6435  data_time: 0.3422  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:23:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:23:37 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:23:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:23:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:23:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0440 s/iter. Eval: 0.0164 s/iter. Total: 0.0611 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 14:23:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.284964 (0.058660 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:23:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043318 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:23:41 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 14:23:41 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07001957763746355\n",
      "\u001b[32m[12/30 14:23:41 d2.utils.events]: \u001b[0m eta: 1:45:08  iter: 25839  total_loss: 0.8801  loss_cls: 0.1308  loss_box_reg: 0.2032  loss_mask: 0.2646  loss_rpn_cls: 0.05085  loss_rpn_loc: 0.1778  time: 0.6435  data_time: 0.4487  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:23:51 d2.utils.events]: \u001b[0m eta: 1:44:40  iter: 25859  total_loss: 0.8013  loss_cls: 0.1398  loss_box_reg: 0.196  loss_mask: 0.2384  loss_rpn_cls: 0.03169  loss_rpn_loc: 0.1574  time: 0.6434  data_time: 0.2709  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:24:03 d2.utils.events]: \u001b[0m eta: 1:43:53  iter: 25879  total_loss: 0.5765  loss_cls: 0.08304  loss_box_reg: 0.1195  loss_mask: 0.1751  loss_rpn_cls: 0.0331  loss_rpn_loc: 0.1686  time: 0.6433  data_time: 0.3989  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:24:16 d2.utils.events]: \u001b[0m eta: 1:43:14  iter: 25899  total_loss: 0.7594  loss_cls: 0.119  loss_box_reg: 0.168  loss_mask: 0.2338  loss_rpn_cls: 0.03085  loss_rpn_loc: 0.169  time: 0.6433  data_time: 0.4313  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:24:28 d2.utils.events]: \u001b[0m eta: 1:43:09  iter: 25919  total_loss: 0.9093  loss_cls: 0.163  loss_box_reg: 0.2237  loss_mask: 0.2665  loss_rpn_cls: 0.06423  loss_rpn_loc: 0.1893  time: 0.6433  data_time: 0.3869  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:24:42 d2.utils.events]: \u001b[0m eta: 1:43:53  iter: 25939  total_loss: 0.9513  loss_cls: 0.1792  loss_box_reg: 0.2389  loss_mask: 0.2602  loss_rpn_cls: 0.06053  loss_rpn_loc: 0.1918  time: 0.6434  data_time: 0.5123  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:24:55 d2.utils.events]: \u001b[0m eta: 1:44:00  iter: 25959  total_loss: 0.8856  loss_cls: 0.1652  loss_box_reg: 0.2156  loss_mask: 0.2656  loss_rpn_cls: 0.06367  loss_rpn_loc: 0.1706  time: 0.6433  data_time: 0.4015  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:25:10 d2.utils.events]: \u001b[0m eta: 1:45:28  iter: 25979  total_loss: 1.038  loss_cls: 0.1862  loss_box_reg: 0.246  loss_mask: 0.2714  loss_rpn_cls: 0.08736  loss_rpn_loc: 0.209  time: 0.6435  data_time: 0.5404  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:25:20 d2.utils.events]: \u001b[0m eta: 1:44:10  iter: 25999  total_loss: 0.7254  loss_cls: 0.1055  loss_box_reg: 0.1924  loss_mask: 0.2073  loss_rpn_cls: 0.03017  loss_rpn_loc: 0.1605  time: 0.6433  data_time: 0.2676  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:25:33 d2.utils.events]: \u001b[0m eta: 1:44:01  iter: 26019  total_loss: 0.8558  loss_cls: 0.1488  loss_box_reg: 0.1905  loss_mask: 0.2629  loss_rpn_cls: 0.03334  loss_rpn_loc: 0.1711  time: 0.6433  data_time: 0.4755  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:25:45 d2.utils.events]: \u001b[0m eta: 1:43:29  iter: 26039  total_loss: 0.8418  loss_cls: 0.1433  loss_box_reg: 0.23  loss_mask: 0.2662  loss_rpn_cls: 0.0418  loss_rpn_loc: 0.1741  time: 0.6432  data_time: 0.3575  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:26:01 d2.utils.events]: \u001b[0m eta: 1:43:48  iter: 26059  total_loss: 1.016  loss_cls: 0.1672  loss_box_reg: 0.2481  loss_mask: 0.2817  loss_rpn_cls: 0.06852  loss_rpn_loc: 0.1795  time: 0.6434  data_time: 0.5843  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:26:13 d2.utils.events]: \u001b[0m eta: 1:43:19  iter: 26079  total_loss: 0.8759  loss_cls: 0.1611  loss_box_reg: 0.2398  loss_mask: 0.2635  loss_rpn_cls: 0.05844  loss_rpn_loc: 0.1818  time: 0.6434  data_time: 0.3532  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:26:27 d2.utils.events]: \u001b[0m eta: 1:43:37  iter: 26099  total_loss: 0.9685  loss_cls: 0.1858  loss_box_reg: 0.228  loss_mask: 0.2605  loss_rpn_cls: 0.06056  loss_rpn_loc: 0.1821  time: 0.6434  data_time: 0.4782  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:26:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:26:33 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:26:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:26:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:26:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0160 s/iter. Total: 0.0614 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 14:26:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.215469 (0.057419 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:26:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043326 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:26:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 14:26:37 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06933271731933925\n",
      "\u001b[32m[12/30 14:26:41 d2.utils.events]: \u001b[0m eta: 1:43:32  iter: 26119  total_loss: 0.7491  loss_cls: 0.1363  loss_box_reg: 0.1751  loss_mask: 0.2198  loss_rpn_cls: 0.02905  loss_rpn_loc: 0.1605  time: 0.6433  data_time: 0.3217  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 14:26:50 d2.utils.events]: \u001b[0m eta: 1:43:27  iter: 26139  total_loss: 0.401  loss_cls: 0.03609  loss_box_reg: 0.07271  loss_mask: 0.09513  loss_rpn_cls: 0.02287  loss_rpn_loc: 0.1454  time: 0.6431  data_time: 0.2539  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:27:01 d2.utils.events]: \u001b[0m eta: 1:43:47  iter: 26159  total_loss: 0.8913  loss_cls: 0.1548  loss_box_reg: 0.2261  loss_mask: 0.2537  loss_rpn_cls: 0.04838  loss_rpn_loc: 0.1887  time: 0.6430  data_time: 0.3432  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:27:18 d2.utils.events]: \u001b[0m eta: 1:44:35  iter: 26179  total_loss: 0.9974  loss_cls: 0.2154  loss_box_reg: 0.245  loss_mask: 0.2766  loss_rpn_cls: 0.07671  loss_rpn_loc: 0.2023  time: 0.6432  data_time: 0.5913  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:27:34 d2.utils.events]: \u001b[0m eta: 1:45:05  iter: 26199  total_loss: 0.9197  loss_cls: 0.1855  loss_box_reg: 0.2223  loss_mask: 0.2839  loss_rpn_cls: 0.05916  loss_rpn_loc: 0.1923  time: 0.6434  data_time: 0.5857  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:27:43 d2.utils.events]: \u001b[0m eta: 1:44:20  iter: 26219  total_loss: 0.7612  loss_cls: 0.115  loss_box_reg: 0.2024  loss_mask: 0.225  loss_rpn_cls: 0.03555  loss_rpn_loc: 0.1746  time: 0.6432  data_time: 0.2730  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:27:55 d2.utils.events]: \u001b[0m eta: 1:43:26  iter: 26239  total_loss: 0.7552  loss_cls: 0.1102  loss_box_reg: 0.1884  loss_mask: 0.2116  loss_rpn_cls: 0.023  loss_rpn_loc: 0.1641  time: 0.6431  data_time: 0.3609  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:28:09 d2.utils.events]: \u001b[0m eta: 1:43:59  iter: 26259  total_loss: 0.908  loss_cls: 0.1622  loss_box_reg: 0.1886  loss_mask: 0.2711  loss_rpn_cls: 0.05139  loss_rpn_loc: 0.1808  time: 0.6432  data_time: 0.5267  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:28:24 d2.utils.events]: \u001b[0m eta: 1:43:54  iter: 26279  total_loss: 1.017  loss_cls: 0.1613  loss_box_reg: 0.2311  loss_mask: 0.2767  loss_rpn_cls: 0.05509  loss_rpn_loc: 0.1837  time: 0.6433  data_time: 0.5108  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:28:34 d2.utils.events]: \u001b[0m eta: 1:43:49  iter: 26299  total_loss: 0.847  loss_cls: 0.1718  loss_box_reg: 0.2353  loss_mask: 0.2374  loss_rpn_cls: 0.03498  loss_rpn_loc: 0.1818  time: 0.6432  data_time: 0.3090  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:28:49 d2.utils.events]: \u001b[0m eta: 1:44:31  iter: 26319  total_loss: 1.071  loss_cls: 0.189  loss_box_reg: 0.2293  loss_mask: 0.2831  loss_rpn_cls: 0.06874  loss_rpn_loc: 0.1999  time: 0.6432  data_time: 0.4795  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:29:01 d2.utils.events]: \u001b[0m eta: 1:45:56  iter: 26339  total_loss: 0.9053  loss_cls: 0.1637  loss_box_reg: 0.2032  loss_mask: 0.2643  loss_rpn_cls: 0.05617  loss_rpn_loc: 0.1961  time: 0.6432  data_time: 0.4016  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:29:15 d2.utils.events]: \u001b[0m eta: 1:44:34  iter: 26359  total_loss: 0.921  loss_cls: 0.136  loss_box_reg: 0.1682  loss_mask: 0.2464  loss_rpn_cls: 0.05082  loss_rpn_loc: 0.18  time: 0.6433  data_time: 0.4889  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:29:28 d2.utils.events]: \u001b[0m eta: 1:44:25  iter: 26379  total_loss: 0.5456  loss_cls: 0.06558  loss_box_reg: 0.1308  loss_mask: 0.1805  loss_rpn_cls: 0.02976  loss_rpn_loc: 0.1693  time: 0.6432  data_time: 0.4180  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:29:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:29:30 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:29:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:29:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:29:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0190 s/iter. Total: 0.0645 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 14:29:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.311286 (0.059130 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:29:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043753 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:29:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 14:29:34 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07154437046972534\n",
      "\u001b[32m[12/30 14:29:42 d2.utils.events]: \u001b[0m eta: 1:43:42  iter: 26399  total_loss: 0.4575  loss_cls: 0.03949  loss_box_reg: 0.08636  loss_mask: 0.1218  loss_rpn_cls: 0.03556  loss_rpn_loc: 0.17  time: 0.6431  data_time: 0.2958  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:30:00 d2.utils.events]: \u001b[0m eta: 1:43:49  iter: 26419  total_loss: 1.162  loss_cls: 0.1895  loss_box_reg: 0.2687  loss_mask: 0.2779  loss_rpn_cls: 0.1131  loss_rpn_loc: 0.2306  time: 0.6434  data_time: 0.6665  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:30:09 d2.utils.events]: \u001b[0m eta: 1:43:12  iter: 26439  total_loss: 0.8373  loss_cls: 0.1459  loss_box_reg: 0.2107  loss_mask: 0.2196  loss_rpn_cls: 0.03008  loss_rpn_loc: 0.1636  time: 0.6432  data_time: 0.2294  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:30:24 d2.utils.events]: \u001b[0m eta: 1:43:07  iter: 26459  total_loss: 0.9214  loss_cls: 0.1733  loss_box_reg: 0.2117  loss_mask: 0.2675  loss_rpn_cls: 0.05973  loss_rpn_loc: 0.1838  time: 0.6433  data_time: 0.5454  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:30:37 d2.utils.events]: \u001b[0m eta: 1:43:33  iter: 26479  total_loss: 0.8838  loss_cls: 0.1478  loss_box_reg: 0.202  loss_mask: 0.2422  loss_rpn_cls: 0.04977  loss_rpn_loc: 0.1644  time: 0.6433  data_time: 0.4124  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:30:45 d2.utils.events]: \u001b[0m eta: 1:42:56  iter: 26499  total_loss: 0.9143  loss_cls: 0.1677  loss_box_reg: 0.2083  loss_mask: 0.2487  loss_rpn_cls: 0.03779  loss_rpn_loc: 0.1625  time: 0.6430  data_time: 0.2242  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:30:59 d2.utils.events]: \u001b[0m eta: 1:43:38  iter: 26519  total_loss: 0.9172  loss_cls: 0.163  loss_box_reg: 0.2329  loss_mask: 0.2738  loss_rpn_cls: 0.06316  loss_rpn_loc: 0.1826  time: 0.6431  data_time: 0.4287  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:31:10 d2.utils.events]: \u001b[0m eta: 1:43:32  iter: 26539  total_loss: 0.8721  loss_cls: 0.1337  loss_box_reg: 0.2107  loss_mask: 0.2378  loss_rpn_cls: 0.0527  loss_rpn_loc: 0.1726  time: 0.6430  data_time: 0.3565  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:31:19 d2.utils.events]: \u001b[0m eta: 1:42:23  iter: 26559  total_loss: 0.5641  loss_cls: 0.08739  loss_box_reg: 0.1228  loss_mask: 0.198  loss_rpn_cls: 0.03663  loss_rpn_loc: 0.1733  time: 0.6428  data_time: 0.2790  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:31:34 d2.utils.events]: \u001b[0m eta: 1:42:45  iter: 26579  total_loss: 0.8664  loss_cls: 0.1456  loss_box_reg: 0.1643  loss_mask: 0.2848  loss_rpn_cls: 0.0588  loss_rpn_loc: 0.1797  time: 0.6429  data_time: 0.5222  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:31:45 d2.utils.events]: \u001b[0m eta: 1:42:15  iter: 26599  total_loss: 0.8569  loss_cls: 0.1322  loss_box_reg: 0.2034  loss_mask: 0.2452  loss_rpn_cls: 0.04234  loss_rpn_loc: 0.1768  time: 0.6428  data_time: 0.3451  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:32:01 d2.utils.events]: \u001b[0m eta: 1:42:25  iter: 26619  total_loss: 0.9215  loss_cls: 0.1564  loss_box_reg: 0.2058  loss_mask: 0.2741  loss_rpn_cls: 0.063  loss_rpn_loc: 0.194  time: 0.6429  data_time: 0.5437  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:32:13 d2.utils.events]: \u001b[0m eta: 1:43:46  iter: 26639  total_loss: 0.9818  loss_cls: 0.1935  loss_box_reg: 0.2577  loss_mask: 0.2698  loss_rpn_cls: 0.05786  loss_rpn_loc: 0.1971  time: 0.6429  data_time: 0.3854  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:32:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:32:23 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:32:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:32:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:32:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0444 s/iter. Eval: 0.0194 s/iter. Total: 0.0645 s/iter. ETA=0:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 14:32:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.322935 (0.059338 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:32:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043329 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:32:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 14:32:27 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07145482368501613\n",
      "\u001b[32m[12/30 14:32:29 d2.utils.events]: \u001b[0m eta: 1:43:11  iter: 26659  total_loss: 0.8953  loss_cls: 0.1482  loss_box_reg: 0.23  loss_mask: 0.2664  loss_rpn_cls: 0.04863  loss_rpn_loc: 0.1719  time: 0.6429  data_time: 0.3912  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:32:40 d2.utils.events]: \u001b[0m eta: 1:43:36  iter: 26679  total_loss: 0.8718  loss_cls: 0.1469  loss_box_reg: 0.2131  loss_mask: 0.2476  loss_rpn_cls: 0.03214  loss_rpn_loc: 0.1667  time: 0.6428  data_time: 0.3575  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:32:54 d2.utils.events]: \u001b[0m eta: 1:44:42  iter: 26699  total_loss: 0.8709  loss_cls: 0.1563  loss_box_reg: 0.1989  loss_mask: 0.2602  loss_rpn_cls: 0.04532  loss_rpn_loc: 0.1763  time: 0.6428  data_time: 0.4498  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:33:09 d2.utils.events]: \u001b[0m eta: 1:45:44  iter: 26719  total_loss: 0.9944  loss_cls: 0.1959  loss_box_reg: 0.2292  loss_mask: 0.2861  loss_rpn_cls: 0.074  loss_rpn_loc: 0.1928  time: 0.6429  data_time: 0.5350  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:33:16 d2.utils.events]: \u001b[0m eta: 1:44:54  iter: 26739  total_loss: 0.7214  loss_cls: 0.1209  loss_box_reg: 0.1649  loss_mask: 0.2116  loss_rpn_cls: 0.03557  loss_rpn_loc: 0.1671  time: 0.6426  data_time: 0.1555  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:33:29 d2.utils.events]: \u001b[0m eta: 1:45:08  iter: 26759  total_loss: 0.9971  loss_cls: 0.1936  loss_box_reg: 0.218  loss_mask: 0.283  loss_rpn_cls: 0.05817  loss_rpn_loc: 0.1769  time: 0.6426  data_time: 0.4039  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:33:41 d2.utils.events]: \u001b[0m eta: 1:43:58  iter: 26779  total_loss: 0.4609  loss_cls: 0.04992  loss_box_reg: 0.08382  loss_mask: 0.1147  loss_rpn_cls: 0.03211  loss_rpn_loc: 0.1657  time: 0.6426  data_time: 0.3855  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:34:00 d2.utils.events]: \u001b[0m eta: 1:44:38  iter: 26799  total_loss: 0.9737  loss_cls: 0.1655  loss_box_reg: 0.2044  loss_mask: 0.2781  loss_rpn_cls: 0.09636  loss_rpn_loc: 0.2046  time: 0.6429  data_time: 0.7231  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:34:10 d2.utils.events]: \u001b[0m eta: 1:44:50  iter: 26819  total_loss: 0.8956  loss_cls: 0.1707  loss_box_reg: 0.2201  loss_mask: 0.2587  loss_rpn_cls: 0.03692  loss_rpn_loc: 0.1678  time: 0.6428  data_time: 0.3171  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:34:21 d2.utils.events]: \u001b[0m eta: 1:44:13  iter: 26839  total_loss: 0.7949  loss_cls: 0.1244  loss_box_reg: 0.2027  loss_mask: 0.2244  loss_rpn_cls: 0.02861  loss_rpn_loc: 0.1719  time: 0.6427  data_time: 0.3536  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:34:33 d2.utils.events]: \u001b[0m eta: 1:44:22  iter: 26859  total_loss: 0.9157  loss_cls: 0.149  loss_box_reg: 0.2197  loss_mask: 0.2555  loss_rpn_cls: 0.04843  loss_rpn_loc: 0.1729  time: 0.6426  data_time: 0.3700  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:34:48 d2.utils.events]: \u001b[0m eta: 1:45:12  iter: 26879  total_loss: 1.006  loss_cls: 0.2011  loss_box_reg: 0.223  loss_mask: 0.2693  loss_rpn_cls: 0.05652  loss_rpn_loc: 0.1906  time: 0.6427  data_time: 0.5014  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:35:00 d2.utils.events]: \u001b[0m eta: 1:45:38  iter: 26899  total_loss: 0.8488  loss_cls: 0.1653  loss_box_reg: 0.2074  loss_mask: 0.2324  loss_rpn_cls: 0.03613  loss_rpn_loc: 0.1734  time: 0.6427  data_time: 0.4033  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:35:12 d2.utils.events]: \u001b[0m eta: 1:45:01  iter: 26919  total_loss: 0.736  loss_cls: 0.123  loss_box_reg: 0.2091  loss_mask: 0.2001  loss_rpn_cls: 0.04797  loss_rpn_loc: 0.1707  time: 0.6426  data_time: 0.3692  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:35:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:35:15 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:35:15 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:35:15 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:35:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0458 s/iter. Eval: 0.0187 s/iter. Total: 0.0653 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 14:35:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.268754 (0.058371 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:35:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043357 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:35:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 14:35:18 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06811809612564247\n",
      "\u001b[32m[12/30 14:35:25 d2.utils.events]: \u001b[0m eta: 1:44:31  iter: 26939  total_loss: 0.7526  loss_cls: 0.1019  loss_box_reg: 0.1827  loss_mask: 0.2219  loss_rpn_cls: 0.03945  loss_rpn_loc: 0.1861  time: 0.6425  data_time: 0.2760  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:35:39 d2.utils.events]: \u001b[0m eta: 1:44:30  iter: 26959  total_loss: 0.9628  loss_cls: 0.1661  loss_box_reg: 0.2245  loss_mask: 0.2841  loss_rpn_cls: 0.06644  loss_rpn_loc: 0.1971  time: 0.6425  data_time: 0.4495  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:35:49 d2.utils.events]: \u001b[0m eta: 1:43:50  iter: 26979  total_loss: 0.7754  loss_cls: 0.131  loss_box_reg: 0.193  loss_mask: 0.2368  loss_rpn_cls: 0.04115  loss_rpn_loc: 0.1574  time: 0.6423  data_time: 0.3003  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:36:05 d2.utils.events]: \u001b[0m eta: 1:44:19  iter: 26999  total_loss: 0.9466  loss_cls: 0.1932  loss_box_reg: 0.2291  loss_mask: 0.2712  loss_rpn_cls: 0.05145  loss_rpn_loc: 0.2  time: 0.6425  data_time: 0.5493  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:36:18 d2.utils.events]: \u001b[0m eta: 1:44:34  iter: 27019  total_loss: 0.9014  loss_cls: 0.1499  loss_box_reg: 0.2438  loss_mask: 0.2723  loss_rpn_cls: 0.0536  loss_rpn_loc: 0.1808  time: 0.6425  data_time: 0.4303  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:36:29 d2.utils.events]: \u001b[0m eta: 1:44:12  iter: 27039  total_loss: 0.8554  loss_cls: 0.1571  loss_box_reg: 0.2303  loss_mask: 0.2586  loss_rpn_cls: 0.0314  loss_rpn_loc: 0.1584  time: 0.6424  data_time: 0.3568  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:36:44 d2.utils.events]: \u001b[0m eta: 1:43:58  iter: 27059  total_loss: 0.8211  loss_cls: 0.1518  loss_box_reg: 0.2022  loss_mask: 0.2577  loss_rpn_cls: 0.03783  loss_rpn_loc: 0.1819  time: 0.6425  data_time: 0.5215  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:37:00 d2.utils.events]: \u001b[0m eta: 1:43:53  iter: 27079  total_loss: 0.921  loss_cls: 0.1711  loss_box_reg: 0.2117  loss_mask: 0.2617  loss_rpn_cls: 0.0663  loss_rpn_loc: 0.1915  time: 0.6427  data_time: 0.5882  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:37:11 d2.utils.events]: \u001b[0m eta: 1:43:34  iter: 27099  total_loss: 0.6927  loss_cls: 0.1364  loss_box_reg: 0.1857  loss_mask: 0.199  loss_rpn_cls: 0.03219  loss_rpn_loc: 0.1516  time: 0.6426  data_time: 0.3153  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:37:23 d2.utils.events]: \u001b[0m eta: 1:43:42  iter: 27119  total_loss: 0.9933  loss_cls: 0.1877  loss_box_reg: 0.2106  loss_mask: 0.2596  loss_rpn_cls: 0.06235  loss_rpn_loc: 0.1905  time: 0.6425  data_time: 0.4205  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:37:39 d2.utils.events]: \u001b[0m eta: 1:44:24  iter: 27139  total_loss: 1.067  loss_cls: 0.178  loss_box_reg: 0.2659  loss_mask: 0.291  loss_rpn_cls: 0.07595  loss_rpn_loc: 0.1986  time: 0.6427  data_time: 0.5587  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:37:54 d2.utils.events]: \u001b[0m eta: 1:44:18  iter: 27159  total_loss: 0.9281  loss_cls: 0.1537  loss_box_reg: 0.1981  loss_mask: 0.2406  loss_rpn_cls: 0.05825  loss_rpn_loc: 0.1814  time: 0.6428  data_time: 0.5501  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:38:10 d2.utils.events]: \u001b[0m eta: 1:43:34  iter: 27179  total_loss: 0.9689  loss_cls: 0.178  loss_box_reg: 0.2139  loss_mask: 0.2786  loss_rpn_cls: 0.05677  loss_rpn_loc: 0.1969  time: 0.6430  data_time: 0.5756  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 14:38:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:38:23 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:38:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:38:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:38:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0159 s/iter. Total: 0.0615 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 14:38:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.267863 (0.058355 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:38:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043642 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:38:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 14:38:27 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06797937676207966\n",
      "\u001b[32m[12/30 14:38:27 d2.utils.events]: \u001b[0m eta: 1:43:20  iter: 27199  total_loss: 1.015  loss_cls: 0.1586  loss_box_reg: 0.2163  loss_mask: 0.2552  loss_rpn_cls: 0.05368  loss_rpn_loc: 0.1738  time: 0.6430  data_time: 0.4440  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:38:40 d2.utils.events]: \u001b[0m eta: 1:43:12  iter: 27219  total_loss: 0.7589  loss_cls: 0.1273  loss_box_reg: 0.1815  loss_mask: 0.2208  loss_rpn_cls: 0.02552  loss_rpn_loc: 0.1622  time: 0.6430  data_time: 0.4406  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:38:57 d2.utils.events]: \u001b[0m eta: 1:44:13  iter: 27239  total_loss: 0.9719  loss_cls: 0.2006  loss_box_reg: 0.2138  loss_mask: 0.2426  loss_rpn_cls: 0.07509  loss_rpn_loc: 0.1893  time: 0.6432  data_time: 0.6299  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:39:09 d2.utils.events]: \u001b[0m eta: 1:44:49  iter: 27259  total_loss: 0.8655  loss_cls: 0.1739  loss_box_reg: 0.2018  loss_mask: 0.2358  loss_rpn_cls: 0.05433  loss_rpn_loc: 0.1874  time: 0.6432  data_time: 0.3931  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:39:23 d2.utils.events]: \u001b[0m eta: 1:44:46  iter: 27279  total_loss: 0.9642  loss_cls: 0.1872  loss_box_reg: 0.2331  loss_mask: 0.2537  loss_rpn_cls: 0.05897  loss_rpn_loc: 0.1637  time: 0.6432  data_time: 0.4596  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:39:32 d2.utils.events]: \u001b[0m eta: 1:43:57  iter: 27299  total_loss: 0.791  loss_cls: 0.1345  loss_box_reg: 0.2024  loss_mask: 0.2331  loss_rpn_cls: 0.03935  loss_rpn_loc: 0.1701  time: 0.6430  data_time: 0.2427  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:39:45 d2.utils.events]: \u001b[0m eta: 1:44:39  iter: 27319  total_loss: 0.9429  loss_cls: 0.1753  loss_box_reg: 0.2284  loss_mask: 0.2637  loss_rpn_cls: 0.04956  loss_rpn_loc: 0.1843  time: 0.6430  data_time: 0.4528  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:39:59 d2.utils.events]: \u001b[0m eta: 1:44:39  iter: 27339  total_loss: 0.9095  loss_cls: 0.1832  loss_box_reg: 0.2087  loss_mask: 0.2552  loss_rpn_cls: 0.06041  loss_rpn_loc: 0.2089  time: 0.6431  data_time: 0.4681  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:40:15 d2.utils.events]: \u001b[0m eta: 1:45:38  iter: 27359  total_loss: 0.9464  loss_cls: 0.1612  loss_box_reg: 0.233  loss_mask: 0.2499  loss_rpn_cls: 0.07749  loss_rpn_loc: 0.1875  time: 0.6432  data_time: 0.5634  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:40:28 d2.utils.events]: \u001b[0m eta: 1:45:43  iter: 27379  total_loss: 0.8769  loss_cls: 0.1416  loss_box_reg: 0.2334  loss_mask: 0.2653  loss_rpn_cls: 0.05237  loss_rpn_loc: 0.1722  time: 0.6432  data_time: 0.4269  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:40:43 d2.utils.events]: \u001b[0m eta: 1:45:57  iter: 27399  total_loss: 1.069  loss_cls: 0.1912  loss_box_reg: 0.2642  loss_mask: 0.2921  loss_rpn_cls: 0.07591  loss_rpn_loc: 0.2087  time: 0.6434  data_time: 0.5289  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:40:51 d2.utils.events]: \u001b[0m eta: 1:43:24  iter: 27419  total_loss: 0.8074  loss_cls: 0.1345  loss_box_reg: 0.2017  loss_mask: 0.2308  loss_rpn_cls: 0.02753  loss_rpn_loc: 0.1613  time: 0.6431  data_time: 0.1941  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:41:01 d2.utils.events]: \u001b[0m eta: 1:42:55  iter: 27439  total_loss: 0.7399  loss_cls: 0.1186  loss_box_reg: 0.1723  loss_mask: 0.2242  loss_rpn_cls: 0.02706  loss_rpn_loc: 0.1698  time: 0.6430  data_time: 0.3094  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:41:12 d2.utils.events]: \u001b[0m eta: 1:42:23  iter: 27459  total_loss: 0.7033  loss_cls: 0.1077  loss_box_reg: 0.1991  loss_mask: 0.2343  loss_rpn_cls: 0.02722  loss_rpn_loc: 0.1611  time: 0.6428  data_time: 0.3123  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:41:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:41:19 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:41:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:41:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:41:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0447 s/iter. Eval: 0.0184 s/iter. Total: 0.0638 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 14:41:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.299962 (0.058928 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:41:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043743 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:41:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 14:41:23 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07004857413961063\n",
      "\u001b[32m[12/30 14:41:28 d2.utils.events]: \u001b[0m eta: 1:43:28  iter: 27479  total_loss: 0.9146  loss_cls: 0.1562  loss_box_reg: 0.1967  loss_mask: 0.2737  loss_rpn_cls: 0.05147  loss_rpn_loc: 0.1814  time: 0.6428  data_time: 0.4104  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:41:41 d2.utils.events]: \u001b[0m eta: 1:44:17  iter: 27499  total_loss: 0.8927  loss_cls: 0.1516  loss_box_reg: 0.2257  loss_mask: 0.2492  loss_rpn_cls: 0.03848  loss_rpn_loc: 0.1797  time: 0.6428  data_time: 0.4526  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:41:55 d2.utils.events]: \u001b[0m eta: 1:43:32  iter: 27519  total_loss: 0.7884  loss_cls: 0.146  loss_box_reg: 0.1869  loss_mask: 0.2453  loss_rpn_cls: 0.0274  loss_rpn_loc: 0.1737  time: 0.6429  data_time: 0.4530  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:42:05 d2.utils.events]: \u001b[0m eta: 1:41:53  iter: 27539  total_loss: 0.4504  loss_cls: 0.04394  loss_box_reg: 0.06803  loss_mask: 0.08711  loss_rpn_cls: 0.03805  loss_rpn_loc: 0.1742  time: 0.6428  data_time: 0.3292  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:42:20 d2.utils.events]: \u001b[0m eta: 1:43:38  iter: 27559  total_loss: 1.069  loss_cls: 0.1926  loss_box_reg: 0.1988  loss_mask: 0.2752  loss_rpn_cls: 0.06632  loss_rpn_loc: 0.1885  time: 0.6428  data_time: 0.5087  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:42:33 d2.utils.events]: \u001b[0m eta: 1:43:42  iter: 27579  total_loss: 0.9057  loss_cls: 0.1646  loss_box_reg: 0.1929  loss_mask: 0.2662  loss_rpn_cls: 0.06191  loss_rpn_loc: 0.1817  time: 0.6429  data_time: 0.4394  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:42:51 d2.utils.events]: \u001b[0m eta: 1:44:25  iter: 27599  total_loss: 0.9379  loss_cls: 0.176  loss_box_reg: 0.2226  loss_mask: 0.2717  loss_rpn_cls: 0.07057  loss_rpn_loc: 0.187  time: 0.6431  data_time: 0.6453  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:43:02 d2.utils.events]: \u001b[0m eta: 1:43:14  iter: 27619  total_loss: 0.9597  loss_cls: 0.1625  loss_box_reg: 0.21  loss_mask: 0.2487  loss_rpn_cls: 0.04568  loss_rpn_loc: 0.1586  time: 0.6430  data_time: 0.3272  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:43:18 d2.utils.events]: \u001b[0m eta: 1:43:08  iter: 27639  total_loss: 0.8937  loss_cls: 0.1636  loss_box_reg: 0.2356  loss_mask: 0.267  loss_rpn_cls: 0.05286  loss_rpn_loc: 0.1842  time: 0.6431  data_time: 0.5656  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:43:30 d2.utils.events]: \u001b[0m eta: 1:44:01  iter: 27659  total_loss: 0.9877  loss_cls: 0.1778  loss_box_reg: 0.2166  loss_mask: 0.2531  loss_rpn_cls: 0.08087  loss_rpn_loc: 0.1753  time: 0.6431  data_time: 0.3902  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 14:43:42 d2.utils.events]: \u001b[0m eta: 1:43:49  iter: 27679  total_loss: 0.8787  loss_cls: 0.1412  loss_box_reg: 0.182  loss_mask: 0.2591  loss_rpn_cls: 0.05345  loss_rpn_loc: 0.1774  time: 0.6431  data_time: 0.3961  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:43:57 d2.utils.events]: \u001b[0m eta: 1:43:50  iter: 27699  total_loss: 0.8715  loss_cls: 0.1427  loss_box_reg: 0.1659  loss_mask: 0.2617  loss_rpn_cls: 0.06811  loss_rpn_loc: 0.183  time: 0.6432  data_time: 0.5334  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:44:12 d2.utils.events]: \u001b[0m eta: 1:43:06  iter: 27719  total_loss: 0.9287  loss_cls: 0.1403  loss_box_reg: 0.1819  loss_mask: 0.2706  loss_rpn_cls: 0.06594  loss_rpn_loc: 0.1926  time: 0.6433  data_time: 0.5541  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:44:23 d2.utils.events]: \u001b[0m eta: 1:43:39  iter: 27739  total_loss: 0.8782  loss_cls: 0.1394  loss_box_reg: 0.198  loss_mask: 0.2354  loss_rpn_cls: 0.03021  loss_rpn_loc: 0.1726  time: 0.6432  data_time: 0.3401  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:44:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:44:26 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:44:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:44:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:44:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0447 s/iter. Eval: 0.0191 s/iter. Total: 0.0645 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 14:44:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.396788 (0.060657 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:44:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.044267 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:44:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 14:44:30 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0710654593126971\n",
      "\u001b[32m[12/30 14:44:40 d2.utils.events]: \u001b[0m eta: 1:42:55  iter: 27759  total_loss: 0.9624  loss_cls: 0.1762  loss_box_reg: 0.2087  loss_mask: 0.2805  loss_rpn_cls: 0.07743  loss_rpn_loc: 0.187  time: 0.6432  data_time: 0.4251  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:44:52 d2.utils.events]: \u001b[0m eta: 1:43:21  iter: 27779  total_loss: 0.9427  loss_cls: 0.1664  loss_box_reg: 0.1971  loss_mask: 0.2653  loss_rpn_cls: 0.05768  loss_rpn_loc: 0.1836  time: 0.6432  data_time: 0.3760  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:45:04 d2.utils.events]: \u001b[0m eta: 1:42:44  iter: 27799  total_loss: 0.9298  loss_cls: 0.1423  loss_box_reg: 0.1953  loss_mask: 0.262  loss_rpn_cls: 0.04508  loss_rpn_loc: 0.1889  time: 0.6431  data_time: 0.4054  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:45:19 d2.utils.events]: \u001b[0m eta: 1:43:23  iter: 27819  total_loss: 0.8946  loss_cls: 0.1582  loss_box_reg: 0.2212  loss_mask: 0.2455  loss_rpn_cls: 0.05711  loss_rpn_loc: 0.1903  time: 0.6432  data_time: 0.5343  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:45:32 d2.utils.events]: \u001b[0m eta: 1:43:53  iter: 27839  total_loss: 0.9441  loss_cls: 0.1537  loss_box_reg: 0.197  loss_mask: 0.2481  loss_rpn_cls: 0.0414  loss_rpn_loc: 0.1799  time: 0.6432  data_time: 0.4379  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:45:47 d2.utils.events]: \u001b[0m eta: 1:44:44  iter: 27859  total_loss: 0.9917  loss_cls: 0.1696  loss_box_reg: 0.2249  loss_mask: 0.284  loss_rpn_cls: 0.04734  loss_rpn_loc: 0.1789  time: 0.6434  data_time: 0.5348  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:46:04 d2.utils.events]: \u001b[0m eta: 1:43:36  iter: 27879  total_loss: 0.9664  loss_cls: 0.1781  loss_box_reg: 0.2299  loss_mask: 0.2859  loss_rpn_cls: 0.06682  loss_rpn_loc: 0.1738  time: 0.6436  data_time: 0.6137  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:46:18 d2.utils.events]: \u001b[0m eta: 1:43:17  iter: 27899  total_loss: 0.9704  loss_cls: 0.1631  loss_box_reg: 0.2203  loss_mask: 0.2697  loss_rpn_cls: 0.06094  loss_rpn_loc: 0.1875  time: 0.6436  data_time: 0.4572  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:46:29 d2.utils.events]: \u001b[0m eta: 1:43:19  iter: 27919  total_loss: 0.7776  loss_cls: 0.1354  loss_box_reg: 0.1654  loss_mask: 0.2384  loss_rpn_cls: 0.0355  loss_rpn_loc: 0.1608  time: 0.6435  data_time: 0.3792  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:46:40 d2.utils.events]: \u001b[0m eta: 1:43:14  iter: 27939  total_loss: 0.92  loss_cls: 0.1662  loss_box_reg: 0.2534  loss_mask: 0.2264  loss_rpn_cls: 0.03953  loss_rpn_loc: 0.1652  time: 0.6434  data_time: 0.3162  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:46:54 d2.utils.events]: \u001b[0m eta: 1:43:13  iter: 27959  total_loss: 0.9284  loss_cls: 0.1673  loss_box_reg: 0.2239  loss_mask: 0.2721  loss_rpn_cls: 0.06278  loss_rpn_loc: 0.1978  time: 0.6434  data_time: 0.4755  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:47:10 d2.utils.events]: \u001b[0m eta: 1:43:08  iter: 27979  total_loss: 0.9281  loss_cls: 0.1622  loss_box_reg: 0.2338  loss_mask: 0.235  loss_rpn_cls: 0.05774  loss_rpn_loc: 0.1769  time: 0.6436  data_time: 0.5728  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:47:20 d2.utils.events]: \u001b[0m eta: 1:42:18  iter: 27999  total_loss: 0.8797  loss_cls: 0.1566  loss_box_reg: 0.2108  loss_mask: 0.2457  loss_rpn_cls: 0.02698  loss_rpn_loc: 0.1568  time: 0.6435  data_time: 0.3132  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:47:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:47:34 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:47:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:47:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:47:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0193 s/iter. Total: 0.0648 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 14:47:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.240683 (0.057869 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:47:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043283 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:47:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 14:47:38 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06798151854166921\n",
      "\u001b[32m[12/30 14:47:41 d2.utils.events]: \u001b[0m eta: 1:42:04  iter: 28019  total_loss: 0.9134  loss_cls: 0.1515  loss_box_reg: 0.1958  loss_mask: 0.2637  loss_rpn_cls: 0.05507  loss_rpn_loc: 0.1713  time: 0.6437  data_time: 0.6151  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:47:54 d2.utils.events]: \u001b[0m eta: 1:42:08  iter: 28039  total_loss: 0.8177  loss_cls: 0.1328  loss_box_reg: 0.2105  loss_mask: 0.2209  loss_rpn_cls: 0.03979  loss_rpn_loc: 0.1717  time: 0.6437  data_time: 0.4255  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:48:04 d2.utils.events]: \u001b[0m eta: 1:41:07  iter: 28059  total_loss: 0.758  loss_cls: 0.1407  loss_box_reg: 0.1629  loss_mask: 0.2138  loss_rpn_cls: 0.035  loss_rpn_loc: 0.1807  time: 0.6436  data_time: 0.3226  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:48:20 d2.utils.events]: \u001b[0m eta: 1:41:26  iter: 28079  total_loss: 0.9694  loss_cls: 0.1543  loss_box_reg: 0.2408  loss_mask: 0.2849  loss_rpn_cls: 0.06548  loss_rpn_loc: 0.198  time: 0.6437  data_time: 0.5633  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:48:29 d2.utils.events]: \u001b[0m eta: 1:40:43  iter: 28099  total_loss: 0.8696  loss_cls: 0.139  loss_box_reg: 0.2025  loss_mask: 0.2253  loss_rpn_cls: 0.02984  loss_rpn_loc: 0.1574  time: 0.6435  data_time: 0.2294  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:48:44 d2.utils.events]: \u001b[0m eta: 1:40:51  iter: 28119  total_loss: 0.8837  loss_cls: 0.1649  loss_box_reg: 0.1926  loss_mask: 0.2586  loss_rpn_cls: 0.06401  loss_rpn_loc: 0.203  time: 0.6436  data_time: 0.5395  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:48:54 d2.utils.events]: \u001b[0m eta: 1:40:22  iter: 28139  total_loss: 0.8999  loss_cls: 0.1599  loss_box_reg: 0.2193  loss_mask: 0.2468  loss_rpn_cls: 0.05116  loss_rpn_loc: 0.1622  time: 0.6435  data_time: 0.2897  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 14:49:10 d2.utils.events]: \u001b[0m eta: 1:40:09  iter: 28159  total_loss: 0.891  loss_cls: 0.1503  loss_box_reg: 0.2122  loss_mask: 0.2554  loss_rpn_cls: 0.04389  loss_rpn_loc: 0.1791  time: 0.6436  data_time: 0.5923  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:49:19 d2.utils.events]: \u001b[0m eta: 1:38:39  iter: 28179  total_loss: 0.2302  loss_cls: 6.693e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04166  loss_rpn_loc: 0.1623  time: 0.6434  data_time: 0.2378  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:49:30 d2.utils.events]: \u001b[0m eta: 1:37:43  iter: 28199  total_loss: 1.031  loss_cls: 0.1578  loss_box_reg: 0.2191  loss_mask: 0.2486  loss_rpn_cls: 0.04373  loss_rpn_loc: 0.1832  time: 0.6433  data_time: 0.3230  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:49:46 d2.utils.events]: \u001b[0m eta: 1:38:44  iter: 28219  total_loss: 1.093  loss_cls: 0.2099  loss_box_reg: 0.2594  loss_mask: 0.2708  loss_rpn_cls: 0.087  loss_rpn_loc: 0.2151  time: 0.6435  data_time: 0.5517  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:49:56 d2.utils.events]: \u001b[0m eta: 1:37:32  iter: 28239  total_loss: 0.8244  loss_cls: 0.1216  loss_box_reg: 0.1779  loss_mask: 0.2471  loss_rpn_cls: 0.0302  loss_rpn_loc: 0.178  time: 0.6433  data_time: 0.2892  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:50:10 d2.utils.events]: \u001b[0m eta: 1:36:39  iter: 28259  total_loss: 0.8305  loss_cls: 0.1207  loss_box_reg: 0.2335  loss_mask: 0.2454  loss_rpn_cls: 0.05696  loss_rpn_loc: 0.1885  time: 0.6434  data_time: 0.4749  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:50:19 d2.utils.events]: \u001b[0m eta: 1:35:45  iter: 28279  total_loss: 0.8228  loss_cls: 0.1341  loss_box_reg: 0.1937  loss_mask: 0.2624  loss_rpn_cls: 0.04165  loss_rpn_loc: 0.1783  time: 0.6432  data_time: 0.2920  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:50:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:50:23 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:50:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:50:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:50:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0454 s/iter. Eval: 0.0185 s/iter. Total: 0.0646 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 14:50:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.277316 (0.058524 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:50:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043621 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:50:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 14:50:26 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06531126929356577\n",
      "\u001b[32m[12/30 14:50:35 d2.utils.events]: \u001b[0m eta: 1:36:41  iter: 28299  total_loss: 0.9971  loss_cls: 0.1599  loss_box_reg: 0.2145  loss_mask: 0.2861  loss_rpn_cls: 0.07184  loss_rpn_loc: 0.1929  time: 0.6432  data_time: 0.3703  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:50:51 d2.utils.events]: \u001b[0m eta: 1:36:35  iter: 28319  total_loss: 0.9893  loss_cls: 0.2093  loss_box_reg: 0.2244  loss_mask: 0.2458  loss_rpn_cls: 0.06901  loss_rpn_loc: 0.2084  time: 0.6433  data_time: 0.5874  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:51:02 d2.utils.events]: \u001b[0m eta: 1:35:59  iter: 28339  total_loss: 0.9077  loss_cls: 0.1528  loss_box_reg: 0.2094  loss_mask: 0.2753  loss_rpn_cls: 0.03779  loss_rpn_loc: 0.1585  time: 0.6432  data_time: 0.3164  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:51:13 d2.utils.events]: \u001b[0m eta: 1:35:54  iter: 28359  total_loss: 1.067  loss_cls: 0.1953  loss_box_reg: 0.2673  loss_mask: 0.265  loss_rpn_cls: 0.06282  loss_rpn_loc: 0.1817  time: 0.6431  data_time: 0.3351  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:51:27 d2.utils.events]: \u001b[0m eta: 1:36:22  iter: 28379  total_loss: 0.9255  loss_cls: 0.1676  loss_box_reg: 0.2065  loss_mask: 0.2623  loss_rpn_cls: 0.07367  loss_rpn_loc: 0.1854  time: 0.6432  data_time: 0.5217  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:51:38 d2.utils.events]: \u001b[0m eta: 1:35:52  iter: 28399  total_loss: 0.737  loss_cls: 0.1319  loss_box_reg: 0.1821  loss_mask: 0.2101  loss_rpn_cls: 0.02556  loss_rpn_loc: 0.1674  time: 0.6431  data_time: 0.3255  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:51:48 d2.utils.events]: \u001b[0m eta: 1:36:07  iter: 28419  total_loss: 0.9018  loss_cls: 0.1542  loss_box_reg: 0.1795  loss_mask: 0.2303  loss_rpn_cls: 0.04007  loss_rpn_loc: 0.1642  time: 0.6430  data_time: 0.2941  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:52:04 d2.utils.events]: \u001b[0m eta: 1:37:44  iter: 28439  total_loss: 0.9507  loss_cls: 0.1586  loss_box_reg: 0.2127  loss_mask: 0.2585  loss_rpn_cls: 0.06558  loss_rpn_loc: 0.1951  time: 0.6431  data_time: 0.5869  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:52:14 d2.utils.events]: \u001b[0m eta: 1:37:23  iter: 28459  total_loss: 0.6827  loss_cls: 0.1062  loss_box_reg: 0.1972  loss_mask: 0.2315  loss_rpn_cls: 0.02657  loss_rpn_loc: 0.1642  time: 0.6429  data_time: 0.2539  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:52:25 d2.utils.events]: \u001b[0m eta: 1:36:00  iter: 28479  total_loss: 0.8914  loss_cls: 0.1585  loss_box_reg: 0.2175  loss_mask: 0.2586  loss_rpn_cls: 0.03423  loss_rpn_loc: 0.1579  time: 0.6429  data_time: 0.3612  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:52:41 d2.utils.events]: \u001b[0m eta: 1:35:45  iter: 28499  total_loss: 0.7445  loss_cls: 0.114  loss_box_reg: 0.1647  loss_mask: 0.2056  loss_rpn_cls: 0.04604  loss_rpn_loc: 0.1812  time: 0.6430  data_time: 0.5682  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:52:55 d2.utils.events]: \u001b[0m eta: 1:35:40  iter: 28519  total_loss: 0.985  loss_cls: 0.1835  loss_box_reg: 0.2134  loss_mask: 0.2635  loss_rpn_cls: 0.04446  loss_rpn_loc: 0.1704  time: 0.6431  data_time: 0.4822  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:53:13 d2.utils.events]: \u001b[0m eta: 1:37:13  iter: 28539  total_loss: 0.9377  loss_cls: 0.1653  loss_box_reg: 0.2181  loss_mask: 0.2894  loss_rpn_cls: 0.07221  loss_rpn_loc: 0.1987  time: 0.6433  data_time: 0.6476  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:53:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:53:30 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:53:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:53:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:53:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0167 s/iter. Total: 0.0622 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 14:53:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.315816 (0.059211 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:53:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043727 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:53:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 14:53:34 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06977819440243963\n",
      "\u001b[32m[12/30 14:53:34 d2.utils.events]: \u001b[0m eta: 1:37:26  iter: 28559  total_loss: 0.9565  loss_cls: 0.18  loss_box_reg: 0.2392  loss_mask: 0.2734  loss_rpn_cls: 0.0437  loss_rpn_loc: 0.1913  time: 0.6435  data_time: 0.6168  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:53:43 d2.utils.events]: \u001b[0m eta: 1:35:14  iter: 28579  total_loss: 0.7088  loss_cls: 0.1079  loss_box_reg: 0.1729  loss_mask: 0.2318  loss_rpn_cls: 0.02693  loss_rpn_loc: 0.1436  time: 0.6434  data_time: 0.2885  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:53:55 d2.utils.events]: \u001b[0m eta: 1:34:47  iter: 28599  total_loss: 0.9473  loss_cls: 0.1506  loss_box_reg: 0.2261  loss_mask: 0.2592  loss_rpn_cls: 0.04906  loss_rpn_loc: 0.1795  time: 0.6433  data_time: 0.3723  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:54:08 d2.utils.events]: \u001b[0m eta: 1:35:03  iter: 28619  total_loss: 0.7834  loss_cls: 0.1191  loss_box_reg: 0.1765  loss_mask: 0.2169  loss_rpn_cls: 0.04693  loss_rpn_loc: 0.1702  time: 0.6433  data_time: 0.4169  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 14:54:15 d2.utils.events]: \u001b[0m eta: 1:33:35  iter: 28639  total_loss: 0.6635  loss_cls: 0.09802  loss_box_reg: 0.1598  loss_mask: 0.2158  loss_rpn_cls: 0.02701  loss_rpn_loc: 0.1463  time: 0.6430  data_time: 0.1836  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:54:28 d2.utils.events]: \u001b[0m eta: 1:33:04  iter: 28659  total_loss: 0.9406  loss_cls: 0.143  loss_box_reg: 0.1977  loss_mask: 0.2371  loss_rpn_cls: 0.04355  loss_rpn_loc: 0.1683  time: 0.6430  data_time: 0.4008  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:54:42 d2.utils.events]: \u001b[0m eta: 1:33:11  iter: 28679  total_loss: 0.9339  loss_cls: 0.1943  loss_box_reg: 0.2487  loss_mask: 0.2519  loss_rpn_cls: 0.06067  loss_rpn_loc: 0.1727  time: 0.6431  data_time: 0.4647  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:54:58 d2.utils.events]: \u001b[0m eta: 1:33:31  iter: 28699  total_loss: 0.9429  loss_cls: 0.1652  loss_box_reg: 0.2112  loss_mask: 0.2814  loss_rpn_cls: 0.07467  loss_rpn_loc: 0.2131  time: 0.6432  data_time: 0.5806  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:55:12 d2.utils.events]: \u001b[0m eta: 1:33:58  iter: 28719  total_loss: 1.009  loss_cls: 0.1743  loss_box_reg: 0.2438  loss_mask: 0.2783  loss_rpn_cls: 0.06468  loss_rpn_loc: 0.1838  time: 0.6433  data_time: 0.5024  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:55:26 d2.utils.events]: \u001b[0m eta: 1:33:53  iter: 28739  total_loss: 0.7768  loss_cls: 0.1362  loss_box_reg: 0.1769  loss_mask: 0.2142  loss_rpn_cls: 0.02816  loss_rpn_loc: 0.1542  time: 0.6434  data_time: 0.4816  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:55:39 d2.utils.events]: \u001b[0m eta: 1:33:29  iter: 28759  total_loss: 0.9418  loss_cls: 0.1865  loss_box_reg: 0.219  loss_mask: 0.2489  loss_rpn_cls: 0.06608  loss_rpn_loc: 0.1909  time: 0.6434  data_time: 0.4345  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:55:49 d2.utils.events]: \u001b[0m eta: 1:33:10  iter: 28779  total_loss: 0.8017  loss_cls: 0.1309  loss_box_reg: 0.2169  loss_mask: 0.2448  loss_rpn_cls: 0.04555  loss_rpn_loc: 0.1841  time: 0.6432  data_time: 0.2835  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:56:06 d2.utils.events]: \u001b[0m eta: 1:33:37  iter: 28799  total_loss: 0.97  loss_cls: 0.1624  loss_box_reg: 0.216  loss_mask: 0.2395  loss_rpn_cls: 0.07028  loss_rpn_loc: 0.1957  time: 0.6434  data_time: 0.5842  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:56:21 d2.utils.events]: \u001b[0m eta: 1:33:13  iter: 28819  total_loss: 0.9101  loss_cls: 0.1528  loss_box_reg: 0.2013  loss_mask: 0.2814  loss_rpn_cls: 0.06017  loss_rpn_loc: 0.1943  time: 0.6435  data_time: 0.5445  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:56:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:56:29 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:56:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:56:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:56:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0453 s/iter. Eval: 0.0218 s/iter. Total: 0.0679 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 14:56:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.311262 (0.059130 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:56:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043404 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:56:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 14:56:33 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0669731452650273\n",
      "\u001b[32m[12/30 14:56:36 d2.utils.events]: \u001b[0m eta: 1:32:42  iter: 28839  total_loss: 0.7629  loss_cls: 0.136  loss_box_reg: 0.2006  loss_mask: 0.239  loss_rpn_cls: 0.04082  loss_rpn_loc: 0.1667  time: 0.6434  data_time: 0.3126  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:56:47 d2.utils.events]: \u001b[0m eta: 1:32:12  iter: 28859  total_loss: 0.7419  loss_cls: 0.1194  loss_box_reg: 0.2006  loss_mask: 0.2468  loss_rpn_cls: 0.03325  loss_rpn_loc: 0.1459  time: 0.6433  data_time: 0.3834  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:57:02 d2.utils.events]: \u001b[0m eta: 1:32:24  iter: 28879  total_loss: 0.9159  loss_cls: 0.1749  loss_box_reg: 0.1901  loss_mask: 0.2549  loss_rpn_cls: 0.05773  loss_rpn_loc: 0.1692  time: 0.6434  data_time: 0.5238  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:57:09 d2.utils.events]: \u001b[0m eta: 1:30:36  iter: 28899  total_loss: 0.7901  loss_cls: 0.1341  loss_box_reg: 0.2015  loss_mask: 0.2381  loss_rpn_cls: 0.03176  loss_rpn_loc: 0.1561  time: 0.6432  data_time: 0.1672  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:57:26 d2.utils.events]: \u001b[0m eta: 1:32:08  iter: 28919  total_loss: 1.003  loss_cls: 0.1804  loss_box_reg: 0.2063  loss_mask: 0.2792  loss_rpn_cls: 0.07303  loss_rpn_loc: 0.201  time: 0.6433  data_time: 0.5963  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:57:39 d2.utils.events]: \u001b[0m eta: 1:32:03  iter: 28939  total_loss: 0.9637  loss_cls: 0.181  loss_box_reg: 0.2492  loss_mask: 0.2539  loss_rpn_cls: 0.05622  loss_rpn_loc: 0.175  time: 0.6433  data_time: 0.4197  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:57:54 d2.utils.events]: \u001b[0m eta: 1:32:10  iter: 28959  total_loss: 1.032  loss_cls: 0.1739  loss_box_reg: 0.231  loss_mask: 0.2729  loss_rpn_cls: 0.07181  loss_rpn_loc: 0.2139  time: 0.6434  data_time: 0.5373  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:58:08 d2.utils.events]: \u001b[0m eta: 1:32:26  iter: 28979  total_loss: 0.9608  loss_cls: 0.177  loss_box_reg: 0.2316  loss_mask: 0.2597  loss_rpn_cls: 0.0611  loss_rpn_loc: 0.1817  time: 0.6435  data_time: 0.4789  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:58:22 d2.utils.events]: \u001b[0m eta: 1:32:54  iter: 28999  total_loss: 0.9508  loss_cls: 0.1819  loss_box_reg: 0.2183  loss_mask: 0.2589  loss_rpn_cls: 0.06778  loss_rpn_loc: 0.1909  time: 0.6435  data_time: 0.4857  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:58:31 d2.utils.events]: \u001b[0m eta: 1:32:38  iter: 29019  total_loss: 0.6914  loss_cls: 0.1037  loss_box_reg: 0.1972  loss_mask: 0.2184  loss_rpn_cls: 0.03342  loss_rpn_loc: 0.1574  time: 0.6434  data_time: 0.2790  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:58:49 d2.utils.events]: \u001b[0m eta: 1:32:58  iter: 29039  total_loss: 1.02  loss_cls: 0.1842  loss_box_reg: 0.2361  loss_mask: 0.3022  loss_rpn_cls: 0.07011  loss_rpn_loc: 0.1992  time: 0.6436  data_time: 0.6291  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:59:02 d2.utils.events]: \u001b[0m eta: 1:32:53  iter: 29059  total_loss: 0.7637  loss_cls: 0.119  loss_box_reg: 0.1505  loss_mask: 0.2534  loss_rpn_cls: 0.03541  loss_rpn_loc: 0.1697  time: 0.6436  data_time: 0.4623  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:59:15 d2.utils.events]: \u001b[0m eta: 1:32:34  iter: 29079  total_loss: 0.9547  loss_cls: 0.1559  loss_box_reg: 0.1741  loss_mask: 0.255  loss_rpn_cls: 0.04812  loss_rpn_loc: 0.1824  time: 0.6436  data_time: 0.4359  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:59:30 d2.utils.events]: \u001b[0m eta: 1:33:00  iter: 29099  total_loss: 0.9663  loss_cls: 0.2063  loss_box_reg: 0.2163  loss_mask: 0.268  loss_rpn_cls: 0.0441  loss_rpn_loc: 0.1863  time: 0.6437  data_time: 0.5232  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:59:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 14:59:32 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 14:59:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 14:59:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 14:59:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0453 s/iter. Eval: 0.0256 s/iter. Total: 0.0716 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 14:59:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.345684 (0.059744 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:59:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043806 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 14:59:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 14:59:36 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06883709256072955\n",
      "\u001b[32m[12/30 14:59:46 d2.utils.events]: \u001b[0m eta: 1:32:48  iter: 29119  total_loss: 0.9046  loss_cls: 0.1528  loss_box_reg: 0.2074  loss_mask: 0.2485  loss_rpn_cls: 0.06881  loss_rpn_loc: 0.1875  time: 0.6437  data_time: 0.3694  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 14:59:56 d2.utils.events]: \u001b[0m eta: 1:32:17  iter: 29139  total_loss: 0.8132  loss_cls: 0.1397  loss_box_reg: 0.1935  loss_mask: 0.2532  loss_rpn_cls: 0.04708  loss_rpn_loc: 0.1675  time: 0.6435  data_time: 0.2811  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:00:10 d2.utils.events]: \u001b[0m eta: 1:31:38  iter: 29159  total_loss: 0.8886  loss_cls: 0.1537  loss_box_reg: 0.2181  loss_mask: 0.2675  loss_rpn_cls: 0.05122  loss_rpn_loc: 0.1853  time: 0.6436  data_time: 0.5167  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:00:27 d2.utils.events]: \u001b[0m eta: 1:32:42  iter: 29179  total_loss: 0.9306  loss_cls: 0.1473  loss_box_reg: 0.1831  loss_mask: 0.2729  loss_rpn_cls: 0.07882  loss_rpn_loc: 0.1934  time: 0.6438  data_time: 0.6068  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:00:42 d2.utils.events]: \u001b[0m eta: 1:33:05  iter: 29199  total_loss: 0.9046  loss_cls: 0.1418  loss_box_reg: 0.2299  loss_mask: 0.2368  loss_rpn_cls: 0.05205  loss_rpn_loc: 0.1769  time: 0.6439  data_time: 0.5358  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:00:54 d2.utils.events]: \u001b[0m eta: 1:32:16  iter: 29219  total_loss: 0.7383  loss_cls: 0.1106  loss_box_reg: 0.1706  loss_mask: 0.2211  loss_rpn_cls: 0.0482  loss_rpn_loc: 0.1868  time: 0.6438  data_time: 0.3722  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:01:06 d2.utils.events]: \u001b[0m eta: 1:32:54  iter: 29239  total_loss: 0.9369  loss_cls: 0.1803  loss_box_reg: 0.2534  loss_mask: 0.2834  loss_rpn_cls: 0.05337  loss_rpn_loc: 0.1718  time: 0.6438  data_time: 0.4004  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:01:16 d2.utils.events]: \u001b[0m eta: 1:32:17  iter: 29259  total_loss: 0.8238  loss_cls: 0.149  loss_box_reg: 0.2042  loss_mask: 0.2464  loss_rpn_cls: 0.03664  loss_rpn_loc: 0.1665  time: 0.6437  data_time: 0.2838  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:01:28 d2.utils.events]: \u001b[0m eta: 1:34:04  iter: 29279  total_loss: 0.8662  loss_cls: 0.1612  loss_box_reg: 0.2126  loss_mask: 0.2543  loss_rpn_cls: 0.04964  loss_rpn_loc: 0.1658  time: 0.6436  data_time: 0.3692  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:01:40 d2.utils.events]: \u001b[0m eta: 1:32:38  iter: 29299  total_loss: 0.8317  loss_cls: 0.1405  loss_box_reg: 0.2117  loss_mask: 0.2494  loss_rpn_cls: 0.04452  loss_rpn_loc: 0.1815  time: 0.6436  data_time: 0.3857  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:01:55 d2.utils.events]: \u001b[0m eta: 1:32:05  iter: 29319  total_loss: 0.9308  loss_cls: 0.1555  loss_box_reg: 0.2264  loss_mask: 0.2743  loss_rpn_cls: 0.05503  loss_rpn_loc: 0.188  time: 0.6437  data_time: 0.5390  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:02:09 d2.utils.events]: \u001b[0m eta: 1:33:48  iter: 29339  total_loss: 0.9355  loss_cls: 0.164  loss_box_reg: 0.1929  loss_mask: 0.2753  loss_rpn_cls: 0.05765  loss_rpn_loc: 0.1774  time: 0.6437  data_time: 0.4831  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:02:20 d2.utils.events]: \u001b[0m eta: 1:31:54  iter: 29359  total_loss: 0.7301  loss_cls: 0.1296  loss_box_reg: 0.191  loss_mask: 0.2268  loss_rpn_cls: 0.03964  loss_rpn_loc: 0.1797  time: 0.6436  data_time: 0.3280  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:02:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 15:02:29 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:02:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:02:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:02:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0438 s/iter. Eval: 0.0162 s/iter. Total: 0.0608 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 15:02:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.236783 (0.057800 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:02:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043440 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:02:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 15:02:33 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0665116711292363\n",
      "\u001b[32m[12/30 15:02:36 d2.utils.events]: \u001b[0m eta: 1:30:33  iter: 29379  total_loss: 1.069  loss_cls: 0.1933  loss_box_reg: 0.2247  loss_mask: 0.2745  loss_rpn_cls: 0.04463  loss_rpn_loc: 0.1866  time: 0.6436  data_time: 0.3955  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:02:49 d2.utils.events]: \u001b[0m eta: 1:31:24  iter: 29399  total_loss: 0.8746  loss_cls: 0.1264  loss_box_reg: 0.1773  loss_mask: 0.2478  loss_rpn_cls: 0.04758  loss_rpn_loc: 0.1975  time: 0.6436  data_time: 0.4397  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:03:10 d2.utils.events]: \u001b[0m eta: 1:35:14  iter: 29419  total_loss: 1.015  loss_cls: 0.1685  loss_box_reg: 0.2375  loss_mask: 0.2927  loss_rpn_cls: 0.07029  loss_rpn_loc: 0.2062  time: 0.6440  data_time: 0.8054  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:03:22 d2.utils.events]: \u001b[0m eta: 1:34:09  iter: 29439  total_loss: 0.8487  loss_cls: 0.1618  loss_box_reg: 0.216  loss_mask: 0.2223  loss_rpn_cls: 0.03447  loss_rpn_loc: 0.1566  time: 0.6440  data_time: 0.4062  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:03:32 d2.utils.events]: \u001b[0m eta: 1:32:14  iter: 29459  total_loss: 0.6985  loss_cls: 0.1116  loss_box_reg: 0.2056  loss_mask: 0.1924  loss_rpn_cls: 0.03073  loss_rpn_loc: 0.1598  time: 0.6438  data_time: 0.2708  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:03:45 d2.utils.events]: \u001b[0m eta: 1:33:10  iter: 29479  total_loss: 0.9961  loss_cls: 0.1794  loss_box_reg: 0.212  loss_mask: 0.2339  loss_rpn_cls: 0.05365  loss_rpn_loc: 0.1871  time: 0.6438  data_time: 0.4563  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:03:59 d2.utils.events]: \u001b[0m eta: 1:34:01  iter: 29499  total_loss: 1.036  loss_cls: 0.1844  loss_box_reg: 0.2469  loss_mask: 0.2729  loss_rpn_cls: 0.07031  loss_rpn_loc: 0.1838  time: 0.6439  data_time: 0.4757  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:04:13 d2.utils.events]: \u001b[0m eta: 1:33:47  iter: 29519  total_loss: 0.9358  loss_cls: 0.1741  loss_box_reg: 0.2134  loss_mask: 0.2319  loss_rpn_cls: 0.03934  loss_rpn_loc: 0.1936  time: 0.6439  data_time: 0.4702  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:04:24 d2.utils.events]: \u001b[0m eta: 1:31:52  iter: 29539  total_loss: 0.8609  loss_cls: 0.1428  loss_box_reg: 0.195  loss_mask: 0.2354  loss_rpn_cls: 0.04827  loss_rpn_loc: 0.1836  time: 0.6438  data_time: 0.3737  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:04:37 d2.utils.events]: \u001b[0m eta: 1:30:17  iter: 29559  total_loss: 0.8345  loss_cls: 0.1519  loss_box_reg: 0.2287  loss_mask: 0.2481  loss_rpn_cls: 0.04548  loss_rpn_loc: 0.1604  time: 0.6438  data_time: 0.3965  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:04:48 d2.utils.events]: \u001b[0m eta: 1:30:52  iter: 29579  total_loss: 0.9774  loss_cls: 0.1379  loss_box_reg: 0.2073  loss_mask: 0.2475  loss_rpn_cls: 0.05138  loss_rpn_loc: 0.1708  time: 0.6438  data_time: 0.3796  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:05:04 d2.utils.events]: \u001b[0m eta: 1:31:36  iter: 29599  total_loss: 0.9556  loss_cls: 0.1794  loss_box_reg: 0.2152  loss_mask: 0.2609  loss_rpn_cls: 0.06091  loss_rpn_loc: 0.1982  time: 0.6439  data_time: 0.5505  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:05:16 d2.utils.events]: \u001b[0m eta: 1:31:12  iter: 29619  total_loss: 0.8385  loss_cls: 0.1158  loss_box_reg: 0.1994  loss_mask: 0.2603  loss_rpn_cls: 0.039  loss_rpn_loc: 0.1614  time: 0.6438  data_time: 0.3758  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:05:24 d2.utils.events]: \u001b[0m eta: 1:31:25  iter: 29639  total_loss: 0.8567  loss_cls: 0.1547  loss_box_reg: 0.2143  loss_mask: 0.2557  loss_rpn_cls: 0.03902  loss_rpn_loc: 0.1729  time: 0.6436  data_time: 0.2270  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:05:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 15:05:31 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:05:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:05:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:05:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0451 s/iter. Eval: 0.0181 s/iter. Total: 0.0640 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 15:05:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.310676 (0.059119 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:05:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043792 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:05:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 15:05:35 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07006375732450855\n",
      "\u001b[32m[12/30 15:05:39 d2.utils.events]: \u001b[0m eta: 1:33:10  iter: 29659  total_loss: 0.8517  loss_cls: 0.1519  loss_box_reg: 0.2276  loss_mask: 0.2479  loss_rpn_cls: 0.04127  loss_rpn_loc: 0.1694  time: 0.6435  data_time: 0.3313  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:05:51 d2.utils.events]: \u001b[0m eta: 1:33:04  iter: 29679  total_loss: 0.9338  loss_cls: 0.1714  loss_box_reg: 0.2276  loss_mask: 0.2744  loss_rpn_cls: 0.06093  loss_rpn_loc: 0.1908  time: 0.6435  data_time: 0.4214  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:06:06 d2.utils.events]: \u001b[0m eta: 1:31:09  iter: 29699  total_loss: 0.6984  loss_cls: 0.1004  loss_box_reg: 0.1529  loss_mask: 0.1925  loss_rpn_cls: 0.02524  loss_rpn_loc: 0.1692  time: 0.6436  data_time: 0.4880  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:06:18 d2.utils.events]: \u001b[0m eta: 1:30:14  iter: 29719  total_loss: 0.823  loss_cls: 0.1405  loss_box_reg: 0.202  loss_mask: 0.2181  loss_rpn_cls: 0.02949  loss_rpn_loc: 0.1522  time: 0.6435  data_time: 0.3929  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:06:31 d2.utils.events]: \u001b[0m eta: 1:30:23  iter: 29739  total_loss: 0.9641  loss_cls: 0.1511  loss_box_reg: 0.2124  loss_mask: 0.2705  loss_rpn_cls: 0.05903  loss_rpn_loc: 0.1836  time: 0.6435  data_time: 0.4439  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:06:46 d2.utils.events]: \u001b[0m eta: 1:30:27  iter: 29759  total_loss: 0.9517  loss_cls: 0.1223  loss_box_reg: 0.1819  loss_mask: 0.2611  loss_rpn_cls: 0.06357  loss_rpn_loc: 0.1895  time: 0.6437  data_time: 0.5505  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:07:00 d2.utils.events]: \u001b[0m eta: 1:30:29  iter: 29779  total_loss: 0.8989  loss_cls: 0.1563  loss_box_reg: 0.2366  loss_mask: 0.2649  loss_rpn_cls: 0.02991  loss_rpn_loc: 0.1733  time: 0.6437  data_time: 0.4780  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:07:09 d2.utils.events]: \u001b[0m eta: 1:29:53  iter: 29799  total_loss: 0.8675  loss_cls: 0.1304  loss_box_reg: 0.1591  loss_mask: 0.2075  loss_rpn_cls: 0.04242  loss_rpn_loc: 0.1644  time: 0.6435  data_time: 0.2438  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:07:20 d2.utils.events]: \u001b[0m eta: 1:27:34  iter: 29819  total_loss: 0.8487  loss_cls: 0.1698  loss_box_reg: 0.1899  loss_mask: 0.2474  loss_rpn_cls: 0.04314  loss_rpn_loc: 0.163  time: 0.6434  data_time: 0.3315  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:07:35 d2.utils.events]: \u001b[0m eta: 1:31:17  iter: 29839  total_loss: 1.013  loss_cls: 0.1955  loss_box_reg: 0.2335  loss_mask: 0.2713  loss_rpn_cls: 0.07087  loss_rpn_loc: 0.1985  time: 0.6435  data_time: 0.5237  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:07:46 d2.utils.events]: \u001b[0m eta: 1:31:45  iter: 29859  total_loss: 0.7184  loss_cls: 0.1216  loss_box_reg: 0.1933  loss_mask: 0.2308  loss_rpn_cls: 0.03165  loss_rpn_loc: 0.1657  time: 0.6435  data_time: 0.3578  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:08:02 d2.utils.events]: \u001b[0m eta: 1:31:06  iter: 29879  total_loss: 0.9846  loss_cls: 0.1599  loss_box_reg: 0.1979  loss_mask: 0.2734  loss_rpn_cls: 0.06176  loss_rpn_loc: 0.1889  time: 0.6436  data_time: 0.5678  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:08:16 d2.utils.events]: \u001b[0m eta: 1:32:12  iter: 29899  total_loss: 0.9148  loss_cls: 0.1636  loss_box_reg: 0.248  loss_mask: 0.2505  loss_rpn_cls: 0.04994  loss_rpn_loc: 0.1907  time: 0.6436  data_time: 0.4704  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:08:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 15:08:30 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:08:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:08:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:08:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0449 s/iter. Eval: 0.0174 s/iter. Total: 0.0630 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 15:08:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.385658 (0.060458 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:08:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043789 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:08:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 15:08:33 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07288256140134504\n",
      "\u001b[32m[12/30 15:08:33 d2.utils.events]: \u001b[0m eta: 1:31:43  iter: 29919  total_loss: 0.8846  loss_cls: 0.1587  loss_box_reg: 0.2273  loss_mask: 0.2538  loss_rpn_cls: 0.05169  loss_rpn_loc: 0.1698  time: 0.6437  data_time: 0.4611  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:08:48 d2.utils.events]: \u001b[0m eta: 1:31:53  iter: 29939  total_loss: 0.9466  loss_cls: 0.1713  loss_box_reg: 0.1952  loss_mask: 0.2594  loss_rpn_cls: 0.0561  loss_rpn_loc: 0.1929  time: 0.6438  data_time: 0.5079  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:09:03 d2.utils.events]: \u001b[0m eta: 1:31:18  iter: 29959  total_loss: 1.026  loss_cls: 0.1923  loss_box_reg: 0.2375  loss_mask: 0.2628  loss_rpn_cls: 0.06979  loss_rpn_loc: 0.1763  time: 0.6438  data_time: 0.5112  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:09:17 d2.utils.events]: \u001b[0m eta: 1:31:46  iter: 29979  total_loss: 0.9964  loss_cls: 0.1677  loss_box_reg: 0.2609  loss_mask: 0.2857  loss_rpn_cls: 0.04829  loss_rpn_loc: 0.1815  time: 0.6439  data_time: 0.4822  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:09:29 d2.utils.events]: \u001b[0m eta: 1:31:59  iter: 29999  total_loss: 0.9818  loss_cls: 0.1784  loss_box_reg: 0.2456  loss_mask: 0.2458  loss_rpn_cls: 0.04226  loss_rpn_loc: 0.1763  time: 0.6438  data_time: 0.3729  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:09:42 d2.utils.events]: \u001b[0m eta: 1:32:50  iter: 30019  total_loss: 0.9684  loss_cls: 0.1765  loss_box_reg: 0.2189  loss_mask: 0.2494  loss_rpn_cls: 0.07288  loss_rpn_loc: 0.1749  time: 0.6438  data_time: 0.4461  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:09:55 d2.utils.events]: \u001b[0m eta: 1:31:48  iter: 30039  total_loss: 0.9543  loss_cls: 0.1757  loss_box_reg: 0.2162  loss_mask: 0.2545  loss_rpn_cls: 0.06325  loss_rpn_loc: 0.1763  time: 0.6438  data_time: 0.4098  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:10:03 d2.utils.events]: \u001b[0m eta: 1:31:31  iter: 30059  total_loss: 0.8053  loss_cls: 0.136  loss_box_reg: 0.2129  loss_mask: 0.2133  loss_rpn_cls: 0.03431  loss_rpn_loc: 0.1504  time: 0.6436  data_time: 0.2215  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:10:19 d2.utils.events]: \u001b[0m eta: 1:31:37  iter: 30079  total_loss: 0.9301  loss_cls: 0.1439  loss_box_reg: 0.1796  loss_mask: 0.2555  loss_rpn_cls: 0.04532  loss_rpn_loc: 0.1749  time: 0.6437  data_time: 0.5503  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:10:26 d2.utils.events]: \u001b[0m eta: 1:30:34  iter: 30099  total_loss: 0.4805  loss_cls: 0.0721  loss_box_reg: 0.1108  loss_mask: 0.1381  loss_rpn_cls: 0.02802  loss_rpn_loc: 0.1593  time: 0.6435  data_time: 0.1807  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:10:37 d2.utils.events]: \u001b[0m eta: 1:30:07  iter: 30119  total_loss: 0.9511  loss_cls: 0.1569  loss_box_reg: 0.1832  loss_mask: 0.2422  loss_rpn_cls: 0.06025  loss_rpn_loc: 0.1746  time: 0.6434  data_time: 0.3472  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:10:53 d2.utils.events]: \u001b[0m eta: 1:30:47  iter: 30139  total_loss: 0.9631  loss_cls: 0.17  loss_box_reg: 0.2199  loss_mask: 0.2701  loss_rpn_cls: 0.0636  loss_rpn_loc: 0.1925  time: 0.6435  data_time: 0.5509  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 15:11:06 d2.utils.events]: \u001b[0m eta: 1:30:18  iter: 30159  total_loss: 0.8216  loss_cls: 0.1234  loss_box_reg: 0.1926  loss_mask: 0.2503  loss_rpn_cls: 0.04104  loss_rpn_loc: 0.1716  time: 0.6435  data_time: 0.4278  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:11:22 d2.utils.events]: \u001b[0m eta: 1:30:12  iter: 30179  total_loss: 0.9858  loss_cls: 0.1706  loss_box_reg: 0.2461  loss_mask: 0.2823  loss_rpn_cls: 0.06162  loss_rpn_loc: 0.1839  time: 0.6437  data_time: 0.6135  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:11:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 15:11:30 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:11:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:11:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:11:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0450 s/iter. Eval: 0.0180 s/iter. Total: 0.0637 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 15:11:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.288958 (0.058731 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:11:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043701 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:11:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 15:11:33 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06948182306772498\n",
      "\u001b[32m[12/30 15:11:39 d2.utils.events]: \u001b[0m eta: 1:29:16  iter: 30199  total_loss: 0.8271  loss_cls: 0.1488  loss_box_reg: 0.187  loss_mask: 0.2407  loss_rpn_cls: 0.03097  loss_rpn_loc: 0.169  time: 0.6437  data_time: 0.4135  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:11:53 d2.utils.events]: \u001b[0m eta: 1:30:02  iter: 30219  total_loss: 0.9629  loss_cls: 0.1591  loss_box_reg: 0.1982  loss_mask: 0.2811  loss_rpn_cls: 0.06217  loss_rpn_loc: 0.1678  time: 0.6438  data_time: 0.5076  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:12:07 d2.utils.events]: \u001b[0m eta: 1:29:34  iter: 30239  total_loss: 0.8952  loss_cls: 0.159  loss_box_reg: 0.2269  loss_mask: 0.2483  loss_rpn_cls: 0.04651  loss_rpn_loc: 0.1759  time: 0.6438  data_time: 0.4833  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:12:20 d2.utils.events]: \u001b[0m eta: 1:29:29  iter: 30259  total_loss: 0.6123  loss_cls: 0.1014  loss_box_reg: 0.1542  loss_mask: 0.1954  loss_rpn_cls: 0.02856  loss_rpn_loc: 0.1607  time: 0.6438  data_time: 0.4261  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:12:30 d2.utils.events]: \u001b[0m eta: 1:28:54  iter: 30279  total_loss: 0.942  loss_cls: 0.1598  loss_box_reg: 0.2061  loss_mask: 0.2459  loss_rpn_cls: 0.0632  loss_rpn_loc: 0.1782  time: 0.6437  data_time: 0.3196  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:12:47 d2.utils.events]: \u001b[0m eta: 1:29:18  iter: 30299  total_loss: 1.075  loss_cls: 0.2159  loss_box_reg: 0.2856  loss_mask: 0.287  loss_rpn_cls: 0.0883  loss_rpn_loc: 0.1983  time: 0.6439  data_time: 0.5817  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:13:00 d2.utils.events]: \u001b[0m eta: 1:28:26  iter: 30319  total_loss: 0.9313  loss_cls: 0.1581  loss_box_reg: 0.2187  loss_mask: 0.2608  loss_rpn_cls: 0.0565  loss_rpn_loc: 0.1755  time: 0.6439  data_time: 0.4604  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:13:10 d2.utils.events]: \u001b[0m eta: 1:26:41  iter: 30339  total_loss: 0.7752  loss_cls: 0.1372  loss_box_reg: 0.217  loss_mask: 0.2413  loss_rpn_cls: 0.02845  loss_rpn_loc: 0.148  time: 0.6438  data_time: 0.2868  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:13:24 d2.utils.events]: \u001b[0m eta: 1:28:32  iter: 30359  total_loss: 0.9378  loss_cls: 0.1764  loss_box_reg: 0.2021  loss_mask: 0.2637  loss_rpn_cls: 0.0541  loss_rpn_loc: 0.1956  time: 0.6438  data_time: 0.4363  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:13:37 d2.utils.events]: \u001b[0m eta: 1:29:07  iter: 30379  total_loss: 0.8872  loss_cls: 0.1425  loss_box_reg: 0.2197  loss_mask: 0.2641  loss_rpn_cls: 0.05552  loss_rpn_loc: 0.1908  time: 0.6438  data_time: 0.4687  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:13:49 d2.utils.events]: \u001b[0m eta: 1:29:17  iter: 30399  total_loss: 0.8915  loss_cls: 0.1609  loss_box_reg: 0.1924  loss_mask: 0.2446  loss_rpn_cls: 0.04613  loss_rpn_loc: 0.185  time: 0.6438  data_time: 0.3920  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:13:58 d2.utils.events]: \u001b[0m eta: 1:26:31  iter: 30419  total_loss: 0.7791  loss_cls: 0.1245  loss_box_reg: 0.1757  loss_mask: 0.2612  loss_rpn_cls: 0.02998  loss_rpn_loc: 0.1687  time: 0.6436  data_time: 0.2469  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:14:11 d2.utils.events]: \u001b[0m eta: 1:27:32  iter: 30439  total_loss: 0.9016  loss_cls: 0.1505  loss_box_reg: 0.2045  loss_mask: 0.2579  loss_rpn_cls: 0.04311  loss_rpn_loc: 0.1766  time: 0.6436  data_time: 0.4270  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:14:20 d2.utils.events]: \u001b[0m eta: 1:27:27  iter: 30459  total_loss: 0.8331  loss_cls: 0.1327  loss_box_reg: 0.2246  loss_mask: 0.215  loss_rpn_cls: 0.04162  loss_rpn_loc: 0.16  time: 0.6434  data_time: 0.2618  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:14:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 15:14:24 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:14:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:14:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:14:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0454 s/iter. Eval: 0.0265 s/iter. Total: 0.0727 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 15:14:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.359828 (0.059997 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:14:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043489 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:14:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 15:14:28 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0690128831254413\n",
      "\u001b[32m[12/30 15:14:39 d2.utils.events]: \u001b[0m eta: 1:26:49  iter: 30479  total_loss: 1.021  loss_cls: 0.2041  loss_box_reg: 0.2703  loss_mask: 0.2612  loss_rpn_cls: 0.05069  loss_rpn_loc: 0.1881  time: 0.6435  data_time: 0.4782  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:14:51 d2.utils.events]: \u001b[0m eta: 1:25:58  iter: 30499  total_loss: 0.915  loss_cls: 0.1599  loss_box_reg: 0.2063  loss_mask: 0.2705  loss_rpn_cls: 0.05455  loss_rpn_loc: 0.185  time: 0.6434  data_time: 0.3910  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:15:05 d2.utils.events]: \u001b[0m eta: 1:27:49  iter: 30519  total_loss: 1.028  loss_cls: 0.1899  loss_box_reg: 0.2426  loss_mask: 0.2668  loss_rpn_cls: 0.07011  loss_rpn_loc: 0.185  time: 0.6435  data_time: 0.5175  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:15:23 d2.utils.events]: \u001b[0m eta: 1:28:23  iter: 30539  total_loss: 0.976  loss_cls: 0.1605  loss_box_reg: 0.2198  loss_mask: 0.2648  loss_rpn_cls: 0.06582  loss_rpn_loc: 0.1943  time: 0.6437  data_time: 0.6498  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:15:33 d2.utils.events]: \u001b[0m eta: 1:28:33  iter: 30559  total_loss: 0.8454  loss_cls: 0.1339  loss_box_reg: 0.2183  loss_mask: 0.2436  loss_rpn_cls: 0.03894  loss_rpn_loc: 0.1585  time: 0.6436  data_time: 0.2709  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:15:50 d2.utils.events]: \u001b[0m eta: 1:28:28  iter: 30579  total_loss: 0.8401  loss_cls: 0.1278  loss_box_reg: 0.178  loss_mask: 0.2315  loss_rpn_cls: 0.03317  loss_rpn_loc: 0.1778  time: 0.6438  data_time: 0.6243  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:16:00 d2.utils.events]: \u001b[0m eta: 1:27:47  iter: 30599  total_loss: 0.7949  loss_cls: 0.1291  loss_box_reg: 0.2155  loss_mask: 0.2304  loss_rpn_cls: 0.03369  loss_rpn_loc: 0.168  time: 0.6436  data_time: 0.2872  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:16:12 d2.utils.events]: \u001b[0m eta: 1:27:41  iter: 30619  total_loss: 0.9351  loss_cls: 0.1621  loss_box_reg: 0.2215  loss_mask: 0.2506  loss_rpn_cls: 0.06241  loss_rpn_loc: 0.1619  time: 0.6436  data_time: 0.4077  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 15:16:21 d2.utils.events]: \u001b[0m eta: 1:28:07  iter: 30639  total_loss: 0.8054  loss_cls: 0.142  loss_box_reg: 0.2022  loss_mask: 0.2309  loss_rpn_cls: 0.03877  loss_rpn_loc: 0.1634  time: 0.6435  data_time: 0.2542  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:16:36 d2.utils.events]: \u001b[0m eta: 1:28:10  iter: 30659  total_loss: 0.9675  loss_cls: 0.1769  loss_box_reg: 0.2154  loss_mask: 0.2784  loss_rpn_cls: 0.07391  loss_rpn_loc: 0.1919  time: 0.6435  data_time: 0.5126  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:16:55 d2.utils.events]: \u001b[0m eta: 1:28:24  iter: 30679  total_loss: 0.9649  loss_cls: 0.1893  loss_box_reg: 0.1994  loss_mask: 0.2806  loss_rpn_cls: 0.1028  loss_rpn_loc: 0.205  time: 0.6438  data_time: 0.7092  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:17:05 d2.utils.events]: \u001b[0m eta: 1:27:53  iter: 30699  total_loss: 0.4053  loss_cls: 0.04698  loss_box_reg: 0.07239  loss_mask: 0.09722  loss_rpn_cls: 0.02991  loss_rpn_loc: 0.1487  time: 0.6437  data_time: 0.3158  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:17:17 d2.utils.events]: \u001b[0m eta: 1:27:53  iter: 30719  total_loss: 0.7988  loss_cls: 0.1493  loss_box_reg: 0.2086  loss_mask: 0.2332  loss_rpn_cls: 0.03234  loss_rpn_loc: 0.1697  time: 0.6436  data_time: 0.3699  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:17:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 15:17:31 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:17:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:17:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:17:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0454 s/iter. Eval: 0.0186 s/iter. Total: 0.0647 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 15:17:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.315375 (0.059203 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:17:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043885 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:17:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 15:17:35 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0722470938045189\n",
      "\u001b[32m[12/30 15:17:37 d2.utils.events]: \u001b[0m eta: 1:28:56  iter: 30739  total_loss: 1.002  loss_cls: 0.1681  loss_box_reg: 0.2201  loss_mask: 0.2779  loss_rpn_cls: 0.08158  loss_rpn_loc: 0.2089  time: 0.6438  data_time: 0.5613  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:17:49 d2.utils.events]: \u001b[0m eta: 1:28:58  iter: 30759  total_loss: 0.9275  loss_cls: 0.145  loss_box_reg: 0.224  loss_mask: 0.2407  loss_rpn_cls: 0.04615  loss_rpn_loc: 0.1895  time: 0.6437  data_time: 0.3795  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:18:03 d2.utils.events]: \u001b[0m eta: 1:29:46  iter: 30779  total_loss: 0.9115  loss_cls: 0.1704  loss_box_reg: 0.215  loss_mask: 0.2888  loss_rpn_cls: 0.05873  loss_rpn_loc: 0.1812  time: 0.6438  data_time: 0.4998  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:18:15 d2.utils.events]: \u001b[0m eta: 1:30:22  iter: 30799  total_loss: 0.8618  loss_cls: 0.16  loss_box_reg: 0.2303  loss_mask: 0.2493  loss_rpn_cls: 0.05171  loss_rpn_loc: 0.176  time: 0.6438  data_time: 0.3895  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:18:27 d2.utils.events]: \u001b[0m eta: 1:28:42  iter: 30819  total_loss: 0.5377  loss_cls: 0.09569  loss_box_reg: 0.1198  loss_mask: 0.1909  loss_rpn_cls: 0.02658  loss_rpn_loc: 0.1716  time: 0.6437  data_time: 0.3608  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:18:39 d2.utils.events]: \u001b[0m eta: 1:28:28  iter: 30839  total_loss: 0.9005  loss_cls: 0.1667  loss_box_reg: 0.2257  loss_mask: 0.2463  loss_rpn_cls: 0.04773  loss_rpn_loc: 0.1605  time: 0.6437  data_time: 0.3932  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:18:47 d2.utils.events]: \u001b[0m eta: 1:28:23  iter: 30859  total_loss: 0.7899  loss_cls: 0.1411  loss_box_reg: 0.2102  loss_mask: 0.259  loss_rpn_cls: 0.04234  loss_rpn_loc: 0.1671  time: 0.6434  data_time: 0.1991  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:19:00 d2.utils.events]: \u001b[0m eta: 1:26:50  iter: 30879  total_loss: 0.779  loss_cls: 0.1426  loss_box_reg: 0.1803  loss_mask: 0.2353  loss_rpn_cls: 0.03676  loss_rpn_loc: 0.1727  time: 0.6435  data_time: 0.4351  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:19:16 d2.utils.events]: \u001b[0m eta: 1:27:08  iter: 30899  total_loss: 0.9552  loss_cls: 0.1599  loss_box_reg: 0.1867  loss_mask: 0.2641  loss_rpn_cls: 0.04831  loss_rpn_loc: 0.2061  time: 0.6436  data_time: 0.5845  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:19:28 d2.utils.events]: \u001b[0m eta: 1:26:53  iter: 30919  total_loss: 0.9627  loss_cls: 0.1629  loss_box_reg: 0.2039  loss_mask: 0.2493  loss_rpn_cls: 0.04343  loss_rpn_loc: 0.167  time: 0.6436  data_time: 0.4070  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:19:39 d2.utils.events]: \u001b[0m eta: 1:26:34  iter: 30939  total_loss: 0.7999  loss_cls: 0.1362  loss_box_reg: 0.2057  loss_mask: 0.2292  loss_rpn_cls: 0.03245  loss_rpn_loc: 0.164  time: 0.6435  data_time: 0.3080  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:19:54 d2.utils.events]: \u001b[0m eta: 1:26:52  iter: 30959  total_loss: 0.9719  loss_cls: 0.1598  loss_box_reg: 0.2285  loss_mask: 0.2742  loss_rpn_cls: 0.0595  loss_rpn_loc: 0.1866  time: 0.6436  data_time: 0.5360  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:20:06 d2.utils.events]: \u001b[0m eta: 1:26:23  iter: 30979  total_loss: 0.7239  loss_cls: 0.1436  loss_box_reg: 0.1562  loss_mask: 0.2234  loss_rpn_cls: 0.02693  loss_rpn_loc: 0.1548  time: 0.6435  data_time: 0.3914  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:20:18 d2.utils.events]: \u001b[0m eta: 1:25:58  iter: 30999  total_loss: 0.8389  loss_cls: 0.1604  loss_box_reg: 0.1933  loss_mask: 0.2598  loss_rpn_cls: 0.04309  loss_rpn_loc: 0.1538  time: 0.6435  data_time: 0.3712  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:20:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 15:20:23 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:20:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:20:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:20:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0454 s/iter. Eval: 0.0192 s/iter. Total: 0.0653 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 15:20:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.338039 (0.059608 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:20:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043726 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:20:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 15:20:26 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06789774286122417\n",
      "\u001b[32m[12/30 15:20:34 d2.utils.events]: \u001b[0m eta: 1:25:40  iter: 31019  total_loss: 0.9454  loss_cls: 0.1775  loss_box_reg: 0.2325  loss_mask: 0.2758  loss_rpn_cls: 0.05228  loss_rpn_loc: 0.1791  time: 0.6435  data_time: 0.3950  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:20:44 d2.utils.events]: \u001b[0m eta: 1:25:15  iter: 31039  total_loss: 0.8172  loss_cls: 0.1409  loss_box_reg: 0.1646  loss_mask: 0.1972  loss_rpn_cls: 0.05264  loss_rpn_loc: 0.1895  time: 0.6433  data_time: 0.2962  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:21:01 d2.utils.events]: \u001b[0m eta: 1:26:15  iter: 31059  total_loss: 0.9578  loss_cls: 0.1759  loss_box_reg: 0.2252  loss_mask: 0.2711  loss_rpn_cls: 0.0596  loss_rpn_loc: 0.1927  time: 0.6435  data_time: 0.6234  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:21:15 d2.utils.events]: \u001b[0m eta: 1:26:15  iter: 31079  total_loss: 0.9309  loss_cls: 0.1735  loss_box_reg: 0.1854  loss_mask: 0.2574  loss_rpn_cls: 0.05915  loss_rpn_loc: 0.1799  time: 0.6436  data_time: 0.4823  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:21:27 d2.utils.events]: \u001b[0m eta: 1:27:24  iter: 31099  total_loss: 0.7187  loss_cls: 0.1171  loss_box_reg: 0.176  loss_mask: 0.2151  loss_rpn_cls: 0.04215  loss_rpn_loc: 0.1667  time: 0.6435  data_time: 0.3807  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 15:21:42 d2.utils.events]: \u001b[0m eta: 1:27:43  iter: 31119  total_loss: 0.9182  loss_cls: 0.1611  loss_box_reg: 0.2243  loss_mask: 0.2733  loss_rpn_cls: 0.03669  loss_rpn_loc: 0.1745  time: 0.6436  data_time: 0.4924  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:21:52 d2.utils.events]: \u001b[0m eta: 1:25:28  iter: 31139  total_loss: 0.7363  loss_cls: 0.1344  loss_box_reg: 0.1788  loss_mask: 0.2258  loss_rpn_cls: 0.03006  loss_rpn_loc: 0.1651  time: 0.6435  data_time: 0.2952  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:22:02 d2.utils.events]: \u001b[0m eta: 1:25:58  iter: 31159  total_loss: 0.9019  loss_cls: 0.1362  loss_box_reg: 0.2156  loss_mask: 0.2423  loss_rpn_cls: 0.05113  loss_rpn_loc: 0.1616  time: 0.6434  data_time: 0.3253  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:22:15 d2.utils.events]: \u001b[0m eta: 1:25:38  iter: 31179  total_loss: 0.8896  loss_cls: 0.1343  loss_box_reg: 0.1587  loss_mask: 0.2543  loss_rpn_cls: 0.06362  loss_rpn_loc: 0.1872  time: 0.6433  data_time: 0.3943  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:22:27 d2.utils.events]: \u001b[0m eta: 1:26:15  iter: 31199  total_loss: 0.7869  loss_cls: 0.1387  loss_box_reg: 0.1839  loss_mask: 0.2262  loss_rpn_cls: 0.0334  loss_rpn_loc: 0.1667  time: 0.6433  data_time: 0.3736  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:22:38 d2.utils.events]: \u001b[0m eta: 1:25:27  iter: 31219  total_loss: 0.7626  loss_cls: 0.1297  loss_box_reg: 0.1709  loss_mask: 0.2497  loss_rpn_cls: 0.037  loss_rpn_loc: 0.1754  time: 0.6432  data_time: 0.3551  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:22:51 d2.utils.events]: \u001b[0m eta: 1:26:34  iter: 31239  total_loss: 0.9199  loss_cls: 0.157  loss_box_reg: 0.2054  loss_mask: 0.2702  loss_rpn_cls: 0.05759  loss_rpn_loc: 0.1846  time: 0.6432  data_time: 0.4309  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:23:06 d2.utils.events]: \u001b[0m eta: 1:27:04  iter: 31259  total_loss: 0.8695  loss_cls: 0.1607  loss_box_reg: 0.1941  loss_mask: 0.2674  loss_rpn_cls: 0.06013  loss_rpn_loc: 0.1768  time: 0.6433  data_time: 0.5202  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:23:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 15:23:17 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:23:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:23:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:23:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0009 s/iter. Inference: 0.0452 s/iter. Eval: 0.0193 s/iter. Total: 0.0654 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 15:23:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.357258 (0.059951 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:23:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043811 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:23:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 15:23:20 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06685806705602093\n",
      "\u001b[32m[12/30 15:23:20 d2.utils.events]: \u001b[0m eta: 1:26:23  iter: 31279  total_loss: 0.1746  loss_cls: 9.295e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02573  loss_rpn_loc: 0.1474  time: 0.6432  data_time: 0.3305  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:23:32 d2.utils.events]: \u001b[0m eta: 1:25:06  iter: 31299  total_loss: 0.8582  loss_cls: 0.1447  loss_box_reg: 0.2414  loss_mask: 0.2645  loss_rpn_cls: 0.04281  loss_rpn_loc: 0.1636  time: 0.6432  data_time: 0.3437  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:23:46 d2.utils.events]: \u001b[0m eta: 1:25:46  iter: 31319  total_loss: 0.8835  loss_cls: 0.1438  loss_box_reg: 0.1696  loss_mask: 0.2478  loss_rpn_cls: 0.04407  loss_rpn_loc: 0.1976  time: 0.6432  data_time: 0.4912  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:23:56 d2.utils.events]: \u001b[0m eta: 1:25:13  iter: 31339  total_loss: 0.5202  loss_cls: 0.07111  loss_box_reg: 0.1133  loss_mask: 0.1181  loss_rpn_cls: 0.02795  loss_rpn_loc: 0.1717  time: 0.6431  data_time: 0.2900  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:24:11 d2.utils.events]: \u001b[0m eta: 1:24:49  iter: 31359  total_loss: 0.9419  loss_cls: 0.176  loss_box_reg: 0.2495  loss_mask: 0.2928  loss_rpn_cls: 0.03538  loss_rpn_loc: 0.18  time: 0.6432  data_time: 0.5266  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:24:21 d2.utils.events]: \u001b[0m eta: 1:24:14  iter: 31379  total_loss: 0.9147  loss_cls: 0.1632  loss_box_reg: 0.2362  loss_mask: 0.2493  loss_rpn_cls: 0.04321  loss_rpn_loc: 0.1703  time: 0.6431  data_time: 0.3124  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:24:33 d2.utils.events]: \u001b[0m eta: 1:24:14  iter: 31399  total_loss: 0.9396  loss_cls: 0.1757  loss_box_reg: 0.2233  loss_mask: 0.2552  loss_rpn_cls: 0.03679  loss_rpn_loc: 0.188  time: 0.6430  data_time: 0.3863  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:24:43 d2.utils.events]: \u001b[0m eta: 1:24:04  iter: 31419  total_loss: 0.7599  loss_cls: 0.1418  loss_box_reg: 0.2033  loss_mask: 0.2199  loss_rpn_cls: 0.03788  loss_rpn_loc: 0.1634  time: 0.6429  data_time: 0.3050  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:24:57 d2.utils.events]: \u001b[0m eta: 1:23:28  iter: 31439  total_loss: 0.6234  loss_cls: 0.09392  loss_box_reg: 0.1673  loss_mask: 0.2144  loss_rpn_cls: 0.02434  loss_rpn_loc: 0.1494  time: 0.6430  data_time: 0.4877  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:25:10 d2.utils.events]: \u001b[0m eta: 1:23:53  iter: 31459  total_loss: 0.8345  loss_cls: 0.132  loss_box_reg: 0.2008  loss_mask: 0.2431  loss_rpn_cls: 0.05283  loss_rpn_loc: 0.1676  time: 0.6430  data_time: 0.4394  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:25:25 d2.utils.events]: \u001b[0m eta: 1:24:34  iter: 31479  total_loss: 0.9455  loss_cls: 0.1602  loss_box_reg: 0.1858  loss_mask: 0.2699  loss_rpn_cls: 0.05718  loss_rpn_loc: 0.2071  time: 0.6430  data_time: 0.5054  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:25:34 d2.utils.events]: \u001b[0m eta: 1:23:35  iter: 31499  total_loss: 0.7798  loss_cls: 0.1337  loss_box_reg: 0.188  loss_mask: 0.2105  loss_rpn_cls: 0.02549  loss_rpn_loc: 0.1572  time: 0.6429  data_time: 0.2516  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:25:52 d2.utils.events]: \u001b[0m eta: 1:22:57  iter: 31519  total_loss: 1.004  loss_cls: 0.173  loss_box_reg: 0.1776  loss_mask: 0.2762  loss_rpn_cls: 0.07019  loss_rpn_loc: 0.2126  time: 0.6431  data_time: 0.6274  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:26:10 d2.utils.events]: \u001b[0m eta: 1:21:52  iter: 31539  total_loss: 0.9879  loss_cls: 0.1832  loss_box_reg: 0.2144  loss_mask: 0.2817  loss_rpn_cls: 0.06502  loss_rpn_loc: 0.1985  time: 0.6433  data_time: 0.6700  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:26:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 15:26:19 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:26:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:26:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:26:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0006 s/iter. Inference: 0.0444 s/iter. Eval: 0.0177 s/iter. Total: 0.0627 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 15:26:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.254700 (0.058120 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:26:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043307 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:26:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 15:26:23 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06900231382222959\n",
      "\u001b[32m[12/30 15:26:28 d2.utils.events]: \u001b[0m eta: 1:21:15  iter: 31559  total_loss: 0.8397  loss_cls: 0.1534  loss_box_reg: 0.1878  loss_mask: 0.25  loss_rpn_cls: 0.04625  loss_rpn_loc: 0.1761  time: 0.6434  data_time: 0.5132  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:26:40 d2.utils.events]: \u001b[0m eta: 1:20:29  iter: 31579  total_loss: 0.615  loss_cls: 0.09879  loss_box_reg: 0.1663  loss_mask: 0.2116  loss_rpn_cls: 0.03434  loss_rpn_loc: 0.1753  time: 0.6433  data_time: 0.3777  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 15:26:54 d2.utils.events]: \u001b[0m eta: 1:21:36  iter: 31599  total_loss: 0.8386  loss_cls: 0.1337  loss_box_reg: 0.2172  loss_mask: 0.2682  loss_rpn_cls: 0.04151  loss_rpn_loc: 0.1706  time: 0.6434  data_time: 0.5100  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:27:06 d2.utils.events]: \u001b[0m eta: 1:20:35  iter: 31619  total_loss: 0.9519  loss_cls: 0.1808  loss_box_reg: 0.198  loss_mask: 0.2391  loss_rpn_cls: 0.04456  loss_rpn_loc: 0.1765  time: 0.6434  data_time: 0.3745  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:27:19 d2.utils.events]: \u001b[0m eta: 1:21:52  iter: 31639  total_loss: 0.9674  loss_cls: 0.1793  loss_box_reg: 0.2424  loss_mask: 0.2523  loss_rpn_cls: 0.03774  loss_rpn_loc: 0.1782  time: 0.6433  data_time: 0.4306  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:27:32 d2.utils.events]: \u001b[0m eta: 1:19:57  iter: 31659  total_loss: 0.7016  loss_cls: 0.09975  loss_box_reg: 0.1113  loss_mask: 0.2289  loss_rpn_cls: 0.02526  loss_rpn_loc: 0.134  time: 0.6433  data_time: 0.4428  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:27:44 d2.utils.events]: \u001b[0m eta: 1:19:09  iter: 31679  total_loss: 0.7509  loss_cls: 0.1119  loss_box_reg: 0.1763  loss_mask: 0.2114  loss_rpn_cls: 0.03837  loss_rpn_loc: 0.173  time: 0.6433  data_time: 0.3818  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:27:57 d2.utils.events]: \u001b[0m eta: 1:20:14  iter: 31699  total_loss: 0.9802  loss_cls: 0.159  loss_box_reg: 0.2069  loss_mask: 0.243  loss_rpn_cls: 0.04236  loss_rpn_loc: 0.1647  time: 0.6433  data_time: 0.4416  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:28:09 d2.utils.events]: \u001b[0m eta: 1:20:32  iter: 31719  total_loss: 0.9537  loss_cls: 0.1782  loss_box_reg: 0.2051  loss_mask: 0.2739  loss_rpn_cls: 0.03068  loss_rpn_loc: 0.1534  time: 0.6433  data_time: 0.3827  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:28:25 d2.utils.events]: \u001b[0m eta: 1:20:04  iter: 31739  total_loss: 1.038  loss_cls: 0.2045  loss_box_reg: 0.2553  loss_mask: 0.2724  loss_rpn_cls: 0.06605  loss_rpn_loc: 0.1885  time: 0.6434  data_time: 0.5932  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:28:39 d2.utils.events]: \u001b[0m eta: 1:19:45  iter: 31759  total_loss: 0.8882  loss_cls: 0.1552  loss_box_reg: 0.1977  loss_mask: 0.2761  loss_rpn_cls: 0.04878  loss_rpn_loc: 0.1962  time: 0.6435  data_time: 0.4984  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:28:54 d2.utils.events]: \u001b[0m eta: 1:19:26  iter: 31779  total_loss: 1.019  loss_cls: 0.1669  loss_box_reg: 0.199  loss_mask: 0.2667  loss_rpn_cls: 0.0531  loss_rpn_loc: 0.2136  time: 0.6435  data_time: 0.5096  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:29:09 d2.utils.events]: \u001b[0m eta: 1:19:35  iter: 31799  total_loss: 0.9919  loss_cls: 0.1655  loss_box_reg: 0.2141  loss_mask: 0.2583  loss_rpn_cls: 0.06252  loss_rpn_loc: 0.1883  time: 0.6436  data_time: 0.4906  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:29:20 d2.utils.events]: \u001b[0m eta: 1:19:43  iter: 31819  total_loss: 0.9255  loss_cls: 0.1777  loss_box_reg: 0.2185  loss_mask: 0.2452  loss_rpn_cls: 0.04891  loss_rpn_loc: 0.1616  time: 0.6436  data_time: 0.3627  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:29:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 15:29:22 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:29:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:29:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:29:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0457 s/iter. Eval: 0.0174 s/iter. Total: 0.0639 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 15:29:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.350186 (0.059825 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:29:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043792 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:29:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 15:29:25 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06684761337098084\n",
      "\u001b[32m[12/30 15:29:33 d2.utils.events]: \u001b[0m eta: 1:19:10  iter: 31839  total_loss: 0.7787  loss_cls: 0.139  loss_box_reg: 0.2202  loss_mask: 0.2349  loss_rpn_cls: 0.03854  loss_rpn_loc: 0.167  time: 0.6434  data_time: 0.2321  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:29:47 d2.utils.events]: \u001b[0m eta: 1:19:19  iter: 31859  total_loss: 0.9447  loss_cls: 0.1419  loss_box_reg: 0.209  loss_mask: 0.2649  loss_rpn_cls: 0.06213  loss_rpn_loc: 0.1829  time: 0.6434  data_time: 0.5097  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:30:01 d2.utils.events]: \u001b[0m eta: 1:20:48  iter: 31879  total_loss: 0.9188  loss_cls: 0.1416  loss_box_reg: 0.2125  loss_mask: 0.2638  loss_rpn_cls: 0.041  loss_rpn_loc: 0.1758  time: 0.6435  data_time: 0.4540  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:30:12 d2.utils.events]: \u001b[0m eta: 1:20:16  iter: 31899  total_loss: 0.9802  loss_cls: 0.1849  loss_box_reg: 0.2354  loss_mask: 0.2566  loss_rpn_cls: 0.06813  loss_rpn_loc: 0.1894  time: 0.6434  data_time: 0.3425  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:30:22 d2.utils.events]: \u001b[0m eta: 1:19:39  iter: 31919  total_loss: 0.8071  loss_cls: 0.1447  loss_box_reg: 0.195  loss_mask: 0.2243  loss_rpn_cls: 0.04034  loss_rpn_loc: 0.1618  time: 0.6433  data_time: 0.2945  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:30:37 d2.utils.events]: \u001b[0m eta: 1:20:05  iter: 31939  total_loss: 0.9148  loss_cls: 0.1482  loss_box_reg: 0.1913  loss_mask: 0.2314  loss_rpn_cls: 0.04514  loss_rpn_loc: 0.1805  time: 0.6434  data_time: 0.5485  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:30:50 d2.utils.events]: \u001b[0m eta: 1:18:42  iter: 31959  total_loss: 0.6948  loss_cls: 0.1114  loss_box_reg: 0.1874  loss_mask: 0.2206  loss_rpn_cls: 0.03699  loss_rpn_loc: 0.1679  time: 0.6434  data_time: 0.4226  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:31:03 d2.utils.events]: \u001b[0m eta: 1:18:46  iter: 31979  total_loss: 0.8616  loss_cls: 0.1473  loss_box_reg: 0.2131  loss_mask: 0.2622  loss_rpn_cls: 0.04386  loss_rpn_loc: 0.1685  time: 0.6434  data_time: 0.4167  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:31:17 d2.utils.events]: \u001b[0m eta: 1:18:55  iter: 31999  total_loss: 0.9342  loss_cls: 0.1686  loss_box_reg: 0.2222  loss_mask: 0.2758  loss_rpn_cls: 0.03905  loss_rpn_loc: 0.1777  time: 0.6434  data_time: 0.5231  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:31:34 d2.utils.events]: \u001b[0m eta: 1:19:13  iter: 32019  total_loss: 0.9653  loss_cls: 0.1671  loss_box_reg: 0.2222  loss_mask: 0.2694  loss_rpn_cls: 0.07914  loss_rpn_loc: 0.1985  time: 0.6436  data_time: 0.6270  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:31:44 d2.utils.events]: \u001b[0m eta: 1:19:08  iter: 32039  total_loss: 0.6436  loss_cls: 0.1011  loss_box_reg: 0.1633  loss_mask: 0.2036  loss_rpn_cls: 0.0259  loss_rpn_loc: 0.1569  time: 0.6435  data_time: 0.2601  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:31:56 d2.utils.events]: \u001b[0m eta: 1:17:51  iter: 32059  total_loss: 0.9022  loss_cls: 0.1474  loss_box_reg: 0.1935  loss_mask: 0.2467  loss_rpn_cls: 0.04466  loss_rpn_loc: 0.1771  time: 0.6435  data_time: 0.4234  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:32:12 d2.utils.events]: \u001b[0m eta: 1:18:10  iter: 32079  total_loss: 0.9616  loss_cls: 0.1571  loss_box_reg: 0.2218  loss_mask: 0.2679  loss_rpn_cls: 0.05797  loss_rpn_loc: 0.189  time: 0.6436  data_time: 0.5733  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:32:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 15:32:23 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:32:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:32:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:32:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0443 s/iter. Eval: 0.0171 s/iter. Total: 0.0621 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 15:32:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.357647 (0.059958 s / iter per device, on 1 devices)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 15:32:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043390 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:32:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 15:32:27 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06989309937227696\n",
      "\u001b[32m[12/30 15:32:30 d2.utils.events]: \u001b[0m eta: 1:18:28  iter: 32099  total_loss: 1.039  loss_cls: 0.1492  loss_box_reg: 0.2006  loss_mask: 0.2757  loss_rpn_cls: 0.05067  loss_rpn_loc: 0.1827  time: 0.6436  data_time: 0.4646  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:32:45 d2.utils.events]: \u001b[0m eta: 1:17:44  iter: 32119  total_loss: 0.7843  loss_cls: 0.1174  loss_box_reg: 0.1885  loss_mask: 0.2475  loss_rpn_cls: 0.03597  loss_rpn_loc: 0.1597  time: 0.6437  data_time: 0.5103  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:32:58 d2.utils.events]: \u001b[0m eta: 1:18:40  iter: 32139  total_loss: 0.7251  loss_cls: 0.1266  loss_box_reg: 0.1937  loss_mask: 0.2055  loss_rpn_cls: 0.0414  loss_rpn_loc: 0.1593  time: 0.6437  data_time: 0.4354  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:33:13 d2.utils.events]: \u001b[0m eta: 1:19:02  iter: 32159  total_loss: 0.9225  loss_cls: 0.1674  loss_box_reg: 0.1833  loss_mask: 0.2667  loss_rpn_cls: 0.05298  loss_rpn_loc: 0.1859  time: 0.6438  data_time: 0.5354  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:33:26 d2.utils.events]: \u001b[0m eta: 1:19:28  iter: 32179  total_loss: 0.9194  loss_cls: 0.1564  loss_box_reg: 0.2222  loss_mask: 0.282  loss_rpn_cls: 0.04417  loss_rpn_loc: 0.1729  time: 0.6438  data_time: 0.4222  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:33:37 d2.utils.events]: \u001b[0m eta: 1:18:58  iter: 32199  total_loss: 0.8731  loss_cls: 0.142  loss_box_reg: 0.2216  loss_mask: 0.2523  loss_rpn_cls: 0.03198  loss_rpn_loc: 0.1538  time: 0.6437  data_time: 0.3506  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:33:50 d2.utils.events]: \u001b[0m eta: 1:20:18  iter: 32219  total_loss: 0.9381  loss_cls: 0.1557  loss_box_reg: 0.224  loss_mask: 0.2358  loss_rpn_cls: 0.03783  loss_rpn_loc: 0.1541  time: 0.6437  data_time: 0.4266  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:34:06 d2.utils.events]: \u001b[0m eta: 1:20:13  iter: 32239  total_loss: 0.8782  loss_cls: 0.169  loss_box_reg: 0.2299  loss_mask: 0.2682  loss_rpn_cls: 0.05427  loss_rpn_loc: 0.1584  time: 0.6438  data_time: 0.5640  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:34:20 d2.utils.events]: \u001b[0m eta: 1:21:40  iter: 32259  total_loss: 0.8993  loss_cls: 0.1385  loss_box_reg: 0.1966  loss_mask: 0.2621  loss_rpn_cls: 0.04479  loss_rpn_loc: 0.1861  time: 0.6439  data_time: 0.5077  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:34:29 d2.utils.events]: \u001b[0m eta: 1:21:41  iter: 32279  total_loss: 0.531  loss_cls: 0.1017  loss_box_reg: 0.1533  loss_mask: 0.1582  loss_rpn_cls: 0.03432  loss_rpn_loc: 0.162  time: 0.6437  data_time: 0.2425  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:34:45 d2.utils.events]: \u001b[0m eta: 1:21:57  iter: 32299  total_loss: 0.8607  loss_cls: 0.1596  loss_box_reg: 0.1993  loss_mask: 0.2443  loss_rpn_cls: 0.03559  loss_rpn_loc: 0.1741  time: 0.6439  data_time: 0.5795  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:34:55 d2.utils.events]: \u001b[0m eta: 1:21:42  iter: 32319  total_loss: 0.8086  loss_cls: 0.1631  loss_box_reg: 0.2064  loss_mask: 0.2148  loss_rpn_cls: 0.03343  loss_rpn_loc: 0.1607  time: 0.6437  data_time: 0.2954  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:35:12 d2.utils.events]: \u001b[0m eta: 1:21:50  iter: 32339  total_loss: 0.9336  loss_cls: 0.1589  loss_box_reg: 0.1992  loss_mask: 0.2645  loss_rpn_cls: 0.05884  loss_rpn_loc: 0.185  time: 0.6439  data_time: 0.6205  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:35:21 d2.utils.events]: \u001b[0m eta: 1:21:19  iter: 32359  total_loss: 0.6136  loss_cls: 0.09535  loss_box_reg: 0.1552  loss_mask: 0.2091  loss_rpn_cls: 0.02684  loss_rpn_loc: 0.1561  time: 0.6437  data_time: 0.2452  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:35:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 15:35:25 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:35:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:35:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:35:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0453 s/iter. Eval: 0.0185 s/iter. Total: 0.0644 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 15:35:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.412592 (0.060939 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:35:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.044073 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:35:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 15:35:29 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07231451228547404\n",
      "\u001b[32m[12/30 15:35:35 d2.utils.events]: \u001b[0m eta: 1:21:35  iter: 32379  total_loss: 0.874  loss_cls: 0.1519  loss_box_reg: 0.1958  loss_mask: 0.2533  loss_rpn_cls: 0.03371  loss_rpn_loc: 0.1811  time: 0.6436  data_time: 0.2989  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:35:49 d2.utils.events]: \u001b[0m eta: 1:21:38  iter: 32399  total_loss: 0.927  loss_cls: 0.1451  loss_box_reg: 0.2417  loss_mask: 0.2731  loss_rpn_cls: 0.05122  loss_rpn_loc: 0.1763  time: 0.6437  data_time: 0.4900  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:36:03 d2.utils.events]: \u001b[0m eta: 1:22:01  iter: 32419  total_loss: 0.7781  loss_cls: 0.1272  loss_box_reg: 0.1893  loss_mask: 0.2347  loss_rpn_cls: 0.0291  loss_rpn_loc: 0.1604  time: 0.6437  data_time: 0.4718  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:36:22 d2.utils.events]: \u001b[0m eta: 1:22:19  iter: 32439  total_loss: 0.9358  loss_cls: 0.1782  loss_box_reg: 0.2016  loss_mask: 0.2835  loss_rpn_cls: 0.07169  loss_rpn_loc: 0.1841  time: 0.6440  data_time: 0.7087  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:36:37 d2.utils.events]: \u001b[0m eta: 1:22:15  iter: 32459  total_loss: 0.95  loss_cls: 0.1778  loss_box_reg: 0.2174  loss_mask: 0.2695  loss_rpn_cls: 0.05461  loss_rpn_loc: 0.1899  time: 0.6440  data_time: 0.5102  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:36:47 d2.utils.events]: \u001b[0m eta: 1:21:44  iter: 32479  total_loss: 0.8338  loss_cls: 0.139  loss_box_reg: 0.2168  loss_mask: 0.2255  loss_rpn_cls: 0.03763  loss_rpn_loc: 0.1648  time: 0.6439  data_time: 0.3179  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:36:58 d2.utils.events]: \u001b[0m eta: 1:22:02  iter: 32499  total_loss: 0.7653  loss_cls: 0.127  loss_box_reg: 0.1893  loss_mask: 0.2136  loss_rpn_cls: 0.03181  loss_rpn_loc: 0.173  time: 0.6439  data_time: 0.3380  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:37:08 d2.utils.events]: \u001b[0m eta: 1:21:42  iter: 32519  total_loss: 0.8103  loss_cls: 0.1284  loss_box_reg: 0.1854  loss_mask: 0.239  loss_rpn_cls: 0.04098  loss_rpn_loc: 0.1712  time: 0.6438  data_time: 0.3019  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:37:25 d2.utils.events]: \u001b[0m eta: 1:21:37  iter: 32539  total_loss: 0.8958  loss_cls: 0.1341  loss_box_reg: 0.154  loss_mask: 0.239  loss_rpn_cls: 0.04384  loss_rpn_loc: 0.1731  time: 0.6439  data_time: 0.6430  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:37:39 d2.utils.events]: \u001b[0m eta: 1:21:47  iter: 32559  total_loss: 0.8731  loss_cls: 0.1612  loss_box_reg: 0.2093  loss_mask: 0.2453  loss_rpn_cls: 0.06875  loss_rpn_loc: 0.1777  time: 0.6440  data_time: 0.4535  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:37:51 d2.utils.events]: \u001b[0m eta: 1:22:00  iter: 32579  total_loss: 0.919  loss_cls: 0.1521  loss_box_reg: 0.2325  loss_mask: 0.2913  loss_rpn_cls: 0.03771  loss_rpn_loc: 0.1751  time: 0.6439  data_time: 0.4023  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:38:04 d2.utils.events]: \u001b[0m eta: 1:21:50  iter: 32599  total_loss: 0.8815  loss_cls: 0.143  loss_box_reg: 0.2214  loss_mask: 0.2205  loss_rpn_cls: 0.04472  loss_rpn_loc: 0.1649  time: 0.6439  data_time: 0.4337  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:38:16 d2.utils.events]: \u001b[0m eta: 1:22:21  iter: 32619  total_loss: 0.9717  loss_cls: 0.1653  loss_box_reg: 0.2114  loss_mask: 0.2578  loss_rpn_cls: 0.06143  loss_rpn_loc: 0.1869  time: 0.6439  data_time: 0.3922  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 15:38:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 15:38:32 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:38:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:38:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:38:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0452 s/iter. Eval: 0.0177 s/iter. Total: 0.0636 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 15:38:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.366051 (0.060108 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:38:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043768 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:38:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 15:38:36 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06781583899224253\n",
      "\u001b[32m[12/30 15:38:36 d2.utils.events]: \u001b[0m eta: 1:23:50  iter: 32639  total_loss: 0.9412  loss_cls: 0.1708  loss_box_reg: 0.2353  loss_mask: 0.2694  loss_rpn_cls: 0.06486  loss_rpn_loc: 0.1887  time: 0.6440  data_time: 0.5683  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:38:48 d2.utils.events]: \u001b[0m eta: 1:24:02  iter: 32659  total_loss: 0.8513  loss_cls: 0.1281  loss_box_reg: 0.168  loss_mask: 0.215  loss_rpn_cls: 0.04113  loss_rpn_loc: 0.1828  time: 0.6440  data_time: 0.3756  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:39:00 d2.utils.events]: \u001b[0m eta: 1:26:03  iter: 32679  total_loss: 0.7837  loss_cls: 0.1492  loss_box_reg: 0.209  loss_mask: 0.2283  loss_rpn_cls: 0.04363  loss_rpn_loc: 0.1493  time: 0.6439  data_time: 0.3771  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:39:13 d2.utils.events]: \u001b[0m eta: 1:25:58  iter: 32699  total_loss: 0.9609  loss_cls: 0.1675  loss_box_reg: 0.2115  loss_mask: 0.2717  loss_rpn_cls: 0.03896  loss_rpn_loc: 0.1612  time: 0.6440  data_time: 0.4596  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:39:30 d2.utils.events]: \u001b[0m eta: 1:25:52  iter: 32719  total_loss: 1.011  loss_cls: 0.1742  loss_box_reg: 0.2039  loss_mask: 0.2746  loss_rpn_cls: 0.0618  loss_rpn_loc: 0.1882  time: 0.6441  data_time: 0.6105  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:39:45 d2.utils.events]: \u001b[0m eta: 1:23:39  iter: 32739  total_loss: 0.9616  loss_cls: 0.1674  loss_box_reg: 0.2012  loss_mask: 0.2659  loss_rpn_cls: 0.05221  loss_rpn_loc: 0.1636  time: 0.6442  data_time: 0.5429  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:40:09 d2.utils.events]: \u001b[0m eta: 1:23:48  iter: 32759  total_loss: 0.927  loss_cls: 0.1338  loss_box_reg: 0.1714  loss_mask: 0.2677  loss_rpn_cls: 0.06009  loss_rpn_loc: 0.1883  time: 0.6447  data_time: 0.9703  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:40:19 d2.utils.events]: \u001b[0m eta: 1:22:03  iter: 32779  total_loss: 0.5959  loss_cls: 0.06995  loss_box_reg: 0.1505  loss_mask: 0.2066  loss_rpn_cls: 0.019  loss_rpn_loc: 0.1484  time: 0.6445  data_time: 0.2555  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:40:30 d2.utils.events]: \u001b[0m eta: 1:21:21  iter: 32799  total_loss: 0.9733  loss_cls: 0.1483  loss_box_reg: 0.2227  loss_mask: 0.2863  loss_rpn_cls: 0.05454  loss_rpn_loc: 0.1941  time: 0.6444  data_time: 0.3476  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:40:43 d2.utils.events]: \u001b[0m eta: 1:23:02  iter: 32819  total_loss: 0.8437  loss_cls: 0.1298  loss_box_reg: 0.2086  loss_mask: 0.2417  loss_rpn_cls: 0.03739  loss_rpn_loc: 0.1759  time: 0.6444  data_time: 0.4334  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:40:56 d2.utils.events]: \u001b[0m eta: 1:25:19  iter: 32839  total_loss: 0.9787  loss_cls: 0.1533  loss_box_reg: 0.2307  loss_mask: 0.284  loss_rpn_cls: 0.04515  loss_rpn_loc: 0.1878  time: 0.6445  data_time: 0.4574  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:41:10 d2.utils.events]: \u001b[0m eta: 1:25:10  iter: 32859  total_loss: 0.8992  loss_cls: 0.1529  loss_box_reg: 0.2109  loss_mask: 0.2751  loss_rpn_cls: 0.04085  loss_rpn_loc: 0.181  time: 0.6445  data_time: 0.4843  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:41:21 d2.utils.events]: \u001b[0m eta: 1:22:58  iter: 32879  total_loss: 0.8441  loss_cls: 0.1556  loss_box_reg: 0.2179  loss_mask: 0.2477  loss_rpn_cls: 0.03173  loss_rpn_loc: 0.1625  time: 0.6444  data_time: 0.3404  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:41:30 d2.utils.events]: \u001b[0m eta: 1:22:52  iter: 32899  total_loss: 0.8299  loss_cls: 0.1581  loss_box_reg: 0.2124  loss_mask: 0.246  loss_rpn_cls: 0.03382  loss_rpn_loc: 0.1646  time: 0.6443  data_time: 0.2325  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:41:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 15:41:43 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:41:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:41:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:41:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0458 s/iter. Eval: 0.0185 s/iter. Total: 0.0650 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 15:41:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.411256 (0.060915 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:41:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043723 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:41:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 15:41:47 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0730311868152469\n",
      "\u001b[32m[12/30 15:41:53 d2.utils.events]: \u001b[0m eta: 1:24:01  iter: 32919  total_loss: 1.053  loss_cls: 0.1784  loss_box_reg: 0.226  loss_mask: 0.2754  loss_rpn_cls: 0.05885  loss_rpn_loc: 0.1949  time: 0.6445  data_time: 0.7053  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:42:05 d2.utils.events]: \u001b[0m eta: 1:23:55  iter: 32939  total_loss: 0.8839  loss_cls: 0.1517  loss_box_reg: 0.2559  loss_mask: 0.2696  loss_rpn_cls: 0.02929  loss_rpn_loc: 0.1692  time: 0.6445  data_time: 0.3948  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:42:16 d2.utils.events]: \u001b[0m eta: 1:22:29  iter: 32959  total_loss: 0.7079  loss_cls: 0.1181  loss_box_reg: 0.1813  loss_mask: 0.2133  loss_rpn_cls: 0.02901  loss_rpn_loc: 0.1572  time: 0.6444  data_time: 0.3256  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:42:29 d2.utils.events]: \u001b[0m eta: 1:21:46  iter: 32979  total_loss: 0.8347  loss_cls: 0.1342  loss_box_reg: 0.2282  loss_mask: 0.2387  loss_rpn_cls: 0.0305  loss_rpn_loc: 0.1515  time: 0.6444  data_time: 0.4233  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:42:39 d2.utils.events]: \u001b[0m eta: 1:21:00  iter: 32999  total_loss: 0.7566  loss_cls: 0.1348  loss_box_reg: 0.1634  loss_mask: 0.217  loss_rpn_cls: 0.02786  loss_rpn_loc: 0.1604  time: 0.6443  data_time: 0.2682  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:42:53 d2.utils.events]: \u001b[0m eta: 1:19:56  iter: 33019  total_loss: 0.6985  loss_cls: 0.1115  loss_box_reg: 0.1608  loss_mask: 0.1886  loss_rpn_cls: 0.04531  loss_rpn_loc: 0.1745  time: 0.6443  data_time: 0.4765  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:43:06 d2.utils.events]: \u001b[0m eta: 1:19:50  iter: 33039  total_loss: 0.5299  loss_cls: 0.07907  loss_box_reg: 0.117  loss_mask: 0.1732  loss_rpn_cls: 0.04438  loss_rpn_loc: 0.1573  time: 0.6443  data_time: 0.4573  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:43:20 d2.utils.events]: \u001b[0m eta: 1:19:34  iter: 33059  total_loss: 0.7827  loss_cls: 0.1193  loss_box_reg: 0.204  loss_mask: 0.2473  loss_rpn_cls: 0.03572  loss_rpn_loc: 0.1696  time: 0.6444  data_time: 0.5119  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:43:35 d2.utils.events]: \u001b[0m eta: 1:19:19  iter: 33079  total_loss: 0.9482  loss_cls: 0.1851  loss_box_reg: 0.2502  loss_mask: 0.2757  loss_rpn_cls: 0.06355  loss_rpn_loc: 0.1761  time: 0.6444  data_time: 0.4750  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:43:44 d2.utils.events]: \u001b[0m eta: 1:18:48  iter: 33099  total_loss: 0.8046  loss_cls: 0.1566  loss_box_reg: 0.1706  loss_mask: 0.2606  loss_rpn_cls: 0.0374  loss_rpn_loc: 0.1693  time: 0.6443  data_time: 0.2669  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 15:43:58 d2.utils.events]: \u001b[0m eta: 1:18:54  iter: 33119  total_loss: 0.9255  loss_cls: 0.179  loss_box_reg: 0.2179  loss_mask: 0.2656  loss_rpn_cls: 0.04914  loss_rpn_loc: 0.1875  time: 0.6443  data_time: 0.4656  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:44:09 d2.utils.events]: \u001b[0m eta: 1:18:39  iter: 33139  total_loss: 0.907  loss_cls: 0.1478  loss_box_reg: 0.2427  loss_mask: 0.2386  loss_rpn_cls: 0.0623  loss_rpn_loc: 0.1899  time: 0.6443  data_time: 0.3705  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:44:24 d2.utils.events]: \u001b[0m eta: 1:18:53  iter: 33159  total_loss: 0.9711  loss_cls: 0.1816  loss_box_reg: 0.2038  loss_mask: 0.3035  loss_rpn_cls: 0.06787  loss_rpn_loc: 0.1769  time: 0.6444  data_time: 0.5072  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:44:40 d2.utils.events]: \u001b[0m eta: 1:19:00  iter: 33179  total_loss: 1.011  loss_cls: 0.1973  loss_box_reg: 0.2743  loss_mask: 0.2735  loss_rpn_cls: 0.08112  loss_rpn_loc: 0.2033  time: 0.6445  data_time: 0.5715  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:44:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 15:44:43 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:44:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:44:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:44:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0445 s/iter. Eval: 0.0172 s/iter. Total: 0.0624 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 15:44:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.265378 (0.058310 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:44:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043237 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:44:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 15:44:46 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06500340418155177\n",
      "\u001b[32m[12/30 15:44:54 d2.utils.events]: \u001b[0m eta: 1:18:42  iter: 33199  total_loss: 0.6554  loss_cls: 0.118  loss_box_reg: 0.1706  loss_mask: 0.1977  loss_rpn_cls: 0.02892  loss_rpn_loc: 0.1467  time: 0.6444  data_time: 0.3090  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:45:07 d2.utils.events]: \u001b[0m eta: 1:17:52  iter: 33219  total_loss: 0.9111  loss_cls: 0.1554  loss_box_reg: 0.1964  loss_mask: 0.27  loss_rpn_cls: 0.03274  loss_rpn_loc: 0.1498  time: 0.6444  data_time: 0.4284  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:45:18 d2.utils.events]: \u001b[0m eta: 1:15:53  iter: 33239  total_loss: 0.8558  loss_cls: 0.1469  loss_box_reg: 0.1868  loss_mask: 0.2423  loss_rpn_cls: 0.03205  loss_rpn_loc: 0.157  time: 0.6443  data_time: 0.3286  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:45:34 d2.utils.events]: \u001b[0m eta: 1:14:57  iter: 33259  total_loss: 1.001  loss_cls: 0.186  loss_box_reg: 0.2261  loss_mask: 0.2674  loss_rpn_cls: 0.07189  loss_rpn_loc: 0.206  time: 0.6444  data_time: 0.6131  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:45:48 d2.utils.events]: \u001b[0m eta: 1:16:42  iter: 33279  total_loss: 0.9381  loss_cls: 0.1675  loss_box_reg: 0.2224  loss_mask: 0.2452  loss_rpn_cls: 0.05131  loss_rpn_loc: 0.174  time: 0.6445  data_time: 0.4564  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:46:03 d2.utils.events]: \u001b[0m eta: 1:15:37  iter: 33299  total_loss: 0.8975  loss_cls: 0.1468  loss_box_reg: 0.198  loss_mask: 0.2226  loss_rpn_cls: 0.05108  loss_rpn_loc: 0.1747  time: 0.6445  data_time: 0.5145  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:46:19 d2.utils.events]: \u001b[0m eta: 1:16:31  iter: 33319  total_loss: 0.9352  loss_cls: 0.1688  loss_box_reg: 0.2146  loss_mask: 0.2618  loss_rpn_cls: 0.05469  loss_rpn_loc: 0.1836  time: 0.6447  data_time: 0.5836  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:46:28 d2.utils.events]: \u001b[0m eta: 1:14:52  iter: 33339  total_loss: 0.5559  loss_cls: 0.06959  loss_box_reg: 0.1531  loss_mask: 0.1794  loss_rpn_cls: 0.02528  loss_rpn_loc: 0.145  time: 0.6445  data_time: 0.2794  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:46:41 d2.utils.events]: \u001b[0m eta: 1:16:20  iter: 33359  total_loss: 0.9975  loss_cls: 0.1892  loss_box_reg: 0.2329  loss_mask: 0.2599  loss_rpn_cls: 0.04862  loss_rpn_loc: 0.1969  time: 0.6445  data_time: 0.4299  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:46:52 d2.utils.events]: \u001b[0m eta: 1:14:41  iter: 33379  total_loss: 0.8069  loss_cls: 0.1325  loss_box_reg: 0.1989  loss_mask: 0.2495  loss_rpn_cls: 0.02623  loss_rpn_loc: 0.1733  time: 0.6444  data_time: 0.3530  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:47:06 d2.utils.events]: \u001b[0m eta: 1:13:57  iter: 33399  total_loss: 0.9141  loss_cls: 0.137  loss_box_reg: 0.1987  loss_mask: 0.2513  loss_rpn_cls: 0.03262  loss_rpn_loc: 0.1747  time: 0.6445  data_time: 0.4535  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:47:17 d2.utils.events]: \u001b[0m eta: 1:14:05  iter: 33419  total_loss: 1.033  loss_cls: 0.2162  loss_box_reg: 0.2613  loss_mask: 0.2696  loss_rpn_cls: 0.06433  loss_rpn_loc: 0.1921  time: 0.6444  data_time: 0.3397  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:47:35 d2.utils.events]: \u001b[0m eta: 1:14:00  iter: 33439  total_loss: 1.06  loss_cls: 0.1894  loss_box_reg: 0.2249  loss_mask: 0.274  loss_rpn_cls: 0.06764  loss_rpn_loc: 0.1771  time: 0.6446  data_time: 0.6380  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:47:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 15:47:42 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:47:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:47:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:47:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0446 s/iter. Eval: 0.0173 s/iter. Total: 0.0626 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 15:47:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.343159 (0.059699 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:47:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043853 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:47:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 15:47:46 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06674800751872342\n",
      "\u001b[32m[12/30 15:47:48 d2.utils.events]: \u001b[0m eta: 1:13:28  iter: 33459  total_loss: 0.7188  loss_cls: 0.1186  loss_box_reg: 0.1846  loss_mask: 0.2339  loss_rpn_cls: 0.02849  loss_rpn_loc: 0.1516  time: 0.6445  data_time: 0.2793  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:48:00 d2.utils.events]: \u001b[0m eta: 1:13:41  iter: 33479  total_loss: 0.9015  loss_cls: 0.1482  loss_box_reg: 0.2196  loss_mask: 0.2624  loss_rpn_cls: 0.04372  loss_rpn_loc: 0.1743  time: 0.6444  data_time: 0.3802  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:48:11 d2.utils.events]: \u001b[0m eta: 1:13:53  iter: 33499  total_loss: 0.9309  loss_cls: 0.158  loss_box_reg: 0.195  loss_mask: 0.2568  loss_rpn_cls: 0.04878  loss_rpn_loc: 0.1787  time: 0.6444  data_time: 0.3622  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:48:19 d2.utils.events]: \u001b[0m eta: 1:13:31  iter: 33519  total_loss: 0.7156  loss_cls: 0.1153  loss_box_reg: 0.2049  loss_mask: 0.2001  loss_rpn_cls: 0.03117  loss_rpn_loc: 0.139  time: 0.6442  data_time: 0.2006  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:48:31 d2.utils.events]: \u001b[0m eta: 1:13:33  iter: 33539  total_loss: 0.8998  loss_cls: 0.1574  loss_box_reg: 0.1982  loss_mask: 0.2391  loss_rpn_cls: 0.04819  loss_rpn_loc: 0.1573  time: 0.6441  data_time: 0.3796  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:48:43 d2.utils.events]: \u001b[0m eta: 1:13:10  iter: 33559  total_loss: 0.7685  loss_cls: 0.1181  loss_box_reg: 0.162  loss_mask: 0.2209  loss_rpn_cls: 0.03816  loss_rpn_loc: 0.1634  time: 0.6441  data_time: 0.3570  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:48:56 d2.utils.events]: \u001b[0m eta: 1:13:05  iter: 33579  total_loss: 1.017  loss_cls: 0.1902  loss_box_reg: 0.2347  loss_mask: 0.2663  loss_rpn_cls: 0.05925  loss_rpn_loc: 0.1927  time: 0.6441  data_time: 0.4729  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 15:49:10 d2.utils.events]: \u001b[0m eta: 1:13:11  iter: 33599  total_loss: 0.9283  loss_cls: 0.1539  loss_box_reg: 0.1976  loss_mask: 0.2779  loss_rpn_cls: 0.05219  loss_rpn_loc: 0.1871  time: 0.6441  data_time: 0.4472  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:49:23 d2.utils.events]: \u001b[0m eta: 1:12:48  iter: 33619  total_loss: 0.8416  loss_cls: 0.1369  loss_box_reg: 0.226  loss_mask: 0.2388  loss_rpn_cls: 0.03552  loss_rpn_loc: 0.1565  time: 0.6441  data_time: 0.4163  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:49:39 d2.utils.events]: \u001b[0m eta: 1:12:40  iter: 33639  total_loss: 0.9692  loss_cls: 0.1669  loss_box_reg: 0.2195  loss_mask: 0.2636  loss_rpn_cls: 0.06063  loss_rpn_loc: 0.1858  time: 0.6442  data_time: 0.5589  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:49:54 d2.utils.events]: \u001b[0m eta: 1:12:37  iter: 33659  total_loss: 0.9216  loss_cls: 0.1567  loss_box_reg: 0.1963  loss_mask: 0.2559  loss_rpn_cls: 0.05078  loss_rpn_loc: 0.1898  time: 0.6443  data_time: 0.5500  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:50:07 d2.utils.events]: \u001b[0m eta: 1:12:29  iter: 33679  total_loss: 0.8442  loss_cls: 0.1404  loss_box_reg: 0.168  loss_mask: 0.2572  loss_rpn_cls: 0.06553  loss_rpn_loc: 0.1498  time: 0.6443  data_time: 0.4594  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:50:17 d2.utils.events]: \u001b[0m eta: 1:11:53  iter: 33699  total_loss: 0.7982  loss_cls: 0.1227  loss_box_reg: 0.2089  loss_mask: 0.2452  loss_rpn_cls: 0.05137  loss_rpn_loc: 0.1824  time: 0.6442  data_time: 0.2457  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:50:32 d2.utils.events]: \u001b[0m eta: 1:12:12  iter: 33719  total_loss: 0.9643  loss_cls: 0.1995  loss_box_reg: 0.2605  loss_mask: 0.2624  loss_rpn_cls: 0.05069  loss_rpn_loc: 0.1745  time: 0.6443  data_time: 0.5249  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:50:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 15:50:39 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:50:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:50:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:50:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0434 s/iter. Eval: 0.0150 s/iter. Total: 0.0591 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/30 15:50:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.161480 (0.056455 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:50:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043018 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:50:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 15:50:43 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.05879285857402666\n",
      "\u001b[32m[12/30 15:50:49 d2.utils.events]: \u001b[0m eta: 1:12:07  iter: 33739  total_loss: 0.8074  loss_cls: 0.1277  loss_box_reg: 0.1874  loss_mask: 0.2608  loss_rpn_cls: 0.0307  loss_rpn_loc: 0.168  time: 0.6443  data_time: 0.4766  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:51:03 d2.utils.events]: \u001b[0m eta: 1:11:38  iter: 33759  total_loss: 0.9484  loss_cls: 0.1765  loss_box_reg: 0.2149  loss_mask: 0.261  loss_rpn_cls: 0.04925  loss_rpn_loc: 0.187  time: 0.6444  data_time: 0.4852  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:51:18 d2.utils.events]: \u001b[0m eta: 1:12:23  iter: 33779  total_loss: 1.031  loss_cls: 0.1903  loss_box_reg: 0.2384  loss_mask: 0.2535  loss_rpn_cls: 0.06686  loss_rpn_loc: 0.1979  time: 0.6444  data_time: 0.4980  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:51:29 d2.utils.events]: \u001b[0m eta: 1:12:13  iter: 33799  total_loss: 0.824  loss_cls: 0.1228  loss_box_reg: 0.1832  loss_mask: 0.2334  loss_rpn_cls: 0.02725  loss_rpn_loc: 0.1507  time: 0.6444  data_time: 0.3541  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:51:40 d2.utils.events]: \u001b[0m eta: 1:11:46  iter: 33819  total_loss: 0.6242  loss_cls: 0.09206  loss_box_reg: 0.1709  loss_mask: 0.1827  loss_rpn_cls: 0.02321  loss_rpn_loc: 0.1518  time: 0.6443  data_time: 0.3167  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:51:50 d2.utils.events]: \u001b[0m eta: 1:10:56  iter: 33839  total_loss: 0.8297  loss_cls: 0.1341  loss_box_reg: 0.2141  loss_mask: 0.2477  loss_rpn_cls: 0.0325  loss_rpn_loc: 0.1643  time: 0.6442  data_time: 0.3215  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:52:01 d2.utils.events]: \u001b[0m eta: 1:10:44  iter: 33859  total_loss: 0.7379  loss_cls: 0.1306  loss_box_reg: 0.166  loss_mask: 0.1891  loss_rpn_cls: 0.02947  loss_rpn_loc: 0.1532  time: 0.6441  data_time: 0.3250  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:52:18 d2.utils.events]: \u001b[0m eta: 1:11:38  iter: 33879  total_loss: 1.059  loss_cls: 0.2021  loss_box_reg: 0.2785  loss_mask: 0.272  loss_rpn_cls: 0.05996  loss_rpn_loc: 0.2105  time: 0.6443  data_time: 0.6355  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:52:33 d2.utils.events]: \u001b[0m eta: 1:11:30  iter: 33899  total_loss: 0.9049  loss_cls: 0.1465  loss_box_reg: 0.177  loss_mask: 0.2777  loss_rpn_cls: 0.04354  loss_rpn_loc: 0.1562  time: 0.6443  data_time: 0.4959  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:52:44 d2.utils.events]: \u001b[0m eta: 1:11:23  iter: 33919  total_loss: 0.8938  loss_cls: 0.1734  loss_box_reg: 0.2015  loss_mask: 0.2491  loss_rpn_cls: 0.04596  loss_rpn_loc: 0.1782  time: 0.6443  data_time: 0.3551  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:52:53 d2.utils.events]: \u001b[0m eta: 1:10:49  iter: 33939  total_loss: 0.6781  loss_cls: 0.1145  loss_box_reg: 0.196  loss_mask: 0.2103  loss_rpn_cls: 0.02901  loss_rpn_loc: 0.1508  time: 0.6441  data_time: 0.2332  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:53:04 d2.utils.events]: \u001b[0m eta: 1:11:14  iter: 33959  total_loss: 0.8188  loss_cls: 0.1327  loss_box_reg: 0.1845  loss_mask: 0.2536  loss_rpn_cls: 0.05303  loss_rpn_loc: 0.1652  time: 0.6440  data_time: 0.3456  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:53:17 d2.utils.events]: \u001b[0m eta: 1:11:25  iter: 33979  total_loss: 0.8393  loss_cls: 0.1534  loss_box_reg: 0.1989  loss_mask: 0.2286  loss_rpn_cls: 0.03094  loss_rpn_loc: 0.1793  time: 0.6440  data_time: 0.4311  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:53:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 15:53:32 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:53:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:53:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:53:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0449 s/iter. Eval: 0.0173 s/iter. Total: 0.0628 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 15:53:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.284390 (0.058650 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:53:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043717 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:53:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 15:53:35 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06667533933103731\n",
      "\u001b[32m[12/30 15:53:35 d2.utils.events]: \u001b[0m eta: 1:11:30  iter: 33999  total_loss: 0.9984  loss_cls: 0.1786  loss_box_reg: 0.2342  loss_mask: 0.2712  loss_rpn_cls: 0.06941  loss_rpn_loc: 0.1859  time: 0.6441  data_time: 0.5127  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:53:52 d2.utils.events]: \u001b[0m eta: 1:11:39  iter: 34019  total_loss: 0.8914  loss_cls: 0.156  loss_box_reg: 0.1884  loss_mask: 0.255  loss_rpn_cls: 0.05  loss_rpn_loc: 0.1808  time: 0.6443  data_time: 0.6131  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:54:03 d2.utils.events]: \u001b[0m eta: 1:12:07  iter: 34039  total_loss: 0.8802  loss_cls: 0.1438  loss_box_reg: 0.235  loss_mask: 0.2575  loss_rpn_cls: 0.04322  loss_rpn_loc: 0.1655  time: 0.6442  data_time: 0.3441  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:54:15 d2.utils.events]: \u001b[0m eta: 1:12:08  iter: 34059  total_loss: 0.8056  loss_cls: 0.1315  loss_box_reg: 0.1883  loss_mask: 0.2173  loss_rpn_cls: 0.03949  loss_rpn_loc: 0.1779  time: 0.6442  data_time: 0.3994  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 15:54:26 d2.utils.events]: \u001b[0m eta: 1:11:56  iter: 34079  total_loss: 0.9462  loss_cls: 0.1496  loss_box_reg: 0.2022  loss_mask: 0.2545  loss_rpn_cls: 0.04802  loss_rpn_loc: 0.1819  time: 0.6440  data_time: 0.3007  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:54:42 d2.utils.events]: \u001b[0m eta: 1:12:29  iter: 34099  total_loss: 0.8564  loss_cls: 0.146  loss_box_reg: 0.1988  loss_mask: 0.2459  loss_rpn_cls: 0.0544  loss_rpn_loc: 0.1745  time: 0.6442  data_time: 0.6112  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:54:54 d2.utils.events]: \u001b[0m eta: 1:12:31  iter: 34119  total_loss: 0.904  loss_cls: 0.1407  loss_box_reg: 0.1869  loss_mask: 0.2606  loss_rpn_cls: 0.03818  loss_rpn_loc: 0.1777  time: 0.6442  data_time: 0.4012  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:55:10 d2.utils.events]: \u001b[0m eta: 1:12:29  iter: 34139  total_loss: 0.8486  loss_cls: 0.1497  loss_box_reg: 0.172  loss_mask: 0.2794  loss_rpn_cls: 0.03808  loss_rpn_loc: 0.1721  time: 0.6443  data_time: 0.5578  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:55:28 d2.utils.events]: \u001b[0m eta: 1:12:12  iter: 34159  total_loss: 0.9826  loss_cls: 0.1604  loss_box_reg: 0.2198  loss_mask: 0.2796  loss_rpn_cls: 0.05428  loss_rpn_loc: 0.1712  time: 0.6445  data_time: 0.6634  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:55:37 d2.utils.events]: \u001b[0m eta: 1:11:11  iter: 34179  total_loss: 0.8088  loss_cls: 0.1292  loss_box_reg: 0.1814  loss_mask: 0.2478  loss_rpn_cls: 0.04148  loss_rpn_loc: 0.1684  time: 0.6443  data_time: 0.2524  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:55:54 d2.utils.events]: \u001b[0m eta: 1:12:09  iter: 34199  total_loss: 0.9415  loss_cls: 0.1762  loss_box_reg: 0.2137  loss_mask: 0.2714  loss_rpn_cls: 0.06035  loss_rpn_loc: 0.1922  time: 0.6445  data_time: 0.6059  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:56:06 d2.utils.events]: \u001b[0m eta: 1:12:29  iter: 34219  total_loss: 0.8797  loss_cls: 0.1409  loss_box_reg: 0.2229  loss_mask: 0.2766  loss_rpn_cls: 0.0296  loss_rpn_loc: 0.1677  time: 0.6444  data_time: 0.3522  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:56:19 d2.utils.events]: \u001b[0m eta: 1:12:42  iter: 34239  total_loss: 0.8915  loss_cls: 0.1718  loss_box_reg: 0.2264  loss_mask: 0.2427  loss_rpn_cls: 0.04567  loss_rpn_loc: 0.1745  time: 0.6444  data_time: 0.4765  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:56:31 d2.utils.events]: \u001b[0m eta: 1:11:53  iter: 34259  total_loss: 0.844  loss_cls: 0.1449  loss_box_reg: 0.1889  loss_mask: 0.2434  loss_rpn_cls: 0.04132  loss_rpn_loc: 0.1642  time: 0.6444  data_time: 0.3594  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:56:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 15:56:40 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:56:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:56:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:56:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0448 s/iter. Eval: 0.0181 s/iter. Total: 0.0636 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 15:56:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.269026 (0.058375 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:56:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043517 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:56:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 15:56:44 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0663950091196384\n",
      "\u001b[32m[12/30 15:56:48 d2.utils.events]: \u001b[0m eta: 1:11:51  iter: 34279  total_loss: 0.9571  loss_cls: 0.1735  loss_box_reg: 0.2392  loss_mask: 0.2773  loss_rpn_cls: 0.05082  loss_rpn_loc: 0.1708  time: 0.6444  data_time: 0.4300  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:57:00 d2.utils.events]: \u001b[0m eta: 1:12:04  iter: 34299  total_loss: 0.9211  loss_cls: 0.1454  loss_box_reg: 0.2153  loss_mask: 0.2451  loss_rpn_cls: 0.04638  loss_rpn_loc: 0.1667  time: 0.6444  data_time: 0.3900  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:57:17 d2.utils.events]: \u001b[0m eta: 1:12:20  iter: 34319  total_loss: 0.9159  loss_cls: 0.1727  loss_box_reg: 0.2196  loss_mask: 0.2687  loss_rpn_cls: 0.05508  loss_rpn_loc: 0.1892  time: 0.6445  data_time: 0.6353  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:57:28 d2.utils.events]: \u001b[0m eta: 1:12:14  iter: 34339  total_loss: 0.709  loss_cls: 0.1062  loss_box_reg: 0.1853  loss_mask: 0.219  loss_rpn_cls: 0.01833  loss_rpn_loc: 0.1382  time: 0.6445  data_time: 0.3689  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:57:42 d2.utils.events]: \u001b[0m eta: 1:12:22  iter: 34359  total_loss: 0.8798  loss_cls: 0.1721  loss_box_reg: 0.2065  loss_mask: 0.2215  loss_rpn_cls: 0.05059  loss_rpn_loc: 0.1946  time: 0.6445  data_time: 0.4676  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:57:55 d2.utils.events]: \u001b[0m eta: 1:14:50  iter: 34379  total_loss: 0.9859  loss_cls: 0.1682  loss_box_reg: 0.2335  loss_mask: 0.2753  loss_rpn_cls: 0.06412  loss_rpn_loc: 0.1882  time: 0.6445  data_time: 0.4351  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:58:07 d2.utils.events]: \u001b[0m eta: 1:14:49  iter: 34399  total_loss: 0.9192  loss_cls: 0.1419  loss_box_reg: 0.2052  loss_mask: 0.2603  loss_rpn_cls: 0.05499  loss_rpn_loc: 0.1794  time: 0.6445  data_time: 0.3696  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:58:22 d2.utils.events]: \u001b[0m eta: 1:15:26  iter: 34419  total_loss: 0.99  loss_cls: 0.1918  loss_box_reg: 0.1934  loss_mask: 0.2718  loss_rpn_cls: 0.04667  loss_rpn_loc: 0.1855  time: 0.6446  data_time: 0.5501  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:58:35 d2.utils.events]: \u001b[0m eta: 1:15:05  iter: 34439  total_loss: 0.8238  loss_cls: 0.1382  loss_box_reg: 0.1924  loss_mask: 0.2492  loss_rpn_cls: 0.03726  loss_rpn_loc: 0.1676  time: 0.6445  data_time: 0.4120  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:58:46 d2.utils.events]: \u001b[0m eta: 1:14:31  iter: 34459  total_loss: 0.2149  loss_cls: 6.273e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02434  loss_rpn_loc: 0.1542  time: 0.6445  data_time: 0.3806  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:58:57 d2.utils.events]: \u001b[0m eta: 1:14:08  iter: 34479  total_loss: 0.7813  loss_cls: 0.1307  loss_box_reg: 0.1754  loss_mask: 0.2431  loss_rpn_cls: 0.03336  loss_rpn_loc: 0.1519  time: 0.6444  data_time: 0.3412  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:59:12 d2.utils.events]: \u001b[0m eta: 1:13:24  iter: 34499  total_loss: 0.7867  loss_cls: 0.141  loss_box_reg: 0.1951  loss_mask: 0.2328  loss_rpn_cls: 0.0437  loss_rpn_loc: 0.1514  time: 0.6445  data_time: 0.5046  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:59:25 d2.utils.events]: \u001b[0m eta: 1:14:14  iter: 34519  total_loss: 0.8398  loss_cls: 0.1358  loss_box_reg: 0.2316  loss_mask: 0.2593  loss_rpn_cls: 0.04777  loss_rpn_loc: 0.1751  time: 0.6445  data_time: 0.4186  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:59:42 d2.utils.events]: \u001b[0m eta: 1:14:57  iter: 34539  total_loss: 0.8955  loss_cls: 0.1451  loss_box_reg: 0.2107  loss_mask: 0.2634  loss_rpn_cls: 0.04977  loss_rpn_loc: 0.1757  time: 0.6446  data_time: 0.6513  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 15:59:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 15:59:44 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 15:59:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 15:59:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 15:59:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0458 s/iter. Eval: 0.0181 s/iter. Total: 0.0646 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 15:59:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.277670 (0.058530 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:59:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043809 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 15:59:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 15:59:47 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06749798040985952\n",
      "\u001b[32m[12/30 15:59:55 d2.utils.events]: \u001b[0m eta: 1:14:51  iter: 34559  total_loss: 0.8795  loss_cls: 0.1323  loss_box_reg: 0.1737  loss_mask: 0.2789  loss_rpn_cls: 0.03797  loss_rpn_loc: 0.1861  time: 0.6445  data_time: 0.2610  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:00:10 d2.utils.events]: \u001b[0m eta: 1:14:40  iter: 34579  total_loss: 0.8742  loss_cls: 0.1308  loss_box_reg: 0.1741  loss_mask: 0.2588  loss_rpn_cls: 0.04296  loss_rpn_loc: 0.1897  time: 0.6446  data_time: 0.5264  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:00:24 d2.utils.events]: \u001b[0m eta: 1:14:34  iter: 34599  total_loss: 0.8839  loss_cls: 0.1335  loss_box_reg: 0.2051  loss_mask: 0.2682  loss_rpn_cls: 0.03028  loss_rpn_loc: 0.169  time: 0.6446  data_time: 0.4772  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:00:35 d2.utils.events]: \u001b[0m eta: 1:13:45  iter: 34619  total_loss: 0.7743  loss_cls: 0.1227  loss_box_reg: 0.1907  loss_mask: 0.2137  loss_rpn_cls: 0.03488  loss_rpn_loc: 0.1515  time: 0.6445  data_time: 0.3515  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:00:50 d2.utils.events]: \u001b[0m eta: 1:13:12  iter: 34639  total_loss: 0.8404  loss_cls: 0.1278  loss_box_reg: 0.2227  loss_mask: 0.2442  loss_rpn_cls: 0.04963  loss_rpn_loc: 0.1714  time: 0.6446  data_time: 0.5255  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:01:01 d2.utils.events]: \u001b[0m eta: 1:11:56  iter: 34659  total_loss: 0.7613  loss_cls: 0.1169  loss_box_reg: 0.1916  loss_mask: 0.2499  loss_rpn_cls: 0.03196  loss_rpn_loc: 0.1529  time: 0.6446  data_time: 0.3289  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:01:13 d2.utils.events]: \u001b[0m eta: 1:11:33  iter: 34679  total_loss: 0.8144  loss_cls: 0.159  loss_box_reg: 0.2189  loss_mask: 0.2379  loss_rpn_cls: 0.03238  loss_rpn_loc: 0.1661  time: 0.6445  data_time: 0.4042  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:01:26 d2.utils.events]: \u001b[0m eta: 1:11:06  iter: 34699  total_loss: 0.967  loss_cls: 0.1839  loss_box_reg: 0.2129  loss_mask: 0.2676  loss_rpn_cls: 0.04207  loss_rpn_loc: 0.1711  time: 0.6445  data_time: 0.4114  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:01:41 d2.utils.events]: \u001b[0m eta: 1:10:42  iter: 34719  total_loss: 0.9733  loss_cls: 0.1786  loss_box_reg: 0.2126  loss_mask: 0.2437  loss_rpn_cls: 0.05614  loss_rpn_loc: 0.1742  time: 0.6446  data_time: 0.5124  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:01:56 d2.utils.events]: \u001b[0m eta: 1:10:55  iter: 34739  total_loss: 0.9953  loss_cls: 0.2093  loss_box_reg: 0.2837  loss_mask: 0.2605  loss_rpn_cls: 0.05831  loss_rpn_loc: 0.1758  time: 0.6447  data_time: 0.5620  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:02:11 d2.utils.events]: \u001b[0m eta: 1:10:31  iter: 34759  total_loss: 0.7768  loss_cls: 0.146  loss_box_reg: 0.2067  loss_mask: 0.2359  loss_rpn_cls: 0.03863  loss_rpn_loc: 0.1446  time: 0.6447  data_time: 0.4929  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:02:27 d2.utils.events]: \u001b[0m eta: 1:09:29  iter: 34779  total_loss: 0.9263  loss_cls: 0.1832  loss_box_reg: 0.2137  loss_mask: 0.2534  loss_rpn_cls: 0.04504  loss_rpn_loc: 0.1859  time: 0.6449  data_time: 0.5942  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:02:36 d2.utils.events]: \u001b[0m eta: 1:08:22  iter: 34799  total_loss: 0.5613  loss_cls: 0.09239  loss_box_reg: 0.1595  loss_mask: 0.1741  loss_rpn_cls: 0.03129  loss_rpn_loc: 0.1773  time: 0.6447  data_time: 0.2331  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:02:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 16:02:47 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:02:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:02:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:02:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0451 s/iter. Eval: 0.0187 s/iter. Total: 0.0646 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 16:02:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.374288 (0.060255 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:02:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.044124 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:02:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 16:02:51 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06983577612820512\n",
      "\u001b[32m[12/30 16:02:52 d2.utils.events]: \u001b[0m eta: 1:09:41  iter: 34819  total_loss: 0.889  loss_cls: 0.1633  loss_box_reg: 0.2071  loss_mask: 0.2735  loss_rpn_cls: 0.05062  loss_rpn_loc: 0.1909  time: 0.6447  data_time: 0.3832  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:03:05 d2.utils.events]: \u001b[0m eta: 1:08:12  iter: 34839  total_loss: 0.776  loss_cls: 0.1191  loss_box_reg: 0.1778  loss_mask: 0.2264  loss_rpn_cls: 0.03208  loss_rpn_loc: 0.1857  time: 0.6447  data_time: 0.4452  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:03:17 d2.utils.events]: \u001b[0m eta: 1:07:46  iter: 34859  total_loss: 0.8492  loss_cls: 0.1323  loss_box_reg: 0.1607  loss_mask: 0.2596  loss_rpn_cls: 0.03746  loss_rpn_loc: 0.1462  time: 0.6446  data_time: 0.3642  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:03:32 d2.utils.events]: \u001b[0m eta: 1:07:11  iter: 34879  total_loss: 1.009  loss_cls: 0.1791  loss_box_reg: 0.2414  loss_mask: 0.2696  loss_rpn_cls: 0.07636  loss_rpn_loc: 0.1899  time: 0.6447  data_time: 0.5433  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:03:42 d2.utils.events]: \u001b[0m eta: 1:06:54  iter: 34899  total_loss: 0.6793  loss_cls: 0.1044  loss_box_reg: 0.1531  loss_mask: 0.2019  loss_rpn_cls: 0.02764  loss_rpn_loc: 0.1613  time: 0.6446  data_time: 0.3009  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:03:51 d2.utils.events]: \u001b[0m eta: 1:05:21  iter: 34919  total_loss: 0.5277  loss_cls: 0.07696  loss_box_reg: 0.1051  loss_mask: 0.167  loss_rpn_cls: 0.02506  loss_rpn_loc: 0.1456  time: 0.6445  data_time: 0.2462  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:04:08 d2.utils.events]: \u001b[0m eta: 1:06:38  iter: 34939  total_loss: 0.9577  loss_cls: 0.1551  loss_box_reg: 0.2502  loss_mask: 0.2502  loss_rpn_cls: 0.0603  loss_rpn_loc: 0.1782  time: 0.6446  data_time: 0.6081  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:04:24 d2.utils.events]: \u001b[0m eta: 1:06:31  iter: 34959  total_loss: 0.7692  loss_cls: 0.14  loss_box_reg: 0.182  loss_mask: 0.2415  loss_rpn_cls: 0.04332  loss_rpn_loc: 0.1562  time: 0.6447  data_time: 0.5588  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:04:38 d2.utils.events]: \u001b[0m eta: 1:05:18  iter: 34979  total_loss: 0.8164  loss_cls: 0.138  loss_box_reg: 0.2133  loss_mask: 0.2403  loss_rpn_cls: 0.02468  loss_rpn_loc: 0.1453  time: 0.6448  data_time: 0.4882  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:04:50 d2.utils.events]: \u001b[0m eta: 1:05:12  iter: 34999  total_loss: 0.8731  loss_cls: 0.1533  loss_box_reg: 0.2033  loss_mask: 0.2452  loss_rpn_cls: 0.05645  loss_rpn_loc: 0.1819  time: 0.6448  data_time: 0.4161  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:05:05 d2.utils.events]: \u001b[0m eta: 1:05:51  iter: 35019  total_loss: 0.9522  loss_cls: 0.1546  loss_box_reg: 0.2388  loss_mask: 0.2935  loss_rpn_cls: 0.06033  loss_rpn_loc: 0.1637  time: 0.6448  data_time: 0.5056  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:05:18 d2.utils.events]: \u001b[0m eta: 1:06:10  iter: 35039  total_loss: 0.8904  loss_cls: 0.1564  loss_box_reg: 0.2153  loss_mask: 0.2701  loss_rpn_cls: 0.04021  loss_rpn_loc: 0.1594  time: 0.6448  data_time: 0.4389  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:05:30 d2.utils.events]: \u001b[0m eta: 1:06:13  iter: 35059  total_loss: 0.9563  loss_cls: 0.141  loss_box_reg: 0.2081  loss_mask: 0.292  loss_rpn_cls: 0.06161  loss_rpn_loc: 0.1709  time: 0.6448  data_time: 0.3672  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:05:41 d2.utils.events]: \u001b[0m eta: 1:06:18  iter: 35079  total_loss: 0.8201  loss_cls: 0.1499  loss_box_reg: 0.2023  loss_mask: 0.2553  loss_rpn_cls: 0.04086  loss_rpn_loc: 0.1531  time: 0.6447  data_time: 0.3457  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:05:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 16:05:47 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:05:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:05:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:05:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0449 s/iter. Eval: 0.0181 s/iter. Total: 0.0636 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 16:05:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.337111 (0.059591 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:05:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043467 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:05:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 16:05:50 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07113808131037742\n",
      "\u001b[32m[12/30 16:05:57 d2.utils.events]: \u001b[0m eta: 1:05:54  iter: 35099  total_loss: 0.9466  loss_cls: 0.1593  loss_box_reg: 0.2063  loss_mask: 0.2904  loss_rpn_cls: 0.04938  loss_rpn_loc: 0.1769  time: 0.6447  data_time: 0.4015  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:06:10 d2.utils.events]: \u001b[0m eta: 1:05:24  iter: 35119  total_loss: 0.9624  loss_cls: 0.1709  loss_box_reg: 0.2161  loss_mask: 0.2789  loss_rpn_cls: 0.04987  loss_rpn_loc: 0.1662  time: 0.6447  data_time: 0.4279  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:06:22 d2.utils.events]: \u001b[0m eta: 1:05:19  iter: 35139  total_loss: 0.7264  loss_cls: 0.132  loss_box_reg: 0.1758  loss_mask: 0.2249  loss_rpn_cls: 0.03468  loss_rpn_loc: 0.1487  time: 0.6447  data_time: 0.3738  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:06:35 d2.utils.events]: \u001b[0m eta: 1:04:36  iter: 35159  total_loss: 0.8049  loss_cls: 0.1354  loss_box_reg: 0.1604  loss_mask: 0.2161  loss_rpn_cls: 0.0278  loss_rpn_loc: 0.1701  time: 0.6447  data_time: 0.4130  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:06:45 d2.utils.events]: \u001b[0m eta: 1:04:09  iter: 35179  total_loss: 0.3613  loss_cls: 0.03427  loss_box_reg: 0.07458  loss_mask: 0.07988  loss_rpn_cls: 0.02789  loss_rpn_loc: 0.1648  time: 0.6446  data_time: 0.3033  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:06:58 d2.utils.events]: \u001b[0m eta: 1:03:26  iter: 35199  total_loss: 0.6213  loss_cls: 0.09687  loss_box_reg: 0.1418  loss_mask: 0.1901  loss_rpn_cls: 0.02587  loss_rpn_loc: 0.1658  time: 0.6445  data_time: 0.4243  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:07:10 d2.utils.events]: \u001b[0m eta: 1:03:02  iter: 35219  total_loss: 0.9127  loss_cls: 0.1603  loss_box_reg: 0.205  loss_mask: 0.26  loss_rpn_cls: 0.05167  loss_rpn_loc: 0.1841  time: 0.6445  data_time: 0.3869  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:07:23 d2.utils.events]: \u001b[0m eta: 1:02:41  iter: 35239  total_loss: 0.8207  loss_cls: 0.137  loss_box_reg: 0.2141  loss_mask: 0.2723  loss_rpn_cls: 0.04424  loss_rpn_loc: 0.1665  time: 0.6445  data_time: 0.4290  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:07:38 d2.utils.events]: \u001b[0m eta: 1:03:37  iter: 35259  total_loss: 0.9035  loss_cls: 0.1448  loss_box_reg: 0.1885  loss_mask: 0.2682  loss_rpn_cls: 0.04958  loss_rpn_loc: 0.1744  time: 0.6446  data_time: 0.5466  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:07:51 d2.utils.events]: \u001b[0m eta: 1:03:06  iter: 35279  total_loss: 0.743  loss_cls: 0.1175  loss_box_reg: 0.1892  loss_mask: 0.2296  loss_rpn_cls: 0.03574  loss_rpn_loc: 0.1678  time: 0.6446  data_time: 0.4470  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:08:04 d2.utils.events]: \u001b[0m eta: 1:03:17  iter: 35299  total_loss: 1.033  loss_cls: 0.2533  loss_box_reg: 0.252  loss_mask: 0.2637  loss_rpn_cls: 0.06209  loss_rpn_loc: 0.2011  time: 0.6446  data_time: 0.4129  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:08:16 d2.utils.events]: \u001b[0m eta: 1:02:55  iter: 35319  total_loss: 0.9113  loss_cls: 0.1827  loss_box_reg: 0.1783  loss_mask: 0.2404  loss_rpn_cls: 0.08436  loss_rpn_loc: 0.1668  time: 0.6446  data_time: 0.3590  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:08:30 d2.utils.events]: \u001b[0m eta: 1:03:49  iter: 35339  total_loss: 1.004  loss_cls: 0.1953  loss_box_reg: 0.232  loss_mask: 0.2475  loss_rpn_cls: 0.05569  loss_rpn_loc: 0.1827  time: 0.6446  data_time: 0.5222  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:08:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 16:08:42 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:08:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:08:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:08:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0447 s/iter. Eval: 0.0174 s/iter. Total: 0.0629 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 16:08:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.312350 (0.059149 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:08:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043573 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:08:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 16:08:46 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06499699926678258\n",
      "\u001b[32m[12/30 16:08:46 d2.utils.events]: \u001b[0m eta: 1:03:44  iter: 35359  total_loss: 0.8011  loss_cls: 0.1528  loss_box_reg: 0.177  loss_mask: 0.2565  loss_rpn_cls: 0.0348  loss_rpn_loc: 0.1681  time: 0.6446  data_time: 0.3904  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:09:04 d2.utils.events]: \u001b[0m eta: 1:03:06  iter: 35379  total_loss: 0.9815  loss_cls: 0.1873  loss_box_reg: 0.2016  loss_mask: 0.2453  loss_rpn_cls: 0.05163  loss_rpn_loc: 0.181  time: 0.6448  data_time: 0.6760  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:09:17 d2.utils.events]: \u001b[0m eta: 1:02:46  iter: 35399  total_loss: 0.6754  loss_cls: 0.09037  loss_box_reg: 0.174  loss_mask: 0.2413  loss_rpn_cls: 0.03557  loss_rpn_loc: 0.1744  time: 0.6448  data_time: 0.4292  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:09:30 d2.utils.events]: \u001b[0m eta: 1:02:22  iter: 35419  total_loss: 0.9529  loss_cls: 0.1712  loss_box_reg: 0.2336  loss_mask: 0.2811  loss_rpn_cls: 0.0521  loss_rpn_loc: 0.1769  time: 0.6448  data_time: 0.3947  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:09:42 d2.utils.events]: \u001b[0m eta: 1:01:38  iter: 35439  total_loss: 0.8004  loss_cls: 0.1406  loss_box_reg: 0.199  loss_mask: 0.237  loss_rpn_cls: 0.04849  loss_rpn_loc: 0.1712  time: 0.6447  data_time: 0.3992  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:09:52 d2.utils.events]: \u001b[0m eta: 1:02:11  iter: 35459  total_loss: 0.7367  loss_cls: 0.1184  loss_box_reg: 0.1857  loss_mask: 0.2251  loss_rpn_cls: 0.037  loss_rpn_loc: 0.1597  time: 0.6446  data_time: 0.2995  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:10:02 d2.utils.events]: \u001b[0m eta: 1:01:28  iter: 35479  total_loss: 0.7535  loss_cls: 0.1198  loss_box_reg: 0.2165  loss_mask: 0.2003  loss_rpn_cls: 0.0253  loss_rpn_loc: 0.141  time: 0.6445  data_time: 0.2920  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:10:16 d2.utils.events]: \u001b[0m eta: 1:01:35  iter: 35499  total_loss: 0.7882  loss_cls: 0.1466  loss_box_reg: 0.1818  loss_mask: 0.2218  loss_rpn_cls: 0.02783  loss_rpn_loc: 0.1618  time: 0.6446  data_time: 0.4948  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:10:29 d2.utils.events]: \u001b[0m eta: 1:01:56  iter: 35519  total_loss: 1.076  loss_cls: 0.1918  loss_box_reg: 0.2603  loss_mask: 0.2677  loss_rpn_cls: 0.0877  loss_rpn_loc: 0.1855  time: 0.6446  data_time: 0.4437  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:10:43 d2.utils.events]: \u001b[0m eta: 1:01:13  iter: 35539  total_loss: 0.9991  loss_cls: 0.2045  loss_box_reg: 0.2752  loss_mask: 0.2409  loss_rpn_cls: 0.04645  loss_rpn_loc: 0.1497  time: 0.6446  data_time: 0.5026  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:10:54 d2.utils.events]: \u001b[0m eta: 1:01:19  iter: 35559  total_loss: 0.7921  loss_cls: 0.1324  loss_box_reg: 0.2261  loss_mask: 0.2448  loss_rpn_cls: 0.03782  loss_rpn_loc: 0.1569  time: 0.6445  data_time: 0.3264  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:11:08 d2.utils.events]: \u001b[0m eta: 1:00:59  iter: 35579  total_loss: 0.8933  loss_cls: 0.1541  loss_box_reg: 0.2178  loss_mask: 0.2431  loss_rpn_cls: 0.04371  loss_rpn_loc: 0.1644  time: 0.6446  data_time: 0.4586  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 16:11:21 d2.utils.events]: \u001b[0m eta: 1:01:32  iter: 35599  total_loss: 0.8926  loss_cls: 0.1498  loss_box_reg: 0.21  loss_mask: 0.2593  loss_rpn_cls: 0.03552  loss_rpn_loc: 0.1568  time: 0.6446  data_time: 0.4401  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:11:35 d2.utils.events]: \u001b[0m eta: 1:01:54  iter: 35619  total_loss: 0.9693  loss_cls: 0.177  loss_box_reg: 0.2089  loss_mask: 0.2472  loss_rpn_cls: 0.04413  loss_rpn_loc: 0.1706  time: 0.6446  data_time: 0.4824  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:11:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 16:11:45 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:11:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:11:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:11:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0453 s/iter. Eval: 0.0192 s/iter. Total: 0.0652 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 16:11:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.344628 (0.059726 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:11:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043803 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:11:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 16:11:48 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0707933770086082\n",
      "\u001b[32m[12/30 16:11:52 d2.utils.events]: \u001b[0m eta: 1:01:44  iter: 35639  total_loss: 0.9148  loss_cls: 0.1453  loss_box_reg: 0.1993  loss_mask: 0.2683  loss_rpn_cls: 0.04854  loss_rpn_loc: 0.1754  time: 0.6446  data_time: 0.4311  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:12:08 d2.utils.events]: \u001b[0m eta: 1:02:44  iter: 35659  total_loss: 0.9265  loss_cls: 0.169  loss_box_reg: 0.192  loss_mask: 0.2586  loss_rpn_cls: 0.06439  loss_rpn_loc: 0.1906  time: 0.6447  data_time: 0.5824  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:12:21 d2.utils.events]: \u001b[0m eta: 1:02:49  iter: 35679  total_loss: 0.8866  loss_cls: 0.1282  loss_box_reg: 0.2005  loss_mask: 0.2584  loss_rpn_cls: 0.05699  loss_rpn_loc: 0.1886  time: 0.6447  data_time: 0.4156  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:12:35 d2.utils.events]: \u001b[0m eta: 1:03:17  iter: 35699  total_loss: 1.045  loss_cls: 0.1854  loss_box_reg: 0.2641  loss_mask: 0.2587  loss_rpn_cls: 0.05505  loss_rpn_loc: 0.1913  time: 0.6448  data_time: 0.4825  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:12:46 d2.utils.events]: \u001b[0m eta: 1:02:38  iter: 35719  total_loss: 0.9452  loss_cls: 0.1622  loss_box_reg: 0.1854  loss_mask: 0.2644  loss_rpn_cls: 0.04779  loss_rpn_loc: 0.1936  time: 0.6447  data_time: 0.3575  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:13:00 d2.utils.events]: \u001b[0m eta: 1:02:33  iter: 35739  total_loss: 0.9317  loss_cls: 0.1674  loss_box_reg: 0.2141  loss_mask: 0.2578  loss_rpn_cls: 0.04896  loss_rpn_loc: 0.1898  time: 0.6447  data_time: 0.4774  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:13:12 d2.utils.events]: \u001b[0m eta: 1:02:43  iter: 35759  total_loss: 0.9144  loss_cls: 0.1507  loss_box_reg: 0.2223  loss_mask: 0.2707  loss_rpn_cls: 0.06953  loss_rpn_loc: 0.1712  time: 0.6447  data_time: 0.3828  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:13:25 d2.utils.events]: \u001b[0m eta: 1:02:22  iter: 35779  total_loss: 0.8461  loss_cls: 0.1378  loss_box_reg: 0.1782  loss_mask: 0.2429  loss_rpn_cls: 0.03581  loss_rpn_loc: 0.167  time: 0.6447  data_time: 0.4536  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:13:40 d2.utils.events]: \u001b[0m eta: 1:02:45  iter: 35799  total_loss: 0.8285  loss_cls: 0.1246  loss_box_reg: 0.1754  loss_mask: 0.2502  loss_rpn_cls: 0.04254  loss_rpn_loc: 0.1581  time: 0.6448  data_time: 0.5167  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:13:49 d2.utils.events]: \u001b[0m eta: 1:02:27  iter: 35819  total_loss: 0.6995  loss_cls: 0.1147  loss_box_reg: 0.1629  loss_mask: 0.1926  loss_rpn_cls: 0.02573  loss_rpn_loc: 0.1524  time: 0.6447  data_time: 0.2663  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:14:01 d2.utils.events]: \u001b[0m eta: 1:02:15  iter: 35839  total_loss: 0.8576  loss_cls: 0.1381  loss_box_reg: 0.2009  loss_mask: 0.2479  loss_rpn_cls: 0.0352  loss_rpn_loc: 0.1557  time: 0.6446  data_time: 0.3694  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:14:17 d2.utils.events]: \u001b[0m eta: 1:02:35  iter: 35859  total_loss: 0.8089  loss_cls: 0.1435  loss_box_reg: 0.1977  loss_mask: 0.2349  loss_rpn_cls: 0.03801  loss_rpn_loc: 0.1744  time: 0.6447  data_time: 0.5556  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:14:25 d2.utils.events]: \u001b[0m eta: 1:02:05  iter: 35879  total_loss: 0.655  loss_cls: 0.08778  loss_box_reg: 0.1749  loss_mask: 0.2266  loss_rpn_cls: 0.02216  loss_rpn_loc: 0.1459  time: 0.6446  data_time: 0.2331  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:14:37 d2.utils.events]: \u001b[0m eta: 1:01:59  iter: 35899  total_loss: 0.9169  loss_cls: 0.142  loss_box_reg: 0.1852  loss_mask: 0.2561  loss_rpn_cls: 0.0402  loss_rpn_loc: 0.1732  time: 0.6445  data_time: 0.4009  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:14:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 16:14:38 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:14:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:14:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:14:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0444 s/iter. Eval: 0.0175 s/iter. Total: 0.0626 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 16:14:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.316853 (0.059230 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:14:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043711 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:14:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 16:14:42 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06836102263665914\n",
      "\u001b[32m[12/30 16:14:51 d2.utils.events]: \u001b[0m eta: 1:02:13  iter: 35919  total_loss: 0.6006  loss_cls: 0.09325  loss_box_reg: 0.1521  loss_mask: 0.1981  loss_rpn_cls: 0.02915  loss_rpn_loc: 0.1551  time: 0.6444  data_time: 0.2876  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:15:06 d2.utils.events]: \u001b[0m eta: 1:01:49  iter: 35939  total_loss: 0.9546  loss_cls: 0.1802  loss_box_reg: 0.2526  loss_mask: 0.2724  loss_rpn_cls: 0.07003  loss_rpn_loc: 0.1926  time: 0.6445  data_time: 0.5407  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:15:17 d2.utils.events]: \u001b[0m eta: 1:02:01  iter: 35959  total_loss: 0.8876  loss_cls: 0.1664  loss_box_reg: 0.1903  loss_mask: 0.2461  loss_rpn_cls: 0.03496  loss_rpn_loc: 0.1622  time: 0.6444  data_time: 0.3504  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:15:29 d2.utils.events]: \u001b[0m eta: 1:02:06  iter: 35979  total_loss: 0.5613  loss_cls: 0.08073  loss_box_reg: 0.1538  loss_mask: 0.1912  loss_rpn_cls: 0.03452  loss_rpn_loc: 0.1512  time: 0.6444  data_time: 0.3931  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:15:44 d2.utils.events]: \u001b[0m eta: 1:01:58  iter: 35999  total_loss: 0.8486  loss_cls: 0.1524  loss_box_reg: 0.2043  loss_mask: 0.2595  loss_rpn_cls: 0.04531  loss_rpn_loc: 0.1916  time: 0.6445  data_time: 0.5042  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:15:58 d2.utils.events]: \u001b[0m eta: 1:01:35  iter: 36019  total_loss: 0.9348  loss_cls: 0.163  loss_box_reg: 0.2168  loss_mask: 0.2671  loss_rpn_cls: 0.0683  loss_rpn_loc: 0.1786  time: 0.6445  data_time: 0.4782  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:16:10 d2.utils.events]: \u001b[0m eta: 1:01:30  iter: 36039  total_loss: 1.013  loss_cls: 0.2151  loss_box_reg: 0.2341  loss_mask: 0.2571  loss_rpn_cls: 0.05713  loss_rpn_loc: 0.1711  time: 0.6445  data_time: 0.3804  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:16:22 d2.utils.events]: \u001b[0m eta: 1:01:17  iter: 36059  total_loss: 0.3166  loss_cls: 0.02402  loss_box_reg: 0.05627  loss_mask: 0.05893  loss_rpn_cls: 0.03684  loss_rpn_loc: 0.1769  time: 0.6444  data_time: 0.3840  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 16:16:36 d2.utils.events]: \u001b[0m eta: 1:00:40  iter: 36079  total_loss: 0.8362  loss_cls: 0.1305  loss_box_reg: 0.2006  loss_mask: 0.2525  loss_rpn_cls: 0.02821  loss_rpn_loc: 0.1813  time: 0.6445  data_time: 0.4587  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:16:51 d2.utils.events]: \u001b[0m eta: 1:00:35  iter: 36099  total_loss: 0.929  loss_cls: 0.1526  loss_box_reg: 0.2098  loss_mask: 0.2663  loss_rpn_cls: 0.05302  loss_rpn_loc: 0.1795  time: 0.6445  data_time: 0.5296  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:17:07 d2.utils.events]: \u001b[0m eta: 1:01:09  iter: 36119  total_loss: 0.8576  loss_cls: 0.1505  loss_box_reg: 0.1677  loss_mask: 0.2619  loss_rpn_cls: 0.05787  loss_rpn_loc: 0.1779  time: 0.6447  data_time: 0.5981  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:17:24 d2.utils.events]: \u001b[0m eta: 1:01:14  iter: 36139  total_loss: 1.018  loss_cls: 0.1674  loss_box_reg: 0.2249  loss_mask: 0.2568  loss_rpn_cls: 0.06362  loss_rpn_loc: 0.2  time: 0.6448  data_time: 0.6221  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:17:33 d2.utils.events]: \u001b[0m eta: 1:01:08  iter: 36159  total_loss: 0.8729  loss_cls: 0.1653  loss_box_reg: 0.2406  loss_mask: 0.2397  loss_rpn_cls: 0.03004  loss_rpn_loc: 0.1336  time: 0.6447  data_time: 0.2441  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:17:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 16:17:45 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:17:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:17:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:17:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0447 s/iter. Eval: 0.0185 s/iter. Total: 0.0640 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 16:17:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.376153 (0.060288 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:17:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043489 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:17:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 16:17:48 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06836559071951176\n",
      "\u001b[32m[12/30 16:17:50 d2.utils.events]: \u001b[0m eta: 1:01:50  iter: 36179  total_loss: 0.9151  loss_cls: 0.1464  loss_box_reg: 0.2203  loss_mask: 0.2507  loss_rpn_cls: 0.05161  loss_rpn_loc: 0.1817  time: 0.6447  data_time: 0.4436  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:18:09 d2.utils.events]: \u001b[0m eta: 1:02:35  iter: 36199  total_loss: 0.9604  loss_cls: 0.1493  loss_box_reg: 0.2176  loss_mask: 0.2792  loss_rpn_cls: 0.05803  loss_rpn_loc: 0.1973  time: 0.6449  data_time: 0.6849  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:18:22 d2.utils.events]: \u001b[0m eta: 1:02:56  iter: 36219  total_loss: 0.817  loss_cls: 0.1234  loss_box_reg: 0.1818  loss_mask: 0.2528  loss_rpn_cls: 0.03796  loss_rpn_loc: 0.1747  time: 0.6449  data_time: 0.4618  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:18:31 d2.utils.events]: \u001b[0m eta: 1:02:24  iter: 36239  total_loss: 0.5449  loss_cls: 0.04723  loss_box_reg: 0.1203  loss_mask: 0.1557  loss_rpn_cls: 0.02687  loss_rpn_loc: 0.1526  time: 0.6448  data_time: 0.2440  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:18:42 d2.utils.events]: \u001b[0m eta: 1:02:45  iter: 36259  total_loss: 0.9429  loss_cls: 0.1749  loss_box_reg: 0.2471  loss_mask: 0.2657  loss_rpn_cls: 0.05461  loss_rpn_loc: 0.1807  time: 0.6447  data_time: 0.3365  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:18:57 d2.utils.events]: \u001b[0m eta: 1:02:39  iter: 36279  total_loss: 0.8529  loss_cls: 0.1457  loss_box_reg: 0.1718  loss_mask: 0.2478  loss_rpn_cls: 0.03676  loss_rpn_loc: 0.1624  time: 0.6447  data_time: 0.5064  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:19:08 d2.utils.events]: \u001b[0m eta: 1:02:06  iter: 36299  total_loss: 0.7971  loss_cls: 0.1412  loss_box_reg: 0.1985  loss_mask: 0.241  loss_rpn_cls: 0.03211  loss_rpn_loc: 0.1664  time: 0.6447  data_time: 0.3290  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:19:19 d2.utils.events]: \u001b[0m eta: 1:02:01  iter: 36319  total_loss: 0.7973  loss_cls: 0.1384  loss_box_reg: 0.1971  loss_mask: 0.2581  loss_rpn_cls: 0.04772  loss_rpn_loc: 0.154  time: 0.6446  data_time: 0.3397  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:19:29 d2.utils.events]: \u001b[0m eta: 1:01:25  iter: 36339  total_loss: 0.7633  loss_cls: 0.1377  loss_box_reg: 0.2107  loss_mask: 0.2584  loss_rpn_cls: 0.02893  loss_rpn_loc: 0.1598  time: 0.6445  data_time: 0.2822  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:19:42 d2.utils.events]: \u001b[0m eta: 1:01:29  iter: 36359  total_loss: 0.9097  loss_cls: 0.1517  loss_box_reg: 0.2165  loss_mask: 0.241  loss_rpn_cls: 0.04782  loss_rpn_loc: 0.1786  time: 0.6445  data_time: 0.4436  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:19:58 d2.utils.events]: \u001b[0m eta: 1:01:34  iter: 36379  total_loss: 0.8194  loss_cls: 0.1405  loss_box_reg: 0.167  loss_mask: 0.2647  loss_rpn_cls: 0.05096  loss_rpn_loc: 0.1491  time: 0.6446  data_time: 0.5598  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:20:13 d2.utils.events]: \u001b[0m eta: 1:01:29  iter: 36399  total_loss: 0.8571  loss_cls: 0.1492  loss_box_reg: 0.2134  loss_mask: 0.2451  loss_rpn_cls: 0.03912  loss_rpn_loc: 0.1455  time: 0.6447  data_time: 0.5645  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:20:26 d2.utils.events]: \u001b[0m eta: 1:01:03  iter: 36419  total_loss: 0.9777  loss_cls: 0.1646  loss_box_reg: 0.2176  loss_mask: 0.256  loss_rpn_cls: 0.05199  loss_rpn_loc: 0.1872  time: 0.6447  data_time: 0.4217  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:20:40 d2.utils.events]: \u001b[0m eta: 1:01:18  iter: 36439  total_loss: 0.9943  loss_cls: 0.1591  loss_box_reg: 0.2368  loss_mask: 0.2694  loss_rpn_cls: 0.05371  loss_rpn_loc: 0.188  time: 0.6447  data_time: 0.4670  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:20:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 16:20:46 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:20:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:20:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:20:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0451 s/iter. Eval: 0.0175 s/iter. Total: 0.0633 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 16:20:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.218610 (0.057475 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:20:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043206 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:20:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 16:20:50 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06655171072497408\n",
      "\u001b[32m[12/30 16:20:57 d2.utils.events]: \u001b[0m eta: 1:01:24  iter: 36459  total_loss: 1.025  loss_cls: 0.1853  loss_box_reg: 0.2351  loss_mask: 0.2536  loss_rpn_cls: 0.05882  loss_rpn_loc: 0.1832  time: 0.6448  data_time: 0.4661  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:21:11 d2.utils.events]: \u001b[0m eta: 1:01:45  iter: 36479  total_loss: 0.6488  loss_cls: 0.1165  loss_box_reg: 0.1686  loss_mask: 0.2162  loss_rpn_cls: 0.03804  loss_rpn_loc: 0.1424  time: 0.6448  data_time: 0.4699  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:21:22 d2.utils.events]: \u001b[0m eta: 1:01:13  iter: 36499  total_loss: 0.5145  loss_cls: 0.06282  loss_box_reg: 0.1575  loss_mask: 0.1691  loss_rpn_cls: 0.03045  loss_rpn_loc: 0.1464  time: 0.6447  data_time: 0.3412  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:21:34 d2.utils.events]: \u001b[0m eta: 1:01:21  iter: 36519  total_loss: 0.903  loss_cls: 0.1572  loss_box_reg: 0.2085  loss_mask: 0.26  loss_rpn_cls: 0.05316  loss_rpn_loc: 0.1783  time: 0.6447  data_time: 0.3873  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:21:45 d2.utils.events]: \u001b[0m eta: 1:01:15  iter: 36539  total_loss: 0.81  loss_cls: 0.1417  loss_box_reg: 0.2022  loss_mask: 0.2614  loss_rpn_cls: 0.03046  loss_rpn_loc: 0.1605  time: 0.6446  data_time: 0.3401  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 16:21:59 d2.utils.events]: \u001b[0m eta: 1:01:03  iter: 36559  total_loss: 0.8116  loss_cls: 0.139  loss_box_reg: 0.2175  loss_mask: 0.2469  loss_rpn_cls: 0.02736  loss_rpn_loc: 0.1674  time: 0.6447  data_time: 0.4772  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:22:17 d2.utils.events]: \u001b[0m eta: 1:02:10  iter: 36579  total_loss: 0.9813  loss_cls: 0.1908  loss_box_reg: 0.2257  loss_mask: 0.2751  loss_rpn_cls: 0.06125  loss_rpn_loc: 0.1852  time: 0.6448  data_time: 0.6659  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:22:31 d2.utils.events]: \u001b[0m eta: 1:02:04  iter: 36599  total_loss: 0.9235  loss_cls: 0.1661  loss_box_reg: 0.2357  loss_mask: 0.2514  loss_rpn_cls: 0.06784  loss_rpn_loc: 0.1697  time: 0.6449  data_time: 0.4634  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:22:44 d2.utils.events]: \u001b[0m eta: 1:01:23  iter: 36619  total_loss: 0.8097  loss_cls: 0.107  loss_box_reg: 0.1845  loss_mask: 0.253  loss_rpn_cls: 0.02945  loss_rpn_loc: 0.1518  time: 0.6449  data_time: 0.4332  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:22:55 d2.utils.events]: \u001b[0m eta: 1:01:53  iter: 36639  total_loss: 0.6845  loss_cls: 0.1106  loss_box_reg: 0.1832  loss_mask: 0.223  loss_rpn_cls: 0.04045  loss_rpn_loc: 0.163  time: 0.6448  data_time: 0.3395  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:23:09 d2.utils.events]: \u001b[0m eta: 1:01:58  iter: 36659  total_loss: 0.9105  loss_cls: 0.1584  loss_box_reg: 0.2089  loss_mask: 0.2632  loss_rpn_cls: 0.05041  loss_rpn_loc: 0.1639  time: 0.6449  data_time: 0.4970  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:23:18 d2.utils.events]: \u001b[0m eta: 1:01:42  iter: 36679  total_loss: 0.6441  loss_cls: 0.09733  loss_box_reg: 0.1822  loss_mask: 0.2112  loss_rpn_cls: 0.02979  loss_rpn_loc: 0.1573  time: 0.6447  data_time: 0.2317  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:23:31 d2.utils.events]: \u001b[0m eta: 1:00:25  iter: 36699  total_loss: 0.7327  loss_cls: 0.112  loss_box_reg: 0.176  loss_mask: 0.2319  loss_rpn_cls: 0.02967  loss_rpn_loc: 0.1722  time: 0.6447  data_time: 0.4316  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:23:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 16:23:48 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:23:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:23:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:23:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0451 s/iter. Eval: 0.0259 s/iter. Total: 0.0717 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 16:23:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.593872 (0.064176 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:23:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043968 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:23:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 16:23:52 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07020819942336033\n",
      "\u001b[32m[12/30 16:23:52 d2.utils.events]: \u001b[0m eta: 1:01:31  iter: 36719  total_loss: 0.9015  loss_cls: 0.1443  loss_box_reg: 0.2017  loss_mask: 0.2489  loss_rpn_cls: 0.0508  loss_rpn_loc: 0.1841  time: 0.6448  data_time: 0.6326  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:24:02 d2.utils.events]: \u001b[0m eta: 1:00:14  iter: 36739  total_loss: 0.9012  loss_cls: 0.1582  loss_box_reg: 0.203  loss_mask: 0.2782  loss_rpn_cls: 0.04239  loss_rpn_loc: 0.186  time: 0.6448  data_time: 0.3017  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:24:16 d2.utils.events]: \u001b[0m eta: 1:00:00  iter: 36759  total_loss: 0.9308  loss_cls: 0.1604  loss_box_reg: 0.2231  loss_mask: 0.2568  loss_rpn_cls: 0.04406  loss_rpn_loc: 0.1724  time: 0.6448  data_time: 0.4753  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:24:29 d2.utils.events]: \u001b[0m eta: 1:00:03  iter: 36779  total_loss: 0.9007  loss_cls: 0.1413  loss_box_reg: 0.1848  loss_mask: 0.2629  loss_rpn_cls: 0.04451  loss_rpn_loc: 0.1682  time: 0.6448  data_time: 0.4395  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:24:40 d2.utils.events]: \u001b[0m eta: 0:59:50  iter: 36799  total_loss: 0.8241  loss_cls: 0.1276  loss_box_reg: 0.1962  loss_mask: 0.2458  loss_rpn_cls: 0.03208  loss_rpn_loc: 0.1551  time: 0.6447  data_time: 0.3469  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:24:50 d2.utils.events]: \u001b[0m eta: 1:00:22  iter: 36819  total_loss: 0.7054  loss_cls: 0.113  loss_box_reg: 0.1496  loss_mask: 0.1955  loss_rpn_cls: 0.02459  loss_rpn_loc: 0.1437  time: 0.6446  data_time: 0.2779  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:25:06 d2.utils.events]: \u001b[0m eta: 1:01:14  iter: 36839  total_loss: 0.9052  loss_cls: 0.1674  loss_box_reg: 0.2295  loss_mask: 0.257  loss_rpn_cls: 0.03257  loss_rpn_loc: 0.1721  time: 0.6447  data_time: 0.5665  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:25:21 d2.utils.events]: \u001b[0m eta: 1:02:08  iter: 36859  total_loss: 0.9652  loss_cls: 0.1729  loss_box_reg: 0.2003  loss_mask: 0.2608  loss_rpn_cls: 0.07503  loss_rpn_loc: 0.2007  time: 0.6448  data_time: 0.5072  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:25:32 d2.utils.events]: \u001b[0m eta: 1:01:26  iter: 36879  total_loss: 0.7313  loss_cls: 0.1256  loss_box_reg: 0.1926  loss_mask: 0.2413  loss_rpn_cls: 0.03261  loss_rpn_loc: 0.1611  time: 0.6447  data_time: 0.3442  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:25:45 d2.utils.events]: \u001b[0m eta: 1:02:25  iter: 36899  total_loss: 0.8985  loss_cls: 0.1439  loss_box_reg: 0.2162  loss_mask: 0.2536  loss_rpn_cls: 0.03999  loss_rpn_loc: 0.1813  time: 0.6447  data_time: 0.4420  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:25:57 d2.utils.events]: \u001b[0m eta: 1:02:19  iter: 36919  total_loss: 0.7052  loss_cls: 0.0996  loss_box_reg: 0.1872  loss_mask: 0.231  loss_rpn_cls: 0.02749  loss_rpn_loc: 0.1602  time: 0.6447  data_time: 0.3586  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:26:13 d2.utils.events]: \u001b[0m eta: 1:01:58  iter: 36939  total_loss: 0.8589  loss_cls: 0.1487  loss_box_reg: 0.1847  loss_mask: 0.2522  loss_rpn_cls: 0.05156  loss_rpn_loc: 0.1718  time: 0.6448  data_time: 0.5987  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:26:27 d2.utils.events]: \u001b[0m eta: 1:01:25  iter: 36959  total_loss: 0.882  loss_cls: 0.1454  loss_box_reg: 0.1953  loss_mask: 0.2619  loss_rpn_cls: 0.0535  loss_rpn_loc: 0.1624  time: 0.6449  data_time: 0.4855  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:26:40 d2.utils.events]: \u001b[0m eta: 1:01:34  iter: 36979  total_loss: 0.8561  loss_cls: 0.1499  loss_box_reg: 0.2203  loss_mask: 0.2343  loss_rpn_cls: 0.02719  loss_rpn_loc: 0.1464  time: 0.6448  data_time: 0.4201  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:26:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 16:26:48 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:26:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:26:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:26:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0446 s/iter. Eval: 0.0208 s/iter. Total: 0.0660 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 16:26:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.326610 (0.059404 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:26:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043459 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:26:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 16:26:52 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06865354435822747\n",
      "\u001b[32m[12/30 16:26:58 d2.utils.events]: \u001b[0m eta: 1:01:38  iter: 36999  total_loss: 0.8847  loss_cls: 0.1521  loss_box_reg: 0.159  loss_mask: 0.2576  loss_rpn_cls: 0.05115  loss_rpn_loc: 0.1899  time: 0.6449  data_time: 0.4610  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:27:07 d2.utils.events]: \u001b[0m eta: 1:01:40  iter: 37019  total_loss: 0.8282  loss_cls: 0.1319  loss_box_reg: 0.2169  loss_mask: 0.2552  loss_rpn_cls: 0.03245  loss_rpn_loc: 0.1559  time: 0.6448  data_time: 0.2734  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 16:27:18 d2.utils.events]: \u001b[0m eta: 1:00:16  iter: 37039  total_loss: 0.6598  loss_cls: 0.1047  loss_box_reg: 0.1596  loss_mask: 0.2055  loss_rpn_cls: 0.0264  loss_rpn_loc: 0.1413  time: 0.6447  data_time: 0.3392  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:27:32 d2.utils.events]: \u001b[0m eta: 1:00:11  iter: 37059  total_loss: 0.8501  loss_cls: 0.1408  loss_box_reg: 0.1831  loss_mask: 0.2427  loss_rpn_cls: 0.05111  loss_rpn_loc: 0.1673  time: 0.6447  data_time: 0.4727  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:27:46 d2.utils.events]: \u001b[0m eta: 1:00:30  iter: 37079  total_loss: 0.9255  loss_cls: 0.16  loss_box_reg: 0.2445  loss_mask: 0.2707  loss_rpn_cls: 0.0489  loss_rpn_loc: 0.1891  time: 0.6448  data_time: 0.4975  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:28:00 d2.utils.events]: \u001b[0m eta: 1:01:00  iter: 37099  total_loss: 0.8933  loss_cls: 0.1531  loss_box_reg: 0.2044  loss_mask: 0.2386  loss_rpn_cls: 0.06586  loss_rpn_loc: 0.1913  time: 0.6448  data_time: 0.4414  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:28:10 d2.utils.events]: \u001b[0m eta: 0:58:56  iter: 37119  total_loss: 0.5863  loss_cls: 0.08013  loss_box_reg: 0.1576  loss_mask: 0.1773  loss_rpn_cls: 0.02877  loss_rpn_loc: 0.1424  time: 0.6447  data_time: 0.3017  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:28:23 d2.utils.events]: \u001b[0m eta: 0:58:34  iter: 37139  total_loss: 0.7948  loss_cls: 0.1311  loss_box_reg: 0.1628  loss_mask: 0.2174  loss_rpn_cls: 0.03646  loss_rpn_loc: 0.1665  time: 0.6447  data_time: 0.4487  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:28:34 d2.utils.events]: \u001b[0m eta: 0:58:24  iter: 37159  total_loss: 0.8097  loss_cls: 0.1384  loss_box_reg: 0.1982  loss_mask: 0.2375  loss_rpn_cls: 0.03444  loss_rpn_loc: 0.1631  time: 0.6446  data_time: 0.3429  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:28:49 d2.utils.events]: \u001b[0m eta: 0:58:06  iter: 37179  total_loss: 0.8086  loss_cls: 0.1404  loss_box_reg: 0.1653  loss_mask: 0.2524  loss_rpn_cls: 0.05588  loss_rpn_loc: 0.1745  time: 0.6447  data_time: 0.5490  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:29:02 d2.utils.events]: \u001b[0m eta: 0:57:15  iter: 37199  total_loss: 0.9732  loss_cls: 0.1731  loss_box_reg: 0.2664  loss_mask: 0.2519  loss_rpn_cls: 0.04245  loss_rpn_loc: 0.166  time: 0.6447  data_time: 0.4046  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:29:20 d2.utils.events]: \u001b[0m eta: 0:57:00  iter: 37219  total_loss: 0.9211  loss_cls: 0.1417  loss_box_reg: 0.1758  loss_mask: 0.2507  loss_rpn_cls: 0.06938  loss_rpn_loc: 0.1845  time: 0.6449  data_time: 0.6587  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:29:34 d2.utils.events]: \u001b[0m eta: 0:57:07  iter: 37239  total_loss: 0.8898  loss_cls: 0.1197  loss_box_reg: 0.2547  loss_mask: 0.2566  loss_rpn_cls: 0.03209  loss_rpn_loc: 0.1692  time: 0.6449  data_time: 0.4797  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:29:47 d2.utils.events]: \u001b[0m eta: 0:56:40  iter: 37259  total_loss: 0.8125  loss_cls: 0.1225  loss_box_reg: 0.1866  loss_mask: 0.2355  loss_rpn_cls: 0.03562  loss_rpn_loc: 0.1554  time: 0.6449  data_time: 0.4654  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:29:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 16:29:51 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:29:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:29:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:29:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0009 s/iter. Inference: 0.0454 s/iter. Eval: 0.0182 s/iter. Total: 0.0645 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 16:29:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.316124 (0.059216 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:29:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043943 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:29:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 16:29:55 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0711413874062235\n",
      "\u001b[32m[12/30 16:30:02 d2.utils.events]: \u001b[0m eta: 0:56:40  iter: 37279  total_loss: 0.8326  loss_cls: 0.1532  loss_box_reg: 0.2002  loss_mask: 0.272  loss_rpn_cls: 0.05139  loss_rpn_loc: 0.1745  time: 0.6449  data_time: 0.3291  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:30:12 d2.utils.events]: \u001b[0m eta: 0:56:51  iter: 37299  total_loss: 0.8218  loss_cls: 0.1228  loss_box_reg: 0.2399  loss_mask: 0.2315  loss_rpn_cls: 0.03414  loss_rpn_loc: 0.1725  time: 0.6448  data_time: 0.2689  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:30:25 d2.utils.events]: \u001b[0m eta: 0:57:21  iter: 37319  total_loss: 0.8891  loss_cls: 0.1578  loss_box_reg: 0.2168  loss_mask: 0.2402  loss_rpn_cls: 0.03011  loss_rpn_loc: 0.1662  time: 0.6448  data_time: 0.4267  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:30:36 d2.utils.events]: \u001b[0m eta: 0:56:53  iter: 37339  total_loss: 0.8015  loss_cls: 0.1286  loss_box_reg: 0.1924  loss_mask: 0.2204  loss_rpn_cls: 0.02929  loss_rpn_loc: 0.1487  time: 0.6447  data_time: 0.3342  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:30:48 d2.utils.events]: \u001b[0m eta: 0:56:19  iter: 37359  total_loss: 0.7111  loss_cls: 0.1042  loss_box_reg: 0.1779  loss_mask: 0.2287  loss_rpn_cls: 0.04871  loss_rpn_loc: 0.1674  time: 0.6446  data_time: 0.3794  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:31:04 d2.utils.events]: \u001b[0m eta: 0:56:17  iter: 37379  total_loss: 0.9543  loss_cls: 0.1748  loss_box_reg: 0.2089  loss_mask: 0.2475  loss_rpn_cls: 0.07231  loss_rpn_loc: 0.1885  time: 0.6448  data_time: 0.6046  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:31:20 d2.utils.events]: \u001b[0m eta: 0:56:48  iter: 37399  total_loss: 0.9675  loss_cls: 0.1781  loss_box_reg: 0.2038  loss_mask: 0.2563  loss_rpn_cls: 0.06456  loss_rpn_loc: 0.2011  time: 0.6449  data_time: 0.5345  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:31:30 d2.utils.events]: \u001b[0m eta: 0:56:19  iter: 37419  total_loss: 0.8333  loss_cls: 0.1353  loss_box_reg: 0.1998  loss_mask: 0.2369  loss_rpn_cls: 0.02146  loss_rpn_loc: 0.1472  time: 0.6448  data_time: 0.3350  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:31:42 d2.utils.events]: \u001b[0m eta: 0:56:01  iter: 37439  total_loss: 0.7445  loss_cls: 0.1183  loss_box_reg: 0.1769  loss_mask: 0.2125  loss_rpn_cls: 0.02773  loss_rpn_loc: 0.1574  time: 0.6448  data_time: 0.3721  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:31:55 d2.utils.events]: \u001b[0m eta: 0:56:00  iter: 37459  total_loss: 0.8385  loss_cls: 0.1318  loss_box_reg: 0.1979  loss_mask: 0.2542  loss_rpn_cls: 0.03019  loss_rpn_loc: 0.153  time: 0.6447  data_time: 0.4009  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:32:05 d2.utils.events]: \u001b[0m eta: 0:55:51  iter: 37479  total_loss: 0.5768  loss_cls: 0.08293  loss_box_reg: 0.1362  loss_mask: 0.1885  loss_rpn_cls: 0.01942  loss_rpn_loc: 0.1459  time: 0.6447  data_time: 0.3385  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:32:22 d2.utils.events]: \u001b[0m eta: 0:56:38  iter: 37499  total_loss: 0.9685  loss_cls: 0.1686  loss_box_reg: 0.1988  loss_mask: 0.288  loss_rpn_cls: 0.05894  loss_rpn_loc: 0.1843  time: 0.6448  data_time: 0.5647  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:32:33 d2.utils.events]: \u001b[0m eta: 0:55:58  iter: 37519  total_loss: 0.8836  loss_cls: 0.1534  loss_box_reg: 0.2028  loss_mask: 0.2147  loss_rpn_cls: 0.02553  loss_rpn_loc: 0.1508  time: 0.6447  data_time: 0.3667  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:32:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 16:32:42 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:32:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:32:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:32:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0462 s/iter. Eval: 0.0220 s/iter. Total: 0.0689 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 16:32:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.392084 (0.060573 s / iter per device, on 1 devices)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 16:32:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043885 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:32:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 16:32:46 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06954432400866176\n",
      "\u001b[32m[12/30 16:32:48 d2.utils.events]: \u001b[0m eta: 0:55:35  iter: 37539  total_loss: 0.7625  loss_cls: 0.113  loss_box_reg: 0.1953  loss_mask: 0.2409  loss_rpn_cls: 0.02561  loss_rpn_loc: 0.153  time: 0.6447  data_time: 0.3550  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:33:03 d2.utils.events]: \u001b[0m eta: 0:55:26  iter: 37559  total_loss: 0.8809  loss_cls: 0.1765  loss_box_reg: 0.2302  loss_mask: 0.2444  loss_rpn_cls: 0.05227  loss_rpn_loc: 0.1618  time: 0.6447  data_time: 0.5039  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:33:19 d2.utils.events]: \u001b[0m eta: 0:55:24  iter: 37579  total_loss: 0.9223  loss_cls: 0.1553  loss_box_reg: 0.1767  loss_mask: 0.2765  loss_rpn_cls: 0.07094  loss_rpn_loc: 0.1837  time: 0.6448  data_time: 0.5929  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:33:31 d2.utils.events]: \u001b[0m eta: 0:55:41  iter: 37599  total_loss: 0.9583  loss_cls: 0.1515  loss_box_reg: 0.2164  loss_mask: 0.2526  loss_rpn_cls: 0.05897  loss_rpn_loc: 0.1858  time: 0.6448  data_time: 0.3710  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:33:43 d2.utils.events]: \u001b[0m eta: 0:55:35  iter: 37619  total_loss: 0.8448  loss_cls: 0.1309  loss_box_reg: 0.2034  loss_mask: 0.234  loss_rpn_cls: 0.06707  loss_rpn_loc: 0.1596  time: 0.6448  data_time: 0.3985  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:33:56 d2.utils.events]: \u001b[0m eta: 0:55:08  iter: 37639  total_loss: 0.7742  loss_cls: 0.1267  loss_box_reg: 0.1713  loss_mask: 0.2345  loss_rpn_cls: 0.03978  loss_rpn_loc: 0.1759  time: 0.6448  data_time: 0.4107  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:34:09 d2.utils.events]: \u001b[0m eta: 0:55:03  iter: 37659  total_loss: 0.927  loss_cls: 0.1599  loss_box_reg: 0.1867  loss_mask: 0.2626  loss_rpn_cls: 0.05847  loss_rpn_loc: 0.1918  time: 0.6448  data_time: 0.4338  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:34:22 d2.utils.events]: \u001b[0m eta: 0:55:44  iter: 37679  total_loss: 0.8712  loss_cls: 0.1282  loss_box_reg: 0.206  loss_mask: 0.2438  loss_rpn_cls: 0.03747  loss_rpn_loc: 0.1512  time: 0.6448  data_time: 0.4480  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:34:32 d2.utils.events]: \u001b[0m eta: 0:55:31  iter: 37699  total_loss: 0.8123  loss_cls: 0.1285  loss_box_reg: 0.1988  loss_mask: 0.2387  loss_rpn_cls: 0.02894  loss_rpn_loc: 0.1722  time: 0.6447  data_time: 0.3005  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:34:48 d2.utils.events]: \u001b[0m eta: 0:55:26  iter: 37719  total_loss: 0.9214  loss_cls: 0.139  loss_box_reg: 0.1853  loss_mask: 0.2656  loss_rpn_cls: 0.05131  loss_rpn_loc: 0.1858  time: 0.6448  data_time: 0.5723  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:35:01 d2.utils.events]: \u001b[0m eta: 0:55:37  iter: 37739  total_loss: 0.8852  loss_cls: 0.1658  loss_box_reg: 0.2007  loss_mask: 0.2533  loss_rpn_cls: 0.05407  loss_rpn_loc: 0.1661  time: 0.6448  data_time: 0.4431  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:35:17 d2.utils.events]: \u001b[0m eta: 0:55:41  iter: 37759  total_loss: 0.989  loss_cls: 0.1826  loss_box_reg: 0.2045  loss_mask: 0.2724  loss_rpn_cls: 0.07795  loss_rpn_loc: 0.205  time: 0.6449  data_time: 0.5845  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:35:28 d2.utils.events]: \u001b[0m eta: 0:55:35  iter: 37779  total_loss: 0.8276  loss_cls: 0.1177  loss_box_reg: 0.1723  loss_mask: 0.2269  loss_rpn_cls: 0.03412  loss_rpn_loc: 0.163  time: 0.6448  data_time: 0.2957  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:35:40 d2.utils.events]: \u001b[0m eta: 0:55:27  iter: 37799  total_loss: 0.688  loss_cls: 0.1227  loss_box_reg: 0.1788  loss_mask: 0.22  loss_rpn_cls: 0.03256  loss_rpn_loc: 0.1549  time: 0.6448  data_time: 0.3708  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:35:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 16:35:45 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:35:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:35:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:35:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0445 s/iter. Eval: 0.0189 s/iter. Total: 0.0641 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 16:35:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.276209 (0.058504 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:35:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043419 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:35:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 16:35:49 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06863851079846249\n",
      "\u001b[32m[12/30 16:35:55 d2.utils.events]: \u001b[0m eta: 0:55:15  iter: 37819  total_loss: 0.9346  loss_cls: 0.1498  loss_box_reg: 0.2244  loss_mask: 0.2647  loss_rpn_cls: 0.05299  loss_rpn_loc: 0.174  time: 0.6447  data_time: 0.3656  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:36:06 d2.utils.events]: \u001b[0m eta: 0:54:06  iter: 37839  total_loss: 0.6545  loss_cls: 0.09282  loss_box_reg: 0.1744  loss_mask: 0.2214  loss_rpn_cls: 0.0277  loss_rpn_loc: 0.15  time: 0.6447  data_time: 0.3285  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:36:19 d2.utils.events]: \u001b[0m eta: 0:52:43  iter: 37859  total_loss: 0.7173  loss_cls: 0.1353  loss_box_reg: 0.1899  loss_mask: 0.2274  loss_rpn_cls: 0.02722  loss_rpn_loc: 0.1576  time: 0.6447  data_time: 0.4260  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:36:30 d2.utils.events]: \u001b[0m eta: 0:52:43  iter: 37879  total_loss: 0.7857  loss_cls: 0.1353  loss_box_reg: 0.1907  loss_mask: 0.2547  loss_rpn_cls: 0.03007  loss_rpn_loc: 0.1638  time: 0.6446  data_time: 0.3694  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:36:47 d2.utils.events]: \u001b[0m eta: 0:52:38  iter: 37899  total_loss: 0.9138  loss_cls: 0.16  loss_box_reg: 0.2152  loss_mask: 0.2682  loss_rpn_cls: 0.04769  loss_rpn_loc: 0.176  time: 0.6447  data_time: 0.6026  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:36:59 d2.utils.events]: \u001b[0m eta: 0:53:04  iter: 37919  total_loss: 0.427  loss_cls: 0.06063  loss_box_reg: 0.0717  loss_mask: 0.09038  loss_rpn_cls: 0.04159  loss_rpn_loc: 0.17  time: 0.6447  data_time: 0.4092  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:37:09 d2.utils.events]: \u001b[0m eta: 0:52:28  iter: 37939  total_loss: 0.7114  loss_cls: 0.1131  loss_box_reg: 0.185  loss_mask: 0.2194  loss_rpn_cls: 0.0332  loss_rpn_loc: 0.1531  time: 0.6446  data_time: 0.3058  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:37:21 d2.utils.events]: \u001b[0m eta: 0:52:23  iter: 37959  total_loss: 0.9322  loss_cls: 0.1659  loss_box_reg: 0.2154  loss_mask: 0.2615  loss_rpn_cls: 0.04423  loss_rpn_loc: 0.1643  time: 0.6446  data_time: 0.3462  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:37:36 d2.utils.events]: \u001b[0m eta: 0:53:06  iter: 37979  total_loss: 0.9443  loss_cls: 0.1655  loss_box_reg: 0.1952  loss_mask: 0.2625  loss_rpn_cls: 0.05607  loss_rpn_loc: 0.2108  time: 0.6447  data_time: 0.5595  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:37:52 d2.utils.events]: \u001b[0m eta: 0:53:16  iter: 37999  total_loss: 0.9856  loss_cls: 0.1861  loss_box_reg: 0.2152  loss_mask: 0.2603  loss_rpn_cls: 0.05864  loss_rpn_loc: 0.1859  time: 0.6447  data_time: 0.5493  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:38:07 d2.utils.events]: \u001b[0m eta: 0:52:17  iter: 38019  total_loss: 0.9076  loss_cls: 0.1503  loss_box_reg: 0.2145  loss_mask: 0.2782  loss_rpn_cls: 0.03272  loss_rpn_loc: 0.1573  time: 0.6448  data_time: 0.5398  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:38:22 d2.utils.events]: \u001b[0m eta: 0:54:15  iter: 38039  total_loss: 0.9979  loss_cls: 0.1943  loss_box_reg: 0.3  loss_mask: 0.2708  loss_rpn_cls: 0.05922  loss_rpn_loc: 0.2061  time: 0.6449  data_time: 0.5518  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:38:36 d2.utils.events]: \u001b[0m eta: 0:54:10  iter: 38059  total_loss: 0.7576  loss_cls: 0.1303  loss_box_reg: 0.1908  loss_mask: 0.2415  loss_rpn_cls: 0.02855  loss_rpn_loc: 0.1568  time: 0.6449  data_time: 0.4512  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 16:38:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 16:38:48 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:38:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:38:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:38:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0450 s/iter. Eval: 0.0184 s/iter. Total: 0.0641 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 16:38:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.253756 (0.058103 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:38:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043503 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:38:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 16:38:52 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06997059945854943\n",
      "\u001b[32m[12/30 16:38:52 d2.utils.events]: \u001b[0m eta: 0:53:32  iter: 38079  total_loss: 0.7327  loss_cls: 0.1106  loss_box_reg: 0.1966  loss_mask: 0.2478  loss_rpn_cls: 0.04325  loss_rpn_loc: 0.1539  time: 0.6449  data_time: 0.4086  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:39:06 d2.utils.events]: \u001b[0m eta: 0:53:15  iter: 38099  total_loss: 0.6989  loss_cls: 0.1069  loss_box_reg: 0.1974  loss_mask: 0.2205  loss_rpn_cls: 0.02958  loss_rpn_loc: 0.1687  time: 0.6449  data_time: 0.4732  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:39:22 d2.utils.events]: \u001b[0m eta: 0:53:53  iter: 38119  total_loss: 0.8715  loss_cls: 0.1492  loss_box_reg: 0.2291  loss_mask: 0.2539  loss_rpn_cls: 0.05567  loss_rpn_loc: 0.1785  time: 0.6450  data_time: 0.5759  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:39:33 d2.utils.events]: \u001b[0m eta: 0:53:53  iter: 38139  total_loss: 0.649  loss_cls: 0.08731  loss_box_reg: 0.1444  loss_mask: 0.1849  loss_rpn_cls: 0.03729  loss_rpn_loc: 0.1599  time: 0.6450  data_time: 0.3515  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:39:46 d2.utils.events]: \u001b[0m eta: 0:53:50  iter: 38159  total_loss: 0.8748  loss_cls: 0.162  loss_box_reg: 0.205  loss_mask: 0.2406  loss_rpn_cls: 0.04407  loss_rpn_loc: 0.1812  time: 0.6450  data_time: 0.4461  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:39:58 d2.utils.events]: \u001b[0m eta: 0:53:37  iter: 38179  total_loss: 0.7411  loss_cls: 0.09287  loss_box_reg: 0.1495  loss_mask: 0.241  loss_rpn_cls: 0.02924  loss_rpn_loc: 0.1552  time: 0.6450  data_time: 0.3951  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:40:12 d2.utils.events]: \u001b[0m eta: 0:53:39  iter: 38199  total_loss: 0.9495  loss_cls: 0.1656  loss_box_reg: 0.2202  loss_mask: 0.2361  loss_rpn_cls: 0.05855  loss_rpn_loc: 0.1705  time: 0.6450  data_time: 0.4664  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:40:23 d2.utils.events]: \u001b[0m eta: 0:53:10  iter: 38219  total_loss: 0.1778  loss_cls: 0.0001298  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01837  loss_rpn_loc: 0.1535  time: 0.6449  data_time: 0.3613  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:40:35 d2.utils.events]: \u001b[0m eta: 0:52:57  iter: 38239  total_loss: 0.7635  loss_cls: 0.1117  loss_box_reg: 0.1918  loss_mask: 0.204  loss_rpn_cls: 0.02713  loss_rpn_loc: 0.1495  time: 0.6449  data_time: 0.3765  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:40:50 d2.utils.events]: \u001b[0m eta: 0:53:22  iter: 38259  total_loss: 1.001  loss_cls: 0.2178  loss_box_reg: 0.2338  loss_mask: 0.288  loss_rpn_cls: 0.0681  loss_rpn_loc: 0.1985  time: 0.6449  data_time: 0.5044  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:41:03 d2.utils.events]: \u001b[0m eta: 0:53:10  iter: 38279  total_loss: 0.9261  loss_cls: 0.1556  loss_box_reg: 0.2128  loss_mask: 0.2586  loss_rpn_cls: 0.06587  loss_rpn_loc: 0.1772  time: 0.6450  data_time: 0.4435  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:41:18 d2.utils.events]: \u001b[0m eta: 0:52:55  iter: 38299  total_loss: 0.8959  loss_cls: 0.1527  loss_box_reg: 0.2059  loss_mask: 0.2553  loss_rpn_cls: 0.03405  loss_rpn_loc: 0.1601  time: 0.6450  data_time: 0.5270  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:41:29 d2.utils.events]: \u001b[0m eta: 0:52:24  iter: 38319  total_loss: 0.8171  loss_cls: 0.1396  loss_box_reg: 0.196  loss_mask: 0.2202  loss_rpn_cls: 0.04244  loss_rpn_loc: 0.1801  time: 0.6450  data_time: 0.3574  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:41:43 d2.utils.events]: \u001b[0m eta: 0:52:43  iter: 38339  total_loss: 0.8989  loss_cls: 0.1553  loss_box_reg: 0.2434  loss_mask: 0.25  loss_rpn_cls: 0.05008  loss_rpn_loc: 0.1755  time: 0.6450  data_time: 0.4540  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:41:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 16:41:49 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:41:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:41:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:41:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0449 s/iter. Eval: 0.0179 s/iter. Total: 0.0635 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 16:41:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.377495 (0.060312 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:41:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043666 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:41:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 16:41:52 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06834596345993417\n",
      "\u001b[32m[12/30 16:41:55 d2.utils.events]: \u001b[0m eta: 0:52:13  iter: 38359  total_loss: 0.5726  loss_cls: 0.07656  loss_box_reg: 0.154  loss_mask: 0.1827  loss_rpn_cls: 0.02336  loss_rpn_loc: 0.1549  time: 0.6449  data_time: 0.2208  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:42:12 d2.utils.events]: \u001b[0m eta: 0:52:07  iter: 38379  total_loss: 0.9177  loss_cls: 0.1509  loss_box_reg: 0.1793  loss_mask: 0.2732  loss_rpn_cls: 0.05848  loss_rpn_loc: 0.195  time: 0.6450  data_time: 0.6122  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:42:21 d2.utils.events]: \u001b[0m eta: 0:51:18  iter: 38399  total_loss: 0.5947  loss_cls: 0.08507  loss_box_reg: 0.1533  loss_mask: 0.2039  loss_rpn_cls: 0.02185  loss_rpn_loc: 0.14  time: 0.6448  data_time: 0.2456  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:42:32 d2.utils.events]: \u001b[0m eta: 0:51:11  iter: 38419  total_loss: 0.3065  loss_cls: 0.01225  loss_box_reg: 0.05143  loss_mask: 0.09978  loss_rpn_cls: 0.02421  loss_rpn_loc: 0.1436  time: 0.6448  data_time: 0.3482  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:42:46 d2.utils.events]: \u001b[0m eta: 0:51:38  iter: 38439  total_loss: 0.9549  loss_cls: 0.1831  loss_box_reg: 0.2204  loss_mask: 0.2708  loss_rpn_cls: 0.06246  loss_rpn_loc: 0.1793  time: 0.6448  data_time: 0.4670  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:43:00 d2.utils.events]: \u001b[0m eta: 0:51:23  iter: 38459  total_loss: 0.8626  loss_cls: 0.155  loss_box_reg: 0.2138  loss_mask: 0.259  loss_rpn_cls: 0.03981  loss_rpn_loc: 0.1783  time: 0.6448  data_time: 0.4507  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:43:15 d2.utils.events]: \u001b[0m eta: 0:51:57  iter: 38479  total_loss: 0.967  loss_cls: 0.1508  loss_box_reg: 0.2334  loss_mask: 0.251  loss_rpn_cls: 0.04306  loss_rpn_loc: 0.1808  time: 0.6449  data_time: 0.5148  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:43:27 d2.utils.events]: \u001b[0m eta: 0:51:32  iter: 38499  total_loss: 0.899  loss_cls: 0.1472  loss_box_reg: 0.211  loss_mask: 0.2604  loss_rpn_cls: 0.0459  loss_rpn_loc: 0.1594  time: 0.6449  data_time: 0.4225  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:43:40 d2.utils.events]: \u001b[0m eta: 0:51:46  iter: 38519  total_loss: 0.9497  loss_cls: 0.1704  loss_box_reg: 0.2222  loss_mask: 0.2069  loss_rpn_cls: 0.05845  loss_rpn_loc: 0.173  time: 0.6449  data_time: 0.4303  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:43:55 d2.utils.events]: \u001b[0m eta: 0:52:00  iter: 38539  total_loss: 0.9271  loss_cls: 0.1501  loss_box_reg: 0.2371  loss_mask: 0.264  loss_rpn_cls: 0.045  loss_rpn_loc: 0.1765  time: 0.6450  data_time: 0.5252  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 16:44:05 d2.utils.events]: \u001b[0m eta: 0:51:35  iter: 38559  total_loss: 0.6826  loss_cls: 0.0946  loss_box_reg: 0.1931  loss_mask: 0.2312  loss_rpn_cls: 0.03151  loss_rpn_loc: 0.1509  time: 0.6449  data_time: 0.2748  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:44:20 d2.utils.events]: \u001b[0m eta: 0:51:17  iter: 38579  total_loss: 0.9655  loss_cls: 0.1765  loss_box_reg: 0.2264  loss_mask: 0.2616  loss_rpn_cls: 0.05125  loss_rpn_loc: 0.1861  time: 0.6449  data_time: 0.5247  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:44:31 d2.utils.events]: \u001b[0m eta: 0:51:24  iter: 38599  total_loss: 0.9618  loss_cls: 0.178  loss_box_reg: 0.2862  loss_mask: 0.2646  loss_rpn_cls: 0.04422  loss_rpn_loc: 0.1694  time: 0.6449  data_time: 0.3606  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:44:45 d2.utils.events]: \u001b[0m eta: 0:51:31  iter: 38619  total_loss: 0.9025  loss_cls: 0.1342  loss_box_reg: 0.2088  loss_mask: 0.2634  loss_rpn_cls: 0.08145  loss_rpn_loc: 0.1776  time: 0.6449  data_time: 0.4690  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:44:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 16:44:48 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:44:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:44:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:44:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0438 s/iter. Eval: 0.0149 s/iter. Total: 0.0594 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/30 16:44:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.463777 (0.061853 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:44:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043158 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:44:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 16:44:52 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06685209997565646\n",
      "\u001b[32m[12/30 16:45:02 d2.utils.events]: \u001b[0m eta: 0:51:32  iter: 38639  total_loss: 0.855  loss_cls: 0.1411  loss_box_reg: 0.2094  loss_mask: 0.2434  loss_rpn_cls: 0.04139  loss_rpn_loc: 0.1676  time: 0.6449  data_time: 0.4202  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:45:14 d2.utils.events]: \u001b[0m eta: 0:51:23  iter: 38659  total_loss: 0.8682  loss_cls: 0.1547  loss_box_reg: 0.1923  loss_mask: 0.2503  loss_rpn_cls: 0.05779  loss_rpn_loc: 0.1787  time: 0.6449  data_time: 0.4042  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:45:25 d2.utils.events]: \u001b[0m eta: 0:51:05  iter: 38679  total_loss: 0.901  loss_cls: 0.1652  loss_box_reg: 0.2302  loss_mask: 0.2465  loss_rpn_cls: 0.04619  loss_rpn_loc: 0.1765  time: 0.6448  data_time: 0.3136  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:45:37 d2.utils.events]: \u001b[0m eta: 0:51:27  iter: 38699  total_loss: 0.8465  loss_cls: 0.1551  loss_box_reg: 0.2232  loss_mask: 0.2417  loss_rpn_cls: 0.04812  loss_rpn_loc: 0.1708  time: 0.6448  data_time: 0.4000  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:45:50 d2.utils.events]: \u001b[0m eta: 0:51:11  iter: 38719  total_loss: 0.4089  loss_cls: 0.05261  loss_box_reg: 0.07859  loss_mask: 0.09467  loss_rpn_cls: 0.0296  loss_rpn_loc: 0.1544  time: 0.6448  data_time: 0.4264  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:46:06 d2.utils.events]: \u001b[0m eta: 0:51:09  iter: 38739  total_loss: 0.8707  loss_cls: 0.1568  loss_box_reg: 0.2126  loss_mask: 0.2335  loss_rpn_cls: 0.04771  loss_rpn_loc: 0.1746  time: 0.6449  data_time: 0.5703  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:46:18 d2.utils.events]: \u001b[0m eta: 0:50:44  iter: 38759  total_loss: 0.8456  loss_cls: 0.158  loss_box_reg: 0.2322  loss_mask: 0.2602  loss_rpn_cls: 0.0404  loss_rpn_loc: 0.162  time: 0.6449  data_time: 0.4058  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:46:32 d2.utils.events]: \u001b[0m eta: 0:50:48  iter: 38779  total_loss: 0.8182  loss_cls: 0.1439  loss_box_reg: 0.1891  loss_mask: 0.2427  loss_rpn_cls: 0.04472  loss_rpn_loc: 0.1602  time: 0.6449  data_time: 0.4883  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:46:49 d2.utils.events]: \u001b[0m eta: 0:51:34  iter: 38799  total_loss: 0.9363  loss_cls: 0.1793  loss_box_reg: 0.2015  loss_mask: 0.2633  loss_rpn_cls: 0.07371  loss_rpn_loc: 0.1914  time: 0.6450  data_time: 0.6227  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:46:59 d2.utils.events]: \u001b[0m eta: 0:51:40  iter: 38819  total_loss: 0.8598  loss_cls: 0.1377  loss_box_reg: 0.1948  loss_mask: 0.2508  loss_rpn_cls: 0.03714  loss_rpn_loc: 0.1598  time: 0.6449  data_time: 0.3069  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:47:20 d2.utils.events]: \u001b[0m eta: 0:52:01  iter: 38839  total_loss: 0.8956  loss_cls: 0.1784  loss_box_reg: 0.2103  loss_mask: 0.255  loss_rpn_cls: 0.0642  loss_rpn_loc: 0.177  time: 0.6452  data_time: 0.8160  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:47:31 d2.utils.events]: \u001b[0m eta: 0:51:49  iter: 38859  total_loss: 0.3959  loss_cls: 0.04122  loss_box_reg: 0.05635  loss_mask: 0.1065  loss_rpn_cls: 0.03466  loss_rpn_loc: 0.1556  time: 0.6451  data_time: 0.3539  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:47:41 d2.utils.events]: \u001b[0m eta: 0:51:28  iter: 38879  total_loss: 0.66  loss_cls: 0.1193  loss_box_reg: 0.1702  loss_mask: 0.2147  loss_rpn_cls: 0.02559  loss_rpn_loc: 0.1368  time: 0.6450  data_time: 0.2486  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:47:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 16:47:51 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:47:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:47:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:47:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0546 s/iter. Inference: 0.0458 s/iter. Eval: 0.0239 s/iter. Total: 0.1242 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/30 16:47:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.773792 (0.067389 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:47:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.044123 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:47:55 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 16:47:55 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06859758385330365\n",
      "\u001b[32m[12/30 16:47:57 d2.utils.events]: \u001b[0m eta: 0:51:14  iter: 38899  total_loss: 0.9056  loss_cls: 0.1445  loss_box_reg: 0.2099  loss_mask: 0.2587  loss_rpn_cls: 0.05403  loss_rpn_loc: 0.1787  time: 0.6450  data_time: 0.3988  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:48:14 d2.utils.events]: \u001b[0m eta: 0:51:17  iter: 38919  total_loss: 0.8241  loss_cls: 0.1137  loss_box_reg: 0.1542  loss_mask: 0.2608  loss_rpn_cls: 0.04883  loss_rpn_loc: 0.1724  time: 0.6451  data_time: 0.6078  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:48:25 d2.utils.events]: \u001b[0m eta: 0:51:03  iter: 38939  total_loss: 0.8075  loss_cls: 0.1471  loss_box_reg: 0.1959  loss_mask: 0.2371  loss_rpn_cls: 0.03288  loss_rpn_loc: 0.1701  time: 0.6451  data_time: 0.3613  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:48:41 d2.utils.events]: \u001b[0m eta: 0:51:12  iter: 38959  total_loss: 0.9404  loss_cls: 0.1361  loss_box_reg: 0.1724  loss_mask: 0.2655  loss_rpn_cls: 0.04918  loss_rpn_loc: 0.1615  time: 0.6452  data_time: 0.5454  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:48:59 d2.utils.events]: \u001b[0m eta: 0:51:22  iter: 38979  total_loss: 0.9756  loss_cls: 0.1614  loss_box_reg: 0.2229  loss_mask: 0.2714  loss_rpn_cls: 0.07869  loss_rpn_loc: 0.1996  time: 0.6453  data_time: 0.6794  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:49:10 d2.utils.events]: \u001b[0m eta: 0:51:04  iter: 38999  total_loss: 0.8356  loss_cls: 0.1345  loss_box_reg: 0.2058  loss_mask: 0.2193  loss_rpn_cls: 0.02644  loss_rpn_loc: 0.148  time: 0.6452  data_time: 0.3105  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:49:20 d2.utils.events]: \u001b[0m eta: 0:51:03  iter: 39019  total_loss: 0.861  loss_cls: 0.1442  loss_box_reg: 0.2149  loss_mask: 0.2425  loss_rpn_cls: 0.03202  loss_rpn_loc: 0.1697  time: 0.6452  data_time: 0.3005  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 16:49:36 d2.utils.events]: \u001b[0m eta: 0:50:53  iter: 39039  total_loss: 0.9229  loss_cls: 0.1606  loss_box_reg: 0.2305  loss_mask: 0.2703  loss_rpn_cls: 0.06926  loss_rpn_loc: 0.193  time: 0.6452  data_time: 0.5593  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:49:49 d2.utils.events]: \u001b[0m eta: 0:50:59  iter: 39059  total_loss: 0.9596  loss_cls: 0.1755  loss_box_reg: 0.2232  loss_mask: 0.2496  loss_rpn_cls: 0.05306  loss_rpn_loc: 0.1708  time: 0.6453  data_time: 0.4485  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:49:58 d2.utils.events]: \u001b[0m eta: 0:50:54  iter: 39079  total_loss: 0.6783  loss_cls: 0.09581  loss_box_reg: 0.1779  loss_mask: 0.201  loss_rpn_cls: 0.02294  loss_rpn_loc: 0.1512  time: 0.6451  data_time: 0.2404  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:50:12 d2.utils.events]: \u001b[0m eta: 0:51:14  iter: 39099  total_loss: 0.9197  loss_cls: 0.1648  loss_box_reg: 0.1929  loss_mask: 0.2698  loss_rpn_cls: 0.05304  loss_rpn_loc: 0.1713  time: 0.6452  data_time: 0.5157  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:50:23 d2.utils.events]: \u001b[0m eta: 0:51:02  iter: 39119  total_loss: 0.8782  loss_cls: 0.1542  loss_box_reg: 0.2052  loss_mask: 0.2459  loss_rpn_cls: 0.02824  loss_rpn_loc: 0.1428  time: 0.6451  data_time: 0.3173  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:50:32 d2.utils.events]: \u001b[0m eta: 0:50:37  iter: 39139  total_loss: 0.7262  loss_cls: 0.1153  loss_box_reg: 0.191  loss_mask: 0.2412  loss_rpn_cls: 0.02271  loss_rpn_loc: 0.1463  time: 0.6450  data_time: 0.2826  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:50:48 d2.utils.events]: \u001b[0m eta: 0:50:48  iter: 39159  total_loss: 0.9281  loss_cls: 0.1575  loss_box_reg: 0.1939  loss_mask: 0.2546  loss_rpn_cls: 0.05707  loss_rpn_loc: 0.1805  time: 0.6451  data_time: 0.5624  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:50:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 16:50:51 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:50:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:50:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:50:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0449 s/iter. Eval: 0.0202 s/iter. Total: 0.0658 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 16:50:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.358553 (0.059974 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:50:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043795 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:50:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 16:50:54 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06374899647598682\n",
      "\u001b[32m[12/30 16:51:00 d2.utils.events]: \u001b[0m eta: 0:50:19  iter: 39179  total_loss: 0.8216  loss_cls: 0.1248  loss_box_reg: 0.1805  loss_mask: 0.2112  loss_rpn_cls: 0.03718  loss_rpn_loc: 0.1502  time: 0.6449  data_time: 0.1955  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:51:12 d2.utils.events]: \u001b[0m eta: 0:50:08  iter: 39199  total_loss: 0.9013  loss_cls: 0.1299  loss_box_reg: 0.1941  loss_mask: 0.248  loss_rpn_cls: 0.06734  loss_rpn_loc: 0.1757  time: 0.6449  data_time: 0.3804  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:51:27 d2.utils.events]: \u001b[0m eta: 0:50:34  iter: 39219  total_loss: 0.9368  loss_cls: 0.1452  loss_box_reg: 0.1863  loss_mask: 0.2632  loss_rpn_cls: 0.04338  loss_rpn_loc: 0.1828  time: 0.6450  data_time: 0.5468  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:51:42 d2.utils.events]: \u001b[0m eta: 0:51:13  iter: 39239  total_loss: 0.9122  loss_cls: 0.1552  loss_box_reg: 0.2094  loss_mask: 0.2817  loss_rpn_cls: 0.06872  loss_rpn_loc: 0.1721  time: 0.6450  data_time: 0.5034  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:51:53 d2.utils.events]: \u001b[0m eta: 0:49:57  iter: 39259  total_loss: 0.6803  loss_cls: 0.1153  loss_box_reg: 0.1846  loss_mask: 0.1987  loss_rpn_cls: 0.02074  loss_rpn_loc: 0.1513  time: 0.6450  data_time: 0.3450  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:52:06 d2.utils.events]: \u001b[0m eta: 0:49:58  iter: 39279  total_loss: 0.8007  loss_cls: 0.1166  loss_box_reg: 0.1937  loss_mask: 0.2497  loss_rpn_cls: 0.01996  loss_rpn_loc: 0.1528  time: 0.6450  data_time: 0.4609  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:52:20 d2.utils.events]: \u001b[0m eta: 0:50:09  iter: 39299  total_loss: 0.9066  loss_cls: 0.1902  loss_box_reg: 0.2424  loss_mask: 0.2414  loss_rpn_cls: 0.04898  loss_rpn_loc: 0.1689  time: 0.6450  data_time: 0.4319  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:52:32 d2.utils.events]: \u001b[0m eta: 0:50:05  iter: 39319  total_loss: 0.8975  loss_cls: 0.1554  loss_box_reg: 0.1822  loss_mask: 0.2449  loss_rpn_cls: 0.04222  loss_rpn_loc: 0.1638  time: 0.6450  data_time: 0.4339  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:52:45 d2.utils.events]: \u001b[0m eta: 0:50:00  iter: 39339  total_loss: 0.7611  loss_cls: 0.1168  loss_box_reg: 0.2042  loss_mask: 0.221  loss_rpn_cls: 0.03301  loss_rpn_loc: 0.1494  time: 0.6450  data_time: 0.3964  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:52:53 d2.utils.events]: \u001b[0m eta: 0:50:38  iter: 39359  total_loss: 0.7005  loss_cls: 0.08557  loss_box_reg: 0.1862  loss_mask: 0.2306  loss_rpn_cls: 0.03586  loss_rpn_loc: 0.1522  time: 0.6448  data_time: 0.1983  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:53:06 d2.utils.events]: \u001b[0m eta: 0:50:04  iter: 39379  total_loss: 0.9054  loss_cls: 0.1411  loss_box_reg: 0.2283  loss_mask: 0.2823  loss_rpn_cls: 0.04177  loss_rpn_loc: 0.1651  time: 0.6448  data_time: 0.4328  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:53:17 d2.utils.events]: \u001b[0m eta: 0:50:34  iter: 39399  total_loss: 0.9257  loss_cls: 0.189  loss_box_reg: 0.2291  loss_mask: 0.257  loss_rpn_cls: 0.04225  loss_rpn_loc: 0.1928  time: 0.6448  data_time: 0.3774  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:53:33 d2.utils.events]: \u001b[0m eta: 0:50:46  iter: 39419  total_loss: 0.8538  loss_cls: 0.1418  loss_box_reg: 0.1916  loss_mask: 0.2196  loss_rpn_cls: 0.06589  loss_rpn_loc: 0.1605  time: 0.6448  data_time: 0.5356  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:53:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 16:53:45 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:53:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:53:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:53:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0451 s/iter. Eval: 0.0176 s/iter. Total: 0.0634 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 16:53:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.274508 (0.058473 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:53:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043635 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:53:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 16:53:49 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06682683116925842\n",
      "\u001b[32m[12/30 16:53:49 d2.utils.events]: \u001b[0m eta: 0:50:15  iter: 39439  total_loss: 0.7293  loss_cls: 0.1257  loss_box_reg: 0.1666  loss_mask: 0.2398  loss_rpn_cls: 0.04413  loss_rpn_loc: 0.1621  time: 0.6448  data_time: 0.4094  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:54:02 d2.utils.events]: \u001b[0m eta: 0:50:10  iter: 39459  total_loss: 0.8258  loss_cls: 0.131  loss_box_reg: 0.2074  loss_mask: 0.2303  loss_rpn_cls: 0.03053  loss_rpn_loc: 0.1632  time: 0.6448  data_time: 0.4062  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:54:11 d2.utils.events]: \u001b[0m eta: 0:49:27  iter: 39479  total_loss: 0.7603  loss_cls: 0.1142  loss_box_reg: 0.2107  loss_mask: 0.1972  loss_rpn_cls: 0.03387  loss_rpn_loc: 0.1584  time: 0.6447  data_time: 0.2694  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:54:24 d2.utils.events]: \u001b[0m eta: 0:49:21  iter: 39499  total_loss: 0.865  loss_cls: 0.1363  loss_box_reg: 0.21  loss_mask: 0.2328  loss_rpn_cls: 0.03802  loss_rpn_loc: 0.1666  time: 0.6447  data_time: 0.4564  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 16:54:35 d2.utils.events]: \u001b[0m eta: 0:49:14  iter: 39519  total_loss: 0.8762  loss_cls: 0.1479  loss_box_reg: 0.2016  loss_mask: 0.2315  loss_rpn_cls: 0.05566  loss_rpn_loc: 0.1732  time: 0.6446  data_time: 0.3028  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:54:48 d2.utils.events]: \u001b[0m eta: 0:48:34  iter: 39539  total_loss: 0.9241  loss_cls: 0.1696  loss_box_reg: 0.2186  loss_mask: 0.2646  loss_rpn_cls: 0.04471  loss_rpn_loc: 0.1646  time: 0.6446  data_time: 0.4257  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:55:05 d2.utils.events]: \u001b[0m eta: 0:49:13  iter: 39559  total_loss: 0.944  loss_cls: 0.1613  loss_box_reg: 0.2443  loss_mask: 0.2708  loss_rpn_cls: 0.05405  loss_rpn_loc: 0.1796  time: 0.6448  data_time: 0.6207  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:55:19 d2.utils.events]: \u001b[0m eta: 0:48:30  iter: 39579  total_loss: 0.6351  loss_cls: 0.0942  loss_box_reg: 0.1527  loss_mask: 0.2095  loss_rpn_cls: 0.0208  loss_rpn_loc: 0.1482  time: 0.6448  data_time: 0.5139  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:55:31 d2.utils.events]: \u001b[0m eta: 0:48:00  iter: 39599  total_loss: 0.7166  loss_cls: 0.1392  loss_box_reg: 0.1618  loss_mask: 0.2053  loss_rpn_cls: 0.0274  loss_rpn_loc: 0.136  time: 0.6448  data_time: 0.3577  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:55:41 d2.utils.events]: \u001b[0m eta: 0:47:52  iter: 39619  total_loss: 0.8289  loss_cls: 0.1225  loss_box_reg: 0.1725  loss_mask: 0.2365  loss_rpn_cls: 0.03716  loss_rpn_loc: 0.169  time: 0.6447  data_time: 0.3035  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:55:54 d2.utils.events]: \u001b[0m eta: 0:47:23  iter: 39639  total_loss: 0.7655  loss_cls: 0.1051  loss_box_reg: 0.1559  loss_mask: 0.238  loss_rpn_cls: 0.02986  loss_rpn_loc: 0.1792  time: 0.6447  data_time: 0.4342  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:56:09 d2.utils.events]: \u001b[0m eta: 0:47:17  iter: 39659  total_loss: 0.7698  loss_cls: 0.1417  loss_box_reg: 0.1776  loss_mask: 0.2346  loss_rpn_cls: 0.04205  loss_rpn_loc: 0.1608  time: 0.6447  data_time: 0.5017  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:56:20 d2.utils.events]: \u001b[0m eta: 0:46:38  iter: 39679  total_loss: 0.3774  loss_cls: 0.03567  loss_box_reg: 0.07303  loss_mask: 0.08121  loss_rpn_cls: 0.03185  loss_rpn_loc: 0.1682  time: 0.6447  data_time: 0.3412  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:56:37 d2.utils.events]: \u001b[0m eta: 0:46:29  iter: 39699  total_loss: 0.9179  loss_cls: 0.1411  loss_box_reg: 0.2028  loss_mask: 0.2788  loss_rpn_cls: 0.07785  loss_rpn_loc: 0.1841  time: 0.6448  data_time: 0.6108  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:56:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 16:56:43 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:56:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:56:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:56:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0449 s/iter. Eval: 0.0192 s/iter. Total: 0.0648 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 16:56:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.706678 (0.066191 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:56:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.044271 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:56:48 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 16:56:48 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0724914349368854\n",
      "\u001b[32m[12/30 16:56:52 d2.utils.events]: \u001b[0m eta: 0:46:27  iter: 39719  total_loss: 0.925  loss_cls: 0.1588  loss_box_reg: 0.2294  loss_mask: 0.233  loss_rpn_cls: 0.04753  loss_rpn_loc: 0.1707  time: 0.6447  data_time: 0.3337  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:57:04 d2.utils.events]: \u001b[0m eta: 0:46:12  iter: 39739  total_loss: 0.8893  loss_cls: 0.1549  loss_box_reg: 0.2104  loss_mask: 0.2349  loss_rpn_cls: 0.03992  loss_rpn_loc: 0.1538  time: 0.6447  data_time: 0.3906  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:57:16 d2.utils.events]: \u001b[0m eta: 0:46:16  iter: 39759  total_loss: 0.8688  loss_cls: 0.1218  loss_box_reg: 0.2282  loss_mask: 0.2444  loss_rpn_cls: 0.0321  loss_rpn_loc: 0.1554  time: 0.6447  data_time: 0.4131  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:57:25 d2.utils.events]: \u001b[0m eta: 0:45:54  iter: 39779  total_loss: 0.8727  loss_cls: 0.1692  loss_box_reg: 0.2406  loss_mask: 0.2391  loss_rpn_cls: 0.03803  loss_rpn_loc: 0.1503  time: 0.6446  data_time: 0.2338  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:57:41 d2.utils.events]: \u001b[0m eta: 0:45:49  iter: 39799  total_loss: 0.8774  loss_cls: 0.1439  loss_box_reg: 0.1882  loss_mask: 0.2604  loss_rpn_cls: 0.0535  loss_rpn_loc: 0.1725  time: 0.6447  data_time: 0.5540  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:57:50 d2.utils.events]: \u001b[0m eta: 0:45:21  iter: 39819  total_loss: 0.6188  loss_cls: 0.1021  loss_box_reg: 0.1482  loss_mask: 0.1821  loss_rpn_cls: 0.01772  loss_rpn_loc: 0.1458  time: 0.6445  data_time: 0.2522  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:58:03 d2.utils.events]: \u001b[0m eta: 0:45:07  iter: 39839  total_loss: 0.9215  loss_cls: 0.163  loss_box_reg: 0.2079  loss_mask: 0.2583  loss_rpn_cls: 0.05782  loss_rpn_loc: 0.1761  time: 0.6445  data_time: 0.4342  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:58:17 d2.utils.events]: \u001b[0m eta: 0:45:14  iter: 39859  total_loss: 0.8853  loss_cls: 0.1335  loss_box_reg: 0.1913  loss_mask: 0.2538  loss_rpn_cls: 0.04829  loss_rpn_loc: 0.1751  time: 0.6446  data_time: 0.5185  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:58:29 d2.utils.events]: \u001b[0m eta: 0:45:29  iter: 39879  total_loss: 0.819  loss_cls: 0.1348  loss_box_reg: 0.1603  loss_mask: 0.2374  loss_rpn_cls: 0.03566  loss_rpn_loc: 0.1587  time: 0.6446  data_time: 0.3870  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:58:41 d2.utils.events]: \u001b[0m eta: 0:44:57  iter: 39899  total_loss: 0.5909  loss_cls: 0.116  loss_box_reg: 0.1494  loss_mask: 0.1904  loss_rpn_cls: 0.0278  loss_rpn_loc: 0.1569  time: 0.6445  data_time: 0.3368  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:58:55 d2.utils.events]: \u001b[0m eta: 0:44:51  iter: 39919  total_loss: 0.8516  loss_cls: 0.1704  loss_box_reg: 0.1608  loss_mask: 0.2237  loss_rpn_cls: 0.03605  loss_rpn_loc: 0.17  time: 0.6445  data_time: 0.4841  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:59:11 d2.utils.events]: \u001b[0m eta: 0:44:53  iter: 39939  total_loss: 0.8373  loss_cls: 0.1337  loss_box_reg: 0.1833  loss_mask: 0.2219  loss_rpn_cls: 0.03476  loss_rpn_loc: 0.1589  time: 0.6447  data_time: 0.6123  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:59:24 d2.utils.events]: \u001b[0m eta: 0:44:41  iter: 39959  total_loss: 0.9067  loss_cls: 0.1392  loss_box_reg: 0.1987  loss_mask: 0.2616  loss_rpn_cls: 0.05252  loss_rpn_loc: 0.1813  time: 0.6447  data_time: 0.4420  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:59:40 d2.utils.events]: \u001b[0m eta: 0:44:26  iter: 39979  total_loss: 0.9384  loss_cls: 0.1464  loss_box_reg: 0.2214  loss_mask: 0.2712  loss_rpn_cls: 0.06437  loss_rpn_loc: 0.1723  time: 0.6448  data_time: 0.5745  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 16:59:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 16:59:43 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 16:59:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 16:59:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 16:59:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0442 s/iter. Inference: 0.0448 s/iter. Eval: 0.0183 s/iter. Total: 0.1073 s/iter. ETA=0:00:05\n",
      "\u001b[32m[12/30 16:59:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.586236 (0.064040 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:59:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043786 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 16:59:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 16:59:47 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07132318494808579\n",
      "\u001b[32m[12/30 16:59:56 d2.utils.events]: \u001b[0m eta: 0:44:12  iter: 39999  total_loss: 0.9363  loss_cls: 0.1468  loss_box_reg: 0.2165  loss_mask: 0.2555  loss_rpn_cls: 0.05352  loss_rpn_loc: 0.181  time: 0.6447  data_time: 0.3831  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:00:11 d2.utils.events]: \u001b[0m eta: 0:44:15  iter: 40019  total_loss: 0.8652  loss_cls: 0.1572  loss_box_reg: 0.1947  loss_mask: 0.2577  loss_rpn_cls: 0.04449  loss_rpn_loc: 0.1783  time: 0.6448  data_time: 0.5152  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:00:26 d2.utils.events]: \u001b[0m eta: 0:42:54  iter: 40039  total_loss: 0.8436  loss_cls: 0.1482  loss_box_reg: 0.1548  loss_mask: 0.262  loss_rpn_cls: 0.05258  loss_rpn_loc: 0.1729  time: 0.6448  data_time: 0.4999  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:00:42 d2.utils.events]: \u001b[0m eta: 0:42:55  iter: 40059  total_loss: 0.9478  loss_cls: 0.1558  loss_box_reg: 0.2233  loss_mask: 0.2875  loss_rpn_cls: 0.06435  loss_rpn_loc: 0.1894  time: 0.6449  data_time: 0.5801  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:00:54 d2.utils.events]: \u001b[0m eta: 0:42:56  iter: 40079  total_loss: 0.7729  loss_cls: 0.1595  loss_box_reg: 0.2182  loss_mask: 0.214  loss_rpn_cls: 0.03672  loss_rpn_loc: 0.1502  time: 0.6449  data_time: 0.3759  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:01:06 d2.utils.events]: \u001b[0m eta: 0:43:31  iter: 40099  total_loss: 0.9867  loss_cls: 0.1572  loss_box_reg: 0.2819  loss_mask: 0.2656  loss_rpn_cls: 0.04546  loss_rpn_loc: 0.1807  time: 0.6449  data_time: 0.4012  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:01:17 d2.utils.events]: \u001b[0m eta: 0:43:40  iter: 40119  total_loss: 0.8646  loss_cls: 0.156  loss_box_reg: 0.1949  loss_mask: 0.2412  loss_rpn_cls: 0.04048  loss_rpn_loc: 0.1543  time: 0.6448  data_time: 0.3557  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:01:33 d2.utils.events]: \u001b[0m eta: 0:43:56  iter: 40139  total_loss: 0.8928  loss_cls: 0.1675  loss_box_reg: 0.2039  loss_mask: 0.2661  loss_rpn_cls: 0.05972  loss_rpn_loc: 0.1899  time: 0.6449  data_time: 0.5396  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:01:48 d2.utils.events]: \u001b[0m eta: 0:43:47  iter: 40159  total_loss: 0.8799  loss_cls: 0.1585  loss_box_reg: 0.2108  loss_mask: 0.2419  loss_rpn_cls: 0.05584  loss_rpn_loc: 0.1633  time: 0.6450  data_time: 0.5674  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:01:59 d2.utils.events]: \u001b[0m eta: 0:43:53  iter: 40179  total_loss: 0.8609  loss_cls: 0.1381  loss_box_reg: 0.1908  loss_mask: 0.2685  loss_rpn_cls: 0.0445  loss_rpn_loc: 0.1793  time: 0.6449  data_time: 0.3164  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:02:08 d2.utils.events]: \u001b[0m eta: 0:43:27  iter: 40199  total_loss: 0.6793  loss_cls: 0.1069  loss_box_reg: 0.1753  loss_mask: 0.2259  loss_rpn_cls: 0.01805  loss_rpn_loc: 0.1386  time: 0.6448  data_time: 0.2594  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:02:19 d2.utils.events]: \u001b[0m eta: 0:42:54  iter: 40219  total_loss: 0.8733  loss_cls: 0.1516  loss_box_reg: 0.1913  loss_mask: 0.2574  loss_rpn_cls: 0.03539  loss_rpn_loc: 0.1586  time: 0.6447  data_time: 0.3117  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:02:31 d2.utils.events]: \u001b[0m eta: 0:42:11  iter: 40239  total_loss: 0.8554  loss_cls: 0.1594  loss_box_reg: 0.1774  loss_mask: 0.2239  loss_rpn_cls: 0.03516  loss_rpn_loc: 0.1477  time: 0.6447  data_time: 0.4157  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:02:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 17:02:41 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 17:02:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 17:02:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 17:02:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0417 s/iter. Inference: 0.0454 s/iter. Eval: 0.0239 s/iter. Total: 0.1111 s/iter. ETA=0:00:05\n",
      "\u001b[32m[12/30 17:02:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.604827 (0.064372 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 17:02:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043766 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 17:02:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 17:02:45 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06895527611583378\n",
      "\u001b[32m[12/30 17:02:48 d2.utils.events]: \u001b[0m eta: 0:42:18  iter: 40259  total_loss: 0.8743  loss_cls: 0.1746  loss_box_reg: 0.1927  loss_mask: 0.2397  loss_rpn_cls: 0.05535  loss_rpn_loc: 0.1822  time: 0.6447  data_time: 0.3806  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:03:03 d2.utils.events]: \u001b[0m eta: 0:42:58  iter: 40279  total_loss: 0.9985  loss_cls: 0.1653  loss_box_reg: 0.229  loss_mask: 0.269  loss_rpn_cls: 0.06325  loss_rpn_loc: 0.1866  time: 0.6448  data_time: 0.5340  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:03:16 d2.utils.events]: \u001b[0m eta: 0:42:52  iter: 40299  total_loss: 1.023  loss_cls: 0.2263  loss_box_reg: 0.2656  loss_mask: 0.2712  loss_rpn_cls: 0.0511  loss_rpn_loc: 0.1758  time: 0.6448  data_time: 0.4457  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:03:25 d2.utils.events]: \u001b[0m eta: 0:42:28  iter: 40319  total_loss: 0.7732  loss_cls: 0.1125  loss_box_reg: 0.2255  loss_mask: 0.2373  loss_rpn_cls: 0.02882  loss_rpn_loc: 0.1479  time: 0.6447  data_time: 0.2244  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:03:37 d2.utils.events]: \u001b[0m eta: 0:42:33  iter: 40339  total_loss: 0.9197  loss_cls: 0.1653  loss_box_reg: 0.2718  loss_mask: 0.247  loss_rpn_cls: 0.03107  loss_rpn_loc: 0.152  time: 0.6446  data_time: 0.3772  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:03:50 d2.utils.events]: \u001b[0m eta: 0:42:27  iter: 40359  total_loss: 0.1986  loss_cls: 0.0001974  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02349  loss_rpn_loc: 0.1533  time: 0.6446  data_time: 0.4466  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:04:06 d2.utils.events]: \u001b[0m eta: 0:42:38  iter: 40379  total_loss: 0.8943  loss_cls: 0.1473  loss_box_reg: 0.2053  loss_mask: 0.2709  loss_rpn_cls: 0.05894  loss_rpn_loc: 0.1687  time: 0.6447  data_time: 0.5696  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:04:16 d2.utils.events]: \u001b[0m eta: 0:42:16  iter: 40399  total_loss: 0.7184  loss_cls: 0.126  loss_box_reg: 0.1814  loss_mask: 0.2212  loss_rpn_cls: 0.02397  loss_rpn_loc: 0.1481  time: 0.6446  data_time: 0.3210  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:04:34 d2.utils.events]: \u001b[0m eta: 0:42:19  iter: 40419  total_loss: 0.8632  loss_cls: 0.1396  loss_box_reg: 0.2202  loss_mask: 0.2708  loss_rpn_cls: 0.04208  loss_rpn_loc: 0.1747  time: 0.6448  data_time: 0.6547  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:04:47 d2.utils.events]: \u001b[0m eta: 0:42:13  iter: 40439  total_loss: 0.6352  loss_cls: 0.1053  loss_box_reg: 0.1481  loss_mask: 0.2115  loss_rpn_cls: 0.0446  loss_rpn_loc: 0.1652  time: 0.6448  data_time: 0.4653  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:05:00 d2.utils.events]: \u001b[0m eta: 0:42:17  iter: 40459  total_loss: 0.8558  loss_cls: 0.1396  loss_box_reg: 0.1923  loss_mask: 0.2586  loss_rpn_cls: 0.05267  loss_rpn_loc: 0.1816  time: 0.6448  data_time: 0.4222  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:05:13 d2.utils.events]: \u001b[0m eta: 0:42:32  iter: 40479  total_loss: 0.9058  loss_cls: 0.1613  loss_box_reg: 0.1924  loss_mask: 0.2493  loss_rpn_cls: 0.06331  loss_rpn_loc: 0.1813  time: 0.6448  data_time: 0.4426  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:05:30 d2.utils.events]: \u001b[0m eta: 0:42:31  iter: 40499  total_loss: 0.9006  loss_cls: 0.1419  loss_box_reg: 0.1613  loss_mask: 0.2474  loss_rpn_cls: 0.08373  loss_rpn_loc: 0.1832  time: 0.6449  data_time: 0.6066  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:05:40 d2.utils.events]: \u001b[0m eta: 0:42:06  iter: 40519  total_loss: 0.7357  loss_cls: 0.1181  loss_box_reg: 0.1983  loss_mask: 0.1786  loss_rpn_cls: 0.02086  loss_rpn_loc: 0.1357  time: 0.6448  data_time: 0.2647  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:05:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 17:05:42 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 17:05:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 17:05:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 17:05:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0452 s/iter. Eval: 0.0271 s/iter. Total: 0.0731 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 17:05:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.507680 (0.062637 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 17:05:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.044050 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 17:05:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 17:05:47 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06968213836779671\n",
      "\u001b[32m[12/30 17:05:55 d2.utils.events]: \u001b[0m eta: 0:42:06  iter: 40539  total_loss: 0.7178  loss_cls: 0.1128  loss_box_reg: 0.1679  loss_mask: 0.2081  loss_rpn_cls: 0.03587  loss_rpn_loc: 0.1422  time: 0.6448  data_time: 0.3493  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:06:10 d2.utils.events]: \u001b[0m eta: 0:42:07  iter: 40559  total_loss: 1.014  loss_cls: 0.19  loss_box_reg: 0.2587  loss_mask: 0.2637  loss_rpn_cls: 0.05242  loss_rpn_loc: 0.1713  time: 0.6448  data_time: 0.5160  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:06:25 d2.utils.events]: \u001b[0m eta: 0:42:21  iter: 40579  total_loss: 0.97  loss_cls: 0.1894  loss_box_reg: 0.2284  loss_mask: 0.2795  loss_rpn_cls: 0.05962  loss_rpn_loc: 0.166  time: 0.6449  data_time: 0.5324  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:06:39 d2.utils.events]: \u001b[0m eta: 0:43:14  iter: 40599  total_loss: 0.8331  loss_cls: 0.1514  loss_box_reg: 0.18  loss_mask: 0.2483  loss_rpn_cls: 0.03166  loss_rpn_loc: 0.1643  time: 0.6449  data_time: 0.4758  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:06:51 d2.utils.events]: \u001b[0m eta: 0:43:09  iter: 40619  total_loss: 0.8095  loss_cls: 0.1439  loss_box_reg: 0.1899  loss_mask: 0.2405  loss_rpn_cls: 0.03132  loss_rpn_loc: 0.1684  time: 0.6449  data_time: 0.3769  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:07:05 d2.utils.events]: \u001b[0m eta: 0:43:38  iter: 40639  total_loss: 0.9584  loss_cls: 0.1592  loss_box_reg: 0.1914  loss_mask: 0.2644  loss_rpn_cls: 0.07567  loss_rpn_loc: 0.189  time: 0.6449  data_time: 0.4849  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:07:16 d2.utils.events]: \u001b[0m eta: 0:43:31  iter: 40659  total_loss: 0.8197  loss_cls: 0.1428  loss_box_reg: 0.1947  loss_mask: 0.235  loss_rpn_cls: 0.03455  loss_rpn_loc: 0.1602  time: 0.6449  data_time: 0.3267  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:07:27 d2.utils.events]: \u001b[0m eta: 0:43:27  iter: 40679  total_loss: 0.7703  loss_cls: 0.1473  loss_box_reg: 0.1632  loss_mask: 0.2326  loss_rpn_cls: 0.03769  loss_rpn_loc: 0.159  time: 0.6448  data_time: 0.3749  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:07:40 d2.utils.events]: \u001b[0m eta: 0:43:13  iter: 40699  total_loss: 0.6463  loss_cls: 0.08873  loss_box_reg: 0.1435  loss_mask: 0.1924  loss_rpn_cls: 0.03794  loss_rpn_loc: 0.1417  time: 0.6448  data_time: 0.4227  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:07:56 d2.utils.events]: \u001b[0m eta: 0:43:09  iter: 40719  total_loss: 0.852  loss_cls: 0.1287  loss_box_reg: 0.1908  loss_mask: 0.2801  loss_rpn_cls: 0.04988  loss_rpn_loc: 0.1948  time: 0.6449  data_time: 0.5808  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:08:09 d2.utils.events]: \u001b[0m eta: 0:43:04  iter: 40739  total_loss: 0.7339  loss_cls: 0.1263  loss_box_reg: 0.2092  loss_mask: 0.233  loss_rpn_cls: 0.03725  loss_rpn_loc: 0.1444  time: 0.6449  data_time: 0.4071  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:08:21 d2.utils.events]: \u001b[0m eta: 0:42:10  iter: 40759  total_loss: 0.7233  loss_cls: 0.1276  loss_box_reg: 0.1831  loss_mask: 0.2167  loss_rpn_cls: 0.03084  loss_rpn_loc: 0.1638  time: 0.6449  data_time: 0.3940  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:08:32 d2.utils.events]: \u001b[0m eta: 0:42:00  iter: 40779  total_loss: 0.6301  loss_cls: 0.116  loss_box_reg: 0.1763  loss_mask: 0.2039  loss_rpn_cls: 0.02818  loss_rpn_loc: 0.1501  time: 0.6448  data_time: 0.3371  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:08:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 17:08:44 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 17:08:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 17:08:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 17:08:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0553 s/iter. Inference: 0.0443 s/iter. Eval: 0.0156 s/iter. Total: 0.1152 s/iter. ETA=0:00:05\n",
      "\u001b[32m[12/30 17:08:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.619178 (0.064628 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 17:08:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043733 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 17:08:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 17:08:49 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06586682025374307\n",
      "\u001b[32m[12/30 17:08:49 d2.utils.events]: \u001b[0m eta: 0:41:49  iter: 40799  total_loss: 0.8987  loss_cls: 0.1494  loss_box_reg: 0.2052  loss_mask: 0.2559  loss_rpn_cls: 0.05241  loss_rpn_loc: 0.152  time: 0.6448  data_time: 0.4101  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:08:58 d2.utils.events]: \u001b[0m eta: 0:41:48  iter: 40819  total_loss: 0.7347  loss_cls: 0.1209  loss_box_reg: 0.1902  loss_mask: 0.2446  loss_rpn_cls: 0.02328  loss_rpn_loc: 0.1476  time: 0.6447  data_time: 0.2907  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:09:14 d2.utils.events]: \u001b[0m eta: 0:41:38  iter: 40839  total_loss: 0.8551  loss_cls: 0.1508  loss_box_reg: 0.1934  loss_mask: 0.2384  loss_rpn_cls: 0.02686  loss_rpn_loc: 0.1374  time: 0.6448  data_time: 0.5335  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:09:26 d2.utils.events]: \u001b[0m eta: 0:41:29  iter: 40859  total_loss: 0.9112  loss_cls: 0.1425  loss_box_reg: 0.2234  loss_mask: 0.2359  loss_rpn_cls: 0.0388  loss_rpn_loc: 0.1675  time: 0.6448  data_time: 0.4239  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:09:41 d2.utils.events]: \u001b[0m eta: 0:41:13  iter: 40879  total_loss: 0.6323  loss_cls: 0.08153  loss_box_reg: 0.1322  loss_mask: 0.1851  loss_rpn_cls: 0.02397  loss_rpn_loc: 0.1395  time: 0.6448  data_time: 0.5165  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:09:55 d2.utils.events]: \u001b[0m eta: 0:41:22  iter: 40899  total_loss: 0.6836  loss_cls: 0.1008  loss_box_reg: 0.1626  loss_mask: 0.204  loss_rpn_cls: 0.02804  loss_rpn_loc: 0.1639  time: 0.6449  data_time: 0.4749  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:10:04 d2.utils.events]: \u001b[0m eta: 0:40:43  iter: 40919  total_loss: 0.6404  loss_cls: 0.1001  loss_box_reg: 0.1718  loss_mask: 0.2057  loss_rpn_cls: 0.03255  loss_rpn_loc: 0.162  time: 0.6448  data_time: 0.2530  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:10:19 d2.utils.events]: \u001b[0m eta: 0:40:41  iter: 40939  total_loss: 1.009  loss_cls: 0.1892  loss_box_reg: 0.2534  loss_mask: 0.2705  loss_rpn_cls: 0.06862  loss_rpn_loc: 0.1895  time: 0.6448  data_time: 0.5012  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:10:32 d2.utils.events]: \u001b[0m eta: 0:41:02  iter: 40959  total_loss: 0.9495  loss_cls: 0.1673  loss_box_reg: 0.2223  loss_mask: 0.2587  loss_rpn_cls: 0.05791  loss_rpn_loc: 0.169  time: 0.6448  data_time: 0.4112  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:10:43 d2.utils.events]: \u001b[0m eta: 0:40:05  iter: 40979  total_loss: 0.6848  loss_cls: 0.1119  loss_box_reg: 0.1902  loss_mask: 0.2129  loss_rpn_cls: 0.02739  loss_rpn_loc: 0.1512  time: 0.6447  data_time: 0.3580  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:10:59 d2.utils.events]: \u001b[0m eta: 0:40:29  iter: 40999  total_loss: 0.9388  loss_cls: 0.179  loss_box_reg: 0.1879  loss_mask: 0.2789  loss_rpn_cls: 0.0705  loss_rpn_loc: 0.1879  time: 0.6449  data_time: 0.5864  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:11:13 d2.utils.events]: \u001b[0m eta: 0:40:23  iter: 41019  total_loss: 0.9053  loss_cls: 0.1585  loss_box_reg: 0.227  loss_mask: 0.2593  loss_rpn_cls: 0.04418  loss_rpn_loc: 0.1773  time: 0.6449  data_time: 0.4693  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 17:11:26 d2.utils.events]: \u001b[0m eta: 0:40:49  iter: 41039  total_loss: 0.9011  loss_cls: 0.1524  loss_box_reg: 0.2144  loss_mask: 0.2718  loss_rpn_cls: 0.03843  loss_rpn_loc: 0.1683  time: 0.6449  data_time: 0.4411  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:11:39 d2.utils.events]: \u001b[0m eta: 0:40:34  iter: 41059  total_loss: 0.8067  loss_cls: 0.1327  loss_box_reg: 0.1685  loss_mask: 0.2406  loss_rpn_cls: 0.04017  loss_rpn_loc: 0.1321  time: 0.6449  data_time: 0.4386  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:11:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 17:11:48 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 17:11:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 17:11:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 17:11:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0465 s/iter. Inference: 0.0446 s/iter. Eval: 0.0199 s/iter. Total: 0.1110 s/iter. ETA=0:00:05\n",
      "\u001b[32m[12/30 17:11:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.662717 (0.065406 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 17:11:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043920 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 17:11:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 17:11:52 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.07021663819292115\n",
      "\u001b[32m[12/30 17:11:57 d2.utils.events]: \u001b[0m eta: 0:40:38  iter: 41079  total_loss: 0.9331  loss_cls: 0.1562  loss_box_reg: 0.2072  loss_mask: 0.2575  loss_rpn_cls: 0.04079  loss_rpn_loc: 0.1799  time: 0.6449  data_time: 0.4629  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:12:09 d2.utils.events]: \u001b[0m eta: 0:39:33  iter: 41099  total_loss: 0.8905  loss_cls: 0.1452  loss_box_reg: 0.1794  loss_mask: 0.2255  loss_rpn_cls: 0.03461  loss_rpn_loc: 0.1496  time: 0.6449  data_time: 0.3421  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:12:18 d2.utils.events]: \u001b[0m eta: 0:39:15  iter: 41119  total_loss: 0.3419  loss_cls: 0.02654  loss_box_reg: 0.0582  loss_mask: 0.06617  loss_rpn_cls: 0.02697  loss_rpn_loc: 0.1439  time: 0.6447  data_time: 0.2580  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:12:30 d2.utils.events]: \u001b[0m eta: 0:38:52  iter: 41139  total_loss: 0.738  loss_cls: 0.1517  loss_box_reg: 0.1847  loss_mask: 0.2353  loss_rpn_cls: 0.03671  loss_rpn_loc: 0.1517  time: 0.6447  data_time: 0.3751  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:12:42 d2.utils.events]: \u001b[0m eta: 0:38:58  iter: 41159  total_loss: 0.941  loss_cls: 0.1665  loss_box_reg: 0.2092  loss_mask: 0.2701  loss_rpn_cls: 0.04227  loss_rpn_loc: 0.1708  time: 0.6447  data_time: 0.4125  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:12:55 d2.utils.events]: \u001b[0m eta: 0:39:07  iter: 41179  total_loss: 0.8992  loss_cls: 0.1536  loss_box_reg: 0.1973  loss_mask: 0.2463  loss_rpn_cls: 0.06385  loss_rpn_loc: 0.1842  time: 0.6447  data_time: 0.4195  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:13:09 d2.utils.events]: \u001b[0m eta: 0:39:35  iter: 41199  total_loss: 0.9216  loss_cls: 0.1441  loss_box_reg: 0.2054  loss_mask: 0.2588  loss_rpn_cls: 0.06517  loss_rpn_loc: 0.1745  time: 0.6447  data_time: 0.4779  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:13:19 d2.utils.events]: \u001b[0m eta: 0:39:16  iter: 41219  total_loss: 0.61  loss_cls: 0.08024  loss_box_reg: 0.1664  loss_mask: 0.185  loss_rpn_cls: 0.02467  loss_rpn_loc: 0.1595  time: 0.6447  data_time: 0.3286  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:13:35 d2.utils.events]: \u001b[0m eta: 0:39:55  iter: 41239  total_loss: 0.9627  loss_cls: 0.1551  loss_box_reg: 0.2488  loss_mask: 0.2631  loss_rpn_cls: 0.04794  loss_rpn_loc: 0.1864  time: 0.6447  data_time: 0.5339  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:13:51 d2.utils.events]: \u001b[0m eta: 0:40:00  iter: 41259  total_loss: 0.814  loss_cls: 0.1361  loss_box_reg: 0.1975  loss_mask: 0.2535  loss_rpn_cls: 0.05585  loss_rpn_loc: 0.1696  time: 0.6448  data_time: 0.5900  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:14:06 d2.utils.events]: \u001b[0m eta: 0:39:44  iter: 41279  total_loss: 0.9786  loss_cls: 0.1704  loss_box_reg: 0.2337  loss_mask: 0.2562  loss_rpn_cls: 0.03909  loss_rpn_loc: 0.1772  time: 0.6449  data_time: 0.5185  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:14:19 d2.utils.events]: \u001b[0m eta: 0:39:16  iter: 41299  total_loss: 0.8904  loss_cls: 0.1459  loss_box_reg: 0.1801  loss_mask: 0.2277  loss_rpn_cls: 0.03404  loss_rpn_loc: 0.1935  time: 0.6449  data_time: 0.4281  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:14:32 d2.utils.events]: \u001b[0m eta: 0:39:17  iter: 41319  total_loss: 0.8193  loss_cls: 0.1428  loss_box_reg: 0.2065  loss_mask: 0.2249  loss_rpn_cls: 0.04779  loss_rpn_loc: 0.1732  time: 0.6449  data_time: 0.4409  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:14:45 d2.utils.events]: \u001b[0m eta: 0:38:57  iter: 41339  total_loss: 0.6853  loss_cls: 0.1121  loss_box_reg: 0.1496  loss_mask: 0.2401  loss_rpn_cls: 0.0173  loss_rpn_loc: 0.1449  time: 0.6449  data_time: 0.4170  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:14:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 17:14:47 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 17:14:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 17:14:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 17:14:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0461 s/iter. Eval: 0.0186 s/iter. Total: 0.0655 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 17:14:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.578703 (0.063905 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 17:14:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043749 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 17:14:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 17:14:52 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06559204166252118\n",
      "\u001b[32m[12/30 17:14:58 d2.utils.events]: \u001b[0m eta: 0:38:39  iter: 41359  total_loss: 0.3235  loss_cls: 0.01196  loss_box_reg: 0.05392  loss_mask: 0.09111  loss_rpn_cls: 0.0254  loss_rpn_loc: 0.1593  time: 0.6448  data_time: 0.2249  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:15:09 d2.utils.events]: \u001b[0m eta: 0:38:19  iter: 41379  total_loss: 0.841  loss_cls: 0.157  loss_box_reg: 0.1808  loss_mask: 0.2299  loss_rpn_cls: 0.04475  loss_rpn_loc: 0.1707  time: 0.6447  data_time: 0.3742  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:15:20 d2.utils.events]: \u001b[0m eta: 0:38:13  iter: 41399  total_loss: 0.5866  loss_cls: 0.09473  loss_box_reg: 0.1587  loss_mask: 0.2024  loss_rpn_cls: 0.02071  loss_rpn_loc: 0.1448  time: 0.6446  data_time: 0.3120  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:15:30 d2.utils.events]: \u001b[0m eta: 0:37:41  iter: 41419  total_loss: 0.5775  loss_cls: 0.07273  loss_box_reg: 0.1225  loss_mask: 0.1665  loss_rpn_cls: 0.01665  loss_rpn_loc: 0.1479  time: 0.6446  data_time: 0.3079  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:15:42 d2.utils.events]: \u001b[0m eta: 0:37:52  iter: 41439  total_loss: 0.9137  loss_cls: 0.1384  loss_box_reg: 0.201  loss_mask: 0.2571  loss_rpn_cls: 0.06057  loss_rpn_loc: 0.1764  time: 0.6445  data_time: 0.3807  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:15:57 d2.utils.events]: \u001b[0m eta: 0:37:51  iter: 41459  total_loss: 0.8088  loss_cls: 0.1193  loss_box_reg: 0.1865  loss_mask: 0.273  loss_rpn_cls: 0.03021  loss_rpn_loc: 0.1624  time: 0.6446  data_time: 0.5547  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:16:10 d2.utils.events]: \u001b[0m eta: 0:37:39  iter: 41479  total_loss: 0.8477  loss_cls: 0.1317  loss_box_reg: 0.2121  loss_mask: 0.2465  loss_rpn_cls: 0.04444  loss_rpn_loc: 0.185  time: 0.6446  data_time: 0.4148  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:16:22 d2.utils.events]: \u001b[0m eta: 0:37:02  iter: 41499  total_loss: 0.7748  loss_cls: 0.1261  loss_box_reg: 0.2042  loss_mask: 0.2218  loss_rpn_cls: 0.02955  loss_rpn_loc: 0.1593  time: 0.6446  data_time: 0.3882  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 17:16:38 d2.utils.events]: \u001b[0m eta: 0:37:41  iter: 41519  total_loss: 0.9652  loss_cls: 0.2162  loss_box_reg: 0.3114  loss_mask: 0.2641  loss_rpn_cls: 0.06759  loss_rpn_loc: 0.1843  time: 0.6447  data_time: 0.5656  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:16:47 d2.utils.events]: \u001b[0m eta: 0:37:23  iter: 41539  total_loss: 0.7278  loss_cls: 0.114  loss_box_reg: 0.1872  loss_mask: 0.228  loss_rpn_cls: 0.02784  loss_rpn_loc: 0.1478  time: 0.6445  data_time: 0.2353  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:17:05 d2.utils.events]: \u001b[0m eta: 0:37:17  iter: 41559  total_loss: 0.9298  loss_cls: 0.172  loss_box_reg: 0.1895  loss_mask: 0.2701  loss_rpn_cls: 0.06371  loss_rpn_loc: 0.2006  time: 0.6447  data_time: 0.7171  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:17:22 d2.utils.events]: \u001b[0m eta: 0:36:35  iter: 41579  total_loss: 0.8998  loss_cls: 0.1417  loss_box_reg: 0.1858  loss_mask: 0.2848  loss_rpn_cls: 0.05656  loss_rpn_loc: 0.1888  time: 0.6448  data_time: 0.5864  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:17:36 d2.utils.events]: \u001b[0m eta: 0:36:30  iter: 41599  total_loss: 0.8782  loss_cls: 0.1392  loss_box_reg: 0.1892  loss_mask: 0.2531  loss_rpn_cls: 0.04606  loss_rpn_loc: 0.151  time: 0.6449  data_time: 0.5033  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:17:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 17:17:49 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 17:17:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 17:17:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 17:17:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0449 s/iter. Eval: 0.0173 s/iter. Total: 0.0630 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 17:17:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.691457 (0.065919 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 17:17:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043961 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 17:17:53 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 17:17:53 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06680488471361062\n",
      "\u001b[32m[12/30 17:17:55 d2.utils.events]: \u001b[0m eta: 0:36:48  iter: 41619  total_loss: 1.059  loss_cls: 0.2189  loss_box_reg: 0.2866  loss_mask: 0.2586  loss_rpn_cls: 0.06581  loss_rpn_loc: 0.1999  time: 0.6449  data_time: 0.4653  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:18:06 d2.utils.events]: \u001b[0m eta: 0:36:08  iter: 41639  total_loss: 0.9554  loss_cls: 0.1746  loss_box_reg: 0.2284  loss_mask: 0.2769  loss_rpn_cls: 0.05107  loss_rpn_loc: 0.1771  time: 0.6448  data_time: 0.3611  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:18:18 d2.utils.events]: \u001b[0m eta: 0:35:48  iter: 41659  total_loss: 0.6725  loss_cls: 0.1043  loss_box_reg: 0.1645  loss_mask: 0.2151  loss_rpn_cls: 0.03508  loss_rpn_loc: 0.1468  time: 0.6448  data_time: 0.4102  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:18:29 d2.utils.events]: \u001b[0m eta: 0:36:04  iter: 41679  total_loss: 0.8649  loss_cls: 0.1509  loss_box_reg: 0.2118  loss_mask: 0.2628  loss_rpn_cls: 0.04647  loss_rpn_loc: 0.1665  time: 0.6448  data_time: 0.3164  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:18:43 d2.utils.events]: \u001b[0m eta: 0:36:10  iter: 41699  total_loss: 0.823  loss_cls: 0.1326  loss_box_reg: 0.2076  loss_mask: 0.2476  loss_rpn_cls: 0.02434  loss_rpn_loc: 0.1632  time: 0.6448  data_time: 0.4652  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:18:53 d2.utils.events]: \u001b[0m eta: 0:35:55  iter: 41719  total_loss: 0.6233  loss_cls: 0.09619  loss_box_reg: 0.1628  loss_mask: 0.2109  loss_rpn_cls: 0.02373  loss_rpn_loc: 0.1466  time: 0.6447  data_time: 0.2833  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:19:08 d2.utils.events]: \u001b[0m eta: 0:36:00  iter: 41739  total_loss: 0.9727  loss_cls: 0.1451  loss_box_reg: 0.1932  loss_mask: 0.2727  loss_rpn_cls: 0.05569  loss_rpn_loc: 0.172  time: 0.6448  data_time: 0.5356  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:19:24 d2.utils.events]: \u001b[0m eta: 0:36:11  iter: 41759  total_loss: 0.878  loss_cls: 0.1353  loss_box_reg: 0.2149  loss_mask: 0.2612  loss_rpn_cls: 0.06353  loss_rpn_loc: 0.195  time: 0.6448  data_time: 0.5451  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:19:35 d2.utils.events]: \u001b[0m eta: 0:36:32  iter: 41779  total_loss: 0.7438  loss_cls: 0.148  loss_box_reg: 0.1783  loss_mask: 0.2172  loss_rpn_cls: 0.02664  loss_rpn_loc: 0.1466  time: 0.6448  data_time: 0.3294  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:19:47 d2.utils.events]: \u001b[0m eta: 0:35:38  iter: 41799  total_loss: 0.2335  loss_cls: 0.0001855  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03116  loss_rpn_loc: 0.1883  time: 0.6448  data_time: 0.3890  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:19:57 d2.utils.events]: \u001b[0m eta: 0:35:29  iter: 41819  total_loss: 0.6292  loss_cls: 0.087  loss_box_reg: 0.1525  loss_mask: 0.1859  loss_rpn_cls: 0.02941  loss_rpn_loc: 0.1427  time: 0.6447  data_time: 0.3039  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:20:11 d2.utils.events]: \u001b[0m eta: 0:35:33  iter: 41839  total_loss: 0.7401  loss_cls: 0.1375  loss_box_reg: 0.1808  loss_mask: 0.2374  loss_rpn_cls: 0.03908  loss_rpn_loc: 0.1572  time: 0.6447  data_time: 0.4873  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:20:23 d2.utils.events]: \u001b[0m eta: 0:36:00  iter: 41859  total_loss: 0.9133  loss_cls: 0.1511  loss_box_reg: 0.2525  loss_mask: 0.2724  loss_rpn_cls: 0.03679  loss_rpn_loc: 0.1683  time: 0.6447  data_time: 0.3904  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:20:38 d2.utils.events]: \u001b[0m eta: 0:36:21  iter: 41879  total_loss: 0.9121  loss_cls: 0.1775  loss_box_reg: 0.2045  loss_mask: 0.2575  loss_rpn_cls: 0.05279  loss_rpn_loc: 0.1636  time: 0.6448  data_time: 0.5106  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:20:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 17:20:42 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 17:20:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 17:20:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 17:20:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0455 s/iter. Eval: 0.0206 s/iter. Total: 0.0669 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 17:20:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.433192 (0.061307 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 17:20:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.044333 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 17:20:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 17:20:46 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06948195493098172\n",
      "\u001b[32m[12/30 17:20:52 d2.utils.events]: \u001b[0m eta: 0:36:01  iter: 41899  total_loss: 0.3939  loss_cls: 0.0368  loss_box_reg: 0.08279  loss_mask: 0.08911  loss_rpn_cls: 0.0352  loss_rpn_loc: 0.1455  time: 0.6447  data_time: 0.2872  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:21:00 d2.utils.events]: \u001b[0m eta: 0:36:20  iter: 41919  total_loss: 0.7045  loss_cls: 0.1125  loss_box_reg: 0.174  loss_mask: 0.2232  loss_rpn_cls: 0.02656  loss_rpn_loc: 0.1555  time: 0.6445  data_time: 0.1878  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:21:12 d2.utils.events]: \u001b[0m eta: 0:36:05  iter: 41939  total_loss: 0.755  loss_cls: 0.1317  loss_box_reg: 0.2074  loss_mask: 0.2267  loss_rpn_cls: 0.02505  loss_rpn_loc: 0.1403  time: 0.6445  data_time: 0.3903  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:21:22 d2.utils.events]: \u001b[0m eta: 0:35:48  iter: 41959  total_loss: 0.8431  loss_cls: 0.1428  loss_box_reg: 0.2168  loss_mask: 0.257  loss_rpn_cls: 0.032  loss_rpn_loc: 0.1608  time: 0.6444  data_time: 0.2847  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:21:34 d2.utils.events]: \u001b[0m eta: 0:36:11  iter: 41979  total_loss: 0.8487  loss_cls: 0.1305  loss_box_reg: 0.1933  loss_mask: 0.2588  loss_rpn_cls: 0.03717  loss_rpn_loc: 0.1807  time: 0.6444  data_time: 0.3809  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 17:21:50 d2.utils.events]: \u001b[0m eta: 0:36:06  iter: 41999  total_loss: 0.8697  loss_cls: 0.1561  loss_box_reg: 0.2104  loss_mask: 0.2458  loss_rpn_cls: 0.06452  loss_rpn_loc: 0.1825  time: 0.6445  data_time: 0.5796  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:22:07 d2.utils.events]: \u001b[0m eta: 0:36:05  iter: 42019  total_loss: 1.036  loss_cls: 0.1985  loss_box_reg: 0.2985  loss_mask: 0.2553  loss_rpn_cls: 0.03756  loss_rpn_loc: 0.1566  time: 0.6446  data_time: 0.6176  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:22:22 d2.utils.events]: \u001b[0m eta: 0:35:52  iter: 42039  total_loss: 0.8463  loss_cls: 0.1441  loss_box_reg: 0.1863  loss_mask: 0.2391  loss_rpn_cls: 0.0455  loss_rpn_loc: 0.1817  time: 0.6446  data_time: 0.5123  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:22:38 d2.utils.events]: \u001b[0m eta: 0:35:54  iter: 42059  total_loss: 0.9211  loss_cls: 0.1495  loss_box_reg: 0.2  loss_mask: 0.2711  loss_rpn_cls: 0.054  loss_rpn_loc: 0.1781  time: 0.6447  data_time: 0.5673  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:22:49 d2.utils.events]: \u001b[0m eta: 0:35:28  iter: 42079  total_loss: 0.7947  loss_cls: 0.1435  loss_box_reg: 0.1725  loss_mask: 0.2393  loss_rpn_cls: 0.03475  loss_rpn_loc: 0.1496  time: 0.6447  data_time: 0.3571  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:22:58 d2.utils.events]: \u001b[0m eta: 0:35:30  iter: 42099  total_loss: 0.4646  loss_cls: 0.06093  loss_box_reg: 0.1256  loss_mask: 0.1527  loss_rpn_cls: 0.0267  loss_rpn_loc: 0.1378  time: 0.6446  data_time: 0.2588  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:23:10 d2.utils.events]: \u001b[0m eta: 0:35:58  iter: 42119  total_loss: 0.9954  loss_cls: 0.1588  loss_box_reg: 0.2779  loss_mask: 0.2502  loss_rpn_cls: 0.0536  loss_rpn_loc: 0.1834  time: 0.6445  data_time: 0.3616  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:23:25 d2.utils.events]: \u001b[0m eta: 0:35:37  iter: 42139  total_loss: 0.8633  loss_cls: 0.143  loss_box_reg: 0.1757  loss_mask: 0.2424  loss_rpn_cls: 0.03823  loss_rpn_loc: 0.2014  time: 0.6446  data_time: 0.5255  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:23:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 17:23:37 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 17:23:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 17:23:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 17:23:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0008 s/iter. Inference: 0.0458 s/iter. Eval: 0.0178 s/iter. Total: 0.0644 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 17:23:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.447328 (0.061559 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 17:23:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.044002 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 17:23:41 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 17:23:41 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06734639668016974\n",
      "\u001b[32m[12/30 17:23:41 d2.utils.events]: \u001b[0m eta: 0:35:06  iter: 42159  total_loss: 0.6522  loss_cls: 0.09269  loss_box_reg: 0.1467  loss_mask: 0.2143  loss_rpn_cls: 0.01942  loss_rpn_loc: 0.1667  time: 0.6446  data_time: 0.3955  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:23:51 d2.utils.events]: \u001b[0m eta: 0:34:00  iter: 42179  total_loss: 0.6952  loss_cls: 0.1174  loss_box_reg: 0.2158  loss_mask: 0.2149  loss_rpn_cls: 0.04477  loss_rpn_loc: 0.1521  time: 0.6445  data_time: 0.2840  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:24:06 d2.utils.events]: \u001b[0m eta: 0:33:55  iter: 42199  total_loss: 0.9458  loss_cls: 0.1732  loss_box_reg: 0.2473  loss_mask: 0.2257  loss_rpn_cls: 0.07109  loss_rpn_loc: 0.1858  time: 0.6446  data_time: 0.5591  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:24:22 d2.utils.events]: \u001b[0m eta: 0:34:54  iter: 42219  total_loss: 0.9257  loss_cls: 0.1668  loss_box_reg: 0.2031  loss_mask: 0.2695  loss_rpn_cls: 0.05066  loss_rpn_loc: 0.1803  time: 0.6446  data_time: 0.5492  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:24:37 d2.utils.events]: \u001b[0m eta: 0:34:13  iter: 42239  total_loss: 0.9363  loss_cls: 0.175  loss_box_reg: 0.2031  loss_mask: 0.2867  loss_rpn_cls: 0.04338  loss_rpn_loc: 0.1593  time: 0.6447  data_time: 0.5458  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:24:50 d2.utils.events]: \u001b[0m eta: 0:33:39  iter: 42259  total_loss: 0.8853  loss_cls: 0.1443  loss_box_reg: 0.2177  loss_mask: 0.2573  loss_rpn_cls: 0.03165  loss_rpn_loc: 0.1526  time: 0.6447  data_time: 0.4071  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:25:01 d2.utils.events]: \u001b[0m eta: 0:33:18  iter: 42279  total_loss: 0.7616  loss_cls: 0.1278  loss_box_reg: 0.1713  loss_mask: 0.2404  loss_rpn_cls: 0.03681  loss_rpn_loc: 0.1571  time: 0.6446  data_time: 0.3575  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:25:13 d2.utils.events]: \u001b[0m eta: 0:33:13  iter: 42299  total_loss: 0.8258  loss_cls: 0.1168  loss_box_reg: 0.2155  loss_mask: 0.2542  loss_rpn_cls: 0.03942  loss_rpn_loc: 0.1709  time: 0.6446  data_time: 0.3792  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:25:25 d2.utils.events]: \u001b[0m eta: 0:33:19  iter: 42319  total_loss: 0.7858  loss_cls: 0.1337  loss_box_reg: 0.2178  loss_mask: 0.2392  loss_rpn_cls: 0.02632  loss_rpn_loc: 0.1526  time: 0.6446  data_time: 0.3838  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:25:36 d2.utils.events]: \u001b[0m eta: 0:33:14  iter: 42339  total_loss: 0.6929  loss_cls: 0.1097  loss_box_reg: 0.1646  loss_mask: 0.209  loss_rpn_cls: 0.02458  loss_rpn_loc: 0.1564  time: 0.6445  data_time: 0.3442  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:25:45 d2.utils.events]: \u001b[0m eta: 0:33:26  iter: 42359  total_loss: 0.8203  loss_cls: 0.1275  loss_box_reg: 0.2033  loss_mask: 0.2356  loss_rpn_cls: 0.03602  loss_rpn_loc: 0.1646  time: 0.6444  data_time: 0.2445  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:26:01 d2.utils.events]: \u001b[0m eta: 0:33:43  iter: 42379  total_loss: 0.7794  loss_cls: 0.1354  loss_box_reg: 0.177  loss_mask: 0.2526  loss_rpn_cls: 0.03609  loss_rpn_loc: 0.1618  time: 0.6445  data_time: 0.5741  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:26:15 d2.utils.events]: \u001b[0m eta: 0:33:38  iter: 42399  total_loss: 0.7391  loss_cls: 0.1363  loss_box_reg: 0.2037  loss_mask: 0.2532  loss_rpn_cls: 0.02705  loss_rpn_loc: 0.1637  time: 0.6445  data_time: 0.4930  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:26:29 d2.utils.events]: \u001b[0m eta: 0:33:44  iter: 42419  total_loss: 0.8632  loss_cls: 0.1627  loss_box_reg: 0.2394  loss_mask: 0.2509  loss_rpn_cls: 0.02582  loss_rpn_loc: 0.1564  time: 0.6446  data_time: 0.4633  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:26:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/30 17:26:39 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/30 17:26:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/30 17:26:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/30 17:26:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0007 s/iter. Inference: 0.0445 s/iter. Eval: 0.0181 s/iter. Total: 0.0633 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/30 17:26:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.377873 (0.060319 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 17:26:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.043911 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/30 17:26:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/30 17:26:43 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06767682781294414\n",
      "\u001b[32m[12/30 17:26:49 d2.utils.events]: \u001b[0m eta: 0:33:31  iter: 42439  total_loss: 0.9781  loss_cls: 0.1826  loss_box_reg: 0.2121  loss_mask: 0.2695  loss_rpn_cls: 0.06955  loss_rpn_loc: 0.2038  time: 0.6447  data_time: 0.5663  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:27:07 d2.utils.events]: \u001b[0m eta: 0:33:26  iter: 42459  total_loss: 0.9322  loss_cls: 0.1566  loss_box_reg: 0.2138  loss_mask: 0.261  loss_rpn_cls: 0.06  loss_rpn_loc: 0.168  time: 0.6448  data_time: 0.6752  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/30 17:27:23 d2.utils.events]: \u001b[0m eta: 0:33:15  iter: 42479  total_loss: 0.9058  loss_cls: 0.157  loss_box_reg: 0.1967  loss_mask: 0.2754  loss_rpn_cls: 0.06072  loss_rpn_loc: 0.1987  time: 0.6449  data_time: 0.5792  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:27:35 d2.utils.events]: \u001b[0m eta: 0:33:11  iter: 42499  total_loss: 0.7518  loss_cls: 0.1155  loss_box_reg: 0.1841  loss_mask: 0.2406  loss_rpn_cls: 0.0304  loss_rpn_loc: 0.1551  time: 0.6449  data_time: 0.3950  lr: 0.00125  max_mem: 6710M\n",
      "\u001b[32m[12/30 17:27:42 d2.engine.hooks]: \u001b[0mOverall training speed: 34409 iterations in 6:09:49 (0.6449 s / it)\n",
      "\u001b[32m[12/30 17:27:42 d2.engine.hooks]: \u001b[0mTotal training time: 6:18:52 (0:09:02 on hooks)\n",
      "\u001b[32m[12/30 17:27:42 d2.utils.events]: \u001b[0m eta: 0:33:00  iter: 42511  total_loss: 0.4376  loss_cls: 0.05312  loss_box_reg: 0.07458  loss_mask: 0.1203  loss_rpn_cls: 0.02754  loss_rpn_loc: 0.1551  time: 0.6449  data_time: 0.3632  lr: 0.00125  max_mem: 6710M\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4635/3194651403.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainModel50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4635/2442257823.py\u001b[0m in \u001b[0;36mtrainModel50\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_or_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0mOrderedDict\u001b[0m \u001b[0mof\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0menabled\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mOtherwise\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \"\"\"\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXPECTED_RESULTS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_main_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             assert hasattr(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0;31m# self.iter == max_iter can be used by `after_train` to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/detectron2/engine/train_loop.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0myou\u001b[0m \u001b[0mwant\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdo\u001b[0m \u001b[0msomething\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myou\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mwrap\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_loader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mdata_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/detectron2/data/common.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"width\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"height\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mbucket_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainModel50()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZvzJoqI6QuAc",
    "outputId": "ffa12a08-356f-45a9-ccab-7bb29f8fb4e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/27 12:07:41 d2.data.datasets.coco]: \u001b[0mLoading /content/livecell/livecell_annotations_train.json takes 21.98 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/27 12:07:41 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/27 12:07:42 d2.data.datasets.coco]: \u001b[0mLoaded 3253 images in COCO format from /content/livecell/livecell_annotations_train.json\n",
      "\u001b[32m[12/27 12:08:01 d2.data.datasets.coco]: \u001b[0mLoading /content/livecell/livecell_annotations_test.json takes 8.76 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/27 12:08:01 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/27 12:08:01 d2.data.datasets.coco]: \u001b[0mLoaded 1564 images in COCO format from /content/livecell/livecell_annotations_test.json\n",
      "/livecell\n",
      "\u001b[32m[12/27 12:08:23 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=9, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=32, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[12/27 12:08:46 d2.data.datasets.coco]: \u001b[0mLoading /content/livecell/livecell_annotations_train.json takes 22.13 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/27 12:08:46 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/27 12:08:46 d2.data.datasets.coco]: \u001b[0mLoaded 3253 images in COCO format from /content/livecell/livecell_annotations_train.json\n",
      "\u001b[32m[12/27 12:09:05 d2.data.datasets.coco]: \u001b[0mLoading /content/livecell/livecell_annotations_test.json takes 10.41 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/27 12:09:05 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/27 12:09:05 d2.data.datasets.coco]: \u001b[0mLoaded 1564 images in COCO format from /content/livecell/livecell_annotations_test.json\n",
      "\u001b[32m[12/27 12:09:08 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 4817 images left.\n",
      "\u001b[32m[12/27 12:09:09 d2.data.build]: \u001b[0mDistribution of instances among all 8 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    a172    | 116153       |   bt474    | 115485       |    bv2     | 330995       |\n",
      "|    huh7    | 35214        |    mcf7    | 309602       |   shsy5y   | 241385       |\n",
      "|   skbr3    | 235123       |   skov3    | 96880        |            |              |\n",
      "|   total    | 1480837      |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[12/27 12:09:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[12/27 12:09:09 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/27 12:09:09 d2.data.common]: \u001b[0mSerializing 4817 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 12:09:14 d2.data.common]: \u001b[0mSerialized dataset takes 707.59 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_a3ec72.pkl: 254MB [00:12, 20.6MB/s]                           \n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (9, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (9,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (32, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (32,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (8, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (8,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/27 12:09:37 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/27 12:09:48 d2.utils.events]: \u001b[0m eta: 1:13:29  iter: 19  total_loss: 5.291  loss_cls: 1.951  loss_box_reg: 0.421  loss_mask: 0.6924  loss_rpn_cls: 1.823  loss_rpn_loc: 0.3426  time: 0.4565  data_time: 0.0536  lr: 9.9905e-05  max_mem: 9000M\n",
      "\u001b[32m[12/27 12:09:57 d2.utils.events]: \u001b[0m eta: 1:15:26  iter: 39  total_loss: 2.924  loss_cls: 1.153  loss_box_reg: 0.4876  loss_mask: 0.6856  loss_rpn_cls: 0.2815  loss_rpn_loc: 0.2853  time: 0.4726  data_time: 0.0240  lr: 0.0001998  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:10:07 d2.utils.events]: \u001b[0m eta: 1:14:51  iter: 59  total_loss: 2.906  loss_cls: 1.066  loss_box_reg: 0.5713  loss_mask: 0.6728  loss_rpn_cls: 0.2219  loss_rpn_loc: 0.2409  time: 0.4668  data_time: 0.0135  lr: 0.0002997  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:10:16 d2.utils.events]: \u001b[0m eta: 1:14:24  iter: 79  total_loss: 2.693  loss_cls: 1.018  loss_box_reg: 0.5283  loss_mask: 0.6462  loss_rpn_cls: 0.2191  loss_rpn_loc: 0.2406  time: 0.4622  data_time: 0.0137  lr: 0.00039961  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:10:25 d2.utils.events]: \u001b[0m eta: 1:14:10  iter: 99  total_loss: 2.554  loss_cls: 0.9875  loss_box_reg: 0.5425  loss_mask: 0.571  loss_rpn_cls: 0.1814  loss_rpn_loc: 0.2346  time: 0.4609  data_time: 0.0146  lr: 0.00049951  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:10:34 d2.utils.events]: \u001b[0m eta: 1:14:26  iter: 119  total_loss: 2.299  loss_cls: 0.9074  loss_box_reg: 0.5264  loss_mask: 0.5113  loss_rpn_cls: 0.1704  loss_rpn_loc: 0.2285  time: 0.4644  data_time: 0.0158  lr: 0.00059941  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:10:43 d2.utils.events]: \u001b[0m eta: 1:14:00  iter: 139  total_loss: 2.284  loss_cls: 0.9266  loss_box_reg: 0.5121  loss_mask: 0.4244  loss_rpn_cls: 0.1891  loss_rpn_loc: 0.215  time: 0.4616  data_time: 0.0137  lr: 0.0006993  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:10:53 d2.utils.events]: \u001b[0m eta: 1:14:22  iter: 159  total_loss: 2.363  loss_cls: 0.9438  loss_box_reg: 0.5789  loss_mask: 0.3991  loss_rpn_cls: 0.1659  loss_rpn_loc: 0.2261  time: 0.4626  data_time: 0.0151  lr: 0.00079921  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:11:02 d2.utils.events]: \u001b[0m eta: 1:14:13  iter: 179  total_loss: 2.066  loss_cls: 0.7762  loss_box_reg: 0.5724  loss_mask: 0.3733  loss_rpn_cls: 0.1661  loss_rpn_loc: 0.2187  time: 0.4615  data_time: 0.0141  lr: 0.0008991  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:11:11 d2.utils.events]: \u001b[0m eta: 1:14:04  iter: 199  total_loss: 2.193  loss_cls: 0.8427  loss_box_reg: 0.5805  loss_mask: 0.3657  loss_rpn_cls: 0.1403  loss_rpn_loc: 0.2481  time: 0.4603  data_time: 0.0133  lr: 0.00099901  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:11:13 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7faf6314e950> to CPU due to CUDA OOM\n",
      "\u001b[32m[12/27 12:11:41 d2.utils.events]: \u001b[0m eta: 1:13:52  iter: 219  total_loss: 2.203  loss_cls: 0.8514  loss_box_reg: 0.6005  loss_mask: 0.3682  loss_rpn_cls: 0.1697  loss_rpn_loc: 0.2401  time: 0.5555  data_time: 0.0166  lr: 0.0010989  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:11:50 d2.utils.events]: \u001b[0m eta: 1:13:48  iter: 239  total_loss: 2.1  loss_cls: 0.7561  loss_box_reg: 0.5748  loss_mask: 0.3438  loss_rpn_cls: 0.1604  loss_rpn_loc: 0.2292  time: 0.5490  data_time: 0.0150  lr: 0.0011988  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:11:59 d2.utils.events]: \u001b[0m eta: 1:13:37  iter: 259  total_loss: 2.14  loss_cls: 0.7618  loss_box_reg: 0.5935  loss_mask: 0.3549  loss_rpn_cls: 0.1592  loss_rpn_loc: 0.2269  time: 0.5409  data_time: 0.0136  lr: 0.0012987  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:12:08 d2.utils.events]: \u001b[0m eta: 1:13:28  iter: 279  total_loss: 1.895  loss_cls: 0.6545  loss_box_reg: 0.556  loss_mask: 0.3104  loss_rpn_cls: 0.1339  loss_rpn_loc: 0.2206  time: 0.5347  data_time: 0.0141  lr: 0.0013986  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:12:17 d2.utils.events]: \u001b[0m eta: 1:13:19  iter: 299  total_loss: 1.909  loss_cls: 0.6803  loss_box_reg: 0.5289  loss_mask: 0.299  loss_rpn_cls: 0.1031  loss_rpn_loc: 0.2023  time: 0.5294  data_time: 0.0124  lr: 0.0014985  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:12:26 d2.utils.events]: \u001b[0m eta: 1:13:09  iter: 319  total_loss: 1.788  loss_cls: 0.6115  loss_box_reg: 0.5369  loss_mask: 0.3269  loss_rpn_cls: 0.1298  loss_rpn_loc: 0.2338  time: 0.5244  data_time: 0.0148  lr: 0.0015984  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:12:36 d2.utils.events]: \u001b[0m eta: 1:12:58  iter: 339  total_loss: 1.813  loss_cls: 0.6268  loss_box_reg: 0.5271  loss_mask: 0.3061  loss_rpn_cls: 0.1237  loss_rpn_loc: 0.2148  time: 0.5206  data_time: 0.0137  lr: 0.0016983  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:12:45 d2.utils.events]: \u001b[0m eta: 1:12:49  iter: 359  total_loss: 1.833  loss_cls: 0.7199  loss_box_reg: 0.5044  loss_mask: 0.3225  loss_rpn_cls: 0.1406  loss_rpn_loc: 0.2141  time: 0.5178  data_time: 0.0156  lr: 0.0017982  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:12:54 d2.utils.events]: \u001b[0m eta: 1:12:38  iter: 379  total_loss: 1.789  loss_cls: 0.5897  loss_box_reg: 0.5215  loss_mask: 0.3081  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.2312  time: 0.5140  data_time: 0.0129  lr: 0.0018981  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:13:04 d2.utils.events]: \u001b[0m eta: 1:12:33  iter: 399  total_loss: 1.806  loss_cls: 0.6494  loss_box_reg: 0.457  loss_mask: 0.3155  loss_rpn_cls: 0.1196  loss_rpn_loc: 0.2095  time: 0.5133  data_time: 0.0174  lr: 0.001998  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:13:13 d2.utils.events]: \u001b[0m eta: 1:12:20  iter: 419  total_loss: 1.811  loss_cls: 0.5751  loss_box_reg: 0.5144  loss_mask: 0.2812  loss_rpn_cls: 0.1125  loss_rpn_loc: 0.228  time: 0.5102  data_time: 0.0135  lr: 0.0020979  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:13:22 d2.utils.events]: \u001b[0m eta: 1:12:07  iter: 439  total_loss: 1.79  loss_cls: 0.6223  loss_box_reg: 0.5444  loss_mask: 0.31  loss_rpn_cls: 0.1336  loss_rpn_loc: 0.2216  time: 0.5068  data_time: 0.0126  lr: 0.0021978  max_mem: 11392M\n",
      "\u001b[32m[12/27 12:13:31 d2.utils.events]: \u001b[0m eta: 1:11:58  iter: 459  total_loss: 1.784  loss_cls: 0.6333  loss_box_reg: 0.4672  loss_mask: 0.3042  loss_rpn_cls: 0.1048  loss_rpn_loc: 0.2005  time: 0.5052  data_time: 0.0144  lr: 0.0022977  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:13:41 d2.utils.events]: \u001b[0m eta: 1:11:53  iter: 479  total_loss: 1.732  loss_cls: 0.5771  loss_box_reg: 0.5196  loss_mask: 0.2998  loss_rpn_cls: 0.1027  loss_rpn_loc: 0.1944  time: 0.5046  data_time: 0.0154  lr: 0.0023976  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:13:51 d2.utils.events]: \u001b[0m eta: 1:11:50  iter: 499  total_loss: 1.788  loss_cls: 0.5982  loss_box_reg: 0.4882  loss_mask: 0.3352  loss_rpn_cls: 0.1218  loss_rpn_loc: 0.2146  time: 0.5034  data_time: 0.0168  lr: 0.0024975  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:13:59 d2.utils.events]: \u001b[0m eta: 1:11:39  iter: 519  total_loss: 1.839  loss_cls: 0.6101  loss_box_reg: 0.5457  loss_mask: 0.3375  loss_rpn_cls: 0.1434  loss_rpn_loc: 0.2327  time: 0.5008  data_time: 0.0134  lr: 0.0025974  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:14:09 d2.utils.events]: \u001b[0m eta: 1:11:33  iter: 539  total_loss: 1.611  loss_cls: 0.5668  loss_box_reg: 0.448  loss_mask: 0.2812  loss_rpn_cls: 0.1156  loss_rpn_loc: 0.2199  time: 0.5003  data_time: 0.0167  lr: 0.0026973  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:14:18 d2.utils.events]: \u001b[0m eta: 1:11:21  iter: 559  total_loss: 1.746  loss_cls: 0.6065  loss_box_reg: 0.4895  loss_mask: 0.3026  loss_rpn_cls: 0.09978  loss_rpn_loc: 0.2214  time: 0.4985  data_time: 0.0134  lr: 0.0027972  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:14:27 d2.utils.events]: \u001b[0m eta: 1:11:12  iter: 579  total_loss: 1.785  loss_cls: 0.5761  loss_box_reg: 0.5236  loss_mask: 0.3161  loss_rpn_cls: 0.1237  loss_rpn_loc: 0.2409  time: 0.4971  data_time: 0.0152  lr: 0.0028971  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:14:37 d2.utils.events]: \u001b[0m eta: 1:11:02  iter: 599  total_loss: 1.811  loss_cls: 0.6241  loss_box_reg: 0.4608  loss_mask: 0.2884  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.2317  time: 0.4963  data_time: 0.0201  lr: 0.002997  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:14:46 d2.utils.events]: \u001b[0m eta: 1:10:53  iter: 619  total_loss: 1.689  loss_cls: 0.6121  loss_box_reg: 0.4872  loss_mask: 0.3024  loss_rpn_cls: 0.1035  loss_rpn_loc: 0.2239  time: 0.4952  data_time: 0.0160  lr: 0.0030969  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:14:56 d2.utils.events]: \u001b[0m eta: 1:10:46  iter: 639  total_loss: 1.812  loss_cls: 0.5379  loss_box_reg: 0.5064  loss_mask: 0.3256  loss_rpn_cls: 0.1357  loss_rpn_loc: 0.226  time: 0.4949  data_time: 0.0181  lr: 0.0031968  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:15:05 d2.utils.events]: \u001b[0m eta: 1:10:39  iter: 659  total_loss: 1.74  loss_cls: 0.5076  loss_box_reg: 0.5219  loss_mask: 0.3085  loss_rpn_cls: 0.1201  loss_rpn_loc: 0.228  time: 0.4940  data_time: 0.0148  lr: 0.0032967  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:15:14 d2.utils.events]: \u001b[0m eta: 1:10:29  iter: 679  total_loss: 1.729  loss_cls: 0.5784  loss_box_reg: 0.5237  loss_mask: 0.279  loss_rpn_cls: 0.1197  loss_rpn_loc: 0.2284  time: 0.4926  data_time: 0.0158  lr: 0.0033966  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:15:23 d2.utils.events]: \u001b[0m eta: 1:10:18  iter: 699  total_loss: 1.726  loss_cls: 0.5272  loss_box_reg: 0.5174  loss_mask: 0.2639  loss_rpn_cls: 0.09476  loss_rpn_loc: 0.2178  time: 0.4916  data_time: 0.0158  lr: 0.0034965  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:15:32 d2.utils.events]: \u001b[0m eta: 1:10:09  iter: 719  total_loss: 1.703  loss_cls: 0.6053  loss_box_reg: 0.4802  loss_mask: 0.2879  loss_rpn_cls: 0.1134  loss_rpn_loc: 0.1958  time: 0.4908  data_time: 0.0153  lr: 0.0035964  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:15:42 d2.utils.events]: \u001b[0m eta: 1:10:04  iter: 739  total_loss: 1.841  loss_cls: 0.6135  loss_box_reg: 0.4907  loss_mask: 0.2868  loss_rpn_cls: 0.1121  loss_rpn_loc: 0.2018  time: 0.4899  data_time: 0.0148  lr: 0.0036963  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:15:51 d2.utils.events]: \u001b[0m eta: 1:09:55  iter: 759  total_loss: 1.662  loss_cls: 0.5483  loss_box_reg: 0.4871  loss_mask: 0.2879  loss_rpn_cls: 0.1206  loss_rpn_loc: 0.2199  time: 0.4896  data_time: 0.0161  lr: 0.0037962  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:16:00 d2.utils.events]: \u001b[0m eta: 1:09:46  iter: 779  total_loss: 1.861  loss_cls: 0.6713  loss_box_reg: 0.5557  loss_mask: 0.292  loss_rpn_cls: 0.1527  loss_rpn_loc: 0.2327  time: 0.4887  data_time: 0.0139  lr: 0.0038961  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:16:09 d2.utils.events]: \u001b[0m eta: 1:09:37  iter: 799  total_loss: 1.775  loss_cls: 0.5951  loss_box_reg: 0.5327  loss_mask: 0.2729  loss_rpn_cls: 0.1245  loss_rpn_loc: 0.2095  time: 0.4875  data_time: 0.0130  lr: 0.003996  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:16:18 d2.utils.events]: \u001b[0m eta: 1:09:25  iter: 819  total_loss: 1.653  loss_cls: 0.5665  loss_box_reg: 0.4746  loss_mask: 0.2854  loss_rpn_cls: 0.1337  loss_rpn_loc: 0.2048  time: 0.4866  data_time: 0.0144  lr: 0.0040959  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:16:27 d2.utils.events]: \u001b[0m eta: 1:09:14  iter: 839  total_loss: 1.653  loss_cls: 0.5847  loss_box_reg: 0.4386  loss_mask: 0.2676  loss_rpn_cls: 0.1111  loss_rpn_loc: 0.2133  time: 0.4859  data_time: 0.0142  lr: 0.0041958  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:16:37 d2.utils.events]: \u001b[0m eta: 1:09:05  iter: 859  total_loss: 1.771  loss_cls: 0.6086  loss_box_reg: 0.4966  loss_mask: 0.2989  loss_rpn_cls: 0.1362  loss_rpn_loc: 0.2134  time: 0.4856  data_time: 0.0149  lr: 0.0042957  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:16:46 d2.utils.events]: \u001b[0m eta: 1:08:56  iter: 879  total_loss: 1.664  loss_cls: 0.5277  loss_box_reg: 0.5039  loss_mask: 0.2768  loss_rpn_cls: 0.1231  loss_rpn_loc: 0.2178  time: 0.4850  data_time: 0.0152  lr: 0.0043956  max_mem: 11946M\n",
      "\u001b[32m[12/27 12:16:56 d2.utils.events]: \u001b[0m eta: 1:08:46  iter: 899  total_loss: 1.573  loss_cls: 0.5582  loss_box_reg: 0.4381  loss_mask: 0.2787  loss_rpn_cls: 0.09715  loss_rpn_loc: 0.2104  time: 0.4850  data_time: 0.0295  lr: 0.0044955  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:17:05 d2.utils.events]: \u001b[0m eta: 1:08:40  iter: 919  total_loss: 1.623  loss_cls: 0.4944  loss_box_reg: 0.4993  loss_mask: 0.2877  loss_rpn_cls: 0.112  loss_rpn_loc: 0.2197  time: 0.4847  data_time: 0.0153  lr: 0.0045954  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:17:14 d2.utils.events]: \u001b[0m eta: 1:08:31  iter: 939  total_loss: 1.646  loss_cls: 0.4909  loss_box_reg: 0.5389  loss_mask: 0.3063  loss_rpn_cls: 0.1059  loss_rpn_loc: 0.1998  time: 0.4840  data_time: 0.0134  lr: 0.0046953  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:17:23 d2.utils.events]: \u001b[0m eta: 1:08:18  iter: 959  total_loss: 1.85  loss_cls: 0.6361  loss_box_reg: 0.507  loss_mask: 0.3015  loss_rpn_cls: 0.1163  loss_rpn_loc: 0.2267  time: 0.4831  data_time: 0.0129  lr: 0.0047952  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:17:32 d2.utils.events]: \u001b[0m eta: 1:08:07  iter: 979  total_loss: 1.677  loss_cls: 0.5634  loss_box_reg: 0.4678  loss_mask: 0.2624  loss_rpn_cls: 0.1133  loss_rpn_loc: 0.2177  time: 0.4823  data_time: 0.0145  lr: 0.0048951  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:17:41 d2.utils.events]: \u001b[0m eta: 1:07:57  iter: 999  total_loss: 1.716  loss_cls: 0.6401  loss_box_reg: 0.4771  loss_mask: 0.272  loss_rpn_cls: 0.09359  loss_rpn_loc: 0.1993  time: 0.4818  data_time: 0.0148  lr: 0.004995  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:17:51 d2.utils.events]: \u001b[0m eta: 1:07:50  iter: 1019  total_loss: 1.719  loss_cls: 0.6292  loss_box_reg: 0.4709  loss_mask: 0.2882  loss_rpn_cls: 0.122  loss_rpn_loc: 0.227  time: 0.4818  data_time: 0.0160  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:18:00 d2.utils.events]: \u001b[0m eta: 1:07:39  iter: 1039  total_loss: 1.67  loss_cls: 0.6116  loss_box_reg: 0.4604  loss_mask: 0.2697  loss_rpn_cls: 0.1311  loss_rpn_loc: 0.2079  time: 0.4812  data_time: 0.0148  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:18:09 d2.utils.events]: \u001b[0m eta: 1:07:30  iter: 1059  total_loss: 1.642  loss_cls: 0.5682  loss_box_reg: 0.4621  loss_mask: 0.2531  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.2227  time: 0.4807  data_time: 0.0137  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:18:18 d2.utils.events]: \u001b[0m eta: 1:07:21  iter: 1079  total_loss: 1.702  loss_cls: 0.6029  loss_box_reg: 0.5139  loss_mask: 0.3074  loss_rpn_cls: 0.1296  loss_rpn_loc: 0.2221  time: 0.4799  data_time: 0.0131  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:18:27 d2.utils.events]: \u001b[0m eta: 1:07:15  iter: 1099  total_loss: 1.792  loss_cls: 0.6552  loss_box_reg: 0.4999  loss_mask: 0.313  loss_rpn_cls: 0.1126  loss_rpn_loc: 0.2099  time: 0.4797  data_time: 0.0139  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:18:36 d2.utils.events]: \u001b[0m eta: 1:07:06  iter: 1119  total_loss: 1.461  loss_cls: 0.4605  loss_box_reg: 0.4421  loss_mask: 0.2691  loss_rpn_cls: 0.1203  loss_rpn_loc: 0.1917  time: 0.4795  data_time: 0.0158  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:18:46 d2.utils.events]: \u001b[0m eta: 1:07:03  iter: 1139  total_loss: 1.532  loss_cls: 0.4304  loss_box_reg: 0.4133  loss_mask: 0.2686  loss_rpn_cls: 0.1128  loss_rpn_loc: 0.2049  time: 0.4793  data_time: 0.0190  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:18:55 d2.utils.events]: \u001b[0m eta: 1:06:51  iter: 1159  total_loss: 1.655  loss_cls: 0.5566  loss_box_reg: 0.4694  loss_mask: 0.2903  loss_rpn_cls: 0.1162  loss_rpn_loc: 0.209  time: 0.4786  data_time: 0.0143  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:19:04 d2.utils.events]: \u001b[0m eta: 1:06:44  iter: 1179  total_loss: 1.724  loss_cls: 0.5239  loss_box_reg: 0.4714  loss_mask: 0.2898  loss_rpn_cls: 0.1279  loss_rpn_loc: 0.2122  time: 0.4784  data_time: 0.0155  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:19:14 d2.utils.events]: \u001b[0m eta: 1:06:36  iter: 1199  total_loss: 1.693  loss_cls: 0.5309  loss_box_reg: 0.4669  loss_mask: 0.2853  loss_rpn_cls: 0.1282  loss_rpn_loc: 0.2085  time: 0.4786  data_time: 0.0221  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:19:23 d2.utils.events]: \u001b[0m eta: 1:06:26  iter: 1219  total_loss: 1.72  loss_cls: 0.6189  loss_box_reg: 0.4734  loss_mask: 0.2832  loss_rpn_cls: 0.09328  loss_rpn_loc: 0.2083  time: 0.4780  data_time: 0.0131  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:19:32 d2.utils.events]: \u001b[0m eta: 1:06:17  iter: 1239  total_loss: 1.789  loss_cls: 0.5619  loss_box_reg: 0.4881  loss_mask: 0.2882  loss_rpn_cls: 0.1092  loss_rpn_loc: 0.2162  time: 0.4777  data_time: 0.0139  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:19:41 d2.utils.events]: \u001b[0m eta: 1:06:08  iter: 1259  total_loss: 1.621  loss_cls: 0.5815  loss_box_reg: 0.4443  loss_mask: 0.273  loss_rpn_cls: 0.1168  loss_rpn_loc: 0.2047  time: 0.4774  data_time: 0.0160  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:19:51 d2.utils.events]: \u001b[0m eta: 1:06:00  iter: 1279  total_loss: 1.585  loss_cls: 0.5109  loss_box_reg: 0.4781  loss_mask: 0.2955  loss_rpn_cls: 0.1492  loss_rpn_loc: 0.2073  time: 0.4773  data_time: 0.0154  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:20:00 d2.utils.events]: \u001b[0m eta: 1:05:50  iter: 1299  total_loss: 1.59  loss_cls: 0.4847  loss_box_reg: 0.5228  loss_mask: 0.2887  loss_rpn_cls: 0.1205  loss_rpn_loc: 0.2088  time: 0.4770  data_time: 0.0134  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:20:09 d2.utils.events]: \u001b[0m eta: 1:05:45  iter: 1319  total_loss: 1.743  loss_cls: 0.531  loss_box_reg: 0.4708  loss_mask: 0.3146  loss_rpn_cls: 0.1445  loss_rpn_loc: 0.2264  time: 0.4769  data_time: 0.0159  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:20:19 d2.utils.events]: \u001b[0m eta: 1:05:36  iter: 1339  total_loss: 1.581  loss_cls: 0.4853  loss_box_reg: 0.4245  loss_mask: 0.2843  loss_rpn_cls: 0.1274  loss_rpn_loc: 0.2165  time: 0.4768  data_time: 0.0162  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:20:28 d2.utils.events]: \u001b[0m eta: 1:05:26  iter: 1359  total_loss: 1.794  loss_cls: 0.5313  loss_box_reg: 0.4932  loss_mask: 0.3318  loss_rpn_cls: 0.1501  loss_rpn_loc: 0.2256  time: 0.4767  data_time: 0.0152  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:20:36 d2.utils.events]: \u001b[0m eta: 1:05:14  iter: 1379  total_loss: 1.739  loss_cls: 0.5337  loss_box_reg: 0.5062  loss_mask: 0.2788  loss_rpn_cls: 0.1365  loss_rpn_loc: 0.2131  time: 0.4759  data_time: 0.0130  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:20:46 d2.utils.events]: \u001b[0m eta: 1:05:04  iter: 1399  total_loss: 1.575  loss_cls: 0.4535  loss_box_reg: 0.434  loss_mask: 0.2755  loss_rpn_cls: 0.1443  loss_rpn_loc: 0.2174  time: 0.4759  data_time: 0.0163  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:20:55 d2.utils.events]: \u001b[0m eta: 1:04:55  iter: 1419  total_loss: 1.535  loss_cls: 0.4768  loss_box_reg: 0.4893  loss_mask: 0.2771  loss_rpn_cls: 0.1109  loss_rpn_loc: 0.2009  time: 0.4757  data_time: 0.0137  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:21:04 d2.utils.events]: \u001b[0m eta: 1:04:47  iter: 1439  total_loss: 1.627  loss_cls: 0.5115  loss_box_reg: 0.4365  loss_mask: 0.2659  loss_rpn_cls: 0.1087  loss_rpn_loc: 0.1902  time: 0.4753  data_time: 0.0135  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:21:13 d2.utils.events]: \u001b[0m eta: 1:04:39  iter: 1459  total_loss: 1.607  loss_cls: 0.4922  loss_box_reg: 0.4989  loss_mask: 0.2837  loss_rpn_cls: 0.1008  loss_rpn_loc: 0.1965  time: 0.4749  data_time: 0.0132  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:21:22 d2.utils.events]: \u001b[0m eta: 1:04:25  iter: 1479  total_loss: 1.493  loss_cls: 0.4622  loss_box_reg: 0.4746  loss_mask: 0.2877  loss_rpn_cls: 0.09503  loss_rpn_loc: 0.203  time: 0.4745  data_time: 0.0133  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:21:31 d2.utils.events]: \u001b[0m eta: 1:04:09  iter: 1499  total_loss: 1.537  loss_cls: 0.4672  loss_box_reg: 0.5087  loss_mask: 0.2812  loss_rpn_cls: 0.09728  loss_rpn_loc: 0.2127  time: 0.4740  data_time: 0.0125  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:21:40 d2.utils.events]: \u001b[0m eta: 1:04:00  iter: 1519  total_loss: 1.628  loss_cls: 0.5474  loss_box_reg: 0.4734  loss_mask: 0.2834  loss_rpn_cls: 0.0917  loss_rpn_loc: 0.1894  time: 0.4737  data_time: 0.0137  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:21:44 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7faf6314e950> to CPU due to CUDA OOM\n",
      "\u001b[32m[12/27 12:22:11 d2.utils.events]: \u001b[0m eta: 1:03:48  iter: 1539  total_loss: 1.585  loss_cls: 0.4926  loss_box_reg: 0.4512  loss_mask: 0.2815  loss_rpn_cls: 0.1344  loss_rpn_loc: 0.2226  time: 0.4881  data_time: 0.0247  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:22:20 d2.utils.events]: \u001b[0m eta: 1:03:38  iter: 1559  total_loss: 1.673  loss_cls: 0.5571  loss_box_reg: 0.485  loss_mask: 0.2855  loss_rpn_cls: 0.1093  loss_rpn_loc: 0.2174  time: 0.4875  data_time: 0.0141  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:22:30 d2.utils.events]: \u001b[0m eta: 1:03:33  iter: 1579  total_loss: 1.482  loss_cls: 0.4608  loss_box_reg: 0.4636  loss_mask: 0.2736  loss_rpn_cls: 0.1348  loss_rpn_loc: 0.1921  time: 0.4874  data_time: 0.0146  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:22:39 d2.utils.events]: \u001b[0m eta: 1:03:22  iter: 1599  total_loss: 1.612  loss_cls: 0.4781  loss_box_reg: 0.4578  loss_mask: 0.2743  loss_rpn_cls: 0.141  loss_rpn_loc: 0.2057  time: 0.4869  data_time: 0.0128  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:22:48 d2.utils.events]: \u001b[0m eta: 1:03:14  iter: 1619  total_loss: 1.565  loss_cls: 0.5033  loss_box_reg: 0.5  loss_mask: 0.272  loss_rpn_cls: 0.09423  loss_rpn_loc: 0.1911  time: 0.4865  data_time: 0.0132  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:22:57 d2.utils.events]: \u001b[0m eta: 1:03:03  iter: 1639  total_loss: 1.522  loss_cls: 0.4867  loss_box_reg: 0.4536  loss_mask: 0.2662  loss_rpn_cls: 0.1088  loss_rpn_loc: 0.179  time: 0.4861  data_time: 0.0133  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:23:06 d2.utils.events]: \u001b[0m eta: 1:02:50  iter: 1659  total_loss: 1.507  loss_cls: 0.5055  loss_box_reg: 0.4075  loss_mask: 0.2547  loss_rpn_cls: 0.1153  loss_rpn_loc: 0.1934  time: 0.4856  data_time: 0.0146  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:23:16 d2.utils.events]: \u001b[0m eta: 1:02:45  iter: 1679  total_loss: 1.531  loss_cls: 0.4776  loss_box_reg: 0.4637  loss_mask: 0.2815  loss_rpn_cls: 0.1144  loss_rpn_loc: 0.2178  time: 0.4858  data_time: 0.0153  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:23:25 d2.utils.events]: \u001b[0m eta: 1:02:40  iter: 1699  total_loss: 1.596  loss_cls: 0.5026  loss_box_reg: 0.474  loss_mask: 0.2704  loss_rpn_cls: 0.1332  loss_rpn_loc: 0.2077  time: 0.4855  data_time: 0.0156  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:23:35 d2.utils.events]: \u001b[0m eta: 1:02:33  iter: 1719  total_loss: 1.499  loss_cls: 0.5077  loss_box_reg: 0.4498  loss_mask: 0.2768  loss_rpn_cls: 0.111  loss_rpn_loc: 0.1821  time: 0.4852  data_time: 0.0146  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:23:44 d2.utils.events]: \u001b[0m eta: 1:02:16  iter: 1739  total_loss: 1.535  loss_cls: 0.4675  loss_box_reg: 0.4973  loss_mask: 0.2813  loss_rpn_cls: 0.07876  loss_rpn_loc: 0.1936  time: 0.4849  data_time: 0.0139  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:23:53 d2.utils.events]: \u001b[0m eta: 1:02:02  iter: 1759  total_loss: 1.613  loss_cls: 0.4996  loss_box_reg: 0.5382  loss_mask: 0.2919  loss_rpn_cls: 0.1211  loss_rpn_loc: 0.2006  time: 0.4846  data_time: 0.0147  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:24:02 d2.utils.events]: \u001b[0m eta: 1:01:54  iter: 1779  total_loss: 1.557  loss_cls: 0.4707  loss_box_reg: 0.4723  loss_mask: 0.285  loss_rpn_cls: 0.1224  loss_rpn_loc: 0.2122  time: 0.4845  data_time: 0.0153  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:24:12 d2.utils.events]: \u001b[0m eta: 1:01:53  iter: 1799  total_loss: 1.348  loss_cls: 0.3745  loss_box_reg: 0.3918  loss_mask: 0.271  loss_rpn_cls: 0.1177  loss_rpn_loc: 0.2021  time: 0.4846  data_time: 0.0166  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:24:21 d2.utils.events]: \u001b[0m eta: 1:01:47  iter: 1819  total_loss: 1.544  loss_cls: 0.4619  loss_box_reg: 0.4862  loss_mask: 0.2707  loss_rpn_cls: 0.1011  loss_rpn_loc: 0.2053  time: 0.4842  data_time: 0.0143  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:24:31 d2.utils.events]: \u001b[0m eta: 1:01:38  iter: 1839  total_loss: 1.409  loss_cls: 0.4277  loss_box_reg: 0.4343  loss_mask: 0.2699  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.1839  time: 0.4840  data_time: 0.0144  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:24:39 d2.utils.events]: \u001b[0m eta: 1:01:24  iter: 1859  total_loss: 1.538  loss_cls: 0.4982  loss_box_reg: 0.4926  loss_mask: 0.2872  loss_rpn_cls: 0.09624  loss_rpn_loc: 0.1941  time: 0.4835  data_time: 0.0130  lr: 0.005  max_mem: 12705M\n",
      "\u001b[32m[12/27 12:24:50 d2.utils.events]: \u001b[0m eta: 1:01:17  iter: 1879  total_loss: 1.647  loss_cls: 0.5177  loss_box_reg: 0.4773  loss_mask: 0.2969  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.1934  time: 0.4838  data_time: 0.0282  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:24:59 d2.utils.events]: \u001b[0m eta: 1:01:06  iter: 1899  total_loss: 1.491  loss_cls: 0.4479  loss_box_reg: 0.4726  loss_mask: 0.2725  loss_rpn_cls: 0.13  loss_rpn_loc: 0.2181  time: 0.4835  data_time: 0.0153  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:25:08 d2.utils.events]: \u001b[0m eta: 1:00:51  iter: 1919  total_loss: 1.579  loss_cls: 0.4778  loss_box_reg: 0.4561  loss_mask: 0.2923  loss_rpn_cls: 0.114  loss_rpn_loc: 0.2174  time: 0.4832  data_time: 0.0149  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:25:17 d2.utils.events]: \u001b[0m eta: 1:00:40  iter: 1939  total_loss: 1.632  loss_cls: 0.5256  loss_box_reg: 0.4951  loss_mask: 0.2755  loss_rpn_cls: 0.1149  loss_rpn_loc: 0.2118  time: 0.4828  data_time: 0.0141  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:25:27 d2.utils.events]: \u001b[0m eta: 1:00:35  iter: 1959  total_loss: 1.466  loss_cls: 0.4483  loss_box_reg: 0.4432  loss_mask: 0.2751  loss_rpn_cls: 0.111  loss_rpn_loc: 0.1884  time: 0.4831  data_time: 0.0360  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:25:36 d2.utils.events]: \u001b[0m eta: 1:00:30  iter: 1979  total_loss: 1.474  loss_cls: 0.4367  loss_box_reg: 0.4653  loss_mask: 0.2718  loss_rpn_cls: 0.1032  loss_rpn_loc: 0.1981  time: 0.4829  data_time: 0.0145  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:25:45 d2.utils.events]: \u001b[0m eta: 1:00:25  iter: 1999  total_loss: 1.414  loss_cls: 0.4624  loss_box_reg: 0.4561  loss_mask: 0.2602  loss_rpn_cls: 0.08417  loss_rpn_loc: 0.195  time: 0.4826  data_time: 0.0143  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:25:55 d2.utils.events]: \u001b[0m eta: 1:00:16  iter: 2019  total_loss: 1.525  loss_cls: 0.4544  loss_box_reg: 0.4365  loss_mask: 0.2757  loss_rpn_cls: 0.104  loss_rpn_loc: 0.2191  time: 0.4825  data_time: 0.0137  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:26:04 d2.utils.events]: \u001b[0m eta: 1:00:08  iter: 2039  total_loss: 1.523  loss_cls: 0.4495  loss_box_reg: 0.4906  loss_mask: 0.3011  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.195  time: 0.4822  data_time: 0.0148  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:26:14 d2.utils.events]: \u001b[0m eta: 1:00:00  iter: 2059  total_loss: 1.524  loss_cls: 0.416  loss_box_reg: 0.4705  loss_mask: 0.2812  loss_rpn_cls: 0.1141  loss_rpn_loc: 0.1967  time: 0.4823  data_time: 0.0305  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:26:21 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7faf6314e950> to CPU due to CUDA OOM\n",
      "\u001b[32m[12/27 12:26:41 d2.utils.events]: \u001b[0m eta: 0:59:53  iter: 2079  total_loss: 1.505  loss_cls: 0.4073  loss_box_reg: 0.481  loss_mask: 0.3057  loss_rpn_cls: 0.1249  loss_rpn_loc: 0.1849  time: 0.4906  data_time: 0.0187  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:26:50 d2.utils.events]: \u001b[0m eta: 0:59:42  iter: 2099  total_loss: 1.405  loss_cls: 0.4005  loss_box_reg: 0.4557  loss_mask: 0.2595  loss_rpn_cls: 0.07733  loss_rpn_loc: 0.1912  time: 0.4903  data_time: 0.0134  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:26:59 d2.utils.events]: \u001b[0m eta: 0:59:31  iter: 2119  total_loss: 1.713  loss_cls: 0.5478  loss_box_reg: 0.4279  loss_mask: 0.2774  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.2137  time: 0.4902  data_time: 0.0154  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:27:09 d2.utils.events]: \u001b[0m eta: 0:59:22  iter: 2139  total_loss: 1.549  loss_cls: 0.4703  loss_box_reg: 0.4263  loss_mask: 0.2806  loss_rpn_cls: 0.102  loss_rpn_loc: 0.2224  time: 0.4902  data_time: 0.0173  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:27:18 d2.utils.events]: \u001b[0m eta: 0:59:14  iter: 2159  total_loss: 1.497  loss_cls: 0.4491  loss_box_reg: 0.4869  loss_mask: 0.2765  loss_rpn_cls: 0.101  loss_rpn_loc: 0.2085  time: 0.4898  data_time: 0.0143  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:27:27 d2.utils.events]: \u001b[0m eta: 0:59:01  iter: 2179  total_loss: 1.571  loss_cls: 0.4667  loss_box_reg: 0.491  loss_mask: 0.2848  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.2047  time: 0.4893  data_time: 0.0131  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:27:36 d2.utils.events]: \u001b[0m eta: 0:58:44  iter: 2199  total_loss: 1.491  loss_cls: 0.4543  loss_box_reg: 0.4552  loss_mask: 0.2783  loss_rpn_cls: 0.09543  loss_rpn_loc: 0.207  time: 0.4888  data_time: 0.0128  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:27:45 d2.utils.events]: \u001b[0m eta: 0:58:36  iter: 2219  total_loss: 1.641  loss_cls: 0.5997  loss_box_reg: 0.483  loss_mask: 0.2771  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.2037  time: 0.4885  data_time: 0.0142  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:27:54 d2.utils.events]: \u001b[0m eta: 0:58:26  iter: 2239  total_loss: 1.549  loss_cls: 0.5351  loss_box_reg: 0.4561  loss_mask: 0.2914  loss_rpn_cls: 0.1116  loss_rpn_loc: 0.1888  time: 0.4883  data_time: 0.0152  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:28:03 d2.utils.events]: \u001b[0m eta: 0:58:18  iter: 2259  total_loss: 1.516  loss_cls: 0.4889  loss_box_reg: 0.4656  loss_mask: 0.2717  loss_rpn_cls: 0.08716  loss_rpn_loc: 0.1861  time: 0.4880  data_time: 0.0136  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:28:12 d2.utils.events]: \u001b[0m eta: 0:58:05  iter: 2279  total_loss: 1.611  loss_cls: 0.5407  loss_box_reg: 0.4768  loss_mask: 0.2698  loss_rpn_cls: 0.09415  loss_rpn_loc: 0.2147  time: 0.4875  data_time: 0.0139  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:28:21 d2.utils.events]: \u001b[0m eta: 0:57:58  iter: 2299  total_loss: 1.543  loss_cls: 0.4997  loss_box_reg: 0.4567  loss_mask: 0.2929  loss_rpn_cls: 0.09495  loss_rpn_loc: 0.2054  time: 0.4872  data_time: 0.0132  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:28:30 d2.utils.events]: \u001b[0m eta: 0:57:48  iter: 2319  total_loss: 1.631  loss_cls: 0.4644  loss_box_reg: 0.4989  loss_mask: 0.295  loss_rpn_cls: 0.1193  loss_rpn_loc: 0.2206  time: 0.4868  data_time: 0.0137  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:28:40 d2.utils.events]: \u001b[0m eta: 0:57:40  iter: 2339  total_loss: 1.487  loss_cls: 0.473  loss_box_reg: 0.4507  loss_mask: 0.2681  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.2006  time: 0.4868  data_time: 0.0157  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:28:49 d2.utils.events]: \u001b[0m eta: 0:57:32  iter: 2359  total_loss: 1.316  loss_cls: 0.387  loss_box_reg: 0.4162  loss_mask: 0.2506  loss_rpn_cls: 0.09457  loss_rpn_loc: 0.1767  time: 0.4865  data_time: 0.0152  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:28:58 d2.utils.events]: \u001b[0m eta: 0:57:28  iter: 2379  total_loss: 1.467  loss_cls: 0.4438  loss_box_reg: 0.4384  loss_mask: 0.2768  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.2017  time: 0.4862  data_time: 0.0141  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:29:07 d2.utils.events]: \u001b[0m eta: 0:57:18  iter: 2399  total_loss: 1.602  loss_cls: 0.4845  loss_box_reg: 0.4695  loss_mask: 0.2948  loss_rpn_cls: 0.1323  loss_rpn_loc: 0.1964  time: 0.4860  data_time: 0.0143  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:29:18 d2.data.datasets.coco]: \u001b[0mLoading /content/livecell/livecell_annotations_val.json takes 6.23 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/27 12:29:18 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/27 12:29:18 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from /content/livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/27 12:29:20 d2.data.build]: \u001b[0mDistribution of instances among all 8 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|    a172    | 15688        |   bt474    | 14526        |    bv2     | 45033        |\n",
      "|    huh7    | 3688         |    mcf7    | 39252        |   shsy5y   | 28199        |\n",
      "|   skbr3    | 29693        |   skov3    | 5531         |            |              |\n",
      "|   total    | 181610       |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[12/27 12:29:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 12:29:20 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 12:29:20 d2.data.common]: \u001b[0mSerialized dataset takes 84.21 MiB\n",
      "\u001b[32m[12/27 12:29:24 d2.data.datasets.coco]: \u001b[0mLoading /content/livecell/livecell_annotations_val.json takes 3.70 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/27 12:29:24 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/27 12:29:24 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from /content/livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/27 12:29:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/27 12:29:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0015 s/iter. Inference: 0.0972 s/iter. Eval: 0.2759 s/iter. Total: 0.3745 s/iter. ETA=0:03:29\n",
      "\u001b[32m[12/27 12:29:36 d2.evaluation.evaluator]: \u001b[0mInference done 27/570. Dataloading: 0.0018 s/iter. Inference: 0.0973 s/iter. Eval: 0.2364 s/iter. Total: 0.3357 s/iter. ETA=0:03:02\n",
      "\u001b[32m[12/27 12:29:41 d2.evaluation.evaluator]: \u001b[0mInference done 42/570. Dataloading: 0.0019 s/iter. Inference: 0.0973 s/iter. Eval: 0.2406 s/iter. Total: 0.3400 s/iter. ETA=0:02:59\n",
      "\u001b[32m[12/27 12:29:46 d2.evaluation.evaluator]: \u001b[0mInference done 57/570. Dataloading: 0.0019 s/iter. Inference: 0.0973 s/iter. Eval: 0.2413 s/iter. Total: 0.3408 s/iter. ETA=0:02:54\n",
      "\u001b[32m[12/27 12:29:51 d2.evaluation.evaluator]: \u001b[0mInference done 73/570. Dataloading: 0.0019 s/iter. Inference: 0.0972 s/iter. Eval: 0.2384 s/iter. Total: 0.3377 s/iter. ETA=0:02:47\n",
      "\u001b[32m[12/27 12:29:56 d2.evaluation.evaluator]: \u001b[0mInference done 87/570. Dataloading: 0.0019 s/iter. Inference: 0.0973 s/iter. Eval: 0.2442 s/iter. Total: 0.3436 s/iter. ETA=0:02:45\n",
      "\u001b[32m[12/27 12:30:02 d2.evaluation.evaluator]: \u001b[0mInference done 100/570. Dataloading: 0.0019 s/iter. Inference: 0.0971 s/iter. Eval: 0.2531 s/iter. Total: 0.3523 s/iter. ETA=0:02:45\n",
      "\u001b[32m[12/27 12:30:07 d2.evaluation.evaluator]: \u001b[0mInference done 117/570. Dataloading: 0.0019 s/iter. Inference: 0.0967 s/iter. Eval: 0.2474 s/iter. Total: 0.3462 s/iter. ETA=0:02:36\n",
      "\u001b[32m[12/27 12:30:12 d2.evaluation.evaluator]: \u001b[0mInference done 131/570. Dataloading: 0.0019 s/iter. Inference: 0.0966 s/iter. Eval: 0.2501 s/iter. Total: 0.3488 s/iter. ETA=0:02:33\n",
      "\u001b[32m[12/27 12:30:18 d2.evaluation.evaluator]: \u001b[0mInference done 146/570. Dataloading: 0.0019 s/iter. Inference: 0.0964 s/iter. Eval: 0.2521 s/iter. Total: 0.3506 s/iter. ETA=0:02:28\n",
      "\u001b[32m[12/27 12:30:23 d2.evaluation.evaluator]: \u001b[0mInference done 156/570. Dataloading: 0.0019 s/iter. Inference: 0.0966 s/iter. Eval: 0.2643 s/iter. Total: 0.3630 s/iter. ETA=0:02:30\n",
      "\u001b[32m[12/27 12:30:28 d2.evaluation.evaluator]: \u001b[0mInference done 164/570. Dataloading: 0.0019 s/iter. Inference: 0.0968 s/iter. Eval: 0.2775 s/iter. Total: 0.3765 s/iter. ETA=0:02:32\n",
      "\u001b[32m[12/27 12:30:33 d2.evaluation.evaluator]: \u001b[0mInference done 171/570. Dataloading: 0.0019 s/iter. Inference: 0.0970 s/iter. Eval: 0.2932 s/iter. Total: 0.3923 s/iter. ETA=0:02:36\n",
      "\u001b[32m[12/27 12:30:39 d2.evaluation.evaluator]: \u001b[0mInference done 177/570. Dataloading: 0.0019 s/iter. Inference: 0.0971 s/iter. Eval: 0.3127 s/iter. Total: 0.4119 s/iter. ETA=0:02:41\n",
      "\u001b[32m[12/27 12:30:44 d2.evaluation.evaluator]: \u001b[0mInference done 188/570. Dataloading: 0.0019 s/iter. Inference: 0.0973 s/iter. Eval: 0.3166 s/iter. Total: 0.4161 s/iter. ETA=0:02:38\n",
      "\u001b[32m[12/27 12:30:49 d2.evaluation.evaluator]: \u001b[0mInference done 198/570. Dataloading: 0.0019 s/iter. Inference: 0.0974 s/iter. Eval: 0.3210 s/iter. Total: 0.4205 s/iter. ETA=0:02:36\n",
      "\u001b[32m[12/27 12:30:56 d2.evaluation.evaluator]: \u001b[0mInference done 206/570. Dataloading: 0.0019 s/iter. Inference: 0.0976 s/iter. Eval: 0.3344 s/iter. Total: 0.4341 s/iter. ETA=0:02:38\n",
      "\u001b[32m[12/27 12:31:01 d2.evaluation.evaluator]: \u001b[0mInference done 214/570. Dataloading: 0.0019 s/iter. Inference: 0.0976 s/iter. Eval: 0.3420 s/iter. Total: 0.4417 s/iter. ETA=0:02:37\n",
      "\u001b[32m[12/27 12:31:06 d2.evaluation.evaluator]: \u001b[0mInference done 223/570. Dataloading: 0.0019 s/iter. Inference: 0.0977 s/iter. Eval: 0.3486 s/iter. Total: 0.4485 s/iter. ETA=0:02:35\n",
      "\u001b[32m[12/27 12:31:12 d2.evaluation.evaluator]: \u001b[0mInference done 229/570. Dataloading: 0.0020 s/iter. Inference: 0.0978 s/iter. Eval: 0.3628 s/iter. Total: 0.4627 s/iter. ETA=0:02:37\n",
      "\u001b[32m[12/27 12:31:17 d2.evaluation.evaluator]: \u001b[0mInference done 235/570. Dataloading: 0.0020 s/iter. Inference: 0.0979 s/iter. Eval: 0.3735 s/iter. Total: 0.4735 s/iter. ETA=0:02:38\n",
      "\u001b[32m[12/27 12:31:23 d2.evaluation.evaluator]: \u001b[0mInference done 241/570. Dataloading: 0.0020 s/iter. Inference: 0.0979 s/iter. Eval: 0.3855 s/iter. Total: 0.4856 s/iter. ETA=0:02:39\n",
      "\u001b[32m[12/27 12:31:29 d2.evaluation.evaluator]: \u001b[0mInference done 249/570. Dataloading: 0.0020 s/iter. Inference: 0.0980 s/iter. Eval: 0.3962 s/iter. Total: 0.4964 s/iter. ETA=0:02:39\n",
      "\u001b[32m[12/27 12:31:35 d2.evaluation.evaluator]: \u001b[0mInference done 257/570. Dataloading: 0.0020 s/iter. Inference: 0.0981 s/iter. Eval: 0.4010 s/iter. Total: 0.5013 s/iter. ETA=0:02:36\n",
      "\u001b[32m[12/27 12:31:41 d2.evaluation.evaluator]: \u001b[0mInference done 266/570. Dataloading: 0.0020 s/iter. Inference: 0.0981 s/iter. Eval: 0.4073 s/iter. Total: 0.5076 s/iter. ETA=0:02:34\n",
      "\u001b[32m[12/27 12:31:46 d2.evaluation.evaluator]: \u001b[0mInference done 275/570. Dataloading: 0.0020 s/iter. Inference: 0.0982 s/iter. Eval: 0.4090 s/iter. Total: 0.5094 s/iter. ETA=0:02:30\n",
      "\u001b[32m[12/27 12:31:51 d2.evaluation.evaluator]: \u001b[0mInference done 285/570. Dataloading: 0.0020 s/iter. Inference: 0.0982 s/iter. Eval: 0.4088 s/iter. Total: 0.5092 s/iter. ETA=0:02:25\n",
      "\u001b[32m[12/27 12:31:56 d2.evaluation.evaluator]: \u001b[0mInference done 291/570. Dataloading: 0.0020 s/iter. Inference: 0.0982 s/iter. Eval: 0.4159 s/iter. Total: 0.5164 s/iter. ETA=0:02:24\n",
      "\u001b[32m[12/27 12:32:01 d2.evaluation.evaluator]: \u001b[0mInference done 298/570. Dataloading: 0.0020 s/iter. Inference: 0.0983 s/iter. Eval: 0.4208 s/iter. Total: 0.5213 s/iter. ETA=0:02:21\n",
      "\u001b[32m[12/27 12:32:06 d2.evaluation.evaluator]: \u001b[0mInference done 321/570. Dataloading: 0.0020 s/iter. Inference: 0.0979 s/iter. Eval: 0.3994 s/iter. Total: 0.4995 s/iter. ETA=0:02:04\n",
      "\u001b[32m[12/27 12:32:11 d2.evaluation.evaluator]: \u001b[0mInference done 349/570. Dataloading: 0.0020 s/iter. Inference: 0.0975 s/iter. Eval: 0.3742 s/iter. Total: 0.4739 s/iter. ETA=0:01:44\n",
      "\u001b[32m[12/27 12:32:17 d2.evaluation.evaluator]: \u001b[0mInference done 367/570. Dataloading: 0.0020 s/iter. Inference: 0.0974 s/iter. Eval: 0.3656 s/iter. Total: 0.4651 s/iter. ETA=0:01:34\n",
      "\u001b[32m[12/27 12:32:22 d2.evaluation.evaluator]: \u001b[0mInference done 377/570. Dataloading: 0.0020 s/iter. Inference: 0.0975 s/iter. Eval: 0.3669 s/iter. Total: 0.4666 s/iter. ETA=0:01:30\n",
      "\u001b[32m[12/27 12:32:27 d2.evaluation.evaluator]: \u001b[0mInference done 388/570. Dataloading: 0.0020 s/iter. Inference: 0.0976 s/iter. Eval: 0.3679 s/iter. Total: 0.4678 s/iter. ETA=0:01:25\n",
      "\u001b[32m[12/27 12:32:33 d2.evaluation.evaluator]: \u001b[0mInference done 400/570. Dataloading: 0.0020 s/iter. Inference: 0.0977 s/iter. Eval: 0.3668 s/iter. Total: 0.4667 s/iter. ETA=0:01:19\n",
      "\u001b[32m[12/27 12:32:38 d2.evaluation.evaluator]: \u001b[0mInference done 410/570. Dataloading: 0.0020 s/iter. Inference: 0.0978 s/iter. Eval: 0.3679 s/iter. Total: 0.4679 s/iter. ETA=0:01:14\n",
      "\u001b[32m[12/27 12:32:43 d2.evaluation.evaluator]: \u001b[0mInference done 419/570. Dataloading: 0.0020 s/iter. Inference: 0.0979 s/iter. Eval: 0.3700 s/iter. Total: 0.4700 s/iter. ETA=0:01:10\n",
      "\u001b[32m[12/27 12:32:48 d2.evaluation.evaluator]: \u001b[0mInference done 429/570. Dataloading: 0.0020 s/iter. Inference: 0.0980 s/iter. Eval: 0.3713 s/iter. Total: 0.4715 s/iter. ETA=0:01:06\n",
      "\u001b[32m[12/27 12:32:54 d2.evaluation.evaluator]: \u001b[0mInference done 440/570. Dataloading: 0.0020 s/iter. Inference: 0.0981 s/iter. Eval: 0.3719 s/iter. Total: 0.4722 s/iter. ETA=0:01:01\n",
      "\u001b[32m[12/27 12:32:59 d2.evaluation.evaluator]: \u001b[0mInference done 454/570. Dataloading: 0.0020 s/iter. Inference: 0.0981 s/iter. Eval: 0.3690 s/iter. Total: 0.4692 s/iter. ETA=0:00:54\n",
      "\u001b[32m[12/27 12:33:04 d2.evaluation.evaluator]: \u001b[0mInference done 474/570. Dataloading: 0.0020 s/iter. Inference: 0.0980 s/iter. Eval: 0.3598 s/iter. Total: 0.4600 s/iter. ETA=0:00:44\n",
      "\u001b[32m[12/27 12:33:10 d2.evaluation.evaluator]: \u001b[0mInference done 493/570. Dataloading: 0.0020 s/iter. Inference: 0.0979 s/iter. Eval: 0.3538 s/iter. Total: 0.4539 s/iter. ETA=0:00:34\n",
      "\u001b[32m[12/27 12:33:15 d2.evaluation.evaluator]: \u001b[0mInference done 503/570. Dataloading: 0.0020 s/iter. Inference: 0.0977 s/iter. Eval: 0.3552 s/iter. Total: 0.4551 s/iter. ETA=0:00:30\n",
      "\u001b[32m[12/27 12:33:20 d2.evaluation.evaluator]: \u001b[0mInference done 515/570. Dataloading: 0.0020 s/iter. Inference: 0.0975 s/iter. Eval: 0.3549 s/iter. Total: 0.4546 s/iter. ETA=0:00:25\n",
      "\u001b[32m[12/27 12:33:26 d2.evaluation.evaluator]: \u001b[0mInference done 530/570. Dataloading: 0.0020 s/iter. Inference: 0.0974 s/iter. Eval: 0.3524 s/iter. Total: 0.4519 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/27 12:33:31 d2.evaluation.evaluator]: \u001b[0mInference done 541/570. Dataloading: 0.0020 s/iter. Inference: 0.0972 s/iter. Eval: 0.3528 s/iter. Total: 0.4522 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/27 12:33:36 d2.evaluation.evaluator]: \u001b[0mInference done 551/570. Dataloading: 0.0020 s/iter. Inference: 0.0971 s/iter. Eval: 0.3548 s/iter. Total: 0.4541 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/27 12:33:41 d2.evaluation.evaluator]: \u001b[0mInference done 563/570. Dataloading: 0.0020 s/iter. Inference: 0.0970 s/iter. Eval: 0.3542 s/iter. Total: 0.4533 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/27 12:33:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:16.370818 (0.453754 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 12:33:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:54 (0.096873 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 12:33:45 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/27 12:33:45 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.21980253626174387\n",
      "\u001b[32m[12/27 12:33:50 d2.utils.events]: \u001b[0m eta: 0:57:06  iter: 2419  total_loss: 1.622  loss_cls: 0.4679  loss_box_reg: 0.4556  loss_mask: 0.2886  loss_rpn_cls: 0.1084  loss_rpn_loc: 0.2082  time: 0.4857  data_time: 0.0150  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:33:59 d2.utils.events]: \u001b[0m eta: 0:57:01  iter: 2439  total_loss: 1.517  loss_cls: 0.4329  loss_box_reg: 0.4405  loss_mask: 0.2813  loss_rpn_cls: 0.1089  loss_rpn_loc: 0.2105  time: 0.4855  data_time: 0.0147  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:34:08 d2.utils.events]: \u001b[0m eta: 0:56:52  iter: 2459  total_loss: 1.433  loss_cls: 0.3998  loss_box_reg: 0.4733  loss_mask: 0.2758  loss_rpn_cls: 0.1022  loss_rpn_loc: 0.1943  time: 0.4852  data_time: 0.0138  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:34:18 d2.utils.events]: \u001b[0m eta: 0:56:48  iter: 2479  total_loss: 1.489  loss_cls: 0.4395  loss_box_reg: 0.4601  loss_mask: 0.2892  loss_rpn_cls: 0.1134  loss_rpn_loc: 0.1971  time: 0.4851  data_time: 0.0152  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:34:27 d2.utils.events]: \u001b[0m eta: 0:56:41  iter: 2499  total_loss: 1.449  loss_cls: 0.4224  loss_box_reg: 0.4526  loss_mask: 0.2906  loss_rpn_cls: 0.08508  loss_rpn_loc: 0.2125  time: 0.4849  data_time: 0.0153  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:34:36 d2.utils.events]: \u001b[0m eta: 0:56:33  iter: 2519  total_loss: 1.374  loss_cls: 0.3892  loss_box_reg: 0.4199  loss_mask: 0.2751  loss_rpn_cls: 0.07957  loss_rpn_loc: 0.2015  time: 0.4847  data_time: 0.0161  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:34:45 d2.utils.events]: \u001b[0m eta: 0:56:18  iter: 2539  total_loss: 1.459  loss_cls: 0.4066  loss_box_reg: 0.4485  loss_mask: 0.2573  loss_rpn_cls: 0.08523  loss_rpn_loc: 0.1778  time: 0.4842  data_time: 0.0123  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:34:54 d2.utils.events]: \u001b[0m eta: 0:56:14  iter: 2559  total_loss: 1.584  loss_cls: 0.4708  loss_box_reg: 0.489  loss_mask: 0.2968  loss_rpn_cls: 0.1089  loss_rpn_loc: 0.2108  time: 0.4841  data_time: 0.0153  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:35:03 d2.utils.events]: \u001b[0m eta: 0:56:00  iter: 2579  total_loss: 1.445  loss_cls: 0.4405  loss_box_reg: 0.431  loss_mask: 0.278  loss_rpn_cls: 0.08035  loss_rpn_loc: 0.1873  time: 0.4838  data_time: 0.0126  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:35:13 d2.utils.events]: \u001b[0m eta: 0:55:58  iter: 2599  total_loss: 1.456  loss_cls: 0.4335  loss_box_reg: 0.4405  loss_mask: 0.2673  loss_rpn_cls: 0.103  loss_rpn_loc: 0.1947  time: 0.4838  data_time: 0.0157  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:35:21 d2.utils.events]: \u001b[0m eta: 0:55:43  iter: 2619  total_loss: 1.416  loss_cls: 0.3763  loss_box_reg: 0.4829  loss_mask: 0.2685  loss_rpn_cls: 0.08527  loss_rpn_loc: 0.1863  time: 0.4833  data_time: 0.0117  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:35:30 d2.utils.events]: \u001b[0m eta: 0:55:31  iter: 2639  total_loss: 1.575  loss_cls: 0.4779  loss_box_reg: 0.4851  loss_mask: 0.2914  loss_rpn_cls: 0.1133  loss_rpn_loc: 0.2024  time: 0.4830  data_time: 0.0133  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:35:39 d2.utils.events]: \u001b[0m eta: 0:55:23  iter: 2659  total_loss: 1.549  loss_cls: 0.4601  loss_box_reg: 0.4696  loss_mask: 0.2638  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.2258  time: 0.4828  data_time: 0.0134  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:35:48 d2.utils.events]: \u001b[0m eta: 0:55:10  iter: 2679  total_loss: 1.543  loss_cls: 0.4866  loss_box_reg: 0.4552  loss_mask: 0.2824  loss_rpn_cls: 0.1083  loss_rpn_loc: 0.2077  time: 0.4825  data_time: 0.0149  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:35:57 d2.utils.events]: \u001b[0m eta: 0:55:01  iter: 2699  total_loss: 1.521  loss_cls: 0.4414  loss_box_reg: 0.4338  loss_mask: 0.2822  loss_rpn_cls: 0.079  loss_rpn_loc: 0.2011  time: 0.4824  data_time: 0.0161  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:36:06 d2.utils.events]: \u001b[0m eta: 0:54:48  iter: 2719  total_loss: 1.471  loss_cls: 0.4493  loss_box_reg: 0.4872  loss_mask: 0.2557  loss_rpn_cls: 0.1013  loss_rpn_loc: 0.1737  time: 0.4820  data_time: 0.0132  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:36:15 d2.utils.events]: \u001b[0m eta: 0:54:39  iter: 2739  total_loss: 1.473  loss_cls: 0.4354  loss_box_reg: 0.4761  loss_mask: 0.2797  loss_rpn_cls: 0.09286  loss_rpn_loc: 0.2125  time: 0.4818  data_time: 0.0133  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:36:24 d2.utils.events]: \u001b[0m eta: 0:54:31  iter: 2759  total_loss: 1.573  loss_cls: 0.4515  loss_box_reg: 0.4599  loss_mask: 0.2841  loss_rpn_cls: 0.1028  loss_rpn_loc: 0.2162  time: 0.4816  data_time: 0.0139  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:36:34 d2.utils.events]: \u001b[0m eta: 0:54:22  iter: 2779  total_loss: 1.419  loss_cls: 0.3743  loss_box_reg: 0.4102  loss_mask: 0.2816  loss_rpn_cls: 0.09997  loss_rpn_loc: 0.1967  time: 0.4815  data_time: 0.0165  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:36:43 d2.utils.events]: \u001b[0m eta: 0:54:12  iter: 2799  total_loss: 1.463  loss_cls: 0.4059  loss_box_reg: 0.3793  loss_mask: 0.2529  loss_rpn_cls: 0.1089  loss_rpn_loc: 0.2098  time: 0.4814  data_time: 0.0148  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:36:52 d2.utils.events]: \u001b[0m eta: 0:54:03  iter: 2819  total_loss: 1.434  loss_cls: 0.4212  loss_box_reg: 0.4418  loss_mask: 0.2696  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.1773  time: 0.4813  data_time: 0.0147  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:37:01 d2.utils.events]: \u001b[0m eta: 0:53:54  iter: 2839  total_loss: 1.413  loss_cls: 0.375  loss_box_reg: 0.433  loss_mask: 0.272  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.1985  time: 0.4811  data_time: 0.0134  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:37:04 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7faf6314e950> to CPU due to CUDA OOM\n",
      "\u001b[32m[12/27 12:37:38 d2.utils.events]: \u001b[0m eta: 0:53:46  iter: 2859  total_loss: 1.304  loss_cls: 0.3769  loss_box_reg: 0.4498  loss_mask: 0.248  loss_rpn_cls: 0.07228  loss_rpn_loc: 0.1829  time: 0.4906  data_time: 0.0178  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:37:47 d2.utils.events]: \u001b[0m eta: 0:53:37  iter: 2879  total_loss: 1.314  loss_cls: 0.4125  loss_box_reg: 0.402  loss_mask: 0.25  loss_rpn_cls: 0.08204  loss_rpn_loc: 0.1786  time: 0.4904  data_time: 0.0140  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:37:49 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7faf6314e950> to CPU due to CUDA OOM\n",
      "\u001b[32m[12/27 12:38:23 d2.utils.events]: \u001b[0m eta: 0:53:32  iter: 2899  total_loss: 1.448  loss_cls: 0.4211  loss_box_reg: 0.4566  loss_mask: 0.2551  loss_rpn_cls: 0.1106  loss_rpn_loc: 0.2162  time: 0.4992  data_time: 0.0241  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:38:32 d2.utils.events]: \u001b[0m eta: 0:53:20  iter: 2919  total_loss: 1.569  loss_cls: 0.4419  loss_box_reg: 0.4502  loss_mask: 0.2886  loss_rpn_cls: 0.09376  loss_rpn_loc: 0.1705  time: 0.4989  data_time: 0.0147  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:38:41 d2.utils.events]: \u001b[0m eta: 0:53:16  iter: 2939  total_loss: 1.363  loss_cls: 0.4017  loss_box_reg: 0.4291  loss_mask: 0.2711  loss_rpn_cls: 0.08286  loss_rpn_loc: 0.1951  time: 0.4986  data_time: 0.0139  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:38:50 d2.utils.events]: \u001b[0m eta: 0:53:02  iter: 2959  total_loss: 1.462  loss_cls: 0.3994  loss_box_reg: 0.4565  loss_mask: 0.2863  loss_rpn_cls: 0.1217  loss_rpn_loc: 0.201  time: 0.4982  data_time: 0.0147  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:38:59 d2.utils.events]: \u001b[0m eta: 0:52:51  iter: 2979  total_loss: 1.484  loss_cls: 0.4143  loss_box_reg: 0.4717  loss_mask: 0.2709  loss_rpn_cls: 0.1162  loss_rpn_loc: 0.2075  time: 0.4978  data_time: 0.0143  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:39:08 d2.utils.events]: \u001b[0m eta: 0:52:41  iter: 2999  total_loss: 1.626  loss_cls: 0.4659  loss_box_reg: 0.4836  loss_mask: 0.2937  loss_rpn_cls: 0.1156  loss_rpn_loc: 0.2129  time: 0.4975  data_time: 0.0135  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:39:17 d2.utils.events]: \u001b[0m eta: 0:52:33  iter: 3019  total_loss: 1.522  loss_cls: 0.4421  loss_box_reg: 0.4487  loss_mask: 0.2925  loss_rpn_cls: 0.1076  loss_rpn_loc: 0.2027  time: 0.4974  data_time: 0.0159  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:39:27 d2.utils.events]: \u001b[0m eta: 0:52:23  iter: 3039  total_loss: 1.395  loss_cls: 0.3671  loss_box_reg: 0.4357  loss_mask: 0.2557  loss_rpn_cls: 0.07578  loss_rpn_loc: 0.1811  time: 0.4972  data_time: 0.0157  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:39:36 d2.utils.events]: \u001b[0m eta: 0:52:13  iter: 3059  total_loss: 1.403  loss_cls: 0.4371  loss_box_reg: 0.4455  loss_mask: 0.2625  loss_rpn_cls: 0.09752  loss_rpn_loc: 0.1947  time: 0.4968  data_time: 0.0152  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:39:45 d2.utils.events]: \u001b[0m eta: 0:52:05  iter: 3079  total_loss: 1.427  loss_cls: 0.4262  loss_box_reg: 0.4197  loss_mask: 0.2675  loss_rpn_cls: 0.1212  loss_rpn_loc: 0.2035  time: 0.4966  data_time: 0.0162  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:39:54 d2.utils.events]: \u001b[0m eta: 0:51:56  iter: 3099  total_loss: 1.352  loss_cls: 0.3771  loss_box_reg: 0.4076  loss_mask: 0.265  loss_rpn_cls: 0.1166  loss_rpn_loc: 0.2192  time: 0.4964  data_time: 0.0168  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:40:03 d2.utils.events]: \u001b[0m eta: 0:51:47  iter: 3119  total_loss: 1.553  loss_cls: 0.4523  loss_box_reg: 0.4704  loss_mask: 0.2807  loss_rpn_cls: 0.1091  loss_rpn_loc: 0.1992  time: 0.4961  data_time: 0.0148  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:40:13 d2.utils.events]: \u001b[0m eta: 0:51:37  iter: 3139  total_loss: 1.585  loss_cls: 0.4279  loss_box_reg: 0.4634  loss_mask: 0.288  loss_rpn_cls: 0.1114  loss_rpn_loc: 0.1955  time: 0.4960  data_time: 0.0158  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:40:23 d2.utils.events]: \u001b[0m eta: 0:51:29  iter: 3159  total_loss: 1.437  loss_cls: 0.364  loss_box_reg: 0.4205  loss_mask: 0.2719  loss_rpn_cls: 0.1112  loss_rpn_loc: 0.1906  time: 0.4960  data_time: 0.0303  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:40:32 d2.utils.events]: \u001b[0m eta: 0:51:19  iter: 3179  total_loss: 1.38  loss_cls: 0.4419  loss_box_reg: 0.4239  loss_mask: 0.2417  loss_rpn_cls: 0.08251  loss_rpn_loc: 0.1693  time: 0.4956  data_time: 0.0137  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:40:41 d2.utils.events]: \u001b[0m eta: 0:51:11  iter: 3199  total_loss: 1.48  loss_cls: 0.4136  loss_box_reg: 0.4762  loss_mask: 0.2775  loss_rpn_cls: 0.08165  loss_rpn_loc: 0.1782  time: 0.4954  data_time: 0.0129  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:40:50 d2.utils.events]: \u001b[0m eta: 0:51:01  iter: 3219  total_loss: 1.569  loss_cls: 0.4775  loss_box_reg: 0.4294  loss_mask: 0.2918  loss_rpn_cls: 0.1081  loss_rpn_loc: 0.2054  time: 0.4951  data_time: 0.0149  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:40:59 d2.utils.events]: \u001b[0m eta: 0:50:53  iter: 3239  total_loss: 1.438  loss_cls: 0.4091  loss_box_reg: 0.452  loss_mask: 0.2636  loss_rpn_cls: 0.09176  loss_rpn_loc: 0.2016  time: 0.4949  data_time: 0.0158  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:41:08 d2.utils.events]: \u001b[0m eta: 0:50:42  iter: 3259  total_loss: 1.528  loss_cls: 0.4623  loss_box_reg: 0.4441  loss_mask: 0.2881  loss_rpn_cls: 0.1095  loss_rpn_loc: 0.1859  time: 0.4947  data_time: 0.0159  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:41:17 d2.utils.events]: \u001b[0m eta: 0:50:35  iter: 3279  total_loss: 1.433  loss_cls: 0.4361  loss_box_reg: 0.4329  loss_mask: 0.2729  loss_rpn_cls: 0.1106  loss_rpn_loc: 0.1891  time: 0.4945  data_time: 0.0141  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:41:27 d2.utils.events]: \u001b[0m eta: 0:50:24  iter: 3299  total_loss: 1.45  loss_cls: 0.4259  loss_box_reg: 0.4473  loss_mask: 0.292  loss_rpn_cls: 0.105  loss_rpn_loc: 0.1899  time: 0.4943  data_time: 0.0153  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:41:36 d2.utils.events]: \u001b[0m eta: 0:50:23  iter: 3319  total_loss: 1.392  loss_cls: 0.4077  loss_box_reg: 0.4242  loss_mask: 0.2592  loss_rpn_cls: 0.06324  loss_rpn_loc: 0.1781  time: 0.4941  data_time: 0.0144  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:41:46 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7faf6314e950> to CPU due to CUDA OOM\n",
      "\u001b[32m[12/27 12:42:07 d2.utils.events]: \u001b[0m eta: 0:50:12  iter: 3339  total_loss: 1.319  loss_cls: 0.3513  loss_box_reg: 0.4039  loss_mask: 0.258  loss_rpn_cls: 0.09783  loss_rpn_loc: 0.1789  time: 0.5003  data_time: 0.0168  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:42:16 d2.utils.events]: \u001b[0m eta: 0:50:04  iter: 3359  total_loss: 1.495  loss_cls: 0.423  loss_box_reg: 0.4397  loss_mask: 0.2793  loss_rpn_cls: 0.09952  loss_rpn_loc: 0.2217  time: 0.5001  data_time: 0.0175  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:42:25 d2.utils.events]: \u001b[0m eta: 0:49:53  iter: 3379  total_loss: 1.396  loss_cls: 0.4371  loss_box_reg: 0.4751  loss_mask: 0.2833  loss_rpn_cls: 0.09348  loss_rpn_loc: 0.201  time: 0.4998  data_time: 0.0162  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:42:34 d2.utils.events]: \u001b[0m eta: 0:49:42  iter: 3399  total_loss: 1.379  loss_cls: 0.3932  loss_box_reg: 0.4515  loss_mask: 0.2599  loss_rpn_cls: 0.06808  loss_rpn_loc: 0.1785  time: 0.4995  data_time: 0.0140  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:42:43 d2.utils.events]: \u001b[0m eta: 0:49:37  iter: 3419  total_loss: 1.503  loss_cls: 0.419  loss_box_reg: 0.4765  loss_mask: 0.2932  loss_rpn_cls: 0.1075  loss_rpn_loc: 0.2072  time: 0.4993  data_time: 0.0180  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:42:52 d2.utils.events]: \u001b[0m eta: 0:49:27  iter: 3439  total_loss: 1.391  loss_cls: 0.4309  loss_box_reg: 0.4656  loss_mask: 0.2823  loss_rpn_cls: 0.08379  loss_rpn_loc: 0.1706  time: 0.4991  data_time: 0.0135  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:43:01 d2.utils.events]: \u001b[0m eta: 0:49:15  iter: 3459  total_loss: 1.393  loss_cls: 0.4155  loss_box_reg: 0.4176  loss_mask: 0.2754  loss_rpn_cls: 0.09089  loss_rpn_loc: 0.173  time: 0.4988  data_time: 0.0141  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:43:11 d2.utils.events]: \u001b[0m eta: 0:49:04  iter: 3479  total_loss: 1.536  loss_cls: 0.4586  loss_box_reg: 0.4506  loss_mask: 0.2803  loss_rpn_cls: 0.1092  loss_rpn_loc: 0.2102  time: 0.4987  data_time: 0.0249  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:43:20 d2.utils.events]: \u001b[0m eta: 0:48:53  iter: 3499  total_loss: 1.474  loss_cls: 0.4034  loss_box_reg: 0.4238  loss_mask: 0.2807  loss_rpn_cls: 0.09339  loss_rpn_loc: 0.1896  time: 0.4984  data_time: 0.0133  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:43:29 d2.utils.events]: \u001b[0m eta: 0:48:44  iter: 3519  total_loss: 1.495  loss_cls: 0.436  loss_box_reg: 0.4556  loss_mask: 0.2606  loss_rpn_cls: 0.09409  loss_rpn_loc: 0.198  time: 0.4982  data_time: 0.0151  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:43:38 d2.utils.events]: \u001b[0m eta: 0:48:37  iter: 3539  total_loss: 1.432  loss_cls: 0.384  loss_box_reg: 0.4415  loss_mask: 0.3049  loss_rpn_cls: 0.08437  loss_rpn_loc: 0.193  time: 0.4979  data_time: 0.0152  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:43:48 d2.utils.events]: \u001b[0m eta: 0:48:29  iter: 3559  total_loss: 1.491  loss_cls: 0.4205  loss_box_reg: 0.4525  loss_mask: 0.2903  loss_rpn_cls: 0.08608  loss_rpn_loc: 0.19  time: 0.4977  data_time: 0.0139  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:43:57 d2.utils.events]: \u001b[0m eta: 0:48:19  iter: 3579  total_loss: 1.461  loss_cls: 0.4876  loss_box_reg: 0.4621  loss_mask: 0.2774  loss_rpn_cls: 0.07852  loss_rpn_loc: 0.2008  time: 0.4974  data_time: 0.0126  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:44:06 d2.utils.events]: \u001b[0m eta: 0:48:04  iter: 3599  total_loss: 1.456  loss_cls: 0.4717  loss_box_reg: 0.4391  loss_mask: 0.2693  loss_rpn_cls: 0.11  loss_rpn_loc: 0.1899  time: 0.4972  data_time: 0.0144  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:44:15 d2.utils.events]: \u001b[0m eta: 0:47:58  iter: 3619  total_loss: 1.464  loss_cls: 0.4444  loss_box_reg: 0.4549  loss_mask: 0.2767  loss_rpn_cls: 0.08878  loss_rpn_loc: 0.2089  time: 0.4971  data_time: 0.0156  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:44:25 d2.utils.events]: \u001b[0m eta: 0:47:49  iter: 3639  total_loss: 1.465  loss_cls: 0.3846  loss_box_reg: 0.4499  loss_mask: 0.2609  loss_rpn_cls: 0.08412  loss_rpn_loc: 0.1935  time: 0.4970  data_time: 0.0160  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:44:34 d2.utils.events]: \u001b[0m eta: 0:47:41  iter: 3659  total_loss: 1.347  loss_cls: 0.3491  loss_box_reg: 0.4134  loss_mask: 0.2994  loss_rpn_cls: 0.1063  loss_rpn_loc: 0.2124  time: 0.4968  data_time: 0.0175  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:44:43 d2.utils.events]: \u001b[0m eta: 0:47:34  iter: 3679  total_loss: 1.43  loss_cls: 0.3963  loss_box_reg: 0.4357  loss_mask: 0.2813  loss_rpn_cls: 0.086  loss_rpn_loc: 0.1997  time: 0.4965  data_time: 0.0138  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:44:53 d2.utils.events]: \u001b[0m eta: 0:47:30  iter: 3699  total_loss: 1.209  loss_cls: 0.3455  loss_box_reg: 0.3946  loss_mask: 0.2426  loss_rpn_cls: 0.07133  loss_rpn_loc: 0.1825  time: 0.4965  data_time: 0.0219  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:45:02 d2.utils.events]: \u001b[0m eta: 0:47:26  iter: 3719  total_loss: 1.511  loss_cls: 0.4514  loss_box_reg: 0.4849  loss_mask: 0.2821  loss_rpn_cls: 0.09505  loss_rpn_loc: 0.1993  time: 0.4964  data_time: 0.0167  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:45:12 d2.utils.events]: \u001b[0m eta: 0:47:19  iter: 3739  total_loss: 1.395  loss_cls: 0.3435  loss_box_reg: 0.4201  loss_mask: 0.2719  loss_rpn_cls: 0.0977  loss_rpn_loc: 0.1946  time: 0.4962  data_time: 0.0154  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:45:21 d2.utils.events]: \u001b[0m eta: 0:47:12  iter: 3759  total_loss: 1.433  loss_cls: 0.4239  loss_box_reg: 0.444  loss_mask: 0.288  loss_rpn_cls: 0.1143  loss_rpn_loc: 0.1957  time: 0.4961  data_time: 0.0167  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:45:30 d2.utils.events]: \u001b[0m eta: 0:46:59  iter: 3779  total_loss: 1.506  loss_cls: 0.4122  loss_box_reg: 0.4697  loss_mask: 0.2857  loss_rpn_cls: 0.09737  loss_rpn_loc: 0.1805  time: 0.4959  data_time: 0.0137  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:45:40 d2.utils.events]: \u001b[0m eta: 0:46:49  iter: 3799  total_loss: 1.366  loss_cls: 0.3708  loss_box_reg: 0.4433  loss_mask: 0.2731  loss_rpn_cls: 0.07516  loss_rpn_loc: 0.1961  time: 0.4958  data_time: 0.0155  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:45:49 d2.utils.events]: \u001b[0m eta: 0:46:44  iter: 3819  total_loss: 1.274  loss_cls: 0.3156  loss_box_reg: 0.4185  loss_mask: 0.2665  loss_rpn_cls: 0.0873  loss_rpn_loc: 0.1958  time: 0.4956  data_time: 0.0151  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:45:59 d2.utils.events]: \u001b[0m eta: 0:46:38  iter: 3839  total_loss: 1.534  loss_cls: 0.4369  loss_box_reg: 0.4687  loss_mask: 0.2754  loss_rpn_cls: 0.09746  loss_rpn_loc: 0.2013  time: 0.4955  data_time: 0.0173  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:46:08 d2.utils.events]: \u001b[0m eta: 0:46:31  iter: 3859  total_loss: 1.413  loss_cls: 0.3866  loss_box_reg: 0.4298  loss_mask: 0.2614  loss_rpn_cls: 0.08808  loss_rpn_loc: 0.2052  time: 0.4953  data_time: 0.0144  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:46:17 d2.utils.events]: \u001b[0m eta: 0:46:22  iter: 3879  total_loss: 1.477  loss_cls: 0.3953  loss_box_reg: 0.4398  loss_mask: 0.2768  loss_rpn_cls: 0.1041  loss_rpn_loc: 0.1919  time: 0.4951  data_time: 0.0152  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:46:26 d2.utils.events]: \u001b[0m eta: 0:46:12  iter: 3899  total_loss: 1.403  loss_cls: 0.3877  loss_box_reg: 0.4301  loss_mask: 0.272  loss_rpn_cls: 0.09735  loss_rpn_loc: 0.1956  time: 0.4949  data_time: 0.0140  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:46:35 d2.utils.events]: \u001b[0m eta: 0:46:03  iter: 3919  total_loss: 1.384  loss_cls: 0.3928  loss_box_reg: 0.4406  loss_mask: 0.2705  loss_rpn_cls: 0.07461  loss_rpn_loc: 0.1846  time: 0.4947  data_time: 0.0129  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:46:44 d2.utils.events]: \u001b[0m eta: 0:45:54  iter: 3939  total_loss: 1.354  loss_cls: 0.4159  loss_box_reg: 0.4518  loss_mask: 0.2713  loss_rpn_cls: 0.08123  loss_rpn_loc: 0.1932  time: 0.4945  data_time: 0.0151  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:46:54 d2.utils.events]: \u001b[0m eta: 0:45:50  iter: 3959  total_loss: 1.486  loss_cls: 0.3972  loss_box_reg: 0.4792  loss_mask: 0.287  loss_rpn_cls: 0.08535  loss_rpn_loc: 0.1949  time: 0.4944  data_time: 0.0151  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:47:03 d2.utils.events]: \u001b[0m eta: 0:45:42  iter: 3979  total_loss: 1.48  loss_cls: 0.4353  loss_box_reg: 0.4682  loss_mask: 0.278  loss_rpn_cls: 0.1009  loss_rpn_loc: 0.198  time: 0.4941  data_time: 0.0120  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:47:12 d2.utils.events]: \u001b[0m eta: 0:45:35  iter: 3999  total_loss: 1.418  loss_cls: 0.4081  loss_box_reg: 0.4453  loss_mask: 0.2656  loss_rpn_cls: 0.0909  loss_rpn_loc: 0.1863  time: 0.4939  data_time: 0.0142  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:47:21 d2.utils.events]: \u001b[0m eta: 0:45:24  iter: 4019  total_loss: 1.454  loss_cls: 0.3899  loss_box_reg: 0.4267  loss_mask: 0.2702  loss_rpn_cls: 0.1199  loss_rpn_loc: 0.2036  time: 0.4937  data_time: 0.0151  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:47:30 d2.utils.events]: \u001b[0m eta: 0:45:14  iter: 4039  total_loss: 1.493  loss_cls: 0.4101  loss_box_reg: 0.4681  loss_mask: 0.2802  loss_rpn_cls: 0.1238  loss_rpn_loc: 0.2077  time: 0.4935  data_time: 0.0155  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:47:39 d2.utils.events]: \u001b[0m eta: 0:45:09  iter: 4059  total_loss: 1.478  loss_cls: 0.3898  loss_box_reg: 0.4533  loss_mask: 0.2962  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.2161  time: 0.4934  data_time: 0.0159  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:47:48 d2.utils.events]: \u001b[0m eta: 0:44:58  iter: 4079  total_loss: 1.345  loss_cls: 0.398  loss_box_reg: 0.4237  loss_mask: 0.2666  loss_rpn_cls: 0.1066  loss_rpn_loc: 0.2001  time: 0.4932  data_time: 0.0158  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:47:57 d2.utils.events]: \u001b[0m eta: 0:44:48  iter: 4099  total_loss: 1.412  loss_cls: 0.4095  loss_box_reg: 0.4311  loss_mask: 0.2563  loss_rpn_cls: 0.08186  loss_rpn_loc: 0.1914  time: 0.4930  data_time: 0.0132  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:48:07 d2.utils.events]: \u001b[0m eta: 0:44:39  iter: 4119  total_loss: 1.431  loss_cls: 0.3989  loss_box_reg: 0.4166  loss_mask: 0.2745  loss_rpn_cls: 0.1072  loss_rpn_loc: 0.1982  time: 0.4928  data_time: 0.0152  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:48:16 d2.utils.events]: \u001b[0m eta: 0:44:29  iter: 4139  total_loss: 1.384  loss_cls: 0.4724  loss_box_reg: 0.4183  loss_mask: 0.2673  loss_rpn_cls: 0.1006  loss_rpn_loc: 0.1998  time: 0.4927  data_time: 0.0154  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:48:25 d2.utils.events]: \u001b[0m eta: 0:44:18  iter: 4159  total_loss: 1.5  loss_cls: 0.421  loss_box_reg: 0.4921  loss_mask: 0.2867  loss_rpn_cls: 0.09454  loss_rpn_loc: 0.1905  time: 0.4926  data_time: 0.0130  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:48:35 d2.utils.events]: \u001b[0m eta: 0:44:11  iter: 4179  total_loss: 1.321  loss_cls: 0.3496  loss_box_reg: 0.4214  loss_mask: 0.27  loss_rpn_cls: 0.1048  loss_rpn_loc: 0.1811  time: 0.4924  data_time: 0.0151  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:48:44 d2.utils.events]: \u001b[0m eta: 0:44:03  iter: 4199  total_loss: 1.433  loss_cls: 0.3988  loss_box_reg: 0.4728  loss_mask: 0.2741  loss_rpn_cls: 0.1264  loss_rpn_loc: 0.2125  time: 0.4922  data_time: 0.0149  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:48:53 d2.utils.events]: \u001b[0m eta: 0:43:55  iter: 4219  total_loss: 1.446  loss_cls: 0.4122  loss_box_reg: 0.4238  loss_mask: 0.2749  loss_rpn_cls: 0.07932  loss_rpn_loc: 0.1851  time: 0.4921  data_time: 0.0163  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:49:03 d2.utils.events]: \u001b[0m eta: 0:43:47  iter: 4239  total_loss: 1.54  loss_cls: 0.5206  loss_box_reg: 0.4261  loss_mask: 0.2617  loss_rpn_cls: 0.1029  loss_rpn_loc: 0.18  time: 0.4920  data_time: 0.0249  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:49:12 d2.utils.events]: \u001b[0m eta: 0:43:40  iter: 4259  total_loss: 1.476  loss_cls: 0.4638  loss_box_reg: 0.4263  loss_mask: 0.2628  loss_rpn_cls: 0.09171  loss_rpn_loc: 0.1953  time: 0.4918  data_time: 0.0154  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:49:21 d2.utils.events]: \u001b[0m eta: 0:43:31  iter: 4279  total_loss: 1.409  loss_cls: 0.4353  loss_box_reg: 0.4537  loss_mask: 0.2709  loss_rpn_cls: 0.08437  loss_rpn_loc: 0.1819  time: 0.4917  data_time: 0.0147  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:49:30 d2.utils.events]: \u001b[0m eta: 0:43:18  iter: 4299  total_loss: 1.366  loss_cls: 0.378  loss_box_reg: 0.4692  loss_mask: 0.2758  loss_rpn_cls: 0.08457  loss_rpn_loc: 0.1792  time: 0.4914  data_time: 0.0120  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:49:38 d2.utils.events]: \u001b[0m eta: 0:43:06  iter: 4319  total_loss: 1.355  loss_cls: 0.3723  loss_box_reg: 0.4579  loss_mask: 0.2752  loss_rpn_cls: 0.08747  loss_rpn_loc: 0.1805  time: 0.4912  data_time: 0.0133  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:49:48 d2.utils.events]: \u001b[0m eta: 0:42:53  iter: 4339  total_loss: 1.421  loss_cls: 0.3818  loss_box_reg: 0.4502  loss_mask: 0.2676  loss_rpn_cls: 0.09858  loss_rpn_loc: 0.1955  time: 0.4912  data_time: 0.0152  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:49:58 d2.utils.events]: \u001b[0m eta: 0:42:44  iter: 4359  total_loss: 1.375  loss_cls: 0.3987  loss_box_reg: 0.4282  loss_mask: 0.2798  loss_rpn_cls: 0.1079  loss_rpn_loc: 0.1939  time: 0.4912  data_time: 0.0148  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:50:08 d2.utils.events]: \u001b[0m eta: 0:42:39  iter: 4379  total_loss: 1.513  loss_cls: 0.4161  loss_box_reg: 0.4485  loss_mask: 0.2866  loss_rpn_cls: 0.1165  loss_rpn_loc: 0.1923  time: 0.4911  data_time: 0.0167  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:50:17 d2.utils.events]: \u001b[0m eta: 0:42:30  iter: 4399  total_loss: 1.342  loss_cls: 0.3532  loss_box_reg: 0.4146  loss_mask: 0.2663  loss_rpn_cls: 0.09496  loss_rpn_loc: 0.1922  time: 0.4911  data_time: 0.0166  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:50:26 d2.utils.events]: \u001b[0m eta: 0:42:21  iter: 4419  total_loss: 1.436  loss_cls: 0.3894  loss_box_reg: 0.4107  loss_mask: 0.2706  loss_rpn_cls: 0.1088  loss_rpn_loc: 0.2073  time: 0.4909  data_time: 0.0147  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:50:36 d2.utils.events]: \u001b[0m eta: 0:42:12  iter: 4439  total_loss: 1.347  loss_cls: 0.3837  loss_box_reg: 0.4589  loss_mask: 0.2686  loss_rpn_cls: 0.09534  loss_rpn_loc: 0.1855  time: 0.4908  data_time: 0.0157  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:50:46 d2.utils.events]: \u001b[0m eta: 0:42:05  iter: 4459  total_loss: 1.579  loss_cls: 0.4173  loss_box_reg: 0.467  loss_mask: 0.2599  loss_rpn_cls: 0.1237  loss_rpn_loc: 0.2134  time: 0.4909  data_time: 0.0275  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:50:55 d2.utils.events]: \u001b[0m eta: 0:41:54  iter: 4479  total_loss: 1.403  loss_cls: 0.3805  loss_box_reg: 0.4628  loss_mask: 0.2732  loss_rpn_cls: 0.07942  loss_rpn_loc: 0.1742  time: 0.4907  data_time: 0.0123  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:51:04 d2.utils.events]: \u001b[0m eta: 0:41:47  iter: 4499  total_loss: 1.396  loss_cls: 0.3664  loss_box_reg: 0.422  loss_mask: 0.2736  loss_rpn_cls: 0.09459  loss_rpn_loc: 0.1941  time: 0.4905  data_time: 0.0149  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:51:13 d2.utils.events]: \u001b[0m eta: 0:41:38  iter: 4519  total_loss: 1.427  loss_cls: 0.3844  loss_box_reg: 0.4563  loss_mask: 0.2743  loss_rpn_cls: 0.1006  loss_rpn_loc: 0.1919  time: 0.4903  data_time: 0.0143  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:51:22 d2.utils.events]: \u001b[0m eta: 0:41:28  iter: 4539  total_loss: 1.491  loss_cls: 0.4198  loss_box_reg: 0.5089  loss_mask: 0.2783  loss_rpn_cls: 0.09669  loss_rpn_loc: 0.188  time: 0.4901  data_time: 0.0132  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:51:31 d2.utils.events]: \u001b[0m eta: 0:41:17  iter: 4559  total_loss: 1.429  loss_cls: 0.3989  loss_box_reg: 0.403  loss_mask: 0.2661  loss_rpn_cls: 0.1044  loss_rpn_loc: 0.2061  time: 0.4900  data_time: 0.0159  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:51:40 d2.utils.events]: \u001b[0m eta: 0:41:08  iter: 4579  total_loss: 1.354  loss_cls: 0.4019  loss_box_reg: 0.4389  loss_mask: 0.2537  loss_rpn_cls: 0.09374  loss_rpn_loc: 0.1938  time: 0.4898  data_time: 0.0192  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:51:49 d2.utils.events]: \u001b[0m eta: 0:41:00  iter: 4599  total_loss: 1.429  loss_cls: 0.3808  loss_box_reg: 0.4263  loss_mask: 0.2662  loss_rpn_cls: 0.1125  loss_rpn_loc: 0.1989  time: 0.4896  data_time: 0.0149  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:51:58 d2.utils.events]: \u001b[0m eta: 0:40:50  iter: 4619  total_loss: 1.372  loss_cls: 0.3695  loss_box_reg: 0.3943  loss_mask: 0.282  loss_rpn_cls: 0.09272  loss_rpn_loc: 0.1766  time: 0.4895  data_time: 0.0151  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:52:07 d2.utils.events]: \u001b[0m eta: 0:40:43  iter: 4639  total_loss: 1.487  loss_cls: 0.4277  loss_box_reg: 0.4411  loss_mask: 0.2947  loss_rpn_cls: 0.1081  loss_rpn_loc: 0.1981  time: 0.4893  data_time: 0.0154  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:52:16 d2.utils.events]: \u001b[0m eta: 0:40:32  iter: 4659  total_loss: 1.296  loss_cls: 0.3959  loss_box_reg: 0.4006  loss_mask: 0.2681  loss_rpn_cls: 0.08827  loss_rpn_loc: 0.1924  time: 0.4892  data_time: 0.0130  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:52:25 d2.utils.events]: \u001b[0m eta: 0:40:25  iter: 4679  total_loss: 1.414  loss_cls: 0.3726  loss_box_reg: 0.4566  loss_mask: 0.2817  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.1937  time: 0.4890  data_time: 0.0128  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:52:35 d2.utils.events]: \u001b[0m eta: 0:40:15  iter: 4699  total_loss: 1.511  loss_cls: 0.4554  loss_box_reg: 0.4624  loss_mask: 0.2787  loss_rpn_cls: 0.09998  loss_rpn_loc: 0.1987  time: 0.4890  data_time: 0.0171  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:52:45 d2.utils.events]: \u001b[0m eta: 0:40:04  iter: 4719  total_loss: 1.463  loss_cls: 0.4483  loss_box_reg: 0.3859  loss_mask: 0.2845  loss_rpn_cls: 0.1221  loss_rpn_loc: 0.2077  time: 0.4890  data_time: 0.0151  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:52:54 d2.utils.events]: \u001b[0m eta: 0:39:55  iter: 4739  total_loss: 1.462  loss_cls: 0.4298  loss_box_reg: 0.4206  loss_mask: 0.2783  loss_rpn_cls: 0.09722  loss_rpn_loc: 0.1972  time: 0.4888  data_time: 0.0140  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:53:03 d2.utils.events]: \u001b[0m eta: 0:39:46  iter: 4759  total_loss: 1.406  loss_cls: 0.4062  loss_box_reg: 0.4325  loss_mask: 0.2958  loss_rpn_cls: 0.09724  loss_rpn_loc: 0.1966  time: 0.4887  data_time: 0.0151  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:53:13 d2.utils.events]: \u001b[0m eta: 0:39:44  iter: 4779  total_loss: 1.227  loss_cls: 0.3193  loss_box_reg: 0.3897  loss_mask: 0.2514  loss_rpn_cls: 0.07902  loss_rpn_loc: 0.1924  time: 0.4887  data_time: 0.0168  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:53:22 d2.utils.events]: \u001b[0m eta: 0:39:34  iter: 4799  total_loss: 1.467  loss_cls: 0.4131  loss_box_reg: 0.4837  loss_mask: 0.2787  loss_rpn_cls: 0.1091  loss_rpn_loc: 0.2059  time: 0.4886  data_time: 0.0146  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:53:35 d2.data.datasets.coco]: \u001b[0mLoading /content/livecell/livecell_annotations_val.json takes 4.71 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/27 12:53:35 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/27 12:53:35 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from /content/livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/27 12:53:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 12:53:37 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 12:53:37 d2.data.common]: \u001b[0mSerialized dataset takes 84.21 MiB\n",
      "\u001b[32m[12/27 12:53:41 d2.data.datasets.coco]: \u001b[0mLoading /content/livecell/livecell_annotations_val.json takes 3.55 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/27 12:53:41 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/27 12:53:41 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from /content/livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/27 12:53:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/27 12:53:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0015 s/iter. Inference: 0.0967 s/iter. Eval: 0.2742 s/iter. Total: 0.3725 s/iter. ETA=0:03:28\n",
      "\u001b[32m[12/27 12:53:53 d2.evaluation.evaluator]: \u001b[0mInference done 26/570. Dataloading: 0.0018 s/iter. Inference: 0.0984 s/iter. Eval: 0.2443 s/iter. Total: 0.3447 s/iter. ETA=0:03:07\n",
      "\u001b[32m[12/27 12:53:58 d2.evaluation.evaluator]: \u001b[0mInference done 41/570. Dataloading: 0.0018 s/iter. Inference: 0.0983 s/iter. Eval: 0.2447 s/iter. Total: 0.3451 s/iter. ETA=0:03:02\n",
      "\u001b[32m[12/27 12:54:03 d2.evaluation.evaluator]: \u001b[0mInference done 56/570. Dataloading: 0.0019 s/iter. Inference: 0.0983 s/iter. Eval: 0.2464 s/iter. Total: 0.3468 s/iter. ETA=0:02:58\n",
      "\u001b[32m[12/27 12:54:08 d2.evaluation.evaluator]: \u001b[0mInference done 71/570. Dataloading: 0.0019 s/iter. Inference: 0.0983 s/iter. Eval: 0.2456 s/iter. Total: 0.3461 s/iter. ETA=0:02:52\n",
      "\u001b[32m[12/27 12:54:13 d2.evaluation.evaluator]: \u001b[0mInference done 84/570. Dataloading: 0.0019 s/iter. Inference: 0.0986 s/iter. Eval: 0.2524 s/iter. Total: 0.3531 s/iter. ETA=0:02:51\n",
      "\u001b[32m[12/27 12:54:18 d2.evaluation.evaluator]: \u001b[0mInference done 97/570. Dataloading: 0.0019 s/iter. Inference: 0.0989 s/iter. Eval: 0.2574 s/iter. Total: 0.3584 s/iter. ETA=0:02:49\n",
      "\u001b[32m[12/27 12:54:23 d2.evaluation.evaluator]: \u001b[0mInference done 110/570. Dataloading: 0.0019 s/iter. Inference: 0.0991 s/iter. Eval: 0.2615 s/iter. Total: 0.3628 s/iter. ETA=0:02:46\n",
      "\u001b[32m[12/27 12:54:29 d2.evaluation.evaluator]: \u001b[0mInference done 124/570. Dataloading: 0.0019 s/iter. Inference: 0.0993 s/iter. Eval: 0.2615 s/iter. Total: 0.3629 s/iter. ETA=0:02:41\n",
      "\u001b[32m[12/27 12:54:34 d2.evaluation.evaluator]: \u001b[0mInference done 136/570. Dataloading: 0.0019 s/iter. Inference: 0.0993 s/iter. Eval: 0.2685 s/iter. Total: 0.3700 s/iter. ETA=0:02:40\n",
      "\u001b[32m[12/27 12:54:39 d2.evaluation.evaluator]: \u001b[0mInference done 150/570. Dataloading: 0.0019 s/iter. Inference: 0.0993 s/iter. Eval: 0.2689 s/iter. Total: 0.3703 s/iter. ETA=0:02:35\n",
      "\u001b[32m[12/27 12:54:44 d2.evaluation.evaluator]: \u001b[0mInference done 158/570. Dataloading: 0.0019 s/iter. Inference: 0.0994 s/iter. Eval: 0.2829 s/iter. Total: 0.3843 s/iter. ETA=0:02:38\n",
      "\u001b[32m[12/27 12:54:50 d2.evaluation.evaluator]: \u001b[0mInference done 167/570. Dataloading: 0.0019 s/iter. Inference: 0.0995 s/iter. Eval: 0.2969 s/iter. Total: 0.3985 s/iter. ETA=0:02:40\n",
      "\u001b[32m[12/27 12:54:55 d2.evaluation.evaluator]: \u001b[0mInference done 173/570. Dataloading: 0.0019 s/iter. Inference: 0.0996 s/iter. Eval: 0.3138 s/iter. Total: 0.4155 s/iter. ETA=0:02:44\n",
      "\u001b[32m[12/27 12:55:00 d2.evaluation.evaluator]: \u001b[0mInference done 180/570. Dataloading: 0.0019 s/iter. Inference: 0.0997 s/iter. Eval: 0.3264 s/iter. Total: 0.4282 s/iter. ETA=0:02:47\n",
      "\u001b[32m[12/27 12:55:06 d2.evaluation.evaluator]: \u001b[0mInference done 191/570. Dataloading: 0.0019 s/iter. Inference: 0.0997 s/iter. Eval: 0.3331 s/iter. Total: 0.4350 s/iter. ETA=0:02:44\n",
      "\u001b[32m[12/27 12:55:12 d2.evaluation.evaluator]: \u001b[0mInference done 202/570. Dataloading: 0.0019 s/iter. Inference: 0.0998 s/iter. Eval: 0.3380 s/iter. Total: 0.4400 s/iter. ETA=0:02:41\n",
      "\u001b[32m[12/27 12:55:17 d2.evaluation.evaluator]: \u001b[0mInference done 208/570. Dataloading: 0.0020 s/iter. Inference: 0.0998 s/iter. Eval: 0.3504 s/iter. Total: 0.4525 s/iter. ETA=0:02:43\n",
      "\u001b[32m[12/27 12:55:22 d2.evaluation.evaluator]: \u001b[0mInference done 217/570. Dataloading: 0.0020 s/iter. Inference: 0.0999 s/iter. Eval: 0.3549 s/iter. Total: 0.4570 s/iter. ETA=0:02:41\n",
      "\u001b[32m[12/27 12:55:27 d2.evaluation.evaluator]: \u001b[0mInference done 225/570. Dataloading: 0.0020 s/iter. Inference: 0.1000 s/iter. Eval: 0.3617 s/iter. Total: 0.4639 s/iter. ETA=0:02:40\n",
      "\u001b[32m[12/27 12:55:32 d2.evaluation.evaluator]: \u001b[0mInference done 231/570. Dataloading: 0.0020 s/iter. Inference: 0.1000 s/iter. Eval: 0.3718 s/iter. Total: 0.4740 s/iter. ETA=0:02:40\n",
      "\u001b[32m[12/27 12:55:38 d2.evaluation.evaluator]: \u001b[0mInference done 236/570. Dataloading: 0.0020 s/iter. Inference: 0.1000 s/iter. Eval: 0.3865 s/iter. Total: 0.4887 s/iter. ETA=0:02:43\n",
      "\u001b[32m[12/27 12:55:44 d2.evaluation.evaluator]: \u001b[0mInference done 242/570. Dataloading: 0.0020 s/iter. Inference: 0.1000 s/iter. Eval: 0.3965 s/iter. Total: 0.4987 s/iter. ETA=0:02:43\n",
      "\u001b[32m[12/27 12:55:50 d2.evaluation.evaluator]: \u001b[0mInference done 249/570. Dataloading: 0.0020 s/iter. Inference: 0.1000 s/iter. Eval: 0.4070 s/iter. Total: 0.5092 s/iter. ETA=0:02:43\n",
      "\u001b[32m[12/27 12:55:55 d2.evaluation.evaluator]: \u001b[0mInference done 257/570. Dataloading: 0.0020 s/iter. Inference: 0.1000 s/iter. Eval: 0.4116 s/iter. Total: 0.5138 s/iter. ETA=0:02:40\n",
      "\u001b[32m[12/27 12:56:00 d2.evaluation.evaluator]: \u001b[0mInference done 265/570. Dataloading: 0.0037 s/iter. Inference: 0.1000 s/iter. Eval: 0.4150 s/iter. Total: 0.5189 s/iter. ETA=0:02:38\n",
      "\u001b[32m[12/27 12:56:05 d2.evaluation.evaluator]: \u001b[0mInference done 272/570. Dataloading: 0.0036 s/iter. Inference: 0.1000 s/iter. Eval: 0.4202 s/iter. Total: 0.5242 s/iter. ETA=0:02:36\n",
      "\u001b[32m[12/27 12:56:10 d2.evaluation.evaluator]: \u001b[0mInference done 283/570. Dataloading: 0.0036 s/iter. Inference: 0.1001 s/iter. Eval: 0.4182 s/iter. Total: 0.5221 s/iter. ETA=0:02:29\n",
      "\u001b[32m[12/27 12:56:17 d2.evaluation.evaluator]: \u001b[0mInference done 291/570. Dataloading: 0.0035 s/iter. Inference: 0.1001 s/iter. Eval: 0.4250 s/iter. Total: 0.5289 s/iter. ETA=0:02:27\n",
      "\u001b[32m[12/27 12:56:22 d2.evaluation.evaluator]: \u001b[0mInference done 298/570. Dataloading: 0.0035 s/iter. Inference: 0.1001 s/iter. Eval: 0.4298 s/iter. Total: 0.5337 s/iter. ETA=0:02:25\n",
      "\u001b[32m[12/27 12:56:27 d2.evaluation.evaluator]: \u001b[0mInference done 321/570. Dataloading: 0.0034 s/iter. Inference: 0.0996 s/iter. Eval: 0.4079 s/iter. Total: 0.5111 s/iter. ETA=0:02:07\n",
      "\u001b[32m[12/27 12:56:32 d2.evaluation.evaluator]: \u001b[0mInference done 348/570. Dataloading: 0.0033 s/iter. Inference: 0.0990 s/iter. Eval: 0.3829 s/iter. Total: 0.4854 s/iter. ETA=0:01:47\n",
      "\u001b[32m[12/27 12:56:37 d2.evaluation.evaluator]: \u001b[0mInference done 367/570. Dataloading: 0.0032 s/iter. Inference: 0.0989 s/iter. Eval: 0.3731 s/iter. Total: 0.4754 s/iter. ETA=0:01:36\n",
      "\u001b[32m[12/27 12:56:43 d2.evaluation.evaluator]: \u001b[0mInference done 377/570. Dataloading: 0.0032 s/iter. Inference: 0.0989 s/iter. Eval: 0.3741 s/iter. Total: 0.4764 s/iter. ETA=0:01:31\n",
      "\u001b[32m[12/27 12:56:48 d2.evaluation.evaluator]: \u001b[0mInference done 388/570. Dataloading: 0.0031 s/iter. Inference: 0.0990 s/iter. Eval: 0.3749 s/iter. Total: 0.4773 s/iter. ETA=0:01:26\n",
      "\u001b[32m[12/27 12:56:53 d2.evaluation.evaluator]: \u001b[0mInference done 400/570. Dataloading: 0.0031 s/iter. Inference: 0.0991 s/iter. Eval: 0.3735 s/iter. Total: 0.4759 s/iter. ETA=0:01:20\n",
      "\u001b[32m[12/27 12:56:58 d2.evaluation.evaluator]: \u001b[0mInference done 410/570. Dataloading: 0.0031 s/iter. Inference: 0.0991 s/iter. Eval: 0.3744 s/iter. Total: 0.4769 s/iter. ETA=0:01:16\n",
      "\u001b[32m[12/27 12:57:04 d2.evaluation.evaluator]: \u001b[0mInference done 419/570. Dataloading: 0.0030 s/iter. Inference: 0.0992 s/iter. Eval: 0.3763 s/iter. Total: 0.4788 s/iter. ETA=0:01:12\n",
      "\u001b[32m[12/27 12:57:09 d2.evaluation.evaluator]: \u001b[0mInference done 429/570. Dataloading: 0.0030 s/iter. Inference: 0.0993 s/iter. Eval: 0.3776 s/iter. Total: 0.4801 s/iter. ETA=0:01:07\n",
      "\u001b[32m[12/27 12:57:14 d2.evaluation.evaluator]: \u001b[0mInference done 440/570. Dataloading: 0.0030 s/iter. Inference: 0.0993 s/iter. Eval: 0.3779 s/iter. Total: 0.4805 s/iter. ETA=0:01:02\n",
      "\u001b[32m[12/27 12:57:19 d2.evaluation.evaluator]: \u001b[0mInference done 453/570. Dataloading: 0.0030 s/iter. Inference: 0.0993 s/iter. Eval: 0.3753 s/iter. Total: 0.4778 s/iter. ETA=0:00:55\n",
      "\u001b[32m[12/27 12:57:25 d2.evaluation.evaluator]: \u001b[0mInference done 474/570. Dataloading: 0.0029 s/iter. Inference: 0.0992 s/iter. Eval: 0.3655 s/iter. Total: 0.4679 s/iter. ETA=0:00:44\n",
      "\u001b[32m[12/27 12:57:31 d2.evaluation.evaluator]: \u001b[0mInference done 493/570. Dataloading: 0.0029 s/iter. Inference: 0.0991 s/iter. Eval: 0.3593 s/iter. Total: 0.4614 s/iter. ETA=0:00:35\n",
      "\u001b[32m[12/27 12:57:36 d2.evaluation.evaluator]: \u001b[0mInference done 503/570. Dataloading: 0.0029 s/iter. Inference: 0.0989 s/iter. Eval: 0.3605 s/iter. Total: 0.4625 s/iter. ETA=0:00:30\n",
      "\u001b[32m[12/27 12:57:41 d2.evaluation.evaluator]: \u001b[0mInference done 515/570. Dataloading: 0.0028 s/iter. Inference: 0.0987 s/iter. Eval: 0.3602 s/iter. Total: 0.4619 s/iter. ETA=0:00:25\n",
      "\u001b[32m[12/27 12:57:46 d2.evaluation.evaluator]: \u001b[0mInference done 530/570. Dataloading: 0.0028 s/iter. Inference: 0.0985 s/iter. Eval: 0.3572 s/iter. Total: 0.4587 s/iter. ETA=0:00:18\n",
      "\u001b[32m[12/27 12:57:51 d2.evaluation.evaluator]: \u001b[0mInference done 541/570. Dataloading: 0.0028 s/iter. Inference: 0.0983 s/iter. Eval: 0.3574 s/iter. Total: 0.4587 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/27 12:57:57 d2.evaluation.evaluator]: \u001b[0mInference done 551/570. Dataloading: 0.0028 s/iter. Inference: 0.0982 s/iter. Eval: 0.3593 s/iter. Total: 0.4604 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/27 12:58:02 d2.evaluation.evaluator]: \u001b[0mInference done 564/570. Dataloading: 0.0028 s/iter. Inference: 0.0979 s/iter. Eval: 0.3584 s/iter. Total: 0.4593 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/27 12:58:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:19.724777 (0.459690 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 12:58:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:55 (0.097847 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 12:58:05 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/27 12:58:05 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.24605246751775223\n",
      "\u001b[32m[12/27 12:58:08 d2.utils.events]: \u001b[0m eta: 0:39:25  iter: 4819  total_loss: 1.355  loss_cls: 0.3504  loss_box_reg: 0.4029  loss_mask: 0.2545  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.1857  time: 0.4885  data_time: 0.0164  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:58:17 d2.utils.events]: \u001b[0m eta: 0:39:17  iter: 4839  total_loss: 1.331  loss_cls: 0.3355  loss_box_reg: 0.4507  loss_mask: 0.2643  loss_rpn_cls: 0.09739  loss_rpn_loc: 0.1759  time: 0.4885  data_time: 0.0149  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:58:27 d2.utils.events]: \u001b[0m eta: 0:39:08  iter: 4859  total_loss: 1.484  loss_cls: 0.3767  loss_box_reg: 0.4641  loss_mask: 0.2809  loss_rpn_cls: 0.09221  loss_rpn_loc: 0.1743  time: 0.4885  data_time: 0.0167  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:58:36 d2.utils.events]: \u001b[0m eta: 0:38:58  iter: 4879  total_loss: 1.344  loss_cls: 0.3763  loss_box_reg: 0.3934  loss_mask: 0.2702  loss_rpn_cls: 0.0971  loss_rpn_loc: 0.1821  time: 0.4883  data_time: 0.0148  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:58:45 d2.utils.events]: \u001b[0m eta: 0:38:49  iter: 4899  total_loss: 1.208  loss_cls: 0.3379  loss_box_reg: 0.3874  loss_mask: 0.2704  loss_rpn_cls: 0.07894  loss_rpn_loc: 0.1821  time: 0.4882  data_time: 0.0153  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:58:54 d2.utils.events]: \u001b[0m eta: 0:38:40  iter: 4919  total_loss: 1.465  loss_cls: 0.4092  loss_box_reg: 0.4465  loss_mask: 0.2783  loss_rpn_cls: 0.1167  loss_rpn_loc: 0.2158  time: 0.4881  data_time: 0.0178  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:59:04 d2.utils.events]: \u001b[0m eta: 0:38:31  iter: 4939  total_loss: 1.35  loss_cls: 0.3704  loss_box_reg: 0.4187  loss_mask: 0.2743  loss_rpn_cls: 0.1022  loss_rpn_loc: 0.1928  time: 0.4880  data_time: 0.0148  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:59:13 d2.utils.events]: \u001b[0m eta: 0:38:21  iter: 4959  total_loss: 1.421  loss_cls: 0.3881  loss_box_reg: 0.4363  loss_mask: 0.2643  loss_rpn_cls: 0.09389  loss_rpn_loc: 0.2136  time: 0.4880  data_time: 0.0145  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:59:22 d2.utils.events]: \u001b[0m eta: 0:38:12  iter: 4979  total_loss: 1.294  loss_cls: 0.356  loss_box_reg: 0.4207  loss_mask: 0.2553  loss_rpn_cls: 0.07733  loss_rpn_loc: 0.1691  time: 0.4878  data_time: 0.0130  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:59:31 d2.utils.events]: \u001b[0m eta: 0:38:03  iter: 4999  total_loss: 1.394  loss_cls: 0.3647  loss_box_reg: 0.4367  loss_mask: 0.2847  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.1886  time: 0.4877  data_time: 0.0141  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:59:41 d2.utils.events]: \u001b[0m eta: 0:37:54  iter: 5019  total_loss: 1.448  loss_cls: 0.4174  loss_box_reg: 0.4235  loss_mask: 0.2655  loss_rpn_cls: 0.09412  loss_rpn_loc: 0.1787  time: 0.4876  data_time: 0.0147  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:59:50 d2.utils.events]: \u001b[0m eta: 0:37:44  iter: 5039  total_loss: 1.379  loss_cls: 0.382  loss_box_reg: 0.4237  loss_mask: 0.2754  loss_rpn_cls: 0.1027  loss_rpn_loc: 0.212  time: 0.4874  data_time: 0.0138  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 12:59:59 d2.utils.events]: \u001b[0m eta: 0:37:33  iter: 5059  total_loss: 1.476  loss_cls: 0.4539  loss_box_reg: 0.4457  loss_mask: 0.2782  loss_rpn_cls: 0.09615  loss_rpn_loc: 0.2154  time: 0.4873  data_time: 0.0171  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:00:08 d2.utils.events]: \u001b[0m eta: 0:37:20  iter: 5079  total_loss: 1.349  loss_cls: 0.3669  loss_box_reg: 0.4234  loss_mask: 0.257  loss_rpn_cls: 0.0715  loss_rpn_loc: 0.1696  time: 0.4871  data_time: 0.0138  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:00:17 d2.utils.events]: \u001b[0m eta: 0:37:11  iter: 5099  total_loss: 1.422  loss_cls: 0.4121  loss_box_reg: 0.437  loss_mask: 0.2733  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.1903  time: 0.4871  data_time: 0.0147  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:00:26 d2.utils.events]: \u001b[0m eta: 0:37:02  iter: 5119  total_loss: 1.409  loss_cls: 0.4261  loss_box_reg: 0.4468  loss_mask: 0.2733  loss_rpn_cls: 0.0954  loss_rpn_loc: 0.1815  time: 0.4870  data_time: 0.0131  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:00:35 d2.utils.events]: \u001b[0m eta: 0:36:52  iter: 5139  total_loss: 1.492  loss_cls: 0.4337  loss_box_reg: 0.4417  loss_mask: 0.2669  loss_rpn_cls: 0.08627  loss_rpn_loc: 0.1726  time: 0.4868  data_time: 0.0136  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:00:45 d2.utils.events]: \u001b[0m eta: 0:36:44  iter: 5159  total_loss: 1.59  loss_cls: 0.4764  loss_box_reg: 0.479  loss_mask: 0.2961  loss_rpn_cls: 0.1343  loss_rpn_loc: 0.222  time: 0.4868  data_time: 0.0154  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:00:54 d2.utils.events]: \u001b[0m eta: 0:36:34  iter: 5179  total_loss: 1.391  loss_cls: 0.3943  loss_box_reg: 0.4167  loss_mask: 0.2793  loss_rpn_cls: 0.08954  loss_rpn_loc: 0.1745  time: 0.4866  data_time: 0.0154  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:01:03 d2.utils.events]: \u001b[0m eta: 0:36:25  iter: 5199  total_loss: 1.428  loss_cls: 0.3855  loss_box_reg: 0.4408  loss_mask: 0.2667  loss_rpn_cls: 0.079  loss_rpn_loc: 0.1824  time: 0.4865  data_time: 0.0148  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:01:12 d2.utils.events]: \u001b[0m eta: 0:36:16  iter: 5219  total_loss: 1.25  loss_cls: 0.3367  loss_box_reg: 0.4082  loss_mask: 0.2703  loss_rpn_cls: 0.08116  loss_rpn_loc: 0.1738  time: 0.4865  data_time: 0.0161  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:01:21 d2.utils.events]: \u001b[0m eta: 0:36:06  iter: 5239  total_loss: 1.318  loss_cls: 0.3679  loss_box_reg: 0.3702  loss_mask: 0.2608  loss_rpn_cls: 0.08876  loss_rpn_loc: 0.1769  time: 0.4863  data_time: 0.0151  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:01:30 d2.utils.events]: \u001b[0m eta: 0:35:53  iter: 5259  total_loss: 1.336  loss_cls: 0.3859  loss_box_reg: 0.4496  loss_mask: 0.2561  loss_rpn_cls: 0.05119  loss_rpn_loc: 0.1661  time: 0.4861  data_time: 0.0122  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:01:39 d2.utils.events]: \u001b[0m eta: 0:35:43  iter: 5279  total_loss: 1.385  loss_cls: 0.336  loss_box_reg: 0.3946  loss_mask: 0.2577  loss_rpn_cls: 0.08115  loss_rpn_loc: 0.177  time: 0.4860  data_time: 0.0140  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:01:48 d2.utils.events]: \u001b[0m eta: 0:35:34  iter: 5299  total_loss: 1.386  loss_cls: 0.3702  loss_box_reg: 0.4503  loss_mask: 0.2654  loss_rpn_cls: 0.1037  loss_rpn_loc: 0.1883  time: 0.4858  data_time: 0.0141  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:01:57 d2.utils.events]: \u001b[0m eta: 0:35:25  iter: 5319  total_loss: 1.428  loss_cls: 0.3845  loss_box_reg: 0.4402  loss_mask: 0.2793  loss_rpn_cls: 0.09794  loss_rpn_loc: 0.2069  time: 0.4858  data_time: 0.0157  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:02:07 d2.utils.events]: \u001b[0m eta: 0:35:16  iter: 5339  total_loss: 1.406  loss_cls: 0.3922  loss_box_reg: 0.4376  loss_mask: 0.2808  loss_rpn_cls: 0.1079  loss_rpn_loc: 0.2135  time: 0.4858  data_time: 0.0178  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:02:16 d2.utils.events]: \u001b[0m eta: 0:35:07  iter: 5359  total_loss: 1.423  loss_cls: 0.3896  loss_box_reg: 0.4591  loss_mask: 0.2829  loss_rpn_cls: 0.08785  loss_rpn_loc: 0.2024  time: 0.4857  data_time: 0.0145  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:02:17 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7faf6314e950> to CPU due to CUDA OOM\n",
      "\u001b[32m[12/27 13:02:46 d2.utils.events]: \u001b[0m eta: 0:34:58  iter: 5379  total_loss: 1.394  loss_cls: 0.3954  loss_box_reg: 0.4335  loss_mask: 0.2928  loss_rpn_cls: 0.09761  loss_rpn_loc: 0.1777  time: 0.4894  data_time: 0.0177  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:02:55 d2.utils.events]: \u001b[0m eta: 0:34:49  iter: 5399  total_loss: 1.285  loss_cls: 0.3526  loss_box_reg: 0.4066  loss_mask: 0.2593  loss_rpn_cls: 0.07154  loss_rpn_loc: 0.1739  time: 0.4893  data_time: 0.0143  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:03:05 d2.utils.events]: \u001b[0m eta: 0:34:42  iter: 5419  total_loss: 1.386  loss_cls: 0.3561  loss_box_reg: 0.4158  loss_mask: 0.2862  loss_rpn_cls: 0.08618  loss_rpn_loc: 0.2046  time: 0.4893  data_time: 0.0169  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:03:14 d2.utils.events]: \u001b[0m eta: 0:34:33  iter: 5439  total_loss: 1.345  loss_cls: 0.3525  loss_box_reg: 0.4081  loss_mask: 0.2841  loss_rpn_cls: 0.08851  loss_rpn_loc: 0.1935  time: 0.4892  data_time: 0.0161  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:03:23 d2.utils.events]: \u001b[0m eta: 0:34:21  iter: 5459  total_loss: 1.352  loss_cls: 0.3784  loss_box_reg: 0.4508  loss_mask: 0.2795  loss_rpn_cls: 0.07784  loss_rpn_loc: 0.1935  time: 0.4890  data_time: 0.0128  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:03:32 d2.utils.events]: \u001b[0m eta: 0:34:14  iter: 5479  total_loss: 1.369  loss_cls: 0.3785  loss_box_reg: 0.4112  loss_mask: 0.2781  loss_rpn_cls: 0.118  loss_rpn_loc: 0.1898  time: 0.4889  data_time: 0.0150  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:03:42 d2.utils.events]: \u001b[0m eta: 0:34:03  iter: 5499  total_loss: 1.375  loss_cls: 0.408  loss_box_reg: 0.4307  loss_mask: 0.2828  loss_rpn_cls: 0.1091  loss_rpn_loc: 0.1854  time: 0.4888  data_time: 0.0132  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:03:51 d2.utils.events]: \u001b[0m eta: 0:33:55  iter: 5519  total_loss: 1.352  loss_cls: 0.3406  loss_box_reg: 0.4062  loss_mask: 0.2672  loss_rpn_cls: 0.08098  loss_rpn_loc: 0.178  time: 0.4887  data_time: 0.0160  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:04:01 d2.utils.events]: \u001b[0m eta: 0:33:49  iter: 5539  total_loss: 1.386  loss_cls: 0.4082  loss_box_reg: 0.4446  loss_mask: 0.2684  loss_rpn_cls: 0.1136  loss_rpn_loc: 0.2005  time: 0.4887  data_time: 0.0320  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:04:10 d2.utils.events]: \u001b[0m eta: 0:33:41  iter: 5559  total_loss: 1.376  loss_cls: 0.3696  loss_box_reg: 0.4394  loss_mask: 0.2704  loss_rpn_cls: 0.09322  loss_rpn_loc: 0.1921  time: 0.4886  data_time: 0.0160  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:04:19 d2.utils.events]: \u001b[0m eta: 0:33:32  iter: 5579  total_loss: 1.452  loss_cls: 0.3629  loss_box_reg: 0.4397  loss_mask: 0.2863  loss_rpn_cls: 0.08234  loss_rpn_loc: 0.1971  time: 0.4885  data_time: 0.0151  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:04:28 d2.utils.events]: \u001b[0m eta: 0:33:22  iter: 5599  total_loss: 1.375  loss_cls: 0.3694  loss_box_reg: 0.4378  loss_mask: 0.2852  loss_rpn_cls: 0.09403  loss_rpn_loc: 0.1905  time: 0.4884  data_time: 0.0151  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:04:37 d2.utils.events]: \u001b[0m eta: 0:33:12  iter: 5619  total_loss: 1.429  loss_cls: 0.3876  loss_box_reg: 0.5243  loss_mask: 0.2992  loss_rpn_cls: 0.09491  loss_rpn_loc: 0.1808  time: 0.4882  data_time: 0.0123  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:04:46 d2.utils.events]: \u001b[0m eta: 0:33:02  iter: 5639  total_loss: 1.247  loss_cls: 0.3259  loss_box_reg: 0.4038  loss_mask: 0.2516  loss_rpn_cls: 0.07643  loss_rpn_loc: 0.1827  time: 0.4881  data_time: 0.0141  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:04:56 d2.utils.events]: \u001b[0m eta: 0:32:53  iter: 5659  total_loss: 1.322  loss_cls: 0.3881  loss_box_reg: 0.3988  loss_mask: 0.2619  loss_rpn_cls: 0.09062  loss_rpn_loc: 0.1894  time: 0.4881  data_time: 0.0158  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:05:05 d2.utils.events]: \u001b[0m eta: 0:32:44  iter: 5679  total_loss: 1.275  loss_cls: 0.3481  loss_box_reg: 0.4053  loss_mask: 0.2617  loss_rpn_cls: 0.07847  loss_rpn_loc: 0.176  time: 0.4879  data_time: 0.0149  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:05:14 d2.utils.events]: \u001b[0m eta: 0:32:34  iter: 5699  total_loss: 1.389  loss_cls: 0.3706  loss_box_reg: 0.4282  loss_mask: 0.2735  loss_rpn_cls: 0.09383  loss_rpn_loc: 0.1906  time: 0.4879  data_time: 0.0152  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:05:23 d2.utils.events]: \u001b[0m eta: 0:32:24  iter: 5719  total_loss: 1.377  loss_cls: 0.4103  loss_box_reg: 0.4277  loss_mask: 0.2782  loss_rpn_cls: 0.08586  loss_rpn_loc: 0.1832  time: 0.4877  data_time: 0.0144  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:05:33 d2.utils.events]: \u001b[0m eta: 0:32:14  iter: 5739  total_loss: 1.435  loss_cls: 0.4266  loss_box_reg: 0.4672  loss_mask: 0.2736  loss_rpn_cls: 0.08126  loss_rpn_loc: 0.1897  time: 0.4877  data_time: 0.0249  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:05:42 d2.utils.events]: \u001b[0m eta: 0:32:03  iter: 5759  total_loss: 1.27  loss_cls: 0.3401  loss_box_reg: 0.3862  loss_mask: 0.2682  loss_rpn_cls: 0.0888  loss_rpn_loc: 0.2006  time: 0.4876  data_time: 0.0146  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:05:51 d2.utils.events]: \u001b[0m eta: 0:31:54  iter: 5779  total_loss: 1.327  loss_cls: 0.3517  loss_box_reg: 0.408  loss_mask: 0.2683  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.1839  time: 0.4875  data_time: 0.0150  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:06:00 d2.utils.events]: \u001b[0m eta: 0:31:44  iter: 5799  total_loss: 1.25  loss_cls: 0.3213  loss_box_reg: 0.4078  loss_mask: 0.257  loss_rpn_cls: 0.07206  loss_rpn_loc: 0.1883  time: 0.4874  data_time: 0.0133  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:06:09 d2.utils.events]: \u001b[0m eta: 0:31:34  iter: 5819  total_loss: 1.329  loss_cls: 0.3885  loss_box_reg: 0.4321  loss_mask: 0.2673  loss_rpn_cls: 0.07927  loss_rpn_loc: 0.1722  time: 0.4873  data_time: 0.0157  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:06:19 d2.utils.events]: \u001b[0m eta: 0:31:23  iter: 5839  total_loss: 1.343  loss_cls: 0.3765  loss_box_reg: 0.4111  loss_mask: 0.2644  loss_rpn_cls: 0.08386  loss_rpn_loc: 0.1926  time: 0.4871  data_time: 0.0152  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:06:28 d2.utils.events]: \u001b[0m eta: 0:31:13  iter: 5859  total_loss: 1.351  loss_cls: 0.3542  loss_box_reg: 0.3948  loss_mask: 0.2633  loss_rpn_cls: 0.08322  loss_rpn_loc: 0.205  time: 0.4871  data_time: 0.0166  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:06:37 d2.utils.events]: \u001b[0m eta: 0:31:04  iter: 5879  total_loss: 1.309  loss_cls: 0.3713  loss_box_reg: 0.4305  loss_mask: 0.2578  loss_rpn_cls: 0.07467  loss_rpn_loc: 0.1783  time: 0.4870  data_time: 0.0138  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:06:46 d2.utils.events]: \u001b[0m eta: 0:30:53  iter: 5899  total_loss: 1.503  loss_cls: 0.4426  loss_box_reg: 0.4501  loss_mask: 0.2802  loss_rpn_cls: 0.1075  loss_rpn_loc: 0.1787  time: 0.4868  data_time: 0.0137  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:06:55 d2.utils.events]: \u001b[0m eta: 0:30:45  iter: 5919  total_loss: 1.411  loss_cls: 0.3954  loss_box_reg: 0.4325  loss_mask: 0.2813  loss_rpn_cls: 0.07651  loss_rpn_loc: 0.1807  time: 0.4868  data_time: 0.0142  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:07:05 d2.utils.events]: \u001b[0m eta: 0:30:36  iter: 5939  total_loss: 1.578  loss_cls: 0.4697  loss_box_reg: 0.466  loss_mask: 0.2953  loss_rpn_cls: 0.1088  loss_rpn_loc: 0.196  time: 0.4867  data_time: 0.0153  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:07:14 d2.utils.events]: \u001b[0m eta: 0:30:27  iter: 5959  total_loss: 1.438  loss_cls: 0.4112  loss_box_reg: 0.4597  loss_mask: 0.2726  loss_rpn_cls: 0.09567  loss_rpn_loc: 0.1954  time: 0.4866  data_time: 0.0159  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:07:23 d2.utils.events]: \u001b[0m eta: 0:30:17  iter: 5979  total_loss: 1.446  loss_cls: 0.4079  loss_box_reg: 0.4476  loss_mask: 0.2609  loss_rpn_cls: 0.09556  loss_rpn_loc: 0.1808  time: 0.4865  data_time: 0.0125  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:07:32 d2.utils.events]: \u001b[0m eta: 0:30:07  iter: 5999  total_loss: 1.405  loss_cls: 0.3761  loss_box_reg: 0.4464  loss_mask: 0.278  loss_rpn_cls: 0.1001  loss_rpn_loc: 0.2012  time: 0.4864  data_time: 0.0153  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:07:41 d2.utils.events]: \u001b[0m eta: 0:29:58  iter: 6019  total_loss: 1.371  loss_cls: 0.3581  loss_box_reg: 0.4379  loss_mask: 0.268  loss_rpn_cls: 0.09832  loss_rpn_loc: 0.2085  time: 0.4863  data_time: 0.0151  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:07:51 d2.utils.events]: \u001b[0m eta: 0:29:51  iter: 6039  total_loss: 1.378  loss_cls: 0.3958  loss_box_reg: 0.4378  loss_mask: 0.2802  loss_rpn_cls: 0.09647  loss_rpn_loc: 0.1903  time: 0.4862  data_time: 0.0141  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:08:00 d2.utils.events]: \u001b[0m eta: 0:29:41  iter: 6059  total_loss: 1.333  loss_cls: 0.386  loss_box_reg: 0.3978  loss_mask: 0.2658  loss_rpn_cls: 0.09346  loss_rpn_loc: 0.2049  time: 0.4861  data_time: 0.0152  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:08:09 d2.utils.events]: \u001b[0m eta: 0:29:33  iter: 6079  total_loss: 1.393  loss_cls: 0.4045  loss_box_reg: 0.4332  loss_mask: 0.2658  loss_rpn_cls: 0.09947  loss_rpn_loc: 0.1885  time: 0.4860  data_time: 0.0234  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:08:18 d2.utils.events]: \u001b[0m eta: 0:29:25  iter: 6099  total_loss: 1.503  loss_cls: 0.3824  loss_box_reg: 0.423  loss_mask: 0.2922  loss_rpn_cls: 0.1422  loss_rpn_loc: 0.199  time: 0.4860  data_time: 0.0167  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:08:28 d2.utils.events]: \u001b[0m eta: 0:29:15  iter: 6119  total_loss: 1.368  loss_cls: 0.3609  loss_box_reg: 0.394  loss_mask: 0.267  loss_rpn_cls: 0.0806  loss_rpn_loc: 0.1917  time: 0.4859  data_time: 0.0148  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:08:37 d2.utils.events]: \u001b[0m eta: 0:29:08  iter: 6139  total_loss: 1.316  loss_cls: 0.3448  loss_box_reg: 0.4528  loss_mask: 0.2563  loss_rpn_cls: 0.08396  loss_rpn_loc: 0.1773  time: 0.4859  data_time: 0.0145  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:08:47 d2.utils.events]: \u001b[0m eta: 0:28:58  iter: 6159  total_loss: 1.358  loss_cls: 0.374  loss_box_reg: 0.4403  loss_mask: 0.2815  loss_rpn_cls: 0.09482  loss_rpn_loc: 0.1886  time: 0.4858  data_time: 0.0179  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:08:56 d2.utils.events]: \u001b[0m eta: 0:28:51  iter: 6179  total_loss: 1.235  loss_cls: 0.3535  loss_box_reg: 0.3932  loss_mask: 0.2663  loss_rpn_cls: 0.07919  loss_rpn_loc: 0.1769  time: 0.4858  data_time: 0.0151  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:09:05 d2.utils.events]: \u001b[0m eta: 0:28:42  iter: 6199  total_loss: 1.436  loss_cls: 0.4234  loss_box_reg: 0.437  loss_mask: 0.2876  loss_rpn_cls: 0.1032  loss_rpn_loc: 0.1947  time: 0.4857  data_time: 0.0145  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:09:15 d2.utils.events]: \u001b[0m eta: 0:28:33  iter: 6219  total_loss: 1.449  loss_cls: 0.4061  loss_box_reg: 0.443  loss_mask: 0.2933  loss_rpn_cls: 0.101  loss_rpn_loc: 0.197  time: 0.4856  data_time: 0.0275  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:09:24 d2.utils.events]: \u001b[0m eta: 0:28:25  iter: 6239  total_loss: 1.526  loss_cls: 0.4646  loss_box_reg: 0.4546  loss_mask: 0.266  loss_rpn_cls: 0.09892  loss_rpn_loc: 0.1842  time: 0.4855  data_time: 0.0128  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:09:33 d2.utils.events]: \u001b[0m eta: 0:28:20  iter: 6259  total_loss: 1.365  loss_cls: 0.3869  loss_box_reg: 0.4247  loss_mask: 0.2586  loss_rpn_cls: 0.07824  loss_rpn_loc: 0.1835  time: 0.4855  data_time: 0.0162  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:09:42 d2.utils.events]: \u001b[0m eta: 0:28:12  iter: 6279  total_loss: 1.477  loss_cls: 0.4307  loss_box_reg: 0.457  loss_mask: 0.2782  loss_rpn_cls: 0.09643  loss_rpn_loc: 0.1923  time: 0.4854  data_time: 0.0147  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:09:51 d2.utils.events]: \u001b[0m eta: 0:28:03  iter: 6299  total_loss: 1.448  loss_cls: 0.3892  loss_box_reg: 0.4055  loss_mask: 0.2709  loss_rpn_cls: 0.08867  loss_rpn_loc: 0.2015  time: 0.4853  data_time: 0.0164  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:10:00 d2.utils.events]: \u001b[0m eta: 0:27:54  iter: 6319  total_loss: 1.305  loss_cls: 0.3499  loss_box_reg: 0.4114  loss_mask: 0.2686  loss_rpn_cls: 0.07081  loss_rpn_loc: 0.1894  time: 0.4852  data_time: 0.0146  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:10:10 d2.utils.events]: \u001b[0m eta: 0:27:46  iter: 6339  total_loss: 1.311  loss_cls: 0.4039  loss_box_reg: 0.3881  loss_mask: 0.2619  loss_rpn_cls: 0.08019  loss_rpn_loc: 0.1829  time: 0.4851  data_time: 0.0138  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:10:19 d2.utils.events]: \u001b[0m eta: 0:27:38  iter: 6359  total_loss: 1.287  loss_cls: 0.3533  loss_box_reg: 0.4254  loss_mask: 0.2661  loss_rpn_cls: 0.09768  loss_rpn_loc: 0.171  time: 0.4851  data_time: 0.0277  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:10:29 d2.utils.events]: \u001b[0m eta: 0:27:27  iter: 6379  total_loss: 1.383  loss_cls: 0.3871  loss_box_reg: 0.4436  loss_mask: 0.2743  loss_rpn_cls: 0.09753  loss_rpn_loc: 0.2019  time: 0.4850  data_time: 0.0147  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:10:38 d2.utils.events]: \u001b[0m eta: 0:27:19  iter: 6399  total_loss: 1.345  loss_cls: 0.356  loss_box_reg: 0.3808  loss_mask: 0.2572  loss_rpn_cls: 0.1098  loss_rpn_loc: 0.1956  time: 0.4849  data_time: 0.0152  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:10:47 d2.utils.events]: \u001b[0m eta: 0:27:08  iter: 6419  total_loss: 1.333  loss_cls: 0.3639  loss_box_reg: 0.4055  loss_mask: 0.2741  loss_rpn_cls: 0.08693  loss_rpn_loc: 0.1919  time: 0.4849  data_time: 0.0162  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:10:56 d2.utils.events]: \u001b[0m eta: 0:27:00  iter: 6439  total_loss: 1.29  loss_cls: 0.3284  loss_box_reg: 0.4165  loss_mask: 0.2691  loss_rpn_cls: 0.08934  loss_rpn_loc: 0.1768  time: 0.4848  data_time: 0.0167  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:11:06 d2.utils.events]: \u001b[0m eta: 0:26:53  iter: 6459  total_loss: 1.29  loss_cls: 0.3081  loss_box_reg: 0.4135  loss_mask: 0.285  loss_rpn_cls: 0.08942  loss_rpn_loc: 0.177  time: 0.4848  data_time: 0.0234  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:11:15 d2.utils.events]: \u001b[0m eta: 0:26:42  iter: 6479  total_loss: 1.293  loss_cls: 0.3348  loss_box_reg: 0.4143  loss_mask: 0.2597  loss_rpn_cls: 0.07507  loss_rpn_loc: 0.1716  time: 0.4846  data_time: 0.0132  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:11:24 d2.utils.events]: \u001b[0m eta: 0:26:33  iter: 6499  total_loss: 1.406  loss_cls: 0.3768  loss_box_reg: 0.453  loss_mask: 0.2683  loss_rpn_cls: 0.08474  loss_rpn_loc: 0.1949  time: 0.4845  data_time: 0.0153  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:11:27 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7faf6314e950> to CPU due to CUDA OOM\n",
      "\u001b[32m[12/27 13:11:55 d2.utils.events]: \u001b[0m eta: 0:26:25  iter: 6519  total_loss: 1.298  loss_cls: 0.3217  loss_box_reg: 0.3877  loss_mask: 0.2557  loss_rpn_cls: 0.09542  loss_rpn_loc: 0.1811  time: 0.4879  data_time: 0.0168  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:12:05 d2.utils.events]: \u001b[0m eta: 0:26:16  iter: 6539  total_loss: 1.346  loss_cls: 0.3285  loss_box_reg: 0.4125  loss_mask: 0.2508  loss_rpn_cls: 0.09825  loss_rpn_loc: 0.1921  time: 0.4878  data_time: 0.0169  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:12:14 d2.utils.events]: \u001b[0m eta: 0:26:07  iter: 6559  total_loss: 1.329  loss_cls: 0.3393  loss_box_reg: 0.4225  loss_mask: 0.2712  loss_rpn_cls: 0.09939  loss_rpn_loc: 0.21  time: 0.4878  data_time: 0.0150  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:12:23 d2.utils.events]: \u001b[0m eta: 0:25:58  iter: 6579  total_loss: 1.391  loss_cls: 0.3893  loss_box_reg: 0.4578  loss_mask: 0.2784  loss_rpn_cls: 0.07902  loss_rpn_loc: 0.2001  time: 0.4877  data_time: 0.0168  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:12:32 d2.utils.events]: \u001b[0m eta: 0:25:50  iter: 6599  total_loss: 1.432  loss_cls: 0.4182  loss_box_reg: 0.4377  loss_mask: 0.2797  loss_rpn_cls: 0.08497  loss_rpn_loc: 0.1718  time: 0.4876  data_time: 0.0138  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:12:41 d2.utils.events]: \u001b[0m eta: 0:25:42  iter: 6619  total_loss: 1.287  loss_cls: 0.369  loss_box_reg: 0.3937  loss_mask: 0.2647  loss_rpn_cls: 0.08902  loss_rpn_loc: 0.1716  time: 0.4874  data_time: 0.0146  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:12:50 d2.utils.events]: \u001b[0m eta: 0:25:33  iter: 6639  total_loss: 1.292  loss_cls: 0.3719  loss_box_reg: 0.4076  loss_mask: 0.2669  loss_rpn_cls: 0.08543  loss_rpn_loc: 0.164  time: 0.4874  data_time: 0.0150  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:12:56 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7faf6314e950> to CPU due to CUDA OOM\n",
      "\u001b[32m[12/27 13:13:19 d2.utils.events]: \u001b[0m eta: 0:25:22  iter: 6659  total_loss: 1.414  loss_cls: 0.3693  loss_box_reg: 0.4537  loss_mask: 0.2865  loss_rpn_cls: 0.08225  loss_rpn_loc: 0.1825  time: 0.4902  data_time: 0.0196  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:13:29 d2.utils.events]: \u001b[0m eta: 0:25:13  iter: 6679  total_loss: 1.361  loss_cls: 0.3888  loss_box_reg: 0.4142  loss_mask: 0.2568  loss_rpn_cls: 0.08726  loss_rpn_loc: 0.1881  time: 0.4902  data_time: 0.0350  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:13:38 d2.utils.events]: \u001b[0m eta: 0:25:02  iter: 6699  total_loss: 1.488  loss_cls: 0.3948  loss_box_reg: 0.4589  loss_mask: 0.2942  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.1943  time: 0.4901  data_time: 0.0135  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:13:47 d2.utils.events]: \u001b[0m eta: 0:24:53  iter: 6719  total_loss: 1.312  loss_cls: 0.371  loss_box_reg: 0.4545  loss_mask: 0.27  loss_rpn_cls: 0.07847  loss_rpn_loc: 0.1774  time: 0.4899  data_time: 0.0122  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:13:56 d2.utils.events]: \u001b[0m eta: 0:24:44  iter: 6739  total_loss: 1.288  loss_cls: 0.3649  loss_box_reg: 0.4294  loss_mask: 0.2581  loss_rpn_cls: 0.0786  loss_rpn_loc: 0.1736  time: 0.4898  data_time: 0.0141  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:14:05 d2.utils.events]: \u001b[0m eta: 0:24:36  iter: 6759  total_loss: 1.314  loss_cls: 0.3853  loss_box_reg: 0.4269  loss_mask: 0.2561  loss_rpn_cls: 0.06944  loss_rpn_loc: 0.1868  time: 0.4898  data_time: 0.0311  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:14:14 d2.utils.events]: \u001b[0m eta: 0:24:26  iter: 6779  total_loss: 1.33  loss_cls: 0.3354  loss_box_reg: 0.4075  loss_mask: 0.2754  loss_rpn_cls: 0.08551  loss_rpn_loc: 0.1857  time: 0.4897  data_time: 0.0159  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:14:23 d2.utils.events]: \u001b[0m eta: 0:24:19  iter: 6799  total_loss: 1.407  loss_cls: 0.3897  loss_box_reg: 0.4574  loss_mask: 0.2758  loss_rpn_cls: 0.1034  loss_rpn_loc: 0.1912  time: 0.4896  data_time: 0.0144  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:14:33 d2.utils.events]: \u001b[0m eta: 0:24:11  iter: 6819  total_loss: 1.287  loss_cls: 0.337  loss_box_reg: 0.4503  loss_mask: 0.2723  loss_rpn_cls: 0.07008  loss_rpn_loc: 0.1689  time: 0.4895  data_time: 0.0145  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:14:42 d2.utils.events]: \u001b[0m eta: 0:24:00  iter: 6839  total_loss: 1.354  loss_cls: 0.3976  loss_box_reg: 0.4563  loss_mask: 0.2724  loss_rpn_cls: 0.09613  loss_rpn_loc: 0.1783  time: 0.4894  data_time: 0.0126  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:14:51 d2.utils.events]: \u001b[0m eta: 0:23:50  iter: 6859  total_loss: 1.338  loss_cls: 0.3669  loss_box_reg: 0.4179  loss_mask: 0.2613  loss_rpn_cls: 0.08023  loss_rpn_loc: 0.1864  time: 0.4893  data_time: 0.0160  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:15:00 d2.utils.events]: \u001b[0m eta: 0:23:41  iter: 6879  total_loss: 1.426  loss_cls: 0.427  loss_box_reg: 0.4533  loss_mask: 0.2878  loss_rpn_cls: 0.09545  loss_rpn_loc: 0.1858  time: 0.4892  data_time: 0.0137  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:15:09 d2.utils.events]: \u001b[0m eta: 0:23:32  iter: 6899  total_loss: 1.513  loss_cls: 0.4257  loss_box_reg: 0.4851  loss_mask: 0.2827  loss_rpn_cls: 0.1311  loss_rpn_loc: 0.2095  time: 0.4890  data_time: 0.0155  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:15:10 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7faf6314e950> to CPU due to CUDA OOM\n",
      "\u001b[32m[12/27 13:15:41 d2.utils.events]: \u001b[0m eta: 0:23:25  iter: 6919  total_loss: 1.315  loss_cls: 0.3566  loss_box_reg: 0.4227  loss_mask: 0.267  loss_rpn_cls: 0.0793  loss_rpn_loc: 0.1797  time: 0.4922  data_time: 0.0273  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:15:50 d2.utils.events]: \u001b[0m eta: 0:23:16  iter: 6939  total_loss: 1.396  loss_cls: 0.3823  loss_box_reg: 0.3995  loss_mask: 0.2708  loss_rpn_cls: 0.08583  loss_rpn_loc: 0.2008  time: 0.4922  data_time: 0.0160  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:15:59 d2.utils.events]: \u001b[0m eta: 0:23:07  iter: 6959  total_loss: 1.331  loss_cls: 0.36  loss_box_reg: 0.4134  loss_mask: 0.2778  loss_rpn_cls: 0.07387  loss_rpn_loc: 0.184  time: 0.4921  data_time: 0.0192  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:16:08 d2.utils.events]: \u001b[0m eta: 0:22:56  iter: 6979  total_loss: 1.379  loss_cls: 0.3654  loss_box_reg: 0.4368  loss_mask: 0.2688  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.1939  time: 0.4919  data_time: 0.0145  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:16:17 d2.utils.events]: \u001b[0m eta: 0:22:46  iter: 6999  total_loss: 1.251  loss_cls: 0.3024  loss_box_reg: 0.4099  loss_mask: 0.2504  loss_rpn_cls: 0.08991  loss_rpn_loc: 0.1891  time: 0.4918  data_time: 0.0150  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:16:26 d2.utils.events]: \u001b[0m eta: 0:22:37  iter: 7019  total_loss: 1.441  loss_cls: 0.3948  loss_box_reg: 0.433  loss_mask: 0.2658  loss_rpn_cls: 0.08965  loss_rpn_loc: 0.199  time: 0.4917  data_time: 0.0130  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:16:35 d2.utils.events]: \u001b[0m eta: 0:22:27  iter: 7039  total_loss: 1.266  loss_cls: 0.3405  loss_box_reg: 0.414  loss_mask: 0.2599  loss_rpn_cls: 0.08806  loss_rpn_loc: 0.1814  time: 0.4916  data_time: 0.0144  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:16:44 d2.utils.events]: \u001b[0m eta: 0:22:17  iter: 7059  total_loss: 1.353  loss_cls: 0.3975  loss_box_reg: 0.4352  loss_mask: 0.2633  loss_rpn_cls: 0.1063  loss_rpn_loc: 0.1916  time: 0.4914  data_time: 0.0145  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:16:53 d2.utils.events]: \u001b[0m eta: 0:22:08  iter: 7079  total_loss: 1.273  loss_cls: 0.3411  loss_box_reg: 0.407  loss_mask: 0.2748  loss_rpn_cls: 0.07843  loss_rpn_loc: 0.1735  time: 0.4913  data_time: 0.0133  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:17:02 d2.utils.events]: \u001b[0m eta: 0:21:57  iter: 7099  total_loss: 1.24  loss_cls: 0.3475  loss_box_reg: 0.404  loss_mask: 0.2652  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.1856  time: 0.4912  data_time: 0.0152  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:17:12 d2.utils.events]: \u001b[0m eta: 0:21:48  iter: 7119  total_loss: 1.411  loss_cls: 0.3512  loss_box_reg: 0.4684  loss_mask: 0.2899  loss_rpn_cls: 0.09471  loss_rpn_loc: 0.2015  time: 0.4912  data_time: 0.0147  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:17:21 d2.utils.events]: \u001b[0m eta: 0:21:38  iter: 7139  total_loss: 1.336  loss_cls: 0.3317  loss_box_reg: 0.4202  loss_mask: 0.2723  loss_rpn_cls: 0.108  loss_rpn_loc: 0.203  time: 0.4911  data_time: 0.0153  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:17:30 d2.utils.events]: \u001b[0m eta: 0:21:28  iter: 7159  total_loss: 1.451  loss_cls: 0.4008  loss_box_reg: 0.4279  loss_mask: 0.2818  loss_rpn_cls: 0.1076  loss_rpn_loc: 0.1785  time: 0.4909  data_time: 0.0141  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:17:39 d2.utils.events]: \u001b[0m eta: 0:21:17  iter: 7179  total_loss: 1.418  loss_cls: 0.3712  loss_box_reg: 0.4754  loss_mask: 0.2646  loss_rpn_cls: 0.08782  loss_rpn_loc: 0.1826  time: 0.4908  data_time: 0.0143  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:17:48 d2.utils.events]: \u001b[0m eta: 0:21:08  iter: 7199  total_loss: 1.293  loss_cls: 0.3383  loss_box_reg: 0.4116  loss_mask: 0.2566  loss_rpn_cls: 0.07072  loss_rpn_loc: 0.2076  time: 0.4908  data_time: 0.0152  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:17:57 d2.utils.events]: \u001b[0m eta: 0:20:58  iter: 7219  total_loss: 1.423  loss_cls: 0.3737  loss_box_reg: 0.4188  loss_mask: 0.2897  loss_rpn_cls: 0.09799  loss_rpn_loc: 0.2136  time: 0.4907  data_time: 0.0158  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:18:05 d2.data.datasets.coco]: \u001b[0mLoading /content/livecell/livecell_annotations_val.json takes 4.81 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/27 13:18:05 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/27 13:18:05 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from /content/livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/27 13:18:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 13:18:07 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 13:18:07 d2.data.common]: \u001b[0mSerialized dataset takes 84.21 MiB\n",
      "\u001b[32m[12/27 13:18:11 d2.data.datasets.coco]: \u001b[0mLoading /content/livecell/livecell_annotations_val.json takes 3.71 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/27 13:18:11 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/27 13:18:11 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from /content/livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/27 13:18:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/27 13:18:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0015 s/iter. Inference: 0.1000 s/iter. Eval: 0.2900 s/iter. Total: 0.3915 s/iter. ETA=0:03:38\n",
      "\u001b[32m[12/27 13:18:23 d2.evaluation.evaluator]: \u001b[0mInference done 26/570. Dataloading: 0.0019 s/iter. Inference: 0.1004 s/iter. Eval: 0.2561 s/iter. Total: 0.3587 s/iter. ETA=0:03:15\n",
      "\u001b[32m[12/27 13:18:29 d2.evaluation.evaluator]: \u001b[0mInference done 41/570. Dataloading: 0.0020 s/iter. Inference: 0.1004 s/iter. Eval: 0.2557 s/iter. Total: 0.3582 s/iter. ETA=0:03:09\n",
      "\u001b[32m[12/27 13:18:34 d2.evaluation.evaluator]: \u001b[0mInference done 55/570. Dataloading: 0.0019 s/iter. Inference: 0.1005 s/iter. Eval: 0.2587 s/iter. Total: 0.3614 s/iter. ETA=0:03:06\n",
      "\u001b[32m[12/27 13:18:39 d2.evaluation.evaluator]: \u001b[0mInference done 70/570. Dataloading: 0.0020 s/iter. Inference: 0.1005 s/iter. Eval: 0.2584 s/iter. Total: 0.3611 s/iter. ETA=0:03:00\n",
      "\u001b[32m[12/27 13:18:45 d2.evaluation.evaluator]: \u001b[0mInference done 84/570. Dataloading: 0.0020 s/iter. Inference: 0.1004 s/iter. Eval: 0.2621 s/iter. Total: 0.3647 s/iter. ETA=0:02:57\n",
      "\u001b[32m[12/27 13:18:50 d2.evaluation.evaluator]: \u001b[0mInference done 97/570. Dataloading: 0.0020 s/iter. Inference: 0.1002 s/iter. Eval: 0.2663 s/iter. Total: 0.3687 s/iter. ETA=0:02:54\n",
      "\u001b[32m[12/27 13:18:55 d2.evaluation.evaluator]: \u001b[0mInference done 110/570. Dataloading: 0.0020 s/iter. Inference: 0.1002 s/iter. Eval: 0.2691 s/iter. Total: 0.3714 s/iter. ETA=0:02:50\n",
      "\u001b[32m[12/27 13:19:00 d2.evaluation.evaluator]: \u001b[0mInference done 124/570. Dataloading: 0.0020 s/iter. Inference: 0.1000 s/iter. Eval: 0.2676 s/iter. Total: 0.3698 s/iter. ETA=0:02:44\n",
      "\u001b[32m[12/27 13:19:05 d2.evaluation.evaluator]: \u001b[0mInference done 136/570. Dataloading: 0.0020 s/iter. Inference: 0.0999 s/iter. Eval: 0.2739 s/iter. Total: 0.3760 s/iter. ETA=0:02:43\n",
      "\u001b[32m[12/27 13:19:10 d2.evaluation.evaluator]: \u001b[0mInference done 150/570. Dataloading: 0.0020 s/iter. Inference: 0.0997 s/iter. Eval: 0.2738 s/iter. Total: 0.3756 s/iter. ETA=0:02:37\n",
      "\u001b[32m[12/27 13:19:15 d2.evaluation.evaluator]: \u001b[0mInference done 158/570. Dataloading: 0.0020 s/iter. Inference: 0.0997 s/iter. Eval: 0.2877 s/iter. Total: 0.3896 s/iter. ETA=0:02:40\n",
      "\u001b[32m[12/27 13:19:21 d2.evaluation.evaluator]: \u001b[0mInference done 167/570. Dataloading: 0.0020 s/iter. Inference: 0.0998 s/iter. Eval: 0.3014 s/iter. Total: 0.4034 s/iter. ETA=0:02:42\n",
      "\u001b[32m[12/27 13:19:26 d2.evaluation.evaluator]: \u001b[0mInference done 173/570. Dataloading: 0.0020 s/iter. Inference: 0.0999 s/iter. Eval: 0.3183 s/iter. Total: 0.4204 s/iter. ETA=0:02:46\n",
      "\u001b[32m[12/27 13:19:32 d2.evaluation.evaluator]: \u001b[0mInference done 180/570. Dataloading: 0.0020 s/iter. Inference: 0.1000 s/iter. Eval: 0.3311 s/iter. Total: 0.4333 s/iter. ETA=0:02:48\n",
      "\u001b[32m[12/27 13:19:38 d2.evaluation.evaluator]: \u001b[0mInference done 191/570. Dataloading: 0.0020 s/iter. Inference: 0.1001 s/iter. Eval: 0.3378 s/iter. Total: 0.4401 s/iter. ETA=0:02:46\n",
      "\u001b[32m[12/27 13:19:43 d2.evaluation.evaluator]: \u001b[0mInference done 201/570. Dataloading: 0.0020 s/iter. Inference: 0.1001 s/iter. Eval: 0.3409 s/iter. Total: 0.4432 s/iter. ETA=0:02:43\n",
      "\u001b[32m[12/27 13:19:48 d2.evaluation.evaluator]: \u001b[0mInference done 207/570. Dataloading: 0.0020 s/iter. Inference: 0.1001 s/iter. Eval: 0.3533 s/iter. Total: 0.4557 s/iter. ETA=0:02:45\n",
      "\u001b[32m[12/27 13:19:53 d2.evaluation.evaluator]: \u001b[0mInference done 215/570. Dataloading: 0.0020 s/iter. Inference: 0.1001 s/iter. Eval: 0.3600 s/iter. Total: 0.4624 s/iter. ETA=0:02:44\n",
      "\u001b[32m[12/27 13:19:58 d2.evaluation.evaluator]: \u001b[0mInference done 224/570. Dataloading: 0.0020 s/iter. Inference: 0.1002 s/iter. Eval: 0.3640 s/iter. Total: 0.4664 s/iter. ETA=0:02:41\n",
      "\u001b[32m[12/27 13:20:04 d2.evaluation.evaluator]: \u001b[0mInference done 229/570. Dataloading: 0.0020 s/iter. Inference: 0.1003 s/iter. Eval: 0.3787 s/iter. Total: 0.4812 s/iter. ETA=0:02:44\n",
      "\u001b[32m[12/27 13:20:09 d2.evaluation.evaluator]: \u001b[0mInference done 234/570. Dataloading: 0.0020 s/iter. Inference: 0.1002 s/iter. Eval: 0.3903 s/iter. Total: 0.4927 s/iter. ETA=0:02:45\n",
      "\u001b[32m[12/27 13:20:15 d2.evaluation.evaluator]: \u001b[0mInference done 241/570. Dataloading: 0.0020 s/iter. Inference: 0.1002 s/iter. Eval: 0.4016 s/iter. Total: 0.5041 s/iter. ETA=0:02:45\n",
      "\u001b[32m[12/27 13:20:21 d2.evaluation.evaluator]: \u001b[0mInference done 249/570. Dataloading: 0.0020 s/iter. Inference: 0.1002 s/iter. Eval: 0.4121 s/iter. Total: 0.5145 s/iter. ETA=0:02:45\n",
      "\u001b[32m[12/27 13:20:27 d2.evaluation.evaluator]: \u001b[0mInference done 257/570. Dataloading: 0.0020 s/iter. Inference: 0.1002 s/iter. Eval: 0.4167 s/iter. Total: 0.5192 s/iter. ETA=0:02:42\n",
      "\u001b[32m[12/27 13:20:32 d2.evaluation.evaluator]: \u001b[0mInference done 265/570. Dataloading: 0.0020 s/iter. Inference: 0.1002 s/iter. Eval: 0.4200 s/iter. Total: 0.5224 s/iter. ETA=0:02:39\n",
      "\u001b[32m[12/27 13:20:37 d2.evaluation.evaluator]: \u001b[0mInference done 272/570. Dataloading: 0.0020 s/iter. Inference: 0.1002 s/iter. Eval: 0.4255 s/iter. Total: 0.5280 s/iter. ETA=0:02:37\n",
      "\u001b[32m[12/27 13:20:42 d2.evaluation.evaluator]: \u001b[0mInference done 283/570. Dataloading: 0.0020 s/iter. Inference: 0.1002 s/iter. Eval: 0.4239 s/iter. Total: 0.5264 s/iter. ETA=0:02:31\n",
      "\u001b[32m[12/27 13:20:47 d2.evaluation.evaluator]: \u001b[0mInference done 290/570. Dataloading: 0.0020 s/iter. Inference: 0.1003 s/iter. Eval: 0.4287 s/iter. Total: 0.5312 s/iter. ETA=0:02:28\n",
      "\u001b[32m[12/27 13:20:53 d2.evaluation.evaluator]: \u001b[0mInference done 298/570. Dataloading: 0.0020 s/iter. Inference: 0.1003 s/iter. Eval: 0.4359 s/iter. Total: 0.5384 s/iter. ETA=0:02:26\n",
      "\u001b[32m[12/27 13:20:59 d2.evaluation.evaluator]: \u001b[0mInference done 320/570. Dataloading: 0.0020 s/iter. Inference: 0.0999 s/iter. Eval: 0.4147 s/iter. Total: 0.5168 s/iter. ETA=0:02:09\n",
      "\u001b[32m[12/27 13:21:04 d2.evaluation.evaluator]: \u001b[0mInference done 346/570. Dataloading: 0.0020 s/iter. Inference: 0.0994 s/iter. Eval: 0.3905 s/iter. Total: 0.4922 s/iter. ETA=0:01:50\n",
      "\u001b[32m[12/27 13:21:09 d2.evaluation.evaluator]: \u001b[0mInference done 366/570. Dataloading: 0.0020 s/iter. Inference: 0.0992 s/iter. Eval: 0.3784 s/iter. Total: 0.4799 s/iter. ETA=0:01:37\n",
      "\u001b[32m[12/27 13:21:14 d2.evaluation.evaluator]: \u001b[0mInference done 376/570. Dataloading: 0.0020 s/iter. Inference: 0.0993 s/iter. Eval: 0.3793 s/iter. Total: 0.4809 s/iter. ETA=0:01:33\n",
      "\u001b[32m[12/27 13:21:19 d2.evaluation.evaluator]: \u001b[0mInference done 386/570. Dataloading: 0.0020 s/iter. Inference: 0.0994 s/iter. Eval: 0.3802 s/iter. Total: 0.4818 s/iter. ETA=0:01:28\n",
      "\u001b[32m[12/27 13:21:25 d2.evaluation.evaluator]: \u001b[0mInference done 399/570. Dataloading: 0.0020 s/iter. Inference: 0.0994 s/iter. Eval: 0.3789 s/iter. Total: 0.4806 s/iter. ETA=0:01:22\n",
      "\u001b[32m[12/27 13:21:31 d2.evaluation.evaluator]: \u001b[0mInference done 409/570. Dataloading: 0.0020 s/iter. Inference: 0.0995 s/iter. Eval: 0.3805 s/iter. Total: 0.4822 s/iter. ETA=0:01:17\n",
      "\u001b[32m[12/27 13:21:36 d2.evaluation.evaluator]: \u001b[0mInference done 418/570. Dataloading: 0.0020 s/iter. Inference: 0.0995 s/iter. Eval: 0.3822 s/iter. Total: 0.4839 s/iter. ETA=0:01:13\n",
      "\u001b[32m[12/27 13:21:41 d2.evaluation.evaluator]: \u001b[0mInference done 428/570. Dataloading: 0.0020 s/iter. Inference: 0.0996 s/iter. Eval: 0.3834 s/iter. Total: 0.4853 s/iter. ETA=0:01:08\n",
      "\u001b[32m[12/27 13:21:46 d2.evaluation.evaluator]: \u001b[0mInference done 439/570. Dataloading: 0.0020 s/iter. Inference: 0.0996 s/iter. Eval: 0.3836 s/iter. Total: 0.4855 s/iter. ETA=0:01:03\n",
      "\u001b[32m[12/27 13:21:52 d2.evaluation.evaluator]: \u001b[0mInference done 452/570. Dataloading: 0.0020 s/iter. Inference: 0.0996 s/iter. Eval: 0.3811 s/iter. Total: 0.4830 s/iter. ETA=0:00:56\n",
      "\u001b[32m[12/27 13:21:57 d2.evaluation.evaluator]: \u001b[0mInference done 472/570. Dataloading: 0.0020 s/iter. Inference: 0.0995 s/iter. Eval: 0.3716 s/iter. Total: 0.4733 s/iter. ETA=0:00:46\n",
      "\u001b[32m[12/27 13:22:02 d2.evaluation.evaluator]: \u001b[0mInference done 490/570. Dataloading: 0.0020 s/iter. Inference: 0.0994 s/iter. Eval: 0.3650 s/iter. Total: 0.4666 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/27 13:22:07 d2.evaluation.evaluator]: \u001b[0mInference done 499/570. Dataloading: 0.0020 s/iter. Inference: 0.0994 s/iter. Eval: 0.3674 s/iter. Total: 0.4690 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/27 13:22:13 d2.evaluation.evaluator]: \u001b[0mInference done 511/570. Dataloading: 0.0020 s/iter. Inference: 0.0994 s/iter. Eval: 0.3663 s/iter. Total: 0.4679 s/iter. ETA=0:00:27\n",
      "\u001b[32m[12/27 13:22:18 d2.evaluation.evaluator]: \u001b[0mInference done 521/570. Dataloading: 0.0020 s/iter. Inference: 0.0994 s/iter. Eval: 0.3675 s/iter. Total: 0.4691 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/27 13:22:23 d2.evaluation.evaluator]: \u001b[0mInference done 535/570. Dataloading: 0.0020 s/iter. Inference: 0.0993 s/iter. Eval: 0.3651 s/iter. Total: 0.4666 s/iter. ETA=0:00:16\n",
      "\u001b[32m[12/27 13:22:28 d2.evaluation.evaluator]: \u001b[0mInference done 544/570. Dataloading: 0.0020 s/iter. Inference: 0.0993 s/iter. Eval: 0.3665 s/iter. Total: 0.4681 s/iter. ETA=0:00:12\n",
      "\u001b[32m[12/27 13:22:33 d2.evaluation.evaluator]: \u001b[0mInference done 552/570. Dataloading: 0.0020 s/iter. Inference: 0.0993 s/iter. Eval: 0.3692 s/iter. Total: 0.4708 s/iter. ETA=0:00:08\n",
      "\u001b[32m[12/27 13:22:38 d2.evaluation.evaluator]: \u001b[0mInference done 563/570. Dataloading: 0.0020 s/iter. Inference: 0.0993 s/iter. Eval: 0.3693 s/iter. Total: 0.4708 s/iter. ETA=0:00:03\n",
      "\u001b[32m[12/27 13:22:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:26.590392 (0.471841 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 13:22:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:56 (0.099264 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 13:22:42 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/27 13:22:42 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.26815263860516725\n",
      "\u001b[32m[12/27 13:22:50 d2.utils.events]: \u001b[0m eta: 0:20:49  iter: 7239  total_loss: 1.337  loss_cls: 0.3554  loss_box_reg: 0.4434  loss_mask: 0.2669  loss_rpn_cls: 0.0767  loss_rpn_loc: 0.1733  time: 0.4906  data_time: 0.0140  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:22:59 d2.utils.events]: \u001b[0m eta: 0:20:39  iter: 7259  total_loss: 1.438  loss_cls: 0.3696  loss_box_reg: 0.4262  loss_mask: 0.2728  loss_rpn_cls: 0.09178  loss_rpn_loc: 0.1789  time: 0.4905  data_time: 0.0161  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:23:08 d2.utils.events]: \u001b[0m eta: 0:20:30  iter: 7279  total_loss: 1.386  loss_cls: 0.3662  loss_box_reg: 0.411  loss_mask: 0.2808  loss_rpn_cls: 0.1075  loss_rpn_loc: 0.1913  time: 0.4903  data_time: 0.0138  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:23:18 d2.utils.events]: \u001b[0m eta: 0:20:22  iter: 7299  total_loss: 1.447  loss_cls: 0.4185  loss_box_reg: 0.4083  loss_mask: 0.2786  loss_rpn_cls: 0.1048  loss_rpn_loc: 0.1883  time: 0.4904  data_time: 0.0171  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:23:27 d2.utils.events]: \u001b[0m eta: 0:20:13  iter: 7319  total_loss: 1.484  loss_cls: 0.4167  loss_box_reg: 0.4202  loss_mask: 0.279  loss_rpn_cls: 0.08807  loss_rpn_loc: 0.21  time: 0.4903  data_time: 0.0220  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:23:36 d2.utils.events]: \u001b[0m eta: 0:20:04  iter: 7339  total_loss: 1.438  loss_cls: 0.4123  loss_box_reg: 0.4347  loss_mask: 0.2674  loss_rpn_cls: 0.09983  loss_rpn_loc: 0.1854  time: 0.4902  data_time: 0.0139  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:23:45 d2.utils.events]: \u001b[0m eta: 0:19:53  iter: 7359  total_loss: 1.431  loss_cls: 0.4024  loss_box_reg: 0.4284  loss_mask: 0.2844  loss_rpn_cls: 0.08042  loss_rpn_loc: 0.195  time: 0.4901  data_time: 0.0147  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:23:54 d2.utils.events]: \u001b[0m eta: 0:19:42  iter: 7379  total_loss: 1.344  loss_cls: 0.392  loss_box_reg: 0.4674  loss_mask: 0.2655  loss_rpn_cls: 0.07367  loss_rpn_loc: 0.1849  time: 0.4899  data_time: 0.0110  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:24:03 d2.utils.events]: \u001b[0m eta: 0:19:33  iter: 7399  total_loss: 1.384  loss_cls: 0.3701  loss_box_reg: 0.4697  loss_mask: 0.2577  loss_rpn_cls: 0.07812  loss_rpn_loc: 0.1804  time: 0.4898  data_time: 0.0141  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:24:12 d2.utils.events]: \u001b[0m eta: 0:19:23  iter: 7419  total_loss: 1.433  loss_cls: 0.3831  loss_box_reg: 0.4563  loss_mask: 0.2706  loss_rpn_cls: 0.1071  loss_rpn_loc: 0.1899  time: 0.4898  data_time: 0.0154  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:24:22 d2.utils.events]: \u001b[0m eta: 0:19:14  iter: 7439  total_loss: 1.27  loss_cls: 0.3125  loss_box_reg: 0.4028  loss_mask: 0.2736  loss_rpn_cls: 0.08479  loss_rpn_loc: 0.1772  time: 0.4897  data_time: 0.0149  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:24:31 d2.utils.events]: \u001b[0m eta: 0:19:05  iter: 7459  total_loss: 1.361  loss_cls: 0.3549  loss_box_reg: 0.436  loss_mask: 0.2586  loss_rpn_cls: 0.0937  loss_rpn_loc: 0.1996  time: 0.4896  data_time: 0.0130  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:24:40 d2.utils.events]: \u001b[0m eta: 0:18:56  iter: 7479  total_loss: 1.46  loss_cls: 0.3797  loss_box_reg: 0.4071  loss_mask: 0.3028  loss_rpn_cls: 0.08108  loss_rpn_loc: 0.2111  time: 0.4895  data_time: 0.0162  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:24:49 d2.utils.events]: \u001b[0m eta: 0:18:47  iter: 7499  total_loss: 1.262  loss_cls: 0.325  loss_box_reg: 0.4017  loss_mask: 0.2667  loss_rpn_cls: 0.08301  loss_rpn_loc: 0.1919  time: 0.4895  data_time: 0.0149  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:24:58 d2.utils.events]: \u001b[0m eta: 0:18:37  iter: 7519  total_loss: 1.351  loss_cls: 0.3602  loss_box_reg: 0.4043  loss_mask: 0.2754  loss_rpn_cls: 0.09991  loss_rpn_loc: 0.1791  time: 0.4894  data_time: 0.0141  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:25:07 d2.utils.events]: \u001b[0m eta: 0:18:26  iter: 7539  total_loss: 1.28  loss_cls: 0.3393  loss_box_reg: 0.4265  loss_mask: 0.281  loss_rpn_cls: 0.07656  loss_rpn_loc: 0.1573  time: 0.4892  data_time: 0.0130  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:25:16 d2.utils.events]: \u001b[0m eta: 0:18:16  iter: 7559  total_loss: 1.389  loss_cls: 0.3559  loss_box_reg: 0.3945  loss_mask: 0.2693  loss_rpn_cls: 0.08903  loss_rpn_loc: 0.1952  time: 0.4891  data_time: 0.0142  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:25:25 d2.utils.events]: \u001b[0m eta: 0:18:07  iter: 7579  total_loss: 1.329  loss_cls: 0.3672  loss_box_reg: 0.4288  loss_mask: 0.2802  loss_rpn_cls: 0.07652  loss_rpn_loc: 0.1638  time: 0.4890  data_time: 0.0146  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:25:35 d2.utils.events]: \u001b[0m eta: 0:17:57  iter: 7599  total_loss: 1.412  loss_cls: 0.3585  loss_box_reg: 0.4185  loss_mask: 0.281  loss_rpn_cls: 0.09063  loss_rpn_loc: 0.1832  time: 0.4890  data_time: 0.0170  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:25:43 d2.utils.events]: \u001b[0m eta: 0:17:48  iter: 7619  total_loss: 1.373  loss_cls: 0.3785  loss_box_reg: 0.4277  loss_mask: 0.2768  loss_rpn_cls: 0.09086  loss_rpn_loc: 0.1931  time: 0.4888  data_time: 0.0138  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:25:52 d2.utils.events]: \u001b[0m eta: 0:17:39  iter: 7639  total_loss: 1.254  loss_cls: 0.3445  loss_box_reg: 0.3885  loss_mask: 0.2456  loss_rpn_cls: 0.06905  loss_rpn_loc: 0.1665  time: 0.4887  data_time: 0.0129  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:26:02 d2.utils.events]: \u001b[0m eta: 0:17:31  iter: 7659  total_loss: 1.393  loss_cls: 0.3886  loss_box_reg: 0.3845  loss_mask: 0.2627  loss_rpn_cls: 0.0714  loss_rpn_loc: 0.1701  time: 0.4887  data_time: 0.0150  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:26:11 d2.utils.events]: \u001b[0m eta: 0:17:23  iter: 7679  total_loss: 1.236  loss_cls: 0.3071  loss_box_reg: 0.3757  loss_mask: 0.2598  loss_rpn_cls: 0.08266  loss_rpn_loc: 0.1812  time: 0.4886  data_time: 0.0163  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:26:21 d2.utils.events]: \u001b[0m eta: 0:17:16  iter: 7699  total_loss: 1.403  loss_cls: 0.3658  loss_box_reg: 0.4501  loss_mask: 0.2883  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.1992  time: 0.4886  data_time: 0.0161  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:26:30 d2.utils.events]: \u001b[0m eta: 0:17:08  iter: 7719  total_loss: 1.365  loss_cls: 0.4031  loss_box_reg: 0.4084  loss_mask: 0.2871  loss_rpn_cls: 0.1179  loss_rpn_loc: 0.2086  time: 0.4885  data_time: 0.0158  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:26:39 d2.utils.events]: \u001b[0m eta: 0:16:58  iter: 7739  total_loss: 1.321  loss_cls: 0.3605  loss_box_reg: 0.3876  loss_mask: 0.2577  loss_rpn_cls: 0.1033  loss_rpn_loc: 0.1904  time: 0.4885  data_time: 0.0134  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:26:48 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 7759  total_loss: 1.578  loss_cls: 0.4142  loss_box_reg: 0.4723  loss_mask: 0.2917  loss_rpn_cls: 0.09934  loss_rpn_loc: 0.1836  time: 0.4883  data_time: 0.0125  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:26:57 d2.utils.events]: \u001b[0m eta: 0:16:37  iter: 7779  total_loss: 1.267  loss_cls: 0.339  loss_box_reg: 0.377  loss_mask: 0.2559  loss_rpn_cls: 0.08161  loss_rpn_loc: 0.171  time: 0.4882  data_time: 0.0134  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:27:06 d2.utils.events]: \u001b[0m eta: 0:16:27  iter: 7799  total_loss: 1.384  loss_cls: 0.348  loss_box_reg: 0.4378  loss_mask: 0.2684  loss_rpn_cls: 0.09554  loss_rpn_loc: 0.1996  time: 0.4882  data_time: 0.0200  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:27:15 d2.utils.events]: \u001b[0m eta: 0:16:15  iter: 7819  total_loss: 1.412  loss_cls: 0.3942  loss_box_reg: 0.447  loss_mask: 0.2642  loss_rpn_cls: 0.09274  loss_rpn_loc: 0.1737  time: 0.4880  data_time: 0.0127  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:27:24 d2.utils.events]: \u001b[0m eta: 0:16:08  iter: 7839  total_loss: 1.317  loss_cls: 0.3686  loss_box_reg: 0.4293  loss_mask: 0.2596  loss_rpn_cls: 0.06794  loss_rpn_loc: 0.1744  time: 0.4880  data_time: 0.0196  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:27:33 d2.utils.events]: \u001b[0m eta: 0:16:00  iter: 7859  total_loss: 1.36  loss_cls: 0.3711  loss_box_reg: 0.4608  loss_mask: 0.2774  loss_rpn_cls: 0.08002  loss_rpn_loc: 0.194  time: 0.4879  data_time: 0.0134  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:27:43 d2.utils.events]: \u001b[0m eta: 0:15:51  iter: 7879  total_loss: 1.36  loss_cls: 0.3276  loss_box_reg: 0.4424  loss_mask: 0.298  loss_rpn_cls: 0.07665  loss_rpn_loc: 0.179  time: 0.4878  data_time: 0.0160  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:27:52 d2.utils.events]: \u001b[0m eta: 0:15:43  iter: 7899  total_loss: 1.353  loss_cls: 0.3647  loss_box_reg: 0.4265  loss_mask: 0.2579  loss_rpn_cls: 0.1056  loss_rpn_loc: 0.1954  time: 0.4878  data_time: 0.0151  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:28:01 d2.utils.events]: \u001b[0m eta: 0:15:33  iter: 7919  total_loss: 1.354  loss_cls: 0.3299  loss_box_reg: 0.4216  loss_mask: 0.2537  loss_rpn_cls: 0.08764  loss_rpn_loc: 0.1897  time: 0.4877  data_time: 0.0137  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:28:10 d2.utils.events]: \u001b[0m eta: 0:15:24  iter: 7939  total_loss: 1.337  loss_cls: 0.3724  loss_box_reg: 0.4377  loss_mask: 0.2681  loss_rpn_cls: 0.09968  loss_rpn_loc: 0.1842  time: 0.4876  data_time: 0.0144  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:28:20 d2.utils.events]: \u001b[0m eta: 0:15:15  iter: 7959  total_loss: 1.273  loss_cls: 0.3395  loss_box_reg: 0.3956  loss_mask: 0.2863  loss_rpn_cls: 0.09698  loss_rpn_loc: 0.1952  time: 0.4876  data_time: 0.0183  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:28:30 d2.utils.events]: \u001b[0m eta: 0:15:08  iter: 7979  total_loss: 1.352  loss_cls: 0.3743  loss_box_reg: 0.4453  loss_mask: 0.2435  loss_rpn_cls: 0.08439  loss_rpn_loc: 0.1722  time: 0.4876  data_time: 0.0164  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:28:38 d2.utils.events]: \u001b[0m eta: 0:14:58  iter: 7999  total_loss: 1.325  loss_cls: 0.346  loss_box_reg: 0.4263  loss_mask: 0.2632  loss_rpn_cls: 0.08044  loss_rpn_loc: 0.1772  time: 0.4874  data_time: 0.0132  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:28:48 d2.utils.events]: \u001b[0m eta: 0:14:50  iter: 8019  total_loss: 1.232  loss_cls: 0.3263  loss_box_reg: 0.4019  loss_mask: 0.2562  loss_rpn_cls: 0.07954  loss_rpn_loc: 0.179  time: 0.4874  data_time: 0.0143  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:28:57 d2.utils.events]: \u001b[0m eta: 0:14:43  iter: 8039  total_loss: 1.33  loss_cls: 0.3821  loss_box_reg: 0.4319  loss_mask: 0.2636  loss_rpn_cls: 0.08391  loss_rpn_loc: 0.1997  time: 0.4873  data_time: 0.0147  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:29:06 d2.utils.events]: \u001b[0m eta: 0:14:35  iter: 8059  total_loss: 1.233  loss_cls: 0.3127  loss_box_reg: 0.3882  loss_mask: 0.2618  loss_rpn_cls: 0.05384  loss_rpn_loc: 0.159  time: 0.4873  data_time: 0.0146  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:29:15 d2.utils.events]: \u001b[0m eta: 0:14:25  iter: 8079  total_loss: 1.365  loss_cls: 0.3463  loss_box_reg: 0.4764  loss_mask: 0.2779  loss_rpn_cls: 0.06421  loss_rpn_loc: 0.1832  time: 0.4872  data_time: 0.0120  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:29:25 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7faf6314e950> to CPU due to CUDA OOM\n",
      "\u001b[32m[12/27 13:29:45 d2.utils.events]: \u001b[0m eta: 0:14:17  iter: 8099  total_loss: 1.27  loss_cls: 0.3179  loss_box_reg: 0.42  loss_mask: 0.2585  loss_rpn_cls: 0.07866  loss_rpn_loc: 0.1754  time: 0.4896  data_time: 0.0197  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:29:54 d2.utils.events]: \u001b[0m eta: 0:14:08  iter: 8119  total_loss: 1.377  loss_cls: 0.4034  loss_box_reg: 0.4232  loss_mask: 0.2843  loss_rpn_cls: 0.09013  loss_rpn_loc: 0.1965  time: 0.4895  data_time: 0.0140  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:30:03 d2.utils.events]: \u001b[0m eta: 0:14:00  iter: 8139  total_loss: 1.314  loss_cls: 0.3328  loss_box_reg: 0.4287  loss_mask: 0.2701  loss_rpn_cls: 0.08433  loss_rpn_loc: 0.1757  time: 0.4895  data_time: 0.0141  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:30:13 d2.utils.events]: \u001b[0m eta: 0:13:51  iter: 8159  total_loss: 1.319  loss_cls: 0.3381  loss_box_reg: 0.4143  loss_mask: 0.2619  loss_rpn_cls: 0.0852  loss_rpn_loc: 0.1946  time: 0.4894  data_time: 0.0157  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:30:22 d2.utils.events]: \u001b[0m eta: 0:13:42  iter: 8179  total_loss: 1.32  loss_cls: 0.4231  loss_box_reg: 0.4454  loss_mask: 0.2667  loss_rpn_cls: 0.09621  loss_rpn_loc: 0.1886  time: 0.4894  data_time: 0.0153  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:30:31 d2.utils.events]: \u001b[0m eta: 0:13:33  iter: 8199  total_loss: 1.224  loss_cls: 0.3259  loss_box_reg: 0.4243  loss_mask: 0.2478  loss_rpn_cls: 0.06102  loss_rpn_loc: 0.1749  time: 0.4893  data_time: 0.0138  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:30:40 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 8219  total_loss: 1.273  loss_cls: 0.3412  loss_box_reg: 0.3876  loss_mask: 0.2654  loss_rpn_cls: 0.05573  loss_rpn_loc: 0.1781  time: 0.4892  data_time: 0.0151  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:30:49 d2.utils.events]: \u001b[0m eta: 0:13:14  iter: 8239  total_loss: 1.34  loss_cls: 0.3571  loss_box_reg: 0.4205  loss_mask: 0.25  loss_rpn_cls: 0.109  loss_rpn_loc: 0.1767  time: 0.4890  data_time: 0.0120  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:30:58 d2.utils.events]: \u001b[0m eta: 0:13:06  iter: 8259  total_loss: 1.367  loss_cls: 0.3686  loss_box_reg: 0.4127  loss_mask: 0.2782  loss_rpn_cls: 0.08963  loss_rpn_loc: 0.1839  time: 0.4890  data_time: 0.0150  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:31:07 d2.utils.events]: \u001b[0m eta: 0:12:56  iter: 8279  total_loss: 1.346  loss_cls: 0.3573  loss_box_reg: 0.4289  loss_mask: 0.2535  loss_rpn_cls: 0.08871  loss_rpn_loc: 0.1875  time: 0.4889  data_time: 0.0142  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:31:16 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 8299  total_loss: 1.426  loss_cls: 0.3797  loss_box_reg: 0.4034  loss_mask: 0.285  loss_rpn_cls: 0.119  loss_rpn_loc: 0.2084  time: 0.4888  data_time: 0.0150  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:31:26 d2.utils.events]: \u001b[0m eta: 0:12:38  iter: 8319  total_loss: 1.281  loss_cls: 0.3478  loss_box_reg: 0.4075  loss_mask: 0.2832  loss_rpn_cls: 0.08668  loss_rpn_loc: 0.1907  time: 0.4888  data_time: 0.0168  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:31:34 d2.utils.events]: \u001b[0m eta: 0:12:27  iter: 8339  total_loss: 1.398  loss_cls: 0.3615  loss_box_reg: 0.4352  loss_mask: 0.2718  loss_rpn_cls: 0.07704  loss_rpn_loc: 0.1779  time: 0.4887  data_time: 0.0133  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:31:44 d2.utils.events]: \u001b[0m eta: 0:12:20  iter: 8359  total_loss: 1.449  loss_cls: 0.37  loss_box_reg: 0.4335  loss_mask: 0.2786  loss_rpn_cls: 0.09851  loss_rpn_loc: 0.1968  time: 0.4886  data_time: 0.0156  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:31:53 d2.utils.events]: \u001b[0m eta: 0:12:11  iter: 8379  total_loss: 1.31  loss_cls: 0.3526  loss_box_reg: 0.3864  loss_mask: 0.2567  loss_rpn_cls: 0.09447  loss_rpn_loc: 0.1996  time: 0.4886  data_time: 0.0163  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:32:03 d2.utils.events]: \u001b[0m eta: 0:12:04  iter: 8399  total_loss: 1.242  loss_cls: 0.3188  loss_box_reg: 0.3631  loss_mask: 0.2581  loss_rpn_cls: 0.08028  loss_rpn_loc: 0.1943  time: 0.4886  data_time: 0.0170  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:32:09 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7faf6314e950> to CPU due to CUDA OOM\n",
      "\u001b[32m[12/27 13:32:31 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 8419  total_loss: 1.389  loss_cls: 0.389  loss_box_reg: 0.3745  loss_mask: 0.2655  loss_rpn_cls: 0.09869  loss_rpn_loc: 0.1995  time: 0.4908  data_time: 0.0248  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:32:41 d2.utils.events]: \u001b[0m eta: 0:11:46  iter: 8439  total_loss: 1.283  loss_cls: 0.3376  loss_box_reg: 0.4137  loss_mask: 0.2721  loss_rpn_cls: 0.07679  loss_rpn_loc: 0.1736  time: 0.4907  data_time: 0.0150  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:32:50 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 8459  total_loss: 1.321  loss_cls: 0.3328  loss_box_reg: 0.4107  loss_mask: 0.271  loss_rpn_cls: 0.08208  loss_rpn_loc: 0.19  time: 0.4907  data_time: 0.0153  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:32:59 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7faf6314e950> to CPU due to CUDA OOM\n",
      "\u001b[32m[12/27 13:33:20 d2.utils.events]: \u001b[0m eta: 0:11:28  iter: 8479  total_loss: 1.257  loss_cls: 0.3038  loss_box_reg: 0.414  loss_mask: 0.2811  loss_rpn_cls: 0.07687  loss_rpn_loc: 0.184  time: 0.4930  data_time: 0.0290  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:33:29 d2.utils.events]: \u001b[0m eta: 0:11:19  iter: 8499  total_loss: 1.261  loss_cls: 0.3494  loss_box_reg: 0.4108  loss_mask: 0.2617  loss_rpn_cls: 0.07778  loss_rpn_loc: 0.1719  time: 0.4930  data_time: 0.0148  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:33:39 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 8519  total_loss: 1.447  loss_cls: 0.4029  loss_box_reg: 0.442  loss_mask: 0.2908  loss_rpn_cls: 0.1129  loss_rpn_loc: 0.1838  time: 0.4929  data_time: 0.0150  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:33:48 d2.utils.events]: \u001b[0m eta: 0:11:04  iter: 8539  total_loss: 1.338  loss_cls: 0.3468  loss_box_reg: 0.4004  loss_mask: 0.2691  loss_rpn_cls: 0.07158  loss_rpn_loc: 0.1792  time: 0.4928  data_time: 0.0167  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:33:57 d2.utils.events]: \u001b[0m eta: 0:10:55  iter: 8559  total_loss: 1.4  loss_cls: 0.3669  loss_box_reg: 0.4324  loss_mask: 0.2982  loss_rpn_cls: 0.08302  loss_rpn_loc: 0.1999  time: 0.4927  data_time: 0.0144  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:34:07 d2.utils.events]: \u001b[0m eta: 0:10:46  iter: 8579  total_loss: 1.508  loss_cls: 0.3856  loss_box_reg: 0.4643  loss_mask: 0.2932  loss_rpn_cls: 0.08618  loss_rpn_loc: 0.1987  time: 0.4927  data_time: 0.0147  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:34:16 d2.utils.events]: \u001b[0m eta: 0:10:37  iter: 8599  total_loss: 1.251  loss_cls: 0.3446  loss_box_reg: 0.4023  loss_mask: 0.2602  loss_rpn_cls: 0.07958  loss_rpn_loc: 0.1876  time: 0.4926  data_time: 0.0151  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:34:25 d2.utils.events]: \u001b[0m eta: 0:10:28  iter: 8619  total_loss: 1.385  loss_cls: 0.3903  loss_box_reg: 0.4164  loss_mask: 0.2736  loss_rpn_cls: 0.1093  loss_rpn_loc: 0.2001  time: 0.4925  data_time: 0.0171  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:34:34 d2.utils.events]: \u001b[0m eta: 0:10:20  iter: 8639  total_loss: 1.303  loss_cls: 0.3149  loss_box_reg: 0.3815  loss_mask: 0.2618  loss_rpn_cls: 0.08338  loss_rpn_loc: 0.1842  time: 0.4925  data_time: 0.0156  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:34:44 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 8659  total_loss: 1.267  loss_cls: 0.3612  loss_box_reg: 0.4079  loss_mask: 0.2648  loss_rpn_cls: 0.08647  loss_rpn_loc: 0.1607  time: 0.4924  data_time: 0.0182  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:34:52 d2.utils.events]: \u001b[0m eta: 0:10:01  iter: 8679  total_loss: 1.286  loss_cls: 0.346  loss_box_reg: 0.413  loss_mask: 0.2673  loss_rpn_cls: 0.09431  loss_rpn_loc: 0.1881  time: 0.4923  data_time: 0.0137  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:35:01 d2.utils.events]: \u001b[0m eta: 0:09:51  iter: 8699  total_loss: 1.281  loss_cls: 0.3597  loss_box_reg: 0.3957  loss_mask: 0.2611  loss_rpn_cls: 0.07366  loss_rpn_loc: 0.1675  time: 0.4922  data_time: 0.0134  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:35:11 d2.utils.events]: \u001b[0m eta: 0:09:42  iter: 8719  total_loss: 1.195  loss_cls: 0.3287  loss_box_reg: 0.3737  loss_mask: 0.2642  loss_rpn_cls: 0.08117  loss_rpn_loc: 0.1725  time: 0.4922  data_time: 0.0153  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:35:20 d2.utils.events]: \u001b[0m eta: 0:09:33  iter: 8739  total_loss: 1.406  loss_cls: 0.394  loss_box_reg: 0.4346  loss_mask: 0.2821  loss_rpn_cls: 0.08304  loss_rpn_loc: 0.1891  time: 0.4921  data_time: 0.0146  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:35:30 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 8759  total_loss: 1.321  loss_cls: 0.3723  loss_box_reg: 0.4104  loss_mask: 0.2668  loss_rpn_cls: 0.1115  loss_rpn_loc: 0.2064  time: 0.4920  data_time: 0.0169  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:35:39 d2.utils.events]: \u001b[0m eta: 0:09:16  iter: 8779  total_loss: 1.482  loss_cls: 0.4062  loss_box_reg: 0.4693  loss_mask: 0.2714  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.1841  time: 0.4920  data_time: 0.0140  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:35:48 d2.utils.events]: \u001b[0m eta: 0:09:07  iter: 8799  total_loss: 1.407  loss_cls: 0.3298  loss_box_reg: 0.4123  loss_mask: 0.274  loss_rpn_cls: 0.1235  loss_rpn_loc: 0.1973  time: 0.4919  data_time: 0.0155  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:35:57 d2.utils.events]: \u001b[0m eta: 0:08:59  iter: 8819  total_loss: 1.431  loss_cls: 0.3811  loss_box_reg: 0.4331  loss_mask: 0.2702  loss_rpn_cls: 0.08802  loss_rpn_loc: 0.1863  time: 0.4918  data_time: 0.0145  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:36:06 d2.utils.events]: \u001b[0m eta: 0:08:49  iter: 8839  total_loss: 1.287  loss_cls: 0.3373  loss_box_reg: 0.4176  loss_mask: 0.2415  loss_rpn_cls: 0.08883  loss_rpn_loc: 0.1854  time: 0.4917  data_time: 0.0148  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:36:15 d2.utils.events]: \u001b[0m eta: 0:08:40  iter: 8859  total_loss: 1.372  loss_cls: 0.3624  loss_box_reg: 0.4159  loss_mask: 0.2685  loss_rpn_cls: 0.09333  loss_rpn_loc: 0.2034  time: 0.4916  data_time: 0.0142  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:36:24 d2.utils.events]: \u001b[0m eta: 0:08:31  iter: 8879  total_loss: 1.322  loss_cls: 0.3709  loss_box_reg: 0.4321  loss_mask: 0.287  loss_rpn_cls: 0.07735  loss_rpn_loc: 0.1794  time: 0.4915  data_time: 0.0145  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:36:34 d2.utils.events]: \u001b[0m eta: 0:08:22  iter: 8899  total_loss: 1.253  loss_cls: 0.3403  loss_box_reg: 0.3976  loss_mask: 0.258  loss_rpn_cls: 0.09715  loss_rpn_loc: 0.1839  time: 0.4915  data_time: 0.0145  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:36:43 d2.utils.events]: \u001b[0m eta: 0:08:13  iter: 8919  total_loss: 1.376  loss_cls: 0.4071  loss_box_reg: 0.4434  loss_mask: 0.2737  loss_rpn_cls: 0.09157  loss_rpn_loc: 0.1861  time: 0.4914  data_time: 0.0169  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:36:53 d2.utils.events]: \u001b[0m eta: 0:08:04  iter: 8939  total_loss: 1.257  loss_cls: 0.3392  loss_box_reg: 0.39  loss_mask: 0.2609  loss_rpn_cls: 0.09024  loss_rpn_loc: 0.1658  time: 0.4914  data_time: 0.0144  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:37:02 d2.utils.events]: \u001b[0m eta: 0:07:55  iter: 8959  total_loss: 1.313  loss_cls: 0.3315  loss_box_reg: 0.427  loss_mask: 0.2558  loss_rpn_cls: 0.07517  loss_rpn_loc: 0.1767  time: 0.4913  data_time: 0.0144  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:37:11 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 8979  total_loss: 1.325  loss_cls: 0.3664  loss_box_reg: 0.4168  loss_mask: 0.2771  loss_rpn_cls: 0.09661  loss_rpn_loc: 0.184  time: 0.4912  data_time: 0.0144  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:37:20 d2.utils.events]: \u001b[0m eta: 0:07:37  iter: 8999  total_loss: 1.334  loss_cls: 0.3853  loss_box_reg: 0.4047  loss_mask: 0.2657  loss_rpn_cls: 0.07979  loss_rpn_loc: 0.1917  time: 0.4911  data_time: 0.0155  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:37:29 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 9019  total_loss: 1.253  loss_cls: 0.3246  loss_box_reg: 0.443  loss_mask: 0.268  loss_rpn_cls: 0.09211  loss_rpn_loc: 0.1662  time: 0.4911  data_time: 0.0144  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:37:38 d2.utils.events]: \u001b[0m eta: 0:07:18  iter: 9039  total_loss: 1.34  loss_cls: 0.3439  loss_box_reg: 0.415  loss_mask: 0.2785  loss_rpn_cls: 0.08448  loss_rpn_loc: 0.1818  time: 0.4910  data_time: 0.0158  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:37:47 d2.utils.events]: \u001b[0m eta: 0:07:09  iter: 9059  total_loss: 1.369  loss_cls: 0.3574  loss_box_reg: 0.4381  loss_mask: 0.2789  loss_rpn_cls: 0.08905  loss_rpn_loc: 0.1815  time: 0.4909  data_time: 0.0137  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:37:56 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 9079  total_loss: 1.408  loss_cls: 0.3647  loss_box_reg: 0.4319  loss_mask: 0.2888  loss_rpn_cls: 0.09946  loss_rpn_loc: 0.1899  time: 0.4908  data_time: 0.0143  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:38:06 d2.utils.events]: \u001b[0m eta: 0:06:51  iter: 9099  total_loss: 1.297  loss_cls: 0.3867  loss_box_reg: 0.3946  loss_mask: 0.2713  loss_rpn_cls: 0.09659  loss_rpn_loc: 0.1931  time: 0.4908  data_time: 0.0174  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:38:15 d2.utils.events]: \u001b[0m eta: 0:06:41  iter: 9119  total_loss: 1.434  loss_cls: 0.3958  loss_box_reg: 0.4232  loss_mask: 0.2735  loss_rpn_cls: 0.08716  loss_rpn_loc: 0.1852  time: 0.4907  data_time: 0.0133  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:38:24 d2.utils.events]: \u001b[0m eta: 0:06:32  iter: 9139  total_loss: 1.402  loss_cls: 0.3916  loss_box_reg: 0.4085  loss_mask: 0.2701  loss_rpn_cls: 0.1249  loss_rpn_loc: 0.1786  time: 0.4907  data_time: 0.0159  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:38:34 d2.utils.events]: \u001b[0m eta: 0:06:23  iter: 9159  total_loss: 1.294  loss_cls: 0.3328  loss_box_reg: 0.393  loss_mask: 0.2666  loss_rpn_cls: 0.0902  loss_rpn_loc: 0.1872  time: 0.4906  data_time: 0.0159  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:38:43 d2.utils.events]: \u001b[0m eta: 0:06:14  iter: 9179  total_loss: 1.271  loss_cls: 0.3227  loss_box_reg: 0.3855  loss_mask: 0.2732  loss_rpn_cls: 0.07986  loss_rpn_loc: 0.1804  time: 0.4905  data_time: 0.0154  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:38:52 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 9199  total_loss: 1.204  loss_cls: 0.3052  loss_box_reg: 0.3895  loss_mask: 0.2554  loss_rpn_cls: 0.07909  loss_rpn_loc: 0.1703  time: 0.4905  data_time: 0.0150  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:39:01 d2.utils.events]: \u001b[0m eta: 0:05:56  iter: 9219  total_loss: 1.239  loss_cls: 0.319  loss_box_reg: 0.4003  loss_mask: 0.249  loss_rpn_cls: 0.0665  loss_rpn_loc: 0.1653  time: 0.4903  data_time: 0.0160  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:39:09 d2.utils.events]: \u001b[0m eta: 0:05:47  iter: 9239  total_loss: 1.289  loss_cls: 0.3514  loss_box_reg: 0.4537  loss_mask: 0.2736  loss_rpn_cls: 0.08106  loss_rpn_loc: 0.1796  time: 0.4902  data_time: 0.0118  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:39:19 d2.utils.events]: \u001b[0m eta: 0:05:37  iter: 9259  total_loss: 1.306  loss_cls: 0.3495  loss_box_reg: 0.3916  loss_mask: 0.2767  loss_rpn_cls: 0.09042  loss_rpn_loc: 0.1826  time: 0.4902  data_time: 0.0157  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:39:28 d2.utils.events]: \u001b[0m eta: 0:05:29  iter: 9279  total_loss: 1.318  loss_cls: 0.3385  loss_box_reg: 0.4261  loss_mask: 0.2793  loss_rpn_cls: 0.08899  loss_rpn_loc: 0.1784  time: 0.4901  data_time: 0.0151  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:39:37 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 9299  total_loss: 1.354  loss_cls: 0.3771  loss_box_reg: 0.4337  loss_mask: 0.2597  loss_rpn_cls: 0.08775  loss_rpn_loc: 0.1909  time: 0.4901  data_time: 0.0159  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:39:46 d2.utils.events]: \u001b[0m eta: 0:05:10  iter: 9319  total_loss: 1.331  loss_cls: 0.3314  loss_box_reg: 0.4273  loss_mask: 0.2696  loss_rpn_cls: 0.09912  loss_rpn_loc: 0.1818  time: 0.4900  data_time: 0.0140  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:39:55 d2.utils.events]: \u001b[0m eta: 0:05:01  iter: 9339  total_loss: 1.178  loss_cls: 0.2781  loss_box_reg: 0.3701  loss_mask: 0.2563  loss_rpn_cls: 0.08023  loss_rpn_loc: 0.188  time: 0.4899  data_time: 0.0137  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:40:05 d2.utils.events]: \u001b[0m eta: 0:04:52  iter: 9359  total_loss: 1.263  loss_cls: 0.3249  loss_box_reg: 0.3812  loss_mask: 0.2652  loss_rpn_cls: 0.08457  loss_rpn_loc: 0.1806  time: 0.4898  data_time: 0.0176  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:40:14 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 9379  total_loss: 1.39  loss_cls: 0.3855  loss_box_reg: 0.4231  loss_mask: 0.2623  loss_rpn_cls: 0.07515  loss_rpn_loc: 0.166  time: 0.4898  data_time: 0.0138  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:40:24 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 9399  total_loss: 1.314  loss_cls: 0.358  loss_box_reg: 0.4347  loss_mask: 0.2728  loss_rpn_cls: 0.08258  loss_rpn_loc: 0.1966  time: 0.4898  data_time: 0.0149  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:40:33 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 9419  total_loss: 1.479  loss_cls: 0.4013  loss_box_reg: 0.4483  loss_mask: 0.2713  loss_rpn_cls: 0.1186  loss_rpn_loc: 0.2097  time: 0.4897  data_time: 0.0145  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:40:42 d2.utils.events]: \u001b[0m eta: 0:04:15  iter: 9439  total_loss: 1.289  loss_cls: 0.3567  loss_box_reg: 0.4265  loss_mask: 0.2561  loss_rpn_cls: 0.07317  loss_rpn_loc: 0.1822  time: 0.4896  data_time: 0.0133  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:40:51 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 9459  total_loss: 1.292  loss_cls: 0.3189  loss_box_reg: 0.4054  loss_mask: 0.2759  loss_rpn_cls: 0.08903  loss_rpn_loc: 0.1894  time: 0.4895  data_time: 0.0158  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:40:57 d2.utils.memory]: \u001b[0mAttempting to copy inputs of <function pairwise_iou at 0x7faf6314e950> to CPU due to CUDA OOM\n",
      "\u001b[32m[12/27 13:41:18 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 9479  total_loss: 1.194  loss_cls: 0.2787  loss_box_reg: 0.3913  loss_mask: 0.2528  loss_rpn_cls: 0.08178  loss_rpn_loc: 0.1822  time: 0.4913  data_time: 0.0275  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:41:27 d2.utils.events]: \u001b[0m eta: 0:03:48  iter: 9499  total_loss: 1.396  loss_cls: 0.3552  loss_box_reg: 0.4696  loss_mask: 0.279  loss_rpn_cls: 0.07193  loss_rpn_loc: 0.1944  time: 0.4912  data_time: 0.0141  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:41:36 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 9519  total_loss: 1.275  loss_cls: 0.3551  loss_box_reg: 0.4123  loss_mask: 0.2753  loss_rpn_cls: 0.07685  loss_rpn_loc: 0.168  time: 0.4912  data_time: 0.0152  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:41:45 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 9539  total_loss: 1.288  loss_cls: 0.3209  loss_box_reg: 0.4405  loss_mask: 0.2583  loss_rpn_cls: 0.08333  loss_rpn_loc: 0.1825  time: 0.4911  data_time: 0.0143  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:41:55 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 9559  total_loss: 1.292  loss_cls: 0.3601  loss_box_reg: 0.4241  loss_mask: 0.2586  loss_rpn_cls: 0.08801  loss_rpn_loc: 0.1768  time: 0.4911  data_time: 0.0153  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:42:04 d2.utils.events]: \u001b[0m eta: 0:03:11  iter: 9579  total_loss: 1.584  loss_cls: 0.4632  loss_box_reg: 0.4597  loss_mask: 0.2694  loss_rpn_cls: 0.08836  loss_rpn_loc: 0.2117  time: 0.4910  data_time: 0.0142  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:42:14 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 9599  total_loss: 1.369  loss_cls: 0.4839  loss_box_reg: 0.3701  loss_mask: 0.2637  loss_rpn_cls: 0.1076  loss_rpn_loc: 0.2034  time: 0.4910  data_time: 0.0168  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:42:23 d2.utils.events]: \u001b[0m eta: 0:02:53  iter: 9619  total_loss: 1.491  loss_cls: 0.4869  loss_box_reg: 0.4204  loss_mask: 0.2805  loss_rpn_cls: 0.1142  loss_rpn_loc: 0.1907  time: 0.4910  data_time: 0.0165  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:42:35 d2.data.datasets.coco]: \u001b[0mLoading /content/livecell/livecell_annotations_val.json takes 5.25 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/27 13:42:35 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/27 13:42:35 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from /content/livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/27 13:42:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 13:42:36 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 13:42:37 d2.data.common]: \u001b[0mSerialized dataset takes 84.21 MiB\n",
      "\u001b[32m[12/27 13:42:41 d2.data.datasets.coco]: \u001b[0mLoading /content/livecell/livecell_annotations_val.json takes 4.14 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/27 13:42:41 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/27 13:42:41 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from /content/livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/27 13:42:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/27 13:42:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0016 s/iter. Inference: 0.0943 s/iter. Eval: 0.2552 s/iter. Total: 0.3511 s/iter. ETA=0:03:16\n",
      "\u001b[32m[12/27 13:42:53 d2.evaluation.evaluator]: \u001b[0mInference done 28/570. Dataloading: 0.0019 s/iter. Inference: 0.0949 s/iter. Eval: 0.2244 s/iter. Total: 0.3213 s/iter. ETA=0:02:54\n",
      "\u001b[32m[12/27 13:42:58 d2.evaluation.evaluator]: \u001b[0mInference done 41/570. Dataloading: 0.0020 s/iter. Inference: 0.0948 s/iter. Eval: 0.2484 s/iter. Total: 0.3453 s/iter. ETA=0:03:02\n",
      "\u001b[32m[12/27 13:43:04 d2.evaluation.evaluator]: \u001b[0mInference done 57/570. Dataloading: 0.0019 s/iter. Inference: 0.0949 s/iter. Eval: 0.2454 s/iter. Total: 0.3424 s/iter. ETA=0:02:55\n",
      "\u001b[32m[12/27 13:43:09 d2.evaluation.evaluator]: \u001b[0mInference done 73/570. Dataloading: 0.0019 s/iter. Inference: 0.0951 s/iter. Eval: 0.2401 s/iter. Total: 0.3373 s/iter. ETA=0:02:47\n",
      "\u001b[32m[12/27 13:43:14 d2.evaluation.evaluator]: \u001b[0mInference done 87/570. Dataloading: 0.0020 s/iter. Inference: 0.0954 s/iter. Eval: 0.2451 s/iter. Total: 0.3427 s/iter. ETA=0:02:45\n",
      "\u001b[32m[12/27 13:43:19 d2.evaluation.evaluator]: \u001b[0mInference done 100/570. Dataloading: 0.0020 s/iter. Inference: 0.0953 s/iter. Eval: 0.2534 s/iter. Total: 0.3509 s/iter. ETA=0:02:44\n",
      "\u001b[32m[12/27 13:43:24 d2.evaluation.evaluator]: \u001b[0mInference done 116/570. Dataloading: 0.0020 s/iter. Inference: 0.0956 s/iter. Eval: 0.2486 s/iter. Total: 0.3464 s/iter. ETA=0:02:37\n",
      "\u001b[32m[12/27 13:43:30 d2.evaluation.evaluator]: \u001b[0mInference done 131/570. Dataloading: 0.0020 s/iter. Inference: 0.0956 s/iter. Eval: 0.2508 s/iter. Total: 0.3486 s/iter. ETA=0:02:33\n",
      "\u001b[32m[12/27 13:43:35 d2.evaluation.evaluator]: \u001b[0mInference done 146/570. Dataloading: 0.0020 s/iter. Inference: 0.0956 s/iter. Eval: 0.2526 s/iter. Total: 0.3504 s/iter. ETA=0:02:28\n",
      "\u001b[32m[12/27 13:43:40 d2.evaluation.evaluator]: \u001b[0mInference done 156/570. Dataloading: 0.0020 s/iter. Inference: 0.0958 s/iter. Eval: 0.2637 s/iter. Total: 0.3617 s/iter. ETA=0:02:29\n",
      "\u001b[32m[12/27 13:43:46 d2.evaluation.evaluator]: \u001b[0mInference done 165/570. Dataloading: 0.0020 s/iter. Inference: 0.0960 s/iter. Eval: 0.2798 s/iter. Total: 0.3780 s/iter. ETA=0:02:33\n",
      "\u001b[32m[12/27 13:43:52 d2.evaluation.evaluator]: \u001b[0mInference done 172/570. Dataloading: 0.0020 s/iter. Inference: 0.0961 s/iter. Eval: 0.2961 s/iter. Total: 0.3944 s/iter. ETA=0:02:36\n",
      "\u001b[32m[12/27 13:43:57 d2.evaluation.evaluator]: \u001b[0mInference done 178/570. Dataloading: 0.0020 s/iter. Inference: 0.0962 s/iter. Eval: 0.3114 s/iter. Total: 0.4098 s/iter. ETA=0:02:40\n",
      "\u001b[32m[12/27 13:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 190/570. Dataloading: 0.0020 s/iter. Inference: 0.0963 s/iter. Eval: 0.3146 s/iter. Total: 0.4132 s/iter. ETA=0:02:37\n",
      "\u001b[32m[12/27 13:44:07 d2.evaluation.evaluator]: \u001b[0mInference done 199/570. Dataloading: 0.0020 s/iter. Inference: 0.0964 s/iter. Eval: 0.3216 s/iter. Total: 0.4202 s/iter. ETA=0:02:35\n",
      "\u001b[32m[12/27 13:44:13 d2.evaluation.evaluator]: \u001b[0mInference done 207/570. Dataloading: 0.0020 s/iter. Inference: 0.0965 s/iter. Eval: 0.3333 s/iter. Total: 0.4320 s/iter. ETA=0:02:36\n",
      "\u001b[32m[12/27 13:44:18 d2.evaluation.evaluator]: \u001b[0mInference done 216/570. Dataloading: 0.0020 s/iter. Inference: 0.0965 s/iter. Eval: 0.3402 s/iter. Total: 0.4389 s/iter. ETA=0:02:35\n",
      "\u001b[32m[12/27 13:44:24 d2.evaluation.evaluator]: \u001b[0mInference done 225/570. Dataloading: 0.0020 s/iter. Inference: 0.0966 s/iter. Eval: 0.3462 s/iter. Total: 0.4450 s/iter. ETA=0:02:33\n",
      "\u001b[32m[12/27 13:44:29 d2.evaluation.evaluator]: \u001b[0mInference done 231/570. Dataloading: 0.0020 s/iter. Inference: 0.0966 s/iter. Eval: 0.3566 s/iter. Total: 0.4555 s/iter. ETA=0:02:34\n",
      "\u001b[32m[12/27 13:44:34 d2.evaluation.evaluator]: \u001b[0mInference done 236/570. Dataloading: 0.0020 s/iter. Inference: 0.0967 s/iter. Eval: 0.3712 s/iter. Total: 0.4701 s/iter. ETA=0:02:37\n",
      "\u001b[32m[12/27 13:44:39 d2.evaluation.evaluator]: \u001b[0mInference done 242/570. Dataloading: 0.0021 s/iter. Inference: 0.0967 s/iter. Eval: 0.3809 s/iter. Total: 0.4799 s/iter. ETA=0:02:37\n",
      "\u001b[32m[12/27 13:44:45 d2.evaluation.evaluator]: \u001b[0mInference done 249/570. Dataloading: 0.0021 s/iter. Inference: 0.0968 s/iter. Eval: 0.3914 s/iter. Total: 0.4905 s/iter. ETA=0:02:37\n",
      "\u001b[32m[12/27 13:44:51 d2.evaluation.evaluator]: \u001b[0mInference done 257/570. Dataloading: 0.0021 s/iter. Inference: 0.0968 s/iter. Eval: 0.3962 s/iter. Total: 0.4953 s/iter. ETA=0:02:35\n",
      "\u001b[32m[12/27 13:44:56 d2.evaluation.evaluator]: \u001b[0mInference done 266/570. Dataloading: 0.0021 s/iter. Inference: 0.0968 s/iter. Eval: 0.4020 s/iter. Total: 0.5011 s/iter. ETA=0:02:32\n",
      "\u001b[32m[12/27 13:45:03 d2.evaluation.evaluator]: \u001b[0mInference done 276/570. Dataloading: 0.0021 s/iter. Inference: 0.0969 s/iter. Eval: 0.4060 s/iter. Total: 0.5051 s/iter. ETA=0:02:28\n",
      "\u001b[32m[12/27 13:45:09 d2.evaluation.evaluator]: \u001b[0mInference done 288/570. Dataloading: 0.0021 s/iter. Inference: 0.0968 s/iter. Eval: 0.4075 s/iter. Total: 0.5066 s/iter. ETA=0:02:22\n",
      "\u001b[32m[12/27 13:45:14 d2.evaluation.evaluator]: \u001b[0mInference done 296/570. Dataloading: 0.0021 s/iter. Inference: 0.0969 s/iter. Eval: 0.4117 s/iter. Total: 0.5108 s/iter. ETA=0:02:19\n",
      "\u001b[32m[12/27 13:45:19 d2.evaluation.evaluator]: \u001b[0mInference done 312/570. Dataloading: 0.0021 s/iter. Inference: 0.0966 s/iter. Eval: 0.4019 s/iter. Total: 0.5009 s/iter. ETA=0:02:09\n",
      "\u001b[32m[12/27 13:45:25 d2.evaluation.evaluator]: \u001b[0mInference done 342/570. Dataloading: 0.0020 s/iter. Inference: 0.0961 s/iter. Eval: 0.3731 s/iter. Total: 0.4715 s/iter. ETA=0:01:47\n",
      "\u001b[32m[12/27 13:45:30 d2.evaluation.evaluator]: \u001b[0mInference done 365/570. Dataloading: 0.0020 s/iter. Inference: 0.0959 s/iter. Eval: 0.3579 s/iter. Total: 0.4560 s/iter. ETA=0:01:33\n",
      "\u001b[32m[12/27 13:45:36 d2.evaluation.evaluator]: \u001b[0mInference done 376/570. Dataloading: 0.0020 s/iter. Inference: 0.0960 s/iter. Eval: 0.3594 s/iter. Total: 0.4577 s/iter. ETA=0:01:28\n",
      "\u001b[32m[12/27 13:45:41 d2.evaluation.evaluator]: \u001b[0mInference done 386/570. Dataloading: 0.0020 s/iter. Inference: 0.0962 s/iter. Eval: 0.3605 s/iter. Total: 0.4590 s/iter. ETA=0:01:24\n",
      "\u001b[32m[12/27 13:45:46 d2.evaluation.evaluator]: \u001b[0mInference done 399/570. Dataloading: 0.0020 s/iter. Inference: 0.0963 s/iter. Eval: 0.3597 s/iter. Total: 0.4582 s/iter. ETA=0:01:18\n",
      "\u001b[32m[12/27 13:45:52 d2.evaluation.evaluator]: \u001b[0mInference done 409/570. Dataloading: 0.0020 s/iter. Inference: 0.0964 s/iter. Eval: 0.3617 s/iter. Total: 0.4604 s/iter. ETA=0:01:14\n",
      "\u001b[32m[12/27 13:45:57 d2.evaluation.evaluator]: \u001b[0mInference done 418/570. Dataloading: 0.0020 s/iter. Inference: 0.0966 s/iter. Eval: 0.3637 s/iter. Total: 0.4625 s/iter. ETA=0:01:10\n",
      "\u001b[32m[12/27 13:46:02 d2.evaluation.evaluator]: \u001b[0mInference done 428/570. Dataloading: 0.0020 s/iter. Inference: 0.0967 s/iter. Eval: 0.3652 s/iter. Total: 0.4642 s/iter. ETA=0:01:05\n",
      "\u001b[32m[12/27 13:46:07 d2.evaluation.evaluator]: \u001b[0mInference done 439/570. Dataloading: 0.0020 s/iter. Inference: 0.0968 s/iter. Eval: 0.3657 s/iter. Total: 0.4648 s/iter. ETA=0:01:00\n",
      "\u001b[32m[12/27 13:46:13 d2.evaluation.evaluator]: \u001b[0mInference done 452/570. Dataloading: 0.0020 s/iter. Inference: 0.0969 s/iter. Eval: 0.3636 s/iter. Total: 0.4627 s/iter. ETA=0:00:54\n",
      "\u001b[32m[12/27 13:46:18 d2.evaluation.evaluator]: \u001b[0mInference done 472/570. Dataloading: 0.0020 s/iter. Inference: 0.0968 s/iter. Eval: 0.3546 s/iter. Total: 0.4537 s/iter. ETA=0:00:44\n",
      "\u001b[32m[12/27 13:46:23 d2.evaluation.evaluator]: \u001b[0mInference done 490/570. Dataloading: 0.0020 s/iter. Inference: 0.0968 s/iter. Eval: 0.3482 s/iter. Total: 0.4473 s/iter. ETA=0:00:35\n",
      "\u001b[32m[12/27 13:46:28 d2.evaluation.evaluator]: \u001b[0mInference done 500/570. Dataloading: 0.0020 s/iter. Inference: 0.0967 s/iter. Eval: 0.3497 s/iter. Total: 0.4486 s/iter. ETA=0:00:31\n",
      "\u001b[32m[12/27 13:46:33 d2.evaluation.evaluator]: \u001b[0mInference done 512/570. Dataloading: 0.0020 s/iter. Inference: 0.0965 s/iter. Eval: 0.3492 s/iter. Total: 0.4480 s/iter. ETA=0:00:25\n",
      "\u001b[32m[12/27 13:46:38 d2.evaluation.evaluator]: \u001b[0mInference done 526/570. Dataloading: 0.0020 s/iter. Inference: 0.0963 s/iter. Eval: 0.3470 s/iter. Total: 0.4456 s/iter. ETA=0:00:19\n",
      "\u001b[32m[12/27 13:46:43 d2.evaluation.evaluator]: \u001b[0mInference done 539/570. Dataloading: 0.0020 s/iter. Inference: 0.0962 s/iter. Eval: 0.3468 s/iter. Total: 0.4452 s/iter. ETA=0:00:13\n",
      "\u001b[32m[12/27 13:46:49 d2.evaluation.evaluator]: \u001b[0mInference done 548/570. Dataloading: 0.0020 s/iter. Inference: 0.0961 s/iter. Eval: 0.3488 s/iter. Total: 0.4471 s/iter. ETA=0:00:09\n",
      "\u001b[32m[12/27 13:46:54 d2.evaluation.evaluator]: \u001b[0mInference done 559/570. Dataloading: 0.0020 s/iter. Inference: 0.0960 s/iter. Eval: 0.3493 s/iter. Total: 0.4475 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 13:46:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:12.891449 (0.447595 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 13:46:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:54 (0.095838 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 13:46:59 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/27 13:46:59 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.21784699199056\n",
      "\u001b[32m[12/27 13:47:03 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 9639  total_loss: 1.477  loss_cls: 0.4342  loss_box_reg: 0.4293  loss_mask: 0.2751  loss_rpn_cls: 0.1058  loss_rpn_loc: 0.1923  time: 0.4909  data_time: 0.0160  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:47:12 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 9659  total_loss: 1.384  loss_cls: 0.4191  loss_box_reg: 0.4066  loss_mask: 0.2638  loss_rpn_cls: 0.08913  loss_rpn_loc: 0.1814  time: 0.4909  data_time: 0.0158  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:47:22 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 9679  total_loss: 1.218  loss_cls: 0.3497  loss_box_reg: 0.389  loss_mask: 0.2534  loss_rpn_cls: 0.1128  loss_rpn_loc: 0.1706  time: 0.4908  data_time: 0.0158  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:47:31 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 9699  total_loss: 1.294  loss_cls: 0.3419  loss_box_reg: 0.4105  loss_mask: 0.2568  loss_rpn_cls: 0.08615  loss_rpn_loc: 0.1842  time: 0.4908  data_time: 0.0155  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:47:40 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 9719  total_loss: 1.245  loss_cls: 0.3524  loss_box_reg: 0.4222  loss_mask: 0.2699  loss_rpn_cls: 0.09262  loss_rpn_loc: 0.174  time: 0.4907  data_time: 0.0137  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:47:49 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 9739  total_loss: 1.313  loss_cls: 0.3187  loss_box_reg: 0.4185  loss_mask: 0.2683  loss_rpn_cls: 0.06039  loss_rpn_loc: 0.1689  time: 0.4907  data_time: 0.0146  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:47:59 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 9759  total_loss: 1.298  loss_cls: 0.3306  loss_box_reg: 0.3858  loss_mask: 0.2687  loss_rpn_cls: 0.09012  loss_rpn_loc: 0.1802  time: 0.4906  data_time: 0.0140  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:48:08 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 9779  total_loss: 1.232  loss_cls: 0.3418  loss_box_reg: 0.4178  loss_mask: 0.2639  loss_rpn_cls: 0.06871  loss_rpn_loc: 0.1849  time: 0.4906  data_time: 0.0152  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:48:18 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 9799  total_loss: 1.209  loss_cls: 0.3077  loss_box_reg: 0.3715  loss_mask: 0.2644  loss_rpn_cls: 0.0908  loss_rpn_loc: 0.172  time: 0.4906  data_time: 0.0153  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:48:27 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 9819  total_loss: 1.315  loss_cls: 0.3486  loss_box_reg: 0.398  loss_mask: 0.2751  loss_rpn_cls: 0.09043  loss_rpn_loc: 0.1858  time: 0.4906  data_time: 0.0177  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:48:37 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 9839  total_loss: 1.42  loss_cls: 0.3938  loss_box_reg: 0.4336  loss_mask: 0.2784  loss_rpn_cls: 0.08435  loss_rpn_loc: 0.1771  time: 0.4905  data_time: 0.0140  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:48:46 d2.utils.events]: \u001b[0m eta: 0:01:04  iter: 9859  total_loss: 1.363  loss_cls: 0.4141  loss_box_reg: 0.4475  loss_mask: 0.2774  loss_rpn_cls: 0.0805  loss_rpn_loc: 0.1666  time: 0.4904  data_time: 0.0152  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:48:55 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 9879  total_loss: 1.47  loss_cls: 0.4122  loss_box_reg: 0.4563  loss_mask: 0.286  loss_rpn_cls: 0.08832  loss_rpn_loc: 0.1875  time: 0.4903  data_time: 0.0136  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:49:04 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 9899  total_loss: 1.331  loss_cls: 0.3117  loss_box_reg: 0.413  loss_mask: 0.2706  loss_rpn_cls: 0.1125  loss_rpn_loc: 0.2021  time: 0.4903  data_time: 0.0149  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:49:13 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 9919  total_loss: 1.379  loss_cls: 0.3711  loss_box_reg: 0.4499  loss_mask: 0.2772  loss_rpn_cls: 0.07814  loss_rpn_loc: 0.1898  time: 0.4902  data_time: 0.0139  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:49:22 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 9939  total_loss: 1.349  loss_cls: 0.3434  loss_box_reg: 0.4232  loss_mask: 0.2595  loss_rpn_cls: 0.06964  loss_rpn_loc: 0.1862  time: 0.4901  data_time: 0.0140  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:49:31 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 9959  total_loss: 1.324  loss_cls: 0.3751  loss_box_reg: 0.4139  loss_mask: 0.2671  loss_rpn_cls: 0.07533  loss_rpn_loc: 0.1738  time: 0.4901  data_time: 0.0141  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:49:40 d2.utils.events]: \u001b[0m eta: 0:00:09  iter: 9979  total_loss: 1.283  loss_cls: 0.3382  loss_box_reg: 0.3937  loss_mask: 0.251  loss_rpn_cls: 0.06287  loss_rpn_loc: 0.1741  time: 0.4900  data_time: 0.0139  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:49:50 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.455  loss_cls: 0.3565  loss_box_reg: 0.4356  loss_mask: 0.2861  loss_rpn_cls: 0.09026  loss_rpn_loc: 0.186  time: 0.4899  data_time: 0.0145  lr: 0.005  max_mem: 13868M\n",
      "\u001b[32m[12/27 13:49:52 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:21:37 (0.4899 s / it)\n",
      "\u001b[32m[12/27 13:49:52 d2.engine.hooks]: \u001b[0mTotal training time: 1:40:12 (0:18:34 on hooks)\n",
      "\u001b[32m[12/27 13:49:56 d2.data.datasets.coco]: \u001b[0mLoading /content/livecell/livecell_annotations_val.json takes 3.92 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/27 13:49:56 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/27 13:49:56 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from /content/livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/27 13:49:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 13:49:57 d2.data.common]: \u001b[0mSerializing 570 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 13:49:57 d2.data.common]: \u001b[0mSerialized dataset takes 84.21 MiB\n",
      "\u001b[32m[12/27 13:50:01 d2.data.datasets.coco]: \u001b[0mLoading /content/livecell/livecell_annotations_val.json takes 4.03 seconds.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/27 13:50:01 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/27 13:50:01 d2.data.datasets.coco]: \u001b[0mLoaded 570 images in COCO format from /content/livecell/livecell_annotations_val.json\n",
      "\u001b[32m[12/27 13:50:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 570 batches\n",
      "\u001b[32m[12/27 13:50:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/570. Dataloading: 0.0016 s/iter. Inference: 0.0981 s/iter. Eval: 0.2906 s/iter. Total: 0.3903 s/iter. ETA=0:03:38\n",
      "\u001b[32m[12/27 13:50:13 d2.evaluation.evaluator]: \u001b[0mInference done 26/570. Dataloading: 0.0019 s/iter. Inference: 0.0996 s/iter. Eval: 0.2534 s/iter. Total: 0.3552 s/iter. ETA=0:03:13\n",
      "\u001b[32m[12/27 13:50:18 d2.evaluation.evaluator]: \u001b[0mInference done 41/570. Dataloading: 0.0019 s/iter. Inference: 0.0995 s/iter. Eval: 0.2518 s/iter. Total: 0.3535 s/iter. ETA=0:03:06\n",
      "\u001b[32m[12/27 13:50:23 d2.evaluation.evaluator]: \u001b[0mInference done 55/570. Dataloading: 0.0020 s/iter. Inference: 0.0995 s/iter. Eval: 0.2537 s/iter. Total: 0.3553 s/iter. ETA=0:03:03\n",
      "\u001b[32m[12/27 13:50:29 d2.evaluation.evaluator]: \u001b[0mInference done 70/570. Dataloading: 0.0020 s/iter. Inference: 0.0997 s/iter. Eval: 0.2542 s/iter. Total: 0.3560 s/iter. ETA=0:02:58\n",
      "\u001b[32m[12/27 13:50:34 d2.evaluation.evaluator]: \u001b[0mInference done 84/570. Dataloading: 0.0020 s/iter. Inference: 0.0997 s/iter. Eval: 0.2587 s/iter. Total: 0.3606 s/iter. ETA=0:02:55\n",
      "\u001b[32m[12/27 13:50:39 d2.evaluation.evaluator]: \u001b[0mInference done 97/570. Dataloading: 0.0020 s/iter. Inference: 0.0998 s/iter. Eval: 0.2629 s/iter. Total: 0.3649 s/iter. ETA=0:02:52\n",
      "\u001b[32m[12/27 13:50:44 d2.evaluation.evaluator]: \u001b[0mInference done 110/570. Dataloading: 0.0020 s/iter. Inference: 0.0999 s/iter. Eval: 0.2659 s/iter. Total: 0.3680 s/iter. ETA=0:02:49\n",
      "\u001b[32m[12/27 13:50:49 d2.evaluation.evaluator]: \u001b[0mInference done 124/570. Dataloading: 0.0020 s/iter. Inference: 0.0999 s/iter. Eval: 0.2653 s/iter. Total: 0.3674 s/iter. ETA=0:02:43\n",
      "\u001b[32m[12/27 13:50:55 d2.evaluation.evaluator]: \u001b[0mInference done 136/570. Dataloading: 0.0020 s/iter. Inference: 0.0999 s/iter. Eval: 0.2721 s/iter. Total: 0.3742 s/iter. ETA=0:02:42\n",
      "\u001b[32m[12/27 13:51:00 d2.evaluation.evaluator]: \u001b[0mInference done 150/570. Dataloading: 0.0020 s/iter. Inference: 0.0998 s/iter. Eval: 0.2724 s/iter. Total: 0.3744 s/iter. ETA=0:02:37\n",
      "\u001b[32m[12/27 13:51:05 d2.evaluation.evaluator]: \u001b[0mInference done 158/570. Dataloading: 0.0020 s/iter. Inference: 0.0999 s/iter. Eval: 0.2866 s/iter. Total: 0.3886 s/iter. ETA=0:02:40\n",
      "\u001b[32m[12/27 13:51:11 d2.evaluation.evaluator]: \u001b[0mInference done 167/570. Dataloading: 0.0020 s/iter. Inference: 0.1000 s/iter. Eval: 0.3003 s/iter. Total: 0.4024 s/iter. ETA=0:02:42\n",
      "\u001b[32m[12/27 13:51:16 d2.evaluation.evaluator]: \u001b[0mInference done 173/570. Dataloading: 0.0020 s/iter. Inference: 0.1001 s/iter. Eval: 0.3170 s/iter. Total: 0.4193 s/iter. ETA=0:02:46\n",
      "\u001b[32m[12/27 13:51:21 d2.evaluation.evaluator]: \u001b[0mInference done 180/570. Dataloading: 0.0020 s/iter. Inference: 0.1001 s/iter. Eval: 0.3297 s/iter. Total: 0.4320 s/iter. ETA=0:02:48\n",
      "\u001b[32m[12/27 13:51:27 d2.evaluation.evaluator]: \u001b[0mInference done 191/570. Dataloading: 0.0020 s/iter. Inference: 0.1002 s/iter. Eval: 0.3366 s/iter. Total: 0.4391 s/iter. ETA=0:02:46\n",
      "\u001b[32m[12/27 13:51:33 d2.evaluation.evaluator]: \u001b[0mInference done 202/570. Dataloading: 0.0020 s/iter. Inference: 0.1002 s/iter. Eval: 0.3417 s/iter. Total: 0.4442 s/iter. ETA=0:02:43\n",
      "\u001b[32m[12/27 13:51:38 d2.evaluation.evaluator]: \u001b[0mInference done 208/570. Dataloading: 0.0020 s/iter. Inference: 0.1003 s/iter. Eval: 0.3542 s/iter. Total: 0.4568 s/iter. ETA=0:02:45\n",
      "\u001b[32m[12/27 13:51:43 d2.evaluation.evaluator]: \u001b[0mInference done 217/570. Dataloading: 0.0020 s/iter. Inference: 0.1003 s/iter. Eval: 0.3588 s/iter. Total: 0.4614 s/iter. ETA=0:02:42\n",
      "\u001b[32m[12/27 13:51:49 d2.evaluation.evaluator]: \u001b[0mInference done 225/570. Dataloading: 0.0020 s/iter. Inference: 0.1004 s/iter. Eval: 0.3654 s/iter. Total: 0.4680 s/iter. ETA=0:02:41\n",
      "\u001b[32m[12/27 13:51:54 d2.evaluation.evaluator]: \u001b[0mInference done 231/570. Dataloading: 0.0020 s/iter. Inference: 0.1004 s/iter. Eval: 0.3756 s/iter. Total: 0.4782 s/iter. ETA=0:02:42\n",
      "\u001b[32m[12/27 13:51:59 d2.evaluation.evaluator]: \u001b[0mInference done 236/570. Dataloading: 0.0020 s/iter. Inference: 0.1004 s/iter. Eval: 0.3902 s/iter. Total: 0.4929 s/iter. ETA=0:02:44\n",
      "\u001b[32m[12/27 13:52:05 d2.evaluation.evaluator]: \u001b[0mInference done 242/570. Dataloading: 0.0020 s/iter. Inference: 0.1004 s/iter. Eval: 0.4001 s/iter. Total: 0.5028 s/iter. ETA=0:02:44\n",
      "\u001b[32m[12/27 13:52:11 d2.evaluation.evaluator]: \u001b[0mInference done 249/570. Dataloading: 0.0020 s/iter. Inference: 0.1004 s/iter. Eval: 0.4105 s/iter. Total: 0.5131 s/iter. ETA=0:02:44\n",
      "\u001b[32m[12/27 13:52:16 d2.evaluation.evaluator]: \u001b[0mInference done 257/570. Dataloading: 0.0020 s/iter. Inference: 0.1004 s/iter. Eval: 0.4148 s/iter. Total: 0.5175 s/iter. ETA=0:02:41\n",
      "\u001b[32m[12/27 13:52:21 d2.evaluation.evaluator]: \u001b[0mInference done 265/570. Dataloading: 0.0021 s/iter. Inference: 0.1004 s/iter. Eval: 0.4185 s/iter. Total: 0.5212 s/iter. ETA=0:02:38\n",
      "\u001b[32m[12/27 13:52:26 d2.evaluation.evaluator]: \u001b[0mInference done 272/570. Dataloading: 0.0021 s/iter. Inference: 0.1004 s/iter. Eval: 0.4240 s/iter. Total: 0.5268 s/iter. ETA=0:02:36\n",
      "\u001b[32m[12/27 13:52:32 d2.evaluation.evaluator]: \u001b[0mInference done 283/570. Dataloading: 0.0021 s/iter. Inference: 0.1005 s/iter. Eval: 0.4222 s/iter. Total: 0.5249 s/iter. ETA=0:02:30\n",
      "\u001b[32m[12/27 13:52:37 d2.evaluation.evaluator]: \u001b[0mInference done 290/570. Dataloading: 0.0021 s/iter. Inference: 0.1005 s/iter. Eval: 0.4268 s/iter. Total: 0.5296 s/iter. ETA=0:02:28\n",
      "\u001b[32m[12/27 13:52:43 d2.evaluation.evaluator]: \u001b[0mInference done 298/570. Dataloading: 0.0021 s/iter. Inference: 0.1005 s/iter. Eval: 0.4340 s/iter. Total: 0.5368 s/iter. ETA=0:02:26\n",
      "\u001b[32m[12/27 13:52:48 d2.evaluation.evaluator]: \u001b[0mInference done 320/570. Dataloading: 0.0020 s/iter. Inference: 0.1001 s/iter. Eval: 0.4131 s/iter. Total: 0.5155 s/iter. ETA=0:02:08\n",
      "\u001b[32m[12/27 13:52:53 d2.evaluation.evaluator]: \u001b[0mInference done 346/570. Dataloading: 0.0020 s/iter. Inference: 0.0996 s/iter. Eval: 0.3890 s/iter. Total: 0.4909 s/iter. ETA=0:01:49\n",
      "\u001b[32m[12/27 13:52:58 d2.evaluation.evaluator]: \u001b[0mInference done 366/570. Dataloading: 0.0020 s/iter. Inference: 0.0993 s/iter. Eval: 0.3769 s/iter. Total: 0.4785 s/iter. ETA=0:01:37\n",
      "\u001b[32m[12/27 13:53:03 d2.evaluation.evaluator]: \u001b[0mInference done 376/570. Dataloading: 0.0020 s/iter. Inference: 0.0994 s/iter. Eval: 0.3777 s/iter. Total: 0.4794 s/iter. ETA=0:01:33\n",
      "\u001b[32m[12/27 13:53:09 d2.evaluation.evaluator]: \u001b[0mInference done 386/570. Dataloading: 0.0020 s/iter. Inference: 0.0995 s/iter. Eval: 0.3785 s/iter. Total: 0.4803 s/iter. ETA=0:01:28\n",
      "\u001b[32m[12/27 13:53:14 d2.evaluation.evaluator]: \u001b[0mInference done 399/570. Dataloading: 0.0021 s/iter. Inference: 0.0995 s/iter. Eval: 0.3772 s/iter. Total: 0.4790 s/iter. ETA=0:01:21\n",
      "\u001b[32m[12/27 13:53:20 d2.evaluation.evaluator]: \u001b[0mInference done 409/570. Dataloading: 0.0021 s/iter. Inference: 0.0996 s/iter. Eval: 0.3789 s/iter. Total: 0.4807 s/iter. ETA=0:01:17\n",
      "\u001b[32m[12/27 13:53:25 d2.evaluation.evaluator]: \u001b[0mInference done 418/570. Dataloading: 0.0021 s/iter. Inference: 0.0996 s/iter. Eval: 0.3806 s/iter. Total: 0.4825 s/iter. ETA=0:01:13\n",
      "\u001b[32m[12/27 13:53:30 d2.evaluation.evaluator]: \u001b[0mInference done 428/570. Dataloading: 0.0021 s/iter. Inference: 0.0997 s/iter. Eval: 0.3819 s/iter. Total: 0.4838 s/iter. ETA=0:01:08\n",
      "\u001b[32m[12/27 13:53:36 d2.evaluation.evaluator]: \u001b[0mInference done 439/570. Dataloading: 0.0021 s/iter. Inference: 0.0997 s/iter. Eval: 0.3821 s/iter. Total: 0.4841 s/iter. ETA=0:01:03\n",
      "\u001b[32m[12/27 13:53:41 d2.evaluation.evaluator]: \u001b[0mInference done 452/570. Dataloading: 0.0021 s/iter. Inference: 0.0997 s/iter. Eval: 0.3796 s/iter. Total: 0.4815 s/iter. ETA=0:00:56\n",
      "\u001b[32m[12/27 13:53:46 d2.evaluation.evaluator]: \u001b[0mInference done 471/570. Dataloading: 0.0020 s/iter. Inference: 0.0996 s/iter. Eval: 0.3708 s/iter. Total: 0.4727 s/iter. ETA=0:00:46\n",
      "\u001b[32m[12/27 13:53:51 d2.evaluation.evaluator]: \u001b[0mInference done 489/570. Dataloading: 0.0020 s/iter. Inference: 0.0995 s/iter. Eval: 0.3637 s/iter. Total: 0.4654 s/iter. ETA=0:00:37\n",
      "\u001b[32m[12/27 13:53:56 d2.evaluation.evaluator]: \u001b[0mInference done 498/570. Dataloading: 0.0020 s/iter. Inference: 0.0995 s/iter. Eval: 0.3657 s/iter. Total: 0.4675 s/iter. ETA=0:00:33\n",
      "\u001b[32m[12/27 13:54:01 d2.evaluation.evaluator]: \u001b[0mInference done 510/570. Dataloading: 0.0020 s/iter. Inference: 0.0994 s/iter. Eval: 0.3650 s/iter. Total: 0.4666 s/iter. ETA=0:00:27\n",
      "\u001b[32m[12/27 13:54:07 d2.evaluation.evaluator]: \u001b[0mInference done 521/570. Dataloading: 0.0020 s/iter. Inference: 0.0994 s/iter. Eval: 0.3657 s/iter. Total: 0.4673 s/iter. ETA=0:00:22\n",
      "\u001b[32m[12/27 13:54:12 d2.evaluation.evaluator]: \u001b[0mInference done 535/570. Dataloading: 0.0020 s/iter. Inference: 0.0993 s/iter. Eval: 0.3632 s/iter. Total: 0.4648 s/iter. ETA=0:00:16\n",
      "\u001b[32m[12/27 13:54:17 d2.evaluation.evaluator]: \u001b[0mInference done 545/570. Dataloading: 0.0020 s/iter. Inference: 0.0993 s/iter. Eval: 0.3648 s/iter. Total: 0.4664 s/iter. ETA=0:00:11\n",
      "\u001b[32m[12/27 13:54:23 d2.evaluation.evaluator]: \u001b[0mInference done 554/570. Dataloading: 0.0020 s/iter. Inference: 0.0993 s/iter. Eval: 0.3669 s/iter. Total: 0.4684 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/27 13:54:29 d2.evaluation.evaluator]: \u001b[0mInference done 565/570. Dataloading: 0.0020 s/iter. Inference: 0.0992 s/iter. Eval: 0.3680 s/iter. Total: 0.4695 s/iter. ETA=0:00:02\n",
      "\u001b[32m[12/27 13:54:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:25.242535 (0.469456 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 13:54:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:56 (0.099205 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 13:54:31 d2.engine.defaults]: \u001b[0mEvaluation results for livecell_val in csv format:\n",
      "\u001b[32m[12/27 13:54:31 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.27020212294449913\n"
     ]
    }
   ],
   "source": [
    "trainModelLiveCell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CZyoAFsJoc1E",
    "outputId": "5bbe4c5a-1480-46f7-8fdc-14191fd5ae57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/0\n",
      "\u001b[32m[12/27 14:05:07 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[12/27 14:05:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[12/27 14:05:07 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/27 14:05:07 d2.data.common]: \u001b[0mSerializing 545 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:05:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.01 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/27 14:05:08 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/detectron2/data/detection_utils.py:433: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/usr/local/lib/python3.7/dist-packages/detectron2/data/detection_utils.py:433: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/27 14:05:16 d2.utils.events]: \u001b[0m eta: 1:06:16  iter: 19  total_loss: 1.286  loss_cls: 0.6369  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.4405  loss_rpn_loc: 0.1593  time: 0.3868  data_time: 0.0587  lr: 2.4976e-05  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:05:24 d2.utils.events]: \u001b[0m eta: 1:06:03  iter: 39  total_loss: 1.081  loss_cls: 0.5504  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.3244  loss_rpn_loc: 0.1659  time: 0.3879  data_time: 0.0123  lr: 4.9951e-05  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:05:32 d2.utils.events]: \u001b[0m eta: 1:05:47  iter: 59  total_loss: 0.8182  loss_cls: 0.4056  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.2942  loss_rpn_loc: 0.1271  time: 0.3904  data_time: 0.0150  lr: 7.4926e-05  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:05:40 d2.utils.events]: \u001b[0m eta: 1:05:39  iter: 79  total_loss: 0.6276  loss_cls: 0.281  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.2424  loss_rpn_loc: 0.1368  time: 0.3927  data_time: 0.0184  lr: 9.9901e-05  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:05:48 d2.utils.events]: \u001b[0m eta: 1:05:31  iter: 99  total_loss: 0.5548  loss_cls: 0.1324  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.255  loss_rpn_loc: 0.1559  time: 0.3924  data_time: 0.0134  lr: 0.00012488  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:05:56 d2.utils.events]: \u001b[0m eta: 1:05:21  iter: 119  total_loss: 0.4048  loss_cls: 0.05345  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.2012  loss_rpn_loc: 0.1152  time: 0.3932  data_time: 0.0122  lr: 0.00014985  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:06:04 d2.utils.events]: \u001b[0m eta: 1:05:17  iter: 139  total_loss: 0.3514  loss_cls: 0.0624  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.1761  loss_rpn_loc: 0.1307  time: 0.3945  data_time: 0.0140  lr: 0.00017483  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:06:12 d2.utils.events]: \u001b[0m eta: 1:04:54  iter: 159  total_loss: 0.2916  loss_cls: 0.02171  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.1349  loss_rpn_loc: 0.131  time: 0.3929  data_time: 0.0115  lr: 0.0001998  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:06:19 d2.utils.events]: \u001b[0m eta: 1:04:45  iter: 179  total_loss: 0.2602  loss_cls: 0.01209  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.134  loss_rpn_loc: 0.1139  time: 0.3922  data_time: 0.0103  lr: 0.00022478  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:06:27 d2.utils.events]: \u001b[0m eta: 1:04:24  iter: 199  total_loss: 0.2469  loss_cls: 0.01052  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.134  loss_rpn_loc: 0.1316  time: 0.3934  data_time: 0.0361  lr: 0.00024975  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:06:35 d2.utils.events]: \u001b[0m eta: 1:04:14  iter: 219  total_loss: 0.2284  loss_cls: 0.006394  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.09753  loss_rpn_loc: 0.1139  time: 0.3924  data_time: 0.0133  lr: 0.00027473  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:06:43 d2.utils.events]: \u001b[0m eta: 1:04:06  iter: 239  total_loss: 0.2585  loss_cls: 0.002389  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.09121  loss_rpn_loc: 0.1411  time: 0.3925  data_time: 0.0137  lr: 0.0002997  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:06:51 d2.utils.events]: \u001b[0m eta: 1:03:51  iter: 259  total_loss: 0.1776  loss_cls: 0.004256  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.08214  loss_rpn_loc: 0.1083  time: 0.3915  data_time: 0.0091  lr: 0.00032468  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:06:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:06:55 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:06:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:06:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:06:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0822 s/iter. Eval: 0.0000 s/iter. Total: 0.0838 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:07:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.981139 (0.088949 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:07:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082161 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:07:01 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:07:01 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:07:05 d2.utils.events]: \u001b[0m eta: 1:03:53  iter: 279  total_loss: 0.1867  loss_cls: 0.0008719  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.07531  loss_rpn_loc: 0.1052  time: 0.3922  data_time: 0.0151  lr: 0.00034965  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:07:12 d2.utils.events]: \u001b[0m eta: 1:03:39  iter: 299  total_loss: 0.1641  loss_cls: 0.001123  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.06671  loss_rpn_loc: 0.1011  time: 0.3914  data_time: 0.0098  lr: 0.00037463  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:07:20 d2.utils.events]: \u001b[0m eta: 1:03:28  iter: 319  total_loss: 0.2448  loss_cls: 0.00222  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0865  loss_rpn_loc: 0.1231  time: 0.3915  data_time: 0.0234  lr: 0.0003996  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:07:28 d2.utils.events]: \u001b[0m eta: 1:03:23  iter: 339  total_loss: 0.1893  loss_cls: 0.002189  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.066  loss_rpn_loc: 0.1031  time: 0.3915  data_time: 0.0131  lr: 0.00042458  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:07:35 d2.utils.events]: \u001b[0m eta: 1:03:12  iter: 359  total_loss: 0.1651  loss_cls: 0.002946  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04893  loss_rpn_loc: 0.09358  time: 0.3902  data_time: 0.0120  lr: 0.00044955  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:07:43 d2.utils.events]: \u001b[0m eta: 1:03:02  iter: 379  total_loss: 0.1726  loss_cls: 0.0004205  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0489  loss_rpn_loc: 0.1251  time: 0.3906  data_time: 0.0265  lr: 0.00047453  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:07:51 d2.utils.events]: \u001b[0m eta: 1:02:57  iter: 399  total_loss: 0.2002  loss_cls: 0.0008839  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.07109  loss_rpn_loc: 0.1292  time: 0.3908  data_time: 0.0146  lr: 0.0004995  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:07:59 d2.utils.events]: \u001b[0m eta: 1:02:48  iter: 419  total_loss: 0.2103  loss_cls: 0.0005213  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.05954  loss_rpn_loc: 0.1453  time: 0.3903  data_time: 0.0095  lr: 0.00052448  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:08:06 d2.utils.events]: \u001b[0m eta: 1:02:26  iter: 439  total_loss: 0.152  loss_cls: 0.001144  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04877  loss_rpn_loc: 0.0971  time: 0.3893  data_time: 0.0096  lr: 0.00054945  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:08:14 d2.utils.events]: \u001b[0m eta: 1:02:24  iter: 459  total_loss: 0.1771  loss_cls: 0.0005252  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04466  loss_rpn_loc: 0.1093  time: 0.3895  data_time: 0.0133  lr: 0.00057443  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:08:21 d2.utils.events]: \u001b[0m eta: 1:02:04  iter: 479  total_loss: 0.1119  loss_cls: 0.0004479  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02852  loss_rpn_loc: 0.08237  time: 0.3886  data_time: 0.0077  lr: 0.0005994  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:08:29 d2.utils.events]: \u001b[0m eta: 1:01:59  iter: 499  total_loss: 0.1299  loss_cls: 0.0006144  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04736  loss_rpn_loc: 0.08773  time: 0.3889  data_time: 0.0179  lr: 0.00062438  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:08:37 d2.utils.events]: \u001b[0m eta: 1:01:49  iter: 519  total_loss: 0.1551  loss_cls: 0.0005846  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03905  loss_rpn_loc: 0.112  time: 0.3883  data_time: 0.0091  lr: 0.00064935  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:08:45 d2.utils.events]: \u001b[0m eta: 1:01:36  iter: 539  total_loss: 0.1365  loss_cls: 0.0006973  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04171  loss_rpn_loc: 0.1007  time: 0.3884  data_time: 0.0207  lr: 0.00067433  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:08:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:08:46 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:08:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:08:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:08:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0812 s/iter. Eval: 0.0000 s/iter. Total: 0.0826 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:08:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.913896 (0.087748 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:08:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081424 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:08:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:08:52 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:08:58 d2.utils.events]: \u001b[0m eta: 1:01:25  iter: 559  total_loss: 0.1299  loss_cls: 0.0004857  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03675  loss_rpn_loc: 0.09521  time: 0.3880  data_time: 0.0097  lr: 0.0006993  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:09:06 d2.utils.events]: \u001b[0m eta: 1:01:11  iter: 579  total_loss: 0.1431  loss_cls: 0.000642  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03417  loss_rpn_loc: 0.1031  time: 0.3876  data_time: 0.0161  lr: 0.00072428  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:09:13 d2.utils.events]: \u001b[0m eta: 1:01:03  iter: 599  total_loss: 0.1577  loss_cls: 0.0003651  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02587  loss_rpn_loc: 0.1168  time: 0.3872  data_time: 0.0097  lr: 0.00074925  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:09:21 d2.utils.events]: \u001b[0m eta: 1:00:55  iter: 619  total_loss: 0.1553  loss_cls: 0.0003847  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03691  loss_rpn_loc: 0.1039  time: 0.3872  data_time: 0.0154  lr: 0.00077423  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:09:29 d2.utils.events]: \u001b[0m eta: 1:00:47  iter: 639  total_loss: 0.1305  loss_cls: 0.0005539  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02964  loss_rpn_loc: 0.1031  time: 0.3873  data_time: 0.0094  lr: 0.0007992  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:09:37 d2.utils.events]: \u001b[0m eta: 1:00:39  iter: 659  total_loss: 0.15  loss_cls: 0.0003888  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03891  loss_rpn_loc: 0.1163  time: 0.3873  data_time: 0.0123  lr: 0.00082418  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:09:44 d2.utils.events]: \u001b[0m eta: 1:00:29  iter: 679  total_loss: 0.1059  loss_cls: 0.0004186  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01719  loss_rpn_loc: 0.07944  time: 0.3870  data_time: 0.0102  lr: 0.00084915  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:09:52 d2.utils.events]: \u001b[0m eta: 1:00:16  iter: 699  total_loss: 0.1411  loss_cls: 0.0002081  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03065  loss_rpn_loc: 0.09965  time: 0.3868  data_time: 0.0128  lr: 0.00087413  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:10:00 d2.utils.events]: \u001b[0m eta: 1:00:09  iter: 719  total_loss: 0.1666  loss_cls: 0.0002445  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0556  loss_rpn_loc: 0.118  time: 0.3868  data_time: 0.0153  lr: 0.0008991  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:10:07 d2.utils.events]: \u001b[0m eta: 1:00:01  iter: 739  total_loss: 0.1656  loss_cls: 0.0001672  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03622  loss_rpn_loc: 0.1181  time: 0.3870  data_time: 0.0192  lr: 0.00092408  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:10:15 d2.utils.events]: \u001b[0m eta: 0:59:53  iter: 759  total_loss: 0.1504  loss_cls: 0.0002596  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03729  loss_rpn_loc: 0.1162  time: 0.3870  data_time: 0.0196  lr: 0.00094905  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:10:23 d2.utils.events]: \u001b[0m eta: 0:59:45  iter: 779  total_loss: 0.1148  loss_cls: 0.0002315  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0276  loss_rpn_loc: 0.0962  time: 0.3868  data_time: 0.0112  lr: 0.00097403  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:10:31 d2.utils.events]: \u001b[0m eta: 0:59:45  iter: 799  total_loss: 0.135  loss_cls: 0.0002428  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03681  loss_rpn_loc: 0.09697  time: 0.3870  data_time: 0.0122  lr: 0.000999  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:10:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:10:37 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:10:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:10:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:10:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0817 s/iter. Eval: 0.0000 s/iter. Total: 0.0833 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:10:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.949613 (0.088386 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:10:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081885 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:10:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:10:43 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:10:44 d2.utils.events]: \u001b[0m eta: 0:59:34  iter: 819  total_loss: 0.1277  loss_cls: 0.0002481  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02559  loss_rpn_loc: 0.09022  time: 0.3869  data_time: 0.0135  lr: 0.001024  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:10:52 d2.utils.events]: \u001b[0m eta: 0:59:22  iter: 839  total_loss: 0.126  loss_cls: 0.0001887  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02271  loss_rpn_loc: 0.09653  time: 0.3868  data_time: 0.0085  lr: 0.001049  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:11:00 d2.utils.events]: \u001b[0m eta: 0:59:18  iter: 859  total_loss: 0.2057  loss_cls: 0.0004344  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.05276  loss_rpn_loc: 0.1398  time: 0.3868  data_time: 0.0152  lr: 0.0010739  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:11:07 d2.utils.events]: \u001b[0m eta: 0:59:10  iter: 879  total_loss: 0.1281  loss_cls: 0.0003792  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03741  loss_rpn_loc: 0.08762  time: 0.3868  data_time: 0.0166  lr: 0.0010989  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:11:15 d2.utils.events]: \u001b[0m eta: 0:59:00  iter: 899  total_loss: 0.1582  loss_cls: 0.0002431  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03888  loss_rpn_loc: 0.1182  time: 0.3867  data_time: 0.0094  lr: 0.0011239  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:11:23 d2.utils.events]: \u001b[0m eta: 0:58:54  iter: 919  total_loss: 0.09633  loss_cls: 0.0001397  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01411  loss_rpn_loc: 0.07894  time: 0.3869  data_time: 0.0163  lr: 0.0011489  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:11:31 d2.utils.events]: \u001b[0m eta: 0:58:46  iter: 939  total_loss: 0.1481  loss_cls: 0.0002024  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03852  loss_rpn_loc: 0.1025  time: 0.3868  data_time: 0.0151  lr: 0.0011738  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:11:38 d2.utils.events]: \u001b[0m eta: 0:58:36  iter: 959  total_loss: 0.1468  loss_cls: 0.0002215  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03964  loss_rpn_loc: 0.1208  time: 0.3868  data_time: 0.0105  lr: 0.0011988  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:11:46 d2.utils.events]: \u001b[0m eta: 0:58:28  iter: 979  total_loss: 0.1476  loss_cls: 0.0001513  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03397  loss_rpn_loc: 0.1137  time: 0.3866  data_time: 0.0097  lr: 0.0012238  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:11:54 d2.utils.events]: \u001b[0m eta: 0:58:18  iter: 999  total_loss: 0.1272  loss_cls: 0.0002012  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02832  loss_rpn_loc: 0.09729  time: 0.3865  data_time: 0.0132  lr: 0.0012488  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:12:01 d2.utils.events]: \u001b[0m eta: 0:58:10  iter: 1019  total_loss: 0.1489  loss_cls: 0.0001976  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02695  loss_rpn_loc: 0.1182  time: 0.3865  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:12:09 d2.utils.events]: \u001b[0m eta: 0:58:00  iter: 1039  total_loss: 0.1273  loss_cls: 0.00036  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02214  loss_rpn_loc: 0.1046  time: 0.3863  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:12:16 d2.utils.events]: \u001b[0m eta: 0:57:50  iter: 1059  total_loss: 0.1162  loss_cls: 0.0001094  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0178  loss_rpn_loc: 0.09424  time: 0.3860  data_time: 0.0106  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:12:24 d2.utils.events]: \u001b[0m eta: 0:57:39  iter: 1079  total_loss: 0.1281  loss_cls: 0.0001706  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02494  loss_rpn_loc: 0.1027  time: 0.3857  data_time: 0.0132  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:12:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:12:27 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:12:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:12:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:12:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0821 s/iter. Eval: 0.0000 s/iter. Total: 0.0836 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:12:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.936886 (0.088159 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:12:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081765 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:12:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:12:33 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:12:37 d2.utils.events]: \u001b[0m eta: 0:57:30  iter: 1099  total_loss: 0.131  loss_cls: 0.0001113  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01808  loss_rpn_loc: 0.09988  time: 0.3856  data_time: 0.0095  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:12:45 d2.utils.events]: \u001b[0m eta: 0:57:21  iter: 1119  total_loss: 0.1283  loss_cls: 0.0001726  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02425  loss_rpn_loc: 0.1031  time: 0.3854  data_time: 0.0085  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:12:53 d2.utils.events]: \u001b[0m eta: 0:57:14  iter: 1139  total_loss: 0.1597  loss_cls: 0.0001131  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03944  loss_rpn_loc: 0.1113  time: 0.3856  data_time: 0.0152  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:13:01 d2.utils.events]: \u001b[0m eta: 0:57:09  iter: 1159  total_loss: 0.1297  loss_cls: 0.0001837  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0293  loss_rpn_loc: 0.1005  time: 0.3858  data_time: 0.0169  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:13:09 d2.utils.events]: \u001b[0m eta: 0:57:01  iter: 1179  total_loss: 0.1595  loss_cls: 0.0001562  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02823  loss_rpn_loc: 0.1112  time: 0.3860  data_time: 0.0133  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:13:16 d2.utils.events]: \u001b[0m eta: 0:56:56  iter: 1199  total_loss: 0.1037  loss_cls: 6.116e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02057  loss_rpn_loc: 0.0856  time: 0.3860  data_time: 0.0086  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:13:24 d2.utils.events]: \u001b[0m eta: 0:56:46  iter: 1219  total_loss: 0.1372  loss_cls: 0.0001  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02905  loss_rpn_loc: 0.09046  time: 0.3858  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:13:32 d2.utils.events]: \u001b[0m eta: 0:56:37  iter: 1239  total_loss: 0.1149  loss_cls: 0.0001372  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02537  loss_rpn_loc: 0.09664  time: 0.3859  data_time: 0.0176  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:13:39 d2.utils.events]: \u001b[0m eta: 0:56:29  iter: 1259  total_loss: 0.129  loss_cls: 0.0001881  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0253  loss_rpn_loc: 0.09951  time: 0.3858  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:13:47 d2.utils.events]: \u001b[0m eta: 0:56:19  iter: 1279  total_loss: 0.1166  loss_cls: 8.69e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02251  loss_rpn_loc: 0.09352  time: 0.3856  data_time: 0.0129  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:13:54 d2.utils.events]: \u001b[0m eta: 0:56:08  iter: 1299  total_loss: 0.139  loss_cls: 0.0001366  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03202  loss_rpn_loc: 0.1136  time: 0.3855  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:14:02 d2.utils.events]: \u001b[0m eta: 0:56:02  iter: 1319  total_loss: 0.1165  loss_cls: 0.0001213  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02789  loss_rpn_loc: 0.09315  time: 0.3855  data_time: 0.0145  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:14:10 d2.utils.events]: \u001b[0m eta: 0:55:53  iter: 1339  total_loss: 0.1418  loss_cls: 0.0001215  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03314  loss_rpn_loc: 0.1155  time: 0.3854  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:14:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:14:17 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:14:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:14:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:14:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0823 s/iter. Eval: 0.0000 s/iter. Total: 0.0837 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:14:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.918704 (0.087834 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:14:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081656 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:14:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:14:23 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:14:23 d2.utils.events]: \u001b[0m eta: 0:55:45  iter: 1359  total_loss: 0.1124  loss_cls: 7.988e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0182  loss_rpn_loc: 0.09329  time: 0.3853  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:14:31 d2.utils.events]: \u001b[0m eta: 0:55:39  iter: 1379  total_loss: 0.1177  loss_cls: 0.0001636  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02459  loss_rpn_loc: 0.09384  time: 0.3854  data_time: 0.0121  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:14:39 d2.utils.events]: \u001b[0m eta: 0:55:30  iter: 1399  total_loss: 0.1501  loss_cls: 0.0001732  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03181  loss_rpn_loc: 0.1127  time: 0.3854  data_time: 0.0129  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:14:46 d2.utils.events]: \u001b[0m eta: 0:55:21  iter: 1419  total_loss: 0.144  loss_cls: 0.0001026  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03192  loss_rpn_loc: 0.1024  time: 0.3853  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:14:54 d2.utils.events]: \u001b[0m eta: 0:55:14  iter: 1439  total_loss: 0.1341  loss_cls: 9.612e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02609  loss_rpn_loc: 0.1054  time: 0.3855  data_time: 0.0219  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:15:02 d2.utils.events]: \u001b[0m eta: 0:55:03  iter: 1459  total_loss: 0.1086  loss_cls: 0.0001297  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02479  loss_rpn_loc: 0.09138  time: 0.3851  data_time: 0.0079  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:15:09 d2.utils.events]: \u001b[0m eta: 0:54:57  iter: 1479  total_loss: 0.1327  loss_cls: 0.0001209  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02795  loss_rpn_loc: 0.1012  time: 0.3849  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:15:16 d2.utils.events]: \u001b[0m eta: 0:54:45  iter: 1499  total_loss: 0.1228  loss_cls: 0.0001311  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0202  loss_rpn_loc: 0.1032  time: 0.3847  data_time: 0.0084  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:15:24 d2.utils.events]: \u001b[0m eta: 0:54:41  iter: 1519  total_loss: 0.1132  loss_cls: 0.0001208  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02045  loss_rpn_loc: 0.09508  time: 0.3847  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:15:32 d2.utils.events]: \u001b[0m eta: 0:54:32  iter: 1539  total_loss: 0.1442  loss_cls: 0.0002594  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02963  loss_rpn_loc: 0.12  time: 0.3846  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:15:39 d2.utils.events]: \u001b[0m eta: 0:54:25  iter: 1559  total_loss: 0.09093  loss_cls: 0.0001396  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009272  loss_rpn_loc: 0.07572  time: 0.3846  data_time: 0.0152  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:15:47 d2.utils.events]: \u001b[0m eta: 0:54:18  iter: 1579  total_loss: 0.123  loss_cls: 0.0001343  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02661  loss_rpn_loc: 0.09837  time: 0.3846  data_time: 0.0125  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:15:55 d2.utils.events]: \u001b[0m eta: 0:54:11  iter: 1599  total_loss: 0.1309  loss_cls: 4.946e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02454  loss_rpn_loc: 0.1017  time: 0.3847  data_time: 0.0133  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:16:03 d2.utils.events]: \u001b[0m eta: 0:54:04  iter: 1619  total_loss: 0.138  loss_cls: 8.733e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02627  loss_rpn_loc: 0.1114  time: 0.3849  data_time: 0.0127  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:16:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:16:08 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:16:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:16:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:16:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0820 s/iter. Eval: 0.0000 s/iter. Total: 0.0836 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:16:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.967306 (0.088702 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:16:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082162 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:16:13 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:16:13 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:16:17 d2.utils.events]: \u001b[0m eta: 0:53:56  iter: 1639  total_loss: 0.1398  loss_cls: 4.669e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02989  loss_rpn_loc: 0.1084  time: 0.3849  data_time: 0.0128  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:16:25 d2.utils.events]: \u001b[0m eta: 0:53:49  iter: 1659  total_loss: 0.1871  loss_cls: 0.0001385  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03544  loss_rpn_loc: 0.1437  time: 0.3850  data_time: 0.0131  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:16:32 d2.utils.events]: \u001b[0m eta: 0:53:44  iter: 1679  total_loss: 0.1072  loss_cls: 8.036e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01637  loss_rpn_loc: 0.09445  time: 0.3850  data_time: 0.0097  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:16:40 d2.utils.events]: \u001b[0m eta: 0:53:41  iter: 1699  total_loss: 0.1863  loss_cls: 0.0001006  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03326  loss_rpn_loc: 0.1256  time: 0.3852  data_time: 0.0247  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:16:48 d2.utils.events]: \u001b[0m eta: 0:53:34  iter: 1719  total_loss: 0.1159  loss_cls: 8.987e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02536  loss_rpn_loc: 0.1095  time: 0.3852  data_time: 0.0103  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:16:56 d2.utils.events]: \u001b[0m eta: 0:53:24  iter: 1739  total_loss: 0.1012  loss_cls: 7.3e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.027  loss_rpn_loc: 0.08352  time: 0.3852  data_time: 0.0117  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:17:03 d2.utils.events]: \u001b[0m eta: 0:53:16  iter: 1759  total_loss: 0.1031  loss_cls: 5.444e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01232  loss_rpn_loc: 0.08192  time: 0.3852  data_time: 0.0088  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:17:11 d2.utils.events]: \u001b[0m eta: 0:53:08  iter: 1779  total_loss: 0.1279  loss_cls: 9.449e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02567  loss_rpn_loc: 0.1052  time: 0.3851  data_time: 0.0121  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:17:19 d2.utils.events]: \u001b[0m eta: 0:52:55  iter: 1799  total_loss: 0.1522  loss_cls: 9.684e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02596  loss_rpn_loc: 0.1197  time: 0.3850  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:17:26 d2.utils.events]: \u001b[0m eta: 0:52:48  iter: 1819  total_loss: 0.145  loss_cls: 0.0001846  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03316  loss_rpn_loc: 0.119  time: 0.3851  data_time: 0.0143  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:17:34 d2.utils.events]: \u001b[0m eta: 0:52:41  iter: 1839  total_loss: 0.08883  loss_cls: 0.0001053  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01886  loss_rpn_loc: 0.06567  time: 0.3850  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:17:41 d2.utils.events]: \u001b[0m eta: 0:52:31  iter: 1859  total_loss: 0.1341  loss_cls: 9.723e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02901  loss_rpn_loc: 0.09663  time: 0.3849  data_time: 0.0132  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:17:49 d2.utils.events]: \u001b[0m eta: 0:52:22  iter: 1879  total_loss: 0.116  loss_cls: 4.985e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02059  loss_rpn_loc: 0.08101  time: 0.3848  data_time: 0.0095  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:17:57 d2.utils.events]: \u001b[0m eta: 0:52:15  iter: 1899  total_loss: 0.1256  loss_cls: 5.531e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01938  loss_rpn_loc: 0.1143  time: 0.3848  data_time: 0.0097  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:17:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:17:58 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:17:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:17:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:18:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0823 s/iter. Eval: 0.0000 s/iter. Total: 0.0839 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:18:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.971606 (0.088779 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:18:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082143 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:18:04 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:18:04 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:18:10 d2.utils.events]: \u001b[0m eta: 0:52:08  iter: 1919  total_loss: 0.1196  loss_cls: 6.082e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02722  loss_rpn_loc: 0.09395  time: 0.3849  data_time: 0.0128  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:18:18 d2.utils.events]: \u001b[0m eta: 0:52:03  iter: 1939  total_loss: 0.1098  loss_cls: 6.694e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01886  loss_rpn_loc: 0.09029  time: 0.3849  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:18:26 d2.utils.events]: \u001b[0m eta: 0:51:57  iter: 1959  total_loss: 0.1167  loss_cls: 7.573e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02423  loss_rpn_loc: 0.09448  time: 0.3849  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:18:34 d2.utils.events]: \u001b[0m eta: 0:51:49  iter: 1979  total_loss: 0.1071  loss_cls: 3.419e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01171  loss_rpn_loc: 0.08255  time: 0.3849  data_time: 0.0110  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:18:42 d2.utils.events]: \u001b[0m eta: 0:51:45  iter: 1999  total_loss: 0.1091  loss_cls: 6.026e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01441  loss_rpn_loc: 0.09752  time: 0.3850  data_time: 0.0127  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:18:50 d2.utils.events]: \u001b[0m eta: 0:51:39  iter: 2019  total_loss: 0.08363  loss_cls: 0.000102  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01398  loss_rpn_loc: 0.07231  time: 0.3853  data_time: 0.0211  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:18:58 d2.utils.events]: \u001b[0m eta: 0:51:31  iter: 2039  total_loss: 0.1064  loss_cls: 4.268e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02305  loss_rpn_loc: 0.07643  time: 0.3853  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:19:06 d2.utils.events]: \u001b[0m eta: 0:51:26  iter: 2059  total_loss: 0.1152  loss_cls: 5.504e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02246  loss_rpn_loc: 0.08991  time: 0.3855  data_time: 0.0282  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:19:14 d2.utils.events]: \u001b[0m eta: 0:51:18  iter: 2079  total_loss: 0.1411  loss_cls: 8.106e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02416  loss_rpn_loc: 0.1086  time: 0.3855  data_time: 0.0106  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:19:22 d2.utils.events]: \u001b[0m eta: 0:51:12  iter: 2099  total_loss: 0.1348  loss_cls: 4.113e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01888  loss_rpn_loc: 0.114  time: 0.3857  data_time: 0.0190  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:19:30 d2.utils.events]: \u001b[0m eta: 0:51:08  iter: 2119  total_loss: 0.15  loss_cls: 8.767e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02578  loss_rpn_loc: 0.1255  time: 0.3860  data_time: 0.0191  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:19:38 d2.utils.events]: \u001b[0m eta: 0:51:03  iter: 2139  total_loss: 0.192  loss_cls: 0.000112  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0439  loss_rpn_loc: 0.1548  time: 0.3863  data_time: 0.0185  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:19:46 d2.utils.events]: \u001b[0m eta: 0:50:53  iter: 2159  total_loss: 0.1406  loss_cls: 5.457e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02971  loss_rpn_loc: 0.1146  time: 0.3864  data_time: 0.0129  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:19:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:19:53 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:19:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:19:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:19:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0838 s/iter. Eval: 0.0000 s/iter. Total: 0.0854 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:19:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:05.131420 (0.091633 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:19:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.083546 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:19:59 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:19:59 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:20:01 d2.utils.events]: \u001b[0m eta: 0:50:45  iter: 2179  total_loss: 0.1139  loss_cls: 6.634e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02256  loss_rpn_loc: 0.09636  time: 0.3865  data_time: 0.0134  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:20:08 d2.utils.events]: \u001b[0m eta: 0:50:37  iter: 2199  total_loss: 0.1192  loss_cls: 0.000116  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02312  loss_rpn_loc: 0.08828  time: 0.3865  data_time: 0.0150  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:20:17 d2.utils.events]: \u001b[0m eta: 0:50:35  iter: 2219  total_loss: 0.119  loss_cls: 2.298e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01177  loss_rpn_loc: 0.09475  time: 0.3867  data_time: 0.0199  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:20:25 d2.utils.events]: \u001b[0m eta: 0:50:35  iter: 2239  total_loss: 0.1125  loss_cls: 5.405e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01885  loss_rpn_loc: 0.09547  time: 0.3869  data_time: 0.0192  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:20:32 d2.utils.events]: \u001b[0m eta: 0:50:27  iter: 2259  total_loss: 0.1304  loss_cls: 5.106e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02516  loss_rpn_loc: 0.1004  time: 0.3869  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:20:40 d2.utils.events]: \u001b[0m eta: 0:50:19  iter: 2279  total_loss: 0.1215  loss_cls: 8.046e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02097  loss_rpn_loc: 0.09458  time: 0.3868  data_time: 0.0164  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:20:48 d2.utils.events]: \u001b[0m eta: 0:50:14  iter: 2299  total_loss: 0.1361  loss_cls: 0.0001018  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02669  loss_rpn_loc: 0.1153  time: 0.3869  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:20:56 d2.utils.events]: \u001b[0m eta: 0:50:06  iter: 2319  total_loss: 0.137  loss_cls: 6.482e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01435  loss_rpn_loc: 0.1209  time: 0.3870  data_time: 0.0140  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:21:04 d2.utils.events]: \u001b[0m eta: 0:49:56  iter: 2339  total_loss: 0.126  loss_cls: 4.067e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0198  loss_rpn_loc: 0.1001  time: 0.3869  data_time: 0.0095  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:21:12 d2.utils.events]: \u001b[0m eta: 0:49:51  iter: 2359  total_loss: 0.1285  loss_cls: 0.0001332  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02539  loss_rpn_loc: 0.1022  time: 0.3870  data_time: 0.0117  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:21:20 d2.utils.events]: \u001b[0m eta: 0:49:47  iter: 2379  total_loss: 0.1413  loss_cls: 5.189e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02382  loss_rpn_loc: 0.1157  time: 0.3872  data_time: 0.0165  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:21:27 d2.utils.events]: \u001b[0m eta: 0:49:42  iter: 2399  total_loss: 0.1198  loss_cls: 3.666e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02875  loss_rpn_loc: 0.09069  time: 0.3872  data_time: 0.0123  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:21:35 d2.utils.events]: \u001b[0m eta: 0:49:36  iter: 2419  total_loss: 0.1292  loss_cls: 7.117e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02395  loss_rpn_loc: 0.09437  time: 0.3871  data_time: 0.0125  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:21:43 d2.utils.events]: \u001b[0m eta: 0:49:26  iter: 2439  total_loss: 0.1224  loss_cls: 8.978e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0244  loss_rpn_loc: 0.09321  time: 0.3872  data_time: 0.0137  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:21:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:21:46 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:21:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:21:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:21:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0821 s/iter. Eval: 0.0000 s/iter. Total: 0.0837 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:21:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.983955 (0.088999 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:21:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082337 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:21:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:21:52 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:21:57 d2.utils.events]: \u001b[0m eta: 0:49:24  iter: 2459  total_loss: 0.1152  loss_cls: 4.955e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01351  loss_rpn_loc: 0.1023  time: 0.3872  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:22:05 d2.utils.events]: \u001b[0m eta: 0:49:18  iter: 2479  total_loss: 0.129  loss_cls: 8.965e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01725  loss_rpn_loc: 0.1128  time: 0.3874  data_time: 0.0236  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:22:13 d2.utils.events]: \u001b[0m eta: 0:49:14  iter: 2499  total_loss: 0.1135  loss_cls: 0.0001073  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02457  loss_rpn_loc: 0.09079  time: 0.3875  data_time: 0.0187  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:22:21 d2.utils.events]: \u001b[0m eta: 0:49:03  iter: 2519  total_loss: 0.07721  loss_cls: 4.937e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.05696  time: 0.3875  data_time: 0.0081  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:22:28 d2.utils.events]: \u001b[0m eta: 0:48:58  iter: 2539  total_loss: 0.1182  loss_cls: 9.407e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02138  loss_rpn_loc: 0.09701  time: 0.3874  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:22:36 d2.utils.events]: \u001b[0m eta: 0:48:53  iter: 2559  total_loss: 0.1082  loss_cls: 4.776e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01778  loss_rpn_loc: 0.09211  time: 0.3874  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:22:44 d2.utils.events]: \u001b[0m eta: 0:48:53  iter: 2579  total_loss: 0.1955  loss_cls: 8.395e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03208  loss_rpn_loc: 0.1659  time: 0.3876  data_time: 0.0167  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:22:52 d2.utils.events]: \u001b[0m eta: 0:48:45  iter: 2599  total_loss: 0.1206  loss_cls: 7.7e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0241  loss_rpn_loc: 0.09346  time: 0.3876  data_time: 0.0149  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:23:00 d2.utils.events]: \u001b[0m eta: 0:48:37  iter: 2619  total_loss: 0.1317  loss_cls: 0.0001007  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02056  loss_rpn_loc: 0.1055  time: 0.3876  data_time: 0.0132  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:23:08 d2.utils.events]: \u001b[0m eta: 0:48:27  iter: 2639  total_loss: 0.1546  loss_cls: 0.0001344  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02391  loss_rpn_loc: 0.1286  time: 0.3876  data_time: 0.0240  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:23:15 d2.utils.events]: \u001b[0m eta: 0:48:15  iter: 2659  total_loss: 0.1074  loss_cls: 7.489e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01846  loss_rpn_loc: 0.09012  time: 0.3876  data_time: 0.0101  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:23:23 d2.utils.events]: \u001b[0m eta: 0:48:01  iter: 2679  total_loss: 0.1158  loss_cls: 7.338e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.016  loss_rpn_loc: 0.09728  time: 0.3875  data_time: 0.0093  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:23:31 d2.utils.events]: \u001b[0m eta: 0:47:51  iter: 2699  total_loss: 0.1184  loss_cls: 9.766e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02398  loss_rpn_loc: 0.1036  time: 0.3875  data_time: 0.0141  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:23:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:23:38 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:23:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:23:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:23:39 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0822 s/iter. Eval: 0.0000 s/iter. Total: 0.0839 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:23:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.981104 (0.088948 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:23:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082403 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:23:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:23:44 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:23:44 d2.utils.events]: \u001b[0m eta: 0:47:39  iter: 2719  total_loss: 0.1117  loss_cls: 3.79e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0243  loss_rpn_loc: 0.07627  time: 0.3874  data_time: 0.0084  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:23:52 d2.utils.events]: \u001b[0m eta: 0:47:34  iter: 2739  total_loss: 0.09551  loss_cls: 6.614e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01433  loss_rpn_loc: 0.07635  time: 0.3874  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:24:00 d2.utils.events]: \u001b[0m eta: 0:47:27  iter: 2759  total_loss: 0.1641  loss_cls: 4.79e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02736  loss_rpn_loc: 0.1274  time: 0.3875  data_time: 0.0164  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:24:07 d2.utils.events]: \u001b[0m eta: 0:47:17  iter: 2779  total_loss: 0.1034  loss_cls: 4.731e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01852  loss_rpn_loc: 0.07522  time: 0.3874  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:24:15 d2.utils.events]: \u001b[0m eta: 0:47:12  iter: 2799  total_loss: 0.1359  loss_cls: 3.246e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02122  loss_rpn_loc: 0.1121  time: 0.3874  data_time: 0.0160  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:24:23 d2.utils.events]: \u001b[0m eta: 0:47:03  iter: 2819  total_loss: 0.08993  loss_cls: 7.677e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009804  loss_rpn_loc: 0.0801  time: 0.3874  data_time: 0.0134  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:24:31 d2.utils.events]: \u001b[0m eta: 0:46:57  iter: 2839  total_loss: 0.174  loss_cls: 7.993e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03172  loss_rpn_loc: 0.1528  time: 0.3874  data_time: 0.0181  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:24:38 d2.utils.events]: \u001b[0m eta: 0:46:49  iter: 2859  total_loss: 0.08563  loss_cls: 3.575e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01283  loss_rpn_loc: 0.07353  time: 0.3874  data_time: 0.0087  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:24:46 d2.utils.events]: \u001b[0m eta: 0:46:42  iter: 2879  total_loss: 0.1084  loss_cls: 4.82e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02481  loss_rpn_loc: 0.08561  time: 0.3873  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:24:54 d2.utils.events]: \u001b[0m eta: 0:46:38  iter: 2899  total_loss: 0.1415  loss_cls: 5.954e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02836  loss_rpn_loc: 0.1072  time: 0.3874  data_time: 0.0141  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:25:02 d2.utils.events]: \u001b[0m eta: 0:46:26  iter: 2919  total_loss: 0.1283  loss_cls: 7.22e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02007  loss_rpn_loc: 0.09978  time: 0.3875  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:25:09 d2.utils.events]: \u001b[0m eta: 0:46:18  iter: 2939  total_loss: 0.1281  loss_cls: 5.803e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02193  loss_rpn_loc: 0.1054  time: 0.3874  data_time: 0.0125  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:25:17 d2.utils.events]: \u001b[0m eta: 0:46:10  iter: 2959  total_loss: 0.185  loss_cls: 0.0001186  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03461  loss_rpn_loc: 0.1155  time: 0.3874  data_time: 0.0181  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:25:25 d2.utils.events]: \u001b[0m eta: 0:46:02  iter: 2979  total_loss: 0.1403  loss_cls: 4.081e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02449  loss_rpn_loc: 0.1109  time: 0.3874  data_time: 0.0160  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:25:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:25:30 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:25:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:25:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:25:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0830 s/iter. Eval: 0.0000 s/iter. Total: 0.0845 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:25:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.972248 (0.088790 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:25:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082316 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:25:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:25:35 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:25:39 d2.utils.events]: \u001b[0m eta: 0:45:54  iter: 2999  total_loss: 0.101  loss_cls: 6.511e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01459  loss_rpn_loc: 0.08473  time: 0.3874  data_time: 0.0173  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:25:46 d2.utils.events]: \u001b[0m eta: 0:45:42  iter: 3019  total_loss: 0.1288  loss_cls: 6.229e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02218  loss_rpn_loc: 0.09698  time: 0.3874  data_time: 0.0171  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:25:54 d2.utils.events]: \u001b[0m eta: 0:45:37  iter: 3039  total_loss: 0.1447  loss_cls: 8.063e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0302  loss_rpn_loc: 0.1155  time: 0.3874  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:26:02 d2.utils.events]: \u001b[0m eta: 0:45:26  iter: 3059  total_loss: 0.1101  loss_cls: 4.097e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01623  loss_rpn_loc: 0.08927  time: 0.3874  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:26:10 d2.utils.events]: \u001b[0m eta: 0:45:21  iter: 3079  total_loss: 0.102  loss_cls: 4.598e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01437  loss_rpn_loc: 0.0865  time: 0.3875  data_time: 0.0230  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:26:18 d2.utils.events]: \u001b[0m eta: 0:45:08  iter: 3099  total_loss: 0.1809  loss_cls: 7.702e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0378  loss_rpn_loc: 0.1463  time: 0.3875  data_time: 0.0142  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:26:25 d2.utils.events]: \u001b[0m eta: 0:44:55  iter: 3119  total_loss: 0.117  loss_cls: 6.412e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02705  loss_rpn_loc: 0.09547  time: 0.3874  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:26:33 d2.utils.events]: \u001b[0m eta: 0:44:44  iter: 3139  total_loss: 0.08204  loss_cls: 5.059e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01113  loss_rpn_loc: 0.0708  time: 0.3874  data_time: 0.0144  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:26:41 d2.utils.events]: \u001b[0m eta: 0:44:34  iter: 3159  total_loss: 0.1154  loss_cls: 6.116e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01918  loss_rpn_loc: 0.09491  time: 0.3874  data_time: 0.0116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:26:48 d2.utils.events]: \u001b[0m eta: 0:44:23  iter: 3179  total_loss: 0.1739  loss_cls: 8.282e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01962  loss_rpn_loc: 0.1545  time: 0.3873  data_time: 0.0149  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:26:56 d2.utils.events]: \u001b[0m eta: 0:44:15  iter: 3199  total_loss: 0.1089  loss_cls: 2.356e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01638  loss_rpn_loc: 0.0921  time: 0.3873  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:27:04 d2.utils.events]: \u001b[0m eta: 0:44:06  iter: 3219  total_loss: 0.13  loss_cls: 4.271e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02939  loss_rpn_loc: 0.107  time: 0.3873  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:27:11 d2.utils.events]: \u001b[0m eta: 0:43:58  iter: 3239  total_loss: 0.1007  loss_cls: 4.666e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01456  loss_rpn_loc: 0.08456  time: 0.3873  data_time: 0.0095  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:27:19 d2.utils.events]: \u001b[0m eta: 0:43:49  iter: 3259  total_loss: 0.1145  loss_cls: 8.07e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0267  loss_rpn_loc: 0.08709  time: 0.3873  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:27:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:27:21 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:27:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:27:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:27:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0826 s/iter. Eval: 0.0000 s/iter. Total: 0.0842 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:27:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.966849 (0.088694 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:27:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082304 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:27:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:27:27 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:27:33 d2.utils.events]: \u001b[0m eta: 0:43:41  iter: 3279  total_loss: 0.09917  loss_cls: 4.711e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01632  loss_rpn_loc: 0.08288  time: 0.3873  data_time: 0.0130  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:27:41 d2.utils.events]: \u001b[0m eta: 0:43:32  iter: 3299  total_loss: 0.11  loss_cls: 8.483e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01815  loss_rpn_loc: 0.08395  time: 0.3873  data_time: 0.0127  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:27:48 d2.utils.events]: \u001b[0m eta: 0:43:24  iter: 3319  total_loss: 0.09397  loss_cls: 9.383e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01653  loss_rpn_loc: 0.07732  time: 0.3873  data_time: 0.0145  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:27:56 d2.utils.events]: \u001b[0m eta: 0:43:17  iter: 3339  total_loss: 0.1248  loss_cls: 4.546e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02292  loss_rpn_loc: 0.08987  time: 0.3873  data_time: 0.0110  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:28:03 d2.utils.events]: \u001b[0m eta: 0:43:06  iter: 3359  total_loss: 0.1182  loss_cls: 0.0001115  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01847  loss_rpn_loc: 0.09872  time: 0.3872  data_time: 0.0121  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:28:12 d2.utils.events]: \u001b[0m eta: 0:42:57  iter: 3379  total_loss: 0.1344  loss_cls: 6.99e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02003  loss_rpn_loc: 0.09876  time: 0.3873  data_time: 0.0190  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:28:19 d2.utils.events]: \u001b[0m eta: 0:42:48  iter: 3399  total_loss: 0.1224  loss_cls: 5.974e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.1032  time: 0.3872  data_time: 0.0138  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:28:27 d2.utils.events]: \u001b[0m eta: 0:42:43  iter: 3419  total_loss: 0.1097  loss_cls: 0.0001114  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02505  loss_rpn_loc: 0.09235  time: 0.3873  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:28:35 d2.utils.events]: \u001b[0m eta: 0:42:35  iter: 3439  total_loss: 0.1318  loss_cls: 5.093e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02751  loss_rpn_loc: 0.09106  time: 0.3873  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:28:43 d2.utils.events]: \u001b[0m eta: 0:42:26  iter: 3459  total_loss: 0.1178  loss_cls: 3.973e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01359  loss_rpn_loc: 0.09303  time: 0.3872  data_time: 0.0123  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:28:50 d2.utils.events]: \u001b[0m eta: 0:42:15  iter: 3479  total_loss: 0.1064  loss_cls: 3.906e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0204  loss_rpn_loc: 0.08886  time: 0.3872  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:28:58 d2.utils.events]: \u001b[0m eta: 0:42:10  iter: 3499  total_loss: 0.1549  loss_cls: 4.453e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02616  loss_rpn_loc: 0.1108  time: 0.3872  data_time: 0.0152  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:29:06 d2.utils.events]: \u001b[0m eta: 0:42:05  iter: 3519  total_loss: 0.1317  loss_cls: 3.349e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02436  loss_rpn_loc: 0.1073  time: 0.3873  data_time: 0.0220  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:29:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:29:12 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:29:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:29:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:29:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0820 s/iter. Eval: 0.0000 s/iter. Total: 0.0836 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:29:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.977630 (0.088886 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:29:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082266 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:29:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:29:18 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:29:20 d2.utils.events]: \u001b[0m eta: 0:41:58  iter: 3539  total_loss: 0.09319  loss_cls: 3.437e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.004832  loss_rpn_loc: 0.08563  time: 0.3873  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:29:28 d2.utils.events]: \u001b[0m eta: 0:41:50  iter: 3559  total_loss: 0.1191  loss_cls: 8.028e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0212  loss_rpn_loc: 0.09212  time: 0.3874  data_time: 0.0159  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:29:36 d2.utils.events]: \u001b[0m eta: 0:41:40  iter: 3579  total_loss: 0.1283  loss_cls: 5.649e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01293  loss_rpn_loc: 0.1061  time: 0.3874  data_time: 0.0196  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:29:44 d2.utils.events]: \u001b[0m eta: 0:41:32  iter: 3599  total_loss: 0.1325  loss_cls: 1.582e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02442  loss_rpn_loc: 0.1079  time: 0.3875  data_time: 0.0147  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:29:51 d2.utils.events]: \u001b[0m eta: 0:41:25  iter: 3619  total_loss: 0.1146  loss_cls: 7.153e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0154  loss_rpn_loc: 0.09296  time: 0.3874  data_time: 0.0096  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:29:59 d2.utils.events]: \u001b[0m eta: 0:41:17  iter: 3639  total_loss: 0.1655  loss_cls: 9.276e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02773  loss_rpn_loc: 0.1177  time: 0.3875  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:30:07 d2.utils.events]: \u001b[0m eta: 0:41:11  iter: 3659  total_loss: 0.1118  loss_cls: 2.25e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01177  loss_rpn_loc: 0.09986  time: 0.3874  data_time: 0.0122  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:30:14 d2.utils.events]: \u001b[0m eta: 0:41:05  iter: 3679  total_loss: 0.1249  loss_cls: 6.132e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02282  loss_rpn_loc: 0.09783  time: 0.3874  data_time: 0.0134  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:30:22 d2.utils.events]: \u001b[0m eta: 0:40:58  iter: 3699  total_loss: 0.1109  loss_cls: 5.409e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01546  loss_rpn_loc: 0.09869  time: 0.3874  data_time: 0.0130  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:30:30 d2.utils.events]: \u001b[0m eta: 0:40:52  iter: 3719  total_loss: 0.1086  loss_cls: 7.217e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02462  loss_rpn_loc: 0.08385  time: 0.3874  data_time: 0.0138  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:30:38 d2.utils.events]: \u001b[0m eta: 0:40:46  iter: 3739  total_loss: 0.1097  loss_cls: 5.867e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02204  loss_rpn_loc: 0.08869  time: 0.3874  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:30:46 d2.utils.events]: \u001b[0m eta: 0:40:36  iter: 3759  total_loss: 0.126  loss_cls: 5.094e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02084  loss_rpn_loc: 0.08613  time: 0.3874  data_time: 0.0085  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:30:53 d2.utils.events]: \u001b[0m eta: 0:40:32  iter: 3779  total_loss: 0.1068  loss_cls: 6.868e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02623  loss_rpn_loc: 0.08244  time: 0.3875  data_time: 0.0136  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:31:01 d2.utils.events]: \u001b[0m eta: 0:40:21  iter: 3799  total_loss: 0.1048  loss_cls: 4.139e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01855  loss_rpn_loc: 0.08758  time: 0.3874  data_time: 0.0086  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:31:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:31:04 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:31:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:31:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:31:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0822 s/iter. Eval: 0.0000 s/iter. Total: 0.0838 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:31:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.975045 (0.088840 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:31:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082363 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:31:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:31:10 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:31:14 d2.utils.events]: \u001b[0m eta: 0:40:14  iter: 3819  total_loss: 0.1412  loss_cls: 8.009e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0163  loss_rpn_loc: 0.1166  time: 0.3873  data_time: 0.0116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:31:22 d2.utils.events]: \u001b[0m eta: 0:40:08  iter: 3839  total_loss: 0.1128  loss_cls: 3.664e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0152  loss_rpn_loc: 0.0959  time: 0.3874  data_time: 0.0141  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:31:30 d2.utils.events]: \u001b[0m eta: 0:40:01  iter: 3859  total_loss: 0.09904  loss_cls: 3.543e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01371  loss_rpn_loc: 0.08028  time: 0.3874  data_time: 0.0100  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:31:38 d2.utils.events]: \u001b[0m eta: 0:39:55  iter: 3879  total_loss: 0.1499  loss_cls: 6.816e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0233  loss_rpn_loc: 0.13  time: 0.3874  data_time: 0.0166  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:31:46 d2.utils.events]: \u001b[0m eta: 0:39:46  iter: 3899  total_loss: 0.09645  loss_cls: 3.57e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.015  loss_rpn_loc: 0.08317  time: 0.3874  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:31:54 d2.utils.events]: \u001b[0m eta: 0:39:38  iter: 3919  total_loss: 0.1119  loss_cls: 3.313e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01977  loss_rpn_loc: 0.09302  time: 0.3874  data_time: 0.0137  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:32:01 d2.utils.events]: \u001b[0m eta: 0:39:30  iter: 3939  total_loss: 0.1054  loss_cls: 2.947e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01798  loss_rpn_loc: 0.09233  time: 0.3874  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:32:09 d2.utils.events]: \u001b[0m eta: 0:39:22  iter: 3959  total_loss: 0.1444  loss_cls: 4.866e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02138  loss_rpn_loc: 0.1162  time: 0.3874  data_time: 0.0250  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:32:17 d2.utils.events]: \u001b[0m eta: 0:39:15  iter: 3979  total_loss: 0.1483  loss_cls: 2.855e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02315  loss_rpn_loc: 0.1209  time: 0.3874  data_time: 0.0133  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:32:25 d2.utils.events]: \u001b[0m eta: 0:39:07  iter: 3999  total_loss: 0.1069  loss_cls: 7.633e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0189  loss_rpn_loc: 0.08043  time: 0.3875  data_time: 0.0110  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:32:33 d2.utils.events]: \u001b[0m eta: 0:39:00  iter: 4019  total_loss: 0.1217  loss_cls: 6.502e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01985  loss_rpn_loc: 0.1013  time: 0.3875  data_time: 0.0134  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:32:40 d2.utils.events]: \u001b[0m eta: 0:38:50  iter: 4039  total_loss: 0.1283  loss_cls: 6.031e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02021  loss_rpn_loc: 0.1  time: 0.3874  data_time: 0.0092  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:32:48 d2.utils.events]: \u001b[0m eta: 0:38:43  iter: 4059  total_loss: 0.101  loss_cls: 5.525e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01753  loss_rpn_loc: 0.08019  time: 0.3875  data_time: 0.0136  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:32:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:32:56 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:32:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:32:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:32:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0820 s/iter. Eval: 0.0000 s/iter. Total: 0.0837 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:33:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.982271 (0.088969 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:33:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082456 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:33:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:33:02 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:33:02 d2.utils.events]: \u001b[0m eta: 0:38:35  iter: 4079  total_loss: 0.1028  loss_cls: 6.358e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01626  loss_rpn_loc: 0.08709  time: 0.3875  data_time: 0.0235  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:33:10 d2.utils.events]: \u001b[0m eta: 0:38:27  iter: 4099  total_loss: 0.1017  loss_cls: 3.18e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02031  loss_rpn_loc: 0.08081  time: 0.3875  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:33:17 d2.utils.events]: \u001b[0m eta: 0:38:21  iter: 4119  total_loss: 0.1176  loss_cls: 4.486e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01373  loss_rpn_loc: 0.09981  time: 0.3875  data_time: 0.0139  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:33:25 d2.utils.events]: \u001b[0m eta: 0:38:12  iter: 4139  total_loss: 0.1473  loss_cls: 4.582e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02063  loss_rpn_loc: 0.1146  time: 0.3875  data_time: 0.0134  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:33:33 d2.utils.events]: \u001b[0m eta: 0:38:05  iter: 4159  total_loss: 0.1091  loss_cls: 4.243e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01759  loss_rpn_loc: 0.09229  time: 0.3875  data_time: 0.0127  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:33:41 d2.utils.events]: \u001b[0m eta: 0:37:58  iter: 4179  total_loss: 0.0923  loss_cls: 6.245e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01299  loss_rpn_loc: 0.08289  time: 0.3875  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:33:48 d2.utils.events]: \u001b[0m eta: 0:37:50  iter: 4199  total_loss: 0.1233  loss_cls: 6.649e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02945  loss_rpn_loc: 0.0989  time: 0.3874  data_time: 0.0176  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:33:56 d2.utils.events]: \u001b[0m eta: 0:37:42  iter: 4219  total_loss: 0.1157  loss_cls: 4.559e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01366  loss_rpn_loc: 0.1001  time: 0.3874  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:34:04 d2.utils.events]: \u001b[0m eta: 0:37:36  iter: 4239  total_loss: 0.1961  loss_cls: 4.127e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03411  loss_rpn_loc: 0.1481  time: 0.3875  data_time: 0.0224  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:34:12 d2.utils.events]: \u001b[0m eta: 0:37:29  iter: 4259  total_loss: 0.11  loss_cls: 0.0001123  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02472  loss_rpn_loc: 0.08731  time: 0.3875  data_time: 0.0097  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:34:20 d2.utils.events]: \u001b[0m eta: 0:37:22  iter: 4279  total_loss: 0.1097  loss_cls: 5.664e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02286  loss_rpn_loc: 0.09275  time: 0.3875  data_time: 0.0152  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:34:28 d2.utils.events]: \u001b[0m eta: 0:37:15  iter: 4299  total_loss: 0.09578  loss_cls: 5.379e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01714  loss_rpn_loc: 0.08493  time: 0.3876  data_time: 0.0135  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:34:35 d2.utils.events]: \u001b[0m eta: 0:37:05  iter: 4319  total_loss: 0.09222  loss_cls: 6.178e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009159  loss_rpn_loc: 0.08177  time: 0.3875  data_time: 0.0099  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:34:43 d2.utils.events]: \u001b[0m eta: 0:36:58  iter: 4339  total_loss: 0.137  loss_cls: 8.457e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03329  loss_rpn_loc: 0.1159  time: 0.3875  data_time: 0.0135  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:34:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:34:47 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:34:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:34:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:34:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0825 s/iter. Eval: 0.0000 s/iter. Total: 0.0841 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:34:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.974142 (0.088824 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:34:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082192 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:34:53 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:34:53 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:34:56 d2.utils.events]: \u001b[0m eta: 0:36:50  iter: 4359  total_loss: 0.08446  loss_cls: 3.024e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01188  loss_rpn_loc: 0.0762  time: 0.3875  data_time: 0.0088  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:35:04 d2.utils.events]: \u001b[0m eta: 0:36:40  iter: 4379  total_loss: 0.09845  loss_cls: 3.577e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01454  loss_rpn_loc: 0.08593  time: 0.3875  data_time: 0.0101  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:35:12 d2.utils.events]: \u001b[0m eta: 0:36:33  iter: 4399  total_loss: 0.09445  loss_cls: 4.658e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01418  loss_rpn_loc: 0.07755  time: 0.3875  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:35:20 d2.utils.events]: \u001b[0m eta: 0:36:25  iter: 4419  total_loss: 0.08143  loss_cls: 3.556e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01642  loss_rpn_loc: 0.06991  time: 0.3875  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:35:27 d2.utils.events]: \u001b[0m eta: 0:36:17  iter: 4439  total_loss: 0.1357  loss_cls: 4.393e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02938  loss_rpn_loc: 0.1046  time: 0.3875  data_time: 0.0099  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:35:35 d2.utils.events]: \u001b[0m eta: 0:36:10  iter: 4459  total_loss: 0.1017  loss_cls: 5.597e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01662  loss_rpn_loc: 0.08825  time: 0.3875  data_time: 0.0100  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:35:43 d2.utils.events]: \u001b[0m eta: 0:36:01  iter: 4479  total_loss: 0.1081  loss_cls: 5.535e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01491  loss_rpn_loc: 0.09782  time: 0.3874  data_time: 0.0097  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:35:51 d2.utils.events]: \u001b[0m eta: 0:35:53  iter: 4499  total_loss: 0.1411  loss_cls: 7.27e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02049  loss_rpn_loc: 0.1136  time: 0.3874  data_time: 0.0128  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:35:58 d2.utils.events]: \u001b[0m eta: 0:35:44  iter: 4519  total_loss: 0.09056  loss_cls: 5.474e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01886  loss_rpn_loc: 0.07278  time: 0.3874  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:36:06 d2.utils.events]: \u001b[0m eta: 0:35:37  iter: 4539  total_loss: 0.1222  loss_cls: 3.086e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02715  loss_rpn_loc: 0.09769  time: 0.3874  data_time: 0.0122  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:36:14 d2.utils.events]: \u001b[0m eta: 0:35:29  iter: 4559  total_loss: 0.1154  loss_cls: 2.47e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01712  loss_rpn_loc: 0.08329  time: 0.3874  data_time: 0.0172  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:36:22 d2.utils.events]: \u001b[0m eta: 0:35:21  iter: 4579  total_loss: 0.1513  loss_cls: 3.373e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02168  loss_rpn_loc: 0.1236  time: 0.3874  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:36:30 d2.utils.events]: \u001b[0m eta: 0:35:13  iter: 4599  total_loss: 0.1649  loss_cls: 5.505e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02635  loss_rpn_loc: 0.1394  time: 0.3875  data_time: 0.0224  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:36:37 d2.utils.events]: \u001b[0m eta: 0:35:05  iter: 4619  total_loss: 0.09651  loss_cls: 4.273e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01638  loss_rpn_loc: 0.08397  time: 0.3875  data_time: 0.0089  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:36:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:36:39 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:36:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:36:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:36:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0822 s/iter. Eval: 0.0000 s/iter. Total: 0.0838 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:36:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.991254 (0.089130 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:36:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082561 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:36:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:36:45 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:36:51 d2.utils.events]: \u001b[0m eta: 0:34:57  iter: 4639  total_loss: 0.1244  loss_cls: 4.905e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02276  loss_rpn_loc: 0.1006  time: 0.3875  data_time: 0.0155  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:36:59 d2.utils.events]: \u001b[0m eta: 0:34:49  iter: 4659  total_loss: 0.1047  loss_cls: 2.287e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01679  loss_rpn_loc: 0.08449  time: 0.3875  data_time: 0.0103  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:37:07 d2.utils.events]: \u001b[0m eta: 0:34:42  iter: 4679  total_loss: 0.1053  loss_cls: 6.48e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01995  loss_rpn_loc: 0.08801  time: 0.3875  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:37:15 d2.utils.events]: \u001b[0m eta: 0:34:34  iter: 4699  total_loss: 0.1036  loss_cls: 3.515e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01039  loss_rpn_loc: 0.08639  time: 0.3875  data_time: 0.0127  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:37:22 d2.utils.events]: \u001b[0m eta: 0:34:27  iter: 4719  total_loss: 0.1254  loss_cls: 3.788e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02215  loss_rpn_loc: 0.1014  time: 0.3876  data_time: 0.0173  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:37:30 d2.utils.events]: \u001b[0m eta: 0:34:19  iter: 4739  total_loss: 0.104  loss_cls: 4.79e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02355  loss_rpn_loc: 0.08083  time: 0.3876  data_time: 0.0188  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:37:38 d2.utils.events]: \u001b[0m eta: 0:34:10  iter: 4759  total_loss: 0.115  loss_cls: 2.689e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01774  loss_rpn_loc: 0.1031  time: 0.3876  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:37:46 d2.utils.events]: \u001b[0m eta: 0:34:03  iter: 4779  total_loss: 0.1021  loss_cls: 2.427e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01737  loss_rpn_loc: 0.08723  time: 0.3876  data_time: 0.0100  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:37:54 d2.utils.events]: \u001b[0m eta: 0:33:56  iter: 4799  total_loss: 0.1009  loss_cls: 4.353e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01524  loss_rpn_loc: 0.0838  time: 0.3876  data_time: 0.0117  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:38:01 d2.utils.events]: \u001b[0m eta: 0:33:47  iter: 4819  total_loss: 0.09855  loss_cls: 2.606e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01248  loss_rpn_loc: 0.09015  time: 0.3876  data_time: 0.0097  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:38:09 d2.utils.events]: \u001b[0m eta: 0:33:39  iter: 4839  total_loss: 0.1085  loss_cls: 5.204e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01663  loss_rpn_loc: 0.08989  time: 0.3876  data_time: 0.0136  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:38:17 d2.utils.events]: \u001b[0m eta: 0:33:31  iter: 4859  total_loss: 0.1209  loss_cls: 5.735e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01856  loss_rpn_loc: 0.09899  time: 0.3876  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:38:25 d2.utils.events]: \u001b[0m eta: 0:33:23  iter: 4879  total_loss: 0.1489  loss_cls: 4.575e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01725  loss_rpn_loc: 0.1281  time: 0.3876  data_time: 0.0209  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:38:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:38:31 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:38:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:38:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:38:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0824 s/iter. Eval: 0.0000 s/iter. Total: 0.0840 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:38:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.996659 (0.089226 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:38:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082701 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:38:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:38:37 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:38:39 d2.utils.events]: \u001b[0m eta: 0:33:15  iter: 4899  total_loss: 0.1326  loss_cls: 2.636e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01743  loss_rpn_loc: 0.1121  time: 0.3877  data_time: 0.0140  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:38:46 d2.utils.events]: \u001b[0m eta: 0:33:07  iter: 4919  total_loss: 0.08812  loss_cls: 2.807e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01161  loss_rpn_loc: 0.07596  time: 0.3876  data_time: 0.0080  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:38:54 d2.utils.events]: \u001b[0m eta: 0:33:00  iter: 4939  total_loss: 0.1728  loss_cls: 5.844e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02214  loss_rpn_loc: 0.1201  time: 0.3877  data_time: 0.0178  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:39:02 d2.utils.events]: \u001b[0m eta: 0:32:53  iter: 4959  total_loss: 0.1207  loss_cls: 1.786e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01641  loss_rpn_loc: 0.1048  time: 0.3877  data_time: 0.0128  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:39:10 d2.utils.events]: \u001b[0m eta: 0:32:45  iter: 4979  total_loss: 0.1183  loss_cls: 3.994e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01893  loss_rpn_loc: 0.1012  time: 0.3877  data_time: 0.0099  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:39:19 d2.utils.events]: \u001b[0m eta: 0:32:37  iter: 4999  total_loss: 0.1003  loss_cls: 2.045e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01831  loss_rpn_loc: 0.08856  time: 0.3877  data_time: 0.0149  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:39:28 d2.utils.events]: \u001b[0m eta: 0:32:28  iter: 5019  total_loss: 0.09755  loss_cls: 1.154e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01793  loss_rpn_loc: 0.08146  time: 0.3876  data_time: 0.0096  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:39:36 d2.utils.events]: \u001b[0m eta: 0:32:21  iter: 5039  total_loss: 0.1115  loss_cls: 2.729e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01616  loss_rpn_loc: 0.09513  time: 0.3876  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:39:44 d2.utils.events]: \u001b[0m eta: 0:32:14  iter: 5059  total_loss: 0.148  loss_cls: 4.509e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02018  loss_rpn_loc: 0.1214  time: 0.3877  data_time: 0.0136  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:39:51 d2.utils.events]: \u001b[0m eta: 0:32:06  iter: 5079  total_loss: 0.104  loss_cls: 5.766e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02613  loss_rpn_loc: 0.07756  time: 0.3877  data_time: 0.0123  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:40:00 d2.utils.events]: \u001b[0m eta: 0:32:00  iter: 5099  total_loss: 0.1377  loss_cls: 3.812e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01161  loss_rpn_loc: 0.112  time: 0.3878  data_time: 0.0163  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:40:07 d2.utils.events]: \u001b[0m eta: 0:31:52  iter: 5119  total_loss: 0.09075  loss_cls: 3.524e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01094  loss_rpn_loc: 0.08184  time: 0.3878  data_time: 0.0084  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:40:15 d2.utils.events]: \u001b[0m eta: 0:31:46  iter: 5139  total_loss: 0.1097  loss_cls: 3.882e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0232  loss_rpn_loc: 0.0902  time: 0.3877  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:40:23 d2.utils.events]: \u001b[0m eta: 0:31:38  iter: 5159  total_loss: 0.1106  loss_cls: 4.494e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0152  loss_rpn_loc: 0.09144  time: 0.3877  data_time: 0.0147  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:40:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:40:26 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:40:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:40:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:40:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0824 s/iter. Eval: 0.0000 s/iter. Total: 0.0839 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:40:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.982729 (0.088977 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:40:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082484 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:40:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:40:32 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:40:36 d2.utils.events]: \u001b[0m eta: 0:31:31  iter: 5179  total_loss: 0.1132  loss_cls: 4.392e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01701  loss_rpn_loc: 0.09141  time: 0.3878  data_time: 0.0168  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:40:44 d2.utils.events]: \u001b[0m eta: 0:31:25  iter: 5199  total_loss: 0.1308  loss_cls: 5.283e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02227  loss_rpn_loc: 0.1155  time: 0.3878  data_time: 0.0139  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:40:52 d2.utils.events]: \u001b[0m eta: 0:31:18  iter: 5219  total_loss: 0.09347  loss_cls: 2.606e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01527  loss_rpn_loc: 0.07468  time: 0.3878  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:41:00 d2.utils.events]: \u001b[0m eta: 0:31:08  iter: 5239  total_loss: 0.1136  loss_cls: 4.364e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01983  loss_rpn_loc: 0.09607  time: 0.3878  data_time: 0.0191  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:41:08 d2.utils.events]: \u001b[0m eta: 0:31:00  iter: 5259  total_loss: 0.1019  loss_cls: 2.344e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01809  loss_rpn_loc: 0.08879  time: 0.3878  data_time: 0.0138  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:41:16 d2.utils.events]: \u001b[0m eta: 0:30:52  iter: 5279  total_loss: 0.178  loss_cls: 3.46e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03007  loss_rpn_loc: 0.1465  time: 0.3879  data_time: 0.0294  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:41:24 d2.utils.events]: \u001b[0m eta: 0:30:44  iter: 5299  total_loss: 0.08814  loss_cls: 2.776e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.008353  loss_rpn_loc: 0.07421  time: 0.3879  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:41:31 d2.utils.events]: \u001b[0m eta: 0:30:37  iter: 5319  total_loss: 0.1088  loss_cls: 3.47e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01358  loss_rpn_loc: 0.09309  time: 0.3879  data_time: 0.0123  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:41:39 d2.utils.events]: \u001b[0m eta: 0:30:29  iter: 5339  total_loss: 0.1138  loss_cls: 3.285e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01455  loss_rpn_loc: 0.1011  time: 0.3879  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:41:47 d2.utils.events]: \u001b[0m eta: 0:30:21  iter: 5359  total_loss: 0.09805  loss_cls: 1.957e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01239  loss_rpn_loc: 0.08235  time: 0.3878  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:41:54 d2.utils.events]: \u001b[0m eta: 0:30:13  iter: 5379  total_loss: 0.1446  loss_cls: 6.204e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01912  loss_rpn_loc: 0.1238  time: 0.3878  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:42:02 d2.utils.events]: \u001b[0m eta: 0:30:05  iter: 5399  total_loss: 0.1074  loss_cls: 4.446e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01604  loss_rpn_loc: 0.0923  time: 0.3878  data_time: 0.0166  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:42:10 d2.utils.events]: \u001b[0m eta: 0:29:57  iter: 5419  total_loss: 0.09601  loss_cls: 1.446e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01511  loss_rpn_loc: 0.07835  time: 0.3878  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:42:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:42:18 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:42:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:42:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:42:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0832 s/iter. Eval: 0.0000 s/iter. Total: 0.0848 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:42:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.986246 (0.089040 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:42:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082540 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:42:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:42:24 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:42:24 d2.utils.events]: \u001b[0m eta: 0:29:50  iter: 5439  total_loss: 0.1238  loss_cls: 4.296e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01947  loss_rpn_loc: 0.1081  time: 0.3878  data_time: 0.0147  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:42:32 d2.utils.events]: \u001b[0m eta: 0:29:42  iter: 5459  total_loss: 0.1016  loss_cls: 5.207e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01821  loss_rpn_loc: 0.08774  time: 0.3878  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:42:40 d2.utils.events]: \u001b[0m eta: 0:29:34  iter: 5479  total_loss: 0.16  loss_cls: 3.846e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02253  loss_rpn_loc: 0.1306  time: 0.3879  data_time: 0.0229  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:42:47 d2.utils.events]: \u001b[0m eta: 0:29:27  iter: 5499  total_loss: 0.117  loss_cls: 3.649e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01938  loss_rpn_loc: 0.09339  time: 0.3879  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:42:55 d2.utils.events]: \u001b[0m eta: 0:29:19  iter: 5519  total_loss: 0.1213  loss_cls: 3.137e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01995  loss_rpn_loc: 0.09904  time: 0.3879  data_time: 0.0215  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:43:03 d2.utils.events]: \u001b[0m eta: 0:29:12  iter: 5539  total_loss: 0.1263  loss_cls: 4.232e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01799  loss_rpn_loc: 0.09777  time: 0.3880  data_time: 0.0120  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:43:11 d2.utils.events]: \u001b[0m eta: 0:29:03  iter: 5559  total_loss: 0.1379  loss_cls: 4.297e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01706  loss_rpn_loc: 0.09889  time: 0.3880  data_time: 0.0117  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:43:19 d2.utils.events]: \u001b[0m eta: 0:28:55  iter: 5579  total_loss: 0.1019  loss_cls: 3.819e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01873  loss_rpn_loc: 0.08122  time: 0.3880  data_time: 0.0096  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:43:27 d2.utils.events]: \u001b[0m eta: 0:28:47  iter: 5599  total_loss: 0.09388  loss_cls: 9.7e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01215  loss_rpn_loc: 0.08067  time: 0.3879  data_time: 0.0087  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:43:34 d2.utils.events]: \u001b[0m eta: 0:28:37  iter: 5619  total_loss: 0.09407  loss_cls: 3.228e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02088  loss_rpn_loc: 0.06887  time: 0.3879  data_time: 0.0084  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:43:42 d2.utils.events]: \u001b[0m eta: 0:28:29  iter: 5639  total_loss: 0.08585  loss_cls: 2.195e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009419  loss_rpn_loc: 0.07203  time: 0.3879  data_time: 0.0084  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:43:49 d2.utils.events]: \u001b[0m eta: 0:28:21  iter: 5659  total_loss: 0.09035  loss_cls: 2.245e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01395  loss_rpn_loc: 0.07544  time: 0.3878  data_time: 0.0101  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:43:57 d2.utils.events]: \u001b[0m eta: 0:28:13  iter: 5679  total_loss: 0.1386  loss_cls: 2.246e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02579  loss_rpn_loc: 0.1144  time: 0.3878  data_time: 0.0222  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:44:05 d2.utils.events]: \u001b[0m eta: 0:28:05  iter: 5699  total_loss: 0.09616  loss_cls: 3.336e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02004  loss_rpn_loc: 0.08082  time: 0.3878  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:44:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:44:10 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:44:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:44:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:44:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0822 s/iter. Eval: 0.0000 s/iter. Total: 0.0838 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:44:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.978061 (0.088894 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:44:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082280 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:44:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:44:16 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:44:19 d2.utils.events]: \u001b[0m eta: 0:27:57  iter: 5719  total_loss: 0.1219  loss_cls: 3.568e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01743  loss_rpn_loc: 0.1026  time: 0.3878  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:44:26 d2.utils.events]: \u001b[0m eta: 0:27:49  iter: 5739  total_loss: 0.08751  loss_cls: 2.083e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01285  loss_rpn_loc: 0.0746  time: 0.3878  data_time: 0.0097  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:44:34 d2.utils.events]: \u001b[0m eta: 0:27:42  iter: 5759  total_loss: 0.1306  loss_cls: 2.968e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01707  loss_rpn_loc: 0.0923  time: 0.3879  data_time: 0.0223  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:44:42 d2.utils.events]: \u001b[0m eta: 0:27:34  iter: 5779  total_loss: 0.0978  loss_cls: 1.894e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01612  loss_rpn_loc: 0.07897  time: 0.3879  data_time: 0.0088  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:44:50 d2.utils.events]: \u001b[0m eta: 0:27:26  iter: 5799  total_loss: 0.1436  loss_cls: 2.517e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01944  loss_rpn_loc: 0.1104  time: 0.3879  data_time: 0.0110  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:44:58 d2.utils.events]: \u001b[0m eta: 0:27:21  iter: 5819  total_loss: 0.1275  loss_cls: 2.454e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0229  loss_rpn_loc: 0.09912  time: 0.3880  data_time: 0.0139  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:45:06 d2.utils.events]: \u001b[0m eta: 0:27:12  iter: 5839  total_loss: 0.0894  loss_cls: 3.025e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009146  loss_rpn_loc: 0.07624  time: 0.3880  data_time: 0.0160  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:45:14 d2.utils.events]: \u001b[0m eta: 0:27:03  iter: 5859  total_loss: 0.09822  loss_cls: 5.232e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01936  loss_rpn_loc: 0.08283  time: 0.3879  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:45:21 d2.utils.events]: \u001b[0m eta: 0:26:55  iter: 5879  total_loss: 0.1298  loss_cls: 5.067e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02637  loss_rpn_loc: 0.1026  time: 0.3879  data_time: 0.0143  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:45:29 d2.utils.events]: \u001b[0m eta: 0:26:47  iter: 5899  total_loss: 0.1079  loss_cls: 2.75e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02317  loss_rpn_loc: 0.08718  time: 0.3879  data_time: 0.0146  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:45:37 d2.utils.events]: \u001b[0m eta: 0:26:39  iter: 5919  total_loss: 0.07892  loss_cls: 3.201e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01037  loss_rpn_loc: 0.06779  time: 0.3879  data_time: 0.0125  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:45:45 d2.utils.events]: \u001b[0m eta: 0:26:31  iter: 5939  total_loss: 0.1075  loss_cls: 4.136e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01619  loss_rpn_loc: 0.08923  time: 0.3879  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:45:53 d2.utils.events]: \u001b[0m eta: 0:26:22  iter: 5959  total_loss: 0.1175  loss_cls: 1.612e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0159  loss_rpn_loc: 0.09059  time: 0.3879  data_time: 0.0174  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:46:00 d2.utils.events]: \u001b[0m eta: 0:26:13  iter: 5979  total_loss: 0.108  loss_cls: 1.554e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01436  loss_rpn_loc: 0.08676  time: 0.3879  data_time: 0.0143  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:46:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:46:02 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:46:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:46:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:46:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0826 s/iter. Eval: 0.0000 s/iter. Total: 0.0842 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:46:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.992227 (0.089147 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:46:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082572 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:46:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:46:08 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:46:14 d2.utils.events]: \u001b[0m eta: 0:26:07  iter: 5999  total_loss: 0.1465  loss_cls: 6.678e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02522  loss_rpn_loc: 0.1198  time: 0.3880  data_time: 0.0145  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:46:22 d2.utils.events]: \u001b[0m eta: 0:26:00  iter: 6019  total_loss: 0.1166  loss_cls: 3.198e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02455  loss_rpn_loc: 0.09899  time: 0.3880  data_time: 0.0183  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:46:30 d2.utils.events]: \u001b[0m eta: 0:25:52  iter: 6039  total_loss: 0.09948  loss_cls: 7.206e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01563  loss_rpn_loc: 0.08049  time: 0.3879  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:46:37 d2.utils.events]: \u001b[0m eta: 0:25:44  iter: 6059  total_loss: 0.1001  loss_cls: 3.31e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01333  loss_rpn_loc: 0.08885  time: 0.3880  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:46:45 d2.utils.events]: \u001b[0m eta: 0:25:34  iter: 6079  total_loss: 0.1201  loss_cls: 4.007e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01689  loss_rpn_loc: 0.1037  time: 0.3879  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:46:53 d2.utils.events]: \u001b[0m eta: 0:25:26  iter: 6099  total_loss: 0.1004  loss_cls: 3.315e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01551  loss_rpn_loc: 0.08478  time: 0.3879  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:47:00 d2.utils.events]: \u001b[0m eta: 0:25:19  iter: 6119  total_loss: 0.1215  loss_cls: 3.486e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02463  loss_rpn_loc: 0.09635  time: 0.3879  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:47:08 d2.utils.events]: \u001b[0m eta: 0:25:11  iter: 6139  total_loss: 0.1224  loss_cls: 5.601e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01832  loss_rpn_loc: 0.09596  time: 0.3879  data_time: 0.0170  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:47:16 d2.utils.events]: \u001b[0m eta: 0:25:03  iter: 6159  total_loss: 0.0911  loss_cls: 4.7e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01848  loss_rpn_loc: 0.07632  time: 0.3879  data_time: 0.0140  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:47:24 d2.utils.events]: \u001b[0m eta: 0:24:56  iter: 6179  total_loss: 0.1302  loss_cls: 5.359e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02897  loss_rpn_loc: 0.1068  time: 0.3879  data_time: 0.0150  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:47:32 d2.utils.events]: \u001b[0m eta: 0:24:46  iter: 6199  total_loss: 0.1314  loss_cls: 2.563e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02159  loss_rpn_loc: 0.1004  time: 0.3879  data_time: 0.0099  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:47:40 d2.utils.events]: \u001b[0m eta: 0:24:39  iter: 6219  total_loss: 0.08482  loss_cls: 1.303e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.00547  loss_rpn_loc: 0.0694  time: 0.3879  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:47:47 d2.utils.events]: \u001b[0m eta: 0:24:31  iter: 6239  total_loss: 0.134  loss_cls: 2.508e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0161  loss_rpn_loc: 0.1051  time: 0.3879  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:47:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:47:54 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:47:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:47:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:47:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0821 s/iter. Eval: 0.0000 s/iter. Total: 0.0837 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:48:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.983007 (0.088982 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:48:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082349 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:48:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:48:00 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:48:01 d2.utils.events]: \u001b[0m eta: 0:24:24  iter: 6259  total_loss: 0.1277  loss_cls: 2.433e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02082  loss_rpn_loc: 0.1022  time: 0.3879  data_time: 0.0121  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:48:09 d2.utils.events]: \u001b[0m eta: 0:24:15  iter: 6279  total_loss: 0.07935  loss_cls: 1.594e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01082  loss_rpn_loc: 0.0708  time: 0.3879  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:48:17 d2.utils.events]: \u001b[0m eta: 0:24:07  iter: 6299  total_loss: 0.1058  loss_cls: 2.781e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.008656  loss_rpn_loc: 0.09126  time: 0.3879  data_time: 0.0176  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:48:25 d2.utils.events]: \u001b[0m eta: 0:23:59  iter: 6319  total_loss: 0.1112  loss_cls: 2.648e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01618  loss_rpn_loc: 0.09273  time: 0.3880  data_time: 0.0254  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:48:33 d2.utils.events]: \u001b[0m eta: 0:23:52  iter: 6339  total_loss: 0.1224  loss_cls: 3.498e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01521  loss_rpn_loc: 0.1043  time: 0.3880  data_time: 0.0155  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:48:40 d2.utils.events]: \u001b[0m eta: 0:23:45  iter: 6359  total_loss: 0.08252  loss_cls: 2.839e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009263  loss_rpn_loc: 0.07091  time: 0.3880  data_time: 0.0072  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:48:48 d2.utils.events]: \u001b[0m eta: 0:23:36  iter: 6379  total_loss: 0.08632  loss_cls: 2.829e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01252  loss_rpn_loc: 0.07079  time: 0.3880  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:48:56 d2.utils.events]: \u001b[0m eta: 0:23:28  iter: 6399  total_loss: 0.08781  loss_cls: 1.13e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009987  loss_rpn_loc: 0.07413  time: 0.3879  data_time: 0.0137  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:49:03 d2.utils.events]: \u001b[0m eta: 0:23:21  iter: 6419  total_loss: 0.1366  loss_cls: 3.98e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0241  loss_rpn_loc: 0.1069  time: 0.3880  data_time: 0.0201  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:49:11 d2.utils.events]: \u001b[0m eta: 0:23:13  iter: 6439  total_loss: 0.1128  loss_cls: 3.209e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01752  loss_rpn_loc: 0.09754  time: 0.3880  data_time: 0.0130  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:49:19 d2.utils.events]: \u001b[0m eta: 0:23:05  iter: 6459  total_loss: 0.1355  loss_cls: 1.357e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01967  loss_rpn_loc: 0.1073  time: 0.3879  data_time: 0.0088  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:49:27 d2.utils.events]: \u001b[0m eta: 0:22:57  iter: 6479  total_loss: 0.1227  loss_cls: 2.309e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01968  loss_rpn_loc: 0.108  time: 0.3880  data_time: 0.0142  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:49:35 d2.utils.events]: \u001b[0m eta: 0:22:49  iter: 6499  total_loss: 0.187  loss_cls: 5.249e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02557  loss_rpn_loc: 0.1493  time: 0.3880  data_time: 0.0150  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:49:42 d2.utils.events]: \u001b[0m eta: 0:22:41  iter: 6519  total_loss: 0.1534  loss_cls: 5.13e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01648  loss_rpn_loc: 0.1381  time: 0.3880  data_time: 0.0140  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:49:45 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:49:45 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:49:45 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:49:45 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:49:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0822 s/iter. Eval: 0.0000 s/iter. Total: 0.0838 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:49:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.981398 (0.088954 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:49:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082565 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:49:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:49:51 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:49:56 d2.utils.events]: \u001b[0m eta: 0:22:32  iter: 6539  total_loss: 0.09154  loss_cls: 4.77e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01495  loss_rpn_loc: 0.08208  time: 0.3880  data_time: 0.0127  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:50:04 d2.utils.events]: \u001b[0m eta: 0:22:24  iter: 6559  total_loss: 0.1036  loss_cls: 3.122e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02074  loss_rpn_loc: 0.0825  time: 0.3879  data_time: 0.0098  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:50:11 d2.utils.events]: \u001b[0m eta: 0:22:17  iter: 6579  total_loss: 0.09821  loss_cls: 3.732e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01153  loss_rpn_loc: 0.07928  time: 0.3880  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:50:19 d2.utils.events]: \u001b[0m eta: 0:22:10  iter: 6599  total_loss: 0.1266  loss_cls: 5.243e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02134  loss_rpn_loc: 0.1059  time: 0.3879  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:50:27 d2.utils.events]: \u001b[0m eta: 0:22:03  iter: 6619  total_loss: 0.116  loss_cls: 5.629e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0198  loss_rpn_loc: 0.09611  time: 0.3880  data_time: 0.0172  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:50:35 d2.utils.events]: \u001b[0m eta: 0:21:56  iter: 6639  total_loss: 0.1334  loss_cls: 5.306e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01406  loss_rpn_loc: 0.1046  time: 0.3880  data_time: 0.0117  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:50:42 d2.utils.events]: \u001b[0m eta: 0:21:48  iter: 6659  total_loss: 0.08174  loss_cls: 3.139e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.012  loss_rpn_loc: 0.05834  time: 0.3879  data_time: 0.0072  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:50:50 d2.utils.events]: \u001b[0m eta: 0:21:42  iter: 6679  total_loss: 0.09969  loss_cls: 2.233e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.008077  loss_rpn_loc: 0.08413  time: 0.3879  data_time: 0.0169  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:50:58 d2.utils.events]: \u001b[0m eta: 0:21:33  iter: 6699  total_loss: 0.1066  loss_cls: 2.933e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02297  loss_rpn_loc: 0.08842  time: 0.3879  data_time: 0.0121  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:51:05 d2.utils.events]: \u001b[0m eta: 0:21:24  iter: 6719  total_loss: 0.1211  loss_cls: 3.385e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01758  loss_rpn_loc: 0.1074  time: 0.3879  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:51:13 d2.utils.events]: \u001b[0m eta: 0:21:16  iter: 6739  total_loss: 0.1282  loss_cls: 1.407e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02363  loss_rpn_loc: 0.09457  time: 0.3879  data_time: 0.0145  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:51:21 d2.utils.events]: \u001b[0m eta: 0:21:07  iter: 6759  total_loss: 0.1328  loss_cls: 1.756e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.018  loss_rpn_loc: 0.1165  time: 0.3879  data_time: 0.0088  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:51:28 d2.utils.events]: \u001b[0m eta: 0:20:59  iter: 6779  total_loss: 0.1073  loss_cls: 1.48e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01576  loss_rpn_loc: 0.08942  time: 0.3878  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:51:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:51:36 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:51:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:51:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:51:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0825 s/iter. Eval: 0.0000 s/iter. Total: 0.0841 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:51:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.980403 (0.088936 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:51:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082471 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:51:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:51:42 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:51:42 d2.utils.events]: \u001b[0m eta: 0:20:52  iter: 6799  total_loss: 0.146  loss_cls: 5.239e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02819  loss_rpn_loc: 0.1079  time: 0.3879  data_time: 0.0154  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:51:50 d2.utils.events]: \u001b[0m eta: 0:20:42  iter: 6819  total_loss: 0.1328  loss_cls: 3.486e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01305  loss_rpn_loc: 0.1098  time: 0.3878  data_time: 0.0137  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:51:58 d2.utils.events]: \u001b[0m eta: 0:20:35  iter: 6839  total_loss: 0.102  loss_cls: 2.59e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01406  loss_rpn_loc: 0.09338  time: 0.3879  data_time: 0.0143  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:52:06 d2.utils.events]: \u001b[0m eta: 0:20:28  iter: 6859  total_loss: 0.09412  loss_cls: 2.67e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01277  loss_rpn_loc: 0.07989  time: 0.3879  data_time: 0.0133  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:52:13 d2.utils.events]: \u001b[0m eta: 0:20:20  iter: 6879  total_loss: 0.1046  loss_cls: 3.145e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009681  loss_rpn_loc: 0.08739  time: 0.3879  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:52:21 d2.utils.events]: \u001b[0m eta: 0:20:12  iter: 6899  total_loss: 0.1255  loss_cls: 3.98e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01351  loss_rpn_loc: 0.09506  time: 0.3878  data_time: 0.0131  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:52:29 d2.utils.events]: \u001b[0m eta: 0:20:04  iter: 6919  total_loss: 0.1368  loss_cls: 3.586e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0196  loss_rpn_loc: 0.1025  time: 0.3878  data_time: 0.0123  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:52:37 d2.utils.events]: \u001b[0m eta: 0:19:56  iter: 6939  total_loss: 0.1615  loss_cls: 2.838e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02528  loss_rpn_loc: 0.136  time: 0.3878  data_time: 0.0103  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:52:44 d2.utils.events]: \u001b[0m eta: 0:19:49  iter: 6959  total_loss: 0.09995  loss_cls: 2.184e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01898  loss_rpn_loc: 0.07744  time: 0.3878  data_time: 0.0095  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:52:52 d2.utils.events]: \u001b[0m eta: 0:19:41  iter: 6979  total_loss: 0.09997  loss_cls: 5.352e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01665  loss_rpn_loc: 0.08548  time: 0.3878  data_time: 0.0103  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:52:59 d2.utils.events]: \u001b[0m eta: 0:19:31  iter: 6999  total_loss: 0.1063  loss_cls: 3.012e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01492  loss_rpn_loc: 0.09273  time: 0.3878  data_time: 0.0123  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:53:07 d2.utils.events]: \u001b[0m eta: 0:19:23  iter: 7019  total_loss: 0.0775  loss_cls: 2.041e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007389  loss_rpn_loc: 0.06869  time: 0.3877  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:53:15 d2.utils.events]: \u001b[0m eta: 0:19:16  iter: 7039  total_loss: 0.1364  loss_cls: 5.146e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02101  loss_rpn_loc: 0.1104  time: 0.3877  data_time: 0.0130  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:53:23 d2.utils.events]: \u001b[0m eta: 0:19:07  iter: 7059  total_loss: 0.1316  loss_cls: 3.94e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01821  loss_rpn_loc: 0.1078  time: 0.3877  data_time: 0.0129  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:53:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:53:27 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:53:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:53:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:53:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0820 s/iter. Eval: 0.0000 s/iter. Total: 0.0836 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:53:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.984189 (0.089003 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:53:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082509 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:53:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:53:33 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:53:36 d2.utils.events]: \u001b[0m eta: 0:19:00  iter: 7079  total_loss: 0.1242  loss_cls: 5.345e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02238  loss_rpn_loc: 0.0893  time: 0.3877  data_time: 0.0086  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:53:44 d2.utils.events]: \u001b[0m eta: 0:18:52  iter: 7099  total_loss: 0.08755  loss_cls: 1.848e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0173  loss_rpn_loc: 0.07469  time: 0.3877  data_time: 0.0135  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:53:52 d2.utils.events]: \u001b[0m eta: 0:18:44  iter: 7119  total_loss: 0.1504  loss_cls: 4.329e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02418  loss_rpn_loc: 0.1174  time: 0.3877  data_time: 0.0148  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:53:59 d2.utils.events]: \u001b[0m eta: 0:18:35  iter: 7139  total_loss: 0.1039  loss_cls: 2.538e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01088  loss_rpn_loc: 0.09326  time: 0.3877  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:54:07 d2.utils.events]: \u001b[0m eta: 0:18:28  iter: 7159  total_loss: 0.1199  loss_cls: 3.292e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01998  loss_rpn_loc: 0.1004  time: 0.3877  data_time: 0.0121  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:54:15 d2.utils.events]: \u001b[0m eta: 0:18:20  iter: 7179  total_loss: 0.08968  loss_cls: 2.085e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.008005  loss_rpn_loc: 0.08351  time: 0.3877  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:54:23 d2.utils.events]: \u001b[0m eta: 0:18:13  iter: 7199  total_loss: 0.08828  loss_cls: 1.638e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007208  loss_rpn_loc: 0.07703  time: 0.3877  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:54:31 d2.utils.events]: \u001b[0m eta: 0:18:06  iter: 7219  total_loss: 0.1512  loss_cls: 2.767e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02173  loss_rpn_loc: 0.1134  time: 0.3878  data_time: 0.0139  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:54:38 d2.utils.events]: \u001b[0m eta: 0:17:57  iter: 7239  total_loss: 0.0845  loss_cls: 8.797e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.011  loss_rpn_loc: 0.07038  time: 0.3877  data_time: 0.0123  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:54:46 d2.utils.events]: \u001b[0m eta: 0:17:49  iter: 7259  total_loss: 0.09  loss_cls: 5.754e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01193  loss_rpn_loc: 0.07543  time: 0.3877  data_time: 0.0089  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:54:54 d2.utils.events]: \u001b[0m eta: 0:17:41  iter: 7279  total_loss: 0.1115  loss_cls: 2.985e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0246  loss_rpn_loc: 0.08155  time: 0.3877  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:55:02 d2.utils.events]: \u001b[0m eta: 0:17:33  iter: 7299  total_loss: 0.132  loss_cls: 3.458e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01668  loss_rpn_loc: 0.1079  time: 0.3877  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:55:09 d2.utils.events]: \u001b[0m eta: 0:17:25  iter: 7319  total_loss: 0.05989  loss_cls: 8.18e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.004184  loss_rpn_loc: 0.04961  time: 0.3877  data_time: 0.0095  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:55:17 d2.utils.events]: \u001b[0m eta: 0:17:18  iter: 7339  total_loss: 0.1182  loss_cls: 5.263e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02478  loss_rpn_loc: 0.1033  time: 0.3877  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:55:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:55:19 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:55:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:55:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:55:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0823 s/iter. Eval: 0.0000 s/iter. Total: 0.0839 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:55:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:05.003605 (0.089350 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:55:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082655 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:55:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:55:25 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:55:31 d2.utils.events]: \u001b[0m eta: 0:17:10  iter: 7359  total_loss: 0.1303  loss_cls: 2.665e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01878  loss_rpn_loc: 0.1087  time: 0.3877  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:55:38 d2.utils.events]: \u001b[0m eta: 0:17:02  iter: 7379  total_loss: 0.1129  loss_cls: 5.442e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0198  loss_rpn_loc: 0.0952  time: 0.3877  data_time: 0.0154  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:55:46 d2.utils.events]: \u001b[0m eta: 0:16:55  iter: 7399  total_loss: 0.1041  loss_cls: 4.664e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01073  loss_rpn_loc: 0.08427  time: 0.3877  data_time: 0.0097  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:55:54 d2.utils.events]: \u001b[0m eta: 0:16:47  iter: 7419  total_loss: 0.09094  loss_cls: 4.874e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009543  loss_rpn_loc: 0.08029  time: 0.3877  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:56:02 d2.utils.events]: \u001b[0m eta: 0:16:39  iter: 7439  total_loss: 0.0936  loss_cls: 3.939e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01203  loss_rpn_loc: 0.08588  time: 0.3877  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:56:09 d2.utils.events]: \u001b[0m eta: 0:16:31  iter: 7459  total_loss: 0.1138  loss_cls: 4.337e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.1038  time: 0.3877  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:56:17 d2.utils.events]: \u001b[0m eta: 0:16:23  iter: 7479  total_loss: 0.1361  loss_cls: 4.136e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02135  loss_rpn_loc: 0.1168  time: 0.3877  data_time: 0.0123  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:56:25 d2.utils.events]: \u001b[0m eta: 0:16:15  iter: 7499  total_loss: 0.09076  loss_cls: 3.087e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.07909  time: 0.3877  data_time: 0.0136  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:56:32 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 7519  total_loss: 0.1337  loss_cls: 7.542e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01816  loss_rpn_loc: 0.1088  time: 0.3876  data_time: 0.0159  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:56:40 d2.utils.events]: \u001b[0m eta: 0:15:59  iter: 7539  total_loss: 0.1049  loss_cls: 2.71e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0164  loss_rpn_loc: 0.08485  time: 0.3876  data_time: 0.0157  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:56:48 d2.utils.events]: \u001b[0m eta: 0:15:52  iter: 7559  total_loss: 0.09095  loss_cls: 3.502e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01372  loss_rpn_loc: 0.07328  time: 0.3876  data_time: 0.0098  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:56:56 d2.utils.events]: \u001b[0m eta: 0:15:44  iter: 7579  total_loss: 0.1201  loss_cls: 2.104e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01483  loss_rpn_loc: 0.09659  time: 0.3876  data_time: 0.0160  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:57:04 d2.utils.events]: \u001b[0m eta: 0:15:36  iter: 7599  total_loss: 0.1071  loss_cls: 4.104e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009924  loss_rpn_loc: 0.09827  time: 0.3876  data_time: 0.0153  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:57:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:57:10 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:57:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:57:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:57:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0821 s/iter. Eval: 0.0000 s/iter. Total: 0.0837 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:57:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.994427 (0.089186 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:57:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082622 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:57:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:57:16 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:57:17 d2.utils.events]: \u001b[0m eta: 0:15:28  iter: 7619  total_loss: 0.0958  loss_cls: 2.199e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01126  loss_rpn_loc: 0.07816  time: 0.3876  data_time: 0.0128  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:57:25 d2.utils.events]: \u001b[0m eta: 0:15:20  iter: 7639  total_loss: 0.1214  loss_cls: 3.535e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0189  loss_rpn_loc: 0.09769  time: 0.3876  data_time: 0.0100  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:57:33 d2.utils.events]: \u001b[0m eta: 0:15:13  iter: 7659  total_loss: 0.1235  loss_cls: 2.268e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01912  loss_rpn_loc: 0.1089  time: 0.3876  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:57:40 d2.utils.events]: \u001b[0m eta: 0:15:05  iter: 7679  total_loss: 0.06765  loss_cls: 1.442e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01062  loss_rpn_loc: 0.05599  time: 0.3876  data_time: 0.0116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:57:48 d2.utils.events]: \u001b[0m eta: 0:14:57  iter: 7699  total_loss: 0.1564  loss_cls: 9.302e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0251  loss_rpn_loc: 0.1316  time: 0.3876  data_time: 0.0163  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:57:56 d2.utils.events]: \u001b[0m eta: 0:14:49  iter: 7719  total_loss: 0.09417  loss_cls: 3.585e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02109  loss_rpn_loc: 0.07677  time: 0.3876  data_time: 0.0106  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:58:04 d2.utils.events]: \u001b[0m eta: 0:14:42  iter: 7739  total_loss: 0.1171  loss_cls: 3.882e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01526  loss_rpn_loc: 0.101  time: 0.3876  data_time: 0.0137  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:58:11 d2.utils.events]: \u001b[0m eta: 0:14:35  iter: 7759  total_loss: 0.0998  loss_cls: 4.348e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01316  loss_rpn_loc: 0.08507  time: 0.3876  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:58:19 d2.utils.events]: \u001b[0m eta: 0:14:27  iter: 7779  total_loss: 0.09291  loss_cls: 3.345e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01751  loss_rpn_loc: 0.07897  time: 0.3876  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:58:27 d2.utils.events]: \u001b[0m eta: 0:14:20  iter: 7799  total_loss: 0.1538  loss_cls: 4.628e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0264  loss_rpn_loc: 0.1325  time: 0.3876  data_time: 0.0169  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:58:35 d2.utils.events]: \u001b[0m eta: 0:14:12  iter: 7819  total_loss: 0.07284  loss_cls: 1.952e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.005069  loss_rpn_loc: 0.06678  time: 0.3876  data_time: 0.0086  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:58:42 d2.utils.events]: \u001b[0m eta: 0:14:04  iter: 7839  total_loss: 0.09016  loss_cls: 1.261e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01287  loss_rpn_loc: 0.07599  time: 0.3876  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:58:50 d2.utils.events]: \u001b[0m eta: 0:13:57  iter: 7859  total_loss: 0.09058  loss_cls: 2.799e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.006326  loss_rpn_loc: 0.07686  time: 0.3876  data_time: 0.0095  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:58:58 d2.utils.events]: \u001b[0m eta: 0:13:49  iter: 7879  total_loss: 0.1181  loss_cls: 4.094e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02132  loss_rpn_loc: 0.09061  time: 0.3876  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:59:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 14:59:01 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 14:59:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 14:59:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 14:59:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0822 s/iter. Eval: 0.0000 s/iter. Total: 0.0836 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 14:59:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.983657 (0.088994 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:59:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082484 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 14:59:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 14:59:07 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 14:59:12 d2.utils.events]: \u001b[0m eta: 0:13:41  iter: 7899  total_loss: 0.1106  loss_cls: 3.524e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01748  loss_rpn_loc: 0.1009  time: 0.3876  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:59:19 d2.utils.events]: \u001b[0m eta: 0:13:33  iter: 7919  total_loss: 0.1051  loss_cls: 1.536e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01379  loss_rpn_loc: 0.09729  time: 0.3876  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:59:27 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 7939  total_loss: 0.1111  loss_cls: 2.825e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02505  loss_rpn_loc: 0.08998  time: 0.3876  data_time: 0.0122  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:59:35 d2.utils.events]: \u001b[0m eta: 0:13:18  iter: 7959  total_loss: 0.1254  loss_cls: 3.988e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02143  loss_rpn_loc: 0.101  time: 0.3876  data_time: 0.0174  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:59:42 d2.utils.events]: \u001b[0m eta: 0:13:10  iter: 7979  total_loss: 0.1038  loss_cls: 2.657e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01249  loss_rpn_loc: 0.08869  time: 0.3876  data_time: 0.0088  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:59:50 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 7999  total_loss: 0.1475  loss_cls: 4.802e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0257  loss_rpn_loc: 0.1179  time: 0.3876  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 14:59:58 d2.utils.events]: \u001b[0m eta: 0:12:55  iter: 8019  total_loss: 0.1125  loss_cls: 3.122e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02282  loss_rpn_loc: 0.09068  time: 0.3876  data_time: 0.0168  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:00:06 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 8039  total_loss: 0.1164  loss_cls: 4.236e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02007  loss_rpn_loc: 0.08971  time: 0.3876  data_time: 0.0121  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:00:13 d2.utils.events]: \u001b[0m eta: 0:12:39  iter: 8059  total_loss: 0.1161  loss_cls: 4.015e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01557  loss_rpn_loc: 0.09968  time: 0.3876  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:00:21 d2.utils.events]: \u001b[0m eta: 0:12:31  iter: 8079  total_loss: 0.1032  loss_cls: 3.251e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01842  loss_rpn_loc: 0.08679  time: 0.3876  data_time: 0.0100  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:00:29 d2.utils.events]: \u001b[0m eta: 0:12:22  iter: 8099  total_loss: 0.0688  loss_cls: 1.893e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007146  loss_rpn_loc: 0.06151  time: 0.3875  data_time: 0.0151  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:00:36 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 8119  total_loss: 0.1115  loss_cls: 4.061e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01641  loss_rpn_loc: 0.09367  time: 0.3875  data_time: 0.0165  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:00:44 d2.utils.events]: \u001b[0m eta: 0:12:06  iter: 8139  total_loss: 0.1263  loss_cls: 2.973e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01556  loss_rpn_loc: 0.1037  time: 0.3875  data_time: 0.0150  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:00:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:00:52 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:00:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:00:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:00:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0017 s/iter. Inference: 0.0821 s/iter. Eval: 0.0000 s/iter. Total: 0.0838 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:00:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.973732 (0.088817 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:00:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082388 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:00:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 15:00:58 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:00:58 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 8159  total_loss: 0.125  loss_cls: 3.291e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02087  loss_rpn_loc: 0.1013  time: 0.3875  data_time: 0.0127  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:01:06 d2.utils.events]: \u001b[0m eta: 0:11:50  iter: 8179  total_loss: 0.08608  loss_cls: 3.31e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.006704  loss_rpn_loc: 0.07721  time: 0.3875  data_time: 0.0143  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:01:13 d2.utils.events]: \u001b[0m eta: 0:11:42  iter: 8199  total_loss: 0.09169  loss_cls: 1.8e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01076  loss_rpn_loc: 0.07405  time: 0.3875  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:01:21 d2.utils.events]: \u001b[0m eta: 0:11:33  iter: 8219  total_loss: 0.09187  loss_cls: 3.339e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01325  loss_rpn_loc: 0.07837  time: 0.3875  data_time: 0.0140  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:01:29 d2.utils.events]: \u001b[0m eta: 0:11:26  iter: 8239  total_loss: 0.1028  loss_cls: 2.478e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01725  loss_rpn_loc: 0.08273  time: 0.3875  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:01:37 d2.utils.events]: \u001b[0m eta: 0:11:18  iter: 8259  total_loss: 0.09697  loss_cls: 1.656e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01553  loss_rpn_loc: 0.08006  time: 0.3875  data_time: 0.0142  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:01:44 d2.utils.events]: \u001b[0m eta: 0:11:10  iter: 8279  total_loss: 0.1089  loss_cls: 1.351e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01419  loss_rpn_loc: 0.08517  time: 0.3875  data_time: 0.0081  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:01:52 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 8299  total_loss: 0.09672  loss_cls: 1.52e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01425  loss_rpn_loc: 0.08203  time: 0.3875  data_time: 0.0090  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:01:59 d2.utils.events]: \u001b[0m eta: 0:10:54  iter: 8319  total_loss: 0.1229  loss_cls: 3.565e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01531  loss_rpn_loc: 0.1088  time: 0.3875  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:02:07 d2.utils.events]: \u001b[0m eta: 0:10:46  iter: 8339  total_loss: 0.0944  loss_cls: 3.059e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01499  loss_rpn_loc: 0.0865  time: 0.3875  data_time: 0.0135  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:02:16 d2.utils.events]: \u001b[0m eta: 0:10:39  iter: 8359  total_loss: 0.09244  loss_cls: 3.422e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01328  loss_rpn_loc: 0.08102  time: 0.3875  data_time: 0.0121  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:02:23 d2.utils.events]: \u001b[0m eta: 0:10:31  iter: 8379  total_loss: 0.1104  loss_cls: 7.153e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01849  loss_rpn_loc: 0.08742  time: 0.3876  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:02:32 d2.utils.events]: \u001b[0m eta: 0:10:24  iter: 8399  total_loss: 0.1026  loss_cls: 2.648e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01839  loss_rpn_loc: 0.08981  time: 0.3876  data_time: 0.0252  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:02:40 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 8419  total_loss: 0.1207  loss_cls: 2.564e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0182  loss_rpn_loc: 0.09657  time: 0.3876  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:02:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:02:44 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:02:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:02:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:02:46 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0821 s/iter. Eval: 0.0000 s/iter. Total: 0.0836 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:02:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.994084 (0.089180 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:02:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082656 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:02:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 15:02:50 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:02:53 d2.utils.events]: \u001b[0m eta: 0:10:08  iter: 8439  total_loss: 0.1146  loss_cls: 1.884e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01966  loss_rpn_loc: 0.09977  time: 0.3876  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:03:01 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 8459  total_loss: 0.101  loss_cls: 3.832e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0131  loss_rpn_loc: 0.08668  time: 0.3876  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:03:09 d2.utils.events]: \u001b[0m eta: 0:09:53  iter: 8479  total_loss: 0.1016  loss_cls: 4.582e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01621  loss_rpn_loc: 0.08315  time: 0.3876  data_time: 0.0092  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:03:16 d2.utils.events]: \u001b[0m eta: 0:09:45  iter: 8499  total_loss: 0.1144  loss_cls: 3.377e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01645  loss_rpn_loc: 0.0933  time: 0.3876  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:03:24 d2.utils.events]: \u001b[0m eta: 0:09:38  iter: 8519  total_loss: 0.1148  loss_cls: 5.195e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01777  loss_rpn_loc: 0.1003  time: 0.3876  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:03:32 d2.utils.events]: \u001b[0m eta: 0:09:30  iter: 8539  total_loss: 0.1106  loss_cls: 5.532e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01347  loss_rpn_loc: 0.09491  time: 0.3876  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:03:40 d2.utils.events]: \u001b[0m eta: 0:09:23  iter: 8559  total_loss: 0.1041  loss_cls: 1.791e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01529  loss_rpn_loc: 0.08906  time: 0.3876  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:03:47 d2.utils.events]: \u001b[0m eta: 0:09:14  iter: 8579  total_loss: 0.09984  loss_cls: 1.411e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.08659  time: 0.3876  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:03:55 d2.utils.events]: \u001b[0m eta: 0:09:06  iter: 8599  total_loss: 0.1128  loss_cls: 2.28e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02415  loss_rpn_loc: 0.08783  time: 0.3876  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:04:03 d2.utils.events]: \u001b[0m eta: 0:08:59  iter: 8619  total_loss: 0.1052  loss_cls: 3.021e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01554  loss_rpn_loc: 0.08796  time: 0.3876  data_time: 0.0137  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:04:10 d2.utils.events]: \u001b[0m eta: 0:08:51  iter: 8639  total_loss: 0.1124  loss_cls: 4.11e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01623  loss_rpn_loc: 0.09372  time: 0.3876  data_time: 0.0096  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:04:18 d2.utils.events]: \u001b[0m eta: 0:08:43  iter: 8659  total_loss: 0.09232  loss_cls: 4.513e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01219  loss_rpn_loc: 0.0804  time: 0.3875  data_time: 0.0082  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:04:27 d2.utils.events]: \u001b[0m eta: 0:08:36  iter: 8679  total_loss: 0.124  loss_cls: 3.402e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02274  loss_rpn_loc: 0.1032  time: 0.3877  data_time: 0.0455  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:04:34 d2.utils.events]: \u001b[0m eta: 0:08:27  iter: 8699  total_loss: 0.1109  loss_cls: 1.707e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01317  loss_rpn_loc: 0.09643  time: 0.3876  data_time: 0.0120  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:04:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:04:36 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:04:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:04:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:04:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0823 s/iter. Eval: 0.0000 s/iter. Total: 0.0839 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:04:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.981657 (0.088958 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:04:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082563 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:04:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 15:04:42 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:04:48 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 8719  total_loss: 0.1353  loss_cls: 2.528e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01854  loss_rpn_loc: 0.1154  time: 0.3877  data_time: 0.0146  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:04:56 d2.utils.events]: \u001b[0m eta: 0:08:12  iter: 8739  total_loss: 0.1057  loss_cls: 3.196e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01643  loss_rpn_loc: 0.09066  time: 0.3877  data_time: 0.0199  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:05:04 d2.utils.events]: \u001b[0m eta: 0:08:04  iter: 8759  total_loss: 0.09741  loss_cls: 3.495e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0148  loss_rpn_loc: 0.08237  time: 0.3876  data_time: 0.0121  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:05:11 d2.utils.events]: \u001b[0m eta: 0:07:56  iter: 8779  total_loss: 0.1028  loss_cls: 2.905e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01621  loss_rpn_loc: 0.08088  time: 0.3876  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:05:19 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 8799  total_loss: 0.09148  loss_cls: 3.612e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01574  loss_rpn_loc: 0.07559  time: 0.3876  data_time: 0.0131  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:05:27 d2.utils.events]: \u001b[0m eta: 0:07:40  iter: 8819  total_loss: 0.08234  loss_cls: 1.309e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01004  loss_rpn_loc: 0.06771  time: 0.3876  data_time: 0.0151  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:05:35 d2.utils.events]: \u001b[0m eta: 0:07:32  iter: 8839  total_loss: 0.09026  loss_cls: 3.39e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01252  loss_rpn_loc: 0.0788  time: 0.3876  data_time: 0.0085  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:05:42 d2.utils.events]: \u001b[0m eta: 0:07:24  iter: 8859  total_loss: 0.1143  loss_cls: 3.064e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01438  loss_rpn_loc: 0.09672  time: 0.3876  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:05:50 d2.utils.events]: \u001b[0m eta: 0:07:16  iter: 8879  total_loss: 0.1086  loss_cls: 5.433e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01778  loss_rpn_loc: 0.09016  time: 0.3876  data_time: 0.0218  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:05:58 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 8899  total_loss: 0.1364  loss_cls: 1.959e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01803  loss_rpn_loc: 0.1052  time: 0.3876  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:06:06 d2.utils.events]: \u001b[0m eta: 0:07:01  iter: 8919  total_loss: 0.105  loss_cls: 2.898e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01268  loss_rpn_loc: 0.08853  time: 0.3876  data_time: 0.0123  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:06:13 d2.utils.events]: \u001b[0m eta: 0:06:53  iter: 8939  total_loss: 0.1195  loss_cls: 1.881e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01516  loss_rpn_loc: 0.1015  time: 0.3876  data_time: 0.0136  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:06:21 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 8959  total_loss: 0.1006  loss_cls: 8.858e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01687  loss_rpn_loc: 0.08844  time: 0.3876  data_time: 0.0092  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:06:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:06:27 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:06:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:06:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:06:29 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0825 s/iter. Eval: 0.0000 s/iter. Total: 0.0840 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:06:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.977672 (0.088887 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:06:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082531 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:06:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 15:06:33 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:06:35 d2.utils.events]: \u001b[0m eta: 0:06:37  iter: 8979  total_loss: 0.09422  loss_cls: 1.303e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01428  loss_rpn_loc: 0.0805  time: 0.3876  data_time: 0.0217  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:06:42 d2.utils.events]: \u001b[0m eta: 0:06:29  iter: 8999  total_loss: 0.09805  loss_cls: 1.035e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01362  loss_rpn_loc: 0.09111  time: 0.3876  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:06:50 d2.utils.events]: \u001b[0m eta: 0:06:22  iter: 9019  total_loss: 0.1147  loss_cls: 2.137e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01537  loss_rpn_loc: 0.1005  time: 0.3876  data_time: 0.0255  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:06:58 d2.utils.events]: \u001b[0m eta: 0:06:14  iter: 9039  total_loss: 0.08933  loss_cls: 1.23e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.07392  time: 0.3876  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:07:06 d2.utils.events]: \u001b[0m eta: 0:06:06  iter: 9059  total_loss: 0.09654  loss_cls: 5.483e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01251  loss_rpn_loc: 0.08748  time: 0.3876  data_time: 0.0192  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:07:13 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 9079  total_loss: 0.07929  loss_cls: 1.867e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007553  loss_rpn_loc: 0.07027  time: 0.3876  data_time: 0.0098  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:07:21 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 9099  total_loss: 0.1572  loss_cls: 2.692e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0249  loss_rpn_loc: 0.1224  time: 0.3876  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:07:29 d2.utils.events]: \u001b[0m eta: 0:05:43  iter: 9119  total_loss: 0.1009  loss_cls: 1.922e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01981  loss_rpn_loc: 0.08041  time: 0.3876  data_time: 0.0101  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:07:36 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 9139  total_loss: 0.1095  loss_cls: 1.89e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009875  loss_rpn_loc: 0.09323  time: 0.3876  data_time: 0.0127  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:07:44 d2.utils.events]: \u001b[0m eta: 0:05:27  iter: 9159  total_loss: 0.1106  loss_cls: 1.8e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01785  loss_rpn_loc: 0.09123  time: 0.3876  data_time: 0.0170  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:07:52 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 9179  total_loss: 0.09421  loss_cls: 1.393e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01705  loss_rpn_loc: 0.07451  time: 0.3876  data_time: 0.0120  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:08:00 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 9199  total_loss: 0.09798  loss_cls: 1.376e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01422  loss_rpn_loc: 0.08899  time: 0.3876  data_time: 0.0142  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:08:08 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 9219  total_loss: 0.1112  loss_cls: 2.691e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009754  loss_rpn_loc: 0.0956  time: 0.3876  data_time: 0.0100  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:08:16 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 9239  total_loss: 0.1257  loss_cls: 3.077e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01906  loss_rpn_loc: 0.1066  time: 0.3876  data_time: 0.0122  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:08:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:08:19 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:08:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:08:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:08:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0826 s/iter. Eval: 0.0000 s/iter. Total: 0.0842 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:08:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.978964 (0.088910 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:08:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082626 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:08:25 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 15:08:25 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:08:29 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 9259  total_loss: 0.08549  loss_cls: 1.555e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01307  loss_rpn_loc: 0.07021  time: 0.3876  data_time: 0.0123  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:08:37 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 9279  total_loss: 0.09652  loss_cls: 3.643e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01117  loss_rpn_loc: 0.08736  time: 0.3876  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:08:45 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 9299  total_loss: 0.08526  loss_cls: 2.209e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01636  loss_rpn_loc: 0.07769  time: 0.3876  data_time: 0.0134  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:08:52 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 9319  total_loss: 0.09389  loss_cls: 1.776e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009417  loss_rpn_loc: 0.07897  time: 0.3876  data_time: 0.0117  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:09:00 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 9339  total_loss: 0.1326  loss_cls: 2.825e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01373  loss_rpn_loc: 0.1221  time: 0.3876  data_time: 0.0150  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:09:08 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 9359  total_loss: 0.1094  loss_cls: 3.412e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01888  loss_rpn_loc: 0.09375  time: 0.3876  data_time: 0.0159  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:09:16 d2.utils.events]: \u001b[0m eta: 0:04:02  iter: 9379  total_loss: 0.1376  loss_cls: 3.782e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01958  loss_rpn_loc: 0.1152  time: 0.3876  data_time: 0.0174  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:09:23 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 9399  total_loss: 0.09286  loss_cls: 2.081e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0128  loss_rpn_loc: 0.08173  time: 0.3875  data_time: 0.0088  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:09:31 d2.utils.events]: \u001b[0m eta: 0:03:46  iter: 9419  total_loss: 0.1257  loss_cls: 3.569e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02172  loss_rpn_loc: 0.1027  time: 0.3876  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:09:39 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 9439  total_loss: 0.1051  loss_cls: 1.368e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01615  loss_rpn_loc: 0.08461  time: 0.3875  data_time: 0.0098  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:09:46 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 9459  total_loss: 0.1025  loss_cls: 3.067e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02096  loss_rpn_loc: 0.08073  time: 0.3875  data_time: 0.0157  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:09:54 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 9479  total_loss: 0.1023  loss_cls: 2.538e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01316  loss_rpn_loc: 0.08851  time: 0.3875  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:10:02 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 9499  total_loss: 0.1021  loss_cls: 1.837e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01495  loss_rpn_loc: 0.09363  time: 0.3875  data_time: 0.0122  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:10:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:10:09 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:10:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:10:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:10:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0820 s/iter. Eval: 0.0000 s/iter. Total: 0.0835 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:10:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.965668 (0.088673 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:10:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082255 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:10:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 15:10:15 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:10:15 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 9519  total_loss: 0.08987  loss_cls: 2.304e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01261  loss_rpn_loc: 0.07574  time: 0.3875  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:10:23 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 9539  total_loss: 0.1306  loss_cls: 2.297e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02446  loss_rpn_loc: 0.1069  time: 0.3875  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:10:31 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 9559  total_loss: 0.1385  loss_cls: 3.619e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02978  loss_rpn_loc: 0.1016  time: 0.3875  data_time: 0.0155  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:10:38 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 9579  total_loss: 0.1025  loss_cls: 1.457e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01257  loss_rpn_loc: 0.08062  time: 0.3875  data_time: 0.0098  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:10:46 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 9599  total_loss: 0.1121  loss_cls: 1.485e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01393  loss_rpn_loc: 0.08818  time: 0.3875  data_time: 0.0089  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:10:54 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 9619  total_loss: 0.09879  loss_cls: 2.267e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01623  loss_rpn_loc: 0.08252  time: 0.3875  data_time: 0.0166  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:11:02 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 9639  total_loss: 0.1213  loss_cls: 3.317e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02002  loss_rpn_loc: 0.09284  time: 0.3875  data_time: 0.0139  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:11:10 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 9659  total_loss: 0.102  loss_cls: 2.295e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.0883  time: 0.3875  data_time: 0.0169  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:11:18 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 9679  total_loss: 0.1064  loss_cls: 2.323e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01968  loss_rpn_loc: 0.09107  time: 0.3875  data_time: 0.0106  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:11:25 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 9699  total_loss: 0.1077  loss_cls: 5.684e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01162  loss_rpn_loc: 0.09711  time: 0.3875  data_time: 0.0138  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:11:33 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 9719  total_loss: 0.1157  loss_cls: 1.617e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01421  loss_rpn_loc: 0.1005  time: 0.3875  data_time: 0.0235  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:11:41 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 9739  total_loss: 0.08891  loss_cls: 3.337e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009131  loss_rpn_loc: 0.07259  time: 0.3876  data_time: 0.0200  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:11:49 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 9759  total_loss: 0.1016  loss_cls: 3.988e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01326  loss_rpn_loc: 0.09218  time: 0.3876  data_time: 0.0220  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:11:57 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 9779  total_loss: 0.1022  loss_cls: 2.478e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01716  loss_rpn_loc: 0.08502  time: 0.3876  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:12:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:12:02 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:12:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:12:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:12:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0830 s/iter. Eval: 0.0000 s/iter. Total: 0.0846 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:12:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.979892 (0.088927 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:12:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082502 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:12:08 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 15:12:08 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:12:11 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 9799  total_loss: 0.1078  loss_cls: 1.799e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01774  loss_rpn_loc: 0.08527  time: 0.3876  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:12:18 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 9819  total_loss: 0.1059  loss_cls: 2.559e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01664  loss_rpn_loc: 0.08894  time: 0.3875  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:12:26 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 9839  total_loss: 0.1118  loss_cls: 1.705e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01429  loss_rpn_loc: 0.09269  time: 0.3875  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:12:33 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 9859  total_loss: 0.09339  loss_cls: 2.165e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0149  loss_rpn_loc: 0.0784  time: 0.3875  data_time: 0.0082  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:12:41 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 9879  total_loss: 0.1066  loss_cls: 2.425e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01178  loss_rpn_loc: 0.08741  time: 0.3875  data_time: 0.0202  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:12:49 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 9899  total_loss: 0.1073  loss_cls: 2.839e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01362  loss_rpn_loc: 0.09028  time: 0.3876  data_time: 0.0141  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:12:57 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 9919  total_loss: 0.09116  loss_cls: 1.052e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01468  loss_rpn_loc: 0.07291  time: 0.3875  data_time: 0.0164  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:13:04 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 9939  total_loss: 0.1073  loss_cls: 2.447e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01061  loss_rpn_loc: 0.09575  time: 0.3875  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:13:12 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 9959  total_loss: 0.1127  loss_cls: 1.964e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0161  loss_rpn_loc: 0.09379  time: 0.3875  data_time: 0.0144  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:13:20 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 9979  total_loss: 0.1276  loss_cls: 2.956e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02002  loss_rpn_loc: 0.1045  time: 0.3876  data_time: 0.0161  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:13:31 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 0.1029  loss_cls: 1.643e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01296  loss_rpn_loc: 0.07465  time: 0.3875  data_time: 0.0099  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:13:32 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:04:34 (0.3876 s / it)\n",
      "\u001b[32m[12/27 15:13:32 d2.engine.hooks]: \u001b[0mTotal training time: 1:08:23 (0:03:48 on hooks)\n",
      "\u001b[32m[12/27 15:13:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:13:32 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:13:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:13:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:13:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0822 s/iter. Eval: 0.0000 s/iter. Total: 0.0837 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:13:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.976535 (0.088867 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:13:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082515 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:13:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_0 in csv format:\n",
      "\u001b[32m[12/27 15:13:38 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "trainModel(0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MzrhA3ggNVue",
    "outputId": "219b41de-c854-42ac-f6d3-f286a18df261"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/1\n",
      "\u001b[32m[12/27 15:13:40 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[12/27 15:13:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[12/27 15:13:40 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/27 15:13:40 d2.data.common]: \u001b[0mSerializing 545 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:13:40 d2.data.common]: \u001b[0mSerialized dataset takes 1.01 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/27 15:13:40 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/detectron2/data/detection_utils.py:433: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/usr/local/lib/python3.7/dist-packages/detectron2/data/detection_utils.py:433: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/27 15:13:49 d2.utils.events]: \u001b[0m eta: 1:04:38  iter: 19  total_loss: 1.355  loss_cls: 0.6788  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.3977  loss_rpn_loc: 0.2297  time: 0.3964  data_time: 0.0646  lr: 2.4976e-05  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:13:57 d2.utils.events]: \u001b[0m eta: 1:04:30  iter: 39  total_loss: 1.133  loss_cls: 0.5656  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.3983  loss_rpn_loc: 0.1321  time: 0.3892  data_time: 0.0112  lr: 4.9951e-05  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:14:05 d2.utils.events]: \u001b[0m eta: 1:04:23  iter: 59  total_loss: 0.9338  loss_cls: 0.4233  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.3861  loss_rpn_loc: 0.1207  time: 0.3878  data_time: 0.0136  lr: 7.4926e-05  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:14:13 d2.utils.events]: \u001b[0m eta: 1:04:14  iter: 79  total_loss: 0.7224  loss_cls: 0.253  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.274  loss_rpn_loc: 0.1496  time: 0.3887  data_time: 0.0097  lr: 9.9901e-05  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:14:20 d2.utils.events]: \u001b[0m eta: 1:04:04  iter: 99  total_loss: 0.5065  loss_cls: 0.1364  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.2091  loss_rpn_loc: 0.1377  time: 0.3872  data_time: 0.0114  lr: 0.00012488  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:14:28 d2.utils.events]: \u001b[0m eta: 1:03:56  iter: 119  total_loss: 0.4054  loss_cls: 0.07965  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.2022  loss_rpn_loc: 0.1263  time: 0.3855  data_time: 0.0118  lr: 0.00014985  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:14:36 d2.utils.events]: \u001b[0m eta: 1:03:50  iter: 139  total_loss: 0.3546  loss_cls: 0.03285  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.1833  loss_rpn_loc: 0.1323  time: 0.3860  data_time: 0.0113  lr: 0.00017483  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:14:43 d2.utils.events]: \u001b[0m eta: 1:03:33  iter: 159  total_loss: 0.272  loss_cls: 0.01904  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.1555  loss_rpn_loc: 0.1205  time: 0.3849  data_time: 0.0123  lr: 0.0001998  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:14:51 d2.utils.events]: \u001b[0m eta: 1:03:26  iter: 179  total_loss: 0.2656  loss_cls: 0.01554  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.1411  loss_rpn_loc: 0.1126  time: 0.3836  data_time: 0.0091  lr: 0.00022478  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:14:58 d2.utils.events]: \u001b[0m eta: 1:03:25  iter: 199  total_loss: 0.3013  loss_cls: 0.005819  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.1141  loss_rpn_loc: 0.1382  time: 0.3847  data_time: 0.0144  lr: 0.00024975  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:15:06 d2.utils.events]: \u001b[0m eta: 1:03:19  iter: 219  total_loss: 0.2274  loss_cls: 0.01121  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.09872  loss_rpn_loc: 0.108  time: 0.3850  data_time: 0.0113  lr: 0.00027473  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:15:14 d2.utils.events]: \u001b[0m eta: 1:03:05  iter: 239  total_loss: 0.1788  loss_cls: 0.006928  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.09099  loss_rpn_loc: 0.08791  time: 0.3848  data_time: 0.0178  lr: 0.0002997  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:15:21 d2.utils.events]: \u001b[0m eta: 1:02:51  iter: 259  total_loss: 0.1849  loss_cls: 0.002  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.08342  loss_rpn_loc: 0.1048  time: 0.3838  data_time: 0.0088  lr: 0.00032468  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:15:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:15:26 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:15:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:15:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:15:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0817 s/iter. Eval: 0.0000 s/iter. Total: 0.0830 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:15:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.961579 (0.088600 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:15:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082236 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:15:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:15:32 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:15:35 d2.utils.events]: \u001b[0m eta: 1:02:43  iter: 279  total_loss: 0.1932  loss_cls: 0.001604  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.08177  loss_rpn_loc: 0.1234  time: 0.3838  data_time: 0.0088  lr: 0.00034965  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:15:43 d2.utils.events]: \u001b[0m eta: 1:02:36  iter: 299  total_loss: 0.219  loss_cls: 0.003074  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.07792  loss_rpn_loc: 0.1629  time: 0.3837  data_time: 0.0116  lr: 0.00037463  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:15:50 d2.utils.events]: \u001b[0m eta: 1:02:27  iter: 319  total_loss: 0.1142  loss_cls: 0.001118  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.06533  loss_rpn_loc: 0.04648  time: 0.3825  data_time: 0.0091  lr: 0.0003996  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:15:58 d2.utils.events]: \u001b[0m eta: 1:02:20  iter: 339  total_loss: 0.2072  loss_cls: 0.000885  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.08279  loss_rpn_loc: 0.1218  time: 0.3828  data_time: 0.0149  lr: 0.00042458  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:16:05 d2.utils.events]: \u001b[0m eta: 1:02:15  iter: 359  total_loss: 0.2417  loss_cls: 0.00055  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.06462  loss_rpn_loc: 0.1584  time: 0.3827  data_time: 0.0102  lr: 0.00044955  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:16:13 d2.utils.events]: \u001b[0m eta: 1:02:11  iter: 379  total_loss: 0.1862  loss_cls: 0.0009052  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.05767  loss_rpn_loc: 0.1116  time: 0.3838  data_time: 0.0209  lr: 0.00047453  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:16:21 d2.utils.events]: \u001b[0m eta: 1:02:02  iter: 399  total_loss: 0.1414  loss_cls: 0.0006757  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0481  loss_rpn_loc: 0.09442  time: 0.3834  data_time: 0.0117  lr: 0.0004995  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:16:29 d2.utils.events]: \u001b[0m eta: 1:01:56  iter: 419  total_loss: 0.1795  loss_cls: 0.0006013  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.05931  loss_rpn_loc: 0.1217  time: 0.3846  data_time: 0.0373  lr: 0.00052448  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:16:37 d2.utils.events]: \u001b[0m eta: 1:01:49  iter: 439  total_loss: 0.167  loss_cls: 0.0004175  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04412  loss_rpn_loc: 0.1221  time: 0.3852  data_time: 0.0143  lr: 0.00054945  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:16:45 d2.utils.events]: \u001b[0m eta: 1:01:41  iter: 459  total_loss: 0.2427  loss_cls: 0.0006981  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.07063  loss_rpn_loc: 0.1624  time: 0.3852  data_time: 0.0120  lr: 0.00057443  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:16:52 d2.utils.events]: \u001b[0m eta: 1:01:32  iter: 479  total_loss: 0.1358  loss_cls: 0.0008314  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04252  loss_rpn_loc: 0.0899  time: 0.3848  data_time: 0.0083  lr: 0.0005994  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:17:00 d2.utils.events]: \u001b[0m eta: 1:01:24  iter: 499  total_loss: 0.1215  loss_cls: 0.0005733  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03076  loss_rpn_loc: 0.08683  time: 0.3846  data_time: 0.0104  lr: 0.00062438  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:17:07 d2.utils.events]: \u001b[0m eta: 1:01:13  iter: 519  total_loss: 0.1631  loss_cls: 0.0006208  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04156  loss_rpn_loc: 0.1227  time: 0.3842  data_time: 0.0086  lr: 0.00064935  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:17:15 d2.utils.events]: \u001b[0m eta: 1:01:03  iter: 539  total_loss: 0.1492  loss_cls: 0.0004817  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04161  loss_rpn_loc: 0.08927  time: 0.3846  data_time: 0.0199  lr: 0.00067433  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:17:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:17:17 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:17:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:17:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:17:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0017 s/iter. Inference: 0.0823 s/iter. Eval: 0.0000 s/iter. Total: 0.0840 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:17:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.977575 (0.088885 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:17:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082251 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:17:23 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:17:23 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:17:29 d2.utils.events]: \u001b[0m eta: 1:00:50  iter: 559  total_loss: 0.1322  loss_cls: 0.0002689  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03882  loss_rpn_loc: 0.09692  time: 0.3839  data_time: 0.0103  lr: 0.0006993  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:17:37 d2.utils.events]: \u001b[0m eta: 1:00:50  iter: 579  total_loss: 0.1725  loss_cls: 0.0005955  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.05288  loss_rpn_loc: 0.116  time: 0.3842  data_time: 0.0107  lr: 0.00072428  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:17:44 d2.utils.events]: \u001b[0m eta: 1:00:45  iter: 599  total_loss: 0.1666  loss_cls: 0.0004085  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04302  loss_rpn_loc: 0.1196  time: 0.3844  data_time: 0.0153  lr: 0.00074925  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:17:52 d2.utils.events]: \u001b[0m eta: 1:00:38  iter: 619  total_loss: 0.2208  loss_cls: 0.0004498  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03925  loss_rpn_loc: 0.1632  time: 0.3850  data_time: 0.0232  lr: 0.00077423  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:18:00 d2.utils.events]: \u001b[0m eta: 1:00:31  iter: 639  total_loss: 0.1326  loss_cls: 0.0003391  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02935  loss_rpn_loc: 0.09413  time: 0.3850  data_time: 0.0082  lr: 0.0007992  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:18:08 d2.utils.events]: \u001b[0m eta: 1:00:22  iter: 659  total_loss: 0.1759  loss_cls: 0.0003156  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03933  loss_rpn_loc: 0.1152  time: 0.3849  data_time: 0.0080  lr: 0.00082418  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:18:15 d2.utils.events]: \u001b[0m eta: 1:00:11  iter: 679  total_loss: 0.1295  loss_cls: 0.0001532  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02679  loss_rpn_loc: 0.09889  time: 0.3844  data_time: 0.0100  lr: 0.00084915  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:18:23 d2.utils.events]: \u001b[0m eta: 1:00:08  iter: 699  total_loss: 0.199  loss_cls: 0.0002839  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.05631  loss_rpn_loc: 0.1164  time: 0.3849  data_time: 0.0157  lr: 0.00087413  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:18:31 d2.utils.events]: \u001b[0m eta: 1:00:00  iter: 719  total_loss: 0.1707  loss_cls: 0.0003185  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.06314  loss_rpn_loc: 0.1123  time: 0.3847  data_time: 0.0112  lr: 0.0008991  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:18:38 d2.utils.events]: \u001b[0m eta: 0:59:52  iter: 739  total_loss: 0.1406  loss_cls: 0.0002393  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03029  loss_rpn_loc: 0.09699  time: 0.3846  data_time: 0.0094  lr: 0.00092408  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:18:46 d2.utils.events]: \u001b[0m eta: 0:59:46  iter: 759  total_loss: 0.1119  loss_cls: 0.0001981  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02084  loss_rpn_loc: 0.09241  time: 0.3846  data_time: 0.0103  lr: 0.00094905  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:18:54 d2.utils.events]: \u001b[0m eta: 0:59:42  iter: 779  total_loss: 0.1648  loss_cls: 0.0001843  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04328  loss_rpn_loc: 0.1157  time: 0.3853  data_time: 0.0213  lr: 0.00097403  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:19:02 d2.utils.events]: \u001b[0m eta: 0:59:34  iter: 799  total_loss: 0.1084  loss_cls: 0.0001547  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.019  loss_rpn_loc: 0.08603  time: 0.3853  data_time: 0.0092  lr: 0.000999  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:19:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:19:08 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:19:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:19:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:19:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0819 s/iter. Eval: 0.0000 s/iter. Total: 0.0835 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:19:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.957184 (0.088521 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:19:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081976 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:19:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:19:14 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:19:16 d2.utils.events]: \u001b[0m eta: 0:59:26  iter: 819  total_loss: 0.1077  loss_cls: 0.0002253  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02207  loss_rpn_loc: 0.07899  time: 0.3853  data_time: 0.0094  lr: 0.001024  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:19:23 d2.utils.events]: \u001b[0m eta: 0:59:15  iter: 839  total_loss: 0.09306  loss_cls: 0.0001647  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02312  loss_rpn_loc: 0.04406  time: 0.3852  data_time: 0.0069  lr: 0.001049  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:19:31 d2.utils.events]: \u001b[0m eta: 0:59:07  iter: 859  total_loss: 0.1313  loss_cls: 0.0001565  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02505  loss_rpn_loc: 0.1054  time: 0.3850  data_time: 0.0110  lr: 0.0010739  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:19:39 d2.utils.events]: \u001b[0m eta: 0:59:02  iter: 879  total_loss: 0.1482  loss_cls: 0.0002293  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03392  loss_rpn_loc: 0.1169  time: 0.3851  data_time: 0.0117  lr: 0.0010989  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:19:46 d2.utils.events]: \u001b[0m eta: 0:58:51  iter: 899  total_loss: 0.1445  loss_cls: 0.0002539  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02832  loss_rpn_loc: 0.1062  time: 0.3848  data_time: 0.0114  lr: 0.0011239  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:19:54 d2.utils.events]: \u001b[0m eta: 0:58:44  iter: 919  total_loss: 0.04919  loss_cls: 0.0002049  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01039  loss_rpn_loc: 0.03769  time: 0.3848  data_time: 0.0123  lr: 0.0011489  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:20:02 d2.utils.events]: \u001b[0m eta: 0:58:36  iter: 939  total_loss: 0.1657  loss_cls: 0.000213  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04182  loss_rpn_loc: 0.1113  time: 0.3850  data_time: 0.0159  lr: 0.0011738  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:20:09 d2.utils.events]: \u001b[0m eta: 0:58:29  iter: 959  total_loss: 0.1453  loss_cls: 0.0001268  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03127  loss_rpn_loc: 0.1065  time: 0.3849  data_time: 0.0096  lr: 0.0011988  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:20:17 d2.utils.events]: \u001b[0m eta: 0:58:24  iter: 979  total_loss: 0.1156  loss_cls: 0.0001735  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02277  loss_rpn_loc: 0.09167  time: 0.3852  data_time: 0.0101  lr: 0.0012238  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:20:25 d2.utils.events]: \u001b[0m eta: 0:58:16  iter: 999  total_loss: 0.1311  loss_cls: 0.0001767  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02428  loss_rpn_loc: 0.1098  time: 0.3852  data_time: 0.0087  lr: 0.0012488  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:20:33 d2.utils.events]: \u001b[0m eta: 0:58:08  iter: 1019  total_loss: 0.209  loss_cls: 0.000341  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04179  loss_rpn_loc: 0.1644  time: 0.3854  data_time: 0.0166  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:20:41 d2.utils.events]: \u001b[0m eta: 0:58:00  iter: 1039  total_loss: 0.1322  loss_cls: 0.0002708  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02401  loss_rpn_loc: 0.1054  time: 0.3853  data_time: 0.0106  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:20:48 d2.utils.events]: \u001b[0m eta: 0:57:53  iter: 1059  total_loss: 0.1068  loss_cls: 0.0001528  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02237  loss_rpn_loc: 0.09187  time: 0.3852  data_time: 0.0090  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:20:56 d2.utils.events]: \u001b[0m eta: 0:57:45  iter: 1079  total_loss: 0.1384  loss_cls: 0.0003553  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02922  loss_rpn_loc: 0.1017  time: 0.3852  data_time: 0.0142  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:20:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:20:59 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:20:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:20:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:21:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0820 s/iter. Eval: 0.0000 s/iter. Total: 0.0835 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:21:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.952899 (0.088445 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:21:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082067 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:21:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:21:05 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:21:10 d2.utils.events]: \u001b[0m eta: 0:57:40  iter: 1099  total_loss: 0.2141  loss_cls: 0.0001889  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04117  loss_rpn_loc: 0.1684  time: 0.3854  data_time: 0.0125  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:21:18 d2.utils.events]: \u001b[0m eta: 0:57:31  iter: 1119  total_loss: 0.1451  loss_cls: 0.000135  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02932  loss_rpn_loc: 0.1059  time: 0.3855  data_time: 0.0136  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:21:26 d2.utils.events]: \u001b[0m eta: 0:57:22  iter: 1139  total_loss: 0.1278  loss_cls: 0.0002746  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03022  loss_rpn_loc: 0.09551  time: 0.3857  data_time: 0.0242  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:21:33 d2.utils.events]: \u001b[0m eta: 0:57:17  iter: 1159  total_loss: 0.14  loss_cls: 7.017e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03373  loss_rpn_loc: 0.09247  time: 0.3857  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:21:42 d2.utils.events]: \u001b[0m eta: 0:57:10  iter: 1179  total_loss: 0.1236  loss_cls: 0.0001158  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02484  loss_rpn_loc: 0.09577  time: 0.3861  data_time: 0.0283  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:21:49 d2.utils.events]: \u001b[0m eta: 0:57:00  iter: 1199  total_loss: 0.09431  loss_cls: 3.928e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01465  loss_rpn_loc: 0.07799  time: 0.3859  data_time: 0.0081  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:21:57 d2.utils.events]: \u001b[0m eta: 0:56:52  iter: 1219  total_loss: 0.1195  loss_cls: 7.494e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02622  loss_rpn_loc: 0.08923  time: 0.3858  data_time: 0.0086  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:22:05 d2.utils.events]: \u001b[0m eta: 0:56:45  iter: 1239  total_loss: 0.1228  loss_cls: 0.0001524  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02128  loss_rpn_loc: 0.09911  time: 0.3859  data_time: 0.0172  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:22:12 d2.utils.events]: \u001b[0m eta: 0:56:38  iter: 1259  total_loss: 0.1131  loss_cls: 8.301e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01536  loss_rpn_loc: 0.1012  time: 0.3858  data_time: 0.0101  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:22:20 d2.utils.events]: \u001b[0m eta: 0:56:30  iter: 1279  total_loss: 0.08204  loss_cls: 6.428e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01418  loss_rpn_loc: 0.07175  time: 0.3859  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:22:28 d2.utils.events]: \u001b[0m eta: 0:56:20  iter: 1299  total_loss: 0.1307  loss_cls: 0.0001487  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03075  loss_rpn_loc: 0.1052  time: 0.3857  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:22:35 d2.utils.events]: \u001b[0m eta: 0:56:15  iter: 1319  total_loss: 0.14  loss_cls: 8.618e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02408  loss_rpn_loc: 0.103  time: 0.3857  data_time: 0.0120  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:22:43 d2.utils.events]: \u001b[0m eta: 0:56:06  iter: 1339  total_loss: 0.2031  loss_cls: 0.0001803  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02766  loss_rpn_loc: 0.1585  time: 0.3858  data_time: 0.0191  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:22:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:22:51 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:22:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:22:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:22:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0819 s/iter. Eval: 0.0000 s/iter. Total: 0.0835 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:22:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.961520 (0.088599 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:22:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082115 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:22:57 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:22:57 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:22:57 d2.utils.events]: \u001b[0m eta: 0:55:59  iter: 1359  total_loss: 0.1473  loss_cls: 5.476e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02936  loss_rpn_loc: 0.1161  time: 0.3858  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:23:05 d2.utils.events]: \u001b[0m eta: 0:55:50  iter: 1379  total_loss: 0.1013  loss_cls: 0.0001086  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02474  loss_rpn_loc: 0.08446  time: 0.3859  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:23:12 d2.utils.events]: \u001b[0m eta: 0:55:44  iter: 1399  total_loss: 0.1258  loss_cls: 0.0001818  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02331  loss_rpn_loc: 0.1031  time: 0.3859  data_time: 0.0134  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:23:20 d2.utils.events]: \u001b[0m eta: 0:55:34  iter: 1419  total_loss: 0.113  loss_cls: 8.381e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01884  loss_rpn_loc: 0.09429  time: 0.3857  data_time: 0.0083  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:23:28 d2.utils.events]: \u001b[0m eta: 0:55:25  iter: 1439  total_loss: 0.1483  loss_cls: 7.741e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0257  loss_rpn_loc: 0.1089  time: 0.3858  data_time: 0.0184  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:23:35 d2.utils.events]: \u001b[0m eta: 0:55:18  iter: 1459  total_loss: 0.12  loss_cls: 7.761e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01472  loss_rpn_loc: 0.1008  time: 0.3857  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:23:43 d2.utils.events]: \u001b[0m eta: 0:55:11  iter: 1479  total_loss: 0.1178  loss_cls: 8.346e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01893  loss_rpn_loc: 0.1031  time: 0.3856  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:23:51 d2.utils.events]: \u001b[0m eta: 0:55:03  iter: 1499  total_loss: 0.119  loss_cls: 0.0001111  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01467  loss_rpn_loc: 0.09538  time: 0.3856  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:23:58 d2.utils.events]: \u001b[0m eta: 0:54:56  iter: 1519  total_loss: 0.1616  loss_cls: 9.913e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02745  loss_rpn_loc: 0.1136  time: 0.3857  data_time: 0.0147  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:24:06 d2.utils.events]: \u001b[0m eta: 0:54:49  iter: 1539  total_loss: 0.15  loss_cls: 5.119e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02877  loss_rpn_loc: 0.1199  time: 0.3856  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:24:14 d2.utils.events]: \u001b[0m eta: 0:54:42  iter: 1559  total_loss: 0.12  loss_cls: 6.124e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02428  loss_rpn_loc: 0.09313  time: 0.3855  data_time: 0.0125  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:24:21 d2.utils.events]: \u001b[0m eta: 0:54:34  iter: 1579  total_loss: 0.1005  loss_cls: 9.148e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0181  loss_rpn_loc: 0.08095  time: 0.3856  data_time: 0.0117  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:24:29 d2.utils.events]: \u001b[0m eta: 0:54:25  iter: 1599  total_loss: 0.119  loss_cls: 6.683e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02679  loss_rpn_loc: 0.09201  time: 0.3855  data_time: 0.0128  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:24:37 d2.utils.events]: \u001b[0m eta: 0:54:17  iter: 1619  total_loss: 0.1513  loss_cls: 0.0001469  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02873  loss_rpn_loc: 0.127  time: 0.3854  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:24:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:24:42 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:24:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:24:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:24:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0818 s/iter. Eval: 0.0000 s/iter. Total: 0.0832 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:24:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.957806 (0.088532 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:24:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081807 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:24:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:24:47 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:24:51 d2.utils.events]: \u001b[0m eta: 0:54:10  iter: 1639  total_loss: 0.1133  loss_cls: 4.891e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02331  loss_rpn_loc: 0.08898  time: 0.3856  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:24:58 d2.utils.events]: \u001b[0m eta: 0:54:03  iter: 1659  total_loss: 0.125  loss_cls: 9.766e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02218  loss_rpn_loc: 0.09734  time: 0.3856  data_time: 0.0116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:25:06 d2.utils.events]: \u001b[0m eta: 0:53:58  iter: 1679  total_loss: 0.1152  loss_cls: 7.298e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01406  loss_rpn_loc: 0.09015  time: 0.3856  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:25:13 d2.utils.events]: \u001b[0m eta: 0:53:46  iter: 1699  total_loss: 0.1002  loss_cls: 4.151e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01415  loss_rpn_loc: 0.07975  time: 0.3853  data_time: 0.0087  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:25:21 d2.utils.events]: \u001b[0m eta: 0:53:38  iter: 1719  total_loss: 0.1052  loss_cls: 9.313e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02118  loss_rpn_loc: 0.09274  time: 0.3853  data_time: 0.0138  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:25:29 d2.utils.events]: \u001b[0m eta: 0:53:31  iter: 1739  total_loss: 0.1014  loss_cls: 4.471e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01478  loss_rpn_loc: 0.0869  time: 0.3854  data_time: 0.0194  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:25:37 d2.utils.events]: \u001b[0m eta: 0:53:23  iter: 1759  total_loss: 0.1383  loss_cls: 0.0001082  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02251  loss_rpn_loc: 0.1112  time: 0.3854  data_time: 0.0128  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:25:44 d2.utils.events]: \u001b[0m eta: 0:53:15  iter: 1779  total_loss: 0.1125  loss_cls: 6.98e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01367  loss_rpn_loc: 0.09597  time: 0.3854  data_time: 0.0097  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:25:52 d2.utils.events]: \u001b[0m eta: 0:53:07  iter: 1799  total_loss: 0.1371  loss_cls: 0.0001239  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0245  loss_rpn_loc: 0.1091  time: 0.3855  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:26:00 d2.utils.events]: \u001b[0m eta: 0:53:00  iter: 1819  total_loss: 0.1206  loss_cls: 0.0001023  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0196  loss_rpn_loc: 0.1004  time: 0.3854  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:26:08 d2.utils.events]: \u001b[0m eta: 0:52:54  iter: 1839  total_loss: 0.1479  loss_cls: 0.0001115  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02855  loss_rpn_loc: 0.1114  time: 0.3855  data_time: 0.0152  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:26:16 d2.utils.events]: \u001b[0m eta: 0:52:47  iter: 1859  total_loss: 0.1352  loss_cls: 0.0001209  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02677  loss_rpn_loc: 0.1077  time: 0.3856  data_time: 0.0130  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:26:23 d2.utils.events]: \u001b[0m eta: 0:52:39  iter: 1879  total_loss: 0.164  loss_cls: 7.037e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.034  loss_rpn_loc: 0.1289  time: 0.3855  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:26:31 d2.utils.events]: \u001b[0m eta: 0:52:33  iter: 1899  total_loss: 0.1166  loss_cls: 5.738e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01414  loss_rpn_loc: 0.09971  time: 0.3856  data_time: 0.0153  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:26:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:26:32 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:26:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:26:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:26:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0821 s/iter. Eval: 0.0000 s/iter. Total: 0.0837 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:26:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.939091 (0.088198 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:26:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081772 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:26:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:26:38 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:26:44 d2.utils.events]: \u001b[0m eta: 0:52:25  iter: 1919  total_loss: 0.1433  loss_cls: 7.701e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02342  loss_rpn_loc: 0.1175  time: 0.3856  data_time: 0.0151  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:26:52 d2.utils.events]: \u001b[0m eta: 0:52:18  iter: 1939  total_loss: 0.1242  loss_cls: 6.735e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02186  loss_rpn_loc: 0.1059  time: 0.3856  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:27:00 d2.utils.events]: \u001b[0m eta: 0:52:09  iter: 1959  total_loss: 0.12  loss_cls: 7.987e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02197  loss_rpn_loc: 0.09225  time: 0.3855  data_time: 0.0083  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:27:08 d2.utils.events]: \u001b[0m eta: 0:52:00  iter: 1979  total_loss: 0.1041  loss_cls: 7.284e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02299  loss_rpn_loc: 0.08338  time: 0.3855  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:27:16 d2.utils.events]: \u001b[0m eta: 0:51:54  iter: 1999  total_loss: 0.1631  loss_cls: 4.524e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0266  loss_rpn_loc: 0.1248  time: 0.3856  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:27:23 d2.utils.events]: \u001b[0m eta: 0:51:46  iter: 2019  total_loss: 0.136  loss_cls: 6.252e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02392  loss_rpn_loc: 0.1144  time: 0.3857  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:27:31 d2.utils.events]: \u001b[0m eta: 0:51:39  iter: 2039  total_loss: 0.1065  loss_cls: 8.859e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02149  loss_rpn_loc: 0.08698  time: 0.3856  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:27:39 d2.utils.events]: \u001b[0m eta: 0:51:33  iter: 2059  total_loss: 0.1295  loss_cls: 7.614e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02892  loss_rpn_loc: 0.09912  time: 0.3856  data_time: 0.0128  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:27:46 d2.utils.events]: \u001b[0m eta: 0:51:25  iter: 2079  total_loss: 0.1085  loss_cls: 0.0001004  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01935  loss_rpn_loc: 0.08435  time: 0.3856  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:27:54 d2.utils.events]: \u001b[0m eta: 0:51:16  iter: 2099  total_loss: 0.1234  loss_cls: 0.0001084  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01653  loss_rpn_loc: 0.1123  time: 0.3856  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:28:02 d2.utils.events]: \u001b[0m eta: 0:51:10  iter: 2119  total_loss: 0.1576  loss_cls: 7.137e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03727  loss_rpn_loc: 0.1087  time: 0.3856  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:28:09 d2.utils.events]: \u001b[0m eta: 0:51:02  iter: 2139  total_loss: 0.1176  loss_cls: 0.0001286  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02492  loss_rpn_loc: 0.08026  time: 0.3855  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:28:17 d2.utils.events]: \u001b[0m eta: 0:50:53  iter: 2159  total_loss: 0.1093  loss_cls: 5.175e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01331  loss_rpn_loc: 0.08905  time: 0.3855  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:28:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:28:23 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:28:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:28:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:28:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0818 s/iter. Eval: 0.0000 s/iter. Total: 0.0833 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:28:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.975076 (0.088841 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:28:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082140 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:28:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:28:29 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:28:31 d2.utils.events]: \u001b[0m eta: 0:50:44  iter: 2179  total_loss: 0.1027  loss_cls: 7.587e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02004  loss_rpn_loc: 0.08396  time: 0.3855  data_time: 0.0117  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:28:38 d2.utils.events]: \u001b[0m eta: 0:50:38  iter: 2199  total_loss: 0.1676  loss_cls: 9.173e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03005  loss_rpn_loc: 0.143  time: 0.3855  data_time: 0.0155  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:28:46 d2.utils.events]: \u001b[0m eta: 0:50:31  iter: 2219  total_loss: 0.1318  loss_cls: 4.572e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02377  loss_rpn_loc: 0.1105  time: 0.3855  data_time: 0.0087  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:28:54 d2.utils.events]: \u001b[0m eta: 0:50:23  iter: 2239  total_loss: 0.1249  loss_cls: 6.793e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02398  loss_rpn_loc: 0.098  time: 0.3854  data_time: 0.0122  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:29:01 d2.utils.events]: \u001b[0m eta: 0:50:16  iter: 2259  total_loss: 0.1347  loss_cls: 5.937e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01562  loss_rpn_loc: 0.1131  time: 0.3854  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:29:09 d2.utils.events]: \u001b[0m eta: 0:50:08  iter: 2279  total_loss: 0.1605  loss_cls: 7.799e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0308  loss_rpn_loc: 0.1135  time: 0.3854  data_time: 0.0086  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:29:17 d2.utils.events]: \u001b[0m eta: 0:50:02  iter: 2299  total_loss: 0.1067  loss_cls: 5.655e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01965  loss_rpn_loc: 0.09244  time: 0.3854  data_time: 0.0144  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:29:25 d2.utils.events]: \u001b[0m eta: 0:49:53  iter: 2319  total_loss: 0.1265  loss_cls: 6.297e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01746  loss_rpn_loc: 0.1063  time: 0.3854  data_time: 0.0125  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:29:32 d2.utils.events]: \u001b[0m eta: 0:49:46  iter: 2339  total_loss: 0.1057  loss_cls: 6.394e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01383  loss_rpn_loc: 0.08519  time: 0.3854  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:29:40 d2.utils.events]: \u001b[0m eta: 0:49:36  iter: 2359  total_loss: 0.1034  loss_cls: 6.286e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01415  loss_rpn_loc: 0.08187  time: 0.3854  data_time: 0.0098  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:29:47 d2.utils.events]: \u001b[0m eta: 0:49:26  iter: 2379  total_loss: 0.1027  loss_cls: 9.575e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02602  loss_rpn_loc: 0.07863  time: 0.3853  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:29:55 d2.utils.events]: \u001b[0m eta: 0:49:18  iter: 2399  total_loss: 0.1002  loss_cls: 7.145e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01664  loss_rpn_loc: 0.08316  time: 0.3853  data_time: 0.0121  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:30:03 d2.utils.events]: \u001b[0m eta: 0:49:10  iter: 2419  total_loss: 0.1137  loss_cls: 6.762e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02622  loss_rpn_loc: 0.0873  time: 0.3852  data_time: 0.0131  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:30:10 d2.utils.events]: \u001b[0m eta: 0:49:03  iter: 2439  total_loss: 0.1354  loss_cls: 9.322e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02533  loss_rpn_loc: 0.1098  time: 0.3852  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:30:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:30:13 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:30:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:30:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:30:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0817 s/iter. Eval: 0.0000 s/iter. Total: 0.0832 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:30:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.944812 (0.088300 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:30:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081960 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:30:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:30:19 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:30:24 d2.utils.events]: \u001b[0m eta: 0:48:57  iter: 2459  total_loss: 0.1296  loss_cls: 4.399e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0243  loss_rpn_loc: 0.1049  time: 0.3851  data_time: 0.0128  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:30:32 d2.utils.events]: \u001b[0m eta: 0:48:50  iter: 2479  total_loss: 0.122  loss_cls: 4.094e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01636  loss_rpn_loc: 0.09438  time: 0.3852  data_time: 0.0090  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:30:39 d2.utils.events]: \u001b[0m eta: 0:48:43  iter: 2499  total_loss: 0.128  loss_cls: 5.212e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02392  loss_rpn_loc: 0.1021  time: 0.3852  data_time: 0.0172  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:30:47 d2.utils.events]: \u001b[0m eta: 0:48:34  iter: 2519  total_loss: 0.09154  loss_cls: 3.554e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01327  loss_rpn_loc: 0.07856  time: 0.3852  data_time: 0.0096  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:30:55 d2.utils.events]: \u001b[0m eta: 0:48:27  iter: 2539  total_loss: 0.1089  loss_cls: 4.173e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01453  loss_rpn_loc: 0.09251  time: 0.3852  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:31:02 d2.utils.events]: \u001b[0m eta: 0:48:19  iter: 2559  total_loss: 0.09982  loss_cls: 3.21e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01495  loss_rpn_loc: 0.07501  time: 0.3852  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:31:10 d2.utils.events]: \u001b[0m eta: 0:48:11  iter: 2579  total_loss: 0.1552  loss_cls: 0.00011  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03463  loss_rpn_loc: 0.1292  time: 0.3852  data_time: 0.0099  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:31:18 d2.utils.events]: \u001b[0m eta: 0:48:05  iter: 2599  total_loss: 0.1662  loss_cls: 5.875e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02727  loss_rpn_loc: 0.1247  time: 0.3853  data_time: 0.0143  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:31:26 d2.utils.events]: \u001b[0m eta: 0:47:58  iter: 2619  total_loss: 0.1505  loss_cls: 9.26e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03336  loss_rpn_loc: 0.1234  time: 0.3853  data_time: 0.0127  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:31:34 d2.utils.events]: \u001b[0m eta: 0:47:49  iter: 2639  total_loss: 0.09155  loss_cls: 3.986e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01618  loss_rpn_loc: 0.07999  time: 0.3853  data_time: 0.0080  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:31:42 d2.utils.events]: \u001b[0m eta: 0:47:42  iter: 2659  total_loss: 0.1381  loss_cls: 7.798e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02777  loss_rpn_loc: 0.1132  time: 0.3854  data_time: 0.0264  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:31:49 d2.utils.events]: \u001b[0m eta: 0:47:34  iter: 2679  total_loss: 0.08052  loss_cls: 3.088e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.00651  loss_rpn_loc: 0.06703  time: 0.3854  data_time: 0.0077  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:31:57 d2.utils.events]: \u001b[0m eta: 0:47:27  iter: 2699  total_loss: 0.1965  loss_cls: 6.814e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02811  loss_rpn_loc: 0.1341  time: 0.3854  data_time: 0.0132  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:32:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:32:05 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:32:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:32:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:32:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0820 s/iter. Eval: 0.0000 s/iter. Total: 0.0835 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:32:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.977908 (0.088891 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:32:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081949 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:32:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:32:11 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:32:11 d2.utils.events]: \u001b[0m eta: 0:47:20  iter: 2719  total_loss: 0.1039  loss_cls: 7.661e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02305  loss_rpn_loc: 0.08742  time: 0.3854  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:32:18 d2.utils.events]: \u001b[0m eta: 0:47:11  iter: 2739  total_loss: 0.1059  loss_cls: 4.408e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01751  loss_rpn_loc: 0.08957  time: 0.3854  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:32:26 d2.utils.events]: \u001b[0m eta: 0:47:03  iter: 2759  total_loss: 0.09878  loss_cls: 5.941e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01805  loss_rpn_loc: 0.08146  time: 0.3854  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:32:34 d2.utils.events]: \u001b[0m eta: 0:46:53  iter: 2779  total_loss: 0.1241  loss_cls: 7.664e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01523  loss_rpn_loc: 0.09898  time: 0.3854  data_time: 0.0116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:32:41 d2.utils.events]: \u001b[0m eta: 0:46:45  iter: 2799  total_loss: 0.1204  loss_cls: 7.218e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02746  loss_rpn_loc: 0.09249  time: 0.3853  data_time: 0.0128  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:32:49 d2.utils.events]: \u001b[0m eta: 0:46:37  iter: 2819  total_loss: 0.1835  loss_cls: 5.754e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03121  loss_rpn_loc: 0.1481  time: 0.3853  data_time: 0.0156  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:32:57 d2.utils.events]: \u001b[0m eta: 0:46:29  iter: 2839  total_loss: 0.144  loss_cls: 6.42e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02003  loss_rpn_loc: 0.0986  time: 0.3853  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:33:04 d2.utils.events]: \u001b[0m eta: 0:46:19  iter: 2859  total_loss: 0.1001  loss_cls: 6.617e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0161  loss_rpn_loc: 0.0882  time: 0.3852  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:33:12 d2.utils.events]: \u001b[0m eta: 0:46:10  iter: 2879  total_loss: 0.1073  loss_cls: 7.342e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02157  loss_rpn_loc: 0.08078  time: 0.3852  data_time: 0.0079  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:33:20 d2.utils.events]: \u001b[0m eta: 0:46:00  iter: 2899  total_loss: 0.1296  loss_cls: 5.853e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02025  loss_rpn_loc: 0.1104  time: 0.3852  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:33:27 d2.utils.events]: \u001b[0m eta: 0:45:51  iter: 2919  total_loss: 0.1041  loss_cls: 4.156e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01285  loss_rpn_loc: 0.08812  time: 0.3852  data_time: 0.0110  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:33:35 d2.utils.events]: \u001b[0m eta: 0:45:43  iter: 2939  total_loss: 0.1593  loss_cls: 0.0001068  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04087  loss_rpn_loc: 0.1254  time: 0.3852  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:33:43 d2.utils.events]: \u001b[0m eta: 0:45:36  iter: 2959  total_loss: 0.1294  loss_cls: 6.29e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02045  loss_rpn_loc: 0.1062  time: 0.3852  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:33:51 d2.utils.events]: \u001b[0m eta: 0:45:28  iter: 2979  total_loss: 0.1312  loss_cls: 3.082e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01895  loss_rpn_loc: 0.1037  time: 0.3852  data_time: 0.0103  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:33:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:33:55 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:33:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:33:55 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:33:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0017 s/iter. Inference: 0.0823 s/iter. Eval: 0.0000 s/iter. Total: 0.0840 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:34:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.932848 (0.088087 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:34:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081827 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:34:01 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:34:01 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:34:04 d2.utils.events]: \u001b[0m eta: 0:45:20  iter: 2999  total_loss: 0.1206  loss_cls: 3.597e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02114  loss_rpn_loc: 0.1027  time: 0.3852  data_time: 0.0090  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:34:12 d2.utils.events]: \u001b[0m eta: 0:45:11  iter: 3019  total_loss: 0.113  loss_cls: 3.686e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01788  loss_rpn_loc: 0.08952  time: 0.3851  data_time: 0.0080  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:34:19 d2.utils.events]: \u001b[0m eta: 0:45:03  iter: 3039  total_loss: 0.1152  loss_cls: 5.037e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02132  loss_rpn_loc: 0.1029  time: 0.3851  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:34:27 d2.utils.events]: \u001b[0m eta: 0:44:55  iter: 3059  total_loss: 0.1115  loss_cls: 8.322e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02421  loss_rpn_loc: 0.08571  time: 0.3851  data_time: 0.0092  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:34:35 d2.utils.events]: \u001b[0m eta: 0:44:47  iter: 3079  total_loss: 0.1551  loss_cls: 9.943e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03044  loss_rpn_loc: 0.1004  time: 0.3852  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:34:43 d2.utils.events]: \u001b[0m eta: 0:44:39  iter: 3099  total_loss: 0.1061  loss_cls: 4.548e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01525  loss_rpn_loc: 0.09075  time: 0.3851  data_time: 0.0090  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:34:50 d2.utils.events]: \u001b[0m eta: 0:44:31  iter: 3119  total_loss: 0.1203  loss_cls: 5.499e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01795  loss_rpn_loc: 0.09859  time: 0.3852  data_time: 0.0090  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:34:58 d2.utils.events]: \u001b[0m eta: 0:44:25  iter: 3139  total_loss: 0.1093  loss_cls: 5.58e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02202  loss_rpn_loc: 0.08495  time: 0.3852  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:35:06 d2.utils.events]: \u001b[0m eta: 0:44:18  iter: 3159  total_loss: 0.1404  loss_cls: 0.000103  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02927  loss_rpn_loc: 0.1075  time: 0.3853  data_time: 0.0149  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:35:14 d2.utils.events]: \u001b[0m eta: 0:44:10  iter: 3179  total_loss: 0.1036  loss_cls: 4.77e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0162  loss_rpn_loc: 0.08343  time: 0.3852  data_time: 0.0085  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:35:22 d2.utils.events]: \u001b[0m eta: 0:44:03  iter: 3199  total_loss: 0.1382  loss_cls: 8.211e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02159  loss_rpn_loc: 0.1142  time: 0.3853  data_time: 0.0204  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:35:29 d2.utils.events]: \u001b[0m eta: 0:43:54  iter: 3219  total_loss: 0.09425  loss_cls: 5.589e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01293  loss_rpn_loc: 0.08023  time: 0.3853  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:35:37 d2.utils.events]: \u001b[0m eta: 0:43:48  iter: 3239  total_loss: 0.1436  loss_cls: 5.512e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01728  loss_rpn_loc: 0.1187  time: 0.3853  data_time: 0.0110  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:35:45 d2.utils.events]: \u001b[0m eta: 0:43:40  iter: 3259  total_loss: 0.13  loss_cls: 4.313e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02277  loss_rpn_loc: 0.1021  time: 0.3855  data_time: 0.0406  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:35:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:35:47 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:35:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:35:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:35:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0820 s/iter. Eval: 0.0000 s/iter. Total: 0.0835 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:35:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.951424 (0.088418 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:35:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082018 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:35:53 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:35:53 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:35:59 d2.utils.events]: \u001b[0m eta: 0:43:32  iter: 3279  total_loss: 0.1155  loss_cls: 6.378e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01709  loss_rpn_loc: 0.09968  time: 0.3854  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:36:07 d2.utils.events]: \u001b[0m eta: 0:43:24  iter: 3299  total_loss: 0.1058  loss_cls: 5.591e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01967  loss_rpn_loc: 0.08596  time: 0.3855  data_time: 0.0087  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:36:14 d2.utils.events]: \u001b[0m eta: 0:43:16  iter: 3319  total_loss: 0.1179  loss_cls: 3.952e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01438  loss_rpn_loc: 0.09541  time: 0.3855  data_time: 0.0093  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:36:22 d2.utils.events]: \u001b[0m eta: 0:43:09  iter: 3339  total_loss: 0.1404  loss_cls: 6.379e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02068  loss_rpn_loc: 0.1136  time: 0.3854  data_time: 0.0092  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:36:30 d2.utils.events]: \u001b[0m eta: 0:43:03  iter: 3359  total_loss: 0.1667  loss_cls: 5.084e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0216  loss_rpn_loc: 0.1376  time: 0.3855  data_time: 0.0153  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:36:38 d2.utils.events]: \u001b[0m eta: 0:42:56  iter: 3379  total_loss: 0.1114  loss_cls: 5.658e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02853  loss_rpn_loc: 0.08896  time: 0.3855  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:36:46 d2.utils.events]: \u001b[0m eta: 0:42:48  iter: 3399  total_loss: 0.1151  loss_cls: 4.006e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02223  loss_rpn_loc: 0.09297  time: 0.3855  data_time: 0.0160  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:36:53 d2.utils.events]: \u001b[0m eta: 0:42:42  iter: 3419  total_loss: 0.1205  loss_cls: 3.442e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01591  loss_rpn_loc: 0.09901  time: 0.3856  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:37:01 d2.utils.events]: \u001b[0m eta: 0:42:33  iter: 3439  total_loss: 0.1092  loss_cls: 4.45e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01789  loss_rpn_loc: 0.0925  time: 0.3855  data_time: 0.0136  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:37:09 d2.utils.events]: \u001b[0m eta: 0:42:23  iter: 3459  total_loss: 0.08626  loss_cls: 4.004e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01453  loss_rpn_loc: 0.07167  time: 0.3855  data_time: 0.0089  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:37:16 d2.utils.events]: \u001b[0m eta: 0:42:16  iter: 3479  total_loss: 0.1162  loss_cls: 4.434e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02024  loss_rpn_loc: 0.09546  time: 0.3855  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:37:24 d2.utils.events]: \u001b[0m eta: 0:42:09  iter: 3499  total_loss: 0.1616  loss_cls: 5.387e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02816  loss_rpn_loc: 0.1308  time: 0.3856  data_time: 0.0132  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:37:32 d2.utils.events]: \u001b[0m eta: 0:42:01  iter: 3519  total_loss: 0.1262  loss_cls: 4.394e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02543  loss_rpn_loc: 0.09094  time: 0.3855  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:37:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:37:38 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:37:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:37:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:37:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0821 s/iter. Eval: 0.0000 s/iter. Total: 0.0837 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:37:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.960631 (0.088583 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:37:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081946 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:37:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:37:44 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:37:46 d2.utils.events]: \u001b[0m eta: 0:41:53  iter: 3539  total_loss: 0.1378  loss_cls: 6.981e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03789  loss_rpn_loc: 0.1052  time: 0.3855  data_time: 0.0158  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:37:53 d2.utils.events]: \u001b[0m eta: 0:41:44  iter: 3559  total_loss: 0.1113  loss_cls: 7.613e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02246  loss_rpn_loc: 0.08356  time: 0.3855  data_time: 0.0137  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:38:01 d2.utils.events]: \u001b[0m eta: 0:41:37  iter: 3579  total_loss: 0.09854  loss_cls: 4.274e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02166  loss_rpn_loc: 0.08011  time: 0.3855  data_time: 0.0131  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:38:09 d2.utils.events]: \u001b[0m eta: 0:41:28  iter: 3599  total_loss: 0.1457  loss_cls: 6.498e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0219  loss_rpn_loc: 0.1147  time: 0.3855  data_time: 0.0129  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:38:16 d2.utils.events]: \u001b[0m eta: 0:41:19  iter: 3619  total_loss: 0.1142  loss_cls: 4.592e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02318  loss_rpn_loc: 0.0855  time: 0.3854  data_time: 0.0100  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:38:24 d2.utils.events]: \u001b[0m eta: 0:41:11  iter: 3639  total_loss: 0.1128  loss_cls: 5.151e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02026  loss_rpn_loc: 0.09159  time: 0.3855  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:38:32 d2.utils.events]: \u001b[0m eta: 0:41:04  iter: 3659  total_loss: 0.1242  loss_cls: 7.065e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02955  loss_rpn_loc: 0.09568  time: 0.3855  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:38:40 d2.utils.events]: \u001b[0m eta: 0:40:57  iter: 3679  total_loss: 0.1019  loss_cls: 3.748e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01371  loss_rpn_loc: 0.08405  time: 0.3855  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:38:47 d2.utils.events]: \u001b[0m eta: 0:40:49  iter: 3699  total_loss: 0.09342  loss_cls: 6.987e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02091  loss_rpn_loc: 0.07792  time: 0.3855  data_time: 0.0082  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:38:55 d2.utils.events]: \u001b[0m eta: 0:40:41  iter: 3719  total_loss: 0.09757  loss_cls: 3.164e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01613  loss_rpn_loc: 0.08608  time: 0.3855  data_time: 0.0177  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:39:03 d2.utils.events]: \u001b[0m eta: 0:40:32  iter: 3739  total_loss: 0.1129  loss_cls: 5.948e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01571  loss_rpn_loc: 0.1043  time: 0.3855  data_time: 0.0093  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:39:10 d2.utils.events]: \u001b[0m eta: 0:40:24  iter: 3759  total_loss: 0.1048  loss_cls: 4.541e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0208  loss_rpn_loc: 0.08244  time: 0.3855  data_time: 0.0099  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:39:18 d2.utils.events]: \u001b[0m eta: 0:40:18  iter: 3779  total_loss: 0.1213  loss_cls: 6.767e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02334  loss_rpn_loc: 0.09673  time: 0.3854  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:39:26 d2.utils.events]: \u001b[0m eta: 0:40:11  iter: 3799  total_loss: 0.0992  loss_cls: 6.28e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02076  loss_rpn_loc: 0.0805  time: 0.3854  data_time: 0.0156  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:39:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:39:29 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:39:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:39:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:39:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0818 s/iter. Eval: 0.0000 s/iter. Total: 0.0833 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:39:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.955503 (0.088491 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:39:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082145 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:39:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:39:35 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:39:40 d2.utils.events]: \u001b[0m eta: 0:40:03  iter: 3819  total_loss: 0.1111  loss_cls: 3.353e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.027  loss_rpn_loc: 0.08588  time: 0.3855  data_time: 0.0244  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:39:47 d2.utils.events]: \u001b[0m eta: 0:39:54  iter: 3839  total_loss: 0.1136  loss_cls: 4.49e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02159  loss_rpn_loc: 0.08615  time: 0.3855  data_time: 0.0122  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:39:55 d2.utils.events]: \u001b[0m eta: 0:39:47  iter: 3859  total_loss: 0.0864  loss_cls: 3.88e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0128  loss_rpn_loc: 0.07342  time: 0.3854  data_time: 0.0103  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:40:03 d2.utils.events]: \u001b[0m eta: 0:39:40  iter: 3879  total_loss: 0.1072  loss_cls: 2.539e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01828  loss_rpn_loc: 0.0856  time: 0.3855  data_time: 0.0129  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:40:10 d2.utils.events]: \u001b[0m eta: 0:39:33  iter: 3899  total_loss: 0.1211  loss_cls: 3.376e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0233  loss_rpn_loc: 0.09462  time: 0.3854  data_time: 0.0090  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:40:18 d2.utils.events]: \u001b[0m eta: 0:39:26  iter: 3919  total_loss: 0.09295  loss_cls: 2.695e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0116  loss_rpn_loc: 0.08183  time: 0.3854  data_time: 0.0095  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:40:25 d2.utils.events]: \u001b[0m eta: 0:39:16  iter: 3939  total_loss: 0.08781  loss_cls: 2.324e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01096  loss_rpn_loc: 0.07607  time: 0.3854  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:40:33 d2.utils.events]: \u001b[0m eta: 0:39:09  iter: 3959  total_loss: 0.1768  loss_cls: 5.03e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02966  loss_rpn_loc: 0.1291  time: 0.3854  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:40:41 d2.utils.events]: \u001b[0m eta: 0:39:04  iter: 3979  total_loss: 0.1381  loss_cls: 2.669e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02504  loss_rpn_loc: 0.1112  time: 0.3854  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:40:49 d2.utils.events]: \u001b[0m eta: 0:38:56  iter: 3999  total_loss: 0.1356  loss_cls: 6.951e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02212  loss_rpn_loc: 0.1181  time: 0.3854  data_time: 0.0195  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:40:56 d2.utils.events]: \u001b[0m eta: 0:38:50  iter: 4019  total_loss: 0.1326  loss_cls: 4.676e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0218  loss_rpn_loc: 0.1023  time: 0.3854  data_time: 0.0127  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:41:04 d2.utils.events]: \u001b[0m eta: 0:38:43  iter: 4039  total_loss: 0.1332  loss_cls: 5.266e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02248  loss_rpn_loc: 0.1068  time: 0.3854  data_time: 0.0162  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:41:12 d2.utils.events]: \u001b[0m eta: 0:38:34  iter: 4059  total_loss: 0.124  loss_cls: 3.081e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0198  loss_rpn_loc: 0.1007  time: 0.3855  data_time: 0.0273  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:41:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:41:20 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:41:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:41:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:41:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0820 s/iter. Eval: 0.0000 s/iter. Total: 0.0836 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:41:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.965136 (0.088663 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:41:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082236 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:41:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:41:26 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:41:26 d2.utils.events]: \u001b[0m eta: 0:38:27  iter: 4079  total_loss: 0.1022  loss_cls: 2.504e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01632  loss_rpn_loc: 0.08645  time: 0.3856  data_time: 0.0083  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:41:34 d2.utils.events]: \u001b[0m eta: 0:38:18  iter: 4099  total_loss: 0.08271  loss_cls: 3.851e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0111  loss_rpn_loc: 0.07313  time: 0.3855  data_time: 0.0095  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:41:41 d2.utils.events]: \u001b[0m eta: 0:38:10  iter: 4119  total_loss: 0.1474  loss_cls: 7.414e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02159  loss_rpn_loc: 0.1256  time: 0.3855  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:41:49 d2.utils.events]: \u001b[0m eta: 0:38:02  iter: 4139  total_loss: 0.1039  loss_cls: 5.786e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01969  loss_rpn_loc: 0.08708  time: 0.3856  data_time: 0.0192  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:41:57 d2.utils.events]: \u001b[0m eta: 0:37:54  iter: 4159  total_loss: 0.1457  loss_cls: 5.108e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02282  loss_rpn_loc: 0.1155  time: 0.3855  data_time: 0.0133  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:42:05 d2.utils.events]: \u001b[0m eta: 0:37:46  iter: 4179  total_loss: 0.12  loss_cls: 6.861e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02435  loss_rpn_loc: 0.1076  time: 0.3856  data_time: 0.0179  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:42:13 d2.utils.events]: \u001b[0m eta: 0:37:38  iter: 4199  total_loss: 0.09836  loss_cls: 5.692e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01484  loss_rpn_loc: 0.08855  time: 0.3856  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:42:21 d2.utils.events]: \u001b[0m eta: 0:37:31  iter: 4219  total_loss: 0.1008  loss_cls: 5.293e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01394  loss_rpn_loc: 0.08613  time: 0.3857  data_time: 0.0300  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:42:28 d2.utils.events]: \u001b[0m eta: 0:37:23  iter: 4239  total_loss: 0.09925  loss_cls: 4.433e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01141  loss_rpn_loc: 0.07949  time: 0.3857  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:42:36 d2.utils.events]: \u001b[0m eta: 0:37:15  iter: 4259  total_loss: 0.08724  loss_cls: 1.986e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0132  loss_rpn_loc: 0.06794  time: 0.3856  data_time: 0.0074  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:42:44 d2.utils.events]: \u001b[0m eta: 0:37:07  iter: 4279  total_loss: 0.1035  loss_cls: 3.186e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01569  loss_rpn_loc: 0.08919  time: 0.3856  data_time: 0.0110  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:42:51 d2.utils.events]: \u001b[0m eta: 0:36:57  iter: 4299  total_loss: 0.1286  loss_cls: 4.624e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02045  loss_rpn_loc: 0.1092  time: 0.3855  data_time: 0.0089  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:42:59 d2.utils.events]: \u001b[0m eta: 0:36:50  iter: 4319  total_loss: 0.09524  loss_cls: 3.598e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.07862  time: 0.3855  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:43:07 d2.utils.events]: \u001b[0m eta: 0:36:42  iter: 4339  total_loss: 0.164  loss_cls: 6.016e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01909  loss_rpn_loc: 0.1137  time: 0.3856  data_time: 0.0200  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:43:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:43:11 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:43:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:43:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:43:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0828 s/iter. Eval: 0.0000 s/iter. Total: 0.0844 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:43:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.958102 (0.088538 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:43:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082163 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:43:17 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:43:17 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:43:20 d2.utils.events]: \u001b[0m eta: 0:36:33  iter: 4359  total_loss: 0.09475  loss_cls: 5.411e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0153  loss_rpn_loc: 0.08256  time: 0.3856  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:43:28 d2.utils.events]: \u001b[0m eta: 0:36:26  iter: 4379  total_loss: 0.1322  loss_cls: 4.236e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02589  loss_rpn_loc: 0.1087  time: 0.3856  data_time: 0.0137  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:43:36 d2.utils.events]: \u001b[0m eta: 0:36:20  iter: 4399  total_loss: 0.1118  loss_cls: 3.674e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02558  loss_rpn_loc: 0.09495  time: 0.3856  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:43:44 d2.utils.events]: \u001b[0m eta: 0:36:11  iter: 4419  total_loss: 0.1344  loss_cls: 5.607e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02268  loss_rpn_loc: 0.1043  time: 0.3856  data_time: 0.0204  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:43:51 d2.utils.events]: \u001b[0m eta: 0:36:05  iter: 4439  total_loss: 0.1233  loss_cls: 4.263e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0208  loss_rpn_loc: 0.0992  time: 0.3856  data_time: 0.0143  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:43:59 d2.utils.events]: \u001b[0m eta: 0:35:57  iter: 4459  total_loss: 0.09106  loss_cls: 4.328e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02184  loss_rpn_loc: 0.08096  time: 0.3857  data_time: 0.0168  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:44:07 d2.utils.events]: \u001b[0m eta: 0:35:49  iter: 4479  total_loss: 0.1117  loss_cls: 3.584e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02033  loss_rpn_loc: 0.08842  time: 0.3856  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:44:15 d2.utils.events]: \u001b[0m eta: 0:35:41  iter: 4499  total_loss: 0.09975  loss_cls: 5.211e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01565  loss_rpn_loc: 0.08054  time: 0.3856  data_time: 0.0089  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:44:22 d2.utils.events]: \u001b[0m eta: 0:35:34  iter: 4519  total_loss: 0.1041  loss_cls: 5.107e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01348  loss_rpn_loc: 0.09034  time: 0.3856  data_time: 0.0106  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:44:30 d2.utils.events]: \u001b[0m eta: 0:35:26  iter: 4539  total_loss: 0.1284  loss_cls: 6.383e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.015  loss_rpn_loc: 0.1063  time: 0.3857  data_time: 0.0120  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:44:38 d2.utils.events]: \u001b[0m eta: 0:35:19  iter: 4559  total_loss: 0.1105  loss_cls: 5.363e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01902  loss_rpn_loc: 0.09039  time: 0.3857  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:44:46 d2.utils.events]: \u001b[0m eta: 0:35:12  iter: 4579  total_loss: 0.09404  loss_cls: 3.6e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01268  loss_rpn_loc: 0.08382  time: 0.3857  data_time: 0.0125  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:44:53 d2.utils.events]: \u001b[0m eta: 0:35:03  iter: 4599  total_loss: 0.08496  loss_cls: 1.722e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.00797  loss_rpn_loc: 0.06903  time: 0.3856  data_time: 0.0074  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:45:01 d2.utils.events]: \u001b[0m eta: 0:34:57  iter: 4619  total_loss: 0.1208  loss_cls: 9.224e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02651  loss_rpn_loc: 0.09303  time: 0.3857  data_time: 0.0179  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:45:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:45:03 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:45:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:45:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:45:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0023 s/iter. Inference: 0.0831 s/iter. Eval: 0.0000 s/iter. Total: 0.0854 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:45:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.967387 (0.088703 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:45:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082307 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:45:09 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:45:09 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:45:15 d2.utils.events]: \u001b[0m eta: 0:34:49  iter: 4639  total_loss: 0.1114  loss_cls: 4.274e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01901  loss_rpn_loc: 0.09202  time: 0.3857  data_time: 0.0139  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:45:23 d2.utils.events]: \u001b[0m eta: 0:34:41  iter: 4659  total_loss: 0.1105  loss_cls: 5.706e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02913  loss_rpn_loc: 0.08622  time: 0.3858  data_time: 0.0208  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:45:31 d2.utils.events]: \u001b[0m eta: 0:34:33  iter: 4679  total_loss: 0.09784  loss_cls: 1.925e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01276  loss_rpn_loc: 0.08664  time: 0.3857  data_time: 0.0078  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:45:39 d2.utils.events]: \u001b[0m eta: 0:34:26  iter: 4699  total_loss: 0.12  loss_cls: 3.523e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01654  loss_rpn_loc: 0.1043  time: 0.3858  data_time: 0.0140  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:45:46 d2.utils.events]: \u001b[0m eta: 0:34:18  iter: 4719  total_loss: 0.1086  loss_cls: 4.281e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0159  loss_rpn_loc: 0.09029  time: 0.3858  data_time: 0.0103  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:45:54 d2.utils.events]: \u001b[0m eta: 0:34:10  iter: 4739  total_loss: 0.08963  loss_cls: 2.822e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01042  loss_rpn_loc: 0.0711  time: 0.3857  data_time: 0.0097  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:46:02 d2.utils.events]: \u001b[0m eta: 0:34:02  iter: 4759  total_loss: 0.1504  loss_cls: 2.899e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03227  loss_rpn_loc: 0.1227  time: 0.3857  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:46:09 d2.utils.events]: \u001b[0m eta: 0:33:56  iter: 4779  total_loss: 0.1478  loss_cls: 8.01e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02044  loss_rpn_loc: 0.1136  time: 0.3858  data_time: 0.0130  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:46:17 d2.utils.events]: \u001b[0m eta: 0:33:47  iter: 4799  total_loss: 0.1058  loss_cls: 2.445e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009923  loss_rpn_loc: 0.08646  time: 0.3857  data_time: 0.0081  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:46:25 d2.utils.events]: \u001b[0m eta: 0:33:39  iter: 4819  total_loss: 0.1481  loss_cls: 9.913e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03012  loss_rpn_loc: 0.1206  time: 0.3857  data_time: 0.0132  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:46:33 d2.utils.events]: \u001b[0m eta: 0:33:32  iter: 4839  total_loss: 0.117  loss_cls: 4.084e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01569  loss_rpn_loc: 0.1085  time: 0.3857  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:46:40 d2.utils.events]: \u001b[0m eta: 0:33:25  iter: 4859  total_loss: 0.1178  loss_cls: 6.043e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02091  loss_rpn_loc: 0.1011  time: 0.3858  data_time: 0.0103  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:46:48 d2.utils.events]: \u001b[0m eta: 0:33:19  iter: 4879  total_loss: 0.1193  loss_cls: 6.208e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01874  loss_rpn_loc: 0.1  time: 0.3858  data_time: 0.0125  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:46:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:46:54 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:46:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:46:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:46:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0823 s/iter. Eval: 0.0000 s/iter. Total: 0.0837 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:47:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.950498 (0.088402 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:47:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082106 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:47:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:47:00 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:47:02 d2.utils.events]: \u001b[0m eta: 0:33:11  iter: 4899  total_loss: 0.1145  loss_cls: 5.065e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02096  loss_rpn_loc: 0.09321  time: 0.3858  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:47:09 d2.utils.events]: \u001b[0m eta: 0:33:02  iter: 4919  total_loss: 0.1202  loss_cls: 3.587e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01146  loss_rpn_loc: 0.09743  time: 0.3857  data_time: 0.0089  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:47:17 d2.utils.events]: \u001b[0m eta: 0:32:56  iter: 4939  total_loss: 0.1111  loss_cls: 4.125e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01366  loss_rpn_loc: 0.09929  time: 0.3857  data_time: 0.0132  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:47:25 d2.utils.events]: \u001b[0m eta: 0:32:48  iter: 4959  total_loss: 0.1432  loss_cls: 3.551e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0206  loss_rpn_loc: 0.1119  time: 0.3857  data_time: 0.0204  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:47:33 d2.utils.events]: \u001b[0m eta: 0:32:38  iter: 4979  total_loss: 0.09802  loss_cls: 5.934e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01894  loss_rpn_loc: 0.08086  time: 0.3858  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:47:41 d2.utils.events]: \u001b[0m eta: 0:32:30  iter: 4999  total_loss: 0.09737  loss_cls: 3.8e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.07665  time: 0.3858  data_time: 0.0082  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:47:50 d2.utils.events]: \u001b[0m eta: 0:32:21  iter: 5019  total_loss: 0.106  loss_cls: 4.785e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02025  loss_rpn_loc: 0.0827  time: 0.3857  data_time: 0.0117  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:47:58 d2.utils.events]: \u001b[0m eta: 0:32:12  iter: 5039  total_loss: 0.0902  loss_cls: 2.565e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01491  loss_rpn_loc: 0.07789  time: 0.3857  data_time: 0.0075  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:48:06 d2.utils.events]: \u001b[0m eta: 0:32:04  iter: 5059  total_loss: 0.1192  loss_cls: 3.072e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.08727  time: 0.3857  data_time: 0.0110  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:48:13 d2.utils.events]: \u001b[0m eta: 0:31:57  iter: 5079  total_loss: 0.1051  loss_cls: 3.855e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01738  loss_rpn_loc: 0.09091  time: 0.3857  data_time: 0.0129  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:48:21 d2.utils.events]: \u001b[0m eta: 0:31:51  iter: 5099  total_loss: 0.1485  loss_cls: 3.235e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01946  loss_rpn_loc: 0.1225  time: 0.3858  data_time: 0.0183  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:48:29 d2.utils.events]: \u001b[0m eta: 0:31:44  iter: 5119  total_loss: 0.1307  loss_cls: 2.24e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01906  loss_rpn_loc: 0.1124  time: 0.3858  data_time: 0.0144  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:48:37 d2.utils.events]: \u001b[0m eta: 0:31:36  iter: 5139  total_loss: 0.1097  loss_cls: 2.694e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01534  loss_rpn_loc: 0.09513  time: 0.3858  data_time: 0.0084  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:48:45 d2.utils.events]: \u001b[0m eta: 0:31:28  iter: 5159  total_loss: 0.09716  loss_cls: 2.616e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0136  loss_rpn_loc: 0.08822  time: 0.3857  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:48:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:48:48 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:48:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:48:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:48:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0833 s/iter. Eval: 0.0000 s/iter. Total: 0.0848 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:48:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.945848 (0.088319 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:48:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082242 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:48:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:48:54 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:48:58 d2.utils.events]: \u001b[0m eta: 0:31:20  iter: 5179  total_loss: 0.1237  loss_cls: 5e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01812  loss_rpn_loc: 0.09856  time: 0.3857  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:49:06 d2.utils.events]: \u001b[0m eta: 0:31:12  iter: 5199  total_loss: 0.146  loss_cls: 5.842e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02373  loss_rpn_loc: 0.1189  time: 0.3858  data_time: 0.0184  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:49:14 d2.utils.events]: \u001b[0m eta: 0:31:03  iter: 5219  total_loss: 0.0003343  loss_cls: 1.011e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0003338  loss_rpn_loc: 0  time: 0.3858  data_time: 0.0079  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:49:21 d2.utils.events]: \u001b[0m eta: 0:30:55  iter: 5239  total_loss: 0.09972  loss_cls: 4.453e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01668  loss_rpn_loc: 0.08474  time: 0.3857  data_time: 0.0152  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:49:29 d2.utils.events]: \u001b[0m eta: 0:30:48  iter: 5259  total_loss: 0.1243  loss_cls: 3.405e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01935  loss_rpn_loc: 0.09115  time: 0.3857  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:49:37 d2.utils.events]: \u001b[0m eta: 0:30:41  iter: 5279  total_loss: 0.133  loss_cls: 2.483e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01607  loss_rpn_loc: 0.09102  time: 0.3857  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:49:45 d2.utils.events]: \u001b[0m eta: 0:30:35  iter: 5299  total_loss: 0.07927  loss_cls: 2.08e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.005717  loss_rpn_loc: 0.07298  time: 0.3857  data_time: 0.0095  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:49:52 d2.utils.events]: \u001b[0m eta: 0:30:26  iter: 5319  total_loss: 0.09579  loss_cls: 2.079e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01259  loss_rpn_loc: 0.07795  time: 0.3857  data_time: 0.0103  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:50:00 d2.utils.events]: \u001b[0m eta: 0:30:19  iter: 5339  total_loss: 0.0963  loss_cls: 1.432e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01153  loss_rpn_loc: 0.08148  time: 0.3857  data_time: 0.0142  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:50:07 d2.utils.events]: \u001b[0m eta: 0:30:11  iter: 5359  total_loss: 0.09915  loss_cls: 1.553e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0114  loss_rpn_loc: 0.08222  time: 0.3857  data_time: 0.0120  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:50:15 d2.utils.events]: \u001b[0m eta: 0:30:04  iter: 5379  total_loss: 0.1429  loss_cls: 7.744e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01887  loss_rpn_loc: 0.1192  time: 0.3857  data_time: 0.0235  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:50:23 d2.utils.events]: \u001b[0m eta: 0:29:55  iter: 5399  total_loss: 0.1025  loss_cls: 3.437e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01274  loss_rpn_loc: 0.08388  time: 0.3857  data_time: 0.0133  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:50:31 d2.utils.events]: \u001b[0m eta: 0:29:48  iter: 5419  total_loss: 0.1229  loss_cls: 6.673e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01855  loss_rpn_loc: 0.1042  time: 0.3857  data_time: 0.0133  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:50:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:50:39 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:50:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:50:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:50:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0017 s/iter. Inference: 0.0827 s/iter. Eval: 0.0000 s/iter. Total: 0.0843 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:50:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.949126 (0.088377 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:50:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082430 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:50:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:50:45 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:50:45 d2.utils.events]: \u001b[0m eta: 0:29:41  iter: 5439  total_loss: 0.1412  loss_cls: 4.677e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02651  loss_rpn_loc: 0.1128  time: 0.3857  data_time: 0.0110  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:50:52 d2.utils.events]: \u001b[0m eta: 0:29:34  iter: 5459  total_loss: 0.1324  loss_cls: 4.084e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02422  loss_rpn_loc: 0.1039  time: 0.3857  data_time: 0.0125  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:51:00 d2.utils.events]: \u001b[0m eta: 0:29:27  iter: 5479  total_loss: 0.08649  loss_cls: 3.083e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009347  loss_rpn_loc: 0.07765  time: 0.3857  data_time: 0.0099  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:51:08 d2.utils.events]: \u001b[0m eta: 0:29:19  iter: 5499  total_loss: 0.1133  loss_cls: 4.246e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01903  loss_rpn_loc: 0.09592  time: 0.3857  data_time: 0.0125  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:51:16 d2.utils.events]: \u001b[0m eta: 0:29:11  iter: 5519  total_loss: 0.1758  loss_cls: 8.045e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04097  loss_rpn_loc: 0.1333  time: 0.3858  data_time: 0.0215  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:51:23 d2.utils.events]: \u001b[0m eta: 0:29:01  iter: 5539  total_loss: 0.1101  loss_cls: 2.953e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01597  loss_rpn_loc: 0.08769  time: 0.3857  data_time: 0.0081  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:51:31 d2.utils.events]: \u001b[0m eta: 0:28:52  iter: 5559  total_loss: 0.123  loss_cls: 4.684e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02302  loss_rpn_loc: 0.1043  time: 0.3857  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:51:39 d2.utils.events]: \u001b[0m eta: 0:28:45  iter: 5579  total_loss: 0.109  loss_cls: 4.444e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01119  loss_rpn_loc: 0.09516  time: 0.3857  data_time: 0.0135  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:51:46 d2.utils.events]: \u001b[0m eta: 0:28:39  iter: 5599  total_loss: 0.1408  loss_cls: 3.254e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01572  loss_rpn_loc: 0.1263  time: 0.3858  data_time: 0.0121  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:51:54 d2.utils.events]: \u001b[0m eta: 0:28:29  iter: 5619  total_loss: 0.07951  loss_cls: 4.166e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.008072  loss_rpn_loc: 0.07226  time: 0.3858  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:52:02 d2.utils.events]: \u001b[0m eta: 0:28:22  iter: 5639  total_loss: 0.1079  loss_cls: 3.741e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01393  loss_rpn_loc: 0.09362  time: 0.3857  data_time: 0.0127  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:52:10 d2.utils.events]: \u001b[0m eta: 0:28:12  iter: 5659  total_loss: 0.1224  loss_cls: 4.098e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01997  loss_rpn_loc: 0.1007  time: 0.3857  data_time: 0.0141  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:52:17 d2.utils.events]: \u001b[0m eta: 0:28:05  iter: 5679  total_loss: 0.08456  loss_cls: 4.67e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009236  loss_rpn_loc: 0.07825  time: 0.3858  data_time: 0.0087  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:52:25 d2.utils.events]: \u001b[0m eta: 0:27:56  iter: 5699  total_loss: 0.08913  loss_cls: 3.765e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01126  loss_rpn_loc: 0.07487  time: 0.3857  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:52:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:52:30 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:52:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:52:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:52:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0835 s/iter. Eval: 0.0000 s/iter. Total: 0.0850 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:52:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.948732 (0.088370 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:52:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082408 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:52:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:52:36 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:52:39 d2.utils.events]: \u001b[0m eta: 0:27:48  iter: 5719  total_loss: 0.1238  loss_cls: 2.392e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01923  loss_rpn_loc: 0.09788  time: 0.3857  data_time: 0.0117  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:52:46 d2.utils.events]: \u001b[0m eta: 0:27:41  iter: 5739  total_loss: 0.09414  loss_cls: 2.077e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0133  loss_rpn_loc: 0.08221  time: 0.3857  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:52:54 d2.utils.events]: \u001b[0m eta: 0:27:35  iter: 5759  total_loss: 0.1231  loss_cls: 2.77e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01939  loss_rpn_loc: 0.1022  time: 0.3858  data_time: 0.0130  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:53:02 d2.utils.events]: \u001b[0m eta: 0:27:26  iter: 5779  total_loss: 0.1178  loss_cls: 4.412e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0178  loss_rpn_loc: 0.1013  time: 0.3858  data_time: 0.0134  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:53:10 d2.utils.events]: \u001b[0m eta: 0:27:19  iter: 5799  total_loss: 0.0848  loss_cls: 4.395e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01521  loss_rpn_loc: 0.07253  time: 0.3858  data_time: 0.0116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:53:18 d2.utils.events]: \u001b[0m eta: 0:27:10  iter: 5819  total_loss: 0.09499  loss_cls: 8.782e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01761  loss_rpn_loc: 0.0742  time: 0.3858  data_time: 0.0079  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:53:26 d2.utils.events]: \u001b[0m eta: 0:27:03  iter: 5839  total_loss: 0.1339  loss_cls: 3.422e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01836  loss_rpn_loc: 0.1086  time: 0.3858  data_time: 0.0170  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:53:34 d2.utils.events]: \u001b[0m eta: 0:26:56  iter: 5859  total_loss: 0.1304  loss_cls: 4.145e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01807  loss_rpn_loc: 0.1088  time: 0.3859  data_time: 0.0161  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:53:41 d2.utils.events]: \u001b[0m eta: 0:26:47  iter: 5879  total_loss: 0.154  loss_cls: 6.013e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02304  loss_rpn_loc: 0.1262  time: 0.3859  data_time: 0.0139  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:53:49 d2.utils.events]: \u001b[0m eta: 0:26:39  iter: 5899  total_loss: 0.1131  loss_cls: 2.135e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01717  loss_rpn_loc: 0.1009  time: 0.3858  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:53:56 d2.utils.events]: \u001b[0m eta: 0:26:31  iter: 5919  total_loss: 0.0766  loss_cls: 1.644e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.00834  loss_rpn_loc: 0.06939  time: 0.3858  data_time: 0.0071  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:54:04 d2.utils.events]: \u001b[0m eta: 0:26:24  iter: 5939  total_loss: 0.1051  loss_cls: 1.789e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01135  loss_rpn_loc: 0.08566  time: 0.3858  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:54:12 d2.utils.events]: \u001b[0m eta: 0:26:16  iter: 5959  total_loss: 0.1017  loss_cls: 2.594e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01435  loss_rpn_loc: 0.08948  time: 0.3858  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:54:20 d2.utils.events]: \u001b[0m eta: 0:26:09  iter: 5979  total_loss: 0.1373  loss_cls: 3.265e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02698  loss_rpn_loc: 0.1049  time: 0.3859  data_time: 0.0160  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:54:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:54:22 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:54:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:54:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:54:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0823 s/iter. Eval: 0.0000 s/iter. Total: 0.0838 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:54:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.941721 (0.088245 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:54:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082300 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:54:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:54:27 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:54:34 d2.utils.events]: \u001b[0m eta: 0:26:02  iter: 5999  total_loss: 0.1135  loss_cls: 3.035e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0187  loss_rpn_loc: 0.09208  time: 0.3859  data_time: 0.0110  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:54:41 d2.utils.events]: \u001b[0m eta: 0:25:55  iter: 6019  total_loss: 0.133  loss_cls: 3.903e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02298  loss_rpn_loc: 0.1088  time: 0.3859  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:54:49 d2.utils.events]: \u001b[0m eta: 0:25:46  iter: 6039  total_loss: 0.08142  loss_cls: 1.557e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009803  loss_rpn_loc: 0.07334  time: 0.3858  data_time: 0.0075  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:54:56 d2.utils.events]: \u001b[0m eta: 0:25:38  iter: 6059  total_loss: 0.1087  loss_cls: 3.606e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01673  loss_rpn_loc: 0.09603  time: 0.3858  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:55:04 d2.utils.events]: \u001b[0m eta: 0:25:29  iter: 6079  total_loss: 0.1163  loss_cls: 2.308e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02386  loss_rpn_loc: 0.0953  time: 0.3858  data_time: 0.0125  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:55:12 d2.utils.events]: \u001b[0m eta: 0:25:22  iter: 6099  total_loss: 0.1471  loss_cls: 3.419e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02388  loss_rpn_loc: 0.1167  time: 0.3858  data_time: 0.0155  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:55:20 d2.utils.events]: \u001b[0m eta: 0:25:12  iter: 6119  total_loss: 0.1276  loss_cls: 3.919e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02315  loss_rpn_loc: 0.09659  time: 0.3858  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:55:28 d2.utils.events]: \u001b[0m eta: 0:25:06  iter: 6139  total_loss: 0.1064  loss_cls: 3.859e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01465  loss_rpn_loc: 0.08129  time: 0.3858  data_time: 0.0117  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:55:35 d2.utils.events]: \u001b[0m eta: 0:24:59  iter: 6159  total_loss: 0.1097  loss_cls: 3.857e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01529  loss_rpn_loc: 0.08982  time: 0.3858  data_time: 0.0153  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:55:43 d2.utils.events]: \u001b[0m eta: 0:24:52  iter: 6179  total_loss: 0.1348  loss_cls: 4.802e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0274  loss_rpn_loc: 0.1045  time: 0.3859  data_time: 0.0258  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:55:51 d2.utils.events]: \u001b[0m eta: 0:24:42  iter: 6199  total_loss: 0.1155  loss_cls: 4.011e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01813  loss_rpn_loc: 0.09619  time: 0.3858  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:55:59 d2.utils.events]: \u001b[0m eta: 0:24:36  iter: 6219  total_loss: 0.09669  loss_cls: 2.102e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01631  loss_rpn_loc: 0.07594  time: 0.3858  data_time: 0.0154  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:56:06 d2.utils.events]: \u001b[0m eta: 0:24:28  iter: 6239  total_loss: 0.08664  loss_cls: 4.773e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01241  loss_rpn_loc: 0.07666  time: 0.3859  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:56:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:56:13 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:56:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:56:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:56:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0819 s/iter. Eval: 0.0000 s/iter. Total: 0.0835 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:56:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.933885 (0.088105 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:56:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082322 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:56:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:56:18 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:56:20 d2.utils.events]: \u001b[0m eta: 0:24:20  iter: 6259  total_loss: 0.07666  loss_cls: 9.439e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007588  loss_rpn_loc: 0.06903  time: 0.3859  data_time: 0.0100  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:56:28 d2.utils.events]: \u001b[0m eta: 0:24:13  iter: 6279  total_loss: 0.1239  loss_cls: 3.052e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01967  loss_rpn_loc: 0.1027  time: 0.3859  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:56:35 d2.utils.events]: \u001b[0m eta: 0:24:05  iter: 6299  total_loss: 0.03294  loss_cls: 3.133e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.001628  loss_rpn_loc: 0.0313  time: 0.3859  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:56:43 d2.utils.events]: \u001b[0m eta: 0:23:57  iter: 6319  total_loss: 0.1354  loss_cls: 5.281e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0227  loss_rpn_loc: 0.1007  time: 0.3858  data_time: 0.0127  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:56:51 d2.utils.events]: \u001b[0m eta: 0:23:49  iter: 6339  total_loss: 0.1185  loss_cls: 4.049e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01521  loss_rpn_loc: 0.1027  time: 0.3858  data_time: 0.0101  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:56:59 d2.utils.events]: \u001b[0m eta: 0:23:43  iter: 6359  total_loss: 0.1448  loss_cls: 5.563e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02136  loss_rpn_loc: 0.1297  time: 0.3859  data_time: 0.0136  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:57:06 d2.utils.events]: \u001b[0m eta: 0:23:35  iter: 6379  total_loss: 0.1246  loss_cls: 3.197e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02017  loss_rpn_loc: 0.1052  time: 0.3859  data_time: 0.0120  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:57:14 d2.utils.events]: \u001b[0m eta: 0:23:27  iter: 6399  total_loss: 0.1343  loss_cls: 4.057e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01725  loss_rpn_loc: 0.1068  time: 0.3859  data_time: 0.0131  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:57:22 d2.utils.events]: \u001b[0m eta: 0:23:19  iter: 6419  total_loss: 0.1199  loss_cls: 5.081e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01999  loss_rpn_loc: 0.1014  time: 0.3858  data_time: 0.0101  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:57:30 d2.utils.events]: \u001b[0m eta: 0:23:11  iter: 6439  total_loss: 0.1139  loss_cls: 3.928e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01583  loss_rpn_loc: 0.08849  time: 0.3859  data_time: 0.0139  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:57:37 d2.utils.events]: \u001b[0m eta: 0:23:04  iter: 6459  total_loss: 0.1223  loss_cls: 2.632e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01493  loss_rpn_loc: 0.1075  time: 0.3859  data_time: 0.0145  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:57:45 d2.utils.events]: \u001b[0m eta: 0:22:54  iter: 6479  total_loss: 0.1438  loss_cls: 1.958e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01375  loss_rpn_loc: 0.111  time: 0.3858  data_time: 0.0099  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:57:53 d2.utils.events]: \u001b[0m eta: 0:22:47  iter: 6499  total_loss: 0.1175  loss_cls: 3.114e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01474  loss_rpn_loc: 0.09701  time: 0.3858  data_time: 0.0227  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:58:01 d2.utils.events]: \u001b[0m eta: 0:22:39  iter: 6519  total_loss: 0.08274  loss_cls: 1.622e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0087  loss_rpn_loc: 0.07856  time: 0.3859  data_time: 0.0148  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:58:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:58:04 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:58:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:58:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:58:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0825 s/iter. Eval: 0.0000 s/iter. Total: 0.0840 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 15:58:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.951515 (0.088420 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:58:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082481 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 15:58:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 15:58:10 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 15:58:14 d2.utils.events]: \u001b[0m eta: 0:22:32  iter: 6539  total_loss: 0.09193  loss_cls: 1.827e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007991  loss_rpn_loc: 0.07639  time: 0.3859  data_time: 0.0121  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:58:22 d2.utils.events]: \u001b[0m eta: 0:22:24  iter: 6559  total_loss: 0.1093  loss_cls: 2.11e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01231  loss_rpn_loc: 0.09882  time: 0.3859  data_time: 0.0093  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:58:29 d2.utils.events]: \u001b[0m eta: 0:22:16  iter: 6579  total_loss: 0.1131  loss_cls: 2.396e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02372  loss_rpn_loc: 0.09008  time: 0.3858  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:58:37 d2.utils.events]: \u001b[0m eta: 0:22:07  iter: 6599  total_loss: 0.1085  loss_cls: 3.049e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.019  loss_rpn_loc: 0.09566  time: 0.3858  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:58:45 d2.utils.events]: \u001b[0m eta: 0:21:59  iter: 6619  total_loss: 0.09284  loss_cls: 3.699e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01603  loss_rpn_loc: 0.07953  time: 0.3858  data_time: 0.0127  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:58:53 d2.utils.events]: \u001b[0m eta: 0:21:52  iter: 6639  total_loss: 0.1409  loss_cls: 2.895e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02363  loss_rpn_loc: 0.1149  time: 0.3859  data_time: 0.0138  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:59:01 d2.utils.events]: \u001b[0m eta: 0:21:44  iter: 6659  total_loss: 0.102  loss_cls: 1.138e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0178  loss_rpn_loc: 0.08098  time: 0.3859  data_time: 0.0135  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:59:08 d2.utils.events]: \u001b[0m eta: 0:21:37  iter: 6679  total_loss: 0.09087  loss_cls: 3.158e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01751  loss_rpn_loc: 0.07736  time: 0.3859  data_time: 0.0116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:59:16 d2.utils.events]: \u001b[0m eta: 0:21:29  iter: 6699  total_loss: 0.0897  loss_cls: 1.526e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009224  loss_rpn_loc: 0.07971  time: 0.3859  data_time: 0.0098  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:59:24 d2.utils.events]: \u001b[0m eta: 0:21:21  iter: 6719  total_loss: 0.1043  loss_cls: 2.349e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01816  loss_rpn_loc: 0.08433  time: 0.3859  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:59:31 d2.utils.events]: \u001b[0m eta: 0:21:13  iter: 6739  total_loss: 0.09611  loss_cls: 2.322e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01781  loss_rpn_loc: 0.08505  time: 0.3858  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:59:39 d2.utils.events]: \u001b[0m eta: 0:21:05  iter: 6759  total_loss: 0.09434  loss_cls: 3.033e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.07603  time: 0.3858  data_time: 0.0179  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:59:47 d2.utils.events]: \u001b[0m eta: 0:20:57  iter: 6779  total_loss: 0.1297  loss_cls: 2.984e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01553  loss_rpn_loc: 0.1117  time: 0.3858  data_time: 0.0130  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 15:59:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 15:59:54 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 15:59:54 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 15:59:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 15:59:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0823 s/iter. Eval: 0.0000 s/iter. Total: 0.0836 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:00:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.887200 (0.087271 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:00:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081709 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:00:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 16:00:00 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:00:00 d2.utils.events]: \u001b[0m eta: 0:20:48  iter: 6799  total_loss: 0.08604  loss_cls: 2.97e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01164  loss_rpn_loc: 0.07518  time: 0.3858  data_time: 0.0134  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:00:08 d2.utils.events]: \u001b[0m eta: 0:20:40  iter: 6819  total_loss: 0.1045  loss_cls: 3.782e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01474  loss_rpn_loc: 0.0854  time: 0.3858  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:00:15 d2.utils.events]: \u001b[0m eta: 0:20:32  iter: 6839  total_loss: 0.1229  loss_cls: 3.348e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01458  loss_rpn_loc: 0.09682  time: 0.3858  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:00:23 d2.utils.events]: \u001b[0m eta: 0:20:24  iter: 6859  total_loss: 0.1229  loss_cls: 1.88e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01609  loss_rpn_loc: 0.0945  time: 0.3858  data_time: 0.0098  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:00:31 d2.utils.events]: \u001b[0m eta: 0:20:17  iter: 6879  total_loss: 0.09675  loss_cls: 3.444e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009832  loss_rpn_loc: 0.08685  time: 0.3858  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:00:39 d2.utils.events]: \u001b[0m eta: 0:20:09  iter: 6899  total_loss: 0.1205  loss_cls: 4.417e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01848  loss_rpn_loc: 0.1044  time: 0.3858  data_time: 0.0088  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:00:46 d2.utils.events]: \u001b[0m eta: 0:20:02  iter: 6919  total_loss: 0.1104  loss_cls: 3.088e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01829  loss_rpn_loc: 0.09269  time: 0.3858  data_time: 0.0110  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:00:54 d2.utils.events]: \u001b[0m eta: 0:19:55  iter: 6939  total_loss: 0.1057  loss_cls: 2.164e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01457  loss_rpn_loc: 0.08933  time: 0.3858  data_time: 0.0121  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:01:02 d2.utils.events]: \u001b[0m eta: 0:19:46  iter: 6959  total_loss: 0.1108  loss_cls: 4.982e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01678  loss_rpn_loc: 0.08995  time: 0.3858  data_time: 0.0141  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:01:10 d2.utils.events]: \u001b[0m eta: 0:19:38  iter: 6979  total_loss: 0.1132  loss_cls: 4.067e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02209  loss_rpn_loc: 0.08781  time: 0.3858  data_time: 0.0164  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:01:17 d2.utils.events]: \u001b[0m eta: 0:19:29  iter: 6999  total_loss: 0.1  loss_cls: 4.1e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01125  loss_rpn_loc: 0.08852  time: 0.3858  data_time: 0.0087  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:01:26 d2.utils.events]: \u001b[0m eta: 0:19:22  iter: 7019  total_loss: 0.1136  loss_cls: 2.11e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01319  loss_rpn_loc: 0.0956  time: 0.3859  data_time: 0.0141  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:01:33 d2.utils.events]: \u001b[0m eta: 0:19:14  iter: 7039  total_loss: 0.08449  loss_cls: 3.204e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.008122  loss_rpn_loc: 0.07273  time: 0.3859  data_time: 0.0122  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:01:41 d2.utils.events]: \u001b[0m eta: 0:19:08  iter: 7059  total_loss: 0.1093  loss_cls: 5.464e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01749  loss_rpn_loc: 0.08815  time: 0.3859  data_time: 0.0170  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:01:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:01:46 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:01:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:01:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:01:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0823 s/iter. Eval: 0.0000 s/iter. Total: 0.0839 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:01:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.909827 (0.087675 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:01:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081907 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:01:51 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 16:01:51 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:01:55 d2.utils.events]: \u001b[0m eta: 0:19:00  iter: 7079  total_loss: 0.1126  loss_cls: 3.076e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02422  loss_rpn_loc: 0.07836  time: 0.3859  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:02:02 d2.utils.events]: \u001b[0m eta: 0:18:51  iter: 7099  total_loss: 0.09232  loss_cls: 1.127e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.008538  loss_rpn_loc: 0.08376  time: 0.3858  data_time: 0.0079  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:02:10 d2.utils.events]: \u001b[0m eta: 0:18:44  iter: 7119  total_loss: 0.1203  loss_cls: 2.685e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0192  loss_rpn_loc: 0.1059  time: 0.3859  data_time: 0.0117  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:02:18 d2.utils.events]: \u001b[0m eta: 0:18:35  iter: 7139  total_loss: 0.1145  loss_cls: 4.886e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01776  loss_rpn_loc: 0.09599  time: 0.3858  data_time: 0.0140  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:02:26 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 7159  total_loss: 0.1167  loss_cls: 3.055e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01657  loss_rpn_loc: 0.09243  time: 0.3859  data_time: 0.0256  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:02:33 d2.utils.events]: \u001b[0m eta: 0:18:19  iter: 7179  total_loss: 0.1329  loss_cls: 3.383e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02244  loss_rpn_loc: 0.1066  time: 0.3859  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:02:41 d2.utils.events]: \u001b[0m eta: 0:18:12  iter: 7199  total_loss: 0.09162  loss_cls: 1.956e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007685  loss_rpn_loc: 0.08411  time: 0.3859  data_time: 0.0146  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:02:49 d2.utils.events]: \u001b[0m eta: 0:18:04  iter: 7219  total_loss: 0.1112  loss_cls: 2.147e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01618  loss_rpn_loc: 0.09637  time: 0.3859  data_time: 0.0099  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:02:57 d2.utils.events]: \u001b[0m eta: 0:17:56  iter: 7239  total_loss: 0.1717  loss_cls: 3.725e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02656  loss_rpn_loc: 0.128  time: 0.3859  data_time: 0.0133  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:03:04 d2.utils.events]: \u001b[0m eta: 0:17:48  iter: 7259  total_loss: 0.1002  loss_cls: 2.466e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0214  loss_rpn_loc: 0.07563  time: 0.3859  data_time: 0.0142  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:03:12 d2.utils.events]: \u001b[0m eta: 0:17:40  iter: 7279  total_loss: 0.1013  loss_cls: 2.241e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01062  loss_rpn_loc: 0.0821  time: 0.3859  data_time: 0.0087  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:03:20 d2.utils.events]: \u001b[0m eta: 0:17:32  iter: 7299  total_loss: 0.101  loss_cls: 3.679e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0116  loss_rpn_loc: 0.08651  time: 0.3859  data_time: 0.0116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:03:28 d2.utils.events]: \u001b[0m eta: 0:17:25  iter: 7319  total_loss: 0.1118  loss_cls: 1.746e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01437  loss_rpn_loc: 0.09713  time: 0.3859  data_time: 0.0197  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:03:36 d2.utils.events]: \u001b[0m eta: 0:17:17  iter: 7339  total_loss: 0.1003  loss_cls: 2.687e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0162  loss_rpn_loc: 0.08536  time: 0.3859  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:03:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:03:37 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:03:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:03:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:03:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0818 s/iter. Eval: 0.0000 s/iter. Total: 0.0831 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:03:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.897473 (0.087455 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:03:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081975 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:03:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 16:03:43 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:03:49 d2.utils.events]: \u001b[0m eta: 0:17:08  iter: 7359  total_loss: 0.0959  loss_cls: 3.181e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.008881  loss_rpn_loc: 0.08757  time: 0.3859  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:03:57 d2.utils.events]: \u001b[0m eta: 0:17:00  iter: 7379  total_loss: 0.1188  loss_cls: 4.458e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01511  loss_rpn_loc: 0.1024  time: 0.3859  data_time: 0.0131  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:04:04 d2.utils.events]: \u001b[0m eta: 0:16:52  iter: 7399  total_loss: 0.1143  loss_cls: 3.944e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01876  loss_rpn_loc: 0.09835  time: 0.3859  data_time: 0.0087  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:04:12 d2.utils.events]: \u001b[0m eta: 0:16:44  iter: 7419  total_loss: 0.1095  loss_cls: 1.101e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01877  loss_rpn_loc: 0.09167  time: 0.3859  data_time: 0.0097  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:04:20 d2.utils.events]: \u001b[0m eta: 0:16:37  iter: 7439  total_loss: 0.1101  loss_cls: 1.852e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01888  loss_rpn_loc: 0.08967  time: 0.3859  data_time: 0.0132  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:04:28 d2.utils.events]: \u001b[0m eta: 0:16:29  iter: 7459  total_loss: 0.1105  loss_cls: 2.417e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01719  loss_rpn_loc: 0.09284  time: 0.3859  data_time: 0.0147  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:04:35 d2.utils.events]: \u001b[0m eta: 0:16:22  iter: 7479  total_loss: 0.1163  loss_cls: 3.318e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02159  loss_rpn_loc: 0.09119  time: 0.3859  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:04:43 d2.utils.events]: \u001b[0m eta: 0:16:14  iter: 7499  total_loss: 0.1141  loss_cls: 3.846e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02231  loss_rpn_loc: 0.09275  time: 0.3859  data_time: 0.0149  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:04:51 d2.utils.events]: \u001b[0m eta: 0:16:05  iter: 7519  total_loss: 0.1276  loss_cls: 2.918e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02144  loss_rpn_loc: 0.09901  time: 0.3859  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:04:58 d2.utils.events]: \u001b[0m eta: 0:15:57  iter: 7539  total_loss: 0.1016  loss_cls: 2.723e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01403  loss_rpn_loc: 0.08874  time: 0.3858  data_time: 0.0132  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:05:06 d2.utils.events]: \u001b[0m eta: 0:15:50  iter: 7559  total_loss: 0.08412  loss_cls: 7.227e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007936  loss_rpn_loc: 0.07407  time: 0.3858  data_time: 0.0092  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:05:13 d2.utils.events]: \u001b[0m eta: 0:15:42  iter: 7579  total_loss: 0.1246  loss_cls: 2.847e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01961  loss_rpn_loc: 0.1094  time: 0.3858  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:05:21 d2.utils.events]: \u001b[0m eta: 0:15:34  iter: 7599  total_loss: 0.09581  loss_cls: 3.084e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01384  loss_rpn_loc: 0.08172  time: 0.3858  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:05:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:05:27 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:05:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:05:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:05:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0815 s/iter. Eval: 0.0000 s/iter. Total: 0.0830 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:05:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.880879 (0.087159 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:05:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081640 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:05:33 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 16:05:33 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:05:34 d2.utils.events]: \u001b[0m eta: 0:15:26  iter: 7619  total_loss: 0.08469  loss_cls: 2.391e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01163  loss_rpn_loc: 0.06975  time: 0.3858  data_time: 0.0103  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:05:42 d2.utils.events]: \u001b[0m eta: 0:15:18  iter: 7639  total_loss: 0.1251  loss_cls: 6.918e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01701  loss_rpn_loc: 0.1035  time: 0.3858  data_time: 0.0136  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:05:49 d2.utils.events]: \u001b[0m eta: 0:15:10  iter: 7659  total_loss: 0.09125  loss_cls: 5.11e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.013  loss_rpn_loc: 0.07611  time: 0.3857  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:05:57 d2.utils.events]: \u001b[0m eta: 0:15:02  iter: 7679  total_loss: 0.1054  loss_cls: 4.02e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02055  loss_rpn_loc: 0.08163  time: 0.3857  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:06:05 d2.utils.events]: \u001b[0m eta: 0:14:55  iter: 7699  total_loss: 0.09246  loss_cls: 9.84e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01214  loss_rpn_loc: 0.08414  time: 0.3858  data_time: 0.0121  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:06:12 d2.utils.events]: \u001b[0m eta: 0:14:47  iter: 7719  total_loss: 0.09035  loss_cls: 2.131e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01062  loss_rpn_loc: 0.08195  time: 0.3857  data_time: 0.0120  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:06:20 d2.utils.events]: \u001b[0m eta: 0:14:39  iter: 7739  total_loss: 0.1175  loss_cls: 2.842e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01889  loss_rpn_loc: 0.09521  time: 0.3857  data_time: 0.0137  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:06:28 d2.utils.events]: \u001b[0m eta: 0:14:32  iter: 7759  total_loss: 0.09779  loss_cls: 3.446e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01037  loss_rpn_loc: 0.0855  time: 0.3857  data_time: 0.0176  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:06:36 d2.utils.events]: \u001b[0m eta: 0:14:24  iter: 7779  total_loss: 0.07477  loss_cls: 1.015e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.005016  loss_rpn_loc: 0.06786  time: 0.3857  data_time: 0.0089  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:06:43 d2.utils.events]: \u001b[0m eta: 0:14:16  iter: 7799  total_loss: 0.115  loss_cls: 3.035e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.09114  time: 0.3857  data_time: 0.0101  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:06:51 d2.utils.events]: \u001b[0m eta: 0:14:08  iter: 7819  total_loss: 0.08534  loss_cls: 2.89e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007536  loss_rpn_loc: 0.07204  time: 0.3857  data_time: 0.0080  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:06:59 d2.utils.events]: \u001b[0m eta: 0:14:01  iter: 7839  total_loss: 0.1211  loss_cls: 5.131e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.09556  time: 0.3857  data_time: 0.0133  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:07:07 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 7859  total_loss: 0.1689  loss_cls: 3.506e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02491  loss_rpn_loc: 0.138  time: 0.3857  data_time: 0.0129  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:07:14 d2.utils.events]: \u001b[0m eta: 0:13:45  iter: 7879  total_loss: 0.1681  loss_cls: 4.217e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02072  loss_rpn_loc: 0.1174  time: 0.3857  data_time: 0.0149  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:07:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:07:18 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:07:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:07:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:07:19 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0824 s/iter. Eval: 0.0000 s/iter. Total: 0.0839 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:07:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.896201 (0.087432 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:07:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081742 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:07:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 16:07:24 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:07:28 d2.utils.events]: \u001b[0m eta: 0:13:38  iter: 7899  total_loss: 0.1029  loss_cls: 3.488e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01893  loss_rpn_loc: 0.08556  time: 0.3857  data_time: 0.0138  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:07:36 d2.utils.events]: \u001b[0m eta: 0:13:30  iter: 7919  total_loss: 0.1029  loss_cls: 5.388e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01537  loss_rpn_loc: 0.08561  time: 0.3857  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:07:43 d2.utils.events]: \u001b[0m eta: 0:13:21  iter: 7939  total_loss: 0.1334  loss_cls: 3.883e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01878  loss_rpn_loc: 0.1139  time: 0.3857  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:07:51 d2.utils.events]: \u001b[0m eta: 0:13:14  iter: 7959  total_loss: 0.1076  loss_cls: 3.448e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01808  loss_rpn_loc: 0.08781  time: 0.3857  data_time: 0.0202  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:07:59 d2.utils.events]: \u001b[0m eta: 0:13:06  iter: 7979  total_loss: 0.09051  loss_cls: 7.737e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.006147  loss_rpn_loc: 0.07349  time: 0.3857  data_time: 0.0101  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:08:06 d2.utils.events]: \u001b[0m eta: 0:12:58  iter: 7999  total_loss: 0.08437  loss_cls: 9.257e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01067  loss_rpn_loc: 0.07307  time: 0.3857  data_time: 0.0068  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:08:14 d2.utils.events]: \u001b[0m eta: 0:12:50  iter: 8019  total_loss: 0.09019  loss_cls: 2.938e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0167  loss_rpn_loc: 0.08169  time: 0.3857  data_time: 0.0140  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:08:22 d2.utils.events]: \u001b[0m eta: 0:12:42  iter: 8039  total_loss: 0.09937  loss_cls: 2.135e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01102  loss_rpn_loc: 0.07909  time: 0.3857  data_time: 0.0135  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:08:29 d2.utils.events]: \u001b[0m eta: 0:12:34  iter: 8059  total_loss: 0.1049  loss_cls: 4.172e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01731  loss_rpn_loc: 0.09703  time: 0.3857  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:08:37 d2.utils.events]: \u001b[0m eta: 0:12:26  iter: 8079  total_loss: 0.1106  loss_cls: 3.431e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01802  loss_rpn_loc: 0.09449  time: 0.3857  data_time: 0.0128  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:08:45 d2.utils.events]: \u001b[0m eta: 0:12:19  iter: 8099  total_loss: 0.1103  loss_cls: 2.301e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01382  loss_rpn_loc: 0.08854  time: 0.3857  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:08:52 d2.utils.events]: \u001b[0m eta: 0:12:10  iter: 8119  total_loss: 0.09297  loss_cls: 2.72e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01193  loss_rpn_loc: 0.07991  time: 0.3857  data_time: 0.0103  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:09:00 d2.utils.events]: \u001b[0m eta: 0:12:03  iter: 8139  total_loss: 0.1216  loss_cls: 2.05e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009294  loss_rpn_loc: 0.1013  time: 0.3857  data_time: 0.0141  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:09:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:09:08 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:09:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:09:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:09:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0818 s/iter. Eval: 0.0000 s/iter. Total: 0.0832 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:09:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.884155 (0.087217 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:09:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081652 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:09:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 16:09:14 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:09:14 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 8159  total_loss: 0.1489  loss_cls: 7.229e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02975  loss_rpn_loc: 0.1059  time: 0.3857  data_time: 0.0161  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:09:22 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 8179  total_loss: 0.09466  loss_cls: 3.445e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.08385  time: 0.3857  data_time: 0.0138  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:09:29 d2.utils.events]: \u001b[0m eta: 0:11:39  iter: 8199  total_loss: 0.07486  loss_cls: 1.796e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.00754  loss_rpn_loc: 0.06318  time: 0.3857  data_time: 0.0080  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:09:37 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 8219  total_loss: 0.09151  loss_cls: 1.487e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01049  loss_rpn_loc: 0.07905  time: 0.3857  data_time: 0.0083  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:09:45 d2.utils.events]: \u001b[0m eta: 0:11:24  iter: 8239  total_loss: 0.1413  loss_cls: 2.588e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02135  loss_rpn_loc: 0.1157  time: 0.3857  data_time: 0.0171  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:09:52 d2.utils.events]: \u001b[0m eta: 0:11:16  iter: 8259  total_loss: 0.1075  loss_cls: 1.839e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01439  loss_rpn_loc: 0.09667  time: 0.3857  data_time: 0.0160  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:10:00 d2.utils.events]: \u001b[0m eta: 0:11:08  iter: 8279  total_loss: 0.1096  loss_cls: 1.996e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0161  loss_rpn_loc: 0.09254  time: 0.3857  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:10:08 d2.utils.events]: \u001b[0m eta: 0:11:01  iter: 8299  total_loss: 0.1014  loss_cls: 2.343e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01401  loss_rpn_loc: 0.08547  time: 0.3857  data_time: 0.0154  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:10:16 d2.utils.events]: \u001b[0m eta: 0:10:53  iter: 8319  total_loss: 0.1681  loss_cls: 5.479e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02431  loss_rpn_loc: 0.1317  time: 0.3857  data_time: 0.0159  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:10:24 d2.utils.events]: \u001b[0m eta: 0:10:45  iter: 8339  total_loss: 0.1042  loss_cls: 2.273e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01224  loss_rpn_loc: 0.0958  time: 0.3858  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:10:32 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 8359  total_loss: 0.1188  loss_cls: 2.489e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01566  loss_rpn_loc: 0.1081  time: 0.3858  data_time: 0.0135  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:10:39 d2.utils.events]: \u001b[0m eta: 0:10:30  iter: 8379  total_loss: 0.117  loss_cls: 1.695e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01709  loss_rpn_loc: 0.09565  time: 0.3857  data_time: 0.0089  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:10:47 d2.utils.events]: \u001b[0m eta: 0:10:22  iter: 8399  total_loss: 0.08996  loss_cls: 3.589e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0176  loss_rpn_loc: 0.08352  time: 0.3857  data_time: 0.0096  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:10:55 d2.utils.events]: \u001b[0m eta: 0:10:14  iter: 8419  total_loss: 0.1007  loss_cls: 4.139e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01813  loss_rpn_loc: 0.08776  time: 0.3857  data_time: 0.0116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:10:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:10:59 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:10:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:10:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:11:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0814 s/iter. Eval: 0.0000 s/iter. Total: 0.0828 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:11:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.896607 (0.087439 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:11:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081760 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:11:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 16:11:05 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:11:08 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 8439  total_loss: 0.0937  loss_cls: 1.421e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01274  loss_rpn_loc: 0.07925  time: 0.3857  data_time: 0.0100  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:11:16 d2.utils.events]: \u001b[0m eta: 0:09:58  iter: 8459  total_loss: 0.1084  loss_cls: 4.204e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01928  loss_rpn_loc: 0.08687  time: 0.3857  data_time: 0.0085  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:11:24 d2.utils.events]: \u001b[0m eta: 0:09:50  iter: 8479  total_loss: 0.1111  loss_cls: 4.643e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01648  loss_rpn_loc: 0.09004  time: 0.3857  data_time: 0.0147  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:11:31 d2.utils.events]: \u001b[0m eta: 0:09:43  iter: 8499  total_loss: 0.09101  loss_cls: 1.333e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01134  loss_rpn_loc: 0.07987  time: 0.3857  data_time: 0.0085  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:11:39 d2.utils.events]: \u001b[0m eta: 0:09:35  iter: 8519  total_loss: 0.1026  loss_cls: 1.873e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.008194  loss_rpn_loc: 0.08674  time: 0.3857  data_time: 0.0150  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:11:47 d2.utils.events]: \u001b[0m eta: 0:09:27  iter: 8539  total_loss: 0.1045  loss_cls: 2.543e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02036  loss_rpn_loc: 0.07912  time: 0.3857  data_time: 0.0169  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:11:54 d2.utils.events]: \u001b[0m eta: 0:09:20  iter: 8559  total_loss: 0.1227  loss_cls: 2.579e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01553  loss_rpn_loc: 0.1004  time: 0.3857  data_time: 0.0135  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:12:02 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 8579  total_loss: 0.148  loss_cls: 1.682e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02241  loss_rpn_loc: 0.1093  time: 0.3857  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:12:10 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 8599  total_loss: 0.1374  loss_cls: 4.883e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01993  loss_rpn_loc: 0.1178  time: 0.3857  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:12:18 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 8619  total_loss: 0.09188  loss_cls: 2.574e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01869  loss_rpn_loc: 0.07548  time: 0.3857  data_time: 0.0177  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:12:26 d2.utils.events]: \u001b[0m eta: 0:08:50  iter: 8639  total_loss: 0.08596  loss_cls: 2.192e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01528  loss_rpn_loc: 0.0769  time: 0.3857  data_time: 0.0138  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:12:34 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 8659  total_loss: 0.1117  loss_cls: 3.104e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01692  loss_rpn_loc: 0.09531  time: 0.3858  data_time: 0.0150  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:12:41 d2.utils.events]: \u001b[0m eta: 0:08:34  iter: 8679  total_loss: 0.09655  loss_cls: 3.987e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01639  loss_rpn_loc: 0.08806  time: 0.3857  data_time: 0.0092  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:12:49 d2.utils.events]: \u001b[0m eta: 0:08:26  iter: 8699  total_loss: 0.09806  loss_cls: 2.64e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01086  loss_rpn_loc: 0.0827  time: 0.3857  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:12:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:12:50 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:12:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:12:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:12:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0822 s/iter. Eval: 0.0000 s/iter. Total: 0.0836 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:12:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.902053 (0.087537 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:12:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081832 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:12:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 16:12:56 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:13:02 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 8719  total_loss: 0.09779  loss_cls: 1.936e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01544  loss_rpn_loc: 0.08344  time: 0.3858  data_time: 0.0135  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:13:10 d2.utils.events]: \u001b[0m eta: 0:08:10  iter: 8739  total_loss: 0.1007  loss_cls: 3.173e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0158  loss_rpn_loc: 0.08245  time: 0.3857  data_time: 0.0137  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:13:18 d2.utils.events]: \u001b[0m eta: 0:08:02  iter: 8759  total_loss: 0.1005  loss_cls: 2.873e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01208  loss_rpn_loc: 0.08648  time: 0.3857  data_time: 0.0101  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:13:25 d2.utils.events]: \u001b[0m eta: 0:07:55  iter: 8779  total_loss: 0.1053  loss_cls: 4.628e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.08161  time: 0.3857  data_time: 0.0131  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:13:33 d2.utils.events]: \u001b[0m eta: 0:07:47  iter: 8799  total_loss: 0.1189  loss_cls: 2.927e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01609  loss_rpn_loc: 0.09617  time: 0.3857  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:13:41 d2.utils.events]: \u001b[0m eta: 0:07:39  iter: 8819  total_loss: 0.08396  loss_cls: 3.119e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01414  loss_rpn_loc: 0.0666  time: 0.3857  data_time: 0.0253  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:13:49 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 8839  total_loss: 0.08126  loss_cls: 4e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.00606  loss_rpn_loc: 0.07336  time: 0.3857  data_time: 0.0089  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:13:57 d2.utils.events]: \u001b[0m eta: 0:07:23  iter: 8859  total_loss: 0.1119  loss_cls: 3.267e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0137  loss_rpn_loc: 0.09261  time: 0.3857  data_time: 0.0123  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:14:04 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 8879  total_loss: 0.1135  loss_cls: 3.206e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01368  loss_rpn_loc: 0.09985  time: 0.3857  data_time: 0.0090  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:14:12 d2.utils.events]: \u001b[0m eta: 0:07:07  iter: 8899  total_loss: 0.1347  loss_cls: 6.163e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0139  loss_rpn_loc: 0.1223  time: 0.3857  data_time: 0.0137  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:14:20 d2.utils.events]: \u001b[0m eta: 0:06:59  iter: 8919  total_loss: 0.09145  loss_cls: 3.042e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0111  loss_rpn_loc: 0.07797  time: 0.3857  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:14:27 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 8939  total_loss: 0.1094  loss_cls: 2.757e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01475  loss_rpn_loc: 0.08953  time: 0.3857  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:14:35 d2.utils.events]: \u001b[0m eta: 0:06:44  iter: 8959  total_loss: 0.1113  loss_cls: 2.351e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007417  loss_rpn_loc: 0.09556  time: 0.3857  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:14:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:14:41 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:14:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:14:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:14:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0818 s/iter. Eval: 0.0000 s/iter. Total: 0.0832 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:14:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.899681 (0.087494 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:14:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081729 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:14:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 16:14:47 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:14:48 d2.utils.events]: \u001b[0m eta: 0:06:36  iter: 8979  total_loss: 0.09549  loss_cls: 6.597e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009693  loss_rpn_loc: 0.07691  time: 0.3857  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:14:56 d2.utils.events]: \u001b[0m eta: 0:06:29  iter: 8999  total_loss: 0.09305  loss_cls: 1.085e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01149  loss_rpn_loc: 0.07639  time: 0.3857  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:15:04 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 9019  total_loss: 0.1461  loss_cls: 3.211e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01513  loss_rpn_loc: 0.1138  time: 0.3857  data_time: 0.0123  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:15:11 d2.utils.events]: \u001b[0m eta: 0:06:13  iter: 9039  total_loss: 0.08583  loss_cls: 2.708e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.011  loss_rpn_loc: 0.07548  time: 0.3857  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:15:19 d2.utils.events]: \u001b[0m eta: 0:06:06  iter: 9059  total_loss: 0.09286  loss_cls: 2.184e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009451  loss_rpn_loc: 0.08352  time: 0.3857  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:15:27 d2.utils.events]: \u001b[0m eta: 0:05:58  iter: 9079  total_loss: 0.08505  loss_cls: 2.743e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01088  loss_rpn_loc: 0.08004  time: 0.3857  data_time: 0.0103  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:15:35 d2.utils.events]: \u001b[0m eta: 0:05:50  iter: 9099  total_loss: 0.1059  loss_cls: 1.525e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01238  loss_rpn_loc: 0.09552  time: 0.3857  data_time: 0.0133  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:15:43 d2.utils.events]: \u001b[0m eta: 0:05:42  iter: 9119  total_loss: 0.1092  loss_cls: 2.404e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01603  loss_rpn_loc: 0.09147  time: 0.3857  data_time: 0.0169  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:15:50 d2.utils.events]: \u001b[0m eta: 0:05:34  iter: 9139  total_loss: 0.07864  loss_cls: 1.195e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.003752  loss_rpn_loc: 0.07353  time: 0.3857  data_time: 0.0084  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:15:58 d2.utils.events]: \u001b[0m eta: 0:05:26  iter: 9159  total_loss: 0.158  loss_cls: 3.884e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0151  loss_rpn_loc: 0.1216  time: 0.3857  data_time: 0.0146  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:16:06 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 9179  total_loss: 0.0939  loss_cls: 1.923e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01001  loss_rpn_loc: 0.08154  time: 0.3857  data_time: 0.0144  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:16:13 d2.utils.events]: \u001b[0m eta: 0:05:11  iter: 9199  total_loss: 0.1143  loss_cls: 3.413e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02779  loss_rpn_loc: 0.09005  time: 0.3857  data_time: 0.0162  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:16:21 d2.utils.events]: \u001b[0m eta: 0:05:03  iter: 9219  total_loss: 0.1275  loss_cls: 3.621e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01967  loss_rpn_loc: 0.109  time: 0.3857  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:16:29 d2.utils.events]: \u001b[0m eta: 0:04:55  iter: 9239  total_loss: 0.09574  loss_cls: 1.666e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01169  loss_rpn_loc: 0.0808  time: 0.3857  data_time: 0.0096  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:16:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:16:32 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:16:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:16:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:16:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0819 s/iter. Eval: 0.0000 s/iter. Total: 0.0832 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:16:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.892546 (0.087367 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:16:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081782 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:16:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 16:16:37 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:16:42 d2.utils.events]: \u001b[0m eta: 0:04:47  iter: 9259  total_loss: 0.1027  loss_cls: 5.296e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0131  loss_rpn_loc: 0.08813  time: 0.3857  data_time: 0.0088  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:16:50 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 9279  total_loss: 0.1259  loss_cls: 1.739e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01667  loss_rpn_loc: 0.1132  time: 0.3857  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:16:58 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 9299  total_loss: 0.1149  loss_cls: 5.647e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01416  loss_rpn_loc: 0.09984  time: 0.3857  data_time: 0.0146  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:17:06 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 9319  total_loss: 0.1456  loss_cls: 1.773e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02365  loss_rpn_loc: 0.1178  time: 0.3857  data_time: 0.0096  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:17:14 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 9339  total_loss: 0.1114  loss_cls: 2.075e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0139  loss_rpn_loc: 0.0928  time: 0.3857  data_time: 0.0209  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:17:21 d2.utils.events]: \u001b[0m eta: 0:04:09  iter: 9359  total_loss: 0.1098  loss_cls: 2.058e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02432  loss_rpn_loc: 0.09639  time: 0.3858  data_time: 0.0129  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:17:29 d2.utils.events]: \u001b[0m eta: 0:04:01  iter: 9379  total_loss: 0.09306  loss_cls: 2.482e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.006105  loss_rpn_loc: 0.08479  time: 0.3858  data_time: 0.0098  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:17:37 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 9399  total_loss: 0.08515  loss_cls: 1.093e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007414  loss_rpn_loc: 0.07527  time: 0.3857  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:17:44 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 9419  total_loss: 0.08004  loss_cls: 1.403e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.005308  loss_rpn_loc: 0.07172  time: 0.3857  data_time: 0.0085  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:17:52 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 9439  total_loss: 0.1026  loss_cls: 1.211e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01735  loss_rpn_loc: 0.0794  time: 0.3857  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:18:00 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 9459  total_loss: 0.08197  loss_cls: 2.986e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01088  loss_rpn_loc: 0.07429  time: 0.3857  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:18:08 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 9479  total_loss: 0.0818  loss_cls: 9.029e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01859  loss_rpn_loc: 0.07586  time: 0.3857  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:18:15 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 9499  total_loss: 0.1086  loss_cls: 2.716e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02379  loss_rpn_loc: 0.07868  time: 0.3857  data_time: 0.0127  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:18:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:18:23 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:18:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:18:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:18:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0012 s/iter. Inference: 0.0816 s/iter. Eval: 0.0000 s/iter. Total: 0.0828 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:18:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.886291 (0.087255 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:18:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081758 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:18:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 16:18:29 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:18:29 d2.utils.events]: \u001b[0m eta: 0:03:06  iter: 9519  total_loss: 0.1039  loss_cls: 1.879e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0114  loss_rpn_loc: 0.08775  time: 0.3857  data_time: 0.0090  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:18:37 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 9539  total_loss: 0.112  loss_cls: 3.108e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01707  loss_rpn_loc: 0.09489  time: 0.3858  data_time: 0.0183  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:18:45 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 9559  total_loss: 0.1104  loss_cls: 2.14e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01541  loss_rpn_loc: 0.09397  time: 0.3858  data_time: 0.0086  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:18:52 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 9579  total_loss: 0.07113  loss_cls: 2.1e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.008328  loss_rpn_loc: 0.05914  time: 0.3858  data_time: 0.0191  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:19:01 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 9599  total_loss: 0.1297  loss_cls: 2.811e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02136  loss_rpn_loc: 0.1144  time: 0.3858  data_time: 0.0190  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:19:08 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 9619  total_loss: 0.1154  loss_cls: 1.894e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009673  loss_rpn_loc: 0.08784  time: 0.3858  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:19:16 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 9639  total_loss: 0.04748  loss_cls: 1.333e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.002178  loss_rpn_loc: 0.04442  time: 0.3858  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:19:24 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 9659  total_loss: 0.1021  loss_cls: 2.283e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0177  loss_rpn_loc: 0.08406  time: 0.3858  data_time: 0.0137  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:19:31 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 9679  total_loss: 0.1027  loss_cls: 4.4e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01555  loss_rpn_loc: 0.08904  time: 0.3858  data_time: 0.0136  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:19:39 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 9699  total_loss: 0.1027  loss_cls: 2e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01448  loss_rpn_loc: 0.07949  time: 0.3858  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:19:47 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 9719  total_loss: 0.1243  loss_cls: 2.386e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01849  loss_rpn_loc: 0.103  time: 0.3858  data_time: 0.0152  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:19:54 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 9739  total_loss: 0.08361  loss_cls: 1.026e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007096  loss_rpn_loc: 0.07529  time: 0.3858  data_time: 0.0086  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:20:02 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 9759  total_loss: 0.1116  loss_cls: 2.89e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01191  loss_rpn_loc: 0.09792  time: 0.3858  data_time: 0.0120  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:20:09 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 9779  total_loss: 0.131  loss_cls: 3.125e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01598  loss_rpn_loc: 0.1071  time: 0.3857  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:20:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:20:14 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:20:14 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:20:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:20:16 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0819 s/iter. Eval: 0.0000 s/iter. Total: 0.0833 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:20:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.910213 (0.087682 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:20:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081800 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:20:20 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 16:20:20 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:20:23 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 9799  total_loss: 0.1023  loss_cls: 3.161e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01142  loss_rpn_loc: 0.08865  time: 0.3858  data_time: 0.0226  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:20:31 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 9819  total_loss: 0.07454  loss_cls: 1.447e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007095  loss_rpn_loc: 0.0663  time: 0.3858  data_time: 0.0151  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:20:39 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 9839  total_loss: 0.1059  loss_cls: 1.477e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01355  loss_rpn_loc: 0.07994  time: 0.3858  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:20:47 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 9859  total_loss: 0.1096  loss_cls: 2.966e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01974  loss_rpn_loc: 0.085  time: 0.3858  data_time: 0.0147  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:20:55 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 9879  total_loss: 0.1346  loss_cls: 3.751e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01992  loss_rpn_loc: 0.1141  time: 0.3858  data_time: 0.0129  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:21:02 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 9899  total_loss: 0.135  loss_cls: 2.118e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0113  loss_rpn_loc: 0.1138  time: 0.3858  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:21:10 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 9919  total_loss: 0.09152  loss_cls: 1.507e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.00877  loss_rpn_loc: 0.07452  time: 0.3858  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:21:18 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 9939  total_loss: 0.118  loss_cls: 3.477e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01595  loss_rpn_loc: 0.09858  time: 0.3858  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:21:25 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 9959  total_loss: 0.08327  loss_cls: 1.235e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01216  loss_rpn_loc: 0.06862  time: 0.3858  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:21:33 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 9979  total_loss: 0.09235  loss_cls: 2.276e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01491  loss_rpn_loc: 0.07677  time: 0.3858  data_time: 0.0144  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:21:45 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 0.1365  loss_cls: 2.475e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02286  loss_rpn_loc: 0.114  time: 0.3858  data_time: 0.0100  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:21:46 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:04:17 (0.3858 s / it)\n",
      "\u001b[32m[12/27 16:21:46 d2.engine.hooks]: \u001b[0mTotal training time: 1:08:03 (0:03:46 on hooks)\n",
      "\u001b[32m[12/27 16:21:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:21:46 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:21:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:21:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:21:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0012 s/iter. Inference: 0.0815 s/iter. Eval: 0.0000 s/iter. Total: 0.0828 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:21:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.889637 (0.087315 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:21:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081837 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:21:52 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_1 in csv format:\n",
      "\u001b[32m[12/27 16:21:52 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "trainModel(1, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RpbCLclINWiS",
    "outputId": "6a6a12e5-4b26-4ff1-9e69-12a7e028f720"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/2\n",
      "\u001b[32m[12/27 16:21:53 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[12/27 16:21:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[12/27 16:21:53 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/27 16:21:53 d2.data.common]: \u001b[0mSerializing 545 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:21:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.01 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/27 16:21:54 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/detectron2/data/detection_utils.py:433: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/usr/local/lib/python3.7/dist-packages/detectron2/data/detection_utils.py:433: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/27 16:22:02 d2.utils.events]: \u001b[0m eta: 1:04:43  iter: 19  total_loss: 1.319  loss_cls: 0.6673  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.3655  loss_rpn_loc: 0.1734  time: 0.3827  data_time: 0.0465  lr: 2.4976e-05  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:22:10 d2.utils.events]: \u001b[0m eta: 1:03:59  iter: 39  total_loss: 1.15  loss_cls: 0.5846  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.3569  loss_rpn_loc: 0.149  time: 0.3818  data_time: 0.0123  lr: 4.9951e-05  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:22:18 d2.utils.events]: \u001b[0m eta: 1:04:05  iter: 59  total_loss: 0.9317  loss_cls: 0.4033  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.363  loss_rpn_loc: 0.1499  time: 0.3840  data_time: 0.0098  lr: 7.4926e-05  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:22:25 d2.utils.events]: \u001b[0m eta: 1:03:50  iter: 79  total_loss: 0.6813  loss_cls: 0.2562  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.2673  loss_rpn_loc: 0.1413  time: 0.3804  data_time: 0.0110  lr: 9.9901e-05  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:22:33 d2.utils.events]: \u001b[0m eta: 1:03:40  iter: 99  total_loss: 0.4823  loss_cls: 0.1425  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.2407  loss_rpn_loc: 0.1312  time: 0.3800  data_time: 0.0102  lr: 0.00012488  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:22:40 d2.utils.events]: \u001b[0m eta: 1:03:33  iter: 119  total_loss: 0.4129  loss_cls: 0.09662  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.1697  loss_rpn_loc: 0.1327  time: 0.3784  data_time: 0.0108  lr: 0.00014985  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:22:48 d2.utils.events]: \u001b[0m eta: 1:03:34  iter: 139  total_loss: 0.3808  loss_cls: 0.03504  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.1855  loss_rpn_loc: 0.1294  time: 0.3810  data_time: 0.0106  lr: 0.00017483  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:22:56 d2.utils.events]: \u001b[0m eta: 1:03:30  iter: 159  total_loss: 0.3089  loss_cls: 0.03741  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.1325  loss_rpn_loc: 0.1299  time: 0.3819  data_time: 0.0099  lr: 0.0001998  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:23:04 d2.utils.events]: \u001b[0m eta: 1:03:23  iter: 179  total_loss: 0.3045  loss_cls: 0.02203  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.1336  loss_rpn_loc: 0.1335  time: 0.3821  data_time: 0.0126  lr: 0.00022478  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:23:11 d2.utils.events]: \u001b[0m eta: 1:03:11  iter: 199  total_loss: 0.2134  loss_cls: 0.01195  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.1162  time: 0.3830  data_time: 0.0211  lr: 0.00024975  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:23:19 d2.utils.events]: \u001b[0m eta: 1:03:03  iter: 219  total_loss: 0.2209  loss_cls: 0.006249  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.1132  loss_rpn_loc: 0.1134  time: 0.3829  data_time: 0.0114  lr: 0.00027473  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:23:27 d2.utils.events]: \u001b[0m eta: 1:02:51  iter: 239  total_loss: 0.2297  loss_cls: 0.00631  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.09457  loss_rpn_loc: 0.1233  time: 0.3832  data_time: 0.0218  lr: 0.0002997  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:23:35 d2.utils.events]: \u001b[0m eta: 1:02:42  iter: 259  total_loss: 0.2087  loss_cls: 0.005091  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.07284  loss_rpn_loc: 0.119  time: 0.3830  data_time: 0.0101  lr: 0.00032468  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:23:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:23:39 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:23:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:23:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:23:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0012 s/iter. Inference: 0.0812 s/iter. Eval: 0.0000 s/iter. Total: 0.0825 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:23:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.852473 (0.086651 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:23:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081200 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:23:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:23:45 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:23:48 d2.utils.events]: \u001b[0m eta: 1:02:33  iter: 279  total_loss: 0.1712  loss_cls: 0.007016  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.06664  loss_rpn_loc: 0.1043  time: 0.3821  data_time: 0.0105  lr: 0.00034965  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:23:56 d2.utils.events]: \u001b[0m eta: 1:02:26  iter: 299  total_loss: 0.1479  loss_cls: 0.002143  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0659  loss_rpn_loc: 0.09031  time: 0.3827  data_time: 0.0174  lr: 0.00037463  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:24:03 d2.utils.events]: \u001b[0m eta: 1:02:08  iter: 319  total_loss: 0.1744  loss_cls: 0.001482  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.06854  loss_rpn_loc: 0.1126  time: 0.3814  data_time: 0.0091  lr: 0.0003996  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:24:11 d2.utils.events]: \u001b[0m eta: 1:02:04  iter: 339  total_loss: 0.1707  loss_cls: 0.001178  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0434  loss_rpn_loc: 0.1025  time: 0.3817  data_time: 0.0119  lr: 0.00042458  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:24:19 d2.utils.events]: \u001b[0m eta: 1:02:03  iter: 359  total_loss: 0.1655  loss_cls: 0.001951  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.05503  loss_rpn_loc: 0.1028  time: 0.3830  data_time: 0.0212  lr: 0.00044955  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:24:26 d2.utils.events]: \u001b[0m eta: 1:01:56  iter: 379  total_loss: 0.1522  loss_cls: 0.0007588  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04503  loss_rpn_loc: 0.1001  time: 0.3832  data_time: 0.0110  lr: 0.00047453  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:24:34 d2.utils.events]: \u001b[0m eta: 1:01:48  iter: 399  total_loss: 0.1529  loss_cls: 0.0009012  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04652  loss_rpn_loc: 0.1136  time: 0.3826  data_time: 0.0095  lr: 0.0004995  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:24:41 d2.utils.events]: \u001b[0m eta: 1:01:34  iter: 419  total_loss: 0.1234  loss_cls: 0.001614  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04222  loss_rpn_loc: 0.07813  time: 0.3819  data_time: 0.0075  lr: 0.00052448  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:24:49 d2.utils.events]: \u001b[0m eta: 1:01:25  iter: 439  total_loss: 0.1557  loss_cls: 0.0008834  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03957  loss_rpn_loc: 0.1043  time: 0.3816  data_time: 0.0092  lr: 0.00054945  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:24:56 d2.utils.events]: \u001b[0m eta: 1:01:19  iter: 459  total_loss: 0.1634  loss_cls: 0.001118  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04806  loss_rpn_loc: 0.1124  time: 0.3817  data_time: 0.0112  lr: 0.00057443  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:25:04 d2.utils.events]: \u001b[0m eta: 1:01:12  iter: 479  total_loss: 0.1485  loss_cls: 0.0006087  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03241  loss_rpn_loc: 0.1127  time: 0.3818  data_time: 0.0124  lr: 0.0005994  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:25:12 d2.utils.events]: \u001b[0m eta: 1:01:08  iter: 499  total_loss: 0.1899  loss_cls: 0.001524  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.06562  loss_rpn_loc: 0.1243  time: 0.3821  data_time: 0.0131  lr: 0.00062438  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:25:19 d2.utils.events]: \u001b[0m eta: 1:01:00  iter: 519  total_loss: 0.1415  loss_cls: 0.001106  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04748  loss_rpn_loc: 0.1051  time: 0.3817  data_time: 0.0082  lr: 0.00064935  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:25:27 d2.utils.events]: \u001b[0m eta: 1:00:51  iter: 539  total_loss: 0.1753  loss_cls: 0.0009467  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04888  loss_rpn_loc: 0.1088  time: 0.3815  data_time: 0.0102  lr: 0.00067433  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:25:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:25:29 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:25:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:25:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:25:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0011 s/iter. Inference: 0.0810 s/iter. Eval: 0.0000 s/iter. Total: 0.0821 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:25:34 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.843221 (0.086486 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:25:34 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081170 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:25:34 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:25:34 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:25:41 d2.utils.events]: \u001b[0m eta: 1:00:44  iter: 559  total_loss: 0.1567  loss_cls: 0.0008257  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04589  loss_rpn_loc: 0.1037  time: 0.3818  data_time: 0.0166  lr: 0.0006993  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:25:48 d2.utils.events]: \u001b[0m eta: 1:00:35  iter: 579  total_loss: 0.1181  loss_cls: 0.0002702  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03594  loss_rpn_loc: 0.08145  time: 0.3817  data_time: 0.0100  lr: 0.00072428  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:25:56 d2.utils.events]: \u001b[0m eta: 1:00:28  iter: 599  total_loss: 0.1297  loss_cls: 0.0003802  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02442  loss_rpn_loc: 0.09337  time: 0.3817  data_time: 0.0096  lr: 0.00074925  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:26:04 d2.utils.events]: \u001b[0m eta: 1:00:23  iter: 619  total_loss: 0.1617  loss_cls: 0.0005274  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.05171  loss_rpn_loc: 0.113  time: 0.3822  data_time: 0.0139  lr: 0.00077423  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:26:11 d2.utils.events]: \u001b[0m eta: 1:00:15  iter: 639  total_loss: 0.1285  loss_cls: 0.0005165  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03387  loss_rpn_loc: 0.09413  time: 0.3821  data_time: 0.0084  lr: 0.0007992  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:26:19 d2.utils.events]: \u001b[0m eta: 1:00:07  iter: 659  total_loss: 0.1949  loss_cls: 0.0006627  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.05492  loss_rpn_loc: 0.1177  time: 0.3823  data_time: 0.0152  lr: 0.00082418  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:26:27 d2.utils.events]: \u001b[0m eta: 1:00:00  iter: 679  total_loss: 0.1797  loss_cls: 0.0005205  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04647  loss_rpn_loc: 0.1253  time: 0.3823  data_time: 0.0120  lr: 0.00084915  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:26:34 d2.utils.events]: \u001b[0m eta: 0:59:52  iter: 699  total_loss: 0.1504  loss_cls: 0.0003711  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03569  loss_rpn_loc: 0.1084  time: 0.3823  data_time: 0.0116  lr: 0.00087413  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:26:42 d2.utils.events]: \u001b[0m eta: 0:59:45  iter: 719  total_loss: 0.1527  loss_cls: 0.0005928  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04263  loss_rpn_loc: 0.1092  time: 0.3822  data_time: 0.0116  lr: 0.0008991  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:26:50 d2.utils.events]: \u001b[0m eta: 0:59:37  iter: 739  total_loss: 0.1263  loss_cls: 0.0003192  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02692  loss_rpn_loc: 0.0939  time: 0.3821  data_time: 0.0085  lr: 0.00092408  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:26:57 d2.utils.events]: \u001b[0m eta: 0:59:29  iter: 759  total_loss: 0.1217  loss_cls: 0.0004894  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02553  loss_rpn_loc: 0.09546  time: 0.3820  data_time: 0.0100  lr: 0.00094905  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:27:05 d2.utils.events]: \u001b[0m eta: 0:59:21  iter: 779  total_loss: 0.1071  loss_cls: 0.0002785  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02783  loss_rpn_loc: 0.08379  time: 0.3820  data_time: 0.0118  lr: 0.00097403  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:27:12 d2.utils.events]: \u001b[0m eta: 0:59:14  iter: 799  total_loss: 0.1534  loss_cls: 0.0002312  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02879  loss_rpn_loc: 0.106  time: 0.3820  data_time: 0.0163  lr: 0.000999  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:27:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:27:18 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:27:18 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:27:18 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:27:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0813 s/iter. Eval: 0.0000 s/iter. Total: 0.0826 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:27:24 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.871060 (0.086983 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:27:24 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081455 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:27:24 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:27:24 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:27:26 d2.utils.events]: \u001b[0m eta: 0:59:06  iter: 819  total_loss: 0.1089  loss_cls: 0.0004268  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02226  loss_rpn_loc: 0.0892  time: 0.3817  data_time: 0.0081  lr: 0.001024  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:27:33 d2.utils.events]: \u001b[0m eta: 0:58:57  iter: 839  total_loss: 0.1201  loss_cls: 0.0002799  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02659  loss_rpn_loc: 0.08925  time: 0.3813  data_time: 0.0078  lr: 0.001049  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:27:41 d2.utils.events]: \u001b[0m eta: 0:58:50  iter: 859  total_loss: 0.168  loss_cls: 0.0005205  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03627  loss_rpn_loc: 0.1287  time: 0.3814  data_time: 0.0160  lr: 0.0010739  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:27:49 d2.utils.events]: \u001b[0m eta: 0:58:43  iter: 879  total_loss: 0.1699  loss_cls: 0.0003278  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02942  loss_rpn_loc: 0.12  time: 0.3817  data_time: 0.0166  lr: 0.0010989  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:27:56 d2.utils.events]: \u001b[0m eta: 0:58:34  iter: 899  total_loss: 0.1522  loss_cls: 0.000368  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03271  loss_rpn_loc: 0.1171  time: 0.3814  data_time: 0.0109  lr: 0.0011239  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:28:04 d2.utils.events]: \u001b[0m eta: 0:58:27  iter: 919  total_loss: 0.1343  loss_cls: 0.0002029  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02635  loss_rpn_loc: 0.1049  time: 0.3814  data_time: 0.0099  lr: 0.0011489  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:28:11 d2.utils.events]: \u001b[0m eta: 0:58:19  iter: 939  total_loss: 0.1163  loss_cls: 0.0002484  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02277  loss_rpn_loc: 0.09165  time: 0.3815  data_time: 0.0097  lr: 0.0011738  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:28:19 d2.utils.events]: \u001b[0m eta: 0:58:12  iter: 959  total_loss: 0.1421  loss_cls: 0.0002596  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02644  loss_rpn_loc: 0.1037  time: 0.3817  data_time: 0.0145  lr: 0.0011988  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:28:27 d2.utils.events]: \u001b[0m eta: 0:58:06  iter: 979  total_loss: 0.1506  loss_cls: 0.000447  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04274  loss_rpn_loc: 0.1167  time: 0.3823  data_time: 0.0246  lr: 0.0012238  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:28:35 d2.utils.events]: \u001b[0m eta: 0:57:58  iter: 999  total_loss: 0.1048  loss_cls: 0.000237  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0139  loss_rpn_loc: 0.09056  time: 0.3822  data_time: 0.0083  lr: 0.0012488  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:28:43 d2.utils.events]: \u001b[0m eta: 0:57:50  iter: 1019  total_loss: 0.129  loss_cls: 0.0003251  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03232  loss_rpn_loc: 0.08932  time: 0.3824  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:28:51 d2.utils.events]: \u001b[0m eta: 0:57:45  iter: 1039  total_loss: 0.1509  loss_cls: 0.0003052  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04467  loss_rpn_loc: 0.1104  time: 0.3824  data_time: 0.0133  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:28:58 d2.utils.events]: \u001b[0m eta: 0:57:35  iter: 1059  total_loss: 0.108  loss_cls: 0.0001209  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01643  loss_rpn_loc: 0.08409  time: 0.3823  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:29:06 d2.utils.events]: \u001b[0m eta: 0:57:28  iter: 1079  total_loss: 0.1119  loss_cls: 0.0001927  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01549  loss_rpn_loc: 0.08155  time: 0.3822  data_time: 0.0078  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:29:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:29:09 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:29:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:29:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:29:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0813 s/iter. Eval: 0.0000 s/iter. Total: 0.0826 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:29:14 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.849812 (0.086604 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:29:14 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081311 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:29:14 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:29:14 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:29:19 d2.utils.events]: \u001b[0m eta: 0:57:18  iter: 1099  total_loss: 0.09927  loss_cls: 0.000273  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02014  loss_rpn_loc: 0.07989  time: 0.3820  data_time: 0.0074  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:29:27 d2.utils.events]: \u001b[0m eta: 0:57:13  iter: 1119  total_loss: 0.1158  loss_cls: 0.0001939  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02054  loss_rpn_loc: 0.09622  time: 0.3820  data_time: 0.0095  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:29:34 d2.utils.events]: \u001b[0m eta: 0:57:03  iter: 1139  total_loss: 0.1464  loss_cls: 0.0001559  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02315  loss_rpn_loc: 0.113  time: 0.3822  data_time: 0.0096  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:29:42 d2.utils.events]: \u001b[0m eta: 0:56:54  iter: 1159  total_loss: 0.169  loss_cls: 0.0002528  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03157  loss_rpn_loc: 0.1262  time: 0.3822  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:29:50 d2.utils.events]: \u001b[0m eta: 0:56:49  iter: 1179  total_loss: 0.1512  loss_cls: 0.0001167  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02737  loss_rpn_loc: 0.1145  time: 0.3822  data_time: 0.0116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:29:58 d2.utils.events]: \u001b[0m eta: 0:56:42  iter: 1199  total_loss: 0.1337  loss_cls: 0.0001387  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03073  loss_rpn_loc: 0.1087  time: 0.3824  data_time: 0.0144  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:30:05 d2.utils.events]: \u001b[0m eta: 0:56:34  iter: 1219  total_loss: 0.1176  loss_cls: 0.0001087  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02154  loss_rpn_loc: 0.08996  time: 0.3824  data_time: 0.0081  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:30:13 d2.utils.events]: \u001b[0m eta: 0:56:27  iter: 1239  total_loss: 0.1113  loss_cls: 0.0001043  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01986  loss_rpn_loc: 0.0912  time: 0.3823  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:30:21 d2.utils.events]: \u001b[0m eta: 0:56:20  iter: 1259  total_loss: 0.1108  loss_cls: 0.0001325  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02075  loss_rpn_loc: 0.09498  time: 0.3825  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:30:28 d2.utils.events]: \u001b[0m eta: 0:56:13  iter: 1279  total_loss: 0.1597  loss_cls: 0.0001676  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03059  loss_rpn_loc: 0.1172  time: 0.3825  data_time: 0.0092  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:30:36 d2.utils.events]: \u001b[0m eta: 0:56:07  iter: 1299  total_loss: 0.1284  loss_cls: 0.0001297  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02384  loss_rpn_loc: 0.1027  time: 0.3826  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:30:44 d2.utils.events]: \u001b[0m eta: 0:56:03  iter: 1319  total_loss: 0.128  loss_cls: 0.0001438  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02501  loss_rpn_loc: 0.101  time: 0.3825  data_time: 0.0095  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:30:51 d2.utils.events]: \u001b[0m eta: 0:55:53  iter: 1339  total_loss: 0.1213  loss_cls: 0.0001784  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01643  loss_rpn_loc: 0.09988  time: 0.3825  data_time: 0.0150  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:31:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:31:00 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:31:00 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:31:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:31:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0812 s/iter. Eval: 0.0000 s/iter. Total: 0.0826 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:31:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.846379 (0.086542 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:31:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081281 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:31:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:31:05 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:31:05 d2.utils.events]: \u001b[0m eta: 0:55:46  iter: 1359  total_loss: 0.1861  loss_cls: 0.0002087  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04251  loss_rpn_loc: 0.1328  time: 0.3829  data_time: 0.0247  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:31:13 d2.utils.events]: \u001b[0m eta: 0:55:37  iter: 1379  total_loss: 0.1204  loss_cls: 9.219e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02312  loss_rpn_loc: 0.09922  time: 0.3828  data_time: 0.0095  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:31:21 d2.utils.events]: \u001b[0m eta: 0:55:30  iter: 1399  total_loss: 0.1273  loss_cls: 9.869e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02416  loss_rpn_loc: 0.102  time: 0.3828  data_time: 0.0101  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:31:28 d2.utils.events]: \u001b[0m eta: 0:55:22  iter: 1419  total_loss: 0.1634  loss_cls: 0.0001706  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02242  loss_rpn_loc: 0.13  time: 0.3827  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:31:36 d2.utils.events]: \u001b[0m eta: 0:55:16  iter: 1439  total_loss: 0.1189  loss_cls: 0.0001646  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01931  loss_rpn_loc: 0.09313  time: 0.3828  data_time: 0.0136  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:31:44 d2.utils.events]: \u001b[0m eta: 0:55:09  iter: 1459  total_loss: 0.1061  loss_cls: 0.000166  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01766  loss_rpn_loc: 0.08704  time: 0.3828  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:31:51 d2.utils.events]: \u001b[0m eta: 0:55:02  iter: 1479  total_loss: 0.1456  loss_cls: 0.0001103  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03084  loss_rpn_loc: 0.1177  time: 0.3829  data_time: 0.0150  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:31:59 d2.utils.events]: \u001b[0m eta: 0:54:52  iter: 1499  total_loss: 0.1065  loss_cls: 0.0001301  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0279  loss_rpn_loc: 0.08946  time: 0.3829  data_time: 0.0178  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:32:07 d2.utils.events]: \u001b[0m eta: 0:54:45  iter: 1519  total_loss: 0.1587  loss_cls: 0.0001156  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02588  loss_rpn_loc: 0.1327  time: 0.3829  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:32:15 d2.utils.events]: \u001b[0m eta: 0:54:39  iter: 1539  total_loss: 0.1558  loss_cls: 0.0001136  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03198  loss_rpn_loc: 0.1199  time: 0.3830  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:32:22 d2.utils.events]: \u001b[0m eta: 0:54:30  iter: 1559  total_loss: 0.1107  loss_cls: 0.0001568  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02255  loss_rpn_loc: 0.08445  time: 0.3830  data_time: 0.0125  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:32:30 d2.utils.events]: \u001b[0m eta: 0:54:23  iter: 1579  total_loss: 0.14  loss_cls: 0.0001691  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03818  loss_rpn_loc: 0.1049  time: 0.3831  data_time: 0.0129  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:32:38 d2.utils.events]: \u001b[0m eta: 0:54:16  iter: 1599  total_loss: 0.1315  loss_cls: 0.000193  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03197  loss_rpn_loc: 0.09595  time: 0.3831  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:32:45 d2.utils.events]: \u001b[0m eta: 0:54:07  iter: 1619  total_loss: 0.1214  loss_cls: 0.0001353  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02237  loss_rpn_loc: 0.09426  time: 0.3831  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:32:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:32:50 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:32:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:32:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:32:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0813 s/iter. Eval: 0.0000 s/iter. Total: 0.0826 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:32:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.895427 (0.087418 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:32:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081359 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:32:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:32:56 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:32:59 d2.utils.events]: \u001b[0m eta: 0:54:00  iter: 1639  total_loss: 0.106  loss_cls: 8.751e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01951  loss_rpn_loc: 0.08457  time: 0.3832  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:33:07 d2.utils.events]: \u001b[0m eta: 0:53:53  iter: 1659  total_loss: 0.1179  loss_cls: 7.206e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02886  loss_rpn_loc: 0.08915  time: 0.3832  data_time: 0.0099  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:33:14 d2.utils.events]: \u001b[0m eta: 0:53:44  iter: 1679  total_loss: 0.1022  loss_cls: 0.0001008  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02111  loss_rpn_loc: 0.08073  time: 0.3831  data_time: 0.0128  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:33:22 d2.utils.events]: \u001b[0m eta: 0:53:37  iter: 1699  total_loss: 0.1807  loss_cls: 5.996e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.04143  loss_rpn_loc: 0.129  time: 0.3832  data_time: 0.0097  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:33:30 d2.utils.events]: \u001b[0m eta: 0:53:30  iter: 1719  total_loss: 0.1894  loss_cls: 0.0001103  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03568  loss_rpn_loc: 0.1455  time: 0.3835  data_time: 0.0216  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:33:38 d2.utils.events]: \u001b[0m eta: 0:53:22  iter: 1739  total_loss: 0.1161  loss_cls: 0.0001108  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01909  loss_rpn_loc: 0.1  time: 0.3834  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:33:45 d2.utils.events]: \u001b[0m eta: 0:53:17  iter: 1759  total_loss: 0.1517  loss_cls: 0.0001429  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03258  loss_rpn_loc: 0.1129  time: 0.3834  data_time: 0.0148  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:33:53 d2.utils.events]: \u001b[0m eta: 0:53:09  iter: 1779  total_loss: 0.1431  loss_cls: 5.423e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02876  loss_rpn_loc: 0.1133  time: 0.3833  data_time: 0.0132  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:34:01 d2.utils.events]: \u001b[0m eta: 0:53:02  iter: 1799  total_loss: 0.1087  loss_cls: 5.115e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01492  loss_rpn_loc: 0.08342  time: 0.3834  data_time: 0.0087  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:34:09 d2.utils.events]: \u001b[0m eta: 0:52:56  iter: 1819  total_loss: 0.1472  loss_cls: 0.0001663  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02717  loss_rpn_loc: 0.1066  time: 0.3836  data_time: 0.0164  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:34:17 d2.utils.events]: \u001b[0m eta: 0:52:52  iter: 1839  total_loss: 0.08651  loss_cls: 4.47e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.008202  loss_rpn_loc: 0.07309  time: 0.3836  data_time: 0.0096  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:34:24 d2.utils.events]: \u001b[0m eta: 0:52:44  iter: 1859  total_loss: 0.1771  loss_cls: 0.0001474  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03101  loss_rpn_loc: 0.1367  time: 0.3835  data_time: 0.0143  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:34:32 d2.utils.events]: \u001b[0m eta: 0:52:36  iter: 1879  total_loss: 0.1635  loss_cls: 8.077e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03113  loss_rpn_loc: 0.1231  time: 0.3836  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:34:40 d2.utils.events]: \u001b[0m eta: 0:52:29  iter: 1899  total_loss: 0.09325  loss_cls: 6.885e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01882  loss_rpn_loc: 0.07665  time: 0.3838  data_time: 0.0350  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:34:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:34:42 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:34:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:34:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:34:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0012 s/iter. Inference: 0.0809 s/iter. Eval: 0.0000 s/iter. Total: 0.0821 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:34:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.840344 (0.086435 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:34:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081341 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:34:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:34:47 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:34:53 d2.utils.events]: \u001b[0m eta: 0:52:20  iter: 1919  total_loss: 0.1068  loss_cls: 9.981e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01698  loss_rpn_loc: 0.08689  time: 0.3837  data_time: 0.0095  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:35:01 d2.utils.events]: \u001b[0m eta: 0:52:14  iter: 1939  total_loss: 0.1315  loss_cls: 0.0001531  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02408  loss_rpn_loc: 0.09989  time: 0.3838  data_time: 0.0147  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:35:09 d2.utils.events]: \u001b[0m eta: 0:52:06  iter: 1959  total_loss: 0.1268  loss_cls: 0.0001646  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02526  loss_rpn_loc: 0.1057  time: 0.3838  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:35:17 d2.utils.events]: \u001b[0m eta: 0:51:58  iter: 1979  total_loss: 0.1364  loss_cls: 7.589e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02573  loss_rpn_loc: 0.1104  time: 0.3839  data_time: 0.0144  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:35:24 d2.utils.events]: \u001b[0m eta: 0:51:51  iter: 1999  total_loss: 0.1085  loss_cls: 6.77e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01707  loss_rpn_loc: 0.0934  time: 0.3839  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:35:32 d2.utils.events]: \u001b[0m eta: 0:51:43  iter: 2019  total_loss: 0.124  loss_cls: 8.184e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02182  loss_rpn_loc: 0.09694  time: 0.3840  data_time: 0.0232  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:35:40 d2.utils.events]: \u001b[0m eta: 0:51:34  iter: 2039  total_loss: 0.1462  loss_cls: 6.034e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0256  loss_rpn_loc: 0.1125  time: 0.3840  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:35:48 d2.utils.events]: \u001b[0m eta: 0:51:28  iter: 2059  total_loss: 0.1017  loss_cls: 7.553e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007552  loss_rpn_loc: 0.09053  time: 0.3842  data_time: 0.0145  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:35:56 d2.utils.events]: \u001b[0m eta: 0:51:27  iter: 2079  total_loss: 0.1475  loss_cls: 0.0001236  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02011  loss_rpn_loc: 0.1201  time: 0.3843  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:36:03 d2.utils.events]: \u001b[0m eta: 0:51:20  iter: 2099  total_loss: 0.1223  loss_cls: 0.000109  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02583  loss_rpn_loc: 0.0993  time: 0.3842  data_time: 0.0127  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:36:11 d2.utils.events]: \u001b[0m eta: 0:51:06  iter: 2119  total_loss: 0.1334  loss_cls: 9.88e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0179  loss_rpn_loc: 0.1054  time: 0.3841  data_time: 0.0093  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:36:19 d2.utils.events]: \u001b[0m eta: 0:51:03  iter: 2139  total_loss: 0.09843  loss_cls: 9.479e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01748  loss_rpn_loc: 0.08714  time: 0.3841  data_time: 0.0099  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:36:26 d2.utils.events]: \u001b[0m eta: 0:50:56  iter: 2159  total_loss: 0.1056  loss_cls: 4.024e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01448  loss_rpn_loc: 0.08753  time: 0.3840  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:36:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:36:32 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:36:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:36:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:36:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0012 s/iter. Inference: 0.0812 s/iter. Eval: 0.0000 s/iter. Total: 0.0825 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:36:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.838877 (0.086409 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:36:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081286 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:36:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:36:38 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:36:39 d2.utils.events]: \u001b[0m eta: 0:50:42  iter: 2179  total_loss: 0.1304  loss_cls: 8.633e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02418  loss_rpn_loc: 0.09928  time: 0.3839  data_time: 0.0100  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:36:47 d2.utils.events]: \u001b[0m eta: 0:50:33  iter: 2199  total_loss: 0.1269  loss_cls: 0.0001645  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01926  loss_rpn_loc: 0.1061  time: 0.3839  data_time: 0.0192  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:36:55 d2.utils.events]: \u001b[0m eta: 0:50:25  iter: 2219  total_loss: 0.1201  loss_cls: 0.0001286  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01479  loss_rpn_loc: 0.1062  time: 0.3839  data_time: 0.0123  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:37:02 d2.utils.events]: \u001b[0m eta: 0:50:18  iter: 2239  total_loss: 0.1197  loss_cls: 9.44e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01838  loss_rpn_loc: 0.09322  time: 0.3839  data_time: 0.0120  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:37:10 d2.utils.events]: \u001b[0m eta: 0:50:08  iter: 2259  total_loss: 0.1391  loss_cls: 0.0002732  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03005  loss_rpn_loc: 0.1073  time: 0.3838  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:37:18 d2.utils.events]: \u001b[0m eta: 0:50:01  iter: 2279  total_loss: 0.1117  loss_cls: 0.0001109  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02012  loss_rpn_loc: 0.09744  time: 0.3839  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:37:25 d2.utils.events]: \u001b[0m eta: 0:49:52  iter: 2299  total_loss: 0.1115  loss_cls: 9.088e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02509  loss_rpn_loc: 0.08972  time: 0.3838  data_time: 0.0155  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:37:33 d2.utils.events]: \u001b[0m eta: 0:49:43  iter: 2319  total_loss: 0.1293  loss_cls: 6.404e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01419  loss_rpn_loc: 0.0969  time: 0.3837  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:37:40 d2.utils.events]: \u001b[0m eta: 0:49:35  iter: 2339  total_loss: 0.1229  loss_cls: 4.747e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0184  loss_rpn_loc: 0.1016  time: 0.3836  data_time: 0.0099  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:37:47 d2.utils.events]: \u001b[0m eta: 0:49:25  iter: 2359  total_loss: 0.09138  loss_cls: 8.475e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01821  loss_rpn_loc: 0.06825  time: 0.3834  data_time: 0.0077  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:37:55 d2.utils.events]: \u001b[0m eta: 0:49:19  iter: 2379  total_loss: 0.1224  loss_cls: 6.559e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02435  loss_rpn_loc: 0.1001  time: 0.3835  data_time: 0.0141  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:38:03 d2.utils.events]: \u001b[0m eta: 0:49:13  iter: 2399  total_loss: 0.1188  loss_cls: 7.783e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02495  loss_rpn_loc: 0.09998  time: 0.3835  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:38:11 d2.utils.events]: \u001b[0m eta: 0:49:06  iter: 2419  total_loss: 0.101  loss_cls: 7.288e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02255  loss_rpn_loc: 0.07986  time: 0.3835  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:38:18 d2.utils.events]: \u001b[0m eta: 0:48:57  iter: 2439  total_loss: 0.1388  loss_cls: 5.689e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02251  loss_rpn_loc: 0.111  time: 0.3835  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:38:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:38:21 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:38:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:38:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:38:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0818 s/iter. Eval: 0.0000 s/iter. Total: 0.0833 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:38:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.841710 (0.086459 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:38:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081295 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:38:27 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:38:27 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:38:32 d2.utils.events]: \u001b[0m eta: 0:48:48  iter: 2459  total_loss: 0.1217  loss_cls: 6.316e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02741  loss_rpn_loc: 0.1066  time: 0.3834  data_time: 0.0120  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:38:40 d2.utils.events]: \u001b[0m eta: 0:48:41  iter: 2479  total_loss: 0.176  loss_cls: 5.37e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02523  loss_rpn_loc: 0.1484  time: 0.3835  data_time: 0.0131  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:38:47 d2.utils.events]: \u001b[0m eta: 0:48:34  iter: 2499  total_loss: 0.1738  loss_cls: 4.938e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03376  loss_rpn_loc: 0.1323  time: 0.3835  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:38:55 d2.utils.events]: \u001b[0m eta: 0:48:25  iter: 2519  total_loss: 0.1049  loss_cls: 7.308e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01273  loss_rpn_loc: 0.08954  time: 0.3834  data_time: 0.0093  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:39:02 d2.utils.events]: \u001b[0m eta: 0:48:15  iter: 2539  total_loss: 0.12  loss_cls: 8.007e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02409  loss_rpn_loc: 0.1025  time: 0.3834  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:39:10 d2.utils.events]: \u001b[0m eta: 0:48:09  iter: 2559  total_loss: 0.1464  loss_cls: 6.972e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02565  loss_rpn_loc: 0.1191  time: 0.3834  data_time: 0.0134  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:39:18 d2.utils.events]: \u001b[0m eta: 0:48:00  iter: 2579  total_loss: 0.0893  loss_cls: 5.178e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01676  loss_rpn_loc: 0.07319  time: 0.3834  data_time: 0.0088  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:39:25 d2.utils.events]: \u001b[0m eta: 0:47:52  iter: 2599  total_loss: 0.102  loss_cls: 7.958e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01912  loss_rpn_loc: 0.07218  time: 0.3834  data_time: 0.0108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:39:33 d2.utils.events]: \u001b[0m eta: 0:47:44  iter: 2619  total_loss: 0.112  loss_cls: 7.105e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01669  loss_rpn_loc: 0.08597  time: 0.3834  data_time: 0.0110  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:39:41 d2.utils.events]: \u001b[0m eta: 0:47:36  iter: 2639  total_loss: 0.1311  loss_cls: 4.628e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01633  loss_rpn_loc: 0.1019  time: 0.3834  data_time: 0.0138  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:39:49 d2.utils.events]: \u001b[0m eta: 0:47:29  iter: 2659  total_loss: 0.1391  loss_cls: 7.065e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02761  loss_rpn_loc: 0.09229  time: 0.3836  data_time: 0.0330  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:39:57 d2.utils.events]: \u001b[0m eta: 0:47:22  iter: 2679  total_loss: 0.1407  loss_cls: 0.0001096  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02677  loss_rpn_loc: 0.1169  time: 0.3837  data_time: 0.0227  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:40:05 d2.utils.events]: \u001b[0m eta: 0:47:13  iter: 2699  total_loss: 0.1171  loss_cls: 5.658e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02204  loss_rpn_loc: 0.09895  time: 0.3837  data_time: 0.0127  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:40:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:40:12 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:40:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:40:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:40:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0012 s/iter. Inference: 0.0814 s/iter. Eval: 0.0000 s/iter. Total: 0.0826 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:40:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.856933 (0.086731 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:40:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081453 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:40:18 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:40:18 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:40:18 d2.utils.events]: \u001b[0m eta: 0:47:05  iter: 2719  total_loss: 0.1073  loss_cls: 3.532e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02055  loss_rpn_loc: 0.08677  time: 0.3837  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:40:26 d2.utils.events]: \u001b[0m eta: 0:46:57  iter: 2739  total_loss: 0.1069  loss_cls: 4.504e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0191  loss_rpn_loc: 0.08513  time: 0.3837  data_time: 0.0093  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:40:33 d2.utils.events]: \u001b[0m eta: 0:46:50  iter: 2759  total_loss: 0.1005  loss_cls: 7.994e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0259  loss_rpn_loc: 0.0819  time: 0.3837  data_time: 0.0093  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:40:41 d2.utils.events]: \u001b[0m eta: 0:46:42  iter: 2779  total_loss: 0.1349  loss_cls: 9.463e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0247  loss_rpn_loc: 0.09802  time: 0.3838  data_time: 0.0225  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:40:49 d2.utils.events]: \u001b[0m eta: 0:46:34  iter: 2799  total_loss: 0.1072  loss_cls: 6.267e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02271  loss_rpn_loc: 0.08012  time: 0.3838  data_time: 0.0146  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:40:57 d2.utils.events]: \u001b[0m eta: 0:46:23  iter: 2819  total_loss: 0.09831  loss_cls: 8.56e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01931  loss_rpn_loc: 0.08262  time: 0.3838  data_time: 0.0096  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:41:05 d2.utils.events]: \u001b[0m eta: 0:46:15  iter: 2839  total_loss: 0.1082  loss_cls: 9.85e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01708  loss_rpn_loc: 0.09634  time: 0.3838  data_time: 0.0138  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:41:12 d2.utils.events]: \u001b[0m eta: 0:46:08  iter: 2859  total_loss: 0.1333  loss_cls: 5.858e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01931  loss_rpn_loc: 0.1181  time: 0.3838  data_time: 0.0110  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:41:20 d2.utils.events]: \u001b[0m eta: 0:46:00  iter: 2879  total_loss: 0.1266  loss_cls: 7.953e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02075  loss_rpn_loc: 0.1046  time: 0.3838  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:41:28 d2.utils.events]: \u001b[0m eta: 0:45:52  iter: 2899  total_loss: 0.09429  loss_cls: 7.493e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.013  loss_rpn_loc: 0.08352  time: 0.3838  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:41:35 d2.utils.events]: \u001b[0m eta: 0:45:44  iter: 2919  total_loss: 0.1298  loss_cls: 6.289e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02519  loss_rpn_loc: 0.1082  time: 0.3838  data_time: 0.0116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:41:43 d2.utils.events]: \u001b[0m eta: 0:45:36  iter: 2939  total_loss: 0.07921  loss_cls: 4.909e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01606  loss_rpn_loc: 0.06912  time: 0.3838  data_time: 0.0099  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:41:51 d2.utils.events]: \u001b[0m eta: 0:45:29  iter: 2959  total_loss: 0.09887  loss_cls: 6.384e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0174  loss_rpn_loc: 0.08671  time: 0.3839  data_time: 0.0170  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:41:58 d2.utils.events]: \u001b[0m eta: 0:45:19  iter: 2979  total_loss: 0.1333  loss_cls: 5.446e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02063  loss_rpn_loc: 0.1124  time: 0.3838  data_time: 0.0149  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:42:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:42:03 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:42:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:42:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:42:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0811 s/iter. Eval: 0.0000 s/iter. Total: 0.0825 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:42:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.840512 (0.086438 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:42:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081324 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:42:09 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:42:09 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:42:12 d2.utils.events]: \u001b[0m eta: 0:45:14  iter: 2999  total_loss: 0.1526  loss_cls: 8.855e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01975  loss_rpn_loc: 0.1288  time: 0.3839  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:42:19 d2.utils.events]: \u001b[0m eta: 0:45:05  iter: 3019  total_loss: 0.124  loss_cls: 6.906e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02659  loss_rpn_loc: 0.1073  time: 0.3838  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:42:27 d2.utils.events]: \u001b[0m eta: 0:44:57  iter: 3039  total_loss: 0.1082  loss_cls: 2.852e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01333  loss_rpn_loc: 0.09834  time: 0.3838  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:42:35 d2.utils.events]: \u001b[0m eta: 0:44:48  iter: 3059  total_loss: 0.0972  loss_cls: 2.706e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01004  loss_rpn_loc: 0.07336  time: 0.3838  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:42:43 d2.utils.events]: \u001b[0m eta: 0:44:39  iter: 3079  total_loss: 0.1213  loss_cls: 5.058e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01704  loss_rpn_loc: 0.1039  time: 0.3838  data_time: 0.0129  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:42:50 d2.utils.events]: \u001b[0m eta: 0:44:31  iter: 3099  total_loss: 0.08948  loss_cls: 5.207e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009763  loss_rpn_loc: 0.08061  time: 0.3838  data_time: 0.0128  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:42:58 d2.utils.events]: \u001b[0m eta: 0:44:24  iter: 3119  total_loss: 0.1412  loss_cls: 5.256e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02929  loss_rpn_loc: 0.1171  time: 0.3839  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:43:06 d2.utils.events]: \u001b[0m eta: 0:44:17  iter: 3139  total_loss: 0.1368  loss_cls: 4.306e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0343  loss_rpn_loc: 0.09228  time: 0.3839  data_time: 0.0122  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:43:13 d2.utils.events]: \u001b[0m eta: 0:44:08  iter: 3159  total_loss: 0.08986  loss_cls: 3.849e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01231  loss_rpn_loc: 0.07741  time: 0.3838  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:43:20 d2.utils.events]: \u001b[0m eta: 0:44:00  iter: 3179  total_loss: 0.1221  loss_cls: 3.164e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01745  loss_rpn_loc: 0.1004  time: 0.3837  data_time: 0.0082  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:43:28 d2.utils.events]: \u001b[0m eta: 0:43:53  iter: 3199  total_loss: 0.1277  loss_cls: 4.906e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02568  loss_rpn_loc: 0.09724  time: 0.3837  data_time: 0.0103  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:43:36 d2.utils.events]: \u001b[0m eta: 0:43:46  iter: 3219  total_loss: 0.1718  loss_cls: 7.625e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02356  loss_rpn_loc: 0.128  time: 0.3838  data_time: 0.0146  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:43:44 d2.utils.events]: \u001b[0m eta: 0:43:38  iter: 3239  total_loss: 0.09441  loss_cls: 8.541e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01309  loss_rpn_loc: 0.08217  time: 0.3837  data_time: 0.0151  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:43:51 d2.utils.events]: \u001b[0m eta: 0:43:29  iter: 3259  total_loss: 0.1437  loss_cls: 8.136e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02524  loss_rpn_loc: 0.1148  time: 0.3836  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:43:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:43:53 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:43:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:43:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:43:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0012 s/iter. Inference: 0.0823 s/iter. Eval: 0.0000 s/iter. Total: 0.0835 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:43:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.872754 (0.087013 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:43:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081654 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:43:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:43:58 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:44:05 d2.utils.events]: \u001b[0m eta: 0:43:22  iter: 3279  total_loss: 0.1296  loss_cls: 9.258e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02253  loss_rpn_loc: 0.09316  time: 0.3837  data_time: 0.0221  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:44:13 d2.utils.events]: \u001b[0m eta: 0:43:15  iter: 3299  total_loss: 0.1077  loss_cls: 5.59e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01136  loss_rpn_loc: 0.08673  time: 0.3838  data_time: 0.0142  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:44:20 d2.utils.events]: \u001b[0m eta: 0:43:09  iter: 3319  total_loss: 0.1316  loss_cls: 7.399e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01878  loss_rpn_loc: 0.1212  time: 0.3838  data_time: 0.0144  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:44:28 d2.utils.events]: \u001b[0m eta: 0:43:02  iter: 3339  total_loss: 0.07833  loss_cls: 3.798e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0107  loss_rpn_loc: 0.06488  time: 0.3837  data_time: 0.0117  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:44:35 d2.utils.events]: \u001b[0m eta: 0:42:54  iter: 3359  total_loss: 0.08965  loss_cls: 7.126e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.008835  loss_rpn_loc: 0.0785  time: 0.3837  data_time: 0.0082  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:44:43 d2.utils.events]: \u001b[0m eta: 0:42:45  iter: 3379  total_loss: 0.1028  loss_cls: 9.496e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02017  loss_rpn_loc: 0.08802  time: 0.3836  data_time: 0.0110  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:44:50 d2.utils.events]: \u001b[0m eta: 0:42:36  iter: 3399  total_loss: 0.1428  loss_cls: 6.177e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.013  loss_rpn_loc: 0.117  time: 0.3836  data_time: 0.0098  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:44:58 d2.utils.events]: \u001b[0m eta: 0:42:28  iter: 3419  total_loss: 0.1708  loss_cls: 0.0001043  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03216  loss_rpn_loc: 0.1304  time: 0.3836  data_time: 0.0133  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:45:06 d2.utils.events]: \u001b[0m eta: 0:42:22  iter: 3439  total_loss: 0.1748  loss_cls: 6.26e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03508  loss_rpn_loc: 0.1276  time: 0.3838  data_time: 0.0278  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:45:14 d2.utils.events]: \u001b[0m eta: 0:42:15  iter: 3459  total_loss: 0.1072  loss_cls: 6.694e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01401  loss_rpn_loc: 0.09302  time: 0.3837  data_time: 0.0086  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:45:21 d2.utils.events]: \u001b[0m eta: 0:42:04  iter: 3479  total_loss: 0.1019  loss_cls: 3.253e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01539  loss_rpn_loc: 0.08671  time: 0.3836  data_time: 0.0120  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:45:29 d2.utils.events]: \u001b[0m eta: 0:41:57  iter: 3499  total_loss: 0.1284  loss_cls: 5.17e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0191  loss_rpn_loc: 0.1003  time: 0.3836  data_time: 0.0100  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:45:37 d2.utils.events]: \u001b[0m eta: 0:41:51  iter: 3519  total_loss: 0.1329  loss_cls: 7.084e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03359  loss_rpn_loc: 0.112  time: 0.3836  data_time: 0.0141  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:45:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:45:43 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:45:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:45:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:45:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0012 s/iter. Inference: 0.0812 s/iter. Eval: 0.0000 s/iter. Total: 0.0825 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:45:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.846219 (0.086540 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:45:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081333 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:45:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:45:49 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:45:50 d2.utils.events]: \u001b[0m eta: 0:41:43  iter: 3539  total_loss: 0.1387  loss_cls: 3.735e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01733  loss_rpn_loc: 0.1139  time: 0.3836  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:45:58 d2.utils.events]: \u001b[0m eta: 0:41:35  iter: 3559  total_loss: 0.1055  loss_cls: 5.379e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01358  loss_rpn_loc: 0.09196  time: 0.3836  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:46:06 d2.utils.events]: \u001b[0m eta: 0:41:28  iter: 3579  total_loss: 0.112  loss_cls: 5.588e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01794  loss_rpn_loc: 0.09769  time: 0.3837  data_time: 0.0103  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:46:13 d2.utils.events]: \u001b[0m eta: 0:41:21  iter: 3599  total_loss: 0.125  loss_cls: 7.364e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02336  loss_rpn_loc: 0.1042  time: 0.3837  data_time: 0.0125  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:46:21 d2.utils.events]: \u001b[0m eta: 0:41:13  iter: 3619  total_loss: 0.1379  loss_cls: 3.822e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02105  loss_rpn_loc: 0.1147  time: 0.3837  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:46:29 d2.utils.events]: \u001b[0m eta: 0:41:05  iter: 3639  total_loss: 0.09544  loss_cls: 4.828e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.006894  loss_rpn_loc: 0.08848  time: 0.3837  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:46:36 d2.utils.events]: \u001b[0m eta: 0:40:56  iter: 3659  total_loss: 0.1268  loss_cls: 5.333e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01412  loss_rpn_loc: 0.09923  time: 0.3836  data_time: 0.0090  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:46:44 d2.utils.events]: \u001b[0m eta: 0:40:48  iter: 3679  total_loss: 0.1218  loss_cls: 5.703e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02854  loss_rpn_loc: 0.09194  time: 0.3836  data_time: 0.0116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:46:51 d2.utils.events]: \u001b[0m eta: 0:40:41  iter: 3699  total_loss: 0.1575  loss_cls: 6.556e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02099  loss_rpn_loc: 0.1342  time: 0.3836  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:46:59 d2.utils.events]: \u001b[0m eta: 0:40:34  iter: 3719  total_loss: 0.1388  loss_cls: 3.907e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02585  loss_rpn_loc: 0.1178  time: 0.3836  data_time: 0.0138  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:47:07 d2.utils.events]: \u001b[0m eta: 0:40:27  iter: 3739  total_loss: 0.1039  loss_cls: 4.158e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02206  loss_rpn_loc: 0.07915  time: 0.3836  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:47:15 d2.utils.events]: \u001b[0m eta: 0:40:19  iter: 3759  total_loss: 0.07764  loss_cls: 1.776e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01015  loss_rpn_loc: 0.06692  time: 0.3836  data_time: 0.0097  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:47:22 d2.utils.events]: \u001b[0m eta: 0:40:11  iter: 3779  total_loss: 0.1041  loss_cls: 4.066e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01467  loss_rpn_loc: 0.08475  time: 0.3836  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:47:30 d2.utils.events]: \u001b[0m eta: 0:40:04  iter: 3799  total_loss: 0.1332  loss_cls: 5.084e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01826  loss_rpn_loc: 0.1017  time: 0.3837  data_time: 0.0119  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:47:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:47:33 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:47:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:47:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:47:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0814 s/iter. Eval: 0.0000 s/iter. Total: 0.0828 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:47:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.850872 (0.086623 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:47:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081446 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:47:39 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:47:39 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:47:43 d2.utils.events]: \u001b[0m eta: 0:39:56  iter: 3819  total_loss: 0.09261  loss_cls: 3.575e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01133  loss_rpn_loc: 0.07715  time: 0.3836  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:47:51 d2.utils.events]: \u001b[0m eta: 0:39:49  iter: 3839  total_loss: 0.1144  loss_cls: 4.784e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01248  loss_rpn_loc: 0.09352  time: 0.3837  data_time: 0.0147  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:47:59 d2.utils.events]: \u001b[0m eta: 0:39:44  iter: 3859  total_loss: 0.1533  loss_cls: 5.249e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02264  loss_rpn_loc: 0.1258  time: 0.3837  data_time: 0.0153  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:48:07 d2.utils.events]: \u001b[0m eta: 0:39:36  iter: 3879  total_loss: 0.1116  loss_cls: 4.331e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01824  loss_rpn_loc: 0.09123  time: 0.3837  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:48:15 d2.utils.events]: \u001b[0m eta: 0:39:30  iter: 3899  total_loss: 0.1066  loss_cls: 4.922e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0118  loss_rpn_loc: 0.09396  time: 0.3839  data_time: 0.0316  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:48:23 d2.utils.events]: \u001b[0m eta: 0:39:23  iter: 3919  total_loss: 0.1124  loss_cls: 4.967e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02018  loss_rpn_loc: 0.09111  time: 0.3838  data_time: 0.0167  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:48:30 d2.utils.events]: \u001b[0m eta: 0:39:14  iter: 3939  total_loss: 0.1331  loss_cls: 4.401e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03109  loss_rpn_loc: 0.1121  time: 0.3838  data_time: 0.0131  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:48:38 d2.utils.events]: \u001b[0m eta: 0:39:06  iter: 3959  total_loss: 0.1242  loss_cls: 4.626e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01493  loss_rpn_loc: 0.1099  time: 0.3839  data_time: 0.0136  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:48:46 d2.utils.events]: \u001b[0m eta: 0:38:59  iter: 3979  total_loss: 0.09971  loss_cls: 2.614e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01723  loss_rpn_loc: 0.08357  time: 0.3838  data_time: 0.0087  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:48:54 d2.utils.events]: \u001b[0m eta: 0:38:51  iter: 3999  total_loss: 0.1082  loss_cls: 4.597e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01449  loss_rpn_loc: 0.09572  time: 0.3839  data_time: 0.0128  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:49:01 d2.utils.events]: \u001b[0m eta: 0:38:44  iter: 4019  total_loss: 0.09751  loss_cls: 6.927e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01652  loss_rpn_loc: 0.06961  time: 0.3839  data_time: 0.0087  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:49:09 d2.utils.events]: \u001b[0m eta: 0:38:38  iter: 4039  total_loss: 0.087  loss_cls: 6.28e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01116  loss_rpn_loc: 0.0762  time: 0.3839  data_time: 0.0099  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:49:17 d2.utils.events]: \u001b[0m eta: 0:38:29  iter: 4059  total_loss: 0.07306  loss_cls: 3.36e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009783  loss_rpn_loc: 0.06954  time: 0.3839  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:49:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:49:25 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:49:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:49:25 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:49:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0012 s/iter. Inference: 0.0815 s/iter. Eval: 0.0000 s/iter. Total: 0.0827 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:49:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.881148 (0.087163 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:49:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081523 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:49:30 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:49:30 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:49:30 d2.utils.events]: \u001b[0m eta: 0:38:23  iter: 4079  total_loss: 0.1543  loss_cls: 6.531e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02697  loss_rpn_loc: 0.1198  time: 0.3840  data_time: 0.0212  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:49:38 d2.utils.events]: \u001b[0m eta: 0:38:15  iter: 4099  total_loss: 0.127  loss_cls: 9.507e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01607  loss_rpn_loc: 0.1108  time: 0.3840  data_time: 0.0171  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:49:46 d2.utils.events]: \u001b[0m eta: 0:38:06  iter: 4119  total_loss: 0.1163  loss_cls: 5.578e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0191  loss_rpn_loc: 0.0979  time: 0.3840  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:49:54 d2.utils.events]: \u001b[0m eta: 0:37:59  iter: 4139  total_loss: 0.1123  loss_cls: 7.284e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0229  loss_rpn_loc: 0.08606  time: 0.3841  data_time: 0.0217  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:50:02 d2.utils.events]: \u001b[0m eta: 0:37:52  iter: 4159  total_loss: 0.1303  loss_cls: 2.955e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01475  loss_rpn_loc: 0.1034  time: 0.3841  data_time: 0.0151  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:50:09 d2.utils.events]: \u001b[0m eta: 0:37:46  iter: 4179  total_loss: 0.09487  loss_cls: 3.069e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01533  loss_rpn_loc: 0.0772  time: 0.3841  data_time: 0.0116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:50:17 d2.utils.events]: \u001b[0m eta: 0:37:36  iter: 4199  total_loss: 0.1032  loss_cls: 2.653e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01718  loss_rpn_loc: 0.08518  time: 0.3841  data_time: 0.0090  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:50:24 d2.utils.events]: \u001b[0m eta: 0:37:27  iter: 4219  total_loss: 0.1092  loss_cls: 3.415e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01546  loss_rpn_loc: 0.09487  time: 0.3840  data_time: 0.0082  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:50:32 d2.utils.events]: \u001b[0m eta: 0:37:19  iter: 4239  total_loss: 0.1215  loss_cls: 5.437e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02374  loss_rpn_loc: 0.09741  time: 0.3839  data_time: 0.0092  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:50:40 d2.utils.events]: \u001b[0m eta: 0:37:15  iter: 4259  total_loss: 0.1051  loss_cls: 2.944e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02323  loss_rpn_loc: 0.08197  time: 0.3840  data_time: 0.0103  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:50:48 d2.utils.events]: \u001b[0m eta: 0:37:06  iter: 4279  total_loss: 0.1246  loss_cls: 8.102e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02319  loss_rpn_loc: 0.1054  time: 0.3840  data_time: 0.0132  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:50:55 d2.utils.events]: \u001b[0m eta: 0:36:57  iter: 4299  total_loss: 0.1077  loss_cls: 4.703e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0226  loss_rpn_loc: 0.09302  time: 0.3840  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:51:03 d2.utils.events]: \u001b[0m eta: 0:36:49  iter: 4319  total_loss: 0.1046  loss_cls: 4.082e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01306  loss_rpn_loc: 0.08565  time: 0.3840  data_time: 0.0123  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:51:11 d2.utils.events]: \u001b[0m eta: 0:36:41  iter: 4339  total_loss: 0.1559  loss_cls: 4.355e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02416  loss_rpn_loc: 0.1306  time: 0.3841  data_time: 0.0328  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:51:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:51:16 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:51:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:51:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:51:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0815 s/iter. Eval: 0.0000 s/iter. Total: 0.0829 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:51:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.893771 (0.087389 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:51:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081474 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:51:22 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:51:22 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:51:25 d2.utils.events]: \u001b[0m eta: 0:36:36  iter: 4359  total_loss: 0.1303  loss_cls: 3.706e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02676  loss_rpn_loc: 0.1011  time: 0.3841  data_time: 0.0132  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:51:32 d2.utils.events]: \u001b[0m eta: 0:36:27  iter: 4379  total_loss: 0.1056  loss_cls: 1.249e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.004523  loss_rpn_loc: 0.07697  time: 0.3841  data_time: 0.0083  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:51:40 d2.utils.events]: \u001b[0m eta: 0:36:21  iter: 4399  total_loss: 0.1453  loss_cls: 3.56e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01538  loss_rpn_loc: 0.1155  time: 0.3841  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:51:48 d2.utils.events]: \u001b[0m eta: 0:36:13  iter: 4419  total_loss: 0.1581  loss_cls: 6.535e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0276  loss_rpn_loc: 0.1387  time: 0.3841  data_time: 0.0120  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:51:56 d2.utils.events]: \u001b[0m eta: 0:36:05  iter: 4439  total_loss: 0.1149  loss_cls: 1.734e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01832  loss_rpn_loc: 0.09155  time: 0.3841  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:52:03 d2.utils.events]: \u001b[0m eta: 0:35:58  iter: 4459  total_loss: 0.1774  loss_cls: 0.0001021  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02526  loss_rpn_loc: 0.148  time: 0.3842  data_time: 0.0137  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:52:11 d2.utils.events]: \u001b[0m eta: 0:35:53  iter: 4479  total_loss: 0.1044  loss_cls: 4.331e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01444  loss_rpn_loc: 0.09225  time: 0.3842  data_time: 0.0106  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:52:19 d2.utils.events]: \u001b[0m eta: 0:35:46  iter: 4499  total_loss: 0.1089  loss_cls: 8.59e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01922  loss_rpn_loc: 0.09053  time: 0.3842  data_time: 0.0137  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:52:26 d2.utils.events]: \u001b[0m eta: 0:35:37  iter: 4519  total_loss: 0.1184  loss_cls: 9.176e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01709  loss_rpn_loc: 0.09822  time: 0.3841  data_time: 0.0098  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:52:34 d2.utils.events]: \u001b[0m eta: 0:35:30  iter: 4539  total_loss: 0.1132  loss_cls: 5.689e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0258  loss_rpn_loc: 0.09548  time: 0.3841  data_time: 0.0139  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:52:42 d2.utils.events]: \u001b[0m eta: 0:35:22  iter: 4559  total_loss: 0.1575  loss_cls: 6.328e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02582  loss_rpn_loc: 0.1376  time: 0.3842  data_time: 0.0140  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:52:50 d2.utils.events]: \u001b[0m eta: 0:35:14  iter: 4579  total_loss: 0.08841  loss_cls: 2.787e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01061  loss_rpn_loc: 0.07358  time: 0.3842  data_time: 0.0090  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:52:57 d2.utils.events]: \u001b[0m eta: 0:35:07  iter: 4599  total_loss: 0.1471  loss_cls: 3.246e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01883  loss_rpn_loc: 0.1243  time: 0.3842  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:53:05 d2.utils.events]: \u001b[0m eta: 0:34:59  iter: 4619  total_loss: 0.09159  loss_cls: 4.452e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01543  loss_rpn_loc: 0.07549  time: 0.3842  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:53:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:53:07 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:53:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:53:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:53:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0822 s/iter. Eval: 0.0000 s/iter. Total: 0.0835 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:53:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.878851 (0.087122 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:53:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081850 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:53:12 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:53:12 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:53:19 d2.utils.events]: \u001b[0m eta: 0:34:51  iter: 4639  total_loss: 0.09129  loss_cls: 4.368e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0146  loss_rpn_loc: 0.07574  time: 0.3842  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:53:26 d2.utils.events]: \u001b[0m eta: 0:34:43  iter: 4659  total_loss: 0.1061  loss_cls: 3.667e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01423  loss_rpn_loc: 0.08643  time: 0.3842  data_time: 0.0086  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:53:34 d2.utils.events]: \u001b[0m eta: 0:34:35  iter: 4679  total_loss: 0.09162  loss_cls: 2.855e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0104  loss_rpn_loc: 0.07918  time: 0.3842  data_time: 0.0089  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:53:42 d2.utils.events]: \u001b[0m eta: 0:34:28  iter: 4699  total_loss: 0.1685  loss_cls: 6.854e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02114  loss_rpn_loc: 0.1224  time: 0.3842  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:53:50 d2.utils.events]: \u001b[0m eta: 0:34:20  iter: 4719  total_loss: 0.1315  loss_cls: 3.829e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02449  loss_rpn_loc: 0.1019  time: 0.3842  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:53:57 d2.utils.events]: \u001b[0m eta: 0:34:12  iter: 4739  total_loss: 0.1246  loss_cls: 4.936e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02575  loss_rpn_loc: 0.09655  time: 0.3842  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:54:05 d2.utils.events]: \u001b[0m eta: 0:34:04  iter: 4759  total_loss: 0.1531  loss_cls: 5.839e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02528  loss_rpn_loc: 0.1239  time: 0.3842  data_time: 0.0190  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:54:13 d2.utils.events]: \u001b[0m eta: 0:33:57  iter: 4779  total_loss: 0.1203  loss_cls: 3.571e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007895  loss_rpn_loc: 0.103  time: 0.3842  data_time: 0.0103  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:54:21 d2.utils.events]: \u001b[0m eta: 0:33:49  iter: 4799  total_loss: 0.1531  loss_cls: 5.544e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01953  loss_rpn_loc: 0.1264  time: 0.3843  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:54:28 d2.utils.events]: \u001b[0m eta: 0:33:40  iter: 4819  total_loss: 0.1213  loss_cls: 5.101e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02181  loss_rpn_loc: 0.1045  time: 0.3842  data_time: 0.0128  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:54:36 d2.utils.events]: \u001b[0m eta: 0:33:32  iter: 4839  total_loss: 0.09148  loss_cls: 2.954e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.006561  loss_rpn_loc: 0.07807  time: 0.3842  data_time: 0.0083  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:54:43 d2.utils.events]: \u001b[0m eta: 0:33:23  iter: 4859  total_loss: 0.1043  loss_cls: 5.288e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01448  loss_rpn_loc: 0.08353  time: 0.3842  data_time: 0.0087  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:54:51 d2.utils.events]: \u001b[0m eta: 0:33:17  iter: 4879  total_loss: 0.1018  loss_cls: 5.657e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01491  loss_rpn_loc: 0.08947  time: 0.3842  data_time: 0.0132  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:54:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:54:57 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:54:57 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:54:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:54:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0816 s/iter. Eval: 0.0000 s/iter. Total: 0.0830 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:55:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.879262 (0.087130 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:55:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081854 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:55:03 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:55:03 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:55:04 d2.utils.events]: \u001b[0m eta: 0:33:07  iter: 4899  total_loss: 0.1178  loss_cls: 4.596e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01417  loss_rpn_loc: 0.1062  time: 0.3842  data_time: 0.0127  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:55:12 d2.utils.events]: \u001b[0m eta: 0:33:00  iter: 4919  total_loss: 0.1019  loss_cls: 2.917e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01485  loss_rpn_loc: 0.08333  time: 0.3842  data_time: 0.0123  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:55:20 d2.utils.events]: \u001b[0m eta: 0:32:53  iter: 4939  total_loss: 0.1445  loss_cls: 4.92e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02145  loss_rpn_loc: 0.1129  time: 0.3842  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:55:28 d2.utils.events]: \u001b[0m eta: 0:32:44  iter: 4959  total_loss: 0.1145  loss_cls: 4.617e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0252  loss_rpn_loc: 0.09065  time: 0.3843  data_time: 0.0127  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:55:35 d2.utils.events]: \u001b[0m eta: 0:32:36  iter: 4979  total_loss: 0.08729  loss_cls: 1.085e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.008869  loss_rpn_loc: 0.0749  time: 0.3842  data_time: 0.0075  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:55:44 d2.utils.events]: \u001b[0m eta: 0:32:27  iter: 4999  total_loss: 0.1057  loss_cls: 4.821e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02052  loss_rpn_loc: 0.0891  time: 0.3842  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:55:53 d2.utils.events]: \u001b[0m eta: 0:32:20  iter: 5019  total_loss: 0.1193  loss_cls: 3.352e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01811  loss_rpn_loc: 0.09183  time: 0.3842  data_time: 0.0093  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:56:01 d2.utils.events]: \u001b[0m eta: 0:32:11  iter: 5039  total_loss: 0.09127  loss_cls: 3.286e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01294  loss_rpn_loc: 0.08384  time: 0.3842  data_time: 0.0083  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:56:09 d2.utils.events]: \u001b[0m eta: 0:32:05  iter: 5059  total_loss: 0.092  loss_cls: 2.732e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01255  loss_rpn_loc: 0.07791  time: 0.3842  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:56:16 d2.utils.events]: \u001b[0m eta: 0:31:54  iter: 5079  total_loss: 0.08335  loss_cls: 3.839e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01647  loss_rpn_loc: 0.0724  time: 0.3842  data_time: 0.0151  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:56:24 d2.utils.events]: \u001b[0m eta: 0:31:47  iter: 5099  total_loss: 0.1385  loss_cls: 3.433e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02589  loss_rpn_loc: 0.1112  time: 0.3842  data_time: 0.0189  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:56:32 d2.utils.events]: \u001b[0m eta: 0:31:40  iter: 5119  total_loss: 0.1629  loss_cls: 4.333e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03012  loss_rpn_loc: 0.1328  time: 0.3843  data_time: 0.0161  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:56:40 d2.utils.events]: \u001b[0m eta: 0:31:31  iter: 5139  total_loss: 0.1315  loss_cls: 4.648e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02845  loss_rpn_loc: 0.1022  time: 0.3843  data_time: 0.0142  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:56:47 d2.utils.events]: \u001b[0m eta: 0:31:24  iter: 5159  total_loss: 0.119  loss_cls: 2.392e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01561  loss_rpn_loc: 0.1052  time: 0.3842  data_time: 0.0097  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:56:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:56:50 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:56:50 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:56:50 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:56:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0012 s/iter. Inference: 0.0814 s/iter. Eval: 0.0000 s/iter. Total: 0.0826 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:56:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.859177 (0.086771 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:56:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081560 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:56:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:56:56 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:57:01 d2.utils.events]: \u001b[0m eta: 0:31:17  iter: 5179  total_loss: 0.1182  loss_cls: 2.821e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02684  loss_rpn_loc: 0.09157  time: 0.3842  data_time: 0.0087  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:57:09 d2.utils.events]: \u001b[0m eta: 0:31:10  iter: 5199  total_loss: 0.1197  loss_cls: 5.391e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01919  loss_rpn_loc: 0.09208  time: 0.3843  data_time: 0.0128  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:57:16 d2.utils.events]: \u001b[0m eta: 0:31:02  iter: 5219  total_loss: 0.0844  loss_cls: 3.774e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01587  loss_rpn_loc: 0.07237  time: 0.3842  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:57:24 d2.utils.events]: \u001b[0m eta: 0:30:55  iter: 5239  total_loss: 0.1494  loss_cls: 7.333e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01642  loss_rpn_loc: 0.112  time: 0.3842  data_time: 0.0122  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:57:32 d2.utils.events]: \u001b[0m eta: 0:30:46  iter: 5259  total_loss: 0.07662  loss_cls: 3.675e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007205  loss_rpn_loc: 0.06093  time: 0.3842  data_time: 0.0169  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:57:40 d2.utils.events]: \u001b[0m eta: 0:30:39  iter: 5279  total_loss: 0.1558  loss_cls: 5.935e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02594  loss_rpn_loc: 0.1266  time: 0.3843  data_time: 0.0165  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:57:47 d2.utils.events]: \u001b[0m eta: 0:30:30  iter: 5299  total_loss: 0.09436  loss_cls: 1.654e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01192  loss_rpn_loc: 0.07982  time: 0.3843  data_time: 0.0098  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:57:55 d2.utils.events]: \u001b[0m eta: 0:30:23  iter: 5319  total_loss: 0.1512  loss_cls: 7.146e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02197  loss_rpn_loc: 0.1327  time: 0.3843  data_time: 0.0178  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:58:03 d2.utils.events]: \u001b[0m eta: 0:30:16  iter: 5339  total_loss: 0.1476  loss_cls: 4.047e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02152  loss_rpn_loc: 0.1259  time: 0.3844  data_time: 0.0134  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:58:10 d2.utils.events]: \u001b[0m eta: 0:30:07  iter: 5359  total_loss: 0.09968  loss_cls: 5.063e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01468  loss_rpn_loc: 0.08782  time: 0.3843  data_time: 0.0095  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:58:18 d2.utils.events]: \u001b[0m eta: 0:30:02  iter: 5379  total_loss: 0.1094  loss_cls: 2.96e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01488  loss_rpn_loc: 0.09063  time: 0.3843  data_time: 0.0137  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:58:26 d2.utils.events]: \u001b[0m eta: 0:29:53  iter: 5399  total_loss: 0.09795  loss_cls: 2.306e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01292  loss_rpn_loc: 0.08676  time: 0.3844  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:58:34 d2.utils.events]: \u001b[0m eta: 0:29:45  iter: 5419  total_loss: 0.1027  loss_cls: 3.914e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01527  loss_rpn_loc: 0.08599  time: 0.3844  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:58:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 16:58:41 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 16:58:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 16:58:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 16:58:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0820 s/iter. Eval: 0.0000 s/iter. Total: 0.0833 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 16:58:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.868250 (0.086933 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:58:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081611 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 16:58:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 16:58:47 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 16:58:47 d2.utils.events]: \u001b[0m eta: 0:29:36  iter: 5439  total_loss: 0.1264  loss_cls: 4.573e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02226  loss_rpn_loc: 0.09935  time: 0.3843  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:58:55 d2.utils.events]: \u001b[0m eta: 0:29:27  iter: 5459  total_loss: 0.09262  loss_cls: 1.328e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01304  loss_rpn_loc: 0.07076  time: 0.3843  data_time: 0.0099  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:59:03 d2.utils.events]: \u001b[0m eta: 0:29:20  iter: 5479  total_loss: 0.1088  loss_cls: 3.196e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01651  loss_rpn_loc: 0.09262  time: 0.3844  data_time: 0.0161  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:59:10 d2.utils.events]: \u001b[0m eta: 0:29:12  iter: 5499  total_loss: 0.0988  loss_cls: 4.591e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0214  loss_rpn_loc: 0.08143  time: 0.3844  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:59:18 d2.utils.events]: \u001b[0m eta: 0:29:04  iter: 5519  total_loss: 0.1285  loss_cls: 4.826e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0169  loss_rpn_loc: 0.0927  time: 0.3843  data_time: 0.0097  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:59:26 d2.utils.events]: \u001b[0m eta: 0:28:56  iter: 5539  total_loss: 0.107  loss_cls: 4.329e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01352  loss_rpn_loc: 0.09066  time: 0.3844  data_time: 0.0136  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:59:33 d2.utils.events]: \u001b[0m eta: 0:28:48  iter: 5559  total_loss: 0.1015  loss_cls: 3.964e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01788  loss_rpn_loc: 0.07772  time: 0.3844  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:59:42 d2.utils.events]: \u001b[0m eta: 0:28:42  iter: 5579  total_loss: 0.0894  loss_cls: 3.853e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01739  loss_rpn_loc: 0.07605  time: 0.3845  data_time: 0.0286  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:59:50 d2.utils.events]: \u001b[0m eta: 0:28:33  iter: 5599  total_loss: 0.1058  loss_cls: 2.984e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01447  loss_rpn_loc: 0.09  time: 0.3845  data_time: 0.0153  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 16:59:57 d2.utils.events]: \u001b[0m eta: 0:28:26  iter: 5619  total_loss: 0.1238  loss_cls: 5.243e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02089  loss_rpn_loc: 0.1001  time: 0.3845  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:00:05 d2.utils.events]: \u001b[0m eta: 0:28:17  iter: 5639  total_loss: 0.1077  loss_cls: 4.614e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01983  loss_rpn_loc: 0.08474  time: 0.3845  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:00:13 d2.utils.events]: \u001b[0m eta: 0:28:09  iter: 5659  total_loss: 0.1174  loss_cls: 4.604e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01957  loss_rpn_loc: 0.0959  time: 0.3845  data_time: 0.0096  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:00:20 d2.utils.events]: \u001b[0m eta: 0:28:01  iter: 5679  total_loss: 0.09749  loss_cls: 3.417e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01122  loss_rpn_loc: 0.08466  time: 0.3845  data_time: 0.0110  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:00:28 d2.utils.events]: \u001b[0m eta: 0:27:51  iter: 5699  total_loss: 0.1069  loss_cls: 2.618e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0147  loss_rpn_loc: 0.09057  time: 0.3844  data_time: 0.0084  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:00:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 17:00:32 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 17:00:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 17:00:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 17:00:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0012 s/iter. Inference: 0.0813 s/iter. Eval: 0.0000 s/iter. Total: 0.0825 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 17:00:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.861627 (0.086815 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:00:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081380 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:00:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 17:00:38 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 17:00:41 d2.utils.events]: \u001b[0m eta: 0:27:43  iter: 5719  total_loss: 0.1322  loss_cls: 3.79e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02091  loss_rpn_loc: 0.09939  time: 0.3844  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:00:49 d2.utils.events]: \u001b[0m eta: 0:27:36  iter: 5739  total_loss: 0.08468  loss_cls: 2.453e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01439  loss_rpn_loc: 0.07519  time: 0.3844  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:00:57 d2.utils.events]: \u001b[0m eta: 0:27:28  iter: 5759  total_loss: 0.1434  loss_cls: 4.685e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02217  loss_rpn_loc: 0.1251  time: 0.3844  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:01:04 d2.utils.events]: \u001b[0m eta: 0:27:22  iter: 5779  total_loss: 0.1121  loss_cls: 5.011e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02051  loss_rpn_loc: 0.09646  time: 0.3844  data_time: 0.0142  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:01:12 d2.utils.events]: \u001b[0m eta: 0:27:13  iter: 5799  total_loss: 0.1114  loss_cls: 5.178e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0137  loss_rpn_loc: 0.08229  time: 0.3844  data_time: 0.0101  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:01:20 d2.utils.events]: \u001b[0m eta: 0:27:06  iter: 5819  total_loss: 0.08417  loss_cls: 4.999e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01226  loss_rpn_loc: 0.07635  time: 0.3844  data_time: 0.0096  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:01:27 d2.utils.events]: \u001b[0m eta: 0:26:57  iter: 5839  total_loss: 0.1028  loss_cls: 3.204e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01472  loss_rpn_loc: 0.09072  time: 0.3844  data_time: 0.0157  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:01:35 d2.utils.events]: \u001b[0m eta: 0:26:49  iter: 5859  total_loss: 0.07303  loss_cls: 2.583e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0037  loss_rpn_loc: 0.05889  time: 0.3844  data_time: 0.0092  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:01:43 d2.utils.events]: \u001b[0m eta: 0:26:42  iter: 5879  total_loss: 0.2017  loss_cls: 5.395e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03261  loss_rpn_loc: 0.169  time: 0.3844  data_time: 0.0164  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:01:50 d2.utils.events]: \u001b[0m eta: 0:26:34  iter: 5899  total_loss: 0.08493  loss_cls: 1.686e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.006846  loss_rpn_loc: 0.07512  time: 0.3844  data_time: 0.0073  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:01:58 d2.utils.events]: \u001b[0m eta: 0:26:26  iter: 5919  total_loss: 0.1025  loss_cls: 3.432e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01723  loss_rpn_loc: 0.08734  time: 0.3844  data_time: 0.0099  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:02:06 d2.utils.events]: \u001b[0m eta: 0:26:18  iter: 5939  total_loss: 0.1071  loss_cls: 3.243e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01889  loss_rpn_loc: 0.09094  time: 0.3844  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:02:13 d2.utils.events]: \u001b[0m eta: 0:26:10  iter: 5959  total_loss: 0.1412  loss_cls: 6.32e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0198  loss_rpn_loc: 0.1257  time: 0.3844  data_time: 0.0139  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:02:21 d2.utils.events]: \u001b[0m eta: 0:26:03  iter: 5979  total_loss: 0.09488  loss_cls: 5.456e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01306  loss_rpn_loc: 0.0825  time: 0.3844  data_time: 0.0128  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:02:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 17:02:22 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 17:02:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 17:02:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 17:02:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0012 s/iter. Inference: 0.0814 s/iter. Eval: 0.0000 s/iter. Total: 0.0825 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 17:02:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.862953 (0.086838 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:02:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081636 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:02:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 17:02:28 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 17:02:35 d2.utils.events]: \u001b[0m eta: 0:25:56  iter: 5999  total_loss: 0.1224  loss_cls: 3.214e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01605  loss_rpn_loc: 0.1051  time: 0.3844  data_time: 0.0116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:02:42 d2.utils.events]: \u001b[0m eta: 0:25:48  iter: 6019  total_loss: 0.1474  loss_cls: 3.239e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02395  loss_rpn_loc: 0.1118  time: 0.3844  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:02:50 d2.utils.events]: \u001b[0m eta: 0:25:41  iter: 6039  total_loss: 0.08616  loss_cls: 1.911e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01104  loss_rpn_loc: 0.07687  time: 0.3844  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:02:58 d2.utils.events]: \u001b[0m eta: 0:25:32  iter: 6059  total_loss: 0.103  loss_cls: 1.355e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01446  loss_rpn_loc: 0.08761  time: 0.3844  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:03:05 d2.utils.events]: \u001b[0m eta: 0:25:25  iter: 6079  total_loss: 0.1019  loss_cls: 1.938e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02471  loss_rpn_loc: 0.07919  time: 0.3844  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:03:13 d2.utils.events]: \u001b[0m eta: 0:25:16  iter: 6099  total_loss: 0.08604  loss_cls: 3.414e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01229  loss_rpn_loc: 0.0706  time: 0.3844  data_time: 0.0158  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:03:21 d2.utils.events]: \u001b[0m eta: 0:25:08  iter: 6119  total_loss: 0.111  loss_cls: 5.121e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01296  loss_rpn_loc: 0.09623  time: 0.3844  data_time: 0.0177  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:03:29 d2.utils.events]: \u001b[0m eta: 0:25:00  iter: 6139  total_loss: 0.1005  loss_cls: 5.654e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0145  loss_rpn_loc: 0.09227  time: 0.3844  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:03:37 d2.utils.events]: \u001b[0m eta: 0:24:54  iter: 6159  total_loss: 0.1283  loss_cls: 6.649e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02269  loss_rpn_loc: 0.1033  time: 0.3845  data_time: 0.0196  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:03:44 d2.utils.events]: \u001b[0m eta: 0:24:46  iter: 6179  total_loss: 0.09863  loss_cls: 3.618e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007754  loss_rpn_loc: 0.08581  time: 0.3845  data_time: 0.0095  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:03:52 d2.utils.events]: \u001b[0m eta: 0:24:37  iter: 6199  total_loss: 0.1129  loss_cls: 3.53e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01563  loss_rpn_loc: 0.09601  time: 0.3845  data_time: 0.0096  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:04:00 d2.utils.events]: \u001b[0m eta: 0:24:30  iter: 6219  total_loss: 0.1085  loss_cls: 5.26e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02265  loss_rpn_loc: 0.09081  time: 0.3844  data_time: 0.0122  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:04:07 d2.utils.events]: \u001b[0m eta: 0:24:23  iter: 6239  total_loss: 0.0884  loss_cls: 3.726e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01245  loss_rpn_loc: 0.07547  time: 0.3844  data_time: 0.0151  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:04:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 17:04:13 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 17:04:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 17:04:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 17:04:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0821 s/iter. Eval: 0.0000 s/iter. Total: 0.0837 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 17:04:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.912011 (0.087714 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:04:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082121 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:04:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 17:04:19 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 17:04:21 d2.utils.events]: \u001b[0m eta: 0:24:16  iter: 6259  total_loss: 0.1124  loss_cls: 4.665e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01449  loss_rpn_loc: 0.09778  time: 0.3844  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:04:28 d2.utils.events]: \u001b[0m eta: 0:24:07  iter: 6279  total_loss: 0.1294  loss_cls: 3.923e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02693  loss_rpn_loc: 0.09615  time: 0.3844  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:04:36 d2.utils.events]: \u001b[0m eta: 0:24:00  iter: 6299  total_loss: 0.09624  loss_cls: 2.813e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01064  loss_rpn_loc: 0.0823  time: 0.3845  data_time: 0.0214  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:04:44 d2.utils.events]: \u001b[0m eta: 0:23:52  iter: 6319  total_loss: 0.1239  loss_cls: 3.075e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02036  loss_rpn_loc: 0.0964  time: 0.3845  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:04:52 d2.utils.events]: \u001b[0m eta: 0:23:44  iter: 6339  total_loss: 0.1116  loss_cls: 1.674e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01952  loss_rpn_loc: 0.08427  time: 0.3845  data_time: 0.0101  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:05:00 d2.utils.events]: \u001b[0m eta: 0:23:38  iter: 6359  total_loss: 0.1268  loss_cls: 4.259e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01815  loss_rpn_loc: 0.1026  time: 0.3845  data_time: 0.0122  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:05:08 d2.utils.events]: \u001b[0m eta: 0:23:30  iter: 6379  total_loss: 0.1224  loss_cls: 4.453e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01953  loss_rpn_loc: 0.1051  time: 0.3845  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:05:15 d2.utils.events]: \u001b[0m eta: 0:23:22  iter: 6399  total_loss: 0.1261  loss_cls: 4.754e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02004  loss_rpn_loc: 0.09502  time: 0.3845  data_time: 0.0134  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:05:23 d2.utils.events]: \u001b[0m eta: 0:23:14  iter: 6419  total_loss: 0.09362  loss_cls: 2.933e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01787  loss_rpn_loc: 0.08685  time: 0.3846  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:05:31 d2.utils.events]: \u001b[0m eta: 0:23:06  iter: 6439  total_loss: 0.09535  loss_cls: 1.885e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.006087  loss_rpn_loc: 0.08783  time: 0.3845  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:05:38 d2.utils.events]: \u001b[0m eta: 0:22:59  iter: 6459  total_loss: 0.1001  loss_cls: 5.5e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01543  loss_rpn_loc: 0.08309  time: 0.3845  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:05:46 d2.utils.events]: \u001b[0m eta: 0:22:51  iter: 6479  total_loss: 0.1173  loss_cls: 2.813e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01507  loss_rpn_loc: 0.09396  time: 0.3846  data_time: 0.0189  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:05:54 d2.utils.events]: \u001b[0m eta: 0:22:43  iter: 6499  total_loss: 0.103  loss_cls: 5.779e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01408  loss_rpn_loc: 0.08946  time: 0.3845  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:06:02 d2.utils.events]: \u001b[0m eta: 0:22:36  iter: 6519  total_loss: 0.1094  loss_cls: 5.024e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01509  loss_rpn_loc: 0.09336  time: 0.3845  data_time: 0.0100  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:06:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 17:06:05 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 17:06:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 17:06:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 17:06:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0820 s/iter. Eval: 0.0000 s/iter. Total: 0.0833 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 17:06:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.870722 (0.086977 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:06:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081669 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:06:10 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 17:06:10 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 17:06:15 d2.utils.events]: \u001b[0m eta: 0:22:27  iter: 6539  total_loss: 0.1065  loss_cls: 4.162e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01382  loss_rpn_loc: 0.08589  time: 0.3846  data_time: 0.0120  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:06:23 d2.utils.events]: \u001b[0m eta: 0:22:19  iter: 6559  total_loss: 0.1179  loss_cls: 3.342e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01571  loss_rpn_loc: 0.1046  time: 0.3846  data_time: 0.0146  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:06:31 d2.utils.events]: \u001b[0m eta: 0:22:11  iter: 6579  total_loss: 0.09027  loss_cls: 1.796e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01087  loss_rpn_loc: 0.07897  time: 0.3846  data_time: 0.0172  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:06:39 d2.utils.events]: \u001b[0m eta: 0:22:04  iter: 6599  total_loss: 0.1245  loss_cls: 2.855e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01432  loss_rpn_loc: 0.1075  time: 0.3846  data_time: 0.0121  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:06:47 d2.utils.events]: \u001b[0m eta: 0:21:56  iter: 6619  total_loss: 0.1142  loss_cls: 7.63e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02133  loss_rpn_loc: 0.09482  time: 0.3847  data_time: 0.0303  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:06:54 d2.utils.events]: \u001b[0m eta: 0:21:48  iter: 6639  total_loss: 0.1126  loss_cls: 3.443e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01431  loss_rpn_loc: 0.09235  time: 0.3847  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:07:02 d2.utils.events]: \u001b[0m eta: 0:21:41  iter: 6659  total_loss: 0.1283  loss_cls: 6.392e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0129  loss_rpn_loc: 0.1078  time: 0.3847  data_time: 0.0116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:07:10 d2.utils.events]: \u001b[0m eta: 0:21:34  iter: 6679  total_loss: 0.1194  loss_cls: 4.432e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01802  loss_rpn_loc: 0.09842  time: 0.3847  data_time: 0.0162  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:07:18 d2.utils.events]: \u001b[0m eta: 0:21:27  iter: 6699  total_loss: 0.08827  loss_cls: 2.995e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01077  loss_rpn_loc: 0.07747  time: 0.3847  data_time: 0.0118  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:07:26 d2.utils.events]: \u001b[0m eta: 0:21:20  iter: 6719  total_loss: 0.116  loss_cls: 5.461e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01918  loss_rpn_loc: 0.09258  time: 0.3847  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:07:33 d2.utils.events]: \u001b[0m eta: 0:21:12  iter: 6739  total_loss: 0.0784  loss_cls: 3.711e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009406  loss_rpn_loc: 0.06842  time: 0.3847  data_time: 0.0097  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:07:41 d2.utils.events]: \u001b[0m eta: 0:21:03  iter: 6759  total_loss: 0.1234  loss_cls: 1.756e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01826  loss_rpn_loc: 0.1002  time: 0.3847  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:07:49 d2.utils.events]: \u001b[0m eta: 0:20:55  iter: 6779  total_loss: 0.1082  loss_cls: 5.108e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01666  loss_rpn_loc: 0.09027  time: 0.3847  data_time: 0.0116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:07:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 17:07:57 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 17:07:57 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 17:07:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 17:07:58 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0818 s/iter. Eval: 0.0000 s/iter. Total: 0.0831 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 17:08:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.878846 (0.087122 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:08:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081884 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:08:02 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 17:08:02 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 17:08:02 d2.utils.events]: \u001b[0m eta: 0:20:49  iter: 6799  total_loss: 0.09417  loss_cls: 4.789e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01641  loss_rpn_loc: 0.07859  time: 0.3847  data_time: 0.0167  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:08:10 d2.utils.events]: \u001b[0m eta: 0:20:41  iter: 6819  total_loss: 0.08953  loss_cls: 3.711e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01198  loss_rpn_loc: 0.07532  time: 0.3848  data_time: 0.0150  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:08:18 d2.utils.events]: \u001b[0m eta: 0:20:34  iter: 6839  total_loss: 0.1843  loss_cls: 5.812e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02436  loss_rpn_loc: 0.1519  time: 0.3848  data_time: 0.0100  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:08:26 d2.utils.events]: \u001b[0m eta: 0:20:26  iter: 6859  total_loss: 0.1095  loss_cls: 2.158e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01331  loss_rpn_loc: 0.09616  time: 0.3848  data_time: 0.0291  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:08:34 d2.utils.events]: \u001b[0m eta: 0:20:17  iter: 6879  total_loss: 0.1144  loss_cls: 5.096e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0177  loss_rpn_loc: 0.0972  time: 0.3848  data_time: 0.0150  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:08:42 d2.utils.events]: \u001b[0m eta: 0:20:11  iter: 6899  total_loss: 0.1102  loss_cls: 6.676e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02035  loss_rpn_loc: 0.09308  time: 0.3849  data_time: 0.0143  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:08:50 d2.utils.events]: \u001b[0m eta: 0:20:05  iter: 6919  total_loss: 0.1056  loss_cls: 6.036e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01223  loss_rpn_loc: 0.08103  time: 0.3849  data_time: 0.0100  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:08:57 d2.utils.events]: \u001b[0m eta: 0:19:56  iter: 6939  total_loss: 0.1049  loss_cls: 1.52e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01129  loss_rpn_loc: 0.08048  time: 0.3849  data_time: 0.0088  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:09:05 d2.utils.events]: \u001b[0m eta: 0:19:48  iter: 6959  total_loss: 0.09787  loss_cls: 6.46e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0142  loss_rpn_loc: 0.08185  time: 0.3848  data_time: 0.0098  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:09:12 d2.utils.events]: \u001b[0m eta: 0:19:40  iter: 6979  total_loss: 0.1038  loss_cls: 4.019e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01127  loss_rpn_loc: 0.09294  time: 0.3848  data_time: 0.0123  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:09:20 d2.utils.events]: \u001b[0m eta: 0:19:33  iter: 6999  total_loss: 0.108  loss_cls: 5.07e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01303  loss_rpn_loc: 0.09225  time: 0.3848  data_time: 0.0089  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:09:28 d2.utils.events]: \u001b[0m eta: 0:19:26  iter: 7019  total_loss: 0.1166  loss_cls: 2.377e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01427  loss_rpn_loc: 0.09848  time: 0.3848  data_time: 0.0095  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:09:36 d2.utils.events]: \u001b[0m eta: 0:19:18  iter: 7039  total_loss: 0.1348  loss_cls: 2.661e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02059  loss_rpn_loc: 0.09453  time: 0.3849  data_time: 0.0154  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:09:43 d2.utils.events]: \u001b[0m eta: 0:19:10  iter: 7059  total_loss: 0.1058  loss_cls: 2.577e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02024  loss_rpn_loc: 0.07984  time: 0.3848  data_time: 0.0095  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:09:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 17:09:48 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 17:09:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 17:09:48 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 17:09:49 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0821 s/iter. Eval: 0.0000 s/iter. Total: 0.0834 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 17:09:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.878844 (0.087122 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:09:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081865 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:09:54 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 17:09:54 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 17:09:57 d2.utils.events]: \u001b[0m eta: 0:19:02  iter: 7079  total_loss: 0.1036  loss_cls: 2.398e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01039  loss_rpn_loc: 0.09395  time: 0.3848  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:10:05 d2.utils.events]: \u001b[0m eta: 0:18:56  iter: 7099  total_loss: 0.1154  loss_cls: 3.122e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01683  loss_rpn_loc: 0.08525  time: 0.3848  data_time: 0.0100  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:10:12 d2.utils.events]: \u001b[0m eta: 0:18:48  iter: 7119  total_loss: 0.1137  loss_cls: 3.626e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01614  loss_rpn_loc: 0.0928  time: 0.3848  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:10:20 d2.utils.events]: \u001b[0m eta: 0:18:40  iter: 7139  total_loss: 0.1507  loss_cls: 4.662e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02488  loss_rpn_loc: 0.1264  time: 0.3849  data_time: 0.0147  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:10:27 d2.utils.events]: \u001b[0m eta: 0:18:31  iter: 7159  total_loss: 0.09911  loss_cls: 2.922e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01007  loss_rpn_loc: 0.08515  time: 0.3848  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:10:35 d2.utils.events]: \u001b[0m eta: 0:18:23  iter: 7179  total_loss: 0.1151  loss_cls: 2.53e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01913  loss_rpn_loc: 0.08749  time: 0.3848  data_time: 0.0100  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:10:43 d2.utils.events]: \u001b[0m eta: 0:18:15  iter: 7199  total_loss: 0.1256  loss_cls: 2.19e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01694  loss_rpn_loc: 0.1109  time: 0.3848  data_time: 0.0129  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:10:50 d2.utils.events]: \u001b[0m eta: 0:18:06  iter: 7219  total_loss: 0.1152  loss_cls: 5.511e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01468  loss_rpn_loc: 0.07792  time: 0.3848  data_time: 0.0138  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:10:58 d2.utils.events]: \u001b[0m eta: 0:17:58  iter: 7239  total_loss: 0.1118  loss_cls: 4.552e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01304  loss_rpn_loc: 0.09674  time: 0.3848  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:11:06 d2.utils.events]: \u001b[0m eta: 0:17:50  iter: 7259  total_loss: 0.07508  loss_cls: 1.935e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.005707  loss_rpn_loc: 0.05806  time: 0.3848  data_time: 0.0145  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:11:14 d2.utils.events]: \u001b[0m eta: 0:17:42  iter: 7279  total_loss: 0.1115  loss_cls: 1.772e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01448  loss_rpn_loc: 0.09207  time: 0.3848  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:11:21 d2.utils.events]: \u001b[0m eta: 0:17:34  iter: 7299  total_loss: 0.1021  loss_cls: 1.974e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01873  loss_rpn_loc: 0.07791  time: 0.3848  data_time: 0.0114  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:11:29 d2.utils.events]: \u001b[0m eta: 0:17:27  iter: 7319  total_loss: 0.1068  loss_cls: 2.586e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02103  loss_rpn_loc: 0.08482  time: 0.3848  data_time: 0.0143  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:11:37 d2.utils.events]: \u001b[0m eta: 0:17:19  iter: 7339  total_loss: 0.1077  loss_cls: 2.313e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01593  loss_rpn_loc: 0.09395  time: 0.3848  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:11:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 17:11:38 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 17:11:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 17:11:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 17:11:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0824 s/iter. Eval: 0.0000 s/iter. Total: 0.0838 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 17:11:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.897587 (0.087457 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:11:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082147 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:11:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 17:11:44 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 17:11:50 d2.utils.events]: \u001b[0m eta: 0:17:10  iter: 7359  total_loss: 0.1015  loss_cls: 2.64e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0156  loss_rpn_loc: 0.07963  time: 0.3848  data_time: 0.0140  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:11:58 d2.utils.events]: \u001b[0m eta: 0:17:02  iter: 7379  total_loss: 0.09916  loss_cls: 2.298e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01608  loss_rpn_loc: 0.07732  time: 0.3848  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:12:06 d2.utils.events]: \u001b[0m eta: 0:16:54  iter: 7399  total_loss: 0.1085  loss_cls: 3.833e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.00956  loss_rpn_loc: 0.09256  time: 0.3848  data_time: 0.0093  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:12:14 d2.utils.events]: \u001b[0m eta: 0:16:46  iter: 7419  total_loss: 0.09065  loss_cls: 2.886e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.006513  loss_rpn_loc: 0.08582  time: 0.3848  data_time: 0.0090  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:12:21 d2.utils.events]: \u001b[0m eta: 0:16:38  iter: 7439  total_loss: 0.1172  loss_cls: 2.369e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01427  loss_rpn_loc: 0.09873  time: 0.3848  data_time: 0.0122  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:12:29 d2.utils.events]: \u001b[0m eta: 0:16:31  iter: 7459  total_loss: 0.1549  loss_cls: 5.352e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02223  loss_rpn_loc: 0.1204  time: 0.3848  data_time: 0.0161  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:12:36 d2.utils.events]: \u001b[0m eta: 0:16:21  iter: 7479  total_loss: 0.085  loss_cls: 3.135e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007788  loss_rpn_loc: 0.06983  time: 0.3848  data_time: 0.0074  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:12:44 d2.utils.events]: \u001b[0m eta: 0:16:12  iter: 7499  total_loss: 0.07751  loss_cls: 1.668e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.005871  loss_rpn_loc: 0.0741  time: 0.3847  data_time: 0.0101  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:12:52 d2.utils.events]: \u001b[0m eta: 0:16:04  iter: 7519  total_loss: 0.1016  loss_cls: 3.488e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02078  loss_rpn_loc: 0.08197  time: 0.3848  data_time: 0.0183  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:12:59 d2.utils.events]: \u001b[0m eta: 0:15:57  iter: 7539  total_loss: 0.1108  loss_cls: 2.491e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01406  loss_rpn_loc: 0.09131  time: 0.3848  data_time: 0.0093  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:13:07 d2.utils.events]: \u001b[0m eta: 0:15:49  iter: 7559  total_loss: 0.1331  loss_cls: 5.877e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0183  loss_rpn_loc: 0.1093  time: 0.3848  data_time: 0.0246  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:13:15 d2.utils.events]: \u001b[0m eta: 0:15:42  iter: 7579  total_loss: 0.09663  loss_cls: 2.442e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01644  loss_rpn_loc: 0.07908  time: 0.3848  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:13:23 d2.utils.events]: \u001b[0m eta: 0:15:34  iter: 7599  total_loss: 0.1293  loss_cls: 3.303e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01715  loss_rpn_loc: 0.1082  time: 0.3848  data_time: 0.0122  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:13:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 17:13:29 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 17:13:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 17:13:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 17:13:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0011 s/iter. Inference: 0.0811 s/iter. Eval: 0.0000 s/iter. Total: 0.0822 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 17:13:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.867664 (0.086923 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:13:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081666 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:13:35 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 17:13:35 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 17:13:36 d2.utils.events]: \u001b[0m eta: 0:15:26  iter: 7619  total_loss: 0.1025  loss_cls: 3.304e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02197  loss_rpn_loc: 0.08095  time: 0.3848  data_time: 0.0168  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:13:44 d2.utils.events]: \u001b[0m eta: 0:15:18  iter: 7639  total_loss: 0.1104  loss_cls: 3.616e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02388  loss_rpn_loc: 0.08506  time: 0.3848  data_time: 0.0210  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:13:52 d2.utils.events]: \u001b[0m eta: 0:15:10  iter: 7659  total_loss: 0.1275  loss_cls: 2.998e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.03074  loss_rpn_loc: 0.1005  time: 0.3848  data_time: 0.0123  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:14:00 d2.utils.events]: \u001b[0m eta: 0:15:02  iter: 7679  total_loss: 0.1475  loss_cls: 4.803e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02103  loss_rpn_loc: 0.1136  time: 0.3848  data_time: 0.0146  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:14:07 d2.utils.events]: \u001b[0m eta: 0:14:54  iter: 7699  total_loss: 0.09493  loss_cls: 4.149e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01307  loss_rpn_loc: 0.08209  time: 0.3848  data_time: 0.0096  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:14:15 d2.utils.events]: \u001b[0m eta: 0:14:46  iter: 7719  total_loss: 0.08542  loss_cls: 4.131e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01367  loss_rpn_loc: 0.07512  time: 0.3848  data_time: 0.0088  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:14:23 d2.utils.events]: \u001b[0m eta: 0:14:39  iter: 7739  total_loss: 0.08745  loss_cls: 4.096e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01286  loss_rpn_loc: 0.0725  time: 0.3848  data_time: 0.0129  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:14:30 d2.utils.events]: \u001b[0m eta: 0:14:31  iter: 7759  total_loss: 0.1114  loss_cls: 3.414e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01927  loss_rpn_loc: 0.09263  time: 0.3848  data_time: 0.0123  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:14:38 d2.utils.events]: \u001b[0m eta: 0:14:23  iter: 7779  total_loss: 0.1124  loss_cls: 3.286e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.09303  time: 0.3848  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:14:46 d2.utils.events]: \u001b[0m eta: 0:14:16  iter: 7799  total_loss: 0.145  loss_cls: 2.062e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01912  loss_rpn_loc: 0.1169  time: 0.3848  data_time: 0.0174  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:14:54 d2.utils.events]: \u001b[0m eta: 0:14:08  iter: 7819  total_loss: 0.09778  loss_cls: 3.484e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01211  loss_rpn_loc: 0.09017  time: 0.3848  data_time: 0.0120  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:15:01 d2.utils.events]: \u001b[0m eta: 0:14:00  iter: 7839  total_loss: 0.06253  loss_cls: 1.726e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.002878  loss_rpn_loc: 0.05605  time: 0.3848  data_time: 0.0069  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:15:09 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 7859  total_loss: 0.1105  loss_cls: 2.404e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0165  loss_rpn_loc: 0.09444  time: 0.3848  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:15:17 d2.utils.events]: \u001b[0m eta: 0:13:45  iter: 7879  total_loss: 0.1127  loss_cls: 2.611e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02103  loss_rpn_loc: 0.08113  time: 0.3848  data_time: 0.0135  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:15:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 17:15:20 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 17:15:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 17:15:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 17:15:21 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0823 s/iter. Eval: 0.0000 s/iter. Total: 0.0836 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 17:15:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.883531 (0.087206 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:15:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081877 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:15:26 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 17:15:26 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 17:15:30 d2.utils.events]: \u001b[0m eta: 0:13:36  iter: 7899  total_loss: 0.0903  loss_cls: 5.559e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01322  loss_rpn_loc: 0.0761  time: 0.3848  data_time: 0.0178  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:15:38 d2.utils.events]: \u001b[0m eta: 0:13:28  iter: 7919  total_loss: 0.1263  loss_cls: 2.895e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02333  loss_rpn_loc: 0.08945  time: 0.3848  data_time: 0.0121  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:15:46 d2.utils.events]: \u001b[0m eta: 0:13:20  iter: 7939  total_loss: 0.12  loss_cls: 3.171e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01955  loss_rpn_loc: 0.1044  time: 0.3848  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:15:54 d2.utils.events]: \u001b[0m eta: 0:13:13  iter: 7959  total_loss: 0.1178  loss_cls: 3.207e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02131  loss_rpn_loc: 0.09351  time: 0.3849  data_time: 0.0314  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:16:01 d2.utils.events]: \u001b[0m eta: 0:13:05  iter: 7979  total_loss: 0.08622  loss_cls: 4.627e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01395  loss_rpn_loc: 0.07783  time: 0.3849  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:16:09 d2.utils.events]: \u001b[0m eta: 0:12:56  iter: 7999  total_loss: 0.1626  loss_cls: 2.983e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01861  loss_rpn_loc: 0.1196  time: 0.3849  data_time: 0.0197  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:16:17 d2.utils.events]: \u001b[0m eta: 0:12:48  iter: 8019  total_loss: 0.09466  loss_cls: 2.945e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01279  loss_rpn_loc: 0.08357  time: 0.3849  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:16:25 d2.utils.events]: \u001b[0m eta: 0:12:40  iter: 8039  total_loss: 0.1323  loss_cls: 4.303e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02759  loss_rpn_loc: 0.09705  time: 0.3849  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:16:32 d2.utils.events]: \u001b[0m eta: 0:12:32  iter: 8059  total_loss: 0.1148  loss_cls: 3.308e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0222  loss_rpn_loc: 0.08771  time: 0.3849  data_time: 0.0098  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:16:40 d2.utils.events]: \u001b[0m eta: 0:12:24  iter: 8079  total_loss: 0.1098  loss_cls: 3.228e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01332  loss_rpn_loc: 0.09527  time: 0.3848  data_time: 0.0090  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:16:47 d2.utils.events]: \u001b[0m eta: 0:12:16  iter: 8099  total_loss: 0.09916  loss_cls: 4.453e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.08174  time: 0.3848  data_time: 0.0098  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:16:55 d2.utils.events]: \u001b[0m eta: 0:12:09  iter: 8119  total_loss: 0.1146  loss_cls: 5.135e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01646  loss_rpn_loc: 0.09256  time: 0.3848  data_time: 0.0100  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:17:03 d2.utils.events]: \u001b[0m eta: 0:12:00  iter: 8139  total_loss: 0.1174  loss_cls: 3.331e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01499  loss_rpn_loc: 0.09978  time: 0.3848  data_time: 0.0085  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:17:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 17:17:10 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 17:17:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 17:17:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 17:17:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0012 s/iter. Inference: 0.0818 s/iter. Eval: 0.0000 s/iter. Total: 0.0830 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 17:17:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.875056 (0.087055 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:17:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081747 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:17:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 17:17:16 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 17:17:16 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 8159  total_loss: 0.0848  loss_cls: 2.397e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01041  loss_rpn_loc: 0.07595  time: 0.3848  data_time: 0.0085  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:17:24 d2.utils.events]: \u001b[0m eta: 0:11:45  iter: 8179  total_loss: 0.1121  loss_cls: 3.071e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01501  loss_rpn_loc: 0.07709  time: 0.3848  data_time: 0.0106  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:17:31 d2.utils.events]: \u001b[0m eta: 0:11:39  iter: 8199  total_loss: 0.1027  loss_cls: 3.78e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01297  loss_rpn_loc: 0.08671  time: 0.3848  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:17:39 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 8219  total_loss: 0.1227  loss_cls: 2.662e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01607  loss_rpn_loc: 0.1109  time: 0.3848  data_time: 0.0137  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:17:47 d2.utils.events]: \u001b[0m eta: 0:11:23  iter: 8239  total_loss: 0.1054  loss_cls: 1.781e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01222  loss_rpn_loc: 0.08761  time: 0.3848  data_time: 0.0085  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:17:54 d2.utils.events]: \u001b[0m eta: 0:11:15  iter: 8259  total_loss: 0.08748  loss_cls: 3.399e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01026  loss_rpn_loc: 0.07926  time: 0.3847  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:18:02 d2.utils.events]: \u001b[0m eta: 0:11:07  iter: 8279  total_loss: 0.1436  loss_cls: 2.528e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01694  loss_rpn_loc: 0.114  time: 0.3848  data_time: 0.0130  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:18:10 d2.utils.events]: \u001b[0m eta: 0:10:59  iter: 8299  total_loss: 0.09782  loss_cls: 3.155e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01494  loss_rpn_loc: 0.08457  time: 0.3847  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:18:17 d2.utils.events]: \u001b[0m eta: 0:10:51  iter: 8319  total_loss: 0.09914  loss_cls: 2.76e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0146  loss_rpn_loc: 0.08302  time: 0.3847  data_time: 0.0082  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:18:25 d2.utils.events]: \u001b[0m eta: 0:10:43  iter: 8339  total_loss: 0.09948  loss_cls: 4.03e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01701  loss_rpn_loc: 0.0822  time: 0.3847  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:18:33 d2.utils.events]: \u001b[0m eta: 0:10:36  iter: 8359  total_loss: 0.128  loss_cls: 3.382e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02576  loss_rpn_loc: 0.09402  time: 0.3847  data_time: 0.0137  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:18:41 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 8379  total_loss: 0.147  loss_cls: 3.316e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02065  loss_rpn_loc: 0.1302  time: 0.3848  data_time: 0.0137  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:18:48 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 8399  total_loss: 0.09551  loss_cls: 2.765e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0156  loss_rpn_loc: 0.07809  time: 0.3848  data_time: 0.0190  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:18:56 d2.utils.events]: \u001b[0m eta: 0:10:13  iter: 8419  total_loss: 0.1065  loss_cls: 5.281e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01781  loss_rpn_loc: 0.08554  time: 0.3848  data_time: 0.0092  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:19:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 17:19:01 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 17:19:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 17:19:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 17:19:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0825 s/iter. Eval: 0.0000 s/iter. Total: 0.0840 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 17:19:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.872713 (0.087013 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:19:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081807 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:19:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 17:19:06 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 17:19:09 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 8439  total_loss: 0.101  loss_cls: 2.918e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01247  loss_rpn_loc: 0.08782  time: 0.3848  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:19:17 d2.utils.events]: \u001b[0m eta: 0:09:58  iter: 8459  total_loss: 0.09221  loss_cls: 1.623e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007839  loss_rpn_loc: 0.07806  time: 0.3848  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:19:25 d2.utils.events]: \u001b[0m eta: 0:09:51  iter: 8479  total_loss: 0.1148  loss_cls: 3.028e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02316  loss_rpn_loc: 0.09748  time: 0.3848  data_time: 0.0134  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:19:33 d2.utils.events]: \u001b[0m eta: 0:09:44  iter: 8499  total_loss: 0.09464  loss_cls: 2.283e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01228  loss_rpn_loc: 0.0805  time: 0.3848  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:19:40 d2.utils.events]: \u001b[0m eta: 0:09:35  iter: 8519  total_loss: 0.1106  loss_cls: 2.853e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01897  loss_rpn_loc: 0.08178  time: 0.3847  data_time: 0.0080  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:19:48 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 8539  total_loss: 0.1237  loss_cls: 4.733e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01883  loss_rpn_loc: 0.1135  time: 0.3847  data_time: 0.0146  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:19:56 d2.utils.events]: \u001b[0m eta: 0:09:20  iter: 8559  total_loss: 0.1203  loss_cls: 5.136e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02062  loss_rpn_loc: 0.09995  time: 0.3848  data_time: 0.0170  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:20:03 d2.utils.events]: \u001b[0m eta: 0:09:13  iter: 8579  total_loss: 0.08315  loss_cls: 2.422e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.005431  loss_rpn_loc: 0.07848  time: 0.3847  data_time: 0.0097  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:20:11 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 8599  total_loss: 0.1159  loss_cls: 3.22e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0212  loss_rpn_loc: 0.09639  time: 0.3848  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:20:19 d2.utils.events]: \u001b[0m eta: 0:08:56  iter: 8619  total_loss: 0.1026  loss_cls: 1.9e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007658  loss_rpn_loc: 0.08699  time: 0.3848  data_time: 0.0148  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:20:27 d2.utils.events]: \u001b[0m eta: 0:08:48  iter: 8639  total_loss: 0.1079  loss_cls: 4.42e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01908  loss_rpn_loc: 0.08644  time: 0.3848  data_time: 0.0117  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:20:34 d2.utils.events]: \u001b[0m eta: 0:08:41  iter: 8659  total_loss: 0.08278  loss_cls: 2.061e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.008237  loss_rpn_loc: 0.07457  time: 0.3847  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:20:42 d2.utils.events]: \u001b[0m eta: 0:08:32  iter: 8679  total_loss: 0.1152  loss_cls: 2.348e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01736  loss_rpn_loc: 0.09586  time: 0.3847  data_time: 0.0089  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:20:49 d2.utils.events]: \u001b[0m eta: 0:08:25  iter: 8699  total_loss: 0.1007  loss_cls: 1.66e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.005842  loss_rpn_loc: 0.09208  time: 0.3847  data_time: 0.0120  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:20:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 17:20:51 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 17:20:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 17:20:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 17:20:52 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0012 s/iter. Inference: 0.0816 s/iter. Eval: 0.0000 s/iter. Total: 0.0828 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 17:20:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.867666 (0.086923 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:20:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081675 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:20:56 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 17:20:56 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 17:21:03 d2.utils.events]: \u001b[0m eta: 0:08:16  iter: 8719  total_loss: 0.09559  loss_cls: 1.838e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007546  loss_rpn_loc: 0.08829  time: 0.3847  data_time: 0.0113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:21:10 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 8739  total_loss: 0.1056  loss_cls: 1.736e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01346  loss_rpn_loc: 0.09075  time: 0.3847  data_time: 0.0132  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:21:18 d2.utils.events]: \u001b[0m eta: 0:08:01  iter: 8759  total_loss: 0.1357  loss_cls: 2.792e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01818  loss_rpn_loc: 0.1151  time: 0.3847  data_time: 0.0181  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:21:26 d2.utils.events]: \u001b[0m eta: 0:07:54  iter: 8779  total_loss: 0.07892  loss_cls: 2.174e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01042  loss_rpn_loc: 0.07196  time: 0.3848  data_time: 0.0098  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:21:33 d2.utils.events]: \u001b[0m eta: 0:07:45  iter: 8799  total_loss: 0.07557  loss_cls: 1.89e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01224  loss_rpn_loc: 0.06891  time: 0.3847  data_time: 0.0088  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:21:41 d2.utils.events]: \u001b[0m eta: 0:07:37  iter: 8819  total_loss: 0.1085  loss_cls: 1.987e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.08589  time: 0.3847  data_time: 0.0116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:21:49 d2.utils.events]: \u001b[0m eta: 0:07:30  iter: 8839  total_loss: 0.1264  loss_cls: 2.391e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02118  loss_rpn_loc: 0.1029  time: 0.3847  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:21:57 d2.utils.events]: \u001b[0m eta: 0:07:22  iter: 8859  total_loss: 0.1094  loss_cls: 3.372e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.008898  loss_rpn_loc: 0.09261  time: 0.3847  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:22:05 d2.utils.events]: \u001b[0m eta: 0:07:14  iter: 8879  total_loss: 0.103  loss_cls: 2.09e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01322  loss_rpn_loc: 0.09104  time: 0.3848  data_time: 0.0156  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:22:12 d2.utils.events]: \u001b[0m eta: 0:07:06  iter: 8899  total_loss: 0.09941  loss_cls: 3.624e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01199  loss_rpn_loc: 0.08342  time: 0.3847  data_time: 0.0107  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:22:20 d2.utils.events]: \u001b[0m eta: 0:06:59  iter: 8919  total_loss: 0.106  loss_cls: 3.658e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01638  loss_rpn_loc: 0.08897  time: 0.3848  data_time: 0.0129  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:22:28 d2.utils.events]: \u001b[0m eta: 0:06:51  iter: 8939  total_loss: 0.09719  loss_cls: 2.258e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01798  loss_rpn_loc: 0.07155  time: 0.3848  data_time: 0.0093  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:22:35 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 8959  total_loss: 0.07581  loss_cls: 3.082e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007669  loss_rpn_loc: 0.0695  time: 0.3847  data_time: 0.0074  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:22:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 17:22:42 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 17:22:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 17:22:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 17:22:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0810 s/iter. Eval: 0.0000 s/iter. Total: 0.0823 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 17:22:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.852486 (0.086652 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:22:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081410 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:22:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 17:22:47 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 17:22:49 d2.utils.events]: \u001b[0m eta: 0:06:35  iter: 8979  total_loss: 0.127  loss_cls: 1.871e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01964  loss_rpn_loc: 0.1072  time: 0.3847  data_time: 0.0097  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:22:56 d2.utils.events]: \u001b[0m eta: 0:06:28  iter: 8999  total_loss: 0.08647  loss_cls: 2.525e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01772  loss_rpn_loc: 0.07395  time: 0.3847  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:23:04 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 9019  total_loss: 0.1284  loss_cls: 2.651e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01836  loss_rpn_loc: 0.1108  time: 0.3847  data_time: 0.0140  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:23:12 d2.utils.events]: \u001b[0m eta: 0:06:12  iter: 9039  total_loss: 0.09058  loss_cls: 2.3e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01167  loss_rpn_loc: 0.08049  time: 0.3847  data_time: 0.0103  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:23:19 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 9059  total_loss: 0.08264  loss_cls: 3.531e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0136  loss_rpn_loc: 0.07025  time: 0.3847  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:23:27 d2.utils.events]: \u001b[0m eta: 0:05:57  iter: 9079  total_loss: 0.09845  loss_cls: 3.099e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.00824  loss_rpn_loc: 0.08212  time: 0.3847  data_time: 0.0138  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:23:35 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 9099  total_loss: 0.09514  loss_cls: 5.124e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01398  loss_rpn_loc: 0.07503  time: 0.3847  data_time: 0.0097  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:23:43 d2.utils.events]: \u001b[0m eta: 0:05:41  iter: 9119  total_loss: 0.1048  loss_cls: 3.135e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01222  loss_rpn_loc: 0.09226  time: 0.3847  data_time: 0.0222  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:23:50 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 9139  total_loss: 0.1378  loss_cls: 5.635e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01925  loss_rpn_loc: 0.1158  time: 0.3847  data_time: 0.0133  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:23:58 d2.utils.events]: \u001b[0m eta: 0:05:25  iter: 9159  total_loss: 0.08792  loss_cls: 3.441e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.008483  loss_rpn_loc: 0.07999  time: 0.3847  data_time: 0.0115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:24:06 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 9179  total_loss: 0.1257  loss_cls: 3.092e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02217  loss_rpn_loc: 0.103  time: 0.3847  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:24:13 d2.utils.events]: \u001b[0m eta: 0:05:10  iter: 9199  total_loss: 0.086  loss_cls: 1.687e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007097  loss_rpn_loc: 0.0818  time: 0.3847  data_time: 0.0093  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:24:21 d2.utils.events]: \u001b[0m eta: 0:05:02  iter: 9219  total_loss: 0.114  loss_cls: 2.953e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01603  loss_rpn_loc: 0.0861  time: 0.3847  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:24:29 d2.utils.events]: \u001b[0m eta: 0:04:54  iter: 9239  total_loss: 0.09489  loss_cls: 1.817e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01502  loss_rpn_loc: 0.0848  time: 0.3847  data_time: 0.0091  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:24:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 17:24:32 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 17:24:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 17:24:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 17:24:33 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0012 s/iter. Inference: 0.0815 s/iter. Eval: 0.0000 s/iter. Total: 0.0827 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 17:24:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.864409 (0.086864 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:24:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081736 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:24:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 17:24:38 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 17:24:43 d2.utils.events]: \u001b[0m eta: 0:04:47  iter: 9259  total_loss: 0.143  loss_cls: 3.045e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02888  loss_rpn_loc: 0.1254  time: 0.3847  data_time: 0.0255  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:24:50 d2.utils.events]: \u001b[0m eta: 0:04:39  iter: 9279  total_loss: 0.09589  loss_cls: 1.96e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01499  loss_rpn_loc: 0.0806  time: 0.3847  data_time: 0.0104  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:24:58 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 9299  total_loss: 0.1091  loss_cls: 2.442e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01334  loss_rpn_loc: 0.09356  time: 0.3847  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:25:06 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 9319  total_loss: 0.1105  loss_cls: 2.463e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01719  loss_rpn_loc: 0.08904  time: 0.3847  data_time: 0.0117  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:25:14 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 9339  total_loss: 0.1088  loss_cls: 1.71e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01402  loss_rpn_loc: 0.09323  time: 0.3847  data_time: 0.0148  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:25:21 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 9359  total_loss: 0.1551  loss_cls: 2.636e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02302  loss_rpn_loc: 0.1148  time: 0.3848  data_time: 0.0135  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:25:29 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 9379  total_loss: 0.1331  loss_cls: 2.22e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.1068  time: 0.3848  data_time: 0.0146  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:25:37 d2.utils.events]: \u001b[0m eta: 0:03:52  iter: 9399  total_loss: 0.08073  loss_cls: 1.658e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01167  loss_rpn_loc: 0.06752  time: 0.3847  data_time: 0.0079  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:25:44 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 9419  total_loss: 0.07464  loss_cls: 1.166e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01131  loss_rpn_loc: 0.06894  time: 0.3847  data_time: 0.0105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:25:52 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 9439  total_loss: 0.1098  loss_cls: 2.705e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01799  loss_rpn_loc: 0.09581  time: 0.3848  data_time: 0.0137  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:26:00 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 9459  total_loss: 0.06652  loss_cls: 5.647e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.004501  loss_rpn_loc: 0.05647  time: 0.3847  data_time: 0.0111  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:26:07 d2.utils.events]: \u001b[0m eta: 0:03:21  iter: 9479  total_loss: 0.09473  loss_cls: 3.79e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01805  loss_rpn_loc: 0.08254  time: 0.3847  data_time: 0.0171  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:26:15 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 9499  total_loss: 0.09607  loss_cls: 2.779e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01398  loss_rpn_loc: 0.09058  time: 0.3847  data_time: 0.0101  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:26:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 17:26:23 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 17:26:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 17:26:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 17:26:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0818 s/iter. Eval: 0.0000 s/iter. Total: 0.0831 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 17:26:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.870543 (0.086974 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:26:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081722 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:26:28 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 17:26:28 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 17:26:28 d2.utils.events]: \u001b[0m eta: 0:03:06  iter: 9519  total_loss: 0.08164  loss_cls: 2.702e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01483  loss_rpn_loc: 0.06676  time: 0.3847  data_time: 0.0080  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:26:36 d2.utils.events]: \u001b[0m eta: 0:02:58  iter: 9539  total_loss: 0.1694  loss_cls: 3.793e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02688  loss_rpn_loc: 0.1411  time: 0.3847  data_time: 0.0136  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:26:44 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 9559  total_loss: 0.08241  loss_cls: 7.213e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.002357  loss_rpn_loc: 0.08016  time: 0.3847  data_time: 0.0083  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:26:51 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 9579  total_loss: 0.1002  loss_cls: 4.305e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01257  loss_rpn_loc: 0.09212  time: 0.3847  data_time: 0.0094  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:26:59 d2.utils.events]: \u001b[0m eta: 0:02:35  iter: 9599  total_loss: 0.1268  loss_cls: 4.161e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01801  loss_rpn_loc: 0.09262  time: 0.3847  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:27:07 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 9619  total_loss: 0.1063  loss_cls: 5.469e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01649  loss_rpn_loc: 0.08362  time: 0.3847  data_time: 0.0151  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:27:14 d2.utils.events]: \u001b[0m eta: 0:02:20  iter: 9639  total_loss: 0.1036  loss_cls: 4.455e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.0153  loss_rpn_loc: 0.08829  time: 0.3847  data_time: 0.0117  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:27:22 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 9659  total_loss: 0.09263  loss_cls: 2.65e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01135  loss_rpn_loc: 0.07379  time: 0.3847  data_time: 0.0125  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:27:30 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 9679  total_loss: 0.07192  loss_cls: 2.52e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.009429  loss_rpn_loc: 0.05732  time: 0.3847  data_time: 0.0078  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:27:38 d2.utils.events]: \u001b[0m eta: 0:01:56  iter: 9699  total_loss: 0.1387  loss_cls: 3.547e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02543  loss_rpn_loc: 0.1134  time: 0.3847  data_time: 0.0189  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:27:45 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 9719  total_loss: 0.08785  loss_cls: 9.17e-06  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01111  loss_rpn_loc: 0.07182  time: 0.3847  data_time: 0.0093  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:27:53 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 9739  total_loss: 0.1028  loss_cls: 2.839e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01754  loss_rpn_loc: 0.08268  time: 0.3847  data_time: 0.0117  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:28:01 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 9759  total_loss: 0.1156  loss_cls: 5.358e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01199  loss_rpn_loc: 0.09249  time: 0.3847  data_time: 0.0122  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:28:09 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 9779  total_loss: 0.1259  loss_cls: 3.303e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01532  loss_rpn_loc: 0.1081  time: 0.3847  data_time: 0.0126  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:28:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 17:28:14 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 17:28:14 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 17:28:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 17:28:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0815 s/iter. Eval: 0.0000 s/iter. Total: 0.0829 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 17:28:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.875511 (0.087063 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:28:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.081772 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:28:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 17:28:19 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n",
      "\u001b[32m[12/27 17:28:22 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 9799  total_loss: 0.1096  loss_cls: 2.697e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01593  loss_rpn_loc: 0.09853  time: 0.3847  data_time: 0.0124  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:28:30 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 9819  total_loss: 0.07608  loss_cls: 4.073e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.007637  loss_rpn_loc: 0.06911  time: 0.3847  data_time: 0.0102  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:28:38 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 9839  total_loss: 0.1079  loss_cls: 4.141e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01199  loss_rpn_loc: 0.09388  time: 0.3848  data_time: 0.0145  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:28:46 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 9859  total_loss: 0.102  loss_cls: 1.988e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.02373  loss_rpn_loc: 0.07509  time: 0.3848  data_time: 0.0106  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:28:53 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 9879  total_loss: 0.09347  loss_cls: 1.749e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01276  loss_rpn_loc: 0.08031  time: 0.3847  data_time: 0.0086  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:29:01 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 9899  total_loss: 0.1084  loss_cls: 2.746e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.008435  loss_rpn_loc: 0.08683  time: 0.3848  data_time: 0.0123  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:29:09 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 9919  total_loss: 0.1073  loss_cls: 4.034e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01427  loss_rpn_loc: 0.08766  time: 0.3848  data_time: 0.0223  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:29:17 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 9939  total_loss: 0.09448  loss_cls: 2.782e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01154  loss_rpn_loc: 0.08092  time: 0.3848  data_time: 0.0116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:29:24 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 9959  total_loss: 0.08707  loss_cls: 3.217e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.008377  loss_rpn_loc: 0.07872  time: 0.3848  data_time: 0.0089  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:29:32 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 9979  total_loss: 0.1261  loss_cls: 1.795e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01482  loss_rpn_loc: 0.1057  time: 0.3848  data_time: 0.0112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:29:42 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 0.09753  loss_cls: 2.097e-05  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.01275  loss_rpn_loc: 0.0825  time: 0.3847  data_time: 0.0109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:29:43 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 1:04:06 (0.3848 s / it)\n",
      "\u001b[32m[12/27 17:29:43 d2.engine.hooks]: \u001b[0mTotal training time: 1:07:47 (0:03:41 on hooks)\n",
      "\u001b[32m[12/27 17:29:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 17:29:43 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 17:29:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
      "\u001b[32m[12/27 17:29:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 17:29:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0012 s/iter. Inference: 0.0826 s/iter. Eval: 0.0000 s/iter. Total: 0.0838 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 17:29:49 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.892116 (0.087359 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:29:49 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082112 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:29:49 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val_2 in csv format:\n",
      "\u001b[32m[12/27 17:29:49 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.45901639344262296\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "trainModel(2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rh-1DMo1_0Fe",
    "outputId": "1593b326-18f3-42ca-9277-0f6f549f8a9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/None\n",
      "\u001b[32m[12/27 17:52:03 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[12/27 17:52:03 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 545 images left.\n",
      "\u001b[32m[12/27 17:52:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[12/27 17:52:03 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/27 17:52:03 d2.data.common]: \u001b[0mSerializing 545 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 17:52:03 d2.data.common]: \u001b[0mSerialized dataset takes 7.77 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (9, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (9,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (32, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (32,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (8, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (8,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/27 17:52:04 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/detectron2/data/detection_utils.py:433: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/usr/local/lib/python3.7/dist-packages/detectron2/data/detection_utils.py:433: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/27 17:52:29 d2.utils.events]: \u001b[0m eta: 1:22:22  iter: 19  total_loss: 2.822  loss_cls: 1.252  loss_box_reg: 0.2487  loss_mask: 0.693  loss_rpn_cls: 0.314  loss_rpn_loc: 0.2942  time: 1.2386  data_time: 0.8289  lr: 2.4976e-05  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:52:59 d2.utils.events]: \u001b[0m eta: 1:26:42  iter: 39  total_loss: 2.741  loss_cls: 1.163  loss_box_reg: 0.3582  loss_mask: 0.6835  loss_rpn_cls: 0.308  loss_rpn_loc: 0.2912  time: 1.3655  data_time: 1.0235  lr: 4.9951e-05  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:53:19 d2.utils.events]: \u001b[0m eta: 1:23:26  iter: 59  total_loss: 2.342  loss_cls: 0.9056  loss_box_reg: 0.09632  loss_mask: 0.639  loss_rpn_cls: 0.3446  loss_rpn_loc: 0.3494  time: 1.2310  data_time: 0.5543  lr: 7.4926e-05  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:53:39 d2.utils.events]: \u001b[0m eta: 1:21:50  iter: 79  total_loss: 2.023  loss_cls: 0.6164  loss_box_reg: 0.2543  loss_mask: 0.6033  loss_rpn_cls: 0.2547  loss_rpn_loc: 0.29  time: 1.1718  data_time: 0.5555  lr: 9.9901e-05  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:54:09 d2.utils.events]: \u001b[0m eta: 1:26:10  iter: 99  total_loss: 1.942  loss_cls: 0.4882  loss_box_reg: 0.2204  loss_mask: 0.6243  loss_rpn_cls: 0.259  loss_rpn_loc: 0.3181  time: 1.2459  data_time: 1.0819  lr: 0.00012488  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:54:42 d2.utils.events]: \u001b[0m eta: 1:30:44  iter: 119  total_loss: 1.846  loss_cls: 0.4535  loss_box_reg: 0.326  loss_mask: 0.5704  loss_rpn_cls: 0.2433  loss_rpn_loc: 0.2935  time: 1.3081  data_time: 1.1521  lr: 0.00014985  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:55:10 d2.utils.events]: \u001b[0m eta: 1:31:14  iter: 139  total_loss: 1.6  loss_cls: 0.3968  loss_box_reg: 0.1758  loss_mask: 0.5232  loss_rpn_cls: 0.2151  loss_rpn_loc: 0.3058  time: 1.3234  data_time: 0.9446  lr: 0.00017483  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:55:29 d2.utils.events]: \u001b[0m eta: 1:29:45  iter: 159  total_loss: 1.566  loss_cls: 0.3991  loss_box_reg: 0.2896  loss_mask: 0.4868  loss_rpn_cls: 0.1502  loss_rpn_loc: 0.2531  time: 1.2748  data_time: 0.5084  lr: 0.0001998  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:55:56 d2.utils.events]: \u001b[0m eta: 1:29:34  iter: 179  total_loss: 1.562  loss_cls: 0.3794  loss_box_reg: 0.2586  loss_mask: 0.4455  loss_rpn_cls: 0.1563  loss_rpn_loc: 0.2777  time: 1.2827  data_time: 0.8966  lr: 0.00022478  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:56:15 d2.utils.events]: \u001b[0m eta: 1:28:08  iter: 199  total_loss: 1.491  loss_cls: 0.3439  loss_box_reg: 0.2895  loss_mask: 0.3889  loss_rpn_cls: 0.1369  loss_rpn_loc: 0.2657  time: 1.2516  data_time: 0.5487  lr: 0.00024975  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:56:34 d2.utils.events]: \u001b[0m eta: 1:26:50  iter: 219  total_loss: 1.406  loss_cls: 0.3194  loss_box_reg: 0.2414  loss_mask: 0.3821  loss_rpn_cls: 0.1487  loss_rpn_loc: 0.2613  time: 1.2229  data_time: 0.5021  lr: 0.00027473  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:56:56 d2.utils.events]: \u001b[0m eta: 1:27:19  iter: 239  total_loss: 1.438  loss_cls: 0.3205  loss_box_reg: 0.2656  loss_mask: 0.3858  loss_rpn_cls: 0.1654  loss_rpn_loc: 0.2648  time: 1.2133  data_time: 0.6505  lr: 0.0002997  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:57:24 d2.utils.events]: \u001b[0m eta: 1:27:09  iter: 259  total_loss: 1.399  loss_cls: 0.3063  loss_box_reg: 0.2259  loss_mask: 0.3594  loss_rpn_cls: 0.1457  loss_rpn_loc: 0.2484  time: 1.2280  data_time: 0.9313  lr: 0.00032468  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:57:37 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 17:57:37 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 17:57:37 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 17:57:37 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 17:57:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0832 s/iter. Eval: 0.0006 s/iter. Total: 0.0854 s/iter. ETA=0:00:04\n",
      "\u001b[32m[12/27 17:57:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:04.915536 (0.087777 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:57:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.082140 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 17:57:43 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 17:57:43 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.00010817263150581451\n",
      "\u001b[32m[12/27 17:57:53 d2.utils.events]: \u001b[0m eta: 1:26:44  iter: 279  total_loss: 1.364  loss_cls: 0.292  loss_box_reg: 0.2711  loss_mask: 0.3396  loss_rpn_cls: 0.1411  loss_rpn_loc: 0.259  time: 1.2207  data_time: 0.6814  lr: 0.00034965  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:58:19 d2.utils.events]: \u001b[0m eta: 1:26:47  iter: 299  total_loss: 1.218  loss_cls: 0.2655  loss_box_reg: 0.1862  loss_mask: 0.3117  loss_rpn_cls: 0.1174  loss_rpn_loc: 0.2668  time: 1.2247  data_time: 0.8442  lr: 0.00037463  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:58:46 d2.utils.events]: \u001b[0m eta: 1:27:03  iter: 319  total_loss: 1.262  loss_cls: 0.2688  loss_box_reg: 0.216  loss_mask: 0.3241  loss_rpn_cls: 0.1483  loss_rpn_loc: 0.2675  time: 1.2274  data_time: 0.8070  lr: 0.0003996  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:59:11 d2.utils.events]: \u001b[0m eta: 1:27:03  iter: 339  total_loss: 1.253  loss_cls: 0.2761  loss_box_reg: 0.2845  loss_mask: 0.3041  loss_rpn_cls: 0.1118  loss_rpn_loc: 0.2477  time: 1.2275  data_time: 0.7636  lr: 0.00042458  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:59:35 d2.utils.events]: \u001b[0m eta: 1:26:52  iter: 359  total_loss: 1.295  loss_cls: 0.2831  loss_box_reg: 0.2849  loss_mask: 0.301  loss_rpn_cls: 0.1214  loss_rpn_loc: 0.2665  time: 1.2269  data_time: 0.7596  lr: 0.00044955  max_mem: 13868M\n",
      "\u001b[32m[12/27 17:59:52 d2.utils.events]: \u001b[0m eta: 1:25:52  iter: 379  total_loss: 1.239  loss_cls: 0.2637  loss_box_reg: 0.2473  loss_mask: 0.2983  loss_rpn_cls: 0.106  loss_rpn_loc: 0.2166  time: 1.2059  data_time: 0.4095  lr: 0.00047453  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:00:15 d2.utils.events]: \u001b[0m eta: 1:25:41  iter: 399  total_loss: 1.402  loss_cls: 0.2808  loss_box_reg: 0.3379  loss_mask: 0.3281  loss_rpn_cls: 0.1499  loss_rpn_loc: 0.2542  time: 1.2035  data_time: 0.6995  lr: 0.0004995  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:00:40 d2.utils.events]: \u001b[0m eta: 1:25:52  iter: 419  total_loss: 1.118  loss_cls: 0.2233  loss_box_reg: 0.2353  loss_mask: 0.3088  loss_rpn_cls: 0.09825  loss_rpn_loc: 0.2283  time: 1.2068  data_time: 0.8204  lr: 0.00052448  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:00:58 d2.utils.events]: \u001b[0m eta: 1:25:41  iter: 439  total_loss: 1.276  loss_cls: 0.2848  loss_box_reg: 0.3463  loss_mask: 0.3075  loss_rpn_cls: 0.1076  loss_rpn_loc: 0.2386  time: 1.1916  data_time: 0.4495  lr: 0.00054945  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:01:26 d2.utils.events]: \u001b[0m eta: 1:25:58  iter: 459  total_loss: 1.491  loss_cls: 0.3599  loss_box_reg: 0.3678  loss_mask: 0.3119  loss_rpn_cls: 0.143  loss_rpn_loc: 0.2541  time: 1.1998  data_time: 0.9181  lr: 0.00057443  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:01:44 d2.utils.events]: \u001b[0m eta: 1:25:36  iter: 479  total_loss: 1.243  loss_cls: 0.2711  loss_box_reg: 0.309  loss_mask: 0.2911  loss_rpn_cls: 0.1009  loss_rpn_loc: 0.2415  time: 1.1886  data_time: 0.4879  lr: 0.0005994  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:02:07 d2.utils.events]: \u001b[0m eta: 1:25:09  iter: 499  total_loss: 1.317  loss_cls: 0.2771  loss_box_reg: 0.3119  loss_mask: 0.2882  loss_rpn_cls: 0.1278  loss_rpn_loc: 0.2391  time: 1.1866  data_time: 0.6935  lr: 0.00062438  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:02:33 d2.utils.events]: \u001b[0m eta: 1:26:28  iter: 519  total_loss: 1.344  loss_cls: 0.2836  loss_box_reg: 0.2891  loss_mask: 0.3032  loss_rpn_cls: 0.1391  loss_rpn_loc: 0.282  time: 1.1902  data_time: 0.8332  lr: 0.00064935  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:02:54 d2.utils.events]: \u001b[0m eta: 1:25:15  iter: 539  total_loss: 1.149  loss_cls: 0.235  loss_box_reg: 0.2519  loss_mask: 0.2615  loss_rpn_cls: 0.09244  loss_rpn_loc: 0.2323  time: 1.1863  data_time: 0.6453  lr: 0.00067433  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:02:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 18:02:59 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 18:02:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 18:02:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 18:03:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0865 s/iter. Eval: 0.0182 s/iter. Total: 0.1061 s/iter. ETA=0:00:05\n",
      "\u001b[32m[12/27 18:03:06 d2.evaluation.evaluator]: \u001b[0mInference done 60/61. Dataloading: 0.0017 s/iter. Inference: 0.0855 s/iter. Eval: 0.0158 s/iter. Total: 0.1031 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 18:03:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:05.938977 (0.106053 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:03:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.085444 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:03:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 18:03:06 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.04344476797471141\n",
      "\u001b[32m[12/27 18:03:23 d2.utils.events]: \u001b[0m eta: 1:25:04  iter: 559  total_loss: 1.262  loss_cls: 0.2541  loss_box_reg: 0.3254  loss_mask: 0.3126  loss_rpn_cls: 0.1081  loss_rpn_loc: 0.2302  time: 1.1829  data_time: 0.6528  lr: 0.0006993  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:03:53 d2.utils.events]: \u001b[0m eta: 1:27:43  iter: 579  total_loss: 1.718  loss_cls: 0.4507  loss_box_reg: 0.4126  loss_mask: 0.31  loss_rpn_cls: 0.1439  loss_rpn_loc: 0.2701  time: 1.1942  data_time: 1.0269  lr: 0.00072428  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:04:14 d2.utils.events]: \u001b[0m eta: 1:26:25  iter: 599  total_loss: 1.207  loss_cls: 0.231  loss_box_reg: 0.2434  loss_mask: 0.297  loss_rpn_cls: 0.1248  loss_rpn_loc: 0.2464  time: 1.1865  data_time: 0.5267  lr: 0.00074925  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:04:35 d2.utils.events]: \u001b[0m eta: 1:24:55  iter: 619  total_loss: 1.263  loss_cls: 0.2478  loss_box_reg: 0.3437  loss_mask: 0.2957  loss_rpn_cls: 0.1374  loss_rpn_loc: 0.2591  time: 1.1794  data_time: 0.5407  lr: 0.00077423  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:04:58 d2.utils.events]: \u001b[0m eta: 1:24:25  iter: 639  total_loss: 1.157  loss_cls: 0.253  loss_box_reg: 0.2491  loss_mask: 0.3122  loss_rpn_cls: 0.08036  loss_rpn_loc: 0.2267  time: 1.1788  data_time: 0.7287  lr: 0.0007992  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:05:24 d2.utils.events]: \u001b[0m eta: 1:24:33  iter: 659  total_loss: 1.22  loss_cls: 0.2478  loss_box_reg: 0.2764  loss_mask: 0.299  loss_rpn_cls: 0.1174  loss_rpn_loc: 0.2506  time: 1.1830  data_time: 0.8485  lr: 0.00082418  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:05:46 d2.utils.events]: \u001b[0m eta: 1:24:04  iter: 679  total_loss: 1.256  loss_cls: 0.2665  loss_box_reg: 0.3145  loss_mask: 0.2958  loss_rpn_cls: 0.1189  loss_rpn_loc: 0.2407  time: 1.1803  data_time: 0.6381  lr: 0.00084915  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:06:10 d2.utils.events]: \u001b[0m eta: 1:23:46  iter: 699  total_loss: 1.172  loss_cls: 0.2329  loss_box_reg: 0.2454  loss_mask: 0.3104  loss_rpn_cls: 0.1022  loss_rpn_loc: 0.2363  time: 1.1808  data_time: 0.7539  lr: 0.00087413  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:06:32 d2.utils.events]: \u001b[0m eta: 1:23:27  iter: 719  total_loss: 1.174  loss_cls: 0.2325  loss_box_reg: 0.2169  loss_mask: 0.2883  loss_rpn_cls: 0.109  loss_rpn_loc: 0.2453  time: 1.1783  data_time: 0.6540  lr: 0.0008991  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:06:55 d2.utils.events]: \u001b[0m eta: 1:23:06  iter: 739  total_loss: 1.095  loss_cls: 0.2259  loss_box_reg: 0.23  loss_mask: 0.2718  loss_rpn_cls: 0.09042  loss_rpn_loc: 0.2274  time: 1.1775  data_time: 0.7073  lr: 0.00092408  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:07:18 d2.utils.events]: \u001b[0m eta: 1:22:47  iter: 759  total_loss: 1.221  loss_cls: 0.2465  loss_box_reg: 0.3226  loss_mask: 0.3025  loss_rpn_cls: 0.1121  loss_rpn_loc: 0.2384  time: 1.1769  data_time: 0.7164  lr: 0.00094905  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:07:42 d2.utils.events]: \u001b[0m eta: 1:22:36  iter: 779  total_loss: 1.245  loss_cls: 0.2492  loss_box_reg: 0.3109  loss_mask: 0.2977  loss_rpn_cls: 0.1188  loss_rpn_loc: 0.2554  time: 1.1771  data_time: 0.7454  lr: 0.00097403  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:08:09 d2.utils.events]: \u001b[0m eta: 1:22:26  iter: 799  total_loss: 1.167  loss_cls: 0.2192  loss_box_reg: 0.2737  loss_mask: 0.2856  loss_rpn_cls: 0.107  loss_rpn_loc: 0.2265  time: 1.1812  data_time: 0.9021  lr: 0.000999  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:08:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 18:08:31 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 18:08:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 18:08:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 18:08:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0870 s/iter. Eval: 0.0174 s/iter. Total: 0.1060 s/iter. ETA=0:00:05\n",
      "\u001b[32m[12/27 18:08:37 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:05.672014 (0.101286 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:08:37 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.085162 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:08:37 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 18:08:37 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.032646193276540274\n",
      "\u001b[32m[12/27 18:08:41 d2.utils.events]: \u001b[0m eta: 1:22:08  iter: 819  total_loss: 1.161  loss_cls: 0.2392  loss_box_reg: 0.2853  loss_mask: 0.3072  loss_rpn_cls: 0.1075  loss_rpn_loc: 0.2316  time: 1.1834  data_time: 0.8050  lr: 0.001024  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:09:16 d2.utils.events]: \u001b[0m eta: 1:22:33  iter: 839  total_loss: 1.283  loss_cls: 0.2543  loss_box_reg: 0.2788  loss_mask: 0.3022  loss_rpn_cls: 0.1469  loss_rpn_loc: 0.2567  time: 1.1970  data_time: 1.2667  lr: 0.001049  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:09:39 d2.utils.events]: \u001b[0m eta: 1:22:26  iter: 859  total_loss: 1.169  loss_cls: 0.2403  loss_box_reg: 0.3105  loss_mask: 0.2739  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.2559  time: 1.1962  data_time: 0.7014  lr: 0.0010739  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:10:07 d2.utils.events]: \u001b[0m eta: 1:22:51  iter: 879  total_loss: 1.222  loss_cls: 0.2584  loss_box_reg: 0.2447  loss_mask: 0.2988  loss_rpn_cls: 0.111  loss_rpn_loc: 0.2578  time: 1.2002  data_time: 0.8990  lr: 0.0010989  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:10:27 d2.utils.events]: \u001b[0m eta: 1:22:23  iter: 899  total_loss: 1.126  loss_cls: 0.2217  loss_box_reg: 0.263  loss_mask: 0.2908  loss_rpn_cls: 0.08132  loss_rpn_loc: 0.2339  time: 1.1947  data_time: 0.5125  lr: 0.0011239  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:10:45 d2.utils.events]: \u001b[0m eta: 1:21:47  iter: 919  total_loss: 1.05  loss_cls: 0.1793  loss_box_reg: 0.2487  loss_mask: 0.2525  loss_rpn_cls: 0.09157  loss_rpn_loc: 0.2417  time: 1.1870  data_time: 0.4143  lr: 0.0011489  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:11:07 d2.utils.events]: \u001b[0m eta: 1:21:33  iter: 939  total_loss: 1.088  loss_cls: 0.2261  loss_box_reg: 0.1897  loss_mask: 0.2769  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.2194  time: 1.1856  data_time: 0.6861  lr: 0.0011738  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:11:35 d2.utils.events]: \u001b[0m eta: 1:21:15  iter: 959  total_loss: 1.241  loss_cls: 0.2544  loss_box_reg: 0.2264  loss_mask: 0.2871  loss_rpn_cls: 0.1238  loss_rpn_loc: 0.2399  time: 1.1897  data_time: 0.9328  lr: 0.0011988  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:11:52 d2.utils.events]: \u001b[0m eta: 1:20:18  iter: 979  total_loss: 0.3042  loss_cls: 0.003738  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.08007  loss_rpn_loc: 0.2049  time: 1.1824  data_time: 0.4098  lr: 0.0012238  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:12:21 d2.utils.events]: \u001b[0m eta: 1:20:46  iter: 999  total_loss: 1.23  loss_cls: 0.2524  loss_box_reg: 0.3279  loss_mask: 0.3198  loss_rpn_cls: 0.1177  loss_rpn_loc: 0.2281  time: 1.1883  data_time: 1.0163  lr: 0.0012488  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:12:51 d2.utils.events]: \u001b[0m eta: 1:20:43  iter: 1019  total_loss: 1.156  loss_cls: 0.2305  loss_box_reg: 0.2228  loss_mask: 0.2826  loss_rpn_cls: 0.1243  loss_rpn_loc: 0.2404  time: 1.1935  data_time: 0.9960  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:13:17 d2.utils.events]: \u001b[0m eta: 1:20:45  iter: 1039  total_loss: 1.101  loss_cls: 0.2386  loss_box_reg: 0.2907  loss_mask: 0.2858  loss_rpn_cls: 0.1035  loss_rpn_loc: 0.2177  time: 1.1964  data_time: 0.9090  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:13:36 d2.utils.events]: \u001b[0m eta: 1:20:38  iter: 1059  total_loss: 1.124  loss_cls: 0.2012  loss_box_reg: 0.2323  loss_mask: 0.2677  loss_rpn_cls: 0.08471  loss_rpn_loc: 0.2215  time: 1.1914  data_time: 0.4967  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:14:02 d2.utils.events]: \u001b[0m eta: 1:21:56  iter: 1079  total_loss: 1.23  loss_cls: 0.2526  loss_box_reg: 0.3064  loss_mask: 0.3203  loss_rpn_cls: 0.1392  loss_rpn_loc: 0.2362  time: 1.1934  data_time: 0.8366  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:14:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 18:14:08 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 18:14:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 18:14:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 18:14:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0875 s/iter. Eval: 0.0298 s/iter. Total: 0.1187 s/iter. ETA=0:00:05\n",
      "\u001b[32m[12/27 18:14:15 d2.evaluation.evaluator]: \u001b[0mInference done 59/61. Dataloading: 0.0017 s/iter. Inference: 0.0864 s/iter. Eval: 0.0197 s/iter. Total: 0.1079 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 18:14:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.236276 (0.111362 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:14:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.086416 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:14:15 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 18:14:15 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.053910138002097076\n",
      "\u001b[32m[12/27 18:14:29 d2.utils.events]: \u001b[0m eta: 1:20:34  iter: 1099  total_loss: 1.062  loss_cls: 0.2046  loss_box_reg: 0.2329  loss_mask: 0.2513  loss_rpn_cls: 0.09883  loss_rpn_loc: 0.224  time: 1.1891  data_time: 0.5202  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:15:01 d2.utils.events]: \u001b[0m eta: 1:20:00  iter: 1119  total_loss: 1.263  loss_cls: 0.2377  loss_box_reg: 0.2883  loss_mask: 0.3026  loss_rpn_cls: 0.1211  loss_rpn_loc: 0.256  time: 1.1968  data_time: 1.1682  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:15:23 d2.utils.events]: \u001b[0m eta: 1:19:23  iter: 1139  total_loss: 1.162  loss_cls: 0.2175  loss_box_reg: 0.2576  loss_mask: 0.2799  loss_rpn_cls: 0.09136  loss_rpn_loc: 0.2524  time: 1.1954  data_time: 0.6915  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:15:47 d2.utils.events]: \u001b[0m eta: 1:19:35  iter: 1159  total_loss: 1.238  loss_cls: 0.2785  loss_box_reg: 0.3263  loss_mask: 0.2929  loss_rpn_cls: 0.1036  loss_rpn_loc: 0.2308  time: 1.1955  data_time: 0.7507  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:16:09 d2.utils.events]: \u001b[0m eta: 1:19:16  iter: 1179  total_loss: 1.193  loss_cls: 0.2295  loss_box_reg: 0.3082  loss_mask: 0.303  loss_rpn_cls: 0.08922  loss_rpn_loc: 0.2387  time: 1.1936  data_time: 0.6384  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:16:31 d2.utils.events]: \u001b[0m eta: 1:19:06  iter: 1199  total_loss: 1.041  loss_cls: 0.1898  loss_box_reg: 0.2009  loss_mask: 0.2475  loss_rpn_cls: 0.08741  loss_rpn_loc: 0.2116  time: 1.1910  data_time: 0.6060  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:16:50 d2.utils.events]: \u001b[0m eta: 1:18:55  iter: 1219  total_loss: 0.7474  loss_cls: 0.1166  loss_box_reg: 0.1247  loss_mask: 0.1162  loss_rpn_cls: 0.06842  loss_rpn_loc: 0.208  time: 1.1860  data_time: 0.4626  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:17:08 d2.utils.events]: \u001b[0m eta: 1:18:21  iter: 1239  total_loss: 1.157  loss_cls: 0.2079  loss_box_reg: 0.2564  loss_mask: 0.2552  loss_rpn_cls: 0.08396  loss_rpn_loc: 0.2188  time: 1.1813  data_time: 0.4679  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:17:37 d2.utils.events]: \u001b[0m eta: 1:18:41  iter: 1259  total_loss: 1.276  loss_cls: 0.2575  loss_box_reg: 0.3292  loss_mask: 0.3146  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.2475  time: 1.1853  data_time: 0.9937  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:17:58 d2.utils.events]: \u001b[0m eta: 1:18:33  iter: 1279  total_loss: 1.131  loss_cls: 0.2125  loss_box_reg: 0.2587  loss_mask: 0.2828  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.2396  time: 1.1836  data_time: 0.6342  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:18:19 d2.utils.events]: \u001b[0m eta: 1:18:12  iter: 1299  total_loss: 1.062  loss_cls: 0.2292  loss_box_reg: 0.2659  loss_mask: 0.2702  loss_rpn_cls: 0.113  loss_rpn_loc: 0.221  time: 1.1815  data_time: 0.6050  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:18:46 d2.utils.events]: \u001b[0m eta: 1:18:08  iter: 1319  total_loss: 1.165  loss_cls: 0.2524  loss_box_reg: 0.2555  loss_mask: 0.2832  loss_rpn_cls: 0.09121  loss_rpn_loc: 0.2389  time: 1.1839  data_time: 0.8822  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:19:19 d2.utils.events]: \u001b[0m eta: 1:18:06  iter: 1339  total_loss: 1.301  loss_cls: 0.2435  loss_box_reg: 0.3108  loss_mask: 0.305  loss_rpn_cls: 0.1225  loss_rpn_loc: 0.2712  time: 1.1910  data_time: 1.1956  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:19:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 18:19:40 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 18:19:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 18:19:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 18:19:42 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0894 s/iter. Eval: 0.0304 s/iter. Total: 0.1214 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 18:19:47 d2.evaluation.evaluator]: \u001b[0mInference done 58/61. Dataloading: 0.0018 s/iter. Inference: 0.0870 s/iter. Eval: 0.0198 s/iter. Total: 0.1087 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 18:19:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.337846 (0.113176 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:19:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087185 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:19:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 18:19:47 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0550106259799145\n",
      "\u001b[32m[12/27 18:19:47 d2.utils.events]: \u001b[0m eta: 1:17:47  iter: 1359  total_loss: 1.065  loss_cls: 0.2186  loss_box_reg: 0.2574  loss_mask: 0.2733  loss_rpn_cls: 0.08375  loss_rpn_loc: 0.2093  time: 1.1887  data_time: 0.5962  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:20:07 d2.utils.events]: \u001b[0m eta: 1:18:00  iter: 1379  total_loss: 1.191  loss_cls: 0.2331  loss_box_reg: 0.3276  loss_mask: 0.2753  loss_rpn_cls: 0.09144  loss_rpn_loc: 0.2211  time: 1.1860  data_time: 0.5611  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:20:34 d2.utils.events]: \u001b[0m eta: 1:17:33  iter: 1399  total_loss: 0.6759  loss_cls: 0.1036  loss_box_reg: 0.07079  loss_mask: 0.1273  loss_rpn_cls: 0.1025  loss_rpn_loc: 0.2074  time: 1.1880  data_time: 0.8618  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:20:55 d2.utils.events]: \u001b[0m eta: 1:17:19  iter: 1419  total_loss: 1.105  loss_cls: 0.2065  loss_box_reg: 0.2514  loss_mask: 0.2857  loss_rpn_cls: 0.08348  loss_rpn_loc: 0.2261  time: 1.1861  data_time: 0.6138  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:21:21 d2.utils.events]: \u001b[0m eta: 1:16:57  iter: 1439  total_loss: 1.042  loss_cls: 0.1954  loss_box_reg: 0.2345  loss_mask: 0.2651  loss_rpn_cls: 0.07536  loss_rpn_loc: 0.2214  time: 1.1873  data_time: 0.8109  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:21:39 d2.utils.events]: \u001b[0m eta: 1:15:37  iter: 1459  total_loss: 1.166  loss_cls: 0.2366  loss_box_reg: 0.2988  loss_mask: 0.2747  loss_rpn_cls: 0.08799  loss_rpn_loc: 0.2317  time: 1.1838  data_time: 0.4783  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:22:12 d2.utils.events]: \u001b[0m eta: 1:16:31  iter: 1479  total_loss: 1.261  loss_cls: 0.2421  loss_box_reg: 0.3025  loss_mask: 0.2828  loss_rpn_cls: 0.1228  loss_rpn_loc: 0.2439  time: 1.1899  data_time: 1.1666  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:22:34 d2.utils.events]: \u001b[0m eta: 1:16:09  iter: 1499  total_loss: 0.8695  loss_cls: 0.1861  loss_box_reg: 0.2171  loss_mask: 0.2169  loss_rpn_cls: 0.08946  loss_rpn_loc: 0.2107  time: 1.1879  data_time: 0.6164  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:22:58 d2.utils.events]: \u001b[0m eta: 1:15:05  iter: 1519  total_loss: 1.04  loss_cls: 0.2042  loss_box_reg: 0.2108  loss_mask: 0.294  loss_rpn_cls: 0.0929  loss_rpn_loc: 0.2683  time: 1.1870  data_time: 0.6663  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:23:16 d2.utils.events]: \u001b[0m eta: 1:15:33  iter: 1539  total_loss: 1.087  loss_cls: 0.2192  loss_box_reg: 0.275  loss_mask: 0.264  loss_rpn_cls: 0.08717  loss_rpn_loc: 0.2218  time: 1.1834  data_time: 0.4945  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:23:42 d2.utils.events]: \u001b[0m eta: 1:15:48  iter: 1559  total_loss: 1.145  loss_cls: 0.2435  loss_box_reg: 0.2333  loss_mask: 0.3059  loss_rpn_cls: 0.1061  loss_rpn_loc: 0.222  time: 1.1852  data_time: 0.8617  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:24:07 d2.utils.events]: \u001b[0m eta: 1:15:12  iter: 1579  total_loss: 1.248  loss_cls: 0.2375  loss_box_reg: 0.2728  loss_mask: 0.2906  loss_rpn_cls: 0.1062  loss_rpn_loc: 0.2457  time: 1.1854  data_time: 0.7545  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:24:34 d2.utils.events]: \u001b[0m eta: 1:15:01  iter: 1599  total_loss: 1.129  loss_cls: 0.2381  loss_box_reg: 0.3141  loss_mask: 0.2684  loss_rpn_cls: 0.08358  loss_rpn_loc: 0.2295  time: 1.1875  data_time: 0.9141  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:24:56 d2.utils.events]: \u001b[0m eta: 1:14:51  iter: 1619  total_loss: 1.157  loss_cls: 0.2392  loss_box_reg: 0.3186  loss_mask: 0.2891  loss_rpn_cls: 0.1084  loss_rpn_loc: 0.2044  time: 1.1869  data_time: 0.6994  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:25:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 18:25:12 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 18:25:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 18:25:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 18:25:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0017 s/iter. Inference: 0.0890 s/iter. Eval: 0.0318 s/iter. Total: 0.1225 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 18:25:19 d2.evaluation.evaluator]: \u001b[0mInference done 58/61. Dataloading: 0.0018 s/iter. Inference: 0.0869 s/iter. Eval: 0.0206 s/iter. Total: 0.1094 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 18:25:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.395267 (0.114201 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:25:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087175 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:25:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 18:25:19 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.05624246630940861\n",
      "\u001b[32m[12/27 18:25:26 d2.utils.events]: \u001b[0m eta: 1:14:40  iter: 1639  total_loss: 1.181  loss_cls: 0.2453  loss_box_reg: 0.2279  loss_mask: 0.2961  loss_rpn_cls: 0.1085  loss_rpn_loc: 0.2332  time: 1.1862  data_time: 0.6696  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:25:55 d2.utils.events]: \u001b[0m eta: 1:14:45  iter: 1659  total_loss: 1.202  loss_cls: 0.2489  loss_box_reg: 0.2769  loss_mask: 0.2962  loss_rpn_cls: 0.1134  loss_rpn_loc: 0.235  time: 1.1893  data_time: 0.9731  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:26:19 d2.utils.events]: \u001b[0m eta: 1:14:48  iter: 1679  total_loss: 1.192  loss_cls: 0.2418  loss_box_reg: 0.2867  loss_mask: 0.2947  loss_rpn_cls: 0.08953  loss_rpn_loc: 0.2397  time: 1.1893  data_time: 0.7201  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:26:39 d2.utils.events]: \u001b[0m eta: 1:14:47  iter: 1699  total_loss: 1.15  loss_cls: 0.2583  loss_box_reg: 0.285  loss_mask: 0.2692  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.227  time: 1.1868  data_time: 0.5402  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:27:00 d2.utils.events]: \u001b[0m eta: 1:14:59  iter: 1719  total_loss: 1.185  loss_cls: 0.2323  loss_box_reg: 0.2913  loss_mask: 0.2887  loss_rpn_cls: 0.09287  loss_rpn_loc: 0.2127  time: 1.1851  data_time: 0.5958  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:27:17 d2.utils.events]: \u001b[0m eta: 1:14:48  iter: 1739  total_loss: 1.044  loss_cls: 0.1996  loss_box_reg: 0.2548  loss_mask: 0.2676  loss_rpn_cls: 0.0999  loss_rpn_loc: 0.2551  time: 1.1817  data_time: 0.4571  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:27:42 d2.utils.events]: \u001b[0m eta: 1:14:49  iter: 1759  total_loss: 1.201  loss_cls: 0.2336  loss_box_reg: 0.2868  loss_mask: 0.304  loss_rpn_cls: 0.09611  loss_rpn_loc: 0.243  time: 1.1824  data_time: 0.7881  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:28:05 d2.utils.events]: \u001b[0m eta: 1:15:08  iter: 1779  total_loss: 1.044  loss_cls: 0.1907  loss_box_reg: 0.2249  loss_mask: 0.2699  loss_rpn_cls: 0.08301  loss_rpn_loc: 0.2197  time: 1.1817  data_time: 0.6619  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:28:25 d2.utils.events]: \u001b[0m eta: 1:14:51  iter: 1799  total_loss: 1.118  loss_cls: 0.238  loss_box_reg: 0.2749  loss_mask: 0.2809  loss_rpn_cls: 0.09239  loss_rpn_loc: 0.2127  time: 1.1792  data_time: 0.5207  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:28:52 d2.utils.events]: \u001b[0m eta: 1:14:52  iter: 1819  total_loss: 1.118  loss_cls: 0.2052  loss_box_reg: 0.2692  loss_mask: 0.2882  loss_rpn_cls: 0.07866  loss_rpn_loc: 0.2228  time: 1.1805  data_time: 0.8532  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:29:22 d2.utils.events]: \u001b[0m eta: 1:13:45  iter: 1839  total_loss: 1.223  loss_cls: 0.2327  loss_box_reg: 0.316  loss_mask: 0.2857  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.2525  time: 1.1835  data_time: 0.9868  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:29:46 d2.utils.events]: \u001b[0m eta: 1:13:21  iter: 1859  total_loss: 1.024  loss_cls: 0.2006  loss_box_reg: 0.1884  loss_mask: 0.2731  loss_rpn_cls: 0.07506  loss_rpn_loc: 0.2129  time: 1.1841  data_time: 0.8034  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:30:05 d2.utils.events]: \u001b[0m eta: 1:13:00  iter: 1879  total_loss: 1.16  loss_cls: 0.2291  loss_box_reg: 0.2741  loss_mask: 0.2803  loss_rpn_cls: 0.1014  loss_rpn_loc: 0.2258  time: 1.1813  data_time: 0.4858  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:30:27 d2.utils.events]: \u001b[0m eta: 1:12:45  iter: 1899  total_loss: 0.9954  loss_cls: 0.1894  loss_box_reg: 0.191  loss_mask: 0.2808  loss_rpn_cls: 0.06594  loss_rpn_loc: 0.2274  time: 1.1806  data_time: 0.6776  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:30:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 18:30:32 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 18:30:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 18:30:32 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 18:30:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0018 s/iter. Inference: 0.0916 s/iter. Eval: 0.0441 s/iter. Total: 0.1375 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 18:30:39 d2.evaluation.evaluator]: \u001b[0mInference done 57/61. Dataloading: 0.0018 s/iter. Inference: 0.0871 s/iter. Eval: 0.0235 s/iter. Total: 0.1125 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 18:30:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.583404 (0.117561 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:30:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087415 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:30:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 18:30:40 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0603210304552905\n",
      "\u001b[32m[12/27 18:31:00 d2.utils.events]: \u001b[0m eta: 1:13:01  iter: 1919  total_loss: 1.108  loss_cls: 0.2185  loss_box_reg: 0.2479  loss_mask: 0.3014  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.2353  time: 1.1813  data_time: 0.8061  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:31:25 d2.utils.events]: \u001b[0m eta: 1:12:43  iter: 1939  total_loss: 1.098  loss_cls: 0.2  loss_box_reg: 0.2202  loss_mask: 0.2743  loss_rpn_cls: 0.09873  loss_rpn_loc: 0.2235  time: 1.1819  data_time: 0.8004  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:31:54 d2.utils.events]: \u001b[0m eta: 1:13:27  iter: 1959  total_loss: 1.11  loss_cls: 0.2123  loss_box_reg: 0.241  loss_mask: 0.2769  loss_rpn_cls: 0.1031  loss_rpn_loc: 0.2326  time: 1.1847  data_time: 0.9917  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:32:16 d2.utils.events]: \u001b[0m eta: 1:14:03  iter: 1979  total_loss: 1.022  loss_cls: 0.2052  loss_box_reg: 0.2597  loss_mask: 0.2577  loss_rpn_cls: 0.06896  loss_rpn_loc: 0.2249  time: 1.1837  data_time: 0.6620  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:32:42 d2.utils.events]: \u001b[0m eta: 1:13:02  iter: 1999  total_loss: 1.131  loss_cls: 0.2432  loss_box_reg: 0.2559  loss_mask: 0.273  loss_rpn_cls: 0.06091  loss_rpn_loc: 0.2074  time: 1.1852  data_time: 0.8724  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:33:06 d2.utils.events]: \u001b[0m eta: 1:12:36  iter: 2019  total_loss: 1.167  loss_cls: 0.2052  loss_box_reg: 0.2637  loss_mask: 0.2816  loss_rpn_cls: 0.09472  loss_rpn_loc: 0.2408  time: 1.1851  data_time: 0.7573  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:33:27 d2.utils.events]: \u001b[0m eta: 1:11:56  iter: 2039  total_loss: 1.162  loss_cls: 0.261  loss_box_reg: 0.2746  loss_mask: 0.2618  loss_rpn_cls: 0.1084  loss_rpn_loc: 0.2307  time: 1.1840  data_time: 0.6215  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:33:51 d2.utils.events]: \u001b[0m eta: 1:12:00  iter: 2059  total_loss: 1.081  loss_cls: 0.2258  loss_box_reg: 0.2716  loss_mask: 0.2883  loss_rpn_cls: 0.1082  loss_rpn_loc: 0.2037  time: 1.1841  data_time: 0.7593  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:34:13 d2.utils.events]: \u001b[0m eta: 1:11:13  iter: 2079  total_loss: 1.108  loss_cls: 0.2222  loss_box_reg: 0.2544  loss_mask: 0.2547  loss_rpn_cls: 0.07924  loss_rpn_loc: 0.2023  time: 1.1832  data_time: 0.6535  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:34:43 d2.utils.events]: \u001b[0m eta: 1:11:32  iter: 2099  total_loss: 1.119  loss_cls: 0.2316  loss_box_reg: 0.2765  loss_mask: 0.2952  loss_rpn_cls: 0.1113  loss_rpn_loc: 0.2254  time: 1.1857  data_time: 0.9880  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:35:15 d2.utils.events]: \u001b[0m eta: 1:11:13  iter: 2119  total_loss: 1.091  loss_cls: 0.2131  loss_box_reg: 0.2381  loss_mask: 0.2853  loss_rpn_cls: 0.1027  loss_rpn_loc: 0.2348  time: 1.1887  data_time: 1.0493  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:35:32 d2.utils.events]: \u001b[0m eta: 1:11:10  iter: 2139  total_loss: 1.069  loss_cls: 0.2229  loss_box_reg: 0.2492  loss_mask: 0.2774  loss_rpn_cls: 0.08282  loss_rpn_loc: 0.2121  time: 1.1856  data_time: 0.4304  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:35:56 d2.utils.events]: \u001b[0m eta: 1:10:39  iter: 2159  total_loss: 1.122  loss_cls: 0.2413  loss_box_reg: 0.2686  loss_mask: 0.2889  loss_rpn_cls: 0.1073  loss_rpn_loc: 0.2358  time: 1.1859  data_time: 0.7767  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:36:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 18:36:13 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 18:36:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 18:36:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 18:36:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0883 s/iter. Eval: 0.0371 s/iter. Total: 0.1268 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 18:36:20 d2.evaluation.evaluator]: \u001b[0mInference done 58/61. Dataloading: 0.0016 s/iter. Inference: 0.0864 s/iter. Eval: 0.0219 s/iter. Total: 0.1101 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 18:36:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.455984 (0.115285 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:36:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.086795 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:36:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 18:36:21 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.060294644438134044\n",
      "\u001b[32m[12/27 18:36:23 d2.utils.events]: \u001b[0m eta: 1:10:28  iter: 2179  total_loss: 1.197  loss_cls: 0.2298  loss_box_reg: 0.3026  loss_mask: 0.2733  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.222  time: 1.1837  data_time: 0.5090  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:36:48 d2.utils.events]: \u001b[0m eta: 1:10:22  iter: 2199  total_loss: 1.081  loss_cls: 0.1998  loss_box_reg: 0.2337  loss_mask: 0.2846  loss_rpn_cls: 0.09204  loss_rpn_loc: 0.2275  time: 1.1843  data_time: 0.7896  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:37:06 d2.utils.events]: \u001b[0m eta: 1:10:04  iter: 2219  total_loss: 1.142  loss_cls: 0.1939  loss_box_reg: 0.2635  loss_mask: 0.2633  loss_rpn_cls: 0.0882  loss_rpn_loc: 0.221  time: 1.1820  data_time: 0.4935  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:37:35 d2.utils.events]: \u001b[0m eta: 1:10:16  iter: 2239  total_loss: 1.134  loss_cls: 0.2361  loss_box_reg: 0.2614  loss_mask: 0.2918  loss_rpn_cls: 0.1024  loss_rpn_loc: 0.2339  time: 1.1843  data_time: 0.9662  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:38:01 d2.utils.events]: \u001b[0m eta: 1:09:42  iter: 2259  total_loss: 1.119  loss_cls: 0.1948  loss_box_reg: 0.241  loss_mask: 0.279  loss_rpn_cls: 0.0962  loss_rpn_loc: 0.2201  time: 1.1854  data_time: 0.8548  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:38:25 d2.utils.events]: \u001b[0m eta: 1:09:46  iter: 2279  total_loss: 1.111  loss_cls: 0.2254  loss_box_reg: 0.266  loss_mask: 0.272  loss_rpn_cls: 0.08539  loss_rpn_loc: 0.2244  time: 1.1855  data_time: 0.7371  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:38:43 d2.utils.events]: \u001b[0m eta: 1:09:28  iter: 2299  total_loss: 1.057  loss_cls: 0.2034  loss_box_reg: 0.2397  loss_mask: 0.2621  loss_rpn_cls: 0.07252  loss_rpn_loc: 0.2202  time: 1.1827  data_time: 0.4432  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:39:11 d2.utils.events]: \u001b[0m eta: 1:09:03  iter: 2319  total_loss: 1.24  loss_cls: 0.2503  loss_box_reg: 0.3669  loss_mask: 0.2849  loss_rpn_cls: 0.1249  loss_rpn_loc: 0.2407  time: 1.1849  data_time: 0.9635  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:39:30 d2.utils.events]: \u001b[0m eta: 1:08:18  iter: 2339  total_loss: 0.9701  loss_cls: 0.1909  loss_box_reg: 0.2257  loss_mask: 0.2473  loss_rpn_cls: 0.07131  loss_rpn_loc: 0.2016  time: 1.1825  data_time: 0.4721  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:39:51 d2.utils.events]: \u001b[0m eta: 1:08:23  iter: 2359  total_loss: 1.163  loss_cls: 0.2298  loss_box_reg: 0.2939  loss_mask: 0.2946  loss_rpn_cls: 0.08556  loss_rpn_loc: 0.2159  time: 1.1816  data_time: 0.6355  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:40:18 d2.utils.events]: \u001b[0m eta: 1:08:16  iter: 2379  total_loss: 1.191  loss_cls: 0.2337  loss_box_reg: 0.2607  loss_mask: 0.3023  loss_rpn_cls: 0.1069  loss_rpn_loc: 0.2557  time: 1.1830  data_time: 0.8969  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:40:42 d2.utils.events]: \u001b[0m eta: 1:08:22  iter: 2399  total_loss: 1.113  loss_cls: 0.21  loss_box_reg: 0.2264  loss_mask: 0.289  loss_rpn_cls: 0.0997  loss_rpn_loc: 0.2223  time: 1.1826  data_time: 0.6930  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:41:05 d2.utils.events]: \u001b[0m eta: 1:07:54  iter: 2419  total_loss: 1.096  loss_cls: 0.197  loss_box_reg: 0.2452  loss_mask: 0.2708  loss_rpn_cls: 0.09991  loss_rpn_loc: 0.2179  time: 1.1817  data_time: 0.6277  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:41:21 d2.utils.events]: \u001b[0m eta: 1:07:40  iter: 2439  total_loss: 1.142  loss_cls: 0.1993  loss_box_reg: 0.2552  loss_mask: 0.2817  loss_rpn_cls: 0.09654  loss_rpn_loc: 0.2136  time: 1.1785  data_time: 0.3752  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:41:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 18:41:33 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 18:41:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 18:41:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 18:41:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0877 s/iter. Eval: 0.0290 s/iter. Total: 0.1181 s/iter. ETA=0:00:05\n",
      "\u001b[32m[12/27 18:41:40 d2.evaluation.evaluator]: \u001b[0mInference done 59/61. Dataloading: 0.0016 s/iter. Inference: 0.0863 s/iter. Eval: 0.0211 s/iter. Total: 0.1090 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 18:41:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.299623 (0.112493 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:41:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.086335 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:41:41 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 18:41:41 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.056329621857206955\n",
      "\u001b[32m[12/27 18:41:53 d2.utils.events]: \u001b[0m eta: 1:07:41  iter: 2459  total_loss: 1.089  loss_cls: 0.2224  loss_box_reg: 0.279  loss_mask: 0.2925  loss_rpn_cls: 0.1125  loss_rpn_loc: 0.2266  time: 1.1791  data_time: 0.8049  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:42:12 d2.utils.events]: \u001b[0m eta: 1:07:03  iter: 2479  total_loss: 1.13  loss_cls: 0.2085  loss_box_reg: 0.2777  loss_mask: 0.2827  loss_rpn_cls: 0.08472  loss_rpn_loc: 0.2249  time: 1.1772  data_time: 0.5211  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:42:36 d2.utils.events]: \u001b[0m eta: 1:07:34  iter: 2499  total_loss: 1.17  loss_cls: 0.2315  loss_box_reg: 0.2397  loss_mask: 0.3051  loss_rpn_cls: 0.0819  loss_rpn_loc: 0.2266  time: 1.1776  data_time: 0.7546  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:43:11 d2.utils.events]: \u001b[0m eta: 1:07:39  iter: 2519  total_loss: 1.104  loss_cls: 0.2144  loss_box_reg: 0.2777  loss_mask: 0.2975  loss_rpn_cls: 0.1043  loss_rpn_loc: 0.2254  time: 1.1820  data_time: 1.2431  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:43:32 d2.utils.events]: \u001b[0m eta: 1:07:46  iter: 2539  total_loss: 1.104  loss_cls: 0.2214  loss_box_reg: 0.2842  loss_mask: 0.2957  loss_rpn_cls: 0.09545  loss_rpn_loc: 0.2176  time: 1.1810  data_time: 0.6290  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:43:54 d2.utils.events]: \u001b[0m eta: 1:06:55  iter: 2559  total_loss: 1.067  loss_cls: 0.2046  loss_box_reg: 0.255  loss_mask: 0.2494  loss_rpn_cls: 0.07132  loss_rpn_loc: 0.2148  time: 1.1803  data_time: 0.6561  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:44:18 d2.utils.events]: \u001b[0m eta: 1:06:36  iter: 2579  total_loss: 1.077  loss_cls: 0.2095  loss_box_reg: 0.2663  loss_mask: 0.2734  loss_rpn_cls: 0.09023  loss_rpn_loc: 0.2065  time: 1.1806  data_time: 0.7530  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:44:49 d2.utils.events]: \u001b[0m eta: 1:07:13  iter: 2599  total_loss: 1.166  loss_cls: 0.2248  loss_box_reg: 0.2665  loss_mask: 0.308  loss_rpn_cls: 0.09445  loss_rpn_loc: 0.2394  time: 1.1831  data_time: 1.0434  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:45:04 d2.utils.events]: \u001b[0m eta: 1:06:42  iter: 2619  total_loss: 0.6366  loss_cls: 0.09263  loss_box_reg: 0.0891  loss_mask: 0.1296  loss_rpn_cls: 0.04945  loss_rpn_loc: 0.1917  time: 1.1801  data_time: 0.3690  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:45:32 d2.utils.events]: \u001b[0m eta: 1:07:10  iter: 2639  total_loss: 1.182  loss_cls: 0.2168  loss_box_reg: 0.2455  loss_mask: 0.2914  loss_rpn_cls: 0.08516  loss_rpn_loc: 0.2521  time: 1.1815  data_time: 0.8959  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:45:58 d2.utils.events]: \u001b[0m eta: 1:06:59  iter: 2659  total_loss: 1.169  loss_cls: 0.2516  loss_box_reg: 0.2848  loss_mask: 0.2961  loss_rpn_cls: 0.106  loss_rpn_loc: 0.2342  time: 1.1824  data_time: 0.8523  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:46:15 d2.utils.events]: \u001b[0m eta: 1:06:09  iter: 2679  total_loss: 1.092  loss_cls: 0.2116  loss_box_reg: 0.2582  loss_mask: 0.2794  loss_rpn_cls: 0.08169  loss_rpn_loc: 0.2099  time: 1.1799  data_time: 0.4278  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:46:39 d2.utils.events]: \u001b[0m eta: 1:05:45  iter: 2699  total_loss: 1.095  loss_cls: 0.2221  loss_box_reg: 0.3064  loss_mask: 0.2759  loss_rpn_cls: 0.0858  loss_rpn_loc: 0.2126  time: 1.1796  data_time: 0.6867  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:47:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 18:47:04 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 18:47:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 18:47:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 18:47:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0876 s/iter. Eval: 0.0256 s/iter. Total: 0.1148 s/iter. ETA=0:00:05\n",
      "\u001b[32m[12/27 18:47:10 d2.evaluation.evaluator]: \u001b[0mInference done 59/61. Dataloading: 0.0016 s/iter. Inference: 0.0861 s/iter. Eval: 0.0185 s/iter. Total: 0.1063 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 18:47:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.170444 (0.110187 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:47:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.086216 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:47:11 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 18:47:11 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.052887515797321025\n",
      "\u001b[32m[12/27 18:47:11 d2.utils.events]: \u001b[0m eta: 1:05:17  iter: 2719  total_loss: 1.058  loss_cls: 0.1906  loss_box_reg: 0.2517  loss_mask: 0.2552  loss_rpn_cls: 0.0667  loss_rpn_loc: 0.1982  time: 1.1796  data_time: 0.7344  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:47:36 d2.utils.events]: \u001b[0m eta: 1:05:18  iter: 2739  total_loss: 1.089  loss_cls: 0.2242  loss_box_reg: 0.2512  loss_mask: 0.2934  loss_rpn_cls: 0.0921  loss_rpn_loc: 0.2398  time: 1.1802  data_time: 0.8105  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:48:02 d2.utils.events]: \u001b[0m eta: 1:04:55  iter: 2759  total_loss: 1.106  loss_cls: 0.2033  loss_box_reg: 0.2577  loss_mask: 0.2939  loss_rpn_cls: 0.07453  loss_rpn_loc: 0.2172  time: 1.1810  data_time: 0.8617  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:48:21 d2.utils.events]: \u001b[0m eta: 1:04:22  iter: 2779  total_loss: 0.7895  loss_cls: 0.09533  loss_box_reg: 0.1182  loss_mask: 0.133  loss_rpn_cls: 0.08707  loss_rpn_loc: 0.218  time: 1.1795  data_time: 0.5426  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:48:38 d2.utils.events]: \u001b[0m eta: 1:04:11  iter: 2799  total_loss: 1.107  loss_cls: 0.1908  loss_box_reg: 0.2505  loss_mask: 0.2847  loss_rpn_cls: 0.08116  loss_rpn_loc: 0.2316  time: 1.1769  data_time: 0.3921  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:49:04 d2.utils.events]: \u001b[0m eta: 1:03:52  iter: 2819  total_loss: 1.125  loss_cls: 0.2335  loss_box_reg: 0.2802  loss_mask: 0.2723  loss_rpn_cls: 0.07707  loss_rpn_loc: 0.2262  time: 1.1779  data_time: 0.8754  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:49:29 d2.utils.events]: \u001b[0m eta: 1:03:36  iter: 2839  total_loss: 1.104  loss_cls: 0.2168  loss_box_reg: 0.2502  loss_mask: 0.241  loss_rpn_cls: 0.09998  loss_rpn_loc: 0.2183  time: 1.1782  data_time: 0.7687  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:49:57 d2.utils.events]: \u001b[0m eta: 1:03:33  iter: 2859  total_loss: 1.108  loss_cls: 0.2095  loss_box_reg: 0.2578  loss_mask: 0.2787  loss_rpn_cls: 0.09076  loss_rpn_loc: 0.2163  time: 1.1798  data_time: 0.9387  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:50:18 d2.utils.events]: \u001b[0m eta: 1:03:10  iter: 2879  total_loss: 0.9562  loss_cls: 0.1736  loss_box_reg: 0.2123  loss_mask: 0.2387  loss_rpn_cls: 0.09083  loss_rpn_loc: 0.1981  time: 1.1791  data_time: 0.6440  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:50:46 d2.utils.events]: \u001b[0m eta: 1:03:17  iter: 2899  total_loss: 1.171  loss_cls: 0.2696  loss_box_reg: 0.3381  loss_mask: 0.2804  loss_rpn_cls: 0.08573  loss_rpn_loc: 0.2113  time: 1.1806  data_time: 0.9452  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:51:03 d2.utils.events]: \u001b[0m eta: 1:02:49  iter: 2919  total_loss: 1.001  loss_cls: 0.1895  loss_box_reg: 0.2111  loss_mask: 0.2418  loss_rpn_cls: 0.08988  loss_rpn_loc: 0.2178  time: 1.1782  data_time: 0.4149  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:51:32 d2.utils.events]: \u001b[0m eta: 1:02:55  iter: 2939  total_loss: 1.133  loss_cls: 0.1923  loss_box_reg: 0.2329  loss_mask: 0.3168  loss_rpn_cls: 0.1038  loss_rpn_loc: 0.2337  time: 1.1801  data_time: 0.9991  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:51:55 d2.utils.events]: \u001b[0m eta: 1:02:26  iter: 2959  total_loss: 1.299  loss_cls: 0.2738  loss_box_reg: 0.3833  loss_mask: 0.3009  loss_rpn_cls: 0.09193  loss_rpn_loc: 0.2223  time: 1.1798  data_time: 0.6887  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:52:17 d2.utils.events]: \u001b[0m eta: 1:02:14  iter: 2979  total_loss: 1.077  loss_cls: 0.2102  loss_box_reg: 0.2484  loss_mask: 0.274  loss_rpn_cls: 0.07615  loss_rpn_loc: 0.2093  time: 1.1792  data_time: 0.6313  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:52:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 18:52:29 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 18:52:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 18:52:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 18:52:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0888 s/iter. Eval: 0.0378 s/iter. Total: 0.1281 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 18:52:36 d2.evaluation.evaluator]: \u001b[0mInference done 58/61. Dataloading: 0.0017 s/iter. Inference: 0.0870 s/iter. Eval: 0.0216 s/iter. Total: 0.1104 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 18:52:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.466538 (0.115474 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:52:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087240 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:52:36 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 18:52:36 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06266066324729419\n",
      "\u001b[32m[12/27 18:52:43 d2.utils.events]: \u001b[0m eta: 1:02:05  iter: 2999  total_loss: 1.219  loss_cls: 0.2454  loss_box_reg: 0.2957  loss_mask: 0.2981  loss_rpn_cls: 0.07835  loss_rpn_loc: 0.2221  time: 1.1773  data_time: 0.4434  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:53:08 d2.utils.events]: \u001b[0m eta: 1:01:50  iter: 3019  total_loss: 1.105  loss_cls: 0.2141  loss_box_reg: 0.2543  loss_mask: 0.2756  loss_rpn_cls: 0.09725  loss_rpn_loc: 0.2163  time: 1.1773  data_time: 0.7335  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:53:32 d2.utils.events]: \u001b[0m eta: 1:01:42  iter: 3039  total_loss: 1.105  loss_cls: 0.2113  loss_box_reg: 0.2879  loss_mask: 0.2917  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.2243  time: 1.1773  data_time: 0.7266  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:53:48 d2.utils.events]: \u001b[0m eta: 1:01:22  iter: 3059  total_loss: 0.9736  loss_cls: 0.1922  loss_box_reg: 0.2149  loss_mask: 0.2106  loss_rpn_cls: 0.06163  loss_rpn_loc: 0.212  time: 1.1750  data_time: 0.4154  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:54:08 d2.utils.events]: \u001b[0m eta: 1:01:13  iter: 3079  total_loss: 1.106  loss_cls: 0.2012  loss_box_reg: 0.2637  loss_mask: 0.2544  loss_rpn_cls: 0.08217  loss_rpn_loc: 0.2144  time: 1.1738  data_time: 0.5552  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:54:37 d2.utils.events]: \u001b[0m eta: 1:00:38  iter: 3099  total_loss: 1.109  loss_cls: 0.2321  loss_box_reg: 0.2966  loss_mask: 0.2603  loss_rpn_cls: 0.09027  loss_rpn_loc: 0.2222  time: 1.1755  data_time: 0.9922  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:54:57 d2.utils.events]: \u001b[0m eta: 1:00:21  iter: 3119  total_loss: 0.9908  loss_cls: 0.1832  loss_box_reg: 0.2287  loss_mask: 0.274  loss_rpn_cls: 0.06803  loss_rpn_loc: 0.211  time: 1.1745  data_time: 0.5909  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:55:20 d2.utils.events]: \u001b[0m eta: 1:00:14  iter: 3139  total_loss: 0.7457  loss_cls: 0.07823  loss_box_reg: 0.1178  loss_mask: 0.1153  loss_rpn_cls: 0.07729  loss_rpn_loc: 0.2094  time: 1.1743  data_time: 0.6949  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:55:51 d2.utils.events]: \u001b[0m eta: 1:00:29  iter: 3159  total_loss: 1.207  loss_cls: 0.2621  loss_box_reg: 0.2655  loss_mask: 0.2937  loss_rpn_cls: 0.1214  loss_rpn_loc: 0.2423  time: 1.1765  data_time: 1.0771  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:56:15 d2.utils.events]: \u001b[0m eta: 1:00:20  iter: 3179  total_loss: 1.274  loss_cls: 0.2221  loss_box_reg: 0.3081  loss_mask: 0.2796  loss_rpn_cls: 0.1105  loss_rpn_loc: 0.2241  time: 1.1766  data_time: 0.7479  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:56:44 d2.utils.events]: \u001b[0m eta: 1:00:14  iter: 3199  total_loss: 1.189  loss_cls: 0.2213  loss_box_reg: 0.2897  loss_mask: 0.2979  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.2499  time: 1.1785  data_time: 1.0176  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:57:03 d2.utils.events]: \u001b[0m eta: 1:00:08  iter: 3219  total_loss: 1.066  loss_cls: 0.2349  loss_box_reg: 0.2689  loss_mask: 0.2627  loss_rpn_cls: 0.06839  loss_rpn_loc: 0.2031  time: 1.1772  data_time: 0.5302  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:57:32 d2.utils.events]: \u001b[0m eta: 0:59:59  iter: 3239  total_loss: 1.061  loss_cls: 0.2135  loss_box_reg: 0.2326  loss_mask: 0.2837  loss_rpn_cls: 0.08203  loss_rpn_loc: 0.2197  time: 1.1786  data_time: 0.9747  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:57:53 d2.utils.events]: \u001b[0m eta: 1:00:32  iter: 3259  total_loss: 1.192  loss_cls: 0.2472  loss_box_reg: 0.3123  loss_mask: 0.3177  loss_rpn_cls: 0.08206  loss_rpn_loc: 0.242  time: 1.1779  data_time: 0.6238  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:57:57 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 18:57:57 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 18:57:57 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 18:57:57 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 18:57:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0903 s/iter. Eval: 0.0426 s/iter. Total: 0.1344 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 18:58:04 d2.evaluation.evaluator]: \u001b[0mInference done 55/61. Dataloading: 0.0018 s/iter. Inference: 0.0878 s/iter. Eval: 0.0266 s/iter. Total: 0.1163 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 18:58:05 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.740541 (0.120367 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:58:05 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087997 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 18:58:05 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 18:58:05 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0654565354694393\n",
      "\u001b[32m[12/27 18:58:18 d2.utils.events]: \u001b[0m eta: 0:59:36  iter: 3279  total_loss: 1.027  loss_cls: 0.1901  loss_box_reg: 0.235  loss_mask: 0.2666  loss_rpn_cls: 0.05846  loss_rpn_loc: 0.204  time: 1.1759  data_time: 0.4187  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:58:40 d2.utils.events]: \u001b[0m eta: 0:59:36  iter: 3299  total_loss: 1.052  loss_cls: 0.2106  loss_box_reg: 0.2325  loss_mask: 0.2901  loss_rpn_cls: 0.07997  loss_rpn_loc: 0.1875  time: 1.1752  data_time: 0.6096  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:59:07 d2.utils.events]: \u001b[0m eta: 0:59:11  iter: 3319  total_loss: 1.111  loss_cls: 0.1783  loss_box_reg: 0.2149  loss_mask: 0.3076  loss_rpn_cls: 0.1009  loss_rpn_loc: 0.2092  time: 1.1757  data_time: 0.8040  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:59:31 d2.utils.events]: \u001b[0m eta: 0:59:53  iter: 3339  total_loss: 1.152  loss_cls: 0.2182  loss_box_reg: 0.3078  loss_mask: 0.2846  loss_rpn_cls: 0.0868  loss_rpn_loc: 0.2323  time: 1.1760  data_time: 0.7673  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 18:59:53 d2.utils.events]: \u001b[0m eta: 0:59:42  iter: 3359  total_loss: 1.091  loss_cls: 0.2173  loss_box_reg: 0.2523  loss_mask: 0.2896  loss_rpn_cls: 0.1007  loss_rpn_loc: 0.2259  time: 1.1755  data_time: 0.6493  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:00:13 d2.utils.events]: \u001b[0m eta: 0:59:21  iter: 3379  total_loss: 1.034  loss_cls: 0.2037  loss_box_reg: 0.2168  loss_mask: 0.2569  loss_rpn_cls: 0.07652  loss_rpn_loc: 0.2121  time: 1.1744  data_time: 0.5611  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:00:41 d2.utils.events]: \u001b[0m eta: 0:59:10  iter: 3399  total_loss: 1.174  loss_cls: 0.2282  loss_box_reg: 0.2679  loss_mask: 0.2904  loss_rpn_cls: 0.0966  loss_rpn_loc: 0.2111  time: 1.1758  data_time: 0.9506  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:01:15 d2.utils.events]: \u001b[0m eta: 0:59:43  iter: 3419  total_loss: 1.132  loss_cls: 0.2284  loss_box_reg: 0.2439  loss_mask: 0.2829  loss_rpn_cls: 0.0892  loss_rpn_loc: 0.2432  time: 1.1786  data_time: 1.1822  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:01:44 d2.utils.events]: \u001b[0m eta: 0:59:50  iter: 3439  total_loss: 1.071  loss_cls: 0.2197  loss_box_reg: 0.2391  loss_mask: 0.2911  loss_rpn_cls: 0.07603  loss_rpn_loc: 0.2192  time: 1.1802  data_time: 0.9914  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:02:08 d2.utils.events]: \u001b[0m eta: 0:59:48  iter: 3459  total_loss: 1.103  loss_cls: 0.2142  loss_box_reg: 0.2647  loss_mask: 0.2777  loss_rpn_cls: 0.09745  loss_rpn_loc: 0.2067  time: 1.1805  data_time: 0.7843  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:02:32 d2.utils.events]: \u001b[0m eta: 0:59:37  iter: 3479  total_loss: 1.121  loss_cls: 0.1974  loss_box_reg: 0.2297  loss_mask: 0.2819  loss_rpn_cls: 0.1094  loss_rpn_loc: 0.2392  time: 1.1806  data_time: 0.7480  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:02:58 d2.utils.events]: \u001b[0m eta: 0:59:17  iter: 3499  total_loss: 0.992  loss_cls: 0.2136  loss_box_reg: 0.2275  loss_mask: 0.2696  loss_rpn_cls: 0.07011  loss_rpn_loc: 0.2037  time: 1.1812  data_time: 0.8435  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:03:22 d2.utils.events]: \u001b[0m eta: 0:58:41  iter: 3519  total_loss: 1.144  loss_cls: 0.2238  loss_box_reg: 0.2633  loss_mask: 0.2826  loss_rpn_cls: 0.07837  loss_rpn_loc: 0.2215  time: 1.1812  data_time: 0.7323  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:03:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 19:03:39 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 19:03:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 19:03:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 19:03:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0896 s/iter. Eval: 0.0388 s/iter. Total: 0.1298 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 19:03:46 d2.evaluation.evaluator]: \u001b[0mInference done 57/61. Dataloading: 0.0016 s/iter. Inference: 0.0871 s/iter. Eval: 0.0226 s/iter. Total: 0.1115 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 19:03:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.550834 (0.116979 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:03:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087491 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:03:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 19:03:47 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.061166600350618036\n",
      "\u001b[32m[12/27 19:03:49 d2.utils.events]: \u001b[0m eta: 0:58:02  iter: 3539  total_loss: 1.039  loss_cls: 0.2247  loss_box_reg: 0.2825  loss_mask: 0.2638  loss_rpn_cls: 0.08383  loss_rpn_loc: 0.2287  time: 1.1801  data_time: 0.5564  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:04:07 d2.utils.events]: \u001b[0m eta: 0:57:51  iter: 3559  total_loss: 1.12  loss_cls: 0.242  loss_box_reg: 0.2723  loss_mask: 0.2745  loss_rpn_cls: 0.08637  loss_rpn_loc: 0.214  time: 1.1786  data_time: 0.4826  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:04:34 d2.utils.events]: \u001b[0m eta: 0:57:34  iter: 3579  total_loss: 1.09  loss_cls: 0.2211  loss_box_reg: 0.2683  loss_mask: 0.272  loss_rpn_cls: 0.08927  loss_rpn_loc: 0.2335  time: 1.1793  data_time: 0.8585  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:04:57 d2.utils.events]: \u001b[0m eta: 0:56:46  iter: 3599  total_loss: 1.003  loss_cls: 0.205  loss_box_reg: 0.2026  loss_mask: 0.2708  loss_rpn_cls: 0.07884  loss_rpn_loc: 0.2153  time: 1.1790  data_time: 0.6749  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:05:21 d2.utils.events]: \u001b[0m eta: 0:56:54  iter: 3619  total_loss: 1.046  loss_cls: 0.2083  loss_box_reg: 0.2517  loss_mask: 0.2472  loss_rpn_cls: 0.0776  loss_rpn_loc: 0.2191  time: 1.1787  data_time: 0.6804  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:05:47 d2.utils.events]: \u001b[0m eta: 0:56:25  iter: 3639  total_loss: 1.093  loss_cls: 0.212  loss_box_reg: 0.234  loss_mask: 0.2862  loss_rpn_cls: 0.09023  loss_rpn_loc: 0.2214  time: 1.1792  data_time: 0.8307  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:06:05 d2.utils.events]: \u001b[0m eta: 0:55:52  iter: 3659  total_loss: 1.105  loss_cls: 0.2103  loss_box_reg: 0.2688  loss_mask: 0.283  loss_rpn_cls: 0.07766  loss_rpn_loc: 0.2099  time: 1.1779  data_time: 0.5158  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:06:37 d2.utils.events]: \u001b[0m eta: 0:55:54  iter: 3679  total_loss: 1.043  loss_cls: 0.2259  loss_box_reg: 0.2475  loss_mask: 0.2848  loss_rpn_cls: 0.08658  loss_rpn_loc: 0.2339  time: 1.1801  data_time: 1.1162  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:07:01 d2.utils.events]: \u001b[0m eta: 0:55:46  iter: 3699  total_loss: 1.057  loss_cls: 0.2041  loss_box_reg: 0.2348  loss_mask: 0.2653  loss_rpn_cls: 0.09036  loss_rpn_loc: 0.2172  time: 1.1802  data_time: 0.7665  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:07:16 d2.utils.events]: \u001b[0m eta: 0:55:15  iter: 3719  total_loss: 0.7673  loss_cls: 0.1118  loss_box_reg: 0.1083  loss_mask: 0.1318  loss_rpn_cls: 0.08084  loss_rpn_loc: 0.2124  time: 1.1779  data_time: 0.3353  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:07:38 d2.utils.events]: \u001b[0m eta: 0:55:02  iter: 3739  total_loss: 1.053  loss_cls: 0.2005  loss_box_reg: 0.2406  loss_mask: 0.2593  loss_rpn_cls: 0.07834  loss_rpn_loc: 0.2139  time: 1.1775  data_time: 0.6629  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:08:03 d2.utils.events]: \u001b[0m eta: 0:54:41  iter: 3759  total_loss: 1  loss_cls: 0.1961  loss_box_reg: 0.2012  loss_mask: 0.25  loss_rpn_cls: 0.07405  loss_rpn_loc: 0.1986  time: 1.1777  data_time: 0.7777  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:08:34 d2.utils.events]: \u001b[0m eta: 0:54:49  iter: 3779  total_loss: 1.097  loss_cls: 0.216  loss_box_reg: 0.2709  loss_mask: 0.3027  loss_rpn_cls: 0.0869  loss_rpn_loc: 0.2447  time: 1.1797  data_time: 1.1038  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:09:03 d2.utils.events]: \u001b[0m eta: 0:55:17  iter: 3799  total_loss: 1.198  loss_cls: 0.2404  loss_box_reg: 0.2721  loss_mask: 0.2896  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.2391  time: 1.1813  data_time: 1.0231  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:09:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 19:09:13 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 19:09:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 19:09:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 19:09:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0017 s/iter. Inference: 0.0911 s/iter. Eval: 0.0446 s/iter. Total: 0.1374 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 19:09:20 d2.evaluation.evaluator]: \u001b[0mInference done 57/61. Dataloading: 0.0019 s/iter. Inference: 0.0874 s/iter. Eval: 0.0228 s/iter. Total: 0.1123 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 19:09:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.571961 (0.117356 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:09:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087801 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:09:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 19:09:21 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.061662283759705006\n",
      "\u001b[32m[12/27 19:09:35 d2.utils.events]: \u001b[0m eta: 0:55:47  iter: 3819  total_loss: 1.067  loss_cls: 0.2089  loss_box_reg: 0.2581  loss_mask: 0.2841  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.2253  time: 1.1814  data_time: 0.7220  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:09:52 d2.utils.events]: \u001b[0m eta: 0:55:25  iter: 3839  total_loss: 1.12  loss_cls: 0.2198  loss_box_reg: 0.2736  loss_mask: 0.2844  loss_rpn_cls: 0.08469  loss_rpn_loc: 0.2103  time: 1.1797  data_time: 0.4165  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:10:18 d2.utils.events]: \u001b[0m eta: 0:55:18  iter: 3859  total_loss: 1.117  loss_cls: 0.2084  loss_box_reg: 0.2525  loss_mask: 0.2894  loss_rpn_cls: 0.09879  loss_rpn_loc: 0.2369  time: 1.1803  data_time: 0.8548  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:10:36 d2.utils.events]: \u001b[0m eta: 0:55:14  iter: 3879  total_loss: 1.021  loss_cls: 0.1883  loss_box_reg: 0.2624  loss_mask: 0.259  loss_rpn_cls: 0.07915  loss_rpn_loc: 0.207  time: 1.1788  data_time: 0.4498  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:10:58 d2.utils.events]: \u001b[0m eta: 0:54:16  iter: 3899  total_loss: 1.038  loss_cls: 0.2078  loss_box_reg: 0.2479  loss_mask: 0.2678  loss_rpn_cls: 0.08111  loss_rpn_loc: 0.2206  time: 1.1781  data_time: 0.6295  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:11:23 d2.utils.events]: \u001b[0m eta: 0:54:06  iter: 3919  total_loss: 1.073  loss_cls: 0.2227  loss_box_reg: 0.2806  loss_mask: 0.2785  loss_rpn_cls: 0.08256  loss_rpn_loc: 0.2035  time: 1.1781  data_time: 0.7161  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:11:42 d2.utils.events]: \u001b[0m eta: 0:53:40  iter: 3939  total_loss: 1.053  loss_cls: 0.2063  loss_box_reg: 0.2651  loss_mask: 0.2744  loss_rpn_cls: 0.07141  loss_rpn_loc: 0.2159  time: 1.1770  data_time: 0.5384  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:12:07 d2.utils.events]: \u001b[0m eta: 0:53:28  iter: 3959  total_loss: 1.056  loss_cls: 0.2091  loss_box_reg: 0.2294  loss_mask: 0.2385  loss_rpn_cls: 0.06751  loss_rpn_loc: 0.223  time: 1.1772  data_time: 0.7831  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:12:36 d2.utils.events]: \u001b[0m eta: 0:54:01  iter: 3979  total_loss: 1.125  loss_cls: 0.2118  loss_box_reg: 0.2543  loss_mask: 0.2999  loss_rpn_cls: 0.08624  loss_rpn_loc: 0.2192  time: 1.1786  data_time: 0.9775  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:13:02 d2.utils.events]: \u001b[0m eta: 0:54:02  iter: 3999  total_loss: 1.185  loss_cls: 0.2021  loss_box_reg: 0.2792  loss_mask: 0.2851  loss_rpn_cls: 0.08299  loss_rpn_loc: 0.2334  time: 1.1791  data_time: 0.8360  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:13:33 d2.utils.events]: \u001b[0m eta: 0:54:16  iter: 4019  total_loss: 1.119  loss_cls: 0.2112  loss_box_reg: 0.2709  loss_mask: 0.286  loss_rpn_cls: 0.09851  loss_rpn_loc: 0.2477  time: 1.1812  data_time: 1.1234  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:13:52 d2.utils.events]: \u001b[0m eta: 0:53:48  iter: 4039  total_loss: 0.9799  loss_cls: 0.186  loss_box_reg: 0.2158  loss_mask: 0.2387  loss_rpn_cls: 0.0633  loss_rpn_loc: 0.1975  time: 1.1799  data_time: 0.5216  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:14:15 d2.utils.events]: \u001b[0m eta: 0:53:37  iter: 4059  total_loss: 1.057  loss_cls: 0.193  loss_box_reg: 0.2371  loss_mask: 0.2692  loss_rpn_cls: 0.07028  loss_rpn_loc: 0.1952  time: 1.1798  data_time: 0.7289  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:14:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 19:14:46 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 19:14:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 19:14:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 19:14:47 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0889 s/iter. Eval: 0.0397 s/iter. Total: 0.1301 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 19:14:52 d2.evaluation.evaluator]: \u001b[0mInference done 58/61. Dataloading: 0.0017 s/iter. Inference: 0.0870 s/iter. Eval: 0.0216 s/iter. Total: 0.1104 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 19:14:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.474220 (0.115611 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:14:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087332 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:14:53 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 19:14:53 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06026586381774295\n",
      "\u001b[32m[12/27 19:14:53 d2.utils.events]: \u001b[0m eta: 0:53:43  iter: 4079  total_loss: 1.171  loss_cls: 0.2364  loss_box_reg: 0.2597  loss_mask: 0.2941  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.2354  time: 1.1815  data_time: 1.0526  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:15:22 d2.utils.events]: \u001b[0m eta: 0:53:32  iter: 4099  total_loss: 1.113  loss_cls: 0.2105  loss_box_reg: 0.2172  loss_mask: 0.2351  loss_rpn_cls: 0.08842  loss_rpn_loc: 0.2449  time: 1.1828  data_time: 0.9935  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:15:51 d2.utils.events]: \u001b[0m eta: 0:53:43  iter: 4119  total_loss: 1.122  loss_cls: 0.2177  loss_box_reg: 0.2619  loss_mask: 0.281  loss_rpn_cls: 0.08497  loss_rpn_loc: 0.2079  time: 1.1839  data_time: 0.9659  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:16:15 d2.utils.events]: \u001b[0m eta: 0:53:33  iter: 4139  total_loss: 1.128  loss_cls: 0.2261  loss_box_reg: 0.2502  loss_mask: 0.2745  loss_rpn_cls: 0.08042  loss_rpn_loc: 0.2166  time: 1.1842  data_time: 0.7783  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:16:41 d2.utils.events]: \u001b[0m eta: 0:53:01  iter: 4159  total_loss: 1.038  loss_cls: 0.2059  loss_box_reg: 0.2445  loss_mask: 0.2775  loss_rpn_cls: 0.07701  loss_rpn_loc: 0.2165  time: 1.1848  data_time: 0.8684  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:17:06 d2.utils.events]: \u001b[0m eta: 0:53:07  iter: 4179  total_loss: 1.012  loss_cls: 0.1978  loss_box_reg: 0.2783  loss_mask: 0.2782  loss_rpn_cls: 0.07066  loss_rpn_loc: 0.2013  time: 1.1850  data_time: 0.7779  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:17:28 d2.utils.events]: \u001b[0m eta: 0:52:38  iter: 4199  total_loss: 0.7642  loss_cls: 0.1546  loss_box_reg: 0.1812  loss_mask: 0.2051  loss_rpn_cls: 0.06183  loss_rpn_loc: 0.2025  time: 1.1842  data_time: 0.5901  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:18:03 d2.utils.events]: \u001b[0m eta: 0:52:36  iter: 4219  total_loss: 1.117  loss_cls: 0.2232  loss_box_reg: 0.2626  loss_mask: 0.2989  loss_rpn_cls: 0.1063  loss_rpn_loc: 0.2443  time: 1.1867  data_time: 1.2483  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:18:26 d2.utils.events]: \u001b[0m eta: 0:52:16  iter: 4239  total_loss: 1.123  loss_cls: 0.2285  loss_box_reg: 0.2772  loss_mask: 0.2978  loss_rpn_cls: 0.07224  loss_rpn_loc: 0.207  time: 1.1865  data_time: 0.6957  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:18:46 d2.utils.events]: \u001b[0m eta: 0:51:37  iter: 4259  total_loss: 1.096  loss_cls: 0.2071  loss_box_reg: 0.2592  loss_mask: 0.2777  loss_rpn_cls: 0.08538  loss_rpn_loc: 0.2201  time: 1.1856  data_time: 0.5585  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:19:01 d2.utils.events]: \u001b[0m eta: 0:51:38  iter: 4279  total_loss: 1.075  loss_cls: 0.2383  loss_box_reg: 0.246  loss_mask: 0.2668  loss_rpn_cls: 0.07456  loss_rpn_loc: 0.192  time: 1.1836  data_time: 0.3479  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:19:27 d2.utils.events]: \u001b[0m eta: 0:51:15  iter: 4299  total_loss: 1.113  loss_cls: 0.1971  loss_box_reg: 0.2465  loss_mask: 0.2862  loss_rpn_cls: 0.1096  loss_rpn_loc: 0.2298  time: 1.1840  data_time: 0.8139  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:19:55 d2.utils.events]: \u001b[0m eta: 0:51:16  iter: 4319  total_loss: 1.209  loss_cls: 0.2367  loss_box_reg: 0.2874  loss_mask: 0.2889  loss_rpn_cls: 0.09021  loss_rpn_loc: 0.1972  time: 1.1850  data_time: 0.9351  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:20:18 d2.utils.events]: \u001b[0m eta: 0:50:52  iter: 4339  total_loss: 1.044  loss_cls: 0.2219  loss_box_reg: 0.2752  loss_mask: 0.2674  loss_rpn_cls: 0.08068  loss_rpn_loc: 0.2167  time: 1.1849  data_time: 0.7184  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:20:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 19:20:33 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 19:20:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 19:20:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 19:20:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0894 s/iter. Eval: 0.0394 s/iter. Total: 0.1304 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 19:20:40 d2.evaluation.evaluator]: \u001b[0mInference done 57/61. Dataloading: 0.0018 s/iter. Inference: 0.0876 s/iter. Eval: 0.0236 s/iter. Total: 0.1131 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 19:20:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.618780 (0.118193 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:20:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087961 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:20:40 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 19:20:40 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06554144032588766\n",
      "\u001b[32m[12/27 19:20:46 d2.utils.events]: \u001b[0m eta: 0:50:43  iter: 4359  total_loss: 1.051  loss_cls: 0.2145  loss_box_reg: 0.267  loss_mask: 0.2384  loss_rpn_cls: 0.07755  loss_rpn_loc: 0.2008  time: 1.1841  data_time: 0.5973  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:21:15 d2.utils.events]: \u001b[0m eta: 0:51:01  iter: 4379  total_loss: 1.129  loss_cls: 0.2165  loss_box_reg: 0.238  loss_mask: 0.2773  loss_rpn_cls: 0.09232  loss_rpn_loc: 0.2095  time: 1.1854  data_time: 1.0269  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:21:42 d2.utils.events]: \u001b[0m eta: 0:50:50  iter: 4399  total_loss: 1.126  loss_cls: 0.2143  loss_box_reg: 0.2524  loss_mask: 0.287  loss_rpn_cls: 0.08137  loss_rpn_loc: 0.2226  time: 1.1861  data_time: 0.8836  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:22:00 d2.utils.events]: \u001b[0m eta: 0:49:36  iter: 4419  total_loss: 1.065  loss_cls: 0.2126  loss_box_reg: 0.2922  loss_mask: 0.2899  loss_rpn_cls: 0.05784  loss_rpn_loc: 0.2073  time: 1.1847  data_time: 0.4332  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:22:21 d2.utils.events]: \u001b[0m eta: 0:49:15  iter: 4439  total_loss: 1.043  loss_cls: 0.2075  loss_box_reg: 0.2278  loss_mask: 0.2368  loss_rpn_cls: 0.07709  loss_rpn_loc: 0.2049  time: 1.1841  data_time: 0.6117  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:22:42 d2.utils.events]: \u001b[0m eta: 0:48:57  iter: 4459  total_loss: 0.9285  loss_cls: 0.1706  loss_box_reg: 0.2305  loss_mask: 0.2409  loss_rpn_cls: 0.06181  loss_rpn_loc: 0.2081  time: 1.1837  data_time: 0.6622  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:23:06 d2.utils.events]: \u001b[0m eta: 0:48:53  iter: 4479  total_loss: 1.22  loss_cls: 0.2558  loss_box_reg: 0.2944  loss_mask: 0.2869  loss_rpn_cls: 0.1063  loss_rpn_loc: 0.2427  time: 1.1836  data_time: 0.7080  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:23:37 d2.utils.events]: \u001b[0m eta: 0:48:43  iter: 4499  total_loss: 1.277  loss_cls: 0.3283  loss_box_reg: 0.353  loss_mask: 0.2737  loss_rpn_cls: 0.08109  loss_rpn_loc: 0.2263  time: 1.1851  data_time: 1.0754  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:23:57 d2.utils.events]: \u001b[0m eta: 0:48:32  iter: 4519  total_loss: 1.113  loss_cls: 0.2426  loss_box_reg: 0.2606  loss_mask: 0.2815  loss_rpn_cls: 0.08127  loss_rpn_loc: 0.2133  time: 1.1839  data_time: 0.4942  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:24:22 d2.utils.events]: \u001b[0m eta: 0:48:19  iter: 4539  total_loss: 0.8981  loss_cls: 0.1628  loss_box_reg: 0.1923  loss_mask: 0.2197  loss_rpn_cls: 0.06368  loss_rpn_loc: 0.2318  time: 1.1841  data_time: 0.7878  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:24:46 d2.utils.events]: \u001b[0m eta: 0:48:15  iter: 4559  total_loss: 1.094  loss_cls: 0.2132  loss_box_reg: 0.2526  loss_mask: 0.2758  loss_rpn_cls: 0.09771  loss_rpn_loc: 0.2227  time: 1.1843  data_time: 0.7874  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:25:14 d2.utils.events]: \u001b[0m eta: 0:48:05  iter: 4579  total_loss: 1.047  loss_cls: 0.1927  loss_box_reg: 0.2401  loss_mask: 0.2831  loss_rpn_cls: 0.09602  loss_rpn_loc: 0.2332  time: 1.1852  data_time: 0.9486  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:25:36 d2.utils.events]: \u001b[0m eta: 0:47:50  iter: 4599  total_loss: 1.071  loss_cls: 0.2318  loss_box_reg: 0.2568  loss_mask: 0.2821  loss_rpn_cls: 0.07149  loss_rpn_loc: 0.211  time: 1.1847  data_time: 0.6295  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:25:54 d2.utils.events]: \u001b[0m eta: 0:47:39  iter: 4619  total_loss: 1.067  loss_cls: 0.2129  loss_box_reg: 0.2801  loss_mask: 0.2854  loss_rpn_cls: 0.06055  loss_rpn_loc: 0.2015  time: 1.1837  data_time: 0.4884  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:25:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 19:25:58 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 19:25:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 19:25:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 19:26:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0018 s/iter. Inference: 0.0951 s/iter. Eval: 0.0350 s/iter. Total: 0.1318 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 19:26:05 d2.evaluation.evaluator]: \u001b[0mInference done 56/61. Dataloading: 0.0022 s/iter. Inference: 0.0900 s/iter. Eval: 0.0227 s/iter. Total: 0.1149 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 19:26:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.676453 (0.119222 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:26:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.090002 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:26:06 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 19:26:06 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06325623540627581\n",
      "\u001b[32m[12/27 19:26:20 d2.utils.events]: \u001b[0m eta: 0:47:23  iter: 4639  total_loss: 0.9807  loss_cls: 0.1982  loss_box_reg: 0.1961  loss_mask: 0.2558  loss_rpn_cls: 0.05537  loss_rpn_loc: 0.1868  time: 1.1823  data_time: 0.4220  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:26:48 d2.utils.events]: \u001b[0m eta: 0:47:32  iter: 4659  total_loss: 1.12  loss_cls: 0.2202  loss_box_reg: 0.2916  loss_mask: 0.3076  loss_rpn_cls: 0.0741  loss_rpn_loc: 0.223  time: 1.1832  data_time: 0.9280  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:27:06 d2.utils.events]: \u001b[0m eta: 0:47:08  iter: 4679  total_loss: 1.019  loss_cls: 0.2004  loss_box_reg: 0.2282  loss_mask: 0.2492  loss_rpn_cls: 0.06551  loss_rpn_loc: 0.198  time: 1.1821  data_time: 0.4807  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:27:37 d2.utils.events]: \u001b[0m eta: 0:46:57  iter: 4699  total_loss: 1.083  loss_cls: 0.2138  loss_box_reg: 0.2692  loss_mask: 0.2998  loss_rpn_cls: 0.08251  loss_rpn_loc: 0.2191  time: 1.1835  data_time: 1.0815  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:28:00 d2.utils.events]: \u001b[0m eta: 0:47:41  iter: 4719  total_loss: 1.147  loss_cls: 0.2346  loss_box_reg: 0.2819  loss_mask: 0.2905  loss_rpn_cls: 0.0924  loss_rpn_loc: 0.2369  time: 1.1835  data_time: 0.7051  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:28:24 d2.utils.events]: \u001b[0m eta: 0:47:30  iter: 4739  total_loss: 1.025  loss_cls: 0.189  loss_box_reg: 0.2228  loss_mask: 0.2702  loss_rpn_cls: 0.09519  loss_rpn_loc: 0.2231  time: 1.1836  data_time: 0.7692  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:28:44 d2.utils.events]: \u001b[0m eta: 0:47:41  iter: 4759  total_loss: 1.214  loss_cls: 0.2258  loss_box_reg: 0.3113  loss_mask: 0.2717  loss_rpn_cls: 0.09134  loss_rpn_loc: 0.2192  time: 1.1828  data_time: 0.5575  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:29:04 d2.utils.events]: \u001b[0m eta: 0:46:39  iter: 4779  total_loss: 1.029  loss_cls: 0.1998  loss_box_reg: 0.2853  loss_mask: 0.2665  loss_rpn_cls: 0.06155  loss_rpn_loc: 0.2096  time: 1.1820  data_time: 0.5480  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:29:29 d2.utils.events]: \u001b[0m eta: 0:46:03  iter: 4799  total_loss: 1.044  loss_cls: 0.2005  loss_box_reg: 0.2329  loss_mask: 0.2839  loss_rpn_cls: 0.08637  loss_rpn_loc: 0.216  time: 1.1820  data_time: 0.7363  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:30:00 d2.utils.events]: \u001b[0m eta: 0:45:53  iter: 4819  total_loss: 1.114  loss_cls: 0.1932  loss_box_reg: 0.238  loss_mask: 0.2909  loss_rpn_cls: 0.08745  loss_rpn_loc: 0.2067  time: 1.1831  data_time: 0.9813  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:30:26 d2.utils.events]: \u001b[0m eta: 0:45:50  iter: 4839  total_loss: 1.078  loss_cls: 0.2045  loss_box_reg: 0.2275  loss_mask: 0.2861  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.2308  time: 1.1837  data_time: 0.8784  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:30:47 d2.utils.events]: \u001b[0m eta: 0:45:26  iter: 4859  total_loss: 0.3676  loss_cls: 0.002207  loss_box_reg: 0  loss_mask: 0  loss_rpn_cls: 0.07221  loss_rpn_loc: 0.2159  time: 1.1832  data_time: 0.6116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:31:10 d2.utils.events]: \u001b[0m eta: 0:45:22  iter: 4879  total_loss: 1.19  loss_cls: 0.2232  loss_box_reg: 0.2875  loss_mask: 0.3082  loss_rpn_cls: 0.08993  loss_rpn_loc: 0.211  time: 1.1831  data_time: 0.7161  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:31:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 19:31:23 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 19:31:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 19:31:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 19:31:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0017 s/iter. Inference: 0.0912 s/iter. Eval: 0.0427 s/iter. Total: 0.1356 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 19:31:30 d2.evaluation.evaluator]: \u001b[0mInference done 56/61. Dataloading: 0.0018 s/iter. Inference: 0.0882 s/iter. Eval: 0.0249 s/iter. Total: 0.1150 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 19:31:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.691868 (0.119498 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:31:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.088417 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:31:31 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 19:31:31 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06486787395467633\n",
      "\u001b[32m[12/27 19:31:36 d2.utils.events]: \u001b[0m eta: 0:45:12  iter: 4899  total_loss: 1.071  loss_cls: 0.2003  loss_box_reg: 0.2508  loss_mask: 0.2779  loss_rpn_cls: 0.06603  loss_rpn_loc: 0.2184  time: 1.1819  data_time: 0.4545  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:32:02 d2.utils.events]: \u001b[0m eta: 0:45:07  iter: 4919  total_loss: 1.098  loss_cls: 0.2156  loss_box_reg: 0.2434  loss_mask: 0.2736  loss_rpn_cls: 0.08343  loss_rpn_loc: 0.2093  time: 1.1823  data_time: 0.8558  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:32:36 d2.utils.events]: \u001b[0m eta: 0:45:55  iter: 4939  total_loss: 1.152  loss_cls: 0.2188  loss_box_reg: 0.2718  loss_mask: 0.3125  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.2305  time: 1.1843  data_time: 1.2060  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:32:54 d2.utils.events]: \u001b[0m eta: 0:45:23  iter: 4959  total_loss: 0.9492  loss_cls: 0.1897  loss_box_reg: 0.1885  loss_mask: 0.2509  loss_rpn_cls: 0.09789  loss_rpn_loc: 0.2143  time: 1.1832  data_time: 0.4804  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:33:19 d2.utils.events]: \u001b[0m eta: 0:44:40  iter: 4979  total_loss: 1.064  loss_cls: 0.1967  loss_box_reg: 0.2577  loss_mask: 0.2887  loss_rpn_cls: 0.09135  loss_rpn_loc: 0.2107  time: 1.1836  data_time: 0.8261  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:33:55 d2.utils.events]: \u001b[0m eta: 0:45:09  iter: 4999  total_loss: 1.102  loss_cls: 0.2098  loss_box_reg: 0.2503  loss_mask: 0.287  loss_rpn_cls: 0.09666  loss_rpn_loc: 0.2234  time: 1.1859  data_time: 1.2754  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:34:14 d2.utils.events]: \u001b[0m eta: 0:44:19  iter: 5019  total_loss: 1.009  loss_cls: 0.193  loss_box_reg: 0.2399  loss_mask: 0.2464  loss_rpn_cls: 0.07098  loss_rpn_loc: 0.2068  time: 1.1851  data_time: 0.5592  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:34:41 d2.utils.events]: \u001b[0m eta: 0:44:56  iter: 5039  total_loss: 1.062  loss_cls: 0.2199  loss_box_reg: 0.2554  loss_mask: 0.273  loss_rpn_cls: 0.09611  loss_rpn_loc: 0.2323  time: 1.1856  data_time: 0.8741  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:35:06 d2.utils.events]: \u001b[0m eta: 0:45:14  iter: 5059  total_loss: 1.175  loss_cls: 0.2262  loss_box_reg: 0.3012  loss_mask: 0.2975  loss_rpn_cls: 0.09025  loss_rpn_loc: 0.223  time: 1.1859  data_time: 0.7833  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:35:23 d2.utils.events]: \u001b[0m eta: 0:44:34  iter: 5079  total_loss: 0.5729  loss_cls: 0.08987  loss_box_reg: 0.08032  loss_mask: 0.114  loss_rpn_cls: 0.05969  loss_rpn_loc: 0.1973  time: 1.1847  data_time: 0.4496  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:35:52 d2.utils.events]: \u001b[0m eta: 0:44:38  iter: 5099  total_loss: 1.097  loss_cls: 0.2293  loss_box_reg: 0.2974  loss_mask: 0.2831  loss_rpn_cls: 0.09563  loss_rpn_loc: 0.2255  time: 1.1855  data_time: 0.9379  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:36:15 d2.utils.events]: \u001b[0m eta: 0:44:13  iter: 5119  total_loss: 1.051  loss_cls: 0.1978  loss_box_reg: 0.2263  loss_mask: 0.2899  loss_rpn_cls: 0.0859  loss_rpn_loc: 0.2087  time: 1.1851  data_time: 0.6304  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:36:33 d2.utils.events]: \u001b[0m eta: 0:43:36  iter: 5139  total_loss: 1.097  loss_cls: 0.2236  loss_box_reg: 0.2639  loss_mask: 0.2645  loss_rpn_cls: 0.0729  loss_rpn_loc: 0.2031  time: 1.1840  data_time: 0.4715  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:37:03 d2.utils.events]: \u001b[0m eta: 0:43:25  iter: 5159  total_loss: 1.081  loss_cls: 0.2152  loss_box_reg: 0.2348  loss_mask: 0.2861  loss_rpn_cls: 0.08167  loss_rpn_loc: 0.2241  time: 1.1852  data_time: 1.0221  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:37:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 19:37:11 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 19:37:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 19:37:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 19:37:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0892 s/iter. Eval: 0.0388 s/iter. Total: 0.1295 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 19:37:18 d2.evaluation.evaluator]: \u001b[0mInference done 57/61. Dataloading: 0.0017 s/iter. Inference: 0.0871 s/iter. Eval: 0.0229 s/iter. Total: 0.1119 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 19:37:19 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.574204 (0.117396 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:37:19 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087548 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:37:19 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 19:37:19 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06679703423376394\n",
      "\u001b[32m[12/27 19:37:26 d2.utils.events]: \u001b[0m eta: 0:42:51  iter: 5179  total_loss: 0.8236  loss_cls: 0.1317  loss_box_reg: 0.2029  loss_mask: 0.2296  loss_rpn_cls: 0.04988  loss_rpn_loc: 0.2114  time: 1.1836  data_time: 0.3545  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:37:53 d2.utils.events]: \u001b[0m eta: 0:42:43  iter: 5199  total_loss: 1.082  loss_cls: 0.2038  loss_box_reg: 0.2374  loss_mask: 0.3052  loss_rpn_cls: 0.08459  loss_rpn_loc: 0.2073  time: 1.1842  data_time: 0.8827  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:38:13 d2.utils.events]: \u001b[0m eta: 0:42:28  iter: 5219  total_loss: 1.039  loss_cls: 0.1873  loss_box_reg: 0.2452  loss_mask: 0.2735  loss_rpn_cls: 0.07253  loss_rpn_loc: 0.221  time: 1.1835  data_time: 0.5673  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:38:38 d2.utils.events]: \u001b[0m eta: 0:42:19  iter: 5239  total_loss: 1.053  loss_cls: 0.1958  loss_box_reg: 0.2741  loss_mask: 0.2683  loss_rpn_cls: 0.08123  loss_rpn_loc: 0.2073  time: 1.1837  data_time: 0.7798  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:39:06 d2.utils.events]: \u001b[0m eta: 0:42:11  iter: 5259  total_loss: 1.146  loss_cls: 0.2212  loss_box_reg: 0.2873  loss_mask: 0.2802  loss_rpn_cls: 0.08943  loss_rpn_loc: 0.232  time: 1.1845  data_time: 0.9324  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:39:28 d2.utils.events]: \u001b[0m eta: 0:42:00  iter: 5279  total_loss: 0.9782  loss_cls: 0.1817  loss_box_reg: 0.1751  loss_mask: 0.2602  loss_rpn_cls: 0.07757  loss_rpn_loc: 0.2321  time: 1.1841  data_time: 0.6481  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:39:47 d2.utils.events]: \u001b[0m eta: 0:41:49  iter: 5299  total_loss: 1.123  loss_cls: 0.232  loss_box_reg: 0.2645  loss_mask: 0.2856  loss_rpn_cls: 0.07987  loss_rpn_loc: 0.2247  time: 1.1833  data_time: 0.5180  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:40:05 d2.utils.events]: \u001b[0m eta: 0:41:37  iter: 5319  total_loss: 1.029  loss_cls: 0.2321  loss_box_reg: 0.2474  loss_mask: 0.2591  loss_rpn_cls: 0.0814  loss_rpn_loc: 0.2028  time: 1.1823  data_time: 0.4962  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:40:27 d2.utils.events]: \u001b[0m eta: 0:41:18  iter: 5339  total_loss: 1.083  loss_cls: 0.2174  loss_box_reg: 0.2487  loss_mask: 0.2674  loss_rpn_cls: 0.07434  loss_rpn_loc: 0.2259  time: 1.1820  data_time: 0.6583  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:40:45 d2.utils.events]: \u001b[0m eta: 0:41:06  iter: 5359  total_loss: 1.016  loss_cls: 0.2019  loss_box_reg: 0.2076  loss_mask: 0.2636  loss_rpn_cls: 0.08563  loss_rpn_loc: 0.2031  time: 1.1809  data_time: 0.4619  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:41:06 d2.utils.events]: \u001b[0m eta: 0:40:33  iter: 5379  total_loss: 1.016  loss_cls: 0.1997  loss_box_reg: 0.2102  loss_mask: 0.2874  loss_rpn_cls: 0.06575  loss_rpn_loc: 0.2075  time: 1.1804  data_time: 0.6343  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:41:38 d2.utils.events]: \u001b[0m eta: 0:40:23  iter: 5399  total_loss: 1.101  loss_cls: 0.1949  loss_box_reg: 0.2531  loss_mask: 0.3119  loss_rpn_cls: 0.06853  loss_rpn_loc: 0.2298  time: 1.1816  data_time: 1.0586  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:42:07 d2.utils.events]: \u001b[0m eta: 0:40:25  iter: 5419  total_loss: 1.108  loss_cls: 0.1981  loss_box_reg: 0.2564  loss_mask: 0.2848  loss_rpn_cls: 0.07038  loss_rpn_loc: 0.2148  time: 1.1825  data_time: 0.9471  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:42:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 19:42:39 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 19:42:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 19:42:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 19:42:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0892 s/iter. Eval: 0.0366 s/iter. Total: 0.1274 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 19:42:46 d2.evaluation.evaluator]: \u001b[0mInference done 57/61. Dataloading: 0.0019 s/iter. Inference: 0.0877 s/iter. Eval: 0.0227 s/iter. Total: 0.1125 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 19:42:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.581120 (0.117520 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:42:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.088016 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:42:47 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 19:42:47 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06321889930872539\n",
      "\u001b[32m[12/27 19:42:47 d2.utils.events]: \u001b[0m eta: 0:40:24  iter: 5439  total_loss: 1.119  loss_cls: 0.2353  loss_box_reg: 0.2502  loss_mask: 0.2967  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.2181  time: 1.1840  data_time: 1.1399  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:43:11 d2.utils.events]: \u001b[0m eta: 0:40:20  iter: 5459  total_loss: 1.033  loss_cls: 0.206  loss_box_reg: 0.2761  loss_mask: 0.2632  loss_rpn_cls: 0.08123  loss_rpn_loc: 0.2202  time: 1.1842  data_time: 0.7953  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:43:43 d2.utils.events]: \u001b[0m eta: 0:40:10  iter: 5479  total_loss: 1.103  loss_cls: 0.2058  loss_box_reg: 0.2915  loss_mask: 0.29  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.2107  time: 1.1857  data_time: 1.1186  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:44:05 d2.utils.events]: \u001b[0m eta: 0:39:59  iter: 5499  total_loss: 1.008  loss_cls: 0.1881  loss_box_reg: 0.2459  loss_mask: 0.2563  loss_rpn_cls: 0.08108  loss_rpn_loc: 0.1986  time: 1.1853  data_time: 0.6498  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:44:35 d2.utils.events]: \u001b[0m eta: 0:39:55  iter: 5519  total_loss: 1.055  loss_cls: 0.1913  loss_box_reg: 0.2346  loss_mask: 0.2787  loss_rpn_cls: 0.07414  loss_rpn_loc: 0.2224  time: 1.1864  data_time: 1.0510  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:44:53 d2.utils.events]: \u001b[0m eta: 0:39:41  iter: 5539  total_loss: 1.08  loss_cls: 0.2187  loss_box_reg: 0.2295  loss_mask: 0.2576  loss_rpn_cls: 0.06733  loss_rpn_loc: 0.1981  time: 1.1853  data_time: 0.4381  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:45:17 d2.utils.events]: \u001b[0m eta: 0:39:34  iter: 5559  total_loss: 1.036  loss_cls: 0.1852  loss_box_reg: 0.2162  loss_mask: 0.2766  loss_rpn_cls: 0.08966  loss_rpn_loc: 0.2097  time: 1.1855  data_time: 0.7834  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:45:34 d2.utils.events]: \u001b[0m eta: 0:39:19  iter: 5579  total_loss: 1.075  loss_cls: 0.196  loss_box_reg: 0.2394  loss_mask: 0.2687  loss_rpn_cls: 0.07494  loss_rpn_loc: 0.2057  time: 1.1842  data_time: 0.4076  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:45:55 d2.utils.events]: \u001b[0m eta: 0:39:18  iter: 5599  total_loss: 1.029  loss_cls: 0.1782  loss_box_reg: 0.2184  loss_mask: 0.2727  loss_rpn_cls: 0.07417  loss_rpn_loc: 0.2091  time: 1.1838  data_time: 0.6169  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:46:22 d2.utils.events]: \u001b[0m eta: 0:39:14  iter: 5619  total_loss: 1.101  loss_cls: 0.1979  loss_box_reg: 0.2186  loss_mask: 0.2823  loss_rpn_cls: 0.09923  loss_rpn_loc: 0.237  time: 1.1843  data_time: 0.8666  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:46:46 d2.utils.events]: \u001b[0m eta: 0:39:20  iter: 5639  total_loss: 1.135  loss_cls: 0.2159  loss_box_reg: 0.2923  loss_mask: 0.2784  loss_rpn_cls: 0.06458  loss_rpn_loc: 0.2124  time: 1.1844  data_time: 0.7585  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:47:11 d2.utils.events]: \u001b[0m eta: 0:38:59  iter: 5659  total_loss: 1.113  loss_cls: 0.2221  loss_box_reg: 0.3072  loss_mask: 0.2841  loss_rpn_cls: 0.08979  loss_rpn_loc: 0.2372  time: 1.1847  data_time: 0.7986  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:47:34 d2.utils.events]: \u001b[0m eta: 0:39:06  iter: 5679  total_loss: 1.14  loss_cls: 0.2288  loss_box_reg: 0.2551  loss_mask: 0.3039  loss_rpn_cls: 0.09959  loss_rpn_loc: 0.222  time: 1.1846  data_time: 0.7116  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:47:56 d2.utils.events]: \u001b[0m eta: 0:38:47  iter: 5699  total_loss: 1.05  loss_cls: 0.2233  loss_box_reg: 0.2853  loss_mask: 0.2646  loss_rpn_cls: 0.06342  loss_rpn_loc: 0.1938  time: 1.1840  data_time: 0.5880  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:48:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 19:48:08 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 19:48:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 19:48:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 19:48:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0900 s/iter. Eval: 0.0381 s/iter. Total: 0.1297 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 19:48:15 d2.evaluation.evaluator]: \u001b[0mInference done 56/61. Dataloading: 0.0017 s/iter. Inference: 0.0874 s/iter. Eval: 0.0246 s/iter. Total: 0.1138 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 19:48:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.652431 (0.118793 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:48:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087741 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:48:16 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 19:48:16 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06760851158506555\n",
      "\u001b[32m[12/27 19:48:25 d2.utils.events]: \u001b[0m eta: 0:38:18  iter: 5719  total_loss: 0.9837  loss_cls: 0.177  loss_box_reg: 0.2356  loss_mask: 0.278  loss_rpn_cls: 0.06176  loss_rpn_loc: 0.2026  time: 1.1834  data_time: 0.5809  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:48:41 d2.utils.events]: \u001b[0m eta: 0:38:06  iter: 5739  total_loss: 1.056  loss_cls: 0.2043  loss_box_reg: 0.2382  loss_mask: 0.2747  loss_rpn_cls: 0.06618  loss_rpn_loc: 0.1934  time: 1.1820  data_time: 0.3756  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:49:07 d2.utils.events]: \u001b[0m eta: 0:37:57  iter: 5759  total_loss: 1.031  loss_cls: 0.2082  loss_box_reg: 0.1944  loss_mask: 0.2679  loss_rpn_cls: 0.06731  loss_rpn_loc: 0.2059  time: 1.1824  data_time: 0.8550  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:49:31 d2.utils.events]: \u001b[0m eta: 0:37:47  iter: 5779  total_loss: 1.084  loss_cls: 0.1947  loss_box_reg: 0.2414  loss_mask: 0.2707  loss_rpn_cls: 0.07313  loss_rpn_loc: 0.2052  time: 1.1824  data_time: 0.7207  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:49:54 d2.utils.events]: \u001b[0m eta: 0:37:34  iter: 5799  total_loss: 1.074  loss_cls: 0.2024  loss_box_reg: 0.2735  loss_mask: 0.2776  loss_rpn_cls: 0.09403  loss_rpn_loc: 0.2285  time: 1.1823  data_time: 0.7340  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:50:17 d2.utils.events]: \u001b[0m eta: 0:37:10  iter: 5819  total_loss: 1.011  loss_cls: 0.2036  loss_box_reg: 0.2301  loss_mask: 0.2663  loss_rpn_cls: 0.06501  loss_rpn_loc: 0.2094  time: 1.1821  data_time: 0.6923  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:50:38 d2.utils.events]: \u001b[0m eta: 0:36:55  iter: 5839  total_loss: 1.12  loss_cls: 0.2344  loss_box_reg: 0.3088  loss_mask: 0.2757  loss_rpn_cls: 0.07461  loss_rpn_loc: 0.2026  time: 1.1818  data_time: 0.6318  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:51:07 d2.utils.events]: \u001b[0m eta: 0:36:52  iter: 5859  total_loss: 1.096  loss_cls: 0.2069  loss_box_reg: 0.2205  loss_mask: 0.2874  loss_rpn_cls: 0.08653  loss_rpn_loc: 0.209  time: 1.1826  data_time: 0.9783  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:51:39 d2.utils.events]: \u001b[0m eta: 0:36:48  iter: 5879  total_loss: 1.091  loss_cls: 0.2146  loss_box_reg: 0.2519  loss_mask: 0.2742  loss_rpn_cls: 0.08794  loss_rpn_loc: 0.2101  time: 1.1840  data_time: 1.1396  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:52:05 d2.utils.events]: \u001b[0m eta: 0:36:42  iter: 5899  total_loss: 1.076  loss_cls: 0.212  loss_box_reg: 0.2802  loss_mask: 0.2888  loss_rpn_cls: 0.08193  loss_rpn_loc: 0.1957  time: 1.1845  data_time: 0.8752  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:52:29 d2.utils.events]: \u001b[0m eta: 0:36:22  iter: 5919  total_loss: 0.9222  loss_cls: 0.1629  loss_box_reg: 0.1657  loss_mask: 0.2409  loss_rpn_cls: 0.05795  loss_rpn_loc: 0.2169  time: 1.1844  data_time: 0.7475  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:52:49 d2.utils.events]: \u001b[0m eta: 0:35:54  iter: 5939  total_loss: 1.022  loss_cls: 0.194  loss_box_reg: 0.2483  loss_mask: 0.2476  loss_rpn_cls: 0.07444  loss_rpn_loc: 0.2152  time: 1.1840  data_time: 0.6027  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:53:10 d2.utils.events]: \u001b[0m eta: 0:35:46  iter: 5959  total_loss: 1.026  loss_cls: 0.1906  loss_box_reg: 0.2244  loss_mask: 0.2507  loss_rpn_cls: 0.07557  loss_rpn_loc: 0.2102  time: 1.1834  data_time: 0.5608  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:53:38 d2.utils.events]: \u001b[0m eta: 0:35:36  iter: 5979  total_loss: 1.172  loss_cls: 0.2353  loss_box_reg: 0.281  loss_mask: 0.2985  loss_rpn_cls: 0.1144  loss_rpn_loc: 0.2096  time: 1.1842  data_time: 0.9580  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:53:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 19:53:46 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 19:53:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 19:53:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 19:53:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0892 s/iter. Eval: 0.0403 s/iter. Total: 0.1310 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 19:53:53 d2.evaluation.evaluator]: \u001b[0mInference done 58/61. Dataloading: 0.0016 s/iter. Inference: 0.0869 s/iter. Eval: 0.0223 s/iter. Total: 0.1110 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 19:53:53 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.511041 (0.116269 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:53:53 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087274 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:53:53 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 19:53:53 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.062211456725971864\n",
      "\u001b[32m[12/27 19:54:12 d2.utils.events]: \u001b[0m eta: 0:35:12  iter: 5999  total_loss: 1.11  loss_cls: 0.2094  loss_box_reg: 0.2505  loss_mask: 0.2763  loss_rpn_cls: 0.07803  loss_rpn_loc: 0.2078  time: 1.1844  data_time: 0.7959  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:54:38 d2.utils.events]: \u001b[0m eta: 0:35:10  iter: 6019  total_loss: 1.028  loss_cls: 0.2006  loss_box_reg: 0.1996  loss_mask: 0.2828  loss_rpn_cls: 0.07864  loss_rpn_loc: 0.2025  time: 1.1845  data_time: 0.7753  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:55:01 d2.utils.events]: \u001b[0m eta: 0:34:48  iter: 6039  total_loss: 1.034  loss_cls: 0.203  loss_box_reg: 0.1877  loss_mask: 0.2572  loss_rpn_cls: 0.08341  loss_rpn_loc: 0.2106  time: 1.1845  data_time: 0.7376  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:55:31 d2.utils.events]: \u001b[0m eta: 0:34:23  iter: 6059  total_loss: 1.005  loss_cls: 0.2047  loss_box_reg: 0.2458  loss_mask: 0.2688  loss_rpn_cls: 0.0854  loss_rpn_loc: 0.2242  time: 1.1855  data_time: 1.0169  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:55:52 d2.utils.events]: \u001b[0m eta: 0:34:20  iter: 6079  total_loss: 1.097  loss_cls: 0.2173  loss_box_reg: 0.3059  loss_mask: 0.3028  loss_rpn_cls: 0.07812  loss_rpn_loc: 0.2125  time: 1.1850  data_time: 0.6052  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:56:15 d2.utils.events]: \u001b[0m eta: 0:33:40  iter: 6099  total_loss: 0.9922  loss_cls: 0.1936  loss_box_reg: 0.2044  loss_mask: 0.2532  loss_rpn_cls: 0.07913  loss_rpn_loc: 0.2139  time: 1.1850  data_time: 0.7579  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:56:39 d2.utils.events]: \u001b[0m eta: 0:33:30  iter: 6119  total_loss: 0.9768  loss_cls: 0.189  loss_box_reg: 0.2316  loss_mask: 0.2726  loss_rpn_cls: 0.05767  loss_rpn_loc: 0.2074  time: 1.1850  data_time: 0.7391  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:57:05 d2.utils.events]: \u001b[0m eta: 0:33:41  iter: 6139  total_loss: 1.089  loss_cls: 0.2137  loss_box_reg: 0.2576  loss_mask: 0.2855  loss_rpn_cls: 0.08404  loss_rpn_loc: 0.2262  time: 1.1853  data_time: 0.8586  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:57:31 d2.utils.events]: \u001b[0m eta: 0:33:30  iter: 6159  total_loss: 1.14  loss_cls: 0.2229  loss_box_reg: 0.243  loss_mask: 0.2906  loss_rpn_cls: 0.07276  loss_rpn_loc: 0.2162  time: 1.1858  data_time: 0.8749  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:57:56 d2.utils.events]: \u001b[0m eta: 0:33:38  iter: 6179  total_loss: 1.135  loss_cls: 0.2379  loss_box_reg: 0.2904  loss_mask: 0.2845  loss_rpn_cls: 0.08957  loss_rpn_loc: 0.2163  time: 1.1860  data_time: 0.7976  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:58:26 d2.utils.events]: \u001b[0m eta: 0:33:32  iter: 6199  total_loss: 1.043  loss_cls: 0.192  loss_box_reg: 0.2511  loss_mask: 0.2715  loss_rpn_cls: 0.07792  loss_rpn_loc: 0.2341  time: 1.1869  data_time: 1.0371  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:58:51 d2.utils.events]: \u001b[0m eta: 0:33:29  iter: 6219  total_loss: 1.085  loss_cls: 0.1952  loss_box_reg: 0.2671  loss_mask: 0.3059  loss_rpn_cls: 0.0875  loss_rpn_loc: 0.2023  time: 1.1871  data_time: 0.7866  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:59:08 d2.utils.events]: \u001b[0m eta: 0:33:13  iter: 6239  total_loss: 0.8734  loss_cls: 0.1682  loss_box_reg: 0.221  loss_mask: 0.2367  loss_rpn_cls: 0.04616  loss_rpn_loc: 0.2056  time: 1.1860  data_time: 0.4225  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:59:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 19:59:21 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 19:59:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 19:59:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 19:59:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0895 s/iter. Eval: 0.0414 s/iter. Total: 0.1322 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 19:59:28 d2.evaluation.evaluator]: \u001b[0mInference done 57/61. Dataloading: 0.0017 s/iter. Inference: 0.0872 s/iter. Eval: 0.0241 s/iter. Total: 0.1131 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 19:59:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.627426 (0.118347 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:59:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087582 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 19:59:29 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 19:59:29 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0663694645721993\n",
      "\u001b[32m[12/27 19:59:32 d2.utils.events]: \u001b[0m eta: 0:32:46  iter: 6259  total_loss: 1.14  loss_cls: 0.2219  loss_box_reg: 0.2894  loss_mask: 0.279  loss_rpn_cls: 0.0779  loss_rpn_loc: 0.2143  time: 1.1848  data_time: 0.3768  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 19:59:59 d2.utils.events]: \u001b[0m eta: 0:32:47  iter: 6279  total_loss: 1.042  loss_cls: 0.2029  loss_box_reg: 0.2562  loss_mask: 0.3023  loss_rpn_cls: 0.07951  loss_rpn_loc: 0.2193  time: 1.1854  data_time: 0.9108  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:00:26 d2.utils.events]: \u001b[0m eta: 0:32:41  iter: 6299  total_loss: 1.05  loss_cls: 0.2055  loss_box_reg: 0.2269  loss_mask: 0.2761  loss_rpn_cls: 0.06819  loss_rpn_loc: 0.2105  time: 1.1857  data_time: 0.8215  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:00:50 d2.utils.events]: \u001b[0m eta: 0:32:34  iter: 6319  total_loss: 1.032  loss_cls: 0.169  loss_box_reg: 0.1903  loss_mask: 0.2743  loss_rpn_cls: 0.0898  loss_rpn_loc: 0.2141  time: 1.1856  data_time: 0.7115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:01:11 d2.utils.events]: \u001b[0m eta: 0:32:25  iter: 6339  total_loss: 1.092  loss_cls: 0.2115  loss_box_reg: 0.2604  loss_mask: 0.2982  loss_rpn_cls: 0.07151  loss_rpn_loc: 0.2159  time: 1.1851  data_time: 0.5834  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:01:26 d2.utils.events]: \u001b[0m eta: 0:32:05  iter: 6359  total_loss: 0.9153  loss_cls: 0.1816  loss_box_reg: 0.2278  loss_mask: 0.2432  loss_rpn_cls: 0.06774  loss_rpn_loc: 0.1926  time: 1.1837  data_time: 0.3278  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:01:50 d2.utils.events]: \u001b[0m eta: 0:31:55  iter: 6379  total_loss: 0.9293  loss_cls: 0.179  loss_box_reg: 0.2134  loss_mask: 0.2509  loss_rpn_cls: 0.05537  loss_rpn_loc: 0.2108  time: 1.1837  data_time: 0.7250  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:02:21 d2.utils.events]: \u001b[0m eta: 0:31:48  iter: 6399  total_loss: 1.177  loss_cls: 0.2073  loss_box_reg: 0.2568  loss_mask: 0.2913  loss_rpn_cls: 0.09788  loss_rpn_loc: 0.2391  time: 1.1849  data_time: 1.1113  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:02:45 d2.utils.events]: \u001b[0m eta: 0:31:28  iter: 6419  total_loss: 1.042  loss_cls: 0.202  loss_box_reg: 0.2742  loss_mask: 0.2811  loss_rpn_cls: 0.0775  loss_rpn_loc: 0.2047  time: 1.1850  data_time: 0.7476  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:03:12 d2.utils.events]: \u001b[0m eta: 0:31:16  iter: 6439  total_loss: 1.119  loss_cls: 0.2246  loss_box_reg: 0.2911  loss_mask: 0.291  loss_rpn_cls: 0.0941  loss_rpn_loc: 0.2108  time: 1.1855  data_time: 0.8955  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:03:41 d2.utils.events]: \u001b[0m eta: 0:31:12  iter: 6459  total_loss: 1.111  loss_cls: 0.234  loss_box_reg: 0.2541  loss_mask: 0.2839  loss_rpn_cls: 0.09765  loss_rpn_loc: 0.2382  time: 1.1863  data_time: 0.9722  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:03:59 d2.utils.events]: \u001b[0m eta: 0:30:54  iter: 6479  total_loss: 0.9231  loss_cls: 0.1767  loss_box_reg: 0.2392  loss_mask: 0.242  loss_rpn_cls: 0.0672  loss_rpn_loc: 0.1839  time: 1.1854  data_time: 0.4728  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:04:21 d2.utils.events]: \u001b[0m eta: 0:30:43  iter: 6499  total_loss: 0.9786  loss_cls: 0.2084  loss_box_reg: 0.2719  loss_mask: 0.2461  loss_rpn_cls: 0.06147  loss_rpn_loc: 0.1981  time: 1.1851  data_time: 0.6424  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:04:45 d2.utils.events]: \u001b[0m eta: 0:30:27  iter: 6519  total_loss: 0.9966  loss_cls: 0.1783  loss_box_reg: 0.2122  loss_mask: 0.2502  loss_rpn_cls: 0.07899  loss_rpn_loc: 0.2041  time: 1.1851  data_time: 0.7461  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:04:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 20:04:52 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 20:04:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 20:04:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 20:04:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0886 s/iter. Eval: 0.0350 s/iter. Total: 0.1249 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 20:04:59 d2.evaluation.evaluator]: \u001b[0mInference done 59/61. Dataloading: 0.0016 s/iter. Inference: 0.0867 s/iter. Eval: 0.0214 s/iter. Total: 0.1098 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 20:05:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.339642 (0.113208 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:05:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.086696 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:05:00 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 20:05:00 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.059783760346650644\n",
      "\u001b[32m[12/27 20:05:16 d2.utils.events]: \u001b[0m eta: 0:30:24  iter: 6539  total_loss: 1.103  loss_cls: 0.2127  loss_box_reg: 0.2297  loss_mask: 0.2779  loss_rpn_cls: 0.09174  loss_rpn_loc: 0.229  time: 1.1852  data_time: 0.7524  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:05:38 d2.utils.events]: \u001b[0m eta: 0:30:13  iter: 6559  total_loss: 1.062  loss_cls: 0.1799  loss_box_reg: 0.234  loss_mask: 0.243  loss_rpn_cls: 0.0841  loss_rpn_loc: 0.203  time: 1.1849  data_time: 0.6605  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:06:07 d2.utils.events]: \u001b[0m eta: 0:30:13  iter: 6579  total_loss: 1.019  loss_cls: 0.1864  loss_box_reg: 0.216  loss_mask: 0.2942  loss_rpn_cls: 0.08224  loss_rpn_loc: 0.2155  time: 1.1856  data_time: 0.9683  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:06:33 d2.utils.events]: \u001b[0m eta: 0:30:03  iter: 6599  total_loss: 1.052  loss_cls: 0.1772  loss_box_reg: 0.1892  loss_mask: 0.297  loss_rpn_cls: 0.07117  loss_rpn_loc: 0.225  time: 1.1859  data_time: 0.8259  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:07:05 d2.utils.events]: \u001b[0m eta: 0:30:01  iter: 6619  total_loss: 1.067  loss_cls: 0.2176  loss_box_reg: 0.2418  loss_mask: 0.2908  loss_rpn_cls: 0.09776  loss_rpn_loc: 0.2234  time: 1.1868  data_time: 1.0379  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:07:31 d2.utils.events]: \u001b[0m eta: 0:30:09  iter: 6639  total_loss: 1.039  loss_cls: 0.1949  loss_box_reg: 0.2108  loss_mask: 0.2749  loss_rpn_cls: 0.09141  loss_rpn_loc: 0.2212  time: 1.1872  data_time: 0.8581  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:08:05 d2.utils.events]: \u001b[0m eta: 0:30:01  iter: 6659  total_loss: 1.077  loss_cls: 0.2212  loss_box_reg: 0.2706  loss_mask: 0.2883  loss_rpn_cls: 0.1008  loss_rpn_loc: 0.2266  time: 1.1887  data_time: 1.2216  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:08:26 d2.utils.events]: \u001b[0m eta: 0:29:48  iter: 6679  total_loss: 1.014  loss_cls: 0.1884  loss_box_reg: 0.2083  loss_mask: 0.2501  loss_rpn_cls: 0.06809  loss_rpn_loc: 0.1969  time: 1.1884  data_time: 0.6522  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:08:41 d2.utils.events]: \u001b[0m eta: 0:29:36  iter: 6699  total_loss: 0.9944  loss_cls: 0.1849  loss_box_reg: 0.2735  loss_mask: 0.2441  loss_rpn_cls: 0.0559  loss_rpn_loc: 0.2016  time: 1.1870  data_time: 0.3324  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:09:08 d2.utils.events]: \u001b[0m eta: 0:29:29  iter: 6719  total_loss: 1.028  loss_cls: 0.2189  loss_box_reg: 0.2148  loss_mask: 0.265  loss_rpn_cls: 0.07904  loss_rpn_loc: 0.1972  time: 1.1876  data_time: 0.9131  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:09:26 d2.utils.events]: \u001b[0m eta: 0:29:17  iter: 6739  total_loss: 0.9541  loss_cls: 0.1817  loss_box_reg: 0.1853  loss_mask: 0.2359  loss_rpn_cls: 0.06225  loss_rpn_loc: 0.1975  time: 1.1866  data_time: 0.4365  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:09:47 d2.utils.events]: \u001b[0m eta: 0:29:05  iter: 6759  total_loss: 1.08  loss_cls: 0.2017  loss_box_reg: 0.2255  loss_mask: 0.2749  loss_rpn_cls: 0.07178  loss_rpn_loc: 0.2192  time: 1.1863  data_time: 0.6345  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:10:14 d2.utils.events]: \u001b[0m eta: 0:28:56  iter: 6779  total_loss: 1.06  loss_cls: 0.2186  loss_box_reg: 0.2447  loss_mask: 0.2841  loss_rpn_cls: 0.09108  loss_rpn_loc: 0.2205  time: 1.1867  data_time: 0.8634  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:10:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 20:10:34 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 20:10:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 20:10:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 20:10:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0884 s/iter. Eval: 0.0275 s/iter. Total: 0.1173 s/iter. ETA=0:00:05\n",
      "\u001b[32m[12/27 20:10:41 d2.evaluation.evaluator]: \u001b[0mInference done 59/61. Dataloading: 0.0017 s/iter. Inference: 0.0866 s/iter. Eval: 0.0199 s/iter. Total: 0.1083 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 20:10:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.228132 (0.111217 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:10:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.086576 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:10:42 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 20:10:42 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.05694779917630809\n",
      "\u001b[32m[12/27 20:10:42 d2.utils.events]: \u001b[0m eta: 0:28:46  iter: 6799  total_loss: 1.11  loss_cls: 0.219  loss_box_reg: 0.2621  loss_mask: 0.319  loss_rpn_cls: 0.08042  loss_rpn_loc: 0.2238  time: 1.1862  data_time: 0.6034  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:10:59 d2.utils.events]: \u001b[0m eta: 0:28:34  iter: 6819  total_loss: 1.004  loss_cls: 0.1917  loss_box_reg: 0.2531  loss_mask: 0.2657  loss_rpn_cls: 0.05721  loss_rpn_loc: 0.2006  time: 1.1852  data_time: 0.4241  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:11:28 d2.utils.events]: \u001b[0m eta: 0:28:33  iter: 6839  total_loss: 1.092  loss_cls: 0.2097  loss_box_reg: 0.2448  loss_mask: 0.2825  loss_rpn_cls: 0.08498  loss_rpn_loc: 0.2102  time: 1.1860  data_time: 1.0027  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:11:44 d2.utils.events]: \u001b[0m eta: 0:28:13  iter: 6859  total_loss: 0.7721  loss_cls: 0.1443  loss_box_reg: 0.2009  loss_mask: 0.1998  loss_rpn_cls: 0.05208  loss_rpn_loc: 0.1782  time: 1.1850  data_time: 0.4098  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:12:16 d2.utils.events]: \u001b[0m eta: 0:28:01  iter: 6879  total_loss: 1.041  loss_cls: 0.2226  loss_box_reg: 0.2546  loss_mask: 0.272  loss_rpn_cls: 0.07929  loss_rpn_loc: 0.2178  time: 1.1861  data_time: 1.1227  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:12:38 d2.utils.events]: \u001b[0m eta: 0:27:48  iter: 6899  total_loss: 1.058  loss_cls: 0.2369  loss_box_reg: 0.2607  loss_mask: 0.2773  loss_rpn_cls: 0.08721  loss_rpn_loc: 0.1992  time: 1.1857  data_time: 0.6132  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:13:00 d2.utils.events]: \u001b[0m eta: 0:27:43  iter: 6919  total_loss: 1.068  loss_cls: 0.1998  loss_box_reg: 0.2571  loss_mask: 0.2735  loss_rpn_cls: 0.08969  loss_rpn_loc: 0.2138  time: 1.1853  data_time: 0.6023  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:13:20 d2.utils.events]: \u001b[0m eta: 0:27:36  iter: 6939  total_loss: 1.023  loss_cls: 0.1852  loss_box_reg: 0.2575  loss_mask: 0.2583  loss_rpn_cls: 0.06108  loss_rpn_loc: 0.2174  time: 1.1848  data_time: 0.5817  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:13:47 d2.utils.events]: \u001b[0m eta: 0:27:33  iter: 6959  total_loss: 1.183  loss_cls: 0.2239  loss_box_reg: 0.2718  loss_mask: 0.2829  loss_rpn_cls: 0.1049  loss_rpn_loc: 0.2291  time: 1.1852  data_time: 0.8703  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:14:17 d2.utils.events]: \u001b[0m eta: 0:27:20  iter: 6979  total_loss: 0.973  loss_cls: 0.2079  loss_box_reg: 0.2166  loss_mask: 0.2614  loss_rpn_cls: 0.09806  loss_rpn_loc: 0.2263  time: 1.1861  data_time: 1.0600  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:14:43 d2.utils.events]: \u001b[0m eta: 0:27:11  iter: 6999  total_loss: 0.9974  loss_cls: 0.1734  loss_box_reg: 0.201  loss_mask: 0.2879  loss_rpn_cls: 0.07441  loss_rpn_loc: 0.2167  time: 1.1865  data_time: 0.8503  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:15:17 d2.utils.events]: \u001b[0m eta: 0:27:00  iter: 7019  total_loss: 1.089  loss_cls: 0.1995  loss_box_reg: 0.2426  loss_mask: 0.3043  loss_rpn_cls: 0.08396  loss_rpn_loc: 0.2214  time: 1.1879  data_time: 1.2112  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:15:38 d2.utils.events]: \u001b[0m eta: 0:26:51  iter: 7039  total_loss: 1.142  loss_cls: 0.222  loss_box_reg: 0.2634  loss_mask: 0.2713  loss_rpn_cls: 0.07041  loss_rpn_loc: 0.1899  time: 1.1875  data_time: 0.6046  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:16:02 d2.utils.events]: \u001b[0m eta: 0:26:46  iter: 7059  total_loss: 1.019  loss_cls: 0.2027  loss_box_reg: 0.254  loss_mask: 0.2742  loss_rpn_cls: 0.05471  loss_rpn_loc: 0.1757  time: 1.1875  data_time: 0.7153  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:16:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 20:16:13 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 20:16:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 20:16:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 20:16:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0903 s/iter. Eval: 0.0413 s/iter. Total: 0.1331 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 20:16:20 d2.evaluation.evaluator]: \u001b[0mInference done 56/61. Dataloading: 0.0019 s/iter. Inference: 0.0879 s/iter. Eval: 0.0248 s/iter. Total: 0.1148 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 20:16:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.706110 (0.119752 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:16:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.088212 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:16:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 20:16:21 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06671175379235111\n",
      "\u001b[32m[12/27 20:16:29 d2.utils.events]: \u001b[0m eta: 0:26:36  iter: 7079  total_loss: 1.117  loss_cls: 0.2039  loss_box_reg: 0.2609  loss_mask: 0.2884  loss_rpn_cls: 0.07398  loss_rpn_loc: 0.2081  time: 1.1870  data_time: 0.5533  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:16:57 d2.utils.events]: \u001b[0m eta: 0:26:33  iter: 7099  total_loss: 1.119  loss_cls: 0.2221  loss_box_reg: 0.2663  loss_mask: 0.2866  loss_rpn_cls: 0.1021  loss_rpn_loc: 0.2137  time: 1.1875  data_time: 0.9110  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:17:21 d2.utils.events]: \u001b[0m eta: 0:26:29  iter: 7119  total_loss: 1.044  loss_cls: 0.1991  loss_box_reg: 0.2405  loss_mask: 0.2852  loss_rpn_cls: 0.08275  loss_rpn_loc: 0.1829  time: 1.1875  data_time: 0.7586  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:17:47 d2.utils.events]: \u001b[0m eta: 0:26:37  iter: 7139  total_loss: 1.069  loss_cls: 0.2181  loss_box_reg: 0.247  loss_mask: 0.2836  loss_rpn_cls: 0.09167  loss_rpn_loc: 0.2423  time: 1.1878  data_time: 0.8653  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:18:01 d2.utils.events]: \u001b[0m eta: 0:25:52  iter: 7159  total_loss: 0.8598  loss_cls: 0.1696  loss_box_reg: 0.2354  loss_mask: 0.2192  loss_rpn_cls: 0.0521  loss_rpn_loc: 0.182  time: 1.1864  data_time: 0.2626  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:18:24 d2.utils.events]: \u001b[0m eta: 0:25:46  iter: 7179  total_loss: 1.067  loss_cls: 0.2132  loss_box_reg: 0.2628  loss_mask: 0.2804  loss_rpn_cls: 0.08386  loss_rpn_loc: 0.2138  time: 1.1864  data_time: 0.7321  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:18:46 d2.utils.events]: \u001b[0m eta: 0:25:33  iter: 7199  total_loss: 0.9549  loss_cls: 0.1743  loss_box_reg: 0.1844  loss_mask: 0.2709  loss_rpn_cls: 0.08304  loss_rpn_loc: 0.2132  time: 1.1859  data_time: 0.5793  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:19:11 d2.utils.events]: \u001b[0m eta: 0:25:20  iter: 7219  total_loss: 1.134  loss_cls: 0.2007  loss_box_reg: 0.2555  loss_mask: 0.2912  loss_rpn_cls: 0.08128  loss_rpn_loc: 0.2296  time: 1.1860  data_time: 0.7572  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:19:47 d2.utils.events]: \u001b[0m eta: 0:25:24  iter: 7239  total_loss: 1.093  loss_cls: 0.2167  loss_box_reg: 0.1996  loss_mask: 0.2858  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.2258  time: 1.1876  data_time: 1.3092  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:20:08 d2.utils.events]: \u001b[0m eta: 0:25:18  iter: 7259  total_loss: 1.077  loss_cls: 0.2031  loss_box_reg: 0.2715  loss_mask: 0.2814  loss_rpn_cls: 0.07831  loss_rpn_loc: 0.1989  time: 1.1873  data_time: 0.6370  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:20:39 d2.utils.events]: \u001b[0m eta: 0:25:18  iter: 7279  total_loss: 1.093  loss_cls: 0.2365  loss_box_reg: 0.2215  loss_mask: 0.2783  loss_rpn_cls: 0.1052  loss_rpn_loc: 0.2369  time: 1.1882  data_time: 1.0804  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:21:05 d2.utils.events]: \u001b[0m eta: 0:24:51  iter: 7299  total_loss: 1.034  loss_cls: 0.1891  loss_box_reg: 0.2191  loss_mask: 0.2536  loss_rpn_cls: 0.06535  loss_rpn_loc: 0.2067  time: 1.1886  data_time: 0.8716  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:21:24 d2.utils.events]: \u001b[0m eta: 0:24:39  iter: 7319  total_loss: 0.9708  loss_cls: 0.1712  loss_box_reg: 0.2011  loss_mask: 0.2541  loss_rpn_cls: 0.0593  loss_rpn_loc: 0.2151  time: 1.1880  data_time: 0.5252  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:21:47 d2.utils.events]: \u001b[0m eta: 0:24:29  iter: 7339  total_loss: 0.9552  loss_cls: 0.185  loss_box_reg: 0.1935  loss_mask: 0.2592  loss_rpn_cls: 0.05781  loss_rpn_loc: 0.1962  time: 1.1878  data_time: 0.6975  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:21:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 20:21:53 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 20:21:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 20:21:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 20:21:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0016 s/iter. Inference: 0.0901 s/iter. Eval: 0.0408 s/iter. Total: 0.1325 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 20:22:00 d2.evaluation.evaluator]: \u001b[0mInference done 57/61. Dataloading: 0.0019 s/iter. Inference: 0.0879 s/iter. Eval: 0.0230 s/iter. Total: 0.1129 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 20:22:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.590346 (0.117685 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:22:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.088175 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:22:01 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 20:22:01 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06647160558669199\n",
      "\u001b[32m[12/27 20:22:14 d2.utils.events]: \u001b[0m eta: 0:25:09  iter: 7359  total_loss: 1.07  loss_cls: 0.2124  loss_box_reg: 0.2436  loss_mask: 0.2713  loss_rpn_cls: 0.06637  loss_rpn_loc: 0.207  time: 1.1872  data_time: 0.5275  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:22:34 d2.utils.events]: \u001b[0m eta: 0:24:58  iter: 7379  total_loss: 0.9705  loss_cls: 0.183  loss_box_reg: 0.2989  loss_mask: 0.2671  loss_rpn_cls: 0.0537  loss_rpn_loc: 0.1891  time: 1.1867  data_time: 0.5628  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:22:56 d2.utils.events]: \u001b[0m eta: 0:24:24  iter: 7399  total_loss: 1.064  loss_cls: 0.179  loss_box_reg: 0.2505  loss_mask: 0.2841  loss_rpn_cls: 0.07343  loss_rpn_loc: 0.2209  time: 1.1865  data_time: 0.6869  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:23:23 d2.utils.events]: \u001b[0m eta: 0:24:29  iter: 7419  total_loss: 0.9984  loss_cls: 0.1923  loss_box_reg: 0.2206  loss_mask: 0.2537  loss_rpn_cls: 0.08369  loss_rpn_loc: 0.2214  time: 1.1869  data_time: 0.8797  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:23:51 d2.utils.events]: \u001b[0m eta: 0:24:09  iter: 7439  total_loss: 1.108  loss_cls: 0.2099  loss_box_reg: 0.2781  loss_mask: 0.298  loss_rpn_cls: 0.07236  loss_rpn_loc: 0.1989  time: 1.1875  data_time: 0.9422  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:24:17 d2.utils.events]: \u001b[0m eta: 0:23:23  iter: 7459  total_loss: 0.8778  loss_cls: 0.1551  loss_box_reg: 0.1988  loss_mask: 0.239  loss_rpn_cls: 0.06929  loss_rpn_loc: 0.214  time: 1.1878  data_time: 0.8339  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:24:35 d2.utils.events]: \u001b[0m eta: 0:23:20  iter: 7479  total_loss: 0.8671  loss_cls: 0.1525  loss_box_reg: 0.2252  loss_mask: 0.2423  loss_rpn_cls: 0.0592  loss_rpn_loc: 0.1878  time: 1.1870  data_time: 0.4608  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:25:00 d2.utils.events]: \u001b[0m eta: 0:23:09  iter: 7499  total_loss: 1.058  loss_cls: 0.1839  loss_box_reg: 0.2132  loss_mask: 0.2892  loss_rpn_cls: 0.06991  loss_rpn_loc: 0.2037  time: 1.1871  data_time: 0.7772  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:25:25 d2.utils.events]: \u001b[0m eta: 0:22:49  iter: 7519  total_loss: 0.97  loss_cls: 0.1899  loss_box_reg: 0.2576  loss_mask: 0.2648  loss_rpn_cls: 0.05297  loss_rpn_loc: 0.1766  time: 1.1870  data_time: 0.7226  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:25:51 d2.utils.events]: \u001b[0m eta: 0:22:30  iter: 7539  total_loss: 1.067  loss_cls: 0.2107  loss_box_reg: 0.264  loss_mask: 0.2774  loss_rpn_cls: 0.0777  loss_rpn_loc: 0.2198  time: 1.1873  data_time: 0.8240  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:26:17 d2.utils.events]: \u001b[0m eta: 0:22:11  iter: 7559  total_loss: 1.15  loss_cls: 0.2085  loss_box_reg: 0.2314  loss_mask: 0.2883  loss_rpn_cls: 0.09208  loss_rpn_loc: 0.2301  time: 1.1876  data_time: 0.8617  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:26:43 d2.utils.events]: \u001b[0m eta: 0:21:52  iter: 7579  total_loss: 1.13  loss_cls: 0.229  loss_box_reg: 0.3074  loss_mask: 0.2807  loss_rpn_cls: 0.09186  loss_rpn_loc: 0.2183  time: 1.1879  data_time: 0.8239  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:27:02 d2.utils.events]: \u001b[0m eta: 0:21:34  iter: 7599  total_loss: 0.9837  loss_cls: 0.1972  loss_box_reg: 0.2403  loss_mask: 0.2714  loss_rpn_cls: 0.06198  loss_rpn_loc: 0.2148  time: 1.1872  data_time: 0.4912  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:27:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 20:27:24 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 20:27:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 20:27:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 20:27:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0903 s/iter. Eval: 0.0312 s/iter. Total: 0.1229 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 20:27:31 d2.evaluation.evaluator]: \u001b[0mInference done 57/61. Dataloading: 0.0017 s/iter. Inference: 0.0870 s/iter. Eval: 0.0218 s/iter. Total: 0.1106 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 20:27:32 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.478754 (0.115692 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:27:32 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087282 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:27:32 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 20:27:32 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06029021275380219\n",
      "\u001b[32m[12/27 20:27:34 d2.utils.events]: \u001b[0m eta: 0:21:15  iter: 7619  total_loss: 1.126  loss_cls: 0.2318  loss_box_reg: 0.2666  loss_mask: 0.2846  loss_rpn_cls: 0.06939  loss_rpn_loc: 0.237  time: 1.1873  data_time: 0.7896  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:28:01 d2.utils.events]: \u001b[0m eta: 0:21:04  iter: 7639  total_loss: 1.162  loss_cls: 0.2234  loss_box_reg: 0.3103  loss_mask: 0.312  loss_rpn_cls: 0.09472  loss_rpn_loc: 0.2446  time: 1.1878  data_time: 0.8954  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:28:25 d2.utils.events]: \u001b[0m eta: 0:20:43  iter: 7659  total_loss: 0.9776  loss_cls: 0.1742  loss_box_reg: 0.1981  loss_mask: 0.2506  loss_rpn_cls: 0.06496  loss_rpn_loc: 0.203  time: 1.1878  data_time: 0.7585  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:28:45 d2.utils.events]: \u001b[0m eta: 0:20:31  iter: 7679  total_loss: 1.006  loss_cls: 0.1805  loss_box_reg: 0.2276  loss_mask: 0.2772  loss_rpn_cls: 0.05955  loss_rpn_loc: 0.2033  time: 1.1872  data_time: 0.5352  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:29:10 d2.utils.events]: \u001b[0m eta: 0:20:23  iter: 7699  total_loss: 1.021  loss_cls: 0.1835  loss_box_reg: 0.2006  loss_mask: 0.3053  loss_rpn_cls: 0.08224  loss_rpn_loc: 0.2107  time: 1.1874  data_time: 0.8175  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:29:32 d2.utils.events]: \u001b[0m eta: 0:20:12  iter: 7719  total_loss: 1.101  loss_cls: 0.218  loss_box_reg: 0.299  loss_mask: 0.2957  loss_rpn_cls: 0.07494  loss_rpn_loc: 0.2154  time: 1.1872  data_time: 0.6383  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:29:57 d2.utils.events]: \u001b[0m eta: 0:20:12  iter: 7739  total_loss: 1.082  loss_cls: 0.205  loss_box_reg: 0.2357  loss_mask: 0.2847  loss_rpn_cls: 0.08044  loss_rpn_loc: 0.1962  time: 1.1873  data_time: 0.8043  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:30:22 d2.utils.events]: \u001b[0m eta: 0:20:08  iter: 7759  total_loss: 1.023  loss_cls: 0.1993  loss_box_reg: 0.2298  loss_mask: 0.2743  loss_rpn_cls: 0.07123  loss_rpn_loc: 0.194  time: 1.1876  data_time: 0.8476  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:30:44 d2.utils.events]: \u001b[0m eta: 0:20:00  iter: 7779  total_loss: 1.071  loss_cls: 0.2034  loss_box_reg: 0.2951  loss_mask: 0.2746  loss_rpn_cls: 0.06612  loss_rpn_loc: 0.2114  time: 1.1873  data_time: 0.6371  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:31:06 d2.utils.events]: \u001b[0m eta: 0:19:49  iter: 7799  total_loss: 1.066  loss_cls: 0.2131  loss_box_reg: 0.2215  loss_mask: 0.2662  loss_rpn_cls: 0.07275  loss_rpn_loc: 0.1992  time: 1.1869  data_time: 0.5727  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:31:28 d2.utils.events]: \u001b[0m eta: 0:19:36  iter: 7819  total_loss: 1.013  loss_cls: 0.1933  loss_box_reg: 0.2437  loss_mask: 0.2604  loss_rpn_cls: 0.05249  loss_rpn_loc: 0.205  time: 1.1865  data_time: 0.6115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:31:49 d2.utils.events]: \u001b[0m eta: 0:19:18  iter: 7839  total_loss: 1.03  loss_cls: 0.1927  loss_box_reg: 0.2522  loss_mask: 0.2498  loss_rpn_cls: 0.07413  loss_rpn_loc: 0.1954  time: 1.1862  data_time: 0.6143  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:32:16 d2.utils.events]: \u001b[0m eta: 0:19:17  iter: 7859  total_loss: 1.091  loss_cls: 0.2072  loss_box_reg: 0.2077  loss_mask: 0.2561  loss_rpn_cls: 0.09463  loss_rpn_loc: 0.2057  time: 1.1866  data_time: 0.8964  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:32:42 d2.utils.events]: \u001b[0m eta: 0:19:11  iter: 7879  total_loss: 1.071  loss_cls: 0.2075  loss_box_reg: 0.2382  loss_mask: 0.2807  loss_rpn_cls: 0.0825  loss_rpn_loc: 0.2049  time: 1.1869  data_time: 0.8488  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:32:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 20:32:49 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 20:32:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 20:32:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 20:32:51 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0893 s/iter. Eval: 0.0382 s/iter. Total: 0.1289 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 20:32:56 d2.evaluation.evaluator]: \u001b[0mInference done 57/61. Dataloading: 0.0017 s/iter. Inference: 0.0871 s/iter. Eval: 0.0236 s/iter. Total: 0.1125 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 20:32:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.583092 (0.117555 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:32:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087469 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:32:57 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 20:32:57 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06513282221287894\n",
      "\u001b[32m[12/27 20:33:10 d2.utils.events]: \u001b[0m eta: 0:19:02  iter: 7899  total_loss: 0.9626  loss_cls: 0.1705  loss_box_reg: 0.2193  loss_mask: 0.2675  loss_rpn_cls: 0.05936  loss_rpn_loc: 0.2234  time: 1.1865  data_time: 0.5939  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:33:37 d2.utils.events]: \u001b[0m eta: 0:19:00  iter: 7919  total_loss: 1.083  loss_cls: 0.2124  loss_box_reg: 0.2528  loss_mask: 0.2884  loss_rpn_cls: 0.09944  loss_rpn_loc: 0.2393  time: 1.1868  data_time: 0.8776  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:34:01 d2.utils.events]: \u001b[0m eta: 0:18:45  iter: 7939  total_loss: 0.9749  loss_cls: 0.2048  loss_box_reg: 0.2498  loss_mask: 0.2623  loss_rpn_cls: 0.06454  loss_rpn_loc: 0.1867  time: 1.1868  data_time: 0.7468  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:34:29 d2.utils.events]: \u001b[0m eta: 0:18:30  iter: 7959  total_loss: 1.015  loss_cls: 0.1999  loss_box_reg: 0.248  loss_mask: 0.2564  loss_rpn_cls: 0.06825  loss_rpn_loc: 0.2025  time: 1.1875  data_time: 0.9541  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:34:58 d2.utils.events]: \u001b[0m eta: 0:18:18  iter: 7979  total_loss: 0.9908  loss_cls: 0.1858  loss_box_reg: 0.2215  loss_mask: 0.2808  loss_rpn_cls: 0.08547  loss_rpn_loc: 0.2083  time: 1.1881  data_time: 0.9985  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:35:22 d2.utils.events]: \u001b[0m eta: 0:18:08  iter: 7999  total_loss: 1.093  loss_cls: 0.2116  loss_box_reg: 0.2602  loss_mask: 0.2899  loss_rpn_cls: 0.07951  loss_rpn_loc: 0.2146  time: 1.1881  data_time: 0.7302  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:35:54 d2.utils.events]: \u001b[0m eta: 0:17:59  iter: 8019  total_loss: 1.036  loss_cls: 0.2106  loss_box_reg: 0.2438  loss_mask: 0.2685  loss_rpn_cls: 0.08974  loss_rpn_loc: 0.2078  time: 1.1892  data_time: 1.1388  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:36:16 d2.utils.events]: \u001b[0m eta: 0:17:45  iter: 8039  total_loss: 0.9775  loss_cls: 0.1857  loss_box_reg: 0.2286  loss_mask: 0.2482  loss_rpn_cls: 0.08401  loss_rpn_loc: 0.2033  time: 1.1888  data_time: 0.6221  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:36:44 d2.utils.events]: \u001b[0m eta: 0:17:41  iter: 8059  total_loss: 1.071  loss_cls: 0.222  loss_box_reg: 0.2505  loss_mask: 0.282  loss_rpn_cls: 0.08748  loss_rpn_loc: 0.2046  time: 1.1894  data_time: 0.9656  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:37:08 d2.utils.events]: \u001b[0m eta: 0:17:30  iter: 8079  total_loss: 0.9921  loss_cls: 0.1836  loss_box_reg: 0.1945  loss_mask: 0.2427  loss_rpn_cls: 0.07071  loss_rpn_loc: 0.2047  time: 1.1895  data_time: 0.7837  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:37:32 d2.utils.events]: \u001b[0m eta: 0:17:15  iter: 8099  total_loss: 0.9687  loss_cls: 0.1759  loss_box_reg: 0.1846  loss_mask: 0.2849  loss_rpn_cls: 0.08433  loss_rpn_loc: 0.2085  time: 1.1894  data_time: 0.6809  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:37:53 d2.utils.events]: \u001b[0m eta: 0:16:56  iter: 8119  total_loss: 1.001  loss_cls: 0.1902  loss_box_reg: 0.2165  loss_mask: 0.2659  loss_rpn_cls: 0.06749  loss_rpn_loc: 0.2163  time: 1.1889  data_time: 0.5493  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:38:16 d2.utils.events]: \u001b[0m eta: 0:16:37  iter: 8139  total_loss: 1.041  loss_cls: 0.1828  loss_box_reg: 0.2596  loss_mask: 0.2712  loss_rpn_cls: 0.07294  loss_rpn_loc: 0.1993  time: 1.1887  data_time: 0.6986  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:38:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 20:38:36 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 20:38:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 20:38:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 20:38:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0015 s/iter. Inference: 0.0907 s/iter. Eval: 0.0416 s/iter. Total: 0.1338 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 20:38:43 d2.evaluation.evaluator]: \u001b[0mInference done 57/61. Dataloading: 0.0018 s/iter. Inference: 0.0876 s/iter. Eval: 0.0240 s/iter. Total: 0.1135 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 20:38:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.630854 (0.118408 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:38:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087876 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:38:44 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 20:38:44 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06269850095072563\n",
      "\u001b[32m[12/27 20:38:44 d2.utils.events]: \u001b[0m eta: 0:16:36  iter: 8159  total_loss: 0.5653  loss_cls: 0.07881  loss_box_reg: 0.07636  loss_mask: 0.1136  loss_rpn_cls: 0.0515  loss_rpn_loc: 0.2013  time: 1.1882  data_time: 0.5550  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:38:58 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 8179  total_loss: 0.5604  loss_cls: 0.05051  loss_box_reg: 0.08229  loss_mask: 0.1207  loss_rpn_cls: 0.05213  loss_rpn_loc: 0.1871  time: 1.1870  data_time: 0.2777  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:39:16 d2.utils.events]: \u001b[0m eta: 0:15:56  iter: 8199  total_loss: 0.9875  loss_cls: 0.1652  loss_box_reg: 0.1904  loss_mask: 0.2675  loss_rpn_cls: 0.05727  loss_rpn_loc: 0.1902  time: 1.1864  data_time: 0.4991  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:39:42 d2.utils.events]: \u001b[0m eta: 0:15:45  iter: 8219  total_loss: 1.104  loss_cls: 0.1941  loss_box_reg: 0.266  loss_mask: 0.3029  loss_rpn_cls: 0.08575  loss_rpn_loc: 0.2013  time: 1.1867  data_time: 0.8652  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:40:08 d2.utils.events]: \u001b[0m eta: 0:15:35  iter: 8239  total_loss: 0.9914  loss_cls: 0.2068  loss_box_reg: 0.2324  loss_mask: 0.258  loss_rpn_cls: 0.06799  loss_rpn_loc: 0.2016  time: 1.1869  data_time: 0.8310  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:40:36 d2.utils.events]: \u001b[0m eta: 0:15:24  iter: 8259  total_loss: 0.9656  loss_cls: 0.1851  loss_box_reg: 0.213  loss_mask: 0.2554  loss_rpn_cls: 0.08321  loss_rpn_loc: 0.2082  time: 1.1874  data_time: 0.9453  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:40:56 d2.utils.events]: \u001b[0m eta: 0:15:13  iter: 8279  total_loss: 0.9833  loss_cls: 0.1695  loss_box_reg: 0.2398  loss_mask: 0.2521  loss_rpn_cls: 0.06701  loss_rpn_loc: 0.1896  time: 1.1870  data_time: 0.5967  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:41:17 d2.utils.events]: \u001b[0m eta: 0:15:03  iter: 8299  total_loss: 1.11  loss_cls: 0.2226  loss_box_reg: 0.2566  loss_mask: 0.2856  loss_rpn_cls: 0.08329  loss_rpn_loc: 0.2074  time: 1.1867  data_time: 0.6173  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:41:38 d2.utils.events]: \u001b[0m eta: 0:14:52  iter: 8319  total_loss: 0.9046  loss_cls: 0.1688  loss_box_reg: 0.2156  loss_mask: 0.2524  loss_rpn_cls: 0.06282  loss_rpn_loc: 0.1964  time: 1.1863  data_time: 0.5805  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:42:02 d2.utils.events]: \u001b[0m eta: 0:14:42  iter: 8339  total_loss: 1.116  loss_cls: 0.1968  loss_box_reg: 0.262  loss_mask: 0.2964  loss_rpn_cls: 0.07978  loss_rpn_loc: 0.2076  time: 1.1864  data_time: 0.7675  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:42:23 d2.utils.events]: \u001b[0m eta: 0:14:31  iter: 8359  total_loss: 0.9832  loss_cls: 0.182  loss_box_reg: 0.2495  loss_mask: 0.2421  loss_rpn_cls: 0.06765  loss_rpn_loc: 0.2235  time: 1.1860  data_time: 0.5777  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:42:50 d2.utils.events]: \u001b[0m eta: 0:14:26  iter: 8379  total_loss: 1.127  loss_cls: 0.2321  loss_box_reg: 0.3145  loss_mask: 0.291  loss_rpn_cls: 0.09797  loss_rpn_loc: 0.2205  time: 1.1864  data_time: 0.9193  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:43:22 d2.utils.events]: \u001b[0m eta: 0:14:17  iter: 8399  total_loss: 0.9869  loss_cls: 0.1833  loss_box_reg: 0.2029  loss_mask: 0.2833  loss_rpn_cls: 0.08682  loss_rpn_loc: 0.2262  time: 1.1873  data_time: 1.0864  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:43:47 d2.utils.events]: \u001b[0m eta: 0:14:06  iter: 8419  total_loss: 1.094  loss_cls: 0.2112  loss_box_reg: 0.246  loss_mask: 0.2781  loss_rpn_cls: 0.08298  loss_rpn_loc: 0.2256  time: 1.1873  data_time: 0.7437  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:44:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 20:44:00 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 20:44:00 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 20:44:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 20:44:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0013 s/iter. Inference: 0.0894 s/iter. Eval: 0.0389 s/iter. Total: 0.1297 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 20:44:07 d2.evaluation.evaluator]: \u001b[0mInference done 57/61. Dataloading: 0.0017 s/iter. Inference: 0.0874 s/iter. Eval: 0.0233 s/iter. Total: 0.1125 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 20:44:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.583939 (0.117570 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:44:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087711 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:44:07 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 20:44:07 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06470955712404791\n",
      "\u001b[32m[12/27 20:44:18 d2.utils.events]: \u001b[0m eta: 0:13:54  iter: 8439  total_loss: 1.032  loss_cls: 0.1946  loss_box_reg: 0.2453  loss_mask: 0.2591  loss_rpn_cls: 0.06336  loss_rpn_loc: 0.1874  time: 1.1872  data_time: 0.7162  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:44:47 d2.utils.events]: \u001b[0m eta: 0:13:47  iter: 8459  total_loss: 1.073  loss_cls: 0.2212  loss_box_reg: 0.3011  loss_mask: 0.2845  loss_rpn_cls: 0.06732  loss_rpn_loc: 0.2086  time: 1.1878  data_time: 0.9745  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:45:13 d2.utils.events]: \u001b[0m eta: 0:13:36  iter: 8479  total_loss: 0.9547  loss_cls: 0.1673  loss_box_reg: 0.1771  loss_mask: 0.2659  loss_rpn_cls: 0.07683  loss_rpn_loc: 0.1882  time: 1.1880  data_time: 0.8492  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:45:32 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 8499  total_loss: 1.113  loss_cls: 0.1923  loss_box_reg: 0.2588  loss_mask: 0.2635  loss_rpn_cls: 0.06934  loss_rpn_loc: 0.2207  time: 1.1876  data_time: 0.5629  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:45:59 d2.utils.events]: \u001b[0m eta: 0:13:25  iter: 8519  total_loss: 1.11  loss_cls: 0.2279  loss_box_reg: 0.2869  loss_mask: 0.2678  loss_rpn_cls: 0.08576  loss_rpn_loc: 0.2253  time: 1.1879  data_time: 0.8452  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:46:28 d2.utils.events]: \u001b[0m eta: 0:13:19  iter: 8539  total_loss: 1.049  loss_cls: 0.206  loss_box_reg: 0.2412  loss_mask: 0.2768  loss_rpn_cls: 0.08581  loss_rpn_loc: 0.2158  time: 1.1885  data_time: 0.9983  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:47:03 d2.utils.events]: \u001b[0m eta: 0:13:09  iter: 8559  total_loss: 0.9698  loss_cls: 0.1781  loss_box_reg: 0.1915  loss_mask: 0.2597  loss_rpn_cls: 0.05715  loss_rpn_loc: 0.2089  time: 1.1898  data_time: 1.2744  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:47:28 d2.utils.events]: \u001b[0m eta: 0:12:55  iter: 8579  total_loss: 0.9871  loss_cls: 0.1905  loss_box_reg: 0.219  loss_mask: 0.2743  loss_rpn_cls: 0.07452  loss_rpn_loc: 0.206  time: 1.1900  data_time: 0.8498  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:47:48 d2.utils.events]: \u001b[0m eta: 0:12:46  iter: 8599  total_loss: 0.9384  loss_cls: 0.2019  loss_box_reg: 0.2167  loss_mask: 0.2365  loss_rpn_cls: 0.05902  loss_rpn_loc: 0.2065  time: 1.1895  data_time: 0.5218  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:48:09 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 8619  total_loss: 0.5551  loss_cls: 0.09328  loss_box_reg: 0.07558  loss_mask: 0.1176  loss_rpn_cls: 0.0633  loss_rpn_loc: 0.1918  time: 1.1892  data_time: 0.6382  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:48:30 d2.utils.events]: \u001b[0m eta: 0:12:19  iter: 8639  total_loss: 1.033  loss_cls: 0.1903  loss_box_reg: 0.2284  loss_mask: 0.2661  loss_rpn_cls: 0.0768  loss_rpn_loc: 0.1917  time: 1.1889  data_time: 0.6192  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:48:51 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 8659  total_loss: 1.113  loss_cls: 0.2181  loss_box_reg: 0.2766  loss_mask: 0.2937  loss_rpn_cls: 0.08354  loss_rpn_loc: 0.2147  time: 1.1886  data_time: 0.6075  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:49:09 d2.utils.events]: \u001b[0m eta: 0:12:02  iter: 8679  total_loss: 0.7588  loss_cls: 0.138  loss_box_reg: 0.1935  loss_mask: 0.2064  loss_rpn_cls: 0.05602  loss_rpn_loc: 0.2032  time: 1.1879  data_time: 0.4616  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:49:35 d2.utils.events]: \u001b[0m eta: 0:11:50  iter: 8699  total_loss: 1.078  loss_cls: 0.2356  loss_box_reg: 0.2629  loss_mask: 0.281  loss_rpn_cls: 0.08031  loss_rpn_loc: 0.2273  time: 1.1880  data_time: 0.7764  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:49:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 20:49:38 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 20:49:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 20:49:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 20:49:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0020 s/iter. Inference: 0.0975 s/iter. Eval: 0.0601 s/iter. Total: 0.1595 s/iter. ETA=0:00:07\n",
      "\u001b[32m[12/27 20:49:46 d2.evaluation.evaluator]: \u001b[0mInference done 57/61. Dataloading: 0.0020 s/iter. Inference: 0.0886 s/iter. Eval: 0.0251 s/iter. Total: 0.1158 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 20:49:46 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.757706 (0.120673 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:49:46 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.088818 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:49:46 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 20:49:46 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0632093354960766\n",
      "\u001b[32m[12/27 20:50:04 d2.utils.events]: \u001b[0m eta: 0:11:34  iter: 8719  total_loss: 0.9101  loss_cls: 0.1705  loss_box_reg: 0.2129  loss_mask: 0.2711  loss_rpn_cls: 0.04416  loss_rpn_loc: 0.1969  time: 1.1874  data_time: 0.5225  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:50:28 d2.utils.events]: \u001b[0m eta: 0:11:17  iter: 8739  total_loss: 1.074  loss_cls: 0.1864  loss_box_reg: 0.2363  loss_mask: 0.27  loss_rpn_cls: 0.06923  loss_rpn_loc: 0.2097  time: 1.1875  data_time: 0.7613  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:50:54 d2.utils.events]: \u001b[0m eta: 0:11:06  iter: 8759  total_loss: 0.9551  loss_cls: 0.1628  loss_box_reg: 0.1726  loss_mask: 0.2878  loss_rpn_cls: 0.04981  loss_rpn_loc: 0.1988  time: 1.1878  data_time: 0.9047  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:51:20 d2.utils.events]: \u001b[0m eta: 0:10:55  iter: 8779  total_loss: 0.9828  loss_cls: 0.1817  loss_box_reg: 0.2319  loss_mask: 0.2676  loss_rpn_cls: 0.05538  loss_rpn_loc: 0.2029  time: 1.1880  data_time: 0.8242  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:51:41 d2.utils.events]: \u001b[0m eta: 0:10:45  iter: 8799  total_loss: 1.025  loss_cls: 0.1904  loss_box_reg: 0.2242  loss_mask: 0.2715  loss_rpn_cls: 0.06891  loss_rpn_loc: 0.1804  time: 1.1877  data_time: 0.6135  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:51:57 d2.utils.events]: \u001b[0m eta: 0:10:34  iter: 8819  total_loss: 0.8636  loss_cls: 0.1471  loss_box_reg: 0.1926  loss_mask: 0.2338  loss_rpn_cls: 0.05935  loss_rpn_loc: 0.1904  time: 1.1868  data_time: 0.3793  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:52:21 d2.utils.events]: \u001b[0m eta: 0:10:27  iter: 8839  total_loss: 1.217  loss_cls: 0.2539  loss_box_reg: 0.3051  loss_mask: 0.2995  loss_rpn_cls: 0.09066  loss_rpn_loc: 0.2174  time: 1.1869  data_time: 0.7702  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:52:47 d2.utils.events]: \u001b[0m eta: 0:10:18  iter: 8859  total_loss: 0.9915  loss_cls: 0.1931  loss_box_reg: 0.2318  loss_mask: 0.2695  loss_rpn_cls: 0.08357  loss_rpn_loc: 0.2212  time: 1.1871  data_time: 0.8230  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:53:20 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 8879  total_loss: 1.103  loss_cls: 0.2009  loss_box_reg: 0.2556  loss_mask: 0.2854  loss_rpn_cls: 0.07663  loss_rpn_loc: 0.2002  time: 1.1882  data_time: 1.1927  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:53:42 d2.utils.events]: \u001b[0m eta: 0:09:58  iter: 8899  total_loss: 0.9561  loss_cls: 0.1882  loss_box_reg: 0.2392  loss_mask: 0.2446  loss_rpn_cls: 0.0702  loss_rpn_loc: 0.2014  time: 1.1880  data_time: 0.6679  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:54:01 d2.utils.events]: \u001b[0m eta: 0:09:40  iter: 8919  total_loss: 0.8492  loss_cls: 0.1526  loss_box_reg: 0.1671  loss_mask: 0.2362  loss_rpn_cls: 0.04982  loss_rpn_loc: 0.2165  time: 1.1874  data_time: 0.5045  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:54:28 d2.utils.events]: \u001b[0m eta: 0:09:33  iter: 8939  total_loss: 1.063  loss_cls: 0.2238  loss_box_reg: 0.2564  loss_mask: 0.2897  loss_rpn_cls: 0.07598  loss_rpn_loc: 0.215  time: 1.1878  data_time: 0.9294  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:54:58 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 8959  total_loss: 1.155  loss_cls: 0.2187  loss_box_reg: 0.2828  loss_mask: 0.2914  loss_rpn_cls: 0.08301  loss_rpn_loc: 0.2214  time: 1.1885  data_time: 0.9952  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:55:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 20:55:13 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 20:55:13 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 20:55:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 20:55:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0018 s/iter. Inference: 0.0948 s/iter. Eval: 0.0409 s/iter. Total: 0.1374 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 20:55:20 d2.evaluation.evaluator]: \u001b[0mInference done 55/61. Dataloading: 0.0023 s/iter. Inference: 0.0916 s/iter. Eval: 0.0249 s/iter. Total: 0.1189 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 20:55:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.863400 (0.122561 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:55:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.091353 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 20:55:21 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 20:55:21 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06542588860367418\n",
      "\u001b[32m[12/27 20:55:25 d2.utils.events]: \u001b[0m eta: 0:09:15  iter: 8979  total_loss: 1.092  loss_cls: 0.1951  loss_box_reg: 0.2331  loss_mask: 0.2947  loss_rpn_cls: 0.07123  loss_rpn_loc: 0.2157  time: 1.1879  data_time: 0.4795  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:55:44 d2.utils.events]: \u001b[0m eta: 0:08:59  iter: 8999  total_loss: 1.067  loss_cls: 0.1857  loss_box_reg: 0.2665  loss_mask: 0.2828  loss_rpn_cls: 0.06355  loss_rpn_loc: 0.2101  time: 1.1872  data_time: 0.4713  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:56:04 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 9019  total_loss: 0.9191  loss_cls: 0.1786  loss_box_reg: 0.234  loss_mask: 0.2439  loss_rpn_cls: 0.05047  loss_rpn_loc: 0.208  time: 1.1867  data_time: 0.5138  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:56:22 d2.utils.events]: \u001b[0m eta: 0:08:35  iter: 9039  total_loss: 1.009  loss_cls: 0.1774  loss_box_reg: 0.2236  loss_mask: 0.2527  loss_rpn_cls: 0.07032  loss_rpn_loc: 0.1983  time: 1.1860  data_time: 0.4739  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:56:40 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 9059  total_loss: 0.9217  loss_cls: 0.1771  loss_box_reg: 0.2451  loss_mask: 0.2419  loss_rpn_cls: 0.04766  loss_rpn_loc: 0.1957  time: 1.1854  data_time: 0.4893  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:57:09 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 9079  total_loss: 0.9713  loss_cls: 0.1852  loss_box_reg: 0.2111  loss_mask: 0.268  loss_rpn_cls: 0.07304  loss_rpn_loc: 0.2055  time: 1.1860  data_time: 0.9615  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:57:30 d2.utils.events]: \u001b[0m eta: 0:08:00  iter: 9099  total_loss: 1.046  loss_cls: 0.2162  loss_box_reg: 0.2764  loss_mask: 0.2711  loss_rpn_cls: 0.04602  loss_rpn_loc: 0.1938  time: 1.1857  data_time: 0.6423  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:57:55 d2.utils.events]: \u001b[0m eta: 0:07:52  iter: 9119  total_loss: 1.052  loss_cls: 0.1928  loss_box_reg: 0.2257  loss_mask: 0.2805  loss_rpn_cls: 0.07517  loss_rpn_loc: 0.194  time: 1.1858  data_time: 0.7799  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:58:29 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 9139  total_loss: 1.033  loss_cls: 0.202  loss_box_reg: 0.222  loss_mask: 0.2783  loss_rpn_cls: 0.08296  loss_rpn_loc: 0.2122  time: 1.1869  data_time: 1.2456  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:58:53 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 9159  total_loss: 1.076  loss_cls: 0.208  loss_box_reg: 0.3099  loss_mask: 0.2861  loss_rpn_cls: 0.07569  loss_rpn_loc: 0.211  time: 1.1869  data_time: 0.7411  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:59:25 d2.utils.events]: \u001b[0m eta: 0:07:29  iter: 9179  total_loss: 1.134  loss_cls: 0.2261  loss_box_reg: 0.2514  loss_mask: 0.2922  loss_rpn_cls: 0.08532  loss_rpn_loc: 0.2242  time: 1.1878  data_time: 1.1400  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 20:59:44 d2.utils.events]: \u001b[0m eta: 0:07:18  iter: 9199  total_loss: 0.935  loss_cls: 0.1771  loss_box_reg: 0.2368  loss_mask: 0.2563  loss_rpn_cls: 0.0452  loss_rpn_loc: 0.1925  time: 1.1874  data_time: 0.5458  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:00:09 d2.utils.events]: \u001b[0m eta: 0:07:02  iter: 9219  total_loss: 1.006  loss_cls: 0.1927  loss_box_reg: 0.2269  loss_mask: 0.267  loss_rpn_cls: 0.05399  loss_rpn_loc: 0.211  time: 1.1874  data_time: 0.7778  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:00:42 d2.utils.events]: \u001b[0m eta: 0:06:54  iter: 9239  total_loss: 1.045  loss_cls: 0.2057  loss_box_reg: 0.2117  loss_mask: 0.2693  loss_rpn_cls: 0.09328  loss_rpn_loc: 0.239  time: 1.1885  data_time: 1.2077  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:00:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 21:00:51 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 21:00:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 21:00:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 21:00:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0017 s/iter. Inference: 0.0911 s/iter. Eval: 0.0393 s/iter. Total: 0.1320 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 21:00:58 d2.evaluation.evaluator]: \u001b[0mInference done 58/61. Dataloading: 0.0017 s/iter. Inference: 0.0870 s/iter. Eval: 0.0215 s/iter. Total: 0.1103 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 21:00:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.446070 (0.115108 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 21:00:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087277 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 21:00:58 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 21:00:58 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06060322814560518\n",
      "\u001b[32m[12/27 21:01:14 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 9259  total_loss: 1.041  loss_cls: 0.1921  loss_box_reg: 0.2364  loss_mask: 0.2736  loss_rpn_cls: 0.08104  loss_rpn_loc: 0.2023  time: 1.1885  data_time: 0.7614  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:01:35 d2.utils.events]: \u001b[0m eta: 0:06:30  iter: 9279  total_loss: 0.9667  loss_cls: 0.1837  loss_box_reg: 0.1955  loss_mask: 0.2689  loss_rpn_cls: 0.07912  loss_rpn_loc: 0.1909  time: 1.1882  data_time: 0.6140  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:01:59 d2.utils.events]: \u001b[0m eta: 0:06:19  iter: 9299  total_loss: 0.9879  loss_cls: 0.18  loss_box_reg: 0.1904  loss_mask: 0.2555  loss_rpn_cls: 0.07461  loss_rpn_loc: 0.2128  time: 1.1881  data_time: 0.6953  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:02:23 d2.utils.events]: \u001b[0m eta: 0:06:11  iter: 9319  total_loss: 1.021  loss_cls: 0.2065  loss_box_reg: 0.2411  loss_mask: 0.2693  loss_rpn_cls: 0.07908  loss_rpn_loc: 0.199  time: 1.1880  data_time: 0.6984  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:02:48 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 9339  total_loss: 1.069  loss_cls: 0.1951  loss_box_reg: 0.2351  loss_mask: 0.2907  loss_rpn_cls: 0.07642  loss_rpn_loc: 0.2161  time: 1.1882  data_time: 0.8257  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:03:12 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 9359  total_loss: 0.7913  loss_cls: 0.1511  loss_box_reg: 0.1441  loss_mask: 0.2301  loss_rpn_cls: 0.04998  loss_rpn_loc: 0.2033  time: 1.1882  data_time: 0.7716  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:03:37 d2.utils.events]: \u001b[0m eta: 0:05:36  iter: 9379  total_loss: 1.052  loss_cls: 0.1982  loss_box_reg: 0.2243  loss_mask: 0.2704  loss_rpn_cls: 0.06549  loss_rpn_loc: 0.1905  time: 1.1883  data_time: 0.8041  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:04:08 d2.utils.events]: \u001b[0m eta: 0:05:25  iter: 9399  total_loss: 1.022  loss_cls: 0.1794  loss_box_reg: 0.2382  loss_mask: 0.2711  loss_rpn_cls: 0.06692  loss_rpn_loc: 0.196  time: 1.1891  data_time: 1.0850  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:04:26 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 9419  total_loss: 1.093  loss_cls: 0.2196  loss_box_reg: 0.2795  loss_mask: 0.2547  loss_rpn_cls: 0.07199  loss_rpn_loc: 0.209  time: 1.1885  data_time: 0.4952  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:04:53 d2.utils.events]: \u001b[0m eta: 0:05:09  iter: 9439  total_loss: 1.034  loss_cls: 0.1967  loss_box_reg: 0.2465  loss_mask: 0.259  loss_rpn_cls: 0.07527  loss_rpn_loc: 0.2116  time: 1.1888  data_time: 0.8873  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:05:19 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 9459  total_loss: 1.043  loss_cls: 0.2041  loss_box_reg: 0.2203  loss_mask: 0.2883  loss_rpn_cls: 0.07913  loss_rpn_loc: 0.1924  time: 1.1890  data_time: 0.8317  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:05:41 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 9479  total_loss: 0.9001  loss_cls: 0.172  loss_box_reg: 0.2077  loss_mask: 0.2535  loss_rpn_cls: 0.04548  loss_rpn_loc: 0.1751  time: 1.1888  data_time: 0.6581  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:06:12 d2.utils.events]: \u001b[0m eta: 0:04:36  iter: 9499  total_loss: 1.175  loss_cls: 0.2163  loss_box_reg: 0.2902  loss_mask: 0.2916  loss_rpn_cls: 0.09134  loss_rpn_loc: 0.2258  time: 1.1896  data_time: 1.1006  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:06:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 21:06:38 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 21:06:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 21:06:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 21:06:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0898 s/iter. Eval: 0.0381 s/iter. Total: 0.1293 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 21:06:45 d2.evaluation.evaluator]: \u001b[0mInference done 57/61. Dataloading: 0.0018 s/iter. Inference: 0.0875 s/iter. Eval: 0.0219 s/iter. Total: 0.1113 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 21:06:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.522476 (0.116473 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 21:06:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087823 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 21:06:45 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 21:06:45 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06501650214683662\n",
      "\u001b[32m[12/27 21:06:45 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 9519  total_loss: 1.036  loss_cls: 0.1947  loss_box_reg: 0.2305  loss_mask: 0.2609  loss_rpn_cls: 0.07338  loss_rpn_loc: 0.2149  time: 1.1898  data_time: 0.8319  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:07:11 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 9539  total_loss: 1.104  loss_cls: 0.2164  loss_box_reg: 0.2639  loss_mask: 0.2989  loss_rpn_cls: 0.08524  loss_rpn_loc: 0.2262  time: 1.1900  data_time: 0.8398  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:07:36 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 9559  total_loss: 1.037  loss_cls: 0.1797  loss_box_reg: 0.2466  loss_mask: 0.2591  loss_rpn_cls: 0.0703  loss_rpn_loc: 0.189  time: 1.1901  data_time: 0.7846  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:08:04 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 9579  total_loss: 1.02  loss_cls: 0.2015  loss_box_reg: 0.2138  loss_mask: 0.2672  loss_rpn_cls: 0.08037  loss_rpn_loc: 0.2109  time: 1.1905  data_time: 0.9427  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:08:31 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 9599  total_loss: 1.081  loss_cls: 0.1922  loss_box_reg: 0.2256  loss_mask: 0.2873  loss_rpn_cls: 0.07841  loss_rpn_loc: 0.2118  time: 1.1908  data_time: 0.8412  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:08:57 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 9619  total_loss: 1.047  loss_cls: 0.2073  loss_box_reg: 0.2102  loss_mask: 0.2667  loss_rpn_cls: 0.0734  loss_rpn_loc: 0.1796  time: 1.1908  data_time: 0.7684  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:09:23 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 9639  total_loss: 1.058  loss_cls: 0.1949  loss_box_reg: 0.2658  loss_mask: 0.289  loss_rpn_cls: 0.08279  loss_rpn_loc: 0.2094  time: 1.1910  data_time: 0.8409  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:09:50 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 9659  total_loss: 1.084  loss_cls: 0.2168  loss_box_reg: 0.2438  loss_mask: 0.2871  loss_rpn_cls: 0.06452  loss_rpn_loc: 0.2171  time: 1.1914  data_time: 0.9057  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:10:22 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 9679  total_loss: 1.128  loss_cls: 0.2202  loss_box_reg: 0.2797  loss_mask: 0.2969  loss_rpn_cls: 0.09061  loss_rpn_loc: 0.2108  time: 1.1922  data_time: 1.1115  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:10:48 d2.utils.events]: \u001b[0m eta: 0:02:48  iter: 9699  total_loss: 1.044  loss_cls: 0.2176  loss_box_reg: 0.2257  loss_mask: 0.2714  loss_rpn_cls: 0.06819  loss_rpn_loc: 0.217  time: 1.1925  data_time: 0.8975  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:11:17 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 9719  total_loss: 1.03  loss_cls: 0.184  loss_box_reg: 0.1898  loss_mask: 0.2653  loss_rpn_cls: 0.0843  loss_rpn_loc: 0.2122  time: 1.1930  data_time: 0.9608  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:11:39 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 9739  total_loss: 0.9703  loss_cls: 0.1364  loss_box_reg: 0.1722  loss_mask: 0.2301  loss_rpn_cls: 0.0604  loss_rpn_loc: 0.1948  time: 1.1928  data_time: 0.6683  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:11:59 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 9759  total_loss: 0.9088  loss_cls: 0.1784  loss_box_reg: 0.2395  loss_mask: 0.255  loss_rpn_cls: 0.05042  loss_rpn_loc: 0.1943  time: 1.1924  data_time: 0.5838  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:12:17 d2.utils.events]: \u001b[0m eta: 0:02:03  iter: 9779  total_loss: 1.085  loss_cls: 0.2112  loss_box_reg: 0.2764  loss_mask: 0.2796  loss_rpn_cls: 0.07668  loss_rpn_loc: 0.211  time: 1.1918  data_time: 0.4699  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:12:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 21:12:31 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 21:12:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 21:12:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 21:12:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0014 s/iter. Inference: 0.0897 s/iter. Eval: 0.0390 s/iter. Total: 0.1301 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 21:12:37 d2.evaluation.evaluator]: \u001b[0mInference done 56/61. Dataloading: 0.0018 s/iter. Inference: 0.0876 s/iter. Eval: 0.0249 s/iter. Total: 0.1144 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 21:12:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.667469 (0.119062 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 21:12:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.087944 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 21:12:38 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 21:12:38 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.0662811979230296\n",
      "\u001b[32m[12/27 21:12:47 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 9799  total_loss: 0.8844  loss_cls: 0.1389  loss_box_reg: 0.1884  loss_mask: 0.2268  loss_rpn_cls: 0.07747  loss_rpn_loc: 0.1947  time: 1.1916  data_time: 0.6348  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:13:05 d2.utils.events]: \u001b[0m eta: 0:01:40  iter: 9819  total_loss: 0.9685  loss_cls: 0.1798  loss_box_reg: 0.2251  loss_mask: 0.2496  loss_rpn_cls: 0.05842  loss_rpn_loc: 0.2171  time: 1.1911  data_time: 0.5040  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:13:38 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 9839  total_loss: 1.024  loss_cls: 0.185  loss_box_reg: 0.1803  loss_mask: 0.2741  loss_rpn_cls: 0.08103  loss_rpn_loc: 0.2095  time: 1.1920  data_time: 1.1625  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:14:13 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 9859  total_loss: 1.07  loss_cls: 0.2085  loss_box_reg: 0.2324  loss_mask: 0.2871  loss_rpn_cls: 0.09786  loss_rpn_loc: 0.2199  time: 1.1931  data_time: 1.2791  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:14:34 d2.utils.events]: \u001b[0m eta: 0:01:06  iter: 9879  total_loss: 1.016  loss_cls: 0.184  loss_box_reg: 0.2281  loss_mask: 0.2469  loss_rpn_cls: 0.06243  loss_rpn_loc: 0.2095  time: 1.1929  data_time: 0.6199  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:14:58 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 9899  total_loss: 1.059  loss_cls: 0.1963  loss_box_reg: 0.2438  loss_mask: 0.2597  loss_rpn_cls: 0.08898  loss_rpn_loc: 0.2155  time: 1.1927  data_time: 0.6681  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:15:17 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 9919  total_loss: 0.9412  loss_cls: 0.1816  loss_box_reg: 0.2092  loss_mask: 0.2681  loss_rpn_cls: 0.06319  loss_rpn_loc: 0.1864  time: 1.1921  data_time: 0.4631  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:15:42 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 9939  total_loss: 1.097  loss_cls: 0.2155  loss_box_reg: 0.2592  loss_mask: 0.2618  loss_rpn_cls: 0.08509  loss_rpn_loc: 0.2033  time: 1.1922  data_time: 0.7649  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:16:05 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 9959  total_loss: 0.8986  loss_cls: 0.1539  loss_box_reg: 0.1962  loss_mask: 0.2471  loss_rpn_cls: 0.06209  loss_rpn_loc: 0.1946  time: 1.1921  data_time: 0.7185  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:16:21 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 9979  total_loss: 0.9962  loss_cls: 0.1887  loss_box_reg: 0.2632  loss_mask: 0.2642  loss_rpn_cls: 0.06132  loss_rpn_loc: 0.2017  time: 1.1913  data_time: 0.3755  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:16:41 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 9999  total_loss: 1.066  loss_cls: 0.2086  loss_box_reg: 0.2598  loss_mask: 0.2781  loss_rpn_cls: 0.06968  loss_rpn_loc: 0.2091  time: 1.1908  data_time: 0.5020  lr: 0.00125  max_mem: 13868M\n",
      "\u001b[32m[12/27 21:16:42 d2.engine.hooks]: \u001b[0mOverall training speed: 9998 iterations in 3:18:25 (1.1908 s / it)\n",
      "\u001b[32m[12/27 21:16:42 d2.engine.hooks]: \u001b[0mTotal training time: 3:24:35 (0:06:09 on hooks)\n",
      "\u001b[32m[12/27 21:16:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[12/27 21:16:42 d2.data.common]: \u001b[0mSerializing 61 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/27 21:16:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.71 MiB\n",
      "\u001b[32m[12/27 21:16:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 61 batches\n",
      "\u001b[32m[12/27 21:16:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/61. Dataloading: 0.0017 s/iter. Inference: 0.0904 s/iter. Eval: 0.0396 s/iter. Total: 0.1317 s/iter. ETA=0:00:06\n",
      "\u001b[32m[12/27 21:16:49 d2.evaluation.evaluator]: \u001b[0mInference done 56/61. Dataloading: 0.0018 s/iter. Inference: 0.0877 s/iter. Eval: 0.0243 s/iter. Total: 0.1140 s/iter. ETA=0:00:00\n",
      "\u001b[32m[12/27 21:16:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.645712 (0.118673 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 21:16:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.088044 s / iter per device, on 1 devices)\n",
      "\u001b[32m[12/27 21:16:50 d2.engine.defaults]: \u001b[0mEvaluation results for sartorius_val in csv format:\n",
      "\u001b[32m[12/27 21:16:50 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.06662800404945811\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "trainModel(None, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tdZ9fMtEuVSg"
   },
   "outputs": [],
   "source": [
    "# From https://www.kaggle.com/stainsby/fast-tested-rle\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "The following code loads the trained models, which were trained on only one class, and puts them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19fqyztzoKok"
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "MIN_PIXELS = [75, 150, 75]\n",
    "\n",
    "\n",
    "for classNum in range(3):\n",
    "  cfg = get_cfg()\n",
    "  cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "  cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "  cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "  cfg.MODEL.WEIGHTS = f'/{classNum}/model_final.pth'\n",
    "  cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.01\n",
    "  cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n",
    "  models.append(DefaultPredictor(cfg))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally we also load the trained model which was used after training with LiveCell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3mpfS9T00rut"
   },
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3\n",
    "cfg.MODEL.WEIGHTS = f'./output50/model_0042299.pth'\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 1000\n",
    "allModel = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code uses the ensemble classifier models to create predictions by concatinating all. When running this all models did not predict any instances. Thus we were not able to successfully build an ensemble classifier using three detectron instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "T6mvRLvVwPjd"
   },
   "outputs": [],
   "source": [
    "# Parts of this code is taken from\n",
    "# https://www.kaggle.com/ammarnassanalhajali/sartorius-segmentation-detectron2-inference\n",
    "from detectron2.structures import Instances\n",
    "def predictMask(name):\n",
    "  im = cv2.imread(str(name))\n",
    "  instances = None\n",
    "  # Remove comment to debug predictions\n",
    "  # for model in models:\n",
    "  #   print(model(im))\n",
    "  # return\n",
    "  for classNum, model in enumerate(models):\n",
    "    pred = model(im)\n",
    "    pred['instances'].pred_classes *= classNum + 1\n",
    "    if instances is None:\n",
    "      instances = pred['instances']\n",
    "    else:\n",
    "      instances = Instances.cat(instances, pred['instances'])\n",
    "    take = pred['instances'].scores >= THRESHOLDS[classNum]\n",
    "    pred_masks = pred['instances'].pred_masks[take]\n",
    "    pred_masks = pred_masks.cpu().numpy()\n",
    "    res = []\n",
    "    used = np.zeros(im.shape[:2], dtype=int) \n",
    "    for mask in pred_masks:\n",
    "        mask = mask * (1-used)\n",
    "        if mask.sum() >= MIN_PIXELS[classNum]: # skip predictions with small area\n",
    "            used += mask\n",
    "            res.append(rle_encode(mask))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function builds predictions using the single model for all cell types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "mkuoltYg9q8C"
   },
   "outputs": [],
   "source": [
    "def predictMaskSingle(name):\n",
    "  im = cv2.imread(str(name))\n",
    "  pred = allModel(im)\n",
    "  take = pred['instances'].scores >= THRESHOLDS[classNum]\n",
    "  pred_masks = pred['instances'].pred_masks[take]\n",
    "  pred_masks = pred_masks.cpu().numpy()\n",
    "  res = []\n",
    "  used = np.zeros(im.shape[:2], dtype=int) \n",
    "  for mask in pred_masks:\n",
    "      mask = mask * (1-used)\n",
    "      if mask.sum() >= MIN_PIXELS[classNum]: # skip predictions with small area\n",
    "          used += mask\n",
    "          res.append(rle_encode(mask))\n",
    "  return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring functions\n",
    "\n",
    "The next functions compute an average MaP-IoU score for all the data in the Sartorius dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "sst6jFSL-SEt"
   },
   "outputs": [],
   "source": [
    "# Define default thresholds. Only instances where the mdodels logits are higher than the threshold\n",
    "# are kept.\n",
    "# Part of this code is taken and adapted from \n",
    "# https://www.kaggle.com/ammarnassanalhajali/sartorius-segmentation-detectron2-training\n",
    "THRESHOLDS = [.15, .15, .15]\n",
    "def scoreWithThreshold(pred, targ):\n",
    "  enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in pred_masks]\n",
    "  enc_targs = list(map(lambda x:x['segmentation'], targ))\n",
    "  ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n",
    "  prec = []\n",
    "  for t in np.arange(0.5, 1.0, 0.05):\n",
    "      tp, fp, fn = precision_at(t, ious)\n",
    "      p = tp / (tp + fp + fn) if (tp + fp + fn) != 0 else 0\n",
    "      prec.append(p)\n",
    "  return np.mean(prec)\n",
    "\n",
    "def evaluateSingleModel():\n",
    "  dataset_dicts = DatasetCatalog.get('sartorius_val')\n",
    "  ious_res = []\n",
    "  for X in tqdm(dataset_dicts):\n",
    "    img = cv2.imread(X[\"file_name\"])\n",
    "    pred = allModel(img)\n",
    "    if len(pred['instances']) == 0:\n",
    "      ious_res.append(0)\n",
    "      continue\n",
    "    pred_class = torch.mode(pred['instances'].pred_classes)[0]\n",
    "    take = pred['instances'].scores >= THRESHOLDS[pred_class]\n",
    "    pred_masks = pred['instances'].pred_masks[take]\n",
    "    pred_masks = pred_masks.cpu().numpy()\n",
    "    res = []\n",
    "    used = np.zeros(img.shape[:2], dtype=int) \n",
    "    for mask in pred_masks:\n",
    "        mask = mask * (1-used)\n",
    "        if mask.sum() >= MIN_PIXELS[pred_class]: # skip predictions with small area\n",
    "            used += mask\n",
    "            res.append(mask.astype(np.uint8))\n",
    "    enc_preds = [mask_util.encode(np.asarray(p, order='F')) for p in res]\n",
    "    enc_targs = list(map(lambda x:x['segmentation'], X[\"annotations\"]))\n",
    "    ious = mask_util.iou(enc_preds, enc_targs, [0]*len(enc_targs))\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, ious)\n",
    "        p = tp / (tp + fp + fn) if (tp + fp + fn) != 0 else 0\n",
    "        prec.append(p)\n",
    "    ious_res.append(np.mean(prec))\n",
    "  return np.mean(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shsy5y': 1, 'astro': 2, 'cort': 3}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best Thresholds\n",
    "\n",
    "We perform a greedy search for the best thresholds by increasing each and scoring the model with the increased threshold. We use the computed minimal pixels for each cell type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QaKS66w4-0c7",
    "outputId": "80adecec-afb6-4f62-d518-9bc3503229df",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 61/61 [00:05<00:00, 11.20it/s]\n",
      "100% 61/61 [00:05<00:00, 11.35it/s]\n",
      "100% 61/61 [00:05<00:00, 11.30it/s]\n",
      "100% 61/61 [00:05<00:00, 11.27it/s]\n",
      "100% 61/61 [00:05<00:00, 11.32it/s]\n",
      "100% 61/61 [00:05<00:00, 11.27it/s]\n",
      "100% 61/61 [00:05<00:00, 11.28it/s]\n",
      "100% 61/61 [00:05<00:00, 11.23it/s]\n",
      "100% 61/61 [00:05<00:00, 11.27it/s]\n",
      "100% 61/61 [00:05<00:00, 11.29it/s]\n",
      "100% 61/61 [00:05<00:00, 11.29it/s]\n",
      "100% 61/61 [00:05<00:00, 11.31it/s]\n",
      "100% 61/61 [00:05<00:00, 11.34it/s]\n",
      "100% 61/61 [00:05<00:00, 11.38it/s]\n",
      " 56% 34/61 [00:02<00:02, 12.14it/s]"
     ]
    }
   ],
   "source": [
    "MIN_PIXELS = [13,18,26] # shsy5y, astro, cort\n",
    "for i in list(range(3)):\n",
    "    thresh = 0.01\n",
    "    bestThresh = 0.01\n",
    "    currentMax = -1\n",
    "    while thresh <= 0.8:\n",
    "        THRESHOLDS[i] = thresh\n",
    "        scored = evaluateSingleModel()\n",
    "        if scored > currentMax:\n",
    "            bestThresh = thresh\n",
    "            currentMax = scored\n",
    "        thresh += 0.02\n",
    "    THRESHOLDS[i] = bestThresh\n",
    "THRESHOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRESHOLDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if RLE predictions are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hUBbqPYDvy7r",
    "outputId": "f1800743-71cc-400a-9d2b-c557208a4ee4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['215857 3 216539 4 216556 12 217241 34 217944 37 218648 39 219353 39 220059 39 220766 37 221480 29 222189 25 222896 23 223602 23 224307 22 225013 21 225718 21 226424 20 227130 19 227835 19 228542 17 229248 16 229955 15 230663 13 231369 12 232075 11 232781 11 233486 11 234192 11 234898 10 235604 9 236309 10 237014 10 237720 10 238425 10 239131 10 239836 10 240542 10 241248 9 241953 9 242658 10 243363 10 244069 9 244775 9 245481 8 246185 9 246890 10 247595 10 248302 8 249007 8 249712 9 250417 9 251122 9 251827 10 252533 9 253238 9 253943 10 254649 9 255354 10 256059 10 256764 10 257469 10 258174 10 258880 8 259586 6 260291 2',\n",
       " '298493 1 299197 1 299900 2 300603 3 301306 4 302010 4 302713 5 303416 6 304120 6 304823 7 305526 8 306230 8 306933 9 307636 10 308339 10 309042 11 309745 11 310449 11 311152 11 311856 11 312559 11 313263 11 313967 11 314670 12 315374 12 316078 12 316783 11 317487 11 318191 11 318895 11 319599 11 320304 10 321008 10 321713 9 322417 9 323121 9 323826 7 324530 7 325235 6 325939 6 326643 5 327347 5 328051 5 328756 4 329460 4 330164 4 330868 4 331572 4 332276 5 332980 5 333684 5 334388 5 335092 5 335796 5 336500 5 337204 5 337908 5 338613 4 339317 4 340021 4 340725 4 341429 4 342133 4 342836 5 343540 5 344244 5 344948 5 345652 5 346356 5 347060 5 347764 5 348468 5 349172 5 349876 5 350580 5 351284 5 351988 5 352692 6 353396 6 354101 5 354805 5 355509 5 356213 6 356917 6 357622 5 358326 6 359031 5 359735 6 360439 6 361144 5 361848 5 362553 3',\n",
       " '1027 13 1729 17 2432 19 3136 21 3840 22 4543 23 5247 25 5951 26 6654 29 7358 30 8061 32 8764 35 9467 38 10171 39 10874 41 11578 41 12281 43 12984 46 13688 48 14391 50 15095 50 15799 51 16502 53 17206 55 17909 57 18613 58 19317 58 20021 59 20725 60 21429 62 22133 63 22837 64 23542 65 24246 67 24950 68 25654 71 26358 73 27062 75 27766 77 28470 79 29174 81 29878 83 30582 85 31286 86 31990 88 32694 90 33397 92 34101 94 34805 95 35509 72 35582 24 36213 71 36288 24 36917 71 36993 24 37621 72 37696 28 38325 72 38399 6 38411 18 39029 79 39117 18 39733 77 39823 18 40437 75 40529 18 41142 73 41235 17 41846 71 41942 16 42550 70 42649 16 43254 70 43355 15 43959 68 44060 17 44663 5 44669 62 44766 17 45374 60 45471 17 46079 58 46179 16 46784 50 46837 3 46885 16 47489 48 47591 15 48193 47 48297 14 48898 45 49002 15 49611 13 49638 7 49708 15 50318 4 50415 15 51121 16 51827 15 52533 16 53238 17 53943 17 54650 15 55356 15 56063 11 56770 6',\n",
       " '157607 5 158310 6 159012 8 159713 9 160415 11 161118 10 161820 11 162523 11 163224 12 163927 11 164629 11 165331 11 166033 12 166735 11 167438 10 168140 11 168841 12 169543 13 170245 13 170946 14 171649 13 172351 13 173052 14 173755 13 174455 14 175157 15 175858 15 176558 18 177260 18 177961 19 178664 18 179366 19 180068 20 180771 20 181474 20 182176 20 182879 20 183581 21 184284 20 184986 20 185689 18 186391 17 187094 13 187797 12 188499 13 189202 13 189905 13 190608 12 191311 12 192014 12 192717 12 193420 12 194123 12 194826 12 195530 11 196233 10 196937 9 197641 8 198345 7 199050 3',\n",
       " '124060 7 124762 10 125463 13 126165 15 126868 16 127571 16 128274 17 128977 17 129680 18 130384 17 131087 17 131791 16 132495 15 133199 13 133903 12 134606 11 135309 10 136013 8 136716 8 137419 8 138122 8 138826 7 139528 8 140232 7 140935 7 141637 8 142340 9 143043 9 143747 8 144450 8 145153 8 145856 7 146559 8 147262 8 147965 8 148668 8 149371 8 150074 8 150778 7 151481 7 152184 7 152887 7 153590 7 154294 7 154998 6 155702 5 156406 4 157110 3 157814 1',\n",
       " '230277 3 230979 6 231682 9 232387 9 233093 9 233798 9 234503 10 235208 11 235913 12 236618 13 237323 14 238027 15 238732 14 239437 14 240141 15 240846 15 241550 15 242255 15 242960 14 243664 15 244369 14 245074 14 245779 13 246484 13 247189 13 247894 12 248598 12 249303 12 250008 11 250713 11 251418 11 252124 10 252830 10 253535 10 254240 10 254945 9 255650 9 256355 8 257059 9 257764 8 258470 8 259175 8 259880 7 260585 7 261289 7 261994 7 262698 8 263403 7 264107 8 264812 7 265517 7 266221 7 266926 7 267630 7 268335 6 269039 7 269743 7 270448 6 271152 7 271857 7 272562 6 273266 7 273971 6 274675 6 275380 6 276084 6 276789 6 277493 6 278198 6 278902 6 279606 6 280310 7 281015 7 281720 6 282424 7 283129 6 283833 7 284538 6 285242 7 285947 6 286651 7 287356 6 288060 6 288764 7 289469 6 290173 6 290878 6 291583 5 292287 6 292991 6 293696 5 294400 6 295105 5 295809 5 296514 5 297218 5 297922 6 298627 5 299331 5 300035 6 300739 6 301443 6 302148 5 302852 6 303557 5 304261 6 304966 5 305670 5 306374 6 307078 6 307782 6 308487 5 309191 6 309896 5 310600 6 311305 4 312009 4 312714 3 313418 2',\n",
       " '112124 4 112826 6 113528 8 114229 11 114924 1 114931 13 115627 3 115633 15 116329 22 117032 22 117735 22 118439 22 119143 21 119847 21 120550 21 121254 20 121958 19 122661 20 123365 19 124068 20 124772 19 125476 19 126180 18 126884 18 127587 18 128291 18 128994 19 129698 18 130401 20 131105 20 131809 22 132514 22 133219 20 133925 16 134631 13 135337 10 136042 9 136748 8 137454 5',\n",
       " '158517 2 159219 4 159922 5 160625 6 161329 5 162032 6 162736 6 163439 6 164142 7 164846 7 165549 7 166252 7 166955 8 167659 7 168362 7 169065 7 169769 7 170472 7 171175 7 171878 8 172580 10 173281 12 173980 16 174681 18 175382 21 176083 24 176784 25 177484 29 178184 32 178882 37 179582 40 180283 42 180984 44 181687 43 182391 42 183095 16 183124 10 183799 9 184504 1',\n",
       " '102111 2 102815 4 103518 7 104223 7 104927 9 105631 10 106336 10 107041 10 107746 9 108451 9 109155 10 109861 9 110566 9 111271 9 111976 10 112681 10 113386 9 114091 9 114796 9 115501 9 116206 9 116911 9 117616 8 118321 9 119027 9 119731 10 120436 10 121140 11 121845 12 122549 13 123254 13 123959 14 124663 14 125368 14 126072 16 126776 17 127481 18 128185 20 128891 21 129596 24 130302 24 131008 26 131714 28 131779 4 132421 28 132474 14 133127 34 133166 26 133834 61 134542 53 135250 45 135957 37 136667 27 137373 21',\n",
       " '196202 17 196907 18 197614 17 198319 18 199024 19 199729 20 200435 20 201140 20 201845 22 202550 27 203256 29 203961 33 204667 39 205375 36 206087 28 206801 18 207510 13 208217 9',\n",
       " '1354 2 2043 5 2053 10 2741 29 3441 34 4141 38 4842 39 5543 40 6243 42 6939 47 7643 45 8346 44 9051 41 9755 38 10460 29 11166 24 11871 20 12576 14 13282 6',\n",
       " '136196 5 136897 11 137602 15 138308 16 139015 16 139722 15 140428 17 141135 17 141841 19 142548 19 143254 19 143960 20 144667 19 145373 19 146080 19 146786 19 147493 19 147533 8 148200 20 148232 14 148907 43 149614 38 150321 33 151027 29 151734 24 152440 20 153145 18 153850 16 154555 14 155259 13 155965 10 156672 6',\n",
       " '101018 2 101718 10 102421 12 103123 15 103825 17 104525 21 105227 16 105929 15 106631 15 107333 14 108035 14 108737 14 109439 14 110142 13 110844 13 111546 13 112248 14 112951 14 113653 14 114355 15 115058 15 115761 14 116463 15 117166 15 117868 16 118571 15 119273 16 119975 16 120677 17 121380 16 122082 17 122785 16 123488 15 124190 16 124893 16 125596 16 126299 15 127003 14 127707 12 128411 11 129116 7',\n",
       " '274888 3 275589 7 276258 4 276288 12 276960 6 276987 17 277662 8 277687 19 278365 10 278386 21 279067 14 279085 22 279770 37 280472 35 281172 36 281870 37 282570 38 283272 37 283975 35 284678 33 285382 30 286087 27 286799 16 287508 10 288214 6 288919 5 289623 5 290327 5 291031 5 291735 4 292439 4 293143 4 293847 3 294551 3 295255 3 295959 3 296663 3 297368 1',\n",
       " '328221 4 328923 8 329625 14 330328 18 331030 23 331733 26 332436 28 333140 29 333844 30 334548 30 335252 31 335956 31 336660 31 337364 31 338068 32 338772 33 339476 33 340180 33 340884 33 341588 34 342292 34 342996 34 343700 34 344404 34 345108 34 345812 34 346516 34 347220 34 347924 34 348628 34 349332 34 350037 32 350741 32 351444 32 352148 31 352852 30 353556 30 354260 29 354964 28 355668 27 356372 26 357076 26 357780 25 358484 24 359188 24 359892 23 360596 22 361300 21 362004 19 362708 18 363413 16 364117 14 364822 11',\n",
       " '225452 8 226156 9 226859 10 227563 11 228267 11 228971 12 229675 13 230379 13 231083 13 231787 14 232491 15 233196 14 233900 14 234606 13 235311 13 236016 12 236721 11 237427 10 238134 8 238839 7 239544 7 240249 6 240953 6 241658 6 242362 6 243067 6 243771 6 244476 5 245180 6 245884 6 246589 6 247293 6 247997 7 248702 6 249406 6 250110 7 250814 7 251519 7 252223 7 252927 7 253632 7 254336 7 255040 8 255744 8 256449 8 257153 8 257857 9 258561 9 259265 10 259968 11 260672 12 261376 12 262080 13 262784 13 263487 14 264191 15 264896 14 265600 14 266304 14 267009 14 267713 14 268418 13 269122 13 269827 12 270531 11 271236 10 271941 9 272645 9 273350 8 274054 8 274759 7 275463 8 276168 7 276872 8 277577 7 278281 7 278986 7 279691 6 280395 7 281100 6 281805 6 282510 5 283214 6 283919 5 284624 4 285328 5 286033 4 286737 5 287442 5 288146 5 288850 5 289555 5 290259 5 290964 4 291668 5 292372 5 293076 5 293781 4 294485 4 295189 4 295895 1',\n",
       " '61242 1 61945 3 62649 3 63352 3 64055 4 64759 4 65463 4 66166 4 66869 5 67573 4 68277 4 68980 4 69684 4 70387 5 71091 4 71795 4 72498 4 73202 4 73906 4 74609 5 75313 4 76017 4 76721 4 77424 5 78128 4 78832 4 79536 4 80239 5 80943 4 81647 4 82351 4 83055 4 83759 4 84462 5 85166 4 85870 4 86574 4 87278 4 87981 5 88685 5 89389 5 90093 4 90797 4 91500 5 92204 5 92908 5 93612 5 94316 5 95019 6 95723 6 96427 5 97131 5 97835 5 98539 5 99242 6 99946 6 100650 6 101354 6 102058 6 102762 5 103465 6 104169 6 104873 6 105577 6 106281 6 106984 7 107688 7 108392 6 109096 6 109800 6 110504 6 111207 7 111911 7 112615 7 113318 8 114022 8 114726 8 115430 9 116134 9 116838 9 117542 9 118246 9 118950 8 119654 8 120358 8 121062 8 121766 8 122470 8 123173 8 123877 8 124581 8 125285 8 125989 7 126693 7 127397 7 128101 7 128805 7 129509 7 130213 7 130917 7 131621 7 132325 7 133029 7 133733 7 134437 7 135141 7 135845 7 136549 7 137253 7 137957 7 138661 7 139365 7 140070 6 140774 6 141478 6 142182 6 142886 6 143590 6 144294 5 144998 4',\n",
       " '322572 3 323276 4 323980 4 324684 4 325388 5 326092 5 326796 5 327500 5 328204 6 328908 6 329613 5 330317 5 331021 6 331725 6 332429 6 333133 6 333837 6 334541 7 335246 6 335950 6 336654 6 337358 6 338062 6 338766 6 339470 6 340174 6 340878 6 341582 6 342286 6 342990 6 343694 6 344398 6 345102 6 345805 7 346509 7 347213 7 347917 7 348621 7 349325 7 350028 9 350732 9 351436 8 352140 8 352844 8 353547 9 354251 9 354955 9 355659 9 356363 9 357067 9 357771 9 358475 9 359179 9 359883 9 360587 9 361290 10 361994 10 362698 10 363402 10 364106 10 364810 10',\n",
       " '343987 11 344691 14 345395 17 346099 19 346803 22 347507 24 348213 25 348919 26 349631 23 350339 26 351046 27 351754 28 352462 37 353170 45 353879 47 354586 51 355294 64 356001 67 356708 70 357416 68 358122 56 358829 44 359534 35 360241 23 360948 14',\n",
       " '138278 4 138981 6 139684 9 140388 9 141092 10 141796 11 142501 10 143205 10 143909 11 144614 10 145318 11 146023 10 146727 11 147432 10 148137 10 148841 10 149546 10 150251 9 150955 9 151660 8 152364 9 153069 8 153773 8 154477 8 155182 8 155886 8 156590 8 157295 7 157999 8 158704 7 159408 7 160113 7 160817 7 161521 7 162226 7 162930 7 163635 6 164340 6 165044 6 165748 6 166453 6 167157 6 167861 7 168566 6 169270 6 169974 7 170679 7 171383 8 172087 10 172792 9 173496 9 174200 9 174904 8 175608 6 176312 5',\n",
       " '122931 3 123635 3 124338 5 125042 5 125746 5 126450 6 127154 6 127858 6 128563 5 129267 6 129971 6 130675 6 131380 5 132084 5 132788 5 133492 6 134196 6 134900 6 135605 5 136309 6 137013 6 137718 6 138422 6 139126 7 139831 6 140535 7 141239 7 141943 8 142647 9 143351 9 144055 10 144759 10 145463 11 146166 13 146869 14 147573 15 148276 17 148979 18 149684 18 150389 18 151094 18 151800 17 152505 18 153210 18 153915 18 154621 17 155326 17 156031 18 156736 17 157440 18 158144 20 158848 20 159552 21 160256 7 160268 9 160960 6 160973 8 161664 6 161679 6 162368 5 162385 3 163072 5 163776 5 164480 5 165184 5 165888 4 166592 4 167296 4 168000 4 168704 4 169408 4 170112 3 170816 3 171520 2',\n",
       " '338669 5 339373 5 340077 5 340781 5 341485 5 342189 6 342893 7 343597 8 344302 7 345007 7 345711 7 346416 7 347120 8 347824 8 348529 8 349233 8 349938 8 350642 8 351346 9 352051 8 352755 9 353460 9 354164 10 354869 10 355573 11 356277 13 356982 14 357686 17 358391 19 359095 21 359800 22 360505 22 361210 22 361915 21 362620 20 363325 19 364032 16 364738 13',\n",
       " '195328 3 196030 6 196733 7 197436 8 198139 9 198842 10 199544 12 200247 13 200950 14 201653 14 202355 15 203058 12 203761 11 204463 12 205165 13 205868 13 206571 13 207274 14 207977 14 208680 15 209383 15 210087 14 210790 14 211493 14 212197 13 212900 13 213603 12 214306 11 215009 9 215712 7 216415 7 217117 8 217820 9 218524 8 219226 9 219929 9 220637 2',\n",
       " '182434 4 183138 4 183841 5 184545 6 185249 6 185952 6 186656 6 187360 6 188064 6 188768 6 189472 6 190176 6 190880 6 191584 6 192288 7 192992 7 193697 6 194401 6 195105 6 195809 6 196513 7 197218 6 197922 6 198626 7 199330 7 200035 6 200739 7 201443 7 202148 6 202852 6 203556 7 204260 7 204965 6 205669 7 206373 7 207078 6 207782 7 208486 7 209190 7 209895 7 210599 7 211303 7 212007 8 212712 7 213416 7 214120 7 214824 8 215529 7 216233 7 216937 8 217641 8 218346 8 219050 9 219754 9 220458 10 221163 10 221867 11 222571 12 223275 13 223979 13 224683 14 225387 14 226092 13 226796 13 227500 13 228204 12 228908 11 229612 11 230316 10 231020 10 231724 9 232428 9 233132 9 233836 8 234541 7 235245 7 235949 7 236652 7 237356 7 238060 7 238764 7 239468 7 240172 7 240876 7 241580 6 242284 6 242988 6 243692 6 244396 6 245100 5 245803 6 246507 6 247211 6 247915 6 248620 4 249324 4 250030 1',\n",
       " '168624 4 169328 6 170033 6 170738 7 171442 8 172147 8 172852 8 173557 8 174262 8 174967 9 175672 9 176377 10 177082 10 177787 11 178493 10 179198 10 179904 10 180609 11 181314 11 182019 11 182725 11 183430 11 184135 11 184840 11 185545 11 186251 10 186956 10 187661 10 188366 9 189071 9 189776 9 190481 9 191186 8 191891 8 192595 9 193300 9 194005 9 194710 9 195414 10 196119 10 196824 10 197528 11 198233 11 198938 11 199642 12 200347 12 201052 12 201757 11 202462 11 203166 12 203871 11 204576 11 205280 12 205985 12 206690 11 207395 11 208100 11 208805 11 209509 11 210215 10 210920 10 211624 11 212330 9 213034 10 213739 9 214443 10 215148 9 215854 3',\n",
       " '3546 2 4247 7 4949 20 5648 28 5677 3 5692 16 6351 65 7055 71 7758 21 7805 28 8461 20 8513 25 9165 17 9220 23 9868 17 9927 21 10572 15 10634 18 11276 9 11340 17 11980 7 12045 16 12685 5 12752 12 13389 5 13459 10 14094 4 14166 8 14799 3 14878 2 15503 4 15582 2 16207 5 16286 3 16912 5 16990 4 17616 5 17694 6 18321 4 18398 6 19027 2 19102 6 19806 7 20510 7 21143 2 21214 7 21848 4 21918 7 22552 5 22621 8 23257 5 23324 9 23962 6 24028 8 24666 9 24733 7 25372 8 25437 6 26077 8 26139 6 26782 9 26840 9 27488 10 27543 10 28193 10 28244 11 28898 11 28947 10 29603 13 29648 11 30309 13 30350 11 31015 14 31052 11 31720 18 31753 12 32425 40 33131 35 33836 33 34543 28 35250 23 35962 9',\n",
       " '301673 5 302374 9 303076 11 303779 12 304481 15 305184 16 305886 18 306589 19 307291 21 307994 21 308697 20 309400 19 310102 20 310805 19 311508 18 312211 18 312914 18 313617 17 314320 17 315023 17 315726 17 316429 16 317132 16 317834 17 318537 17 319240 17 319942 17 320645 17 321347 17 322050 17 322752 18 323454 18 324157 18 324860 17 325563 17 326267 16 326971 15 327675 13 328378 13 329082 12 329786 10 330490 9 331194 7',\n",
       " '145019 4 145718 10 146418 14 147119 17 147821 19 148523 21 149222 26 149923 29 150626 30 151328 32 152030 33 152732 32 153434 32 154137 32 154841 30 155546 28 156250 27 156954 26 157658 25 158362 24 159066 23 159770 22 160474 22 161179 21 161883 21 162587 21 163293 11',\n",
       " '159 60 860 71 1563 72 2267 72 2970 73 3673 74 4376 75 5080 75 5783 76 6487 74 7191 72 7894 72 8598 71 9301 72 10004 72 10707 73 11410 74 12113 75 12817 75 13520 77 14224 77 14928 77 15632 78 16336 78 17040 79 17744 78 18447 76 19151 71 19855 63 20560 56 21264 50 21968 45 22672 41 23376 35 24081 21',\n",
       " '322353 5 323056 9 323071 1 323760 19 323804 1 324464 22 324507 4 325169 23 325210 5 325873 25 325914 5 326576 28 326617 5 327280 29 327319 7 327984 31 328021 9 328688 46 329392 45 330096 45 330800 45 331505 44 332209 44 332914 44 333619 44 334325 43 335030 43 335735 43 336440 44 337144 45 337849 45 338554 46 339259 46 339983 28 340693 23 341402 18 342109 15 342815 13 343522 10 344228 8 344934 6 345640 4',\n",
       " '191242 3 191946 4 192650 4 193353 6 194057 6 194761 6 195465 6 196169 7 196873 7 197577 7 198281 8 198985 8 199689 8 200392 10 201096 10 201800 10 202504 10 203208 11 203912 11 204616 11 205320 11 206024 11 206728 12 207432 12 208136 12 208841 11 209545 11 210249 10 210953 10 211658 9 212362 8 213066 8 213770 8 214475 6 215179 6 215883 6 216587 6 217291 6 217995 6 218699 6 219402 7 220106 6 220810 6 221514 6 222219 5',\n",
       " '33641 2 34344 3 35047 4 35750 5 36452 7 37155 8 37859 7 38562 8 39266 8 39969 9 40673 9 41376 9 42080 9 42783 10 43486 10 44190 10 44894 10 45597 10 46301 10 47005 9 47709 9 48412 10 49116 9 49820 9 50523 10 51227 9 51930 10 52634 10 53337 10 54041 10 54745 10 55448 11 56152 10 56856 10 57559 11 58263 11 58966 12 59670 12 60373 13 61076 14 61780 14 62483 15 63187 15 63890 16 64593 17 65296 18 66000 18 66703 19 67407 19 68111 19 68814 20 69518 20 70222 20 70926 20 71630 20 72334 20 73038 19 73742 19 74446 19 75150 19 75855 18 76559 18 77263 18 77967 18 78671 18 79377 16 80081 16 80785 16 81492 1 81494 1 81496 9 82201 8 82906 7 83610 7 84315 6 85020 6 85724 6 86429 5',\n",
       " '44150 3 44851 7 45553 9 46256 10 46959 11 47662 12 48365 13 49069 13 49772 14 50476 14 51179 16 51883 16 52586 17 53290 17 53994 17 54698 17 55401 18 56105 18 56809 18 57513 19 58217 19 58921 20 59625 20 60329 20 61033 20 61737 21 62441 21 63145 21 63849 21 64553 21 65257 21 65961 21 66665 20 67369 20 68073 20 68777 20 69481 19 70185 19 70888 19 71592 19 72296 19 73000 18 73704 18 74407 18 75111 17 75814 18 76518 17 77222 16 77925 16 78629 15 79333 14 80035 14 80736 15 81437 17 82140 17 82841 19 83544 19 84245 20 84949 18 85652 18 86356 17 87059 17 87763 14 88466 14 89172 10 89876 8 90581 5',\n",
       " '87552 1 89655 1 89659 4 90358 9 91062 8 91765 9 92469 8 93172 9 93876 9 94580 8 95283 8 95987 7 96690 7 97394 7 98097 7 98801 7 99504 8 100208 7 100911 8 101614 8 102318 8 103021 8 103725 8 104428 9 105130 10 105834 10 106537 10 107241 10 107944 11 108647 12 109350 13 110054 12 110757 13 111461 12 112164 13 112868 13 113572 12 114276 12 114980 11 115683 12 116387 11 117090 12 117794 12 118498 11 119202 11 119905 11 120609 11 121313 10 122016 11 122720 11 123423 11 124127 11 124831 10 125534 11 126237 11 126941 11 127644 11 128348 11 129051 12 129755 11 130458 12 131162 11 131865 11 132568 12 133272 11 133975 11 134679 11 135382 11 136085 12 136789 11 137492 12 138195 13 138898 13 139602 13 140305 13 141008 14 141711 14 142414 15 143118 14 143821 15 144524 16 145227 16 145930 17 146633 18 147337 17 148040 18 148743 19 149447 18 150150 19 150853 19 151557 19 152261 19 152965 19 153669 18 154372 19 155076 19 155780 19 156484 19 157188 19 157893 18 158597 17 159301 17 160005 17 160709 17 161414 15 162121 10',\n",
       " '256525 2 257227 4 257928 7 258627 12 259328 14 260029 17 260721 2 260730 19 261424 27 262127 26 262830 25 263534 25 264237 26 264940 27 265644 26 266347 26 267050 16 267754 11 268457 9 269161 7 269865 6 270568 6 271272 6 271976 5 272679 6 273383 6 274086 6 274790 6 275493 6 276197 6 276900 6 277604 6 278307 7 279010 8 279714 7 280418 7 281121 8 281824 8 282527 9 283230 10 283933 10 284637 10 285340 11 286044 11 286748 11 287453 9 288158 6',\n",
       " '321956 1 322653 15 323354 22 324056 26 324758 31 325460 36 326159 45 326861 48 327563 50 328266 52 328968 54 329672 54 330375 56 331078 57 331781 58 332483 60 333186 61 333888 63 334591 63 335294 63 335996 64 336699 64 337403 63 338106 62 338810 61 339514 59 340218 58 340922 57 341626 55 342330 54 343034 53 343739 51 344443 50 345147 49 345852 47 346556 46 347261 44 347965 43 348670 41 349375 39 350081 36 350786 34 351491 32 352196 31 352901 29 353606 27 354311 25 355015 24 355720 23 356424 22 357129 20 357834 18 358538 17 359243 15 359947 14 360652 12 361356 11 362061 9 362765 8 363471 4',\n",
       " '324099 11 324802 19 325505 23 326209 26 326913 30 327617 34 328322 39 329026 52 329730 54 330434 56 331138 56 331842 57 332546 57 333250 57 333955 56 334659 56 335363 56 336068 54 336772 52 337477 50 338182 47 338887 44 339593 40 340299 36 341004 34 341709 31 342415 28 343120 26 343826 22 344531 20 345237 16 345941 14 346646 11 347351 9 348056 7 348761 4',\n",
       " '240897 2 241600 5 242304 6 243008 6 243713 6 244419 5 245123 6 245829 6 246534 5 247239 5 247944 5 248649 5 249337 2 249355 3 250041 4 250060 3 250747 6 250766 2 251451 8 252157 10 252862 20 253567 21 254272 24 254976 41 255678 45 256381 48 257084 6 257094 39 257785 8 257804 34 258488 7 258512 32 259190 7 259220 30 259892 8 259927 30 260595 8 260633 29 261299 6 261338 28 262003 3 262043 28 262707 1 262748 27 263453 26 264160 23 264876 11',\n",
       " '339633 5 340335 7 341038 8 341740 10 342443 11 343146 12 343848 14 344551 15 345253 17 345955 19 346657 22 347360 23 348063 24 348765 26 349466 29 350170 30 350873 31 351577 31 352281 32 352984 33 353688 33 354391 35 355094 36 355797 37 356501 38 357204 39 357906 42 358609 43 359311 46 360013 48 360715 51 361417 53 362119 56 362823 56 363527 56 364231 56 364935 56',\n",
       " '4180 1 4884 2 5587 3 6290 3 6995 2 9798 1 11897 10 12595 22 13295 29 13995 42 14694 48 15390 56 16089 60 16787 59 17487 36 18187 33 18888 30 19589 27 20290 25 20992 23 21694 20 22395 20 23097 19 23798 18 24500 18 25201 18 25902 18 26603 19 27305 19 28007 18 28708 19 29410 19 30112 17 30813 18 31515 17 32218 16 32922 13 33626 11 34330 8',\n",
       " '135878 2 136581 5 137285 6 137989 6 138693 6 139397 7 140101 7 140805 7 141510 7 142214 7 142918 7 143623 7 144327 7 145032 6 145736 7 146441 7 147145 7 147850 6 148554 7 149259 7 149964 7 150668 8 151373 7 152077 7 152782 7 153487 7 154191 8 154896 7 155601 7 156305 9 157010 9 157715 11 158419 13 159124 13 159829 13 160534 13 161238 14 161943 15 162648 14 163352 15 164057 15 164762 14 165467 14 166172 13 166877 13 167582 12 168287 12 168993 11 169699 9 170404 9 171110 8 171815 8 172520 8 173225 9 173930 9 174635 9 175340 8 176045 8 176750 7 177455 7 178160 6 178864 7 179569 6 180273 6 180978 6 181682 5 182386 5 183090 5 183794 5 184498 6 185203 5 185907 5 186611 4 187315 4',\n",
       " '1390 14 2094 15 2799 15 3505 14 4210 14 4918 10 5625 8 6330 7 7036 5 7741 4 8446 3',\n",
       " '140803 1 141506 3 142210 4 142914 4 143619 4 144323 4 145027 4 145731 5 146435 5 147139 5 147843 5 148547 6 149251 6 149955 6 150659 6 151363 6 152067 7 152771 7 153475 7 154179 7 154883 8 155587 8 156291 8 156995 9 157699 9 158403 9 159107 10 159811 10 160515 10 161219 10 161923 11 162627 11 163331 11 164035 11 164739 11 165443 12 166147 12 166851 12 167555 12 168259 11 168963 11 169668 10 170372 10 171076 9 171780 9 172484 9 173188 8 173892 8 174596 8 175300 7 176004 7 176709 6 177413 6 178117 5 178821 5 179525 5 180229 5 180933 4 181637 4 182341 4 183045 4 183750 3 184454 3 185158 2',\n",
       " '301585 10 302283 26 302986 57 303689 61 304392 65 305096 67 305799 70 306503 71 307206 73 307910 73 308614 74 309318 74 310024 3 310040 57 310757 44 311466 40 312174 36 312881 33 313587 30 314293 26 315000 8',\n",
       " '77119 5 77819 8 78520 11 79219 14 79917 18 80568 5 80612 24 81271 11 81302 33 81975 61 82679 59 83384 60 84088 66 84793 68 85498 69 86202 39 86248 24 86907 33 86948 1 86952 26 87611 29 87656 27 88315 25 88361 11 88375 14 89019 22 89067 8 89082 12 89723 18 89789 9 90426 16 90495 7 91130 12 91200 6 91834 8 91905 4',\n",
       " '22075 3 22778 7 22786 3 23480 14 24182 16 24885 16 25588 17 26292 17 26995 17 27699 17 28402 18 29106 18 29810 17 30514 17 31218 17 31921 18 32625 17 33329 17 34032 18 34736 18 35440 17 36143 18 36847 18 37550 19 38254 19 38957 20 39661 20 40364 21 41068 21 41772 21 42475 21 43179 21 43883 21 44587 21 45290 22 45994 22 46698 22 47402 22 48105 23 48809 23 49513 24 50217 24 50921 24 51625 24 52329 24 53033 24 53737 24 54442 23 55146 24 55850 24 56554 24 57258 24 57963 24 58667 24 59371 24 60075 25 60779 25 61484 24 62188 24 62892 23 63597 22 64301 22 65005 21 65709 21 66414 19 67118 18 67822 17 68527 16 69231 15 69935 15 70639 14 71344 12 72048 12 72752 11 73457 9 74161 9 74865 8 75570 5',\n",
       " '846 4 1549 6 2252 7 2956 7 3659 8 4362 9 5066 9 5769 10 6472 11 7175 12 7879 11 8582 12 9286 11 9989 12 10693 11 11397 11 12101 10 12805 10 13509 9 14213 9 14917 8 15621 8 16324 8 17028 8 17732 7 18436 7 19140 6 19843 7 20547 6 21251 6 21954 6 22658 6 23362 6 24066 5 24769 6 25473 5 26177 5 26881 5 27585 4',\n",
       " '196903 4 197606 8 198310 9 199014 10 199719 10 200424 11 201128 12 201833 12 202538 12 203243 13 203949 12 204655 12 205360 14 206067 12 206773 12 207479 11 208184 11 208889 10 209595 9 210301 7 211006 6 211710 7 212415 7 213120 6 213824 7 214529 7 215234 6 215938 7 216643 7 217348 6 218053 6 218757 6 219462 5 220167 4',\n",
       " '491 23 1195 24 1901 22 2607 20 3312 19 4018 17 4723 17 5428 16 6133 16 6838 15 7543 14 8248 14 8953 14 9658 14 10363 14 11068 14 11772 15 12477 14 13182 14 13887 14 14592 13 15297 12 16001 12 16706 11 17411 10 18116 8 18821 7 19526 5 20231 3',\n",
       " '73018 1 73722 1 74425 2 75128 3 75832 3 76535 3 77238 3 77941 4 78644 4 79347 4 80049 5 80751 6 81454 7 82157 6 82860 6 83563 5 84265 6 84967 8 85670 8 86373 8 87076 8 87779 8 88482 8 89184 10 89887 10 90590 10 91292 11 91994 12 92697 12 93398 14 94101 14 94803 15 95506 15 96208 16 96911 15 97614 15 98317 15 99019 15 99722 14 100425 13 101127 13 101830 12 102532 12 103235 11 103938 11 104641 9 105344 9 106046 9 106749 9 107452 9 108155 9 108858 9 109561 8 110264 8 110966 10 111669 10 112373 9 113076 9 113780 7 114483 8 115186 8 115890 7 116594 6 117298 5',\n",
       " '62963 4 63666 7 64370 9 65073 11 65776 14 66479 17 67183 18 67887 20 68591 22 69295 25 69999 28 70703 30 71407 33 72112 35 72819 34 73525 35 74230 36 74935 38 75640 40 76344 6 76364 22 77050 2 77074 17 77782 14 78489 12 79195 12 79903 11',\n",
       " '63211 2 63913 6 64616 9 65319 11 66023 11 66726 13 67431 12 68135 13 68839 14 69544 14 70248 15 70953 14 71657 15 72362 14 73067 14 73771 15 74476 14 75181 14 75886 13 76590 13 77295 13 78000 12 78705 12 79410 11 80114 12 80819 11 81523 12 82227 12 82932 11 83637 11 84342 10 85046 11 85751 10 86455 11 87160 10 87864 11 88569 11 89273 11 89978 11 90682 11 91387 10 92091 11 92795 11 93500 11 94204 11 94908 12 95612 12 96317 11 97021 12 97726 11 98431 11 99135 11 99839 12 100544 11 101248 11 101952 12 102657 11 103361 11 104065 12 104770 11 105475 10 106179 11 106884 10 107588 11 108293 11 108997 11 109702 10 110406 11 111111 10 111816 9 112520 10 113224 10 113929 9 114633 10 115338 10 116042 11 116747 10 117451 10 118156 10 118860 10 119565 10 120270 9 120974 10 121679 10 122383 10 123088 9 123793 9 124497 10 125202 10 125906 11 126610 11 127315 11 128019 11 128724 10 129429 10 130133 10 130838 10 131542 10 132246 11 132951 11 133655 11 134360 11 135065 10 135769 11 136474 10 137178 11 137882 12 138587 11 139291 11 139996 11 140701 10 141405 10 142110 9 142814 10 143519 9 144224 8 144929 8 145634 8 146338 8 147043 7 147747 8 148451 8 149156 8 149860 8 150564 9 151269 8 151973 9 152678 9 153383 9 154087 10 154792 11 155496 12 156200 13 156905 13 157612 12 158316 16 159020 25 159724 28 160429 26 161134 23 161839 20 162544 18 163249 17 163954 15 164658 15 165363 13 166068 12 166772 12 167477 10 168181 10 168885 10 169590 9 170294 9 170998 9 171703 8 172407 8 173111 8 173816 8 174520 8 175224 8 175928 8 176632 8 177337 8 178041 8 178745 8 179449 8 180153 9 180857 9 181561 9 182265 10 182970 9 183674 9 184378 9 185083 7 185787 7 186492 6 187197 4 187902 3',\n",
       " '242458 6 243159 10 243862 11 244565 13 245269 13 245973 13 246676 14 247380 14 248084 14 248787 15 249491 15 250195 15 250898 16 251602 17 252306 17 253010 17 253714 16 254417 17 255121 16 255825 14 256529 12 257233 11 257937 9 258641 8 259345 7 260049 7 260753 6 261456 6 262160 6 262864 5 263567 6 264271 5 264974 6 265678 6 266381 6 267085 6 267789 5 268492 6 269196 5 269900 5 270604 5 271307 6 272011 5 272715 5 273418 6 274122 6 274826 5 275530 5 276233 6 276937 6 277641 5 278345 5 279048 6 279752 6 280456 6 281160 5 281863 5 282567 3 283271 1',\n",
       " '75144 2 75846 5 76549 7 77252 9 77956 9 78659 10 79363 10 80066 12 80770 13 81474 14 82177 16 82880 18 83584 20 84288 22 84992 25 85695 27 86399 29 87103 30 87806 32 88510 33 89214 35 89918 36 90622 38 91325 41 92029 42 92734 41 93438 42 94142 42 94847 41 95551 42 96255 42 96960 41 97664 42 98369 41 99073 41 99777 42 100482 42 101186 42 101890 42 102595 42 103299 43 104003 43 104708 43 105412 43 106117 43 106822 42 107528 41 108235 38 108943 35 109653 29 110360 27 111066 25 111772 23 112478 22 113184 20 113889 19 114595 17 115302 13 116016 3',\n",
       " '203036 2 203738 5 204440 8 205144 9 205847 11 206550 13 207254 14 207957 16 208661 17 209364 18 210068 18 210772 18 211475 18 212179 18 212883 17 213587 16 214291 15 214995 14 215699 13 216403 12 217107 10 217811 9 218515 9 219220 6 219924 4 220629 3 221333 3 222038 2',\n",
       " '36710 4 37410 9 38112 12 38814 14 39516 16 40219 17 40923 17 41626 17 42329 18 43031 19 43733 19 44436 19 45139 20 45842 20 46544 21 47247 21 47949 22 48652 23 49355 23 50057 24 50760 24 51464 23 52167 23 52870 23 53573 23 54276 23 54980 23 55683 23 56387 23 57090 23 57794 22 58497 22 59201 20 59904 20 60608 19 61311 19 62014 19 62718 18 63421 18 64125 17 64828 17 65532 16 66235 16 66938 16 67642 15 68345 15 69049 14 69752 14 70455 14 71158 14 71862 13 72565 13 73268 13 73971 13 74675 12 75378 12 76081 12 76784 12 77488 11 78191 11 78894 12 79598 11 80301 12 81004 13 81708 12 82411 13 83115 12 83818 12 84522 12 85225 12 85929 11 86632 11 87336 11 88040 11 88744 10 89447 10 90151 10 90854 10 91558 9 92262 8 92966 8 93670 7',\n",
       " '1010 3 1713 5 2416 5 3119 6 3822 7 4525 7 5228 8 5932 8 6636 7 7339 8 8043 8 8747 8 9451 8 10155 7 10859 7 11562 8 12266 8 12970 7 13674 7 14378 7 15081 8 15785 8 16489 8 17193 8 17896 9 18600 9 19304 8 20007 9 20711 9 21415 10 22118 12 22822 12 23526 12 24230 13 24933 15 25637 15 26340 16 27044 16 27747 17 28451 17 29154 18 29858 19 30561 19 31265 19 31968 20 32672 20 33376 19 34079 20 34783 20 35487 19 36190 20 36894 20 37598 18 38301 19 39005 18 39708 17 40412 16 41116 14 41819 13 42523 12 43226 11 43930 10 44634 9 45337 8 46041 7 46744 7 47448 6 48151 6 48855 5 49558 6 50262 5 50966 4 51669 5 52373 4 53077 3 53780 3 54484 1',\n",
       " '339964 19 340667 26 341370 32 342072 37 342775 40 343477 44 344180 46 344883 48 345585 50 346287 55 346989 57 347692 55 347749 1 348395 51 349098 51 349802 49 350506 42 351210 33 351914 32 352618 29 353322 27 354025 13 354039 14 354729 11 355433 10 356137 9 356841 8 357545 8 358248 8 358952 8 359656 7 360360 6 361064 5 361770 1',\n",
       " '297997 3 298700 5 299403 6 300106 7 300809 7 301513 7 302216 8 302919 9 303623 8 304326 9 305030 9 305733 9 306436 10 307140 10 307843 11 308547 11 309250 12 309953 13 310656 14 311360 14 312063 15 312766 16 313468 18 314171 19 314874 20 315577 21 316279 23 316982 24 317685 25 318389 25 319092 26 319795 27 320499 26 321202 27 321906 27 322610 27 323313 27 324017 27 324721 26 325425 26 326129 25 326833 24 327538 22 328242 20 328946 19 329650 18 330354 17 331058 17 331763 9 331773 2 332467 8 333171 7 333875 6 334580 3',\n",
       " '31102 3 31803 7 32505 9 33208 10 33911 10 34614 11 35317 12 36020 13 36723 14 37427 14 38130 14 38833 15 39536 16 40239 17 40942 17 41645 18 42348 19 43051 20 43754 20 44457 21 45160 21 45862 23 46565 24 47268 24 47971 25 48675 25 49378 25 50081 26 50784 24 51487 22 52190 21 52893 19 53596 18 54299 17 55003 15 55706 13 56410 11 57113 10 57816 9 58519 8 59221 8 59924 8 60627 7 61330 6']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predictMaskSingle('train/0140b3c8f445.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can upload the weights and config to kaggle to make the predictions."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Ensemble",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
