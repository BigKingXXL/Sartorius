{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT REQUIRED LIBRARIES\n",
    "import torch\n",
    "import torchvision\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.modeling import build_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "First we load the data from the `dataset` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(\"kaggle_dataset_train\", {}, \"dataset/annotations_train.json\", \"dataset\")\n",
    "register_coco_instances(\"kaggle_dataset_test\", {}, \"dataset/annotations_val.json\", \"dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Detectron2 Model\n",
    "Now that the data is loaded we can train the Detectron2 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/09 17:04:56 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=4, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=12, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/09 17:04:57 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from dataset/annotations_train.json\n",
      "\u001b[32m[11/09 17:04:58 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[11/09 17:04:58 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 41615        |   astro    | 8122         |    cort    | 8492         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 58229        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[11/09 17:04:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[11/09 17:04:58 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[11/09 17:04:58 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/09 17:04:58 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n",
      "\u001b[32m[11/09 17:04:58 d2.engine.hooks]: \u001b[0mLoading scheduler from state_dict ...\n",
      "\u001b[32m[11/09 17:04:58 d2.engine.train_loop]: \u001b[0mStarting training from iteration 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/09 17:05:12 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 319  total_loss: 1.807  loss_cls: 0.4688  loss_box_reg: 0.581  loss_mask: 0.3118  loss_rpn_cls: 0.1572  loss_rpn_loc: 0.2737  time: 0.6072  data_time: 0.1575  lr: 0.007992  max_mem: 4553M\n",
      "\u001b[32m[11/09 17:05:25 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 339  total_loss: 1.778  loss_cls: 0.4193  loss_box_reg: 0.5526  loss_mask: 0.3071  loss_rpn_cls: 0.18  loss_rpn_loc: 0.2637  time: 0.6112  data_time: 0.0393  lr: 0.0084915  max_mem: 5149M\n",
      "\u001b[32m[11/09 17:05:36 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 359  total_loss: 1.644  loss_cls: 0.3852  loss_box_reg: 0.5621  loss_mask: 0.3125  loss_rpn_cls: 0.09831  loss_rpn_loc: 0.2538  time: 0.5918  data_time: 0.0199  lr: 0.008991  max_mem: 5149M\n",
      "\u001b[32m[11/09 17:05:47 d2.utils.events]: \u001b[0m eta: 0:05:40  iter: 379  total_loss: 1.722  loss_cls: 0.4697  loss_box_reg: 0.5419  loss_mask: 0.3024  loss_rpn_cls: 0.1642  loss_rpn_loc: 0.2703  time: 0.5911  data_time: 0.0277  lr: 0.0094905  max_mem: 5447M\n",
      "\u001b[32m[11/09 17:05:59 d2.utils.events]: \u001b[0m eta: 0:05:30  iter: 399  total_loss: 1.734  loss_cls: 0.4363  loss_box_reg: 0.5575  loss_mask: 0.3099  loss_rpn_cls: 0.1301  loss_rpn_loc: 0.2918  time: 0.5887  data_time: 0.0203  lr: 0.00999  max_mem: 5447M\n",
      "\u001b[32m[11/09 17:06:11 d2.utils.events]: \u001b[0m eta: 0:05:23  iter: 419  total_loss: 1.66  loss_cls: 0.4126  loss_box_reg: 0.5417  loss_mask: 0.3203  loss_rpn_cls: 0.1419  loss_rpn_loc: 0.2889  time: 0.5905  data_time: 0.0266  lr: 0.01049  max_mem: 5915M\n",
      "\u001b[32m[11/09 17:06:23 d2.utils.events]: \u001b[0m eta: 0:05:13  iter: 439  total_loss: 1.681  loss_cls: 0.4568  loss_box_reg: 0.5556  loss_mask: 0.3139  loss_rpn_cls: 0.1136  loss_rpn_loc: 0.2567  time: 0.5893  data_time: 0.0192  lr: 0.010989  max_mem: 5915M\n",
      "\u001b[32m[11/09 17:06:35 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 459  total_loss: 1.714  loss_cls: 0.4146  loss_box_reg: 0.5446  loss_mask: 0.3096  loss_rpn_cls: 0.1291  loss_rpn_loc: 0.2923  time: 0.5913  data_time: 0.0324  lr: 0.011489  max_mem: 5915M\n",
      "\u001b[32m[11/09 17:06:48 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 479  total_loss: 1.748  loss_cls: 0.4291  loss_box_reg: 0.541  loss_mask: 0.3192  loss_rpn_cls: 0.1199  loss_rpn_loc: 0.2615  time: 0.5959  data_time: 0.0368  lr: 0.011988  max_mem: 5915M\n",
      "\u001b[32m[11/09 17:07:00 d2.utils.events]: \u001b[0m eta: 0:04:42  iter: 499  total_loss: 1.738  loss_cls: 0.4706  loss_box_reg: 0.5434  loss_mask: 0.3272  loss_rpn_cls: 0.1184  loss_rpn_loc: 0.2668  time: 0.5972  data_time: 0.0292  lr: 0.012488  max_mem: 5915M\n",
      "\u001b[32m[11/09 17:07:12 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 519  total_loss: 1.745  loss_cls: 0.4541  loss_box_reg: 0.5397  loss_mask: 0.2899  loss_rpn_cls: 0.1549  loss_rpn_loc: 0.3022  time: 0.5996  data_time: 0.0334  lr: 0.012987  max_mem: 5915M\n",
      "\u001b[32m[11/09 17:07:24 d2.utils.events]: \u001b[0m eta: 0:04:20  iter: 539  total_loss: 1.733  loss_cls: 0.431  loss_box_reg: 0.5855  loss_mask: 0.3235  loss_rpn_cls: 0.1455  loss_rpn_loc: 0.2688  time: 0.5988  data_time: 0.0246  lr: 0.013487  max_mem: 5915M\n",
      "\u001b[32m[11/09 17:07:35 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 559  total_loss: 1.681  loss_cls: 0.4025  loss_box_reg: 0.5426  loss_mask: 0.3078  loss_rpn_cls: 0.1454  loss_rpn_loc: 0.2658  time: 0.5945  data_time: 0.0210  lr: 0.013986  max_mem: 5915M\n",
      "\u001b[32m[11/09 17:07:47 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 579  total_loss: 1.818  loss_cls: 0.4672  loss_box_reg: 0.539  loss_mask: 0.3054  loss_rpn_cls: 0.2311  loss_rpn_loc: 0.278  time: 0.5954  data_time: 0.0270  lr: 0.014486  max_mem: 5915M\n",
      "\u001b[32m[11/09 17:08:00 d2.utils.events]: \u001b[0m eta: 0:03:47  iter: 599  total_loss: 1.78  loss_cls: 0.4599  loss_box_reg: 0.5404  loss_mask: 0.3154  loss_rpn_cls: 0.1697  loss_rpn_loc: 0.2828  time: 0.5979  data_time: 0.0326  lr: 0.014985  max_mem: 5915M\n",
      "\u001b[32m[11/09 17:08:11 d2.utils.events]: \u001b[0m eta: 0:03:36  iter: 619  total_loss: 1.786  loss_cls: 0.4457  loss_box_reg: 0.5544  loss_mask: 0.2987  loss_rpn_cls: 0.1422  loss_rpn_loc: 0.2803  time: 0.5965  data_time: 0.0248  lr: 0.015485  max_mem: 5915M\n",
      "\u001b[32m[11/09 17:08:23 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 639  total_loss: 1.707  loss_cls: 0.3956  loss_box_reg: 0.5807  loss_mask: 0.297  loss_rpn_cls: 0.1193  loss_rpn_loc: 0.2662  time: 0.5947  data_time: 0.0287  lr: 0.015984  max_mem: 5915M\n",
      "\u001b[32m[11/09 17:08:35 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 659  total_loss: 1.879  loss_cls: 0.5312  loss_box_reg: 0.5527  loss_mask: 0.3279  loss_rpn_cls: 0.1682  loss_rpn_loc: 0.2867  time: 0.5962  data_time: 0.0322  lr: 0.016484  max_mem: 5915M\n",
      "\u001b[32m[11/09 17:08:46 d2.utils.events]: \u001b[0m eta: 0:03:02  iter: 679  total_loss: 1.69  loss_cls: 0.4112  loss_box_reg: 0.5529  loss_mask: 0.296  loss_rpn_cls: 0.0948  loss_rpn_loc: 0.2616  time: 0.5944  data_time: 0.0174  lr: 0.016983  max_mem: 5915M\n",
      "\u001b[32m[11/09 17:08:59 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 699  total_loss: 1.736  loss_cls: 0.4173  loss_box_reg: 0.556  loss_mask: 0.3162  loss_rpn_cls: 0.1495  loss_rpn_loc: 0.2536  time: 0.5956  data_time: 0.0387  lr: 0.017483  max_mem: 5915M\n",
      "\u001b[32m[11/09 17:09:11 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 719  total_loss: 1.712  loss_cls: 0.4247  loss_box_reg: 0.5247  loss_mask: 0.3072  loss_rpn_cls: 0.1734  loss_rpn_loc: 0.2681  time: 0.5961  data_time: 0.0299  lr: 0.017982  max_mem: 5915M\n",
      "\u001b[32m[11/09 17:09:23 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 739  total_loss: 1.752  loss_cls: 0.469  loss_box_reg: 0.5818  loss_mask: 0.2995  loss_rpn_cls: 0.1335  loss_rpn_loc: 0.2656  time: 0.5962  data_time: 0.0316  lr: 0.018482  max_mem: 5915M\n",
      "\u001b[32m[11/09 17:09:35 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 759  total_loss: 1.709  loss_cls: 0.4562  loss_box_reg: 0.5544  loss_mask: 0.3111  loss_rpn_cls: 0.1323  loss_rpn_loc: 0.2836  time: 0.5970  data_time: 0.0261  lr: 0.018981  max_mem: 5915M\n",
      "\u001b[32m[11/09 17:09:47 d2.utils.events]: \u001b[0m eta: 0:02:05  iter: 779  total_loss: 1.92  loss_cls: 0.4524  loss_box_reg: 0.5686  loss_mask: 0.3246  loss_rpn_cls: 0.1993  loss_rpn_loc: 0.3168  time: 0.5968  data_time: 0.0250  lr: 0.019481  max_mem: 5915M\n",
      "\u001b[32m[11/09 17:09:59 d2.utils.events]: \u001b[0m eta: 0:01:53  iter: 799  total_loss: 1.784  loss_cls: 0.4549  loss_box_reg: 0.5553  loss_mask: 0.3058  loss_rpn_cls: 0.1815  loss_rpn_loc: 0.2742  time: 0.5961  data_time: 0.0215  lr: 0.01998  max_mem: 6325M\n",
      "\u001b[32m[11/09 17:10:11 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 819  total_loss: 2.003  loss_cls: 0.5517  loss_box_reg: 0.5555  loss_mask: 0.3156  loss_rpn_cls: 0.202  loss_rpn_loc: 0.3204  time: 0.5968  data_time: 0.0392  lr: 0.02048  max_mem: 6325M\n",
      "\u001b[32m[11/09 17:10:23 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 839  total_loss: 1.831  loss_cls: 0.4856  loss_box_reg: 0.5718  loss_mask: 0.3064  loss_rpn_cls: 0.1703  loss_rpn_loc: 0.2899  time: 0.5974  data_time: 0.0272  lr: 0.020979  max_mem: 6325M\n",
      "\u001b[32m[11/09 17:10:35 d2.utils.events]: \u001b[0m eta: 0:01:20  iter: 859  total_loss: 1.836  loss_cls: 0.464  loss_box_reg: 0.5393  loss_mask: 0.3144  loss_rpn_cls: 0.1741  loss_rpn_loc: 0.3148  time: 0.5978  data_time: 0.0291  lr: 0.021479  max_mem: 6325M\n",
      "\u001b[32m[11/09 17:10:48 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 879  total_loss: 1.758  loss_cls: 0.4275  loss_box_reg: 0.5223  loss_mask: 0.3037  loss_rpn_cls: 0.1844  loss_rpn_loc: 0.2848  time: 0.5989  data_time: 0.0349  lr: 0.021978  max_mem: 6325M\n",
      "\u001b[32m[11/09 17:10:59 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 899  total_loss: 1.728  loss_cls: 0.414  loss_box_reg: 0.5438  loss_mask: 0.3138  loss_rpn_cls: 0.1347  loss_rpn_loc: 0.315  time: 0.5977  data_time: 0.0240  lr: 0.022478  max_mem: 6325M\n",
      "\u001b[32m[11/09 17:11:12 d2.utils.events]: \u001b[0m eta: 0:00:45  iter: 919  total_loss: 1.862  loss_cls: 0.4512  loss_box_reg: 0.5266  loss_mask: 0.327  loss_rpn_cls: 0.1922  loss_rpn_loc: 0.3092  time: 0.5984  data_time: 0.0348  lr: 0.022977  max_mem: 6325M\n",
      "\u001b[32m[11/09 17:11:25 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 939  total_loss: 1.923  loss_cls: 0.4572  loss_box_reg: 0.5575  loss_mask: 0.3348  loss_rpn_cls: 0.2388  loss_rpn_loc: 0.3661  time: 0.5995  data_time: 0.0435  lr: 0.023477  max_mem: 6325M\n",
      "\u001b[32m[11/09 17:11:36 d2.utils.events]: \u001b[0m eta: 0:00:22  iter: 959  total_loss: 1.913  loss_cls: 0.422  loss_box_reg: 0.5625  loss_mask: 0.3276  loss_rpn_cls: 0.2027  loss_rpn_loc: 0.3267  time: 0.5979  data_time: 0.0163  lr: 0.023976  max_mem: 6325M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[11/09 17:11:50 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 979  total_loss: 1.699  loss_cls: 0.4343  loss_box_reg: 0.5496  loss_mask: 0.2904  loss_rpn_cls: 0.1535  loss_rpn_loc: 0.3052  time: 0.5982  data_time: 0.0411  lr: 0.024476  max_mem: 6325M\n",
      "\u001b[32m[11/09 17:12:06 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 1.741  loss_cls: 0.4183  loss_box_reg: 0.5419  loss_mask: 0.2974  loss_rpn_cls: 0.1901  loss_rpn_loc: 0.3154  time: 0.5991  data_time: 0.0430  lr: 0.024975  max_mem: 6325M\n",
      "\u001b[32m[11/09 17:12:07 d2.engine.hooks]: \u001b[0mOverall training speed: 698 iterations in 0:06:58 (0.5991 s / it)\n",
      "\u001b[32m[11/09 17:12:07 d2.engine.hooks]: \u001b[0mTotal training time: 0:07:05 (0:00:07 on hooks)\n",
      "\u001b[32m[11/09 17:12:07 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from dataset/annotations_val.json\n",
      "\u001b[32m[11/09 17:12:07 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 10671        |   astro    | 2400         |    cort    | 2285         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 15356        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[11/09 17:12:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[11/09 17:12:07 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[11/09 17:12:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/09 17:12:07 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.INPUT.MASK_FORMAT='bitmask'\n",
    "cfg.DATASETS.TRAIN = (\"kaggle_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"kaggle_dataset_test\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 8\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.0025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 1000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 400   # faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=True)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "As evaluation metric the `intersection over union objects` is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DefaultTrainer' object has no attribute '__attributes__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1037/522164041.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__attributes__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DefaultTrainer' object has no attribute '__attributes__'"
     ]
    }
   ],
   "source": [
    "model = build_model(cfg)\n",
    "trainer.__attributes__"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
